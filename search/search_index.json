{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"index.html","title":"Bem vindo disciplina de AI Engineering, Cognitive and Semantics Computing &amp; IoT","text":"<p>Ol\u00e1 pessoal, bem vindos!! Nesta p\u00e1gina voc\u00ea ir\u00e1 encontrar os conte\u00fados ministrados em sala de aula assim como dicas,atividades, labor\u00f3rios e muito mais. </p> <ul> <li>Curso: Sistemas da Informa\u00e7\u00e3o</li> <li>Disciplina: AI Engineering, Cognitive and Semantics Computing &amp; IoT</li> <li>Turmas 2025: 4SIPF, 4SIR</li> <li>Reposit\u00f3rio com todos os arquivos est\u00e1 disponivel em: https://github.com/arnaldojr/cognitivecomputing/</li> </ul> <p>Prof. Arnaldo Viana</p>"},{"location":"index.html#objetivos","title":"Objetivos","text":"<p>Nosso curso est\u00e1 dividido em IA e IoT, ao final da disciplina o estudante ser\u00e1 capaz de:</p> <ul> <li>Compreender o conceitos de Processamento digital de imagens </li> <li>Conhecer as principais tecnicas para detec\u00e7\u00e3o e segmenta\u00e7\u00e3o de objetos</li> <li>Conhecer e aplicar tecnicas de vis\u00e3o computacional</li> <li>Compreender os conceitos de An\u00e1lise de dados, Machine Learning (ML) e Deep Learning (DL)</li> <li>Aplicar conceitos e t\u00e9cnicas de DL</li> <li>Desenvolver pequenos projetos envolvendo IA.</li> <li>Compreender o conceitos de sistemas baseados em IoT (Internet das Coisas)</li> <li>Conhecer as principais tecnologias habilitadoras da IoT</li> <li>Programar e desenvolver pequenos projetos de IoT</li> </ul>"},{"location":"index.html#o-que-preciso-tersaber-para-acompanhar-esse-curso","title":"O que preciso ter/saber para acompanhar esse curso?","text":"<ul> <li>L\u00f3gica de programa\u00e7\u00e3o</li> <li>Python b\u00e1sico</li> <li>Algebra linear</li> <li>Dedica\u00e7\u00e3o</li> </ul>"},{"location":"index.html#dinamica-das-aulas","title":"Din\u00e2mica das aulas:","text":"<p>O curso \u00e9 baseadas em desafios (exercicios, atividades, pesquisa e etc.) que abordam teoria e pr\u00e1tica.</p> <p>Por essa raz\u00e3o as aulas est\u00e3o divididas em pequenos laborat\u00f3rios, cada laborat\u00f3rio possui os seus objetivos especificos. </p> <p></p>"},{"location":"index.html#quais-software-preciso-instalar-para-acompanhar-esse-curso","title":"Quais software preciso instalar para acompanhar esse curso?","text":"<p>Basicamente, vamos trabalhar com scripts em python e algumas bibliotecas que podem ser executados localmente ou em nuvem. </p> <p>Como sugest\u00e3o de instala\u00e7\u00e3o local:</p> <ul> <li>Python 3.x.</li> <li>Jupyter Notebook.</li> <li>Anaconda.</li> </ul> <p>Em nuvem:</p> <ul> <li>Google Colab.</li> <li> <p>Kaggle.</p> </li> <li> <p>Quer detalhes de como instalar a infra necess\u00e1ria para o curso? Da uma olhadinha na aba instala\u00e7\u00e3o.</p> </li> </ul>"},{"location":"index.html#ideias-de-projetos","title":"Id\u00e9ias de projetos","text":"<p>As aplica\u00e7\u00f5es s\u00e3o vastas e diversas... Para ajudar a despertar a curiosidade, pense de que forma podemos utilizar ML para resolver um problema do nosso dia a dia.</p>"},{"location":"index.html#bibliografia","title":"Bibliografia","text":"<ul> <li>Stewart Russel e Peter Norvig . Intelig\u00eancia artificial. 3\u00aa. Ed., Rio de Janeiro: Campus, 2012.</li> <li>George F. Luger . Intelig\u00eancia Artificial, 6\u00aa ed. S\u00e3o Paulo: Pearson Education do Brasil, 2013 (biblioteca virtual)</li> <li>Aur\u00e9lien Geron. 2019. Hands-On Machine Learning with Scikit-Learn, Keras, and Tensorflow: Concepts, Tools, and Techniques to Build Intelligent Systems</li> </ul>"},{"location":"agenda/agenda.html","title":"Agenda","text":""},{"location":"agenda/agenda.html#cronograma","title":"Cronograma","text":""},{"location":"agenda/agenda.html#1o-semestre-2025","title":"1\u00ba Semestre - 2025","text":"4SIPF(Segunda) 4SIPF(Sexta) 4SIR(Quinta) LABORAT\u00d3RIO CONTE\u00daDO 10/02/2025 14/02/2025 13/02/2025 lab1 Aula MagnaApresenta\u00e7\u00e3o do curso, din\u00e2mica das aulas, datas importantes (CP), lan\u00e7amento CP1 17/02/2025 21/02/2025 20/02/2025 lab02, lab03 Processamento de imagem digital. Segmenta\u00e7\u00e3o por pixel, histograma e equaliza\u00e7\u00e3o de histograma 24/02/2025 28/02/2025 27/02/2025 lab04, lab05 filtos de convolu\u00e7\u00e3o, espa\u00e7o de cores e contorno 03/03/2025 07/03/2025 06/03/2025 lab06, la07 transformada de hough, traking de objetos 10/03/2025 14/03/2025 13/03/2025 lab08, lab09 Relacionamento e opera\u00e7\u00f5es entre imagens, FFT 17/03/2025 21/03/2025 20/03/2025 lab10, lab11 medidas aproximadas, transformada de watershed 24/03/2025 28/03/2025 27/03/2025 avalia\u00e7\u00e3o CP1 AVALIA\u00c7\u00c3O EM AULA CP1CP1 - Sistema de segmenta\u00e7\u00e3o de objetos 31/03/2025 04/04/2025 03/04/2025 -- feriado (quinta e sexta) paix\u00e3o de cristo 07/04/2025 11/04/2025 10/04/2025 lab12, lab13 template matching, features ORB, SIFT 14/04/2025 18/04/2025 17/04/2025 lab14, lab15 Haar Cascade, Event Mouse 21/04/2025 25/04/2025 24/04/2025 lab16, lab17 Detector dlib, aplica\u00e7\u00f5es media pipe 28/04/2025 02/05/2025 01/05/2025 Deep Learing, lab7-IA Introdu\u00e7\u00e3o ao deep learning - MLP 05/05/2025 09/05/2025 08/05/2025 lab8-IA Treinamento de CNN, Aplica\u00e7\u00f5es em Redes Neurais pr\u00e9-treinadas 12/05/2025 16/05/2025 15/05/2025 lab9-IA, lab10-IA Aplica\u00e7\u00e3o de Transfer Learning 19/05/2025 23/05/2025 22/05/2025 lab9-IA p.2, lab10-IA Simulado GS Aplica\u00e7\u00e3o de redes neurais com transfer learning e libera o simulado da GS 26/05/2025 30/05/2025 29/05/2025 apresnta mini projeto CP2 AAVALIA\u00c7\u00c3O EM AULA CP2CP2 - Apresenta\u00e7\u00e3o Mini-projeto de Vis\u00e3o Computacional 02/06/2025 06/06/2025 05/06/2025 avalia\u00e7\u00e3o GS1 02/06 - Inicio Global Solutions"},{"location":"aulas/IA/batalharedes/batalha_das_redes.html","title":"BATALHA DAS REDES","text":"In\u00a0[\u00a0]: Copied! <pre>## importa dataset\nfrom sklearn.datasets import load_iris\nfrom sklearn.model_selection import train_test_split\n\ndef iris():\n    iris = load_iris()\n    X, y = iris.data, iris.target\n    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n    return X_train, X_test, y_train, y_test\n</pre> ## importa dataset from sklearn.datasets import load_iris from sklearn.model_selection import train_test_split  def iris():     iris = load_iris()     X, y = iris.data, iris.target     X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)      return X_train, X_test, y_train, y_test  In\u00a0[\u00a0]: Copied! <pre>import pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\n\ndef heart():\n    url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/heart-disease/processed.cleveland.data\"\n    columns = ['age', 'sex', 'cp', 'trestbps', 'chol', 'fbs', 'restecg', 'thalach', 'exang', 'oldpeak', 'slope', 'ca', 'thal', 'target']\n\n    heart_disease_data = pd.read_csv(url, header=None, names=columns, na_values=\"?\")\n    #valores ausentes (NaN), substitue pela m\u00e9dia da coluna\n    heart_disease_data.fillna(heart_disease_data.mean(), inplace=True)\n\n    X = heart_disease_data.drop('target', axis=1)\n    y = heart_disease_data[\"target\"].values\n    # Converta os valores de r\u00f3tulo 1-4 em 1\n    y = np.where(y &gt; 0, 1, 0)\n\n\n    scaler = StandardScaler()\n    X_scaled = scaler.fit_transform(X)\n\n\n    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n    return X_train, X_test, y_train, y_test\n</pre> import pandas as pd from sklearn.model_selection import train_test_split from sklearn.preprocessing import StandardScaler  def heart():     url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/heart-disease/processed.cleveland.data\"     columns = ['age', 'sex', 'cp', 'trestbps', 'chol', 'fbs', 'restecg', 'thalach', 'exang', 'oldpeak', 'slope', 'ca', 'thal', 'target']      heart_disease_data = pd.read_csv(url, header=None, names=columns, na_values=\"?\")     #valores ausentes (NaN), substitue pela m\u00e9dia da coluna     heart_disease_data.fillna(heart_disease_data.mean(), inplace=True)      X = heart_disease_data.drop('target', axis=1)     y = heart_disease_data[\"target\"].values     # Converta os valores de r\u00f3tulo 1-4 em 1     y = np.where(y &gt; 0, 1, 0)       scaler = StandardScaler()     X_scaled = scaler.fit_transform(X)       X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)      return X_train, X_test, y_train, y_test In\u00a0[\u00a0]: Copied! <pre>import tensorflow as tf\n\ndef cifar():\n    (X_train, y_train), (X_test, y_test) = tf.keras.datasets.cifar10.load_data()\n\n    X_train = X_train.astype('float32')\n    X_test = X_test.astype('float32')\n    #normaliza os dados para o pixel ficar com valores entre 0 e 1\n    X_train = X_train / 255.0\n    X_test = X_test / 255.0\n\n    print('shape original')\n    print('X_train: {}, X_test: {}, y_train:{}, y_test:{}'.format(X_train.shape, X_test.shape, y_train.shape, y_test.shape))\n    print('shape redimensionado, flatten')\n    X_train = X_train.reshape(X_train.shape[0], -1)\n    X_test = X_test.reshape(X_test.shape[0], -1)\n\n    return X_train, X_test, y_train, y_test\n</pre> import tensorflow as tf  def cifar():     (X_train, y_train), (X_test, y_test) = tf.keras.datasets.cifar10.load_data()      X_train = X_train.astype('float32')     X_test = X_test.astype('float32')     #normaliza os dados para o pixel ficar com valores entre 0 e 1     X_train = X_train / 255.0     X_test = X_test / 255.0      print('shape original')     print('X_train: {}, X_test: {}, y_train:{}, y_test:{}'.format(X_train.shape, X_test.shape, y_train.shape, y_test.shape))     print('shape redimensionado, flatten')     X_train = X_train.reshape(X_train.shape[0], -1)     X_test = X_test.reshape(X_test.shape[0], -1)      return X_train, X_test, y_train, y_test In\u00a0[\u00a0]: Copied! <pre># Importa\u00e7\u00e3o das bibliotecas necess\u00e1rias\nimport numpy as np\nimport pandas as pd\nimport tensorflow as tf\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense\nfrom tensorflow.keras.layers import Dropout\nfrom tensorflow.keras.layers import BatchNormalization\nfrom keras.utils.np_utils import to_categorical\n\n# importa as m\u00e9tricas de avalia\u00e7\u00e3o\nfrom sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n</pre> # Importa\u00e7\u00e3o das bibliotecas necess\u00e1rias import numpy as np import pandas as pd import tensorflow as tf from tensorflow.keras.models import Sequential from tensorflow.keras.layers import Dense from tensorflow.keras.layers import Dropout from tensorflow.keras.layers import BatchNormalization from keras.utils.np_utils import to_categorical  # importa as m\u00e9tricas de avalia\u00e7\u00e3o from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score  In\u00a0[\u00a0]: Copied! <pre>### dataset da rodada, basta descomentar uma das linhas abaixo\n\n#dataset = 'rodada1'\n#dataset = 'rodada2'\ndataset = 'rodada3'\n\n\n\n# Fun\u00e7\u00e3o para carregar e preprocessar o dataset\ndef load_and_preprocess_data(dataset):\n    if dataset == \"rodada1\":\n        X_train, X_test, y_train, y_test = iris()\n\n    elif dataset == \"rodada2\":\n        X_train, X_test, y_train, y_test = heart()\n\n    else:\n        X_train, X_test, y_train, y_test = cifar()\n\n    return X_train, X_test, y_train, y_test\n\n# Carregue e preprocess os dados\nX_train, X_test, y_train, y_test = load_and_preprocess_data(dataset)\n\nprint(\"\\n---------LEIA COM ATEN\u00c7\u00c3O--------------------------\")\nprint('\\nX_train: {}, X_test: {}\\ny_train: {}, y_test: {}'.format(X_train.shape, X_test.shape, y_train.shape, y_test.shape))\n</pre> ### dataset da rodada, basta descomentar uma das linhas abaixo  #dataset = 'rodada1' #dataset = 'rodada2' dataset = 'rodada3'    # Fun\u00e7\u00e3o para carregar e preprocessar o dataset def load_and_preprocess_data(dataset):     if dataset == \"rodada1\":         X_train, X_test, y_train, y_test = iris()      elif dataset == \"rodada2\":         X_train, X_test, y_train, y_test = heart()      else:         X_train, X_test, y_train, y_test = cifar()      return X_train, X_test, y_train, y_test  # Carregue e preprocess os dados X_train, X_test, y_train, y_test = load_and_preprocess_data(dataset)  print(\"\\n---------LEIA COM ATEN\u00c7\u00c3O--------------------------\") print('\\nX_train: {}, X_test: {}\\ny_train: {}, y_test: {}'.format(X_train.shape, X_test.shape, y_train.shape, y_test.shape)) In\u00a0[\u00a0]: Copied! <pre># Fun\u00e7\u00e3o para criar o modelo MLP\ndef create_model(dataset):\n    model = Sequential()\n    # Adicione as camadas aqui\n\n\n\n\n\n    # Compile o modelo N\u00e3o altera aqui, por enquanto.\n    if dataset == 'rodada2': model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n    else: model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n\n    return model\n\n# Crie o modelo\nprint(dataset)\nmodel = create_model(dataset)\n\nmodel.summary()\nprint(\"Loss function:\", model.loss)\nprint(\"Optimizer name:\", model.optimizer.get_config()[\"name\"])\n</pre> # Fun\u00e7\u00e3o para criar o modelo MLP def create_model(dataset):     model = Sequential()     # Adicione as camadas aqui          # Compile o modelo N\u00e3o altera aqui, por enquanto.     if dataset == 'rodada2': model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])     else: model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])      return model  # Crie o modelo print(dataset) model = create_model(dataset)  model.summary() print(\"Loss function:\", model.loss) print(\"Optimizer name:\", model.optimizer.get_config()[\"name\"])  In\u00a0[\u00a0]: Copied! <pre># Treine o modelo\nhistory = model.fit(X_train, y_train, epochs=10, validation_split=0.2)\n\n#Validad\u00e7\u00e3o\ntrain_loss, train_acc = model.evaluate(X_train,  y_train, verbose=2)\ntest_loss, test_acc = model.evaluate(X_test,  y_test, verbose=2)\n</pre> # Treine o modelo history = model.fit(X_train, y_train, epochs=10, validation_split=0.2)  #Validad\u00e7\u00e3o train_loss, train_acc = model.evaluate(X_train,  y_train, verbose=2) test_loss, test_acc = model.evaluate(X_test,  y_test, verbose=2) In\u00a0[\u00a0]: Copied! <pre>## exibe os graficos da fun\u00e7\u00e3o loss e acuracia\n\nhistory_df = pd.DataFrame(history.history)\n\nhistory_df[['loss','val_loss']].plot();\nhistory_df[['accuracy','val_accuracy']].plot();\n</pre> ## exibe os graficos da fun\u00e7\u00e3o loss e acuracia  history_df = pd.DataFrame(history.history)  history_df[['loss','val_loss']].plot(); history_df[['accuracy','val_accuracy']].plot();  In\u00a0[\u00a0]: Copied! <pre># Fun\u00e7\u00e3o para avaliar o modelo\ndef train_and_evaluate_model(model, dataset, X_train, X_test, y_train, y_test):\n\n    # Fa\u00e7a previs\u00f5es no conjunto de teste\n    if dataset =='rodada2':\n      y_pred = np.round(model.predict(X_test))\n    else:\n      y_pred = np.argmax(model.predict(X_test), axis=-1)\n\n    # Converta os r\u00f3tulos para inteiros\n    y_test = y_test.astype(int)\n    y_pred = y_pred.astype(int)\n\n\n    # Calcule as m\u00e9tricas de avalia\u00e7\u00e3o\n    accuracy = accuracy_score(y_test, y_pred)\n    precision = precision_score(y_test, y_pred, average='weighted')\n    recall = recall_score(y_test, y_pred, average='weighted')\n    f1 = f1_score(y_test, y_pred, average='weighted')\n\n    return accuracy, precision, recall, f1\n\n# Treine e avalie o modelo\naccuracy, precision, recall, f1 = train_and_evaluate_model(model,dataset, X_train, X_test, y_train, y_test)\n\n# Exiba os resultados\nprint(\"Acur\u00e1cia:\", accuracy)\nprint(\"Precis\u00e3o:\", precision)\nprint(\"Revoca\u00e7\u00e3o:\", recall)\nprint(\"F1-Score:\", f1)\n</pre> # Fun\u00e7\u00e3o para avaliar o modelo def train_and_evaluate_model(model, dataset, X_train, X_test, y_train, y_test):      # Fa\u00e7a previs\u00f5es no conjunto de teste     if dataset =='rodada2':       y_pred = np.round(model.predict(X_test))     else:       y_pred = np.argmax(model.predict(X_test), axis=-1)      # Converta os r\u00f3tulos para inteiros     y_test = y_test.astype(int)     y_pred = y_pred.astype(int)       # Calcule as m\u00e9tricas de avalia\u00e7\u00e3o     accuracy = accuracy_score(y_test, y_pred)     precision = precision_score(y_test, y_pred, average='weighted')     recall = recall_score(y_test, y_pred, average='weighted')     f1 = f1_score(y_test, y_pred, average='weighted')      return accuracy, precision, recall, f1  # Treine e avalie o modelo accuracy, precision, recall, f1 = train_and_evaluate_model(model,dataset, X_train, X_test, y_train, y_test)  # Exiba os resultados print(\"Acur\u00e1cia:\", accuracy) print(\"Precis\u00e3o:\", precision) print(\"Revoca\u00e7\u00e3o:\", recall) print(\"F1-Score:\", f1)  In\u00a0[\u00a0]: Copied! <pre>\n</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre>"},{"location":"aulas/IA/batalharedes/batalha_das_redes.html#2-redes-neurais","title":"2. Redes Neurais\u00b6","text":""},{"location":"aulas/IA/batalharedes/batalha_das_redes.html#objetivos","title":"Objetivos\u00b6","text":"<ul> <li>Conhecer e praticar Redes Neurais MLP</li> </ul>"},{"location":"aulas/IA/batalharedes/batalha_das_redes.html#batalha-das-redes","title":"Batalha das redes\u00b6","text":"<p>Bem-vindos \u00e0 nossa emocionante competi\u00e7\u00e3o de Redes Neurais Multilayer Perceptron (MLP)! Hoje, voc\u00eas participar\u00e3o de uma competi\u00e7\u00e3o estilo Kaggle simplificada, projetada para colocar suas habilidades \u00e0 prova e acelerar sua aprendizagem em um ambiente divertido e colaborativo.</p> <p>Ao longo desta aula, voc\u00eas enfrentar\u00e3o tr\u00eas rodadas de desafios, cada uma com um dataset de dificuldade crescente. O objetivo \u00e9 criar e otimizar modelos de redes neurais MLP para resolver problemas de classifica\u00e7\u00e3o. Voc\u00eas trabalhar\u00e3o em duplas para desenvolver as melhores solu\u00e7\u00f5es poss\u00edveis, competindo uns contra os outros para ver quem alcan\u00e7a o melhor desempenho.</p> <p>A competi\u00e7\u00e3o \u00e9 estruturada da seguinte maneira:</p> <ul> <li>Primeira rodada: Dataset f\u00e1cil para que todos possam se familiarizar com o processo e come\u00e7ar a se aquecer.</li> <li>Segunda rodada: Dataset de dificuldade m\u00e9dia para desafiar suas habilidades e encoraj\u00e1-los a explorar t\u00e9cnicas avan\u00e7adas de otimiza\u00e7\u00e3o.</li> <li>Terceira rodada: Dataset dif\u00edcil, onde voc\u00eas colocar\u00e3o \u00e0 prova tudo o que aprenderam, desenvolvendo solu\u00e7\u00f5es para problemas complexos e realistas.</li> </ul> <p>Voc\u00eas ser\u00e3o avaliados com base no desempenho de suas redes neurais e em crit\u00e9rios relacionados \u00e0 arquitetura e complexidade da rede. Isso inclui m\u00e9tricas como acur\u00e1cia, F1-Score e o n\u00famero de neur\u00f4nios usados no modelo. O objetivo \u00e9 incentivar a cria\u00e7\u00e3o de solu\u00e7\u00f5es eficientes e de alto desempenho.</p> <p>Preparem-se para mergulhar no mundo das redes neurais e aprender atrav\u00e9s da experi\u00eancia pr\u00e1tica. A competi\u00e7\u00e3o ser\u00e1 acirrada, mas, no final, todos sair\u00e3o ganhando com o conhecimento e as habilidades adquiridas.</p> <p>Boa sorte a todos e que ven\u00e7a a melhor solu\u00e7\u00e3o!</p>"},{"location":"aulas/IA/batalharedes/batalha_das_redes.html#descricao-dos-datasets-para-as-rodadas-de-competicao","title":"Descri\u00e7\u00e3o dos Datasets para as Rodadas de Competi\u00e7\u00e3o\u00b6","text":"<p>Ao longo desta competi\u00e7\u00e3o, voc\u00eas enfrentar\u00e3o tr\u00eas rodadas de desafios, cada uma com um dataset de dificuldade crescente. Abaixo est\u00e3o as descri\u00e7\u00f5es dos datasets selecionados para cada rodada:</p>"},{"location":"aulas/IA/batalharedes/batalha_das_redes.html#primeira-rodada-dataset-facil-iris-dataset","title":"Primeira rodada - Dataset f\u00e1cil: Iris Dataset\u00b6","text":"<p>O <code>Iris dataset</code> voc\u00ea j\u00e1 conhece, \u00e9 um conjunto cl\u00e1ssico de dados usado para problemas de classifica\u00e7\u00e3o. Ele cont\u00e9m 150 amostras de flores de \u00edris, divididas em 3 classes, cada uma representando um tipo de \u00edris (Setosa, Versicolour e Virginica). Para cada amostra, h\u00e1 quatro caracter\u00edsticas: comprimento e largura das s\u00e9palas e p\u00e9talas.</p> <p>O objetivo \u00e9 criar um modelo MLP para classificar corretamente o tipo de \u00edris com base nessas caracter\u00edsticas.</p> <p>Para carregar o Iris dataset:</p>"},{"location":"aulas/IA/batalharedes/batalha_das_redes.html#segunda-rodada-dataset-medio-heart-disease-uci-dataset","title":"Segunda rodada - Dataset m\u00e9dio: Heart Disease UCI Dataset\u00b6","text":"<p>O <code>Heart Disease UCI dataset</code> \u00e9 um conjunto de dados m\u00e9dicos que cont\u00e9m informa\u00e7\u00f5es sobre pacientes e a presen\u00e7a de doen\u00e7as card\u00edacas. S\u00e3o 303 amostras com 13 caracter\u00edsticas, incluindo idade, sexo, press\u00e3o arterial em repouso e n\u00edveis de colesterol.</p> <p>O objetivo \u00e9 classificar as amostras em duas classes: presen\u00e7a ou aus\u00eancia de doen\u00e7a card\u00edaca.</p> <p>Para carregar o Heart Disease UCI dataset:</p>"},{"location":"aulas/IA/batalharedes/batalha_das_redes.html#terceira-rodada-dataset-dificil-cifar10-dataset","title":"Terceira rodada - Dataset dif\u00edcil: Cifar10 Dataset\u00b6","text":"<p>O <code>cifar10</code> \u00e9 um conjunto de dados mais desafiador, contendo mais de 60.000 imagens em cores de 32x32 pixels, representando 10 classes de objetos capturados em imagens reais.</p> <p>link: https://www.cs.toronto.edu/~kriz/cifar.html</p> <p>O objetivo \u00e9 criar um modelo MLP capaz de classificar corretamente cada imagem em seu respectivo d\u00edgito.</p> <p>Para carregar o SVHN dataset:</p>"},{"location":"aulas/IA/batalharedes/batalha_das_redes.html#codigo-base","title":"C\u00f3digo base\u00b6","text":"<p>O seu objetivo \u00e9 a cria\u00e7\u00e3o da rede MLP mais eficiente, este co\u00f3digo base te auxilia no restante.</p> <p>Para rodar, execute as celulas de c\u00f3digo abaixo e fa\u00e7a as altera\u00e7\u00f5es onde for solicitado:</p>"},{"location":"aulas/IA/batalharedes/batalha_das_redes.html#primeiro-passo","title":"Primeiro passo\u00b6","text":"<p>Aqui voc\u00ea deve escolhar do dataset.</p> <p>Defina o dataset de acordo com rodada da competi\u00e7\u00e3o.</p> <ul> <li>dataset = 'rodada1'   --&gt; primeira rodada</li> <li>dataset = 'rodada2'   --&gt; primeira rodada</li> <li>dataset = 'rodada3'   --&gt; primeira rodada</li> </ul>"},{"location":"aulas/IA/batalharedes/batalha_das_redes.html#segundo-passo","title":"Segundo passo\u00b6","text":"<p>Crie sua rede neural MLP dentro da fun\u00e7\u00e3o create_model().</p> <p>\u00c9 aqui que voc\u00ea vai trabalhar! Use a fun\u00e7\u00e3o create_model() para definir a arquitetura da sua rede neural MLP.</p>"},{"location":"aulas/IA/batalharedes/batalha_das_redes.html#dicas","title":"Dicas\u00b6","text":"<ul> <li>Adicione as camadas Densas, Dropout, etc.</li> <li>Adicione/altere quantidade de neuronios.</li> <li>Adicione/altere fun\u00e7\u00e3o de ativa\u00e7\u00e3o ('relu','softmax','sigmoid')</li> </ul> <p>Exemplos:</p> <ul> <li>model.add(Dense(18, activation='relu', input_shape=(4,)))</li> <li>model.add(Dropout(rate=0.5))</li> <li>model.add(BatchNormalization())</li> </ul>"},{"location":"aulas/IA/batalharedes/batalha_das_redes.html#terceiro-passo","title":"Terceiro passo\u00b6","text":"<p>Treine o seu modelo, aqui voce deve trabalhar para definir os parametros de treinamento da rede neural.</p>"},{"location":"aulas/IA/batalharedes/batalha_das_redes.html#dicas","title":"Dicas\u00b6","text":"<ul> <li>Altere quantidade de epocas, batch_size e validation_split</li> </ul>"},{"location":"aulas/IA/batalharedes/batalha_das_redes.html#quarto-passo","title":"Quarto passo\u00b6","text":"<p>Avalia\u00e7\u00e3o do modelo treinado</p>"},{"location":"aulas/IA/batalharedes/batalha_das_redes.html#pontuacao","title":"Pontua\u00e7\u00e3o\u00b6","text":"<p>Para computar seus pontos anote os resultados obtidos</p> <ul> <li>Acur\u00e1cia</li> <li>Quantidade de camadas</li> </ul>"},{"location":"aulas/IA/batalharedes/batalha_das_redes.html#se-der-empate","title":"se der empate\u00b6","text":"<ul> <li>F1-Scores</li> <li>Quantidade de parametros trein\u00e1veis</li> </ul>"},{"location":"aulas/IA/intro/index.html","title":"IA","text":"<p>Fa\u00e7a o download do pdf de Introdu\u00e7\u00e3o.</p> <ul> <li>arquivo pdf: Introdu\u00e7\u00e3o</li> </ul>"},{"location":"aulas/IA/intro/index.html#introducao","title":"Introdu\u00e7\u00e3o","text":"<p>Vamos come\u00e7ar essa etapa do nosso curso com o ciclo de vida de dados em projetos de ci\u00eancia de dados. Com foco especial no CRISP-DM (Cross-Industry Standard Process for Data Mining).</p>"},{"location":"aulas/IA/intro/index.html#ciclo-de-vida-de-dados-em-projetos-de-ciencia-de-dados","title":"Ciclo de Vida de Dados em Projetos de Ci\u00eancia de Dados","text":""},{"location":"aulas/IA/intro/index.html#1-entendimento-do-negocio","title":"1. Entendimento do Neg\u00f3cio","text":"<p>O primeiro passo em qualquer projeto de ci\u00eancia de dados \u00e9 entender o problema de neg\u00f3cio. \u00c9 fundamental definir claramente os objetivos do projeto e como os resultados ser\u00e3o utilizados pela organiza\u00e7\u00e3o. Isso geralmente envolve reuni\u00f5es com stakeholders, levantamento de requisitos e defini\u00e7\u00e3o de KPIs (Key Performance Indicators) que ajudar\u00e3o a medir o sucesso do projeto.</p>"},{"location":"aulas/IA/intro/index.html#ferramentas-e-tecnicas","title":"Ferramentas e T\u00e9cnicas","text":"<ul> <li>Entrevistas e Workshops: Para coletar informa\u00e7\u00f5es dos stakeholders e especialistas.</li> <li>Mapas Mentais: Para visualizar o problema e suas poss\u00edveis solu\u00e7\u00f5es.</li> </ul>"},{"location":"aulas/IA/intro/index.html#2-entendimento-dos-dados","title":"2. Entendimento dos Dados","text":"<p>Ap\u00f3s definir o problema de neg\u00f3cio, \u00e9 necess\u00e1rio coletar dados relevantes. Esta etapa inclui a coleta, descri\u00e7\u00e3o, explora\u00e7\u00e3o e verifica\u00e7\u00e3o da qualidade dos dados dispon\u00edveis. O entendimento dos dados ajuda a identificar quais dados s\u00e3o necess\u00e1rios e como eles podem ser usados para resolver o problema.</p>"},{"location":"aulas/IA/intro/index.html#ferramentas-e-tecnicas_1","title":"Ferramentas e T\u00e9cnicas","text":"<ul> <li>SQL e NoSQL: Para coleta de dados de bases de dados estruturadas e n\u00e3o estruturadas.</li> <li>Explora\u00e7\u00e3o de Dados: Usando ferramentas como pandas, matplotlib e seaborn para an\u00e1lise explorat\u00f3ria dos dados (EDA).</li> <li>An\u00e1lise de Qualidade dos Dados: Verifica\u00e7\u00e3o de inconsist\u00eancias, valores ausentes e outliers.</li> </ul>"},{"location":"aulas/IA/intro/index.html#3-preparacao-dos-dados","title":"3. Prepara\u00e7\u00e3o dos Dados","text":"<p>A prepara\u00e7\u00e3o dos dados \u00e9 uma das etapas mais cr\u00edticas e trabalhosas. Envolve a limpeza, transforma\u00e7\u00e3o e formata\u00e7\u00e3o dos dados para torn\u00e1-los adequados para modelagem. Esta etapa pode incluir a imputa\u00e7\u00e3o de valores ausentes, normaliza\u00e7\u00e3o, codifica\u00e7\u00e3o de vari\u00e1veis categ\u00f3ricas e sele\u00e7\u00e3o de features.</p>"},{"location":"aulas/IA/intro/index.html#ferramentas-e-tecnicas_2","title":"Ferramentas e T\u00e9cnicas","text":"<ul> <li>Pandas e NumPy: Para manipula\u00e7\u00e3o e transforma\u00e7\u00e3o de dados.</li> <li>Scikit-learn: Para t\u00e9cnicas de pr\u00e9-processamento como normaliza\u00e7\u00e3o, padroniza\u00e7\u00e3o e codifica\u00e7\u00e3o de vari\u00e1veis.</li> <li>Feature Engineering: Cria\u00e7\u00e3o de novas features a partir dos dados existentes para melhorar a performance dos modelos.</li> </ul>"},{"location":"aulas/IA/intro/index.html#4-modelagem","title":"4. Modelagem","text":"<p>Nesta etapa, diferentes t\u00e9cnicas de modelagem s\u00e3o aplicadas aos dados preparados. A escolha do modelo depende da natureza do problema e dos dados. T\u00e9cnicas comuns incluem: - Regress\u00e3o Linear e Log\u00edstica: Para problemas de previs\u00e3o e classifica\u00e7\u00e3o bin\u00e1ria. - \u00c1rvores de Decis\u00e3o e Random Forest: Para problemas de classifica\u00e7\u00e3o e regress\u00e3o. - M\u00e1quinas de Vetores de Suporte (SVM): Para problemas de classifica\u00e7\u00e3o complexos. - Redes Neurais: Para problemas de alta complexidade, como reconhecimento de imagem e processamento de linguagem natural.</p>"},{"location":"aulas/IA/intro/index.html#ferramentas-e-tecnicas_3","title":"Ferramentas e T\u00e9cnicas","text":"<ul> <li>Scikit-learn: Para algoritmos de machine learning.</li> <li>TensorFlow e Keras: Para constru\u00e7\u00e3o e treinamento de redes neurais profundas.</li> <li>Cross-validation: Para avalia\u00e7\u00e3o e valida\u00e7\u00e3o de modelos.</li> </ul>"},{"location":"aulas/IA/intro/index.html#5-avaliacao","title":"5. Avalia\u00e7\u00e3o","text":"<p>A avalia\u00e7\u00e3o do modelo \u00e9 crucial para garantir que ele atenda aos objetivos do neg\u00f3cio. M\u00e9tricas comuns de avalia\u00e7\u00e3o incluem precis\u00e3o, recall, F1-score, e AUC-ROC. A avalia\u00e7\u00e3o deve ser feita em dados que n\u00e3o foram usados no treinamento para garantir a generaliza\u00e7\u00e3o do modelo.</p>"},{"location":"aulas/IA/intro/index.html#ferramentas-e-tecnicas_4","title":"Ferramentas e T\u00e9cnicas","text":"<ul> <li>M\u00e9tricas de Avalia\u00e7\u00e3o: Como precis\u00e3o, recall, F1-score, AUC-ROC para classifica\u00e7\u00e3o; RMSE, MAE para regress\u00e3o.</li> <li>Confusion Matrix: Para an\u00e1lise detalhada de modelos de classifica\u00e7\u00e3o.</li> <li>ROC Curves e Precision-Recall Curves: Para avalia\u00e7\u00e3o de modelos bin\u00e1rios.</li> </ul>"},{"location":"aulas/IA/intro/index.html#6-implantacao","title":"6. Implanta\u00e7\u00e3o","text":"<p>Uma vez que o modelo \u00e9 avaliado e aprovado, ele \u00e9 implantado no ambiente de produ\u00e7\u00e3o. Esta etapa envolve a integra\u00e7\u00e3o do modelo nos sistemas existentes e a configura\u00e7\u00e3o de monitoramento e manuten\u00e7\u00e3o cont\u00ednua. A implanta\u00e7\u00e3o pode ser feita atrav\u00e9s de APIs, sistemas de batch processing ou integra\u00e7\u00e3o direta em aplica\u00e7\u00f5es web e mobile.</p>"},{"location":"aulas/IA/intro/index.html#ferramentas-e-tecnicas_5","title":"Ferramentas e T\u00e9cnicas","text":"<ul> <li>Flask e FastAPI: Para servir modelos como APIs web.</li> <li>Docker e Kubernetes: Para containeriza\u00e7\u00e3o e orquestra\u00e7\u00e3o de servi\u00e7os.</li> <li>Monitoramento: Usando ferramentas como Prometheus e Grafana para monitorar a performance do modelo em produ\u00e7\u00e3o.</li> </ul>"},{"location":"aulas/IA/intro/index.html#crisp-dm-cross-industry-standard-process-for-data-mining","title":"CRISP-DM: Cross-Industry Standard Process for Data Mining","text":"<p>CRISP-DM \u00e9 uma metodologia amplamente utilizada em ci\u00eancia de dados que fornece um processo estruturado para a condu\u00e7\u00e3o de projetos de data mining. Ele consiste em seis fases principais:</p> <ol> <li>Entendimento do Neg\u00f3cio: Compreender os objetivos e requisitos do neg\u00f3cio.</li> <li>Entendimento dos Dados: Coletar, descrever e explorar os dados iniciais.</li> <li>Prepara\u00e7\u00e3o dos Dados: Selecionar, limpar e transformar dados para modelagem.</li> <li>Modelagem: Selecionar e aplicar t\u00e9cnicas de modelagem apropriadas.</li> <li>Avalia\u00e7\u00e3o: Avaliar a qualidade e efic\u00e1cia dos modelos.</li> <li>Implanta\u00e7\u00e3o: Implementar o modelo no ambiente de produ\u00e7\u00e3o.</li> </ol>"},{"location":"aulas/IA/intro/index.html#vantagens-do-crisp-dm","title":"Vantagens do CRISP-DM","text":"<ul> <li>Flexibilidade: Pode ser aplicado a uma ampla gama de ind\u00fastrias e problemas.</li> <li>Estruturado: Fornece uma abordagem sistem\u00e1tica para projetos de data mining.</li> <li>Iterativo: Permite revis\u00f5es e melhorias cont\u00ednuas em cada fase.</li> </ul>"},{"location":"aulas/IA/lab-01/aula5-parte2.html","title":"lab2","text":"In\u00a0[1]: Copied! <pre>#Importe das libs\nimport pandas as pd\n\nfrom sklearn.cluster import KMeans, DBSCAN\nfrom sklearn.mixture import GaussianMixture\n\nimport matplotlib.pyplot as plt\n</pre> #Importe das libs import pandas as pd  from sklearn.cluster import KMeans, DBSCAN from sklearn.mixture import GaussianMixture  import matplotlib.pyplot as plt In\u00a0[2]: Copied! <pre>url_db = 'https://raw.githubusercontent.com/reisanar/datasets/master/moons.csv'\nmoons = pd.read_csv(url_db)\n</pre> url_db = 'https://raw.githubusercontent.com/reisanar/datasets/master/moons.csv' moons = pd.read_csv(url_db) In\u00a0[3]: Copied! <pre>moons.head()\n</pre> moons.head() Out[3]: X Y 0 -0.415208 1.035735 1 0.058781 0.304334 2 1.109379 -0.509738 3 1.540948 -0.427550 4 0.929095 -0.532388 In\u00a0[4]: Copied! <pre>plt.scatter(x=moons['X'], y=moons['Y'])\n</pre> plt.scatter(x=moons['X'], y=moons['Y']) Out[4]: <pre>&lt;matplotlib.collections.PathCollection at 0x16a43b1c0&gt;</pre> In\u00a0[5]: Copied! <pre># Modelos de agrupamento\n\nrandom_state = 42\n\n#k-means\nkm = KMeans(n_clusters=4, random_state=random_state) # k=4\n#Gaussian Mixture\ngm = GaussianMixture(n_components=4, random_state=random_state) #k=4\n#DBScan\ndb = DBSCAN(eps=0.4)\n</pre> # Modelos de agrupamento  random_state = 42  #k-means km = KMeans(n_clusters=4, random_state=random_state) # k=4 #Gaussian Mixture gm = GaussianMixture(n_components=4, random_state=random_state) #k=4 #DBScan db = DBSCAN(eps=0.4) In\u00a0[6]: Copied! <pre>#aplica o algoritimo e armazena o cluster de cada dado\n\nkm_c = km.fit_predict(moons)\ngm_c = gm.fit_predict(moons)\ndb_c = db.fit_predict(moons)\n</pre> #aplica o algoritimo e armazena o cluster de cada dado  km_c = km.fit_predict(moons) gm_c = gm.fit_predict(moons) db_c = db.fit_predict(moons) In\u00a0[7]: Copied! <pre>fig = plt.figure(figsize = (12,8), dpi=80)\nplt.subplot(2,2,1)\nplt.scatter(x=moons['X'],y=moons['Y'])\nplt.title('Original')\nplt.subplot(2,2,2)\nplt.scatter(x=moons['X'],y=moons['Y'], c=km_c)\nplt.title('KMeans')\nplt.subplot(2,2,3)\nplt.scatter(x=moons['X'],y=moons['Y'], c=gm_c)\nplt.title('GaussianMixture')\nplt.subplot(2,2,4)\nplt.scatter(x=moons['X'],y=moons['Y'], c=db_c)\nplt.title('DBScan')\n</pre> fig = plt.figure(figsize = (12,8), dpi=80) plt.subplot(2,2,1) plt.scatter(x=moons['X'],y=moons['Y']) plt.title('Original') plt.subplot(2,2,2) plt.scatter(x=moons['X'],y=moons['Y'], c=km_c) plt.title('KMeans') plt.subplot(2,2,3) plt.scatter(x=moons['X'],y=moons['Y'], c=gm_c) plt.title('GaussianMixture') plt.subplot(2,2,4) plt.scatter(x=moons['X'],y=moons['Y'], c=db_c) plt.title('DBScan') Out[7]: <pre>Text(0.5, 1.0, 'DBScan')</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre>"},{"location":"aulas/IA/lab-01/aula5-parte2.html#2-aprendizagem-de-maquina","title":"2. Aprendizagem de m\u00e1quina\u00b6","text":""},{"location":"aulas/IA/lab-01/aula5-parte2.html#objetivos","title":"Objetivos\u00b6","text":"<ul> <li>Apresentar e praticar conceitos de aprendizado n\u00e3o supervisionado</li> <li>Compreender o conceito de cluster</li> <li>Apresentar os algoritimos KMeans, DBScan e GaussianMixture</li> </ul>"},{"location":"aulas/IA/lab-01/aula5-parte2.html#e-se-os-dados-nao-forem-volumetricos-ou-globulares-o-k-means-consegue-clusterizar","title":"E se os dados n\u00e3o forem volum\u00e9tricos ou globulares?  o K-Means consegue clusterizar?\u00b6","text":""},{"location":"aulas/IA/lab-01/aula5-parte2.html#aplicando-gmm-e-dbscan","title":"Aplicando GMM e DBSCAN\u00b6","text":"<ul> <li><p><code>Gaussian Mixture Models</code> \u00e9 uma abordagem probabil\u00edstica para o agrupamento, que tenta modelar cada cluster como uma distribui\u00e7\u00e3o gaussiana (normal).</p> </li> <li><p><code>DBSCAN (Density-Based Spatial Clustering of Applications with Noise)</code> \u00e9 um algoritmo de clustering baseado na densidade dos pontos. Ele \u00e9 capaz de identificar clusters de formas arbitr\u00e1rias e tratar pontos ruidosos (outliers) de maneira eficiente.</p> <ul> <li><p>O DBSCAN possui dois principais par\u00e2metros:</p> <ul> <li><code>eps</code>: A dist\u00e2ncia m\u00e1xima entre dois pontos para que sejam considerados vizinhos.</li> <li><code>min_samples</code>: O n\u00famero m\u00ednimo de pontos vizinhos para que um ponto seja considerado parte de um cluster.</li> </ul> </li> </ul> </li> </ul>"},{"location":"aulas/IA/lab-01/aula5-parte2.html#carregando-os-dados","title":"Carregando os dados\u00b6","text":""},{"location":"aulas/IA/lab-01/aula5-parte2.html#criacao-de-modelos-de-agrupamento","title":"Cria\u00e7\u00e3o de modelos de Agrupamento\u00b6","text":""},{"location":"aulas/IA/lab-01/aula5.html","title":"lab1","text":"<p>Uma das t\u00e9cnicas de aprendizagem n\u00e3o supervisionada \u00e9 o agrupamento autom\u00e1tico de dados ou clusteriza\u00e7\u00e3o.</p> <p>Lembre-se: Em aprendizagem n\u00e3o supervissionada, o nosso conjunto de dados para treino n\u00e3o possui label.</p> <p>Essa t\u00e9cnica classifica os dados em conjuntos que apresentam alguma similaridade (dist\u00e2ncia das observa\u00e7\u00f5es). Os grupos gerados nesse processo s\u00e3o chamados de <code>clusters</code>.</p> In\u00a0[2]: Copied! <pre>%matplotlib inline\nimport matplotlib.pyplot as plt\nimport seaborn as sns; sns.set()  # for plot styling\nimport numpy as np\n</pre> %matplotlib inline import matplotlib.pyplot as plt import seaborn as sns; sns.set()  # for plot styling import numpy as np In\u00a0[3]: Copied! <pre>from sklearn.datasets import make_blobs\n\nX, y_true = make_blobs(n_samples=300, centers=4,\n                       cluster_std=0.60, random_state=0)\nplt.scatter(X[:, 0], X[:, 1], s=50);\n</pre> from sklearn.datasets import make_blobs  X, y_true = make_blobs(n_samples=300, centers=4,                        cluster_std=0.60, random_state=0) plt.scatter(X[:, 0], X[:, 1], s=50); In\u00a0[4]: Copied! <pre>from sklearn.cluster import KMeans\nkmeans = KMeans(n_clusters=4)\nkmeans.fit(X)\ny_kmeans = kmeans.predict(X)\n</pre> from sklearn.cluster import KMeans kmeans = KMeans(n_clusters=4) kmeans.fit(X) y_kmeans = kmeans.predict(X) In\u00a0[5]: Copied! <pre>plt.scatter(X[:, 0], X[:, 1], c=y_kmeans, s=50, cmap='viridis')\n\ncenters = kmeans.cluster_centers_\nplt.scatter(centers[:, 0], centers[:, 1], c='black', s=200, alpha=0.5);\n</pre> plt.scatter(X[:, 0], X[:, 1], c=y_kmeans, s=50, cmap='viridis')  centers = kmeans.cluster_centers_ plt.scatter(centers[:, 0], centers[:, 1], c='black', s=200, alpha=0.5); In\u00a0[\u00a0]: Copied! <pre>## sua resposta...\n</pre> ## sua resposta... In\u00a0[6]: Copied! <pre>inertias = []\nK = range(1, 10)\n\nfor k in K:\n    kmeans = KMeans(n_clusters=k, random_state=42)\n    kmeans.fit(X)\n    inertias.append(kmeans.inertia_)\n\n# Plotando o gr\u00e1fico\nplt.plot(K, inertias, 'bo-')\nplt.xlabel('N\u00famero de clusters, K')\nplt.ylabel('In\u00e9rcia')\nplt.title('M\u00e9todo do Cotovelo para Escolher K')\nplt.show()\n</pre> inertias = [] K = range(1, 10)  for k in K:     kmeans = KMeans(n_clusters=k, random_state=42)     kmeans.fit(X)     inertias.append(kmeans.inertia_)  # Plotando o gr\u00e1fico plt.plot(K, inertias, 'bo-') plt.xlabel('N\u00famero de clusters, K') plt.ylabel('In\u00e9rcia') plt.title('M\u00e9todo do Cotovelo para Escolher K') plt.show()  In\u00a0[14]: Copied! <pre>import pandas as pd\n\nfrom sklearn.cluster import KMeans\n\nk_otimo = 4 # Definindo o n\u00famero \u00f3timo de clusters\n\nkmeans = KMeans(n_clusters=k_otimo)\n\nkmeans.fit(X)\ny_kmeans = kmeans.predict(X)\n\n# Criando um DataFrame a partir dos dados gerados\ndf = pd.DataFrame(X, columns=['Feature 1', 'Feature 2'])\n\n# Adicionando a coluna de clusters ao DataFrame\ndf['Cluster'] = y_kmeans\n\n# Exibindo as primeiras linhas do DataFrame para visualiza\u00e7\u00e3o\ndf.head()\n</pre> import pandas as pd  from sklearn.cluster import KMeans  k_otimo = 4 # Definindo o n\u00famero \u00f3timo de clusters  kmeans = KMeans(n_clusters=k_otimo)  kmeans.fit(X) y_kmeans = kmeans.predict(X)  # Criando um DataFrame a partir dos dados gerados df = pd.DataFrame(X, columns=['Feature 1', 'Feature 2'])  # Adicionando a coluna de clusters ao DataFrame df['Cluster'] = y_kmeans  # Exibindo as primeiras linhas do DataFrame para visualiza\u00e7\u00e3o df.head()  Out[14]: Feature 1 Feature 2 Cluster 0 0.836857 2.136359 0 1 -1.413658 7.409623 2 2 1.155213 5.099619 1 3 -1.018616 7.814915 2 4 1.271351 1.892542 0"},{"location":"aulas/IA/lab-01/aula5.html#2-aprendizagem-de-maquina","title":"2. Aprendizagem de m\u00e1quina\u00b6","text":""},{"location":"aulas/IA/lab-01/aula5.html#objetivos","title":"Objetivos\u00b6","text":"<ul> <li>Apresentar e praticar conceitos de aprendizado n\u00e3o supervisionado</li> <li>Compreender o conceito de cluster</li> <li>Apresentar os algoritimos KMeans, DBScan e GaussianMixture</li> </ul>"},{"location":"aulas/IA/lab-01/aula5.html#metodos-de-agrupamento","title":"M\u00e9todos de agrupamento\u00b6","text":""},{"location":"aulas/IA/lab-01/aula5.html#desafio-1","title":"Desafio 1\u00b6","text":"<p>Acesse o link e realize o cadastro com email <code>FIAP</code> e bora fazer a atividade: https://miro.com/app/board/o9J_l2e1B1U=/</p>"},{"location":"aulas/IA/lab-01/aula5.html#k-means","title":"K-Means\u00b6","text":"<p>O K-Means \u00e9 SIMPLE por isso \u00e9 um dos metodos de clusteriza\u00e7\u00e3o mais \"cl\u00e1sicos\" e recebe esse nome pois encontra uma quantidade <code>K de clusters</code>, sendo K um par\u00e2metro para o modelo e para cada cluster \u00e9 atribu\u00eddo um centro chamado de <code>centroide</code>. Tambem conhecido m\u00e9todo de parti\u00e7\u00e3o sem sobreposi\u00e7\u00e3o.</p>"},{"location":"aulas/IA/lab-01/aula5.html#curiosidades","title":"Curiosidades\u00b6","text":"<p>Esse algoritimo est\u00e1 entre os top 10 algoritimos de minera\u00e7\u00e3o de dados (data mining)</p> <p>\u00c9 um algoritimo utilizado a mais de 70 anos, existe papers das decadas de 50 e 60 que falam sobre ele.</p>"},{"location":"aulas/IA/lab-01/aula5.html#algoritmo-k-means","title":"Algoritmo K-Means\u00b6","text":"<p>O algoritimo K-Means trata-se de um m\u00e9todo iterativo e pode ser definido em 4 etapas, s\u00e3o elas:</p> <ol> <li><p>Escolher aleatoriamente k prot\u00f3tipos (centros) para os clusters</p> </li> <li><p>Atribuir cada objeto para o cluster de centro mais pr\u00f3ximo (segundo alguma dist\u00e2ncia, e.g. Euclidiana)</p> </li> <li><p>Mover cada centro para a m\u00e9dia (centr\u00f3ide) dos objetos do cluster correspondente</p> </li> <li><p>Repetir os passos 2 e 3 at\u00e9 que algum crit\u00e9rio de converg\u00eancia seja obtido:</p> </li> </ol> <ul> <li>n\u00famero m\u00e1ximo de itera\u00e7\u00f5es</li> <li>limiar m\u00ednimo de mudan\u00e7as nos centr\u00f3ides</li> </ul>"},{"location":"aulas/IA/lab-01/aula5.html#vantagens-e-desvantagens","title":"Vantagens e Desvantagens\u00b6","text":""},{"location":"aulas/IA/lab-01/aula5.html#vantagens","title":"Vantagens\u00b6","text":"<ul> <li>Simples e intuitivo</li> <li>Complexidade computacional linear em todas as vari\u00e1veis cr\u00edticas</li> <li>Eficaz em muitos cen\u00e1rios de aplica\u00e7\u00e3o e produz resultados de interpreta\u00e7\u00e3o simples</li> </ul>"},{"location":"aulas/IA/lab-01/aula5.html#desvantagens","title":"Desvantagens\u00b6","text":"<ul> <li>k = ?</li> <li>Sens\u00edvel \u00e0 inicializa\u00e7\u00e3o dos prot\u00f3tipos (m\u00ednimos locais)</li> <li>Limita-se a encontrar clusters volum\u00e9tricos / globulares</li> <li>Cada item deve pertencer a um \u00fanico cluster (parti\u00e7\u00e3o r\u00edgida, ou seja, sem sobreposi\u00e7\u00e3o)</li> <li>Limitado a atributos num\u00e9ricos</li> <li>Sens\u00edvel a outliers</li> </ul>"},{"location":"aulas/IA/lab-01/aula5.html#desafio-2","title":"Desafio 2\u00b6","text":"<p>Pergunta: E como descobrir o n\u00famero de k?</p> <p>dica: Busque por refer\u00eancias como o m\u00e9todo do cotovelo ou elbow...</p>"},{"location":"aulas/IA/lab-01/aula5.html#selecionando-o-numero-otimo-de-clusters-com-o-metodo-do-cotovelo","title":"Selecionando o N\u00famero \u00d3timo de Clusters com o M\u00e9todo do Cotovelo\u00b6","text":"<p>O m\u00e9todo do cotovelo ajuda a escolher o n\u00famero ideal de clusters, plotando a in\u00e9rcia contra o n\u00famero de clusters. Quando o gr\u00e1fico come\u00e7a a \"dobrar\", \u00e9 um bom indicativo de que o n\u00famero de clusters adequado foi atingido.</p>"},{"location":"aulas/IA/lab-01/aula5.html#adicionar-os-clusters-ao-dataset","title":"Adicionar os Clusters ao Dataset\u00b6","text":"<p>Para adicionar os clusters encontrados pelo algoritmo K-means como uma nova coluna no dataset, podemos usar o pacote Pandas para manipular os dados de forma organizada.</p> <p>Passos para Adicionar os Clusters ao Dataset:</p> <ul> <li>Usaremos Pandas para criar um DataFrame com os dados originais.</li> <li>Adicionaremos a coluna clusters com os valores gerados pelo K-means.</li> </ul>"},{"location":"aulas/IA/lab-02/aula6.html","title":"lab2","text":"In\u00a0[1]: Copied! <pre>%matplotlib inline\n\n# O scipy \u00e9 bastante utilizada para Data Science\nfrom scipy.cluster.hierarchy import dendrogram, linkage\n\nfrom sklearn.cluster import AgglomerativeClustering\nimport matplotlib.pyplot as plt\nimport pandas as pd\nimport numpy as np\n</pre> %matplotlib inline  # O scipy \u00e9 bastante utilizada para Data Science from scipy.cluster.hierarchy import dendrogram, linkage  from sklearn.cluster import AgglomerativeClustering import matplotlib.pyplot as plt import pandas as pd import numpy as np In\u00a0[2]: Copied! <pre>url_db= 'https://stackabuse.s3.amazonaws.com/files/hierarchical-clustering-with-python-and-scikit-learn-shopping-data.csv'\ndf = pd.read_csv(url_db)\n\n#renomeando o nome das colunas para tirar espa\u00e7o\ndf.columns = ['CustomerID', 'Genre', 'Age', 'Annual_Income_k','Spending_Score_1_100']\ndf.head()\n</pre> url_db= 'https://stackabuse.s3.amazonaws.com/files/hierarchical-clustering-with-python-and-scikit-learn-shopping-data.csv' df = pd.read_csv(url_db)  #renomeando o nome das colunas para tirar espa\u00e7o df.columns = ['CustomerID', 'Genre', 'Age', 'Annual_Income_k','Spending_Score_1_100'] df.head() Out[2]: CustomerID Genre Age Annual_Income_k Spending_Score_1_100 0 1 Male 19 15 39 1 2 Male 21 15 81 2 3 Female 20 16 6 3 4 Female 23 16 77 4 5 Female 31 17 40 <p>Descri\u00e7\u00e3o das colunas do dataset:</p> <pre><code>            CustomerID = Identifica\u00e7\u00e3o do usuario\n                Genre  = Genero\n                Age    = Idade\n    Annual Income (k$) = Rendimento anual em k$\t\nSpending Score (1-100) = Indice de \"vontade de gastar no shooping\"</code></pre> In\u00a0[4]: Copied! <pre>data = df.iloc[:,[3,4]].values;\ndata\n</pre> data = df.iloc[:,[3,4]].values; data Out[4]: <pre>array([[ 15,  39],\n       [ 15,  81],\n       [ 16,   6],\n       [ 16,  77],\n       [ 17,  40],\n       [ 17,  76],\n       [ 18,   6],\n       [ 18,  94],\n       [ 19,   3],\n       [ 19,  72],\n       [ 19,  14],\n       [ 19,  99],\n       [ 20,  15],\n       [ 20,  77],\n       [ 20,  13],\n       [ 20,  79],\n       [ 21,  35],\n       [ 21,  66],\n       [ 23,  29],\n       [ 23,  98],\n       [ 24,  35],\n       [ 24,  73],\n       [ 25,   5],\n       [ 25,  73],\n       [ 28,  14],\n       [ 28,  82],\n       [ 28,  32],\n       [ 28,  61],\n       [ 29,  31],\n       [ 29,  87],\n       [ 30,   4],\n       [ 30,  73],\n       [ 33,   4],\n       [ 33,  92],\n       [ 33,  14],\n       [ 33,  81],\n       [ 34,  17],\n       [ 34,  73],\n       [ 37,  26],\n       [ 37,  75],\n       [ 38,  35],\n       [ 38,  92],\n       [ 39,  36],\n       [ 39,  61],\n       [ 39,  28],\n       [ 39,  65],\n       [ 40,  55],\n       [ 40,  47],\n       [ 40,  42],\n       [ 40,  42],\n       [ 42,  52],\n       [ 42,  60],\n       [ 43,  54],\n       [ 43,  60],\n       [ 43,  45],\n       [ 43,  41],\n       [ 44,  50],\n       [ 44,  46],\n       [ 46,  51],\n       [ 46,  46],\n       [ 46,  56],\n       [ 46,  55],\n       [ 47,  52],\n       [ 47,  59],\n       [ 48,  51],\n       [ 48,  59],\n       [ 48,  50],\n       [ 48,  48],\n       [ 48,  59],\n       [ 48,  47],\n       [ 49,  55],\n       [ 49,  42],\n       [ 50,  49],\n       [ 50,  56],\n       [ 54,  47],\n       [ 54,  54],\n       [ 54,  53],\n       [ 54,  48],\n       [ 54,  52],\n       [ 54,  42],\n       [ 54,  51],\n       [ 54,  55],\n       [ 54,  41],\n       [ 54,  44],\n       [ 54,  57],\n       [ 54,  46],\n       [ 57,  58],\n       [ 57,  55],\n       [ 58,  60],\n       [ 58,  46],\n       [ 59,  55],\n       [ 59,  41],\n       [ 60,  49],\n       [ 60,  40],\n       [ 60,  42],\n       [ 60,  52],\n       [ 60,  47],\n       [ 60,  50],\n       [ 61,  42],\n       [ 61,  49],\n       [ 62,  41],\n       [ 62,  48],\n       [ 62,  59],\n       [ 62,  55],\n       [ 62,  56],\n       [ 62,  42],\n       [ 63,  50],\n       [ 63,  46],\n       [ 63,  43],\n       [ 63,  48],\n       [ 63,  52],\n       [ 63,  54],\n       [ 64,  42],\n       [ 64,  46],\n       [ 65,  48],\n       [ 65,  50],\n       [ 65,  43],\n       [ 65,  59],\n       [ 67,  43],\n       [ 67,  57],\n       [ 67,  56],\n       [ 67,  40],\n       [ 69,  58],\n       [ 69,  91],\n       [ 70,  29],\n       [ 70,  77],\n       [ 71,  35],\n       [ 71,  95],\n       [ 71,  11],\n       [ 71,  75],\n       [ 71,   9],\n       [ 71,  75],\n       [ 72,  34],\n       [ 72,  71],\n       [ 73,   5],\n       [ 73,  88],\n       [ 73,   7],\n       [ 73,  73],\n       [ 74,  10],\n       [ 74,  72],\n       [ 75,   5],\n       [ 75,  93],\n       [ 76,  40],\n       [ 76,  87],\n       [ 77,  12],\n       [ 77,  97],\n       [ 77,  36],\n       [ 77,  74],\n       [ 78,  22],\n       [ 78,  90],\n       [ 78,  17],\n       [ 78,  88],\n       [ 78,  20],\n       [ 78,  76],\n       [ 78,  16],\n       [ 78,  89],\n       [ 78,   1],\n       [ 78,  78],\n       [ 78,   1],\n       [ 78,  73],\n       [ 79,  35],\n       [ 79,  83],\n       [ 81,   5],\n       [ 81,  93],\n       [ 85,  26],\n       [ 85,  75],\n       [ 86,  20],\n       [ 86,  95],\n       [ 87,  27],\n       [ 87,  63],\n       [ 87,  13],\n       [ 87,  75],\n       [ 87,  10],\n       [ 87,  92],\n       [ 88,  13],\n       [ 88,  86],\n       [ 88,  15],\n       [ 88,  69],\n       [ 93,  14],\n       [ 93,  90],\n       [ 97,  32],\n       [ 97,  86],\n       [ 98,  15],\n       [ 98,  88],\n       [ 99,  39],\n       [ 99,  97],\n       [101,  24],\n       [101,  68],\n       [103,  17],\n       [103,  85],\n       [103,  23],\n       [103,  69],\n       [113,   8],\n       [113,  91],\n       [120,  16],\n       [120,  79],\n       [126,  28],\n       [126,  74],\n       [137,  18],\n       [137,  83]])</pre> In\u00a0[7]: Copied! <pre>plt.figure(figsize=(10,7))\nplt.scatter(data[:, 0], data[:, 1])\n</pre> plt.figure(figsize=(10,7)) plt.scatter(data[:, 0], data[:, 1])  Out[7]: <pre>&lt;matplotlib.collections.PathCollection at 0x1483ec7f0&gt;</pre> In\u00a0[8]: Copied! <pre>plt.figure(figsize=(10,10))\nden = dendrogram(linkage(data, method='average'))\n#plt.axhline(y=30)\n</pre> plt.figure(figsize=(10,10)) den = dendrogram(linkage(data, method='average')) #plt.axhline(y=30) In\u00a0[29]: Copied! <pre>## sua resposta aqui.....\n</pre> ## sua resposta aqui.....         In\u00a0[9]: Copied! <pre>cluster = AgglomerativeClustering(n_clusters=5, affinity=\"euclidean\", linkage=\"ward\")\ncluster.fit_predict(data)\n</pre> cluster = AgglomerativeClustering(n_clusters=5, affinity=\"euclidean\", linkage=\"ward\") cluster.fit_predict(data) <pre>\n---------------------------------------------------------------------------\nTypeError                                 Traceback (most recent call last)\nCell In[9], line 1\n----&gt; 1 cluster = AgglomerativeClustering(n_clusters=5, affinity=\"euclidean\", linkage=\"ward\")\n      2 cluster.fit_predict(data)\n\nTypeError: __init__() got an unexpected keyword argument 'affinity'</pre> In\u00a0[35]: Copied! <pre>cluster.labels_\n</pre> cluster.labels_ Out[35]: <pre>array([4, 3, 4, 3, 4, 3, 4, 3, 4, 3, 4, 3, 4, 3, 4, 3, 4, 3, 4, 3, 4, 3,\n       4, 3, 4, 3, 4, 3, 4, 3, 4, 3, 4, 3, 4, 3, 4, 3, 4, 3, 4, 3, 4, 1,\n       4, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 2, 1, 2, 0, 2, 0, 2,\n       1, 2, 0, 2, 0, 2, 0, 2, 0, 2, 1, 2, 0, 2, 1, 2, 0, 2, 0, 2, 0, 2,\n       0, 2, 0, 2, 0, 2, 1, 2, 0, 2, 0, 2, 0, 2, 0, 2, 0, 2, 0, 2, 0, 2,\n       0, 2, 0, 2, 0, 2, 0, 2, 0, 2, 0, 2, 0, 2, 0, 2, 0, 2, 0, 2, 0, 2,\n       0, 2])</pre> In\u00a0[10]: Copied! <pre>plt.figure(figsize=(10,7))\nplt.scatter(data[:,0],data[:,1], c=cluster.labels_, cmap=\"rainbow\")\n</pre> plt.figure(figsize=(10,7)) plt.scatter(data[:,0],data[:,1], c=cluster.labels_, cmap=\"rainbow\") <pre>\n---------------------------------------------------------------------------\nNameError                                 Traceback (most recent call last)\nCell In[10], line 2\n      1 plt.figure(figsize=(10,7))\n----&gt; 2 plt.scatter(data[:,0],data[:,1], c=cluster.labels_, cmap=\"rainbow\")\n\nNameError: name 'cluster' is not defined</pre> <pre>&lt;Figure size 1000x700 with 0 Axes&gt;</pre> In\u00a0[38]: Copied! <pre>## implemente sua resposta\n</pre> ## implemente sua resposta"},{"location":"aulas/IA/lab-02/aula6.html#2-aprendizagem-de-maquina","title":"2. Aprendizagem de m\u00e1quina\u00b6","text":""},{"location":"aulas/IA/lab-02/aula6.html#objetivos","title":"Objetivos\u00b6","text":"<ul> <li>continua\u00e7\u00e3o de aprendizado n\u00e3o supervisionado</li> <li>Apresentar uma intui\u00e7\u00e3o dos algoritimos de agupamento por densidade - DBScan</li> <li>Apresentar uma intui\u00e7\u00e3o e praticar o algoritimo de agrupamento hierarquico - AGNES</li> </ul>"},{"location":"aulas/IA/lab-02/aula6.html#metodos-de-agrupamento","title":"M\u00e9todos de agrupamento\u00b6","text":""},{"location":"aulas/IA/lab-02/aula6.html#de-forma-geral-as-estrategias-de-agrupamento-sao","title":"De forma geral as estrat\u00e9gias de agrupamento s\u00e3o:\u00b6","text":"<ul> <li>Parti\u00e7\u00e3o: exemplo KMeans</li> <li>Densidade: exemplo DBSCAN</li> <li>Hierarquicas: exemplo AGNES</li> </ul> <p>Utilizamos a ferramenta <code>orange-canvas</code> para obter uma intui\u00e7\u00e3o sobre esses algoritimos al\u00e9m de compreender suas principais diferen\u00e7a.</p>"},{"location":"aulas/IA/lab-02/aula6.html#desafio-1-sugestao","title":"Desafio 1 (Sugest\u00e3o)\u00b6","text":"<p>Fa\u00e7a a instala\u00e7\u00e3o do <code>orange-canvas</code> em sua maquina e realize os exemplos dados em sala de aula.</p> <p>Para usuarios linux o site oficial https://orangedatamining.com/ recomenda o uso de virutal env, eu uso direto sem virtual env:</p> <p>Instala\u00e7\u00e3o:</p> <pre><code>sudo apt install python3-pyqt5.*\npip install --upgrade --user pyqtwebengine==5.12\npip install --upgrade --user pyqt5==5.12\npip3 install orange3 --user\npip install orange3-educational</code></pre> <p>Execute:</p> <pre><code>python3 -m Orange.canvas\nou\norange-canvas</code></pre>"},{"location":"aulas/IA/lab-02/aula6.html#agrupamento-por-estrategia-hierarquica","title":"Agrupamento por estrat\u00e9gia Hierarquica\u00b6","text":""},{"location":"aulas/IA/lab-02/aula6.html#introducao-ao-problema-segmentacao-de-clientes","title":"Introdu\u00e7\u00e3o ao Problema: Segmenta\u00e7\u00e3o de Clientes\u00b6","text":"<p>Voc\u00ea \u00e9 um analista de dados contratado por um grande shopping center. O shopping quer melhorar suas campanhas de marketing e otimizar o atendimento aos clientes. Atualmente, eles possuem uma vasta quantidade de dados sobre seus clientes, mas enfrentam um desafio: Como identificar grupos de clientes que compartilham caracter\u00edsticas semelhantes para criar estrat\u00e9gias de marketing mais eficazes?</p>"},{"location":"aulas/IA/lab-02/aula6.html#descricao-do-problema","title":"Descri\u00e7\u00e3o do Problema\u00b6","text":"<p>Voc\u00ea recebeu um dataset contendo informa\u00e7\u00f5es sobre os clientes do shopping. Este dataset inclui vari\u00e1veis como a idade dos clientes, sua renda anual, e uma pontua\u00e7\u00e3o de gastos, que representa o quanto esses clientes tendem a gastar. Com base nesses dados, sua tarefa \u00e9 identificar grupos distintos de clientes que possam ser tratados de forma diferente pelo shopping.</p> <p>Por exemplo, pode haver um grupo de clientes jovens com alta renda que gasta muito, ou outro grupo de clientes mais velhos com uma renda menor, mas que s\u00e3o clientes fi\u00e9is e regulares. Entender essas segmenta\u00e7\u00f5es pode ajudar o shopping a personalizar ofertas, melhorar a satisfa\u00e7\u00e3o do cliente e, consequentemente, aumentar as vendas.</p>"},{"location":"aulas/IA/lab-02/aula6.html#reflexao-inicial","title":"Reflex\u00e3o Inicial\u00b6","text":"<p>Antes de mergulharmos nas t\u00e9cnicas de clustering, pense nas seguintes quest\u00f5es:</p> <ul> <li><p>Quais caracter\u00edsticas dos clientes s\u00e3o mais importantes para identificar padr\u00f5es de comportamento?</p> </li> <li><p>Como voc\u00ea definiria um \"grupo\" de clientes em termos de caracter\u00edsticas como idade, renda e pontua\u00e7\u00e3o de gastos?</p> </li> <li><p>O que voc\u00ea esperaria encontrar ap\u00f3s agrupar os clientes? Quais tipos de grupos ou segmentos voc\u00ea acha que poderiam surgir?</p> </li> <li><p>Como voc\u00ea pode preparar os dados para que sejam adequados para an\u00e1lise de clustering?</p> </li> <li><p>Qual t\u00e9cnica de clustering voc\u00ea escolheria para este problema e por qu\u00ea?</p> </li> <li><p>Como voc\u00ea pode avaliar se os grupos identificados realmente fazem sentido?</p> </li> </ul>"},{"location":"aulas/IA/lab-02/aula6.html#importa-libs","title":"Importa libs\u00b6","text":""},{"location":"aulas/IA/lab-02/aula6.html#importa-dataset","title":"Importa dataset\u00b6","text":""},{"location":"aulas/IA/lab-02/aula6.html#criando-um-subset","title":"Criando um subset\u00b6","text":""},{"location":"aulas/IA/lab-02/aula6.html#visualizacao-no-espaco-2d","title":"Visualiza\u00e7\u00e3o no espa\u00e7o 2D\u00b6","text":""},{"location":"aulas/IA/lab-02/aula6.html#desafio-2","title":"Desafio 2\u00b6","text":"<p>Realize uma an\u00e1lise visual e determine uma quantidade de cluster.</p> <pre><code>[ ] - 2 clusters\n[ ] - 3 clusters\n[ ] - 4 clusters\n[ ] - 5 clusters\n[ ] - 6 clusters\n[ ] - 7 clusters\n[ ] - 8 clusters    </code></pre>"},{"location":"aulas/IA/lab-02/aula6.html#dendrograma","title":"Dendrograma\u00b6","text":"<p>O dendrograma \u00e9 uma forma grafica de visualizar o agrupamentos de objetos.</p> <p>O agrupamento (<code>linkage</code>) \u00e9 feito de forma iterativa: No inicio, cada objeto \u00e9 um cluster e no fim, todos os objetos fazem parte do mesmo cluster.</p>"},{"location":"aulas/IA/lab-02/aula6.html#desafio-2","title":"Desafio 2\u00b6","text":"<p>Visualmente, com base no dendrograma acima, qual seria o melhor corte para realizar a clusteriza\u00e7\u00e3o hierarquica?</p> <pre><code>[ ] - 2 clusters\n[ ] - 3 clusters\n[ ] - 4 clusters\n[ ] - 5 clusters\n[ ] - 6 clusters\n[ ] - 7 clusters\n[ ] - 8 clusters </code></pre>"},{"location":"aulas/IA/lab-02/aula6.html#desafio-3","title":"Desafio 3\u00b6","text":"<p>O agrupameno dos dados foi realizado a partir do calculo da m\u00e9dia (average). Realize um estudo para comparar com outros linkage methtods.</p> <pre><code>single\ncomplete\naverage\nweighted\ncentroid\nmedian\nward</code></pre> <p>Compare os resultados de pelo menos 3 m\u00e9todos: single, average e ward</p> <p>Refer\u00eancia: Leia a documenta\u00e7\u00e3o oficial https://docs.scipy.org/doc/scipy/reference/generated/scipy.cluster.hierarchy.linkage.html#scipy.cluster.hierarchy.linkage</p>"},{"location":"aulas/IA/lab-02/aula6.html#agnes","title":"AGNES\u00b6","text":"<p>AGNES (AgglomerativeClustering) \u00e9 uma estrat\u00e9gia de agrupamento de dados do tipo botton-top.</p> <p>Como parametros deve ser passado o numero de cluster que foi encontrado no dendrograma e os metodos utilizados affinity e linkage.</p>"},{"location":"aulas/IA/lab-02/aula6.html#desafio-4","title":"Desafio 4\u00b6","text":"<p>Utilizando este dataset compare com os resultados para KMeans e DBSCAN</p>"},{"location":"aulas/IA/lab-03/aula7.html","title":"lab3","text":"In\u00a0[1]: Copied! <pre>%matplotlib inline\n\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom sklearn.cluster import KMeans\nfrom sklearn.preprocessing import StandardScaler\n</pre> %matplotlib inline  import pandas as pd import matplotlib.pyplot as plt from sklearn.cluster import KMeans from sklearn.preprocessing import StandardScaler In\u00a0[7]: Copied! <pre>url_db = 'default of credit card clients.csv'\ndf = pd.read_csv(url_db, sep=';', header=1)  # Definindo o delimitador como ponto e v\u00edrgula\ndf.head()\n</pre> url_db = 'default of credit card clients.csv' df = pd.read_csv(url_db, sep=';', header=1)  # Definindo o delimitador como ponto e v\u00edrgula df.head()  Out[7]: ID LIMIT_BAL SEX EDUCATION MARRIAGE AGE PAY_0 PAY_2 PAY_3 PAY_4 ... BILL_AMT4 BILL_AMT5 BILL_AMT6 PAY_AMT1 PAY_AMT2 PAY_AMT3 PAY_AMT4 PAY_AMT5 PAY_AMT6 default payment next month 0 1 20000 2 2 1 24 2 2 -1 -1 ... 0 0 0 0 689 0 0 0 0 1 1 2 120000 2 2 2 26 -1 2 0 0 ... 3272 3455 3261 0 1000 1000 1000 0 2000 1 2 3 90000 2 2 2 34 0 0 0 0 ... 14331 14948 15549 1518 1500 1000 1000 1000 5000 0 3 4 50000 2 2 1 37 0 0 0 0 ... 28314 28959 29547 2000 2019 1200 1100 1069 1000 0 4 5 50000 1 2 1 57 -1 0 -1 0 ... 20940 19146 19131 2000 36681 10000 9000 689 679 0 <p>5 rows \u00d7 25 columns</p> In\u00a0[18]: Copied! <pre>## Analise se o dataset possui dados faltantes, se sim, fa\u00e7a o drop dessas entradas\n\n## Seu c\u00f3digo aqui.....\n</pre> ## Analise se o dataset possui dados faltantes, se sim, fa\u00e7a o drop dessas entradas  ## Seu c\u00f3digo aqui.....   <p>Descri\u00e7\u00e3o das colunas Principais:</p> <ul> <li><code>ID</code>: Identifica\u00e7\u00e3o \u00fanica de cada cliente.</li> <li><code>LIMIT_BAL</code>: Limite de cr\u00e9dito concedido ao cliente (em d\u00f3lares).</li> <li><code>SEX</code>: G\u00eanero do cliente (1 = Masculino, 2 = Feminino).</li> <li><code>EDUCATION</code>: N\u00edvel educacional do cliente (1 = P\u00f3s-gradua\u00e7\u00e3o, 2 = Gradua\u00e7\u00e3o, 3 = Ensino M\u00e9dio, 4 = Outros).</li> <li><code>MARRIAGE</code>: Estado civil do cliente (1 = Casado, 2 = Solteiro, 3 = Outros).</li> <li><code>AGE</code>: Idade do cliente.</li> <li><code>PAY_0 a PAY_6</code>: Status de pagamento dos \u00faltimos 6 meses (0 = Pago na data, -1 = Pagamento adiantado, 1 = Atraso de 1 m\u00eas, etc.).</li> <li><code>BILL_AMT1 a BILL_AMT6</code>: Valor da fatura (em d\u00f3lares) nos \u00faltimos 6 meses.</li> <li><code>PAY_AMT1 a PAY_AMT6</code>: Pagamento realizado (em d\u00f3lares) nos \u00faltimos 6 meses.</li> <li><code>Y (default payment next month)</code>: Indicador de inadimpl\u00eancia no pr\u00f3ximo m\u00eas (1 = Inadimplente, 0 = N\u00e3o inadimplente).</li> </ul> <p>ref: https://archive.ics.uci.edu/dataset/350/default+of+credit+card+clients</p> In\u00a0[\u00a0]: Copied! <pre>## Crie uma nova coluna que soma todas as colunas de d\u00edvidas \n\n## Seu c\u00f3digo aqui.....\n</pre> ## Crie uma nova coluna que soma todas as colunas de d\u00edvidas   ## Seu c\u00f3digo aqui.....      In\u00a0[\u00a0]: Copied! <pre>## Selecione as colunas de limite de cr\u00e9dito e divida total \n\n#data = df.iloc[:,[,]].values\n#data;\n</pre> ## Selecione as colunas de limite de cr\u00e9dito e divida total   #data = df.iloc[:,[,]].values #data; In\u00a0[21]: Copied! <pre>## Como estamos trabalhos com algoritmos de dist\u00e2ncia, \u00e9 importante e recomendavel que os dados sejam normalizados\n## seu c\u00f3digo de normaliza\u00e7\u00e3o...\n</pre> ## Como estamos trabalhos com algoritmos de dist\u00e2ncia, \u00e9 importante e recomendavel que os dados sejam normalizados ## seu c\u00f3digo de normaliza\u00e7\u00e3o...   In\u00a0[19]: Copied! <pre>## Seu c\u00f3digo aqui......\n</pre> ## Seu c\u00f3digo aqui......     In\u00a0[20]: Copied! <pre>## Sua resposta aqui.....\n</pre> ## Sua resposta aqui.....     In\u00a0[23]: Copied! <pre>## Fa\u00e7a uma breve descri\u00e7\u00e3o de cada cluster obtido, o que eles indicam?\n</pre> ## Fa\u00e7a uma breve descri\u00e7\u00e3o de cada cluster obtido, o que eles indicam?"},{"location":"aulas/IA/lab-03/aula7.html#2-aprendizagem-de-maquina","title":"2. Aprendizagem de m\u00e1quina\u00b6","text":""},{"location":"aulas/IA/lab-03/aula7.html#objetivos","title":"Objetivos\u00b6","text":"<ul> <li>Praticar os algoritmos de clusteriza\u00e7\u00e3o</li> </ul>"},{"location":"aulas/IA/lab-03/aula7.html#analise-de-credito-do-cartao-de-credito","title":"An\u00e1lise de cr\u00e9dito do cart\u00e3o de credito\u00b6","text":"<p>Realizar uma an\u00e1lise explorat\u00f3ria na base de dados de clientes afim de categorizar a quantidade de perfis</p>"},{"location":"aulas/IA/lab-03/aula7.html#importa-libs","title":"Importa libs\u00b6","text":""},{"location":"aulas/IA/lab-03/aula7.html#importa-dataset","title":"Importa dataset\u00b6","text":"<p>link para download: https://drive.google.com/file/d/1jhWFqkYWtyhJhvpMtu5xX0EHsQjUOlw0/view?usp=sharing</p>"},{"location":"aulas/IA/lab-03/aula7.html#criando-um-subset","title":"Criando um subset\u00b6","text":""},{"location":"aulas/IA/lab-03/aula7.html#quantidade-de-k-cluster","title":"Quantidade de k cluster\u00b6","text":"<p>Escolha uma t\u00e9cnica dada em aula para inicializar o Kmeans. Poder ser a t\u00e9cnica <code>Elbow</code> ou <code>dendrograma</code>.</p> <p>wcss = within-cluster sum of squares = soma dos quadrados intra-clusters</p> <pre>wcss = []\nK = range(1,12)\n\nfor k in K:\n  km = KMeans(n_clusters=k)\n  km = km.fit(data_treino)\n  wcss.append(km.inertia_)\n  \n\nplt.plot(K, wcss, \"bx-\", color = \"grey\")\nplt.xlabel(\"k\")\nplt.ylabel(\"WCSS\")\nplt.title(\"M\u00e9todo do Cotovelo para k Otimizado\");\n</pre>"},{"location":"aulas/IA/lab-03/aula7.html#agrupando-dados","title":"Agrupando dados\u00b6","text":"<p>Realize o agrupamento utilizando <code>Kmeans e Agnes</code> e compare os resultados obtidos.</p>"},{"location":"aulas/IA/lab-04/aula8.html","title":"Aula8","text":"In\u00a0[19]: Copied! <pre>%matplotlib inline\n\nimport pandas as pd # data frame\nimport numpy as np # matriz\nimport matplotlib.pyplot as plt # grafico\nimport seaborn as sns # graficos estatisticos\n</pre> %matplotlib inline  import pandas as pd # data frame import numpy as np # matriz import matplotlib.pyplot as plt # grafico import seaborn as sns # graficos estatisticos   In\u00a0[20]: Copied! <pre>df = pd.read_csv('df.csv', header = None)\n\ncolumns_name = ['age', 'workclass', 'fnlwgt', 'education', 'education_num', 'marital_status', 'occupation', 'relationship',\n             'race', 'sex', 'capital_gain', 'capital_loss', 'hours_per_week', 'native_country', 'income']\n\ndf.columns = columns_name\n\ndf.shape\n</pre> df = pd.read_csv('df.csv', header = None)  columns_name = ['age', 'workclass', 'fnlwgt', 'education', 'education_num', 'marital_status', 'occupation', 'relationship',              'race', 'sex', 'capital_gain', 'capital_loss', 'hours_per_week', 'native_country', 'income']  df.columns = columns_name  df.shape Out[20]: <pre>(32561, 15)</pre> <p>Descri\u00e7\u00e3o do dataset:</p> <pre><code>Age \u2013 idade \nWorkclass \u2013 classe de trabalho\nfnlwgt \u2013 n\u00famero de pessoas que amostra representa comparada a popula\u00e7\u00e3o.\nEducation \u2013 educa\u00e7\u00e3o\nEducation_Num \u2013 anos de escolaridade\nMartial_Status \u2013 Estado Civil\nOccupation \u2013 ocupa\u00e7\u00e3o, cargo que ocupa\nRelationship \u2013 parentesco\nRace \u2013 ra\u00e7a\nSex \u2013 sexo\nCapital_Gain \u2013 ganho capital\nCapital_Loss \u2013 perda capital\nHours_per_week \u2013 horas por semana\nCountry \u2013 Nacionalidade\n\nincome \u2013 renda anual</code></pre> In\u00a0[21]: Copied! <pre>df.head()\n</pre> df.head() Out[21]: age workclass fnlwgt education education_num marital_status occupation relationship race sex capital_gain capital_loss hours_per_week native_country income 0 39 State-gov 77516 Bachelors 13 Never-married Adm-clerical Not-in-family White Male 2174 0 40 United-States &lt;=50K 1 50 Self-emp-not-inc 83311 Bachelors 13 Married-civ-spouse Exec-managerial Husband White Male 0 0 13 United-States &lt;=50K 2 38 Private 215646 HS-grad 9 Divorced Handlers-cleaners Not-in-family White Male 0 0 40 United-States &lt;=50K 3 53 Private 234721 11th 7 Married-civ-spouse Handlers-cleaners Husband Black Male 0 0 40 United-States &lt;=50K 4 28 Private 338409 Bachelors 13 Married-civ-spouse Prof-specialty Wife Black Female 0 0 40 Cuba &lt;=50K In\u00a0[\u00a0]: Copied! <pre>## verifica as informa\u00e7\u00f5es do dataset\n## Seu c\u00f3digo aqui....\n</pre> ## verifica as informa\u00e7\u00f5es do dataset ## Seu c\u00f3digo aqui....   In\u00a0[22]: Copied! <pre>## Seu c\u00f3digo aqui....\n\ndf.isnull().sum()\n</pre> ## Seu c\u00f3digo aqui....  df.isnull().sum() Out[22]: <pre>age               0\nworkclass         0\nfnlwgt            0\neducation         0\neducation_num     0\nmarital_status    0\noccupation        0\nrelationship      0\nrace              0\nsex               0\ncapital_gain      0\ncapital_loss      0\nhours_per_week    0\nnative_country    0\nincome            0\ndtype: int64</pre> <p>Aparentemente, n\u00e3o possui dados ausente. Vamos visualizar de forma diferente...</p> In\u00a0[23]: Copied! <pre>for v2 in df:\n    print(df[v2].value_counts())\n</pre> for v2 in df:     print(df[v2].value_counts()) <pre>age\n36    898\n31    888\n34    886\n23    877\n35    876\n     ... \n83      6\n88      3\n85      3\n86      1\n87      1\nName: count, Length: 73, dtype: int64\nworkclass\n Private             22696\n Self-emp-not-inc     2541\n Local-gov            2093\n ?                    1836\n State-gov            1298\n Self-emp-inc         1116\n Federal-gov           960\n Without-pay            14\n Never-worked            7\nName: count, dtype: int64\nfnlwgt\n164190    13\n203488    13\n123011    13\n148995    12\n121124    12\n          ..\n232784     1\n325573     1\n140176     1\n318264     1\n257302     1\nName: count, Length: 21648, dtype: int64\neducation\n HS-grad         10501\n Some-college     7291\n Bachelors        5355\n Masters          1723\n Assoc-voc        1382\n 11th             1175\n Assoc-acdm       1067\n 10th              933\n 7th-8th           646\n Prof-school       576\n 9th               514\n 12th              433\n Doctorate         413\n 5th-6th           333\n 1st-4th           168\n Preschool          51\nName: count, dtype: int64\neducation_num\n9     10501\n10     7291\n13     5355\n14     1723\n11     1382\n7      1175\n12     1067\n6       933\n4       646\n15      576\n5       514\n8       433\n16      413\n3       333\n2       168\n1        51\nName: count, dtype: int64\nmarital_status\n Married-civ-spouse       14976\n Never-married            10683\n Divorced                  4443\n Separated                 1025\n Widowed                    993\n Married-spouse-absent      418\n Married-AF-spouse           23\nName: count, dtype: int64\noccupation\n Prof-specialty       4140\n Craft-repair         4099\n Exec-managerial      4066\n Adm-clerical         3770\n Sales                3650\n Other-service        3295\n Machine-op-inspct    2002\n ?                    1843\n Transport-moving     1597\n Handlers-cleaners    1370\n Farming-fishing       994\n Tech-support          928\n Protective-serv       649\n Priv-house-serv       149\n Armed-Forces            9\nName: count, dtype: int64\nrelationship\n Husband           13193\n Not-in-family      8305\n Own-child          5068\n Unmarried          3446\n Wife               1568\n Other-relative      981\nName: count, dtype: int64\nrace\n White                 27816\n Black                  3124\n Asian-Pac-Islander     1039\n Amer-Indian-Eskimo      311\n Other                   271\nName: count, dtype: int64\nsex\n Male      21790\n Female    10771\nName: count, dtype: int64\ncapital_gain\n0        29849\n15024      347\n7688       284\n7298       246\n99999      159\n         ...  \n1111         1\n2538         1\n22040        1\n4931         1\n5060         1\nName: count, Length: 119, dtype: int64\ncapital_loss\n0       31042\n1902      202\n1977      168\n1887      159\n1848       51\n        ...  \n2080        1\n1539        1\n1844        1\n2489        1\n1411        1\nName: count, Length: 92, dtype: int64\nhours_per_week\n40    15217\n50     2819\n45     1824\n60     1475\n35     1297\n      ...  \n82        1\n92        1\n87        1\n74        1\n94        1\nName: count, Length: 94, dtype: int64\nnative_country\n United-States                 29170\n Mexico                          643\n ?                               583\n Philippines                     198\n Germany                         137\n Canada                          121\n Puerto-Rico                     114\n El-Salvador                     106\n India                           100\n Cuba                             95\n England                          90\n Jamaica                          81\n South                            80\n China                            75\n Italy                            73\n Dominican-Republic               70\n Vietnam                          67\n Guatemala                        64\n Japan                            62\n Poland                           60\n Columbia                         59\n Taiwan                           51\n Haiti                            44\n Iran                             43\n Portugal                         37\n Nicaragua                        34\n Peru                             31\n France                           29\n Greece                           29\n Ecuador                          28\n Ireland                          24\n Hong                             20\n Cambodia                         19\n Trinadad&amp;Tobago                  19\n Laos                             18\n Thailand                         18\n Yugoslavia                       16\n Outlying-US(Guam-USVI-etc)       14\n Honduras                         13\n Hungary                          13\n Scotland                         12\n Holand-Netherlands                1\nName: count, dtype: int64\nincome\n &lt;=50K    24720\n &gt;50K      7841\nName: count, dtype: int64\n</pre> <p>Fa\u00e7a a interpreta\u00e7\u00e3o das informa\u00e7\u00f5es, observe o caracter <code>?</code>.</p> <p>Em quais colunas ele aparece?</p> <p>Fa\u00e7a o replace dos <code>?</code> por np.NaN.</p> In\u00a0[24]: Copied! <pre>## Seu c\u00f3digo aqui...\n\ndf=df.replace(' ?', np.nan)\n</pre> ## Seu c\u00f3digo aqui...  df=df.replace(' ?', np.nan)  <p>Vamos ver como ficou</p> In\u00a0[26]: Copied! <pre>for v2 in df:\n    print(df[v2].value_counts())\n    \ndf.isnull().sum()\n</pre> for v2 in df:     print(df[v2].value_counts())      df.isnull().sum() <pre>age\n36    898\n31    888\n34    886\n23    877\n35    876\n     ... \n83      6\n88      3\n85      3\n86      1\n87      1\nName: count, Length: 73, dtype: int64\nworkclass\n Private             22696\n Self-emp-not-inc     2541\n Local-gov            2093\n State-gov            1298\n Self-emp-inc         1116\n Federal-gov           960\n Without-pay            14\n Never-worked            7\nName: count, dtype: int64\nfnlwgt\n164190    13\n203488    13\n123011    13\n148995    12\n121124    12\n          ..\n232784     1\n325573     1\n140176     1\n318264     1\n257302     1\nName: count, Length: 21648, dtype: int64\neducation\n HS-grad         10501\n Some-college     7291\n Bachelors        5355\n Masters          1723\n Assoc-voc        1382\n 11th             1175\n Assoc-acdm       1067\n 10th              933\n 7th-8th           646\n Prof-school       576\n 9th               514\n 12th              433\n Doctorate         413\n 5th-6th           333\n 1st-4th           168\n Preschool          51\nName: count, dtype: int64\neducation_num\n9     10501\n10     7291\n13     5355\n14     1723\n11     1382\n7      1175\n12     1067\n6       933\n4       646\n15      576\n5       514\n8       433\n16      413\n3       333\n2       168\n1        51\nName: count, dtype: int64\nmarital_status\n Married-civ-spouse       14976\n Never-married            10683\n Divorced                  4443\n Separated                 1025\n Widowed                    993\n Married-spouse-absent      418\n Married-AF-spouse           23\nName: count, dtype: int64\noccupation\n Prof-specialty       4140\n Craft-repair         4099\n Exec-managerial      4066\n Adm-clerical         3770\n Sales                3650\n Other-service        3295\n Machine-op-inspct    2002\n Transport-moving     1597\n Handlers-cleaners    1370\n Farming-fishing       994\n Tech-support          928\n Protective-serv       649\n Priv-house-serv       149\n Armed-Forces            9\nName: count, dtype: int64\nrelationship\n Husband           13193\n Not-in-family      8305\n Own-child          5068\n Unmarried          3446\n Wife               1568\n Other-relative      981\nName: count, dtype: int64\nrace\n White                 27816\n Black                  3124\n Asian-Pac-Islander     1039\n Amer-Indian-Eskimo      311\n Other                   271\nName: count, dtype: int64\nsex\n Male      21790\n Female    10771\nName: count, dtype: int64\ncapital_gain\n0        29849\n15024      347\n7688       284\n7298       246\n99999      159\n         ...  \n1111         1\n2538         1\n22040        1\n4931         1\n5060         1\nName: count, Length: 119, dtype: int64\ncapital_loss\n0       31042\n1902      202\n1977      168\n1887      159\n1848       51\n        ...  \n2080        1\n1539        1\n1844        1\n2489        1\n1411        1\nName: count, Length: 92, dtype: int64\nhours_per_week\n40    15217\n50     2819\n45     1824\n60     1475\n35     1297\n      ...  \n82        1\n92        1\n87        1\n74        1\n94        1\nName: count, Length: 94, dtype: int64\nnative_country\n United-States                 29170\n Mexico                          643\n Philippines                     198\n Germany                         137\n Canada                          121\n Puerto-Rico                     114\n El-Salvador                     106\n India                           100\n Cuba                             95\n England                          90\n Jamaica                          81\n South                            80\n China                            75\n Italy                            73\n Dominican-Republic               70\n Vietnam                          67\n Guatemala                        64\n Japan                            62\n Poland                           60\n Columbia                         59\n Taiwan                           51\n Haiti                            44\n Iran                             43\n Portugal                         37\n Nicaragua                        34\n Peru                             31\n France                           29\n Greece                           29\n Ecuador                          28\n Ireland                          24\n Hong                             20\n Cambodia                         19\n Trinadad&amp;Tobago                  19\n Laos                             18\n Thailand                         18\n Yugoslavia                       16\n Outlying-US(Guam-USVI-etc)       14\n Honduras                         13\n Hungary                          13\n Scotland                         12\n Holand-Netherlands                1\nName: count, dtype: int64\nincome\n &lt;=50K    24720\n &gt;50K      7841\nName: count, dtype: int64\n</pre> Out[26]: <pre>age                  0\nworkclass         1836\nfnlwgt               0\neducation            0\neducation_num        0\nmarital_status       0\noccupation        1843\nrelationship         0\nrace                 0\nsex                  0\ncapital_gain         0\ncapital_loss         0\nhours_per_week       0\nnative_country     583\nincome               0\ndtype: int64</pre> <p>note que agora conseguimos ver que existem dados faltantes no dataset.</p> <p>Use o m\u00e9todo <code>.fillna()</code>, para substituir os nulos (np.nan) por zero.</p> In\u00a0[27]: Copied! <pre>## Seu c\u00f3digo aqui...\n\ndf.fillna(0)\n</pre> ## Seu c\u00f3digo aqui...  df.fillna(0)  Out[27]: age workclass fnlwgt education education_num marital_status occupation relationship race sex capital_gain capital_loss hours_per_week native_country income 0 39 State-gov 77516 Bachelors 13 Never-married Adm-clerical Not-in-family White Male 2174 0 40 United-States &lt;=50K 1 50 Self-emp-not-inc 83311 Bachelors 13 Married-civ-spouse Exec-managerial Husband White Male 0 0 13 United-States &lt;=50K 2 38 Private 215646 HS-grad 9 Divorced Handlers-cleaners Not-in-family White Male 0 0 40 United-States &lt;=50K 3 53 Private 234721 11th 7 Married-civ-spouse Handlers-cleaners Husband Black Male 0 0 40 United-States &lt;=50K 4 28 Private 338409 Bachelors 13 Married-civ-spouse Prof-specialty Wife Black Female 0 0 40 Cuba &lt;=50K ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... 32556 27 Private 257302 Assoc-acdm 12 Married-civ-spouse Tech-support Wife White Female 0 0 38 United-States &lt;=50K 32557 40 Private 154374 HS-grad 9 Married-civ-spouse Machine-op-inspct Husband White Male 0 0 40 United-States &gt;50K 32558 58 Private 151910 HS-grad 9 Widowed Adm-clerical Unmarried White Female 0 0 40 United-States &lt;=50K 32559 22 Private 201490 HS-grad 9 Never-married Adm-clerical Own-child White Male 0 0 20 United-States &lt;=50K 32560 52 Self-emp-inc 287927 HS-grad 9 Married-civ-spouse Exec-managerial Wife White Female 15024 0 40 United-States &gt;50K <p>32561 rows \u00d7 15 columns</p> In\u00a0[30]: Copied! <pre>df['occupation'].value_counts()\n</pre> df['occupation'].value_counts() Out[30]: <pre>occupation\n Prof-specialty       4140\n Craft-repair         4099\n Exec-managerial      4066\n Adm-clerical         3770\n Sales                3650\n Other-service        3295\n Machine-op-inspct    2002\n Transport-moving     1597\n Handlers-cleaners    1370\n Farming-fishing       994\n Tech-support          928\n Protective-serv       649\n Priv-house-serv       149\n Armed-Forces            9\nName: count, dtype: int64</pre> <p>Ainda temos um problema, os classificadores que estudamos at\u00e9 agora n\u00e3o se d\u00e3o bem com vari\u00e1veis categ\u00f3ricas.</p> <p>Dentre as diversas formas de se fazer isso.....</p> <p>Vamos utilizar a t\u00e9cnica de OneHotEncoder com a biblioteca <code>category_encoders</code> apenas para economizar tempo.</p> In\u00a0[31]: Copied! <pre>## Se necess\u00e1rio, pip install category_encoders\n\nimport category_encoders as ce\n\nencoder = ce.OneHotEncoder(cols=[\"----Coloque aqui as colunas categoricas para realizar a transforma\u00e7\u00e3o----\"])\n\ndf = encoder.fit_transform(df)\n</pre> ## Se necess\u00e1rio, pip install category_encoders  import category_encoders as ce  encoder = ce.OneHotEncoder(cols=[\"----Coloque aqui as colunas categoricas para realizar a transforma\u00e7\u00e3o----\"])  df = encoder.fit_transform(df)   <pre>\n---------------------------------------------------------------------------\nModuleNotFoundError                       Traceback (most recent call last)\nCell In[31], line 3\n      1 ## Se necess\u00e1rio, pip install category_encoders\n----&gt; 3 import category_encoders as ce\n      5 encoder = ce.OneHotEncoder(cols=[\"----Coloque aqui as colunas categoricas para realizar a transforma\u00e7\u00e3o----\"])\n      7 df = encoder.fit_transform(df)\n\nModuleNotFoundError: No module named 'category_encoders'</pre> In\u00a0[\u00a0]: Copied! <pre>df.head()\n</pre> df.head() <p>Criamos um novo problema, os valores est\u00e3o em escalas muito diferentes, o que pode prejudicar o aprendizado.</p> <p>Podemos tomar algumas desci\u00e7\u00f5es: Vamos normatizar os dados, mas antes, fa\u00e7a o drop da coluna <code>income</code> para n\u00e3o mudar a escala dela; Da um replace na coluna <code>income</code> para 0 ou 1.</p> <p>Variavel independente: --&gt; X Variavel dependente: --&gt; y</p> In\u00a0[\u00a0]: Copied! <pre>#Vamos fazer um drop da coluna de interesse de estudo `income`. (y)\n</pre> #Vamos fazer um drop da coluna de interesse de estudo `income`. (y)   In\u00a0[\u00a0]: Copied! <pre>## Fa\u00e7a a normaliza\u00e7\u00e3o dos dados\n## escolha um dos m\u00e9todos....\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.preprocessing import minmax_scale\nfrom sklearn.preprocessing import MaxAbsScaler\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.preprocessing import RobustScaler\nfrom sklearn.preprocessing import Normalizer\nfrom sklearn.preprocessing import QuantileTransformer\nfrom sklearn.preprocessing import PowerTransformer\n\n## seu c\u00f3digo aqui...\n</pre> ## Fa\u00e7a a normaliza\u00e7\u00e3o dos dados ## escolha um dos m\u00e9todos.... from sklearn.preprocessing import MinMaxScaler from sklearn.preprocessing import minmax_scale from sklearn.preprocessing import MaxAbsScaler from sklearn.preprocessing import StandardScaler from sklearn.preprocessing import RobustScaler from sklearn.preprocessing import Normalizer from sklearn.preprocessing import QuantileTransformer from sklearn.preprocessing import PowerTransformer  ## seu c\u00f3digo aqui...   <p>Agora sim! temos uma base limpa e organizada para rodar diversos modelos de ML. onde:</p> <p>X - &gt; possui as variaveis independentes. y - &gt; \u00e9 a nossa variavel de interesse.</p> <p>Separe os dados em treino e teste, qual a propo\u00e7\u00e3o ser\u00e1 utiizada para cada subset??</p> In\u00a0[\u00a0]: Copied! <pre>#Separar os dados em treino e teste\nfrom sklearn.model_selection import train_test_split\n</pre> #Separar os dados em treino e teste from sklearn.model_selection import train_test_split   In\u00a0[\u00a0]: Copied! <pre>from sklearn.naive_bayes import GaussianNB\n\ngnb = GaussianNB()\n\ngnb.fit(X_train, y_train)\ny_pred = gnb.predict(X_test)\ny_pred\n</pre> from sklearn.naive_bayes import GaussianNB  gnb = GaussianNB()  gnb.fit(X_train, y_train) y_pred = gnb.predict(X_test) y_pred In\u00a0[\u00a0]: Copied! <pre>from sklearn.metrics import accuracy_score\n\naccuracy_score(y_test, y_pred)\n</pre> from sklearn.metrics import accuracy_score  accuracy_score(y_test, y_pred) In\u00a0[\u00a0]: Copied! <pre>y_pred_train = gnb.predict(X_train)\ny_pred_train\n</pre> y_pred_train = gnb.predict(X_train) y_pred_train In\u00a0[\u00a0]: Copied! <pre>accuracy_score(y_train, y_pred_train)\n</pre> accuracy_score(y_train, y_pred_train) In\u00a0[\u00a0]: Copied! <pre>### sua resposta aqui....\n</pre> ### sua resposta aqui....    In\u00a0[\u00a0]: Copied! <pre>\n</pre>"},{"location":"aulas/IA/lab-04/aula8.html#2-aprendizagem-de-maquina","title":"2. Aprendizagem de m\u00e1quina\u00b6","text":""},{"location":"aulas/IA/lab-04/aula8.html#objetivos","title":"Objetivos\u00b6","text":"<ul> <li>Praticar os algoritmos de aprendizado de maquina</li> <li>Conhecer e aplicar o algoritmo Naive Bayes</li> </ul>"},{"location":"aulas/IA/lab-04/aula8.html#objetivos-especificos","title":"Objetivos espec\u00edficos\u00b6","text":"<ul> <li>Obter ao final da aula de hoje um roteiro com dicas de como processar algoritmos de aprendizado de maquina.</li> </ul>"},{"location":"aulas/IA/lab-04/aula8.html#dinamica-da-aula","title":"Dinamica da aula\u00b6","text":"<pre><code>- 10min - Apresenta\u00e7\u00e3o do notebook e do case a ser resolvido. \n- 30min - Desenvolvimento do grupo para resolver o notebook\n- 60min - Resolu\u00e7\u00e3o em conjunto (aluno + professor) do problema.</code></pre>"},{"location":"aulas/IA/lab-04/aula8.html#projeto-completo-de-aprendizado-de-maquina","title":"Projeto completo de aprendizado de m\u00e1quina\u00b6","text":"<p>O objetivo deste notebook \u00e9 servir como inspira\u00e7\u00e3o para realizar uma an\u00e1lise explorat\u00f3ria de dados e desenvolimento de modelos preditivos usando ML.</p> <p>De forma geral, e bem superficial, podemos separar esse processo em algumas etapa:</p> <pre><code>[ ] An\u00e1lise explorat\u00f3ria e prepara\u00e7\u00e3o dos dados \n[ ] Treina um(uns) modelo(s) de ML\n[ ] An\u00e1lisa e valida o modelo, responde as perguntas </code></pre>"},{"location":"aulas/IA/lab-04/aula8.html#classificador-de-renda","title":"Classificador de renda\u00b6","text":"<p>Voc\u00ea foi contratado por uma empresa para prestar um servi\u00e7o de consultor, nesse sentido a empresa disponibilizou uma base de dados dos seus clientes e gostaria de saber se \u00e9 poss\u00edvel criar um modelo preditivo que deve classificar se determinadas pessoas ganham mais ou menos de 50k por ano.</p> <p>Nosso dataset:http://archive.ics.uci.edu/ml/datasets/Adult</p>"},{"location":"aulas/IA/lab-04/aula8.html#importa-as-bibliotecas","title":"Importa as bibliotecas\u00b6","text":""},{"location":"aulas/IA/lab-04/aula8.html#carrega-o-dataset","title":"Carrega o dataset\u00b6","text":""},{"location":"aulas/IA/lab-04/aula8.html#verificar-se-possui-dados-ausentes","title":"Verificar se possui dados ausentes\u00b6","text":""},{"location":"aulas/IA/lab-04/aula8.html#classificadores-naive-bayes","title":"Classificadores Naive Bayes\u00b6","text":"<p>Trata-se de \"classificadores probabil\u00edsticos\" simples, baseados na aplica\u00e7\u00e3o do <code>teorema de Bayes</code> com fortes pressupostos de independ\u00eancia entre os atributos. Eles est\u00e3o entre os modelos de rede bayesianos mais simples.</p> <p>Existem 3 tipos diferentes de Naive Bayes:</p> <pre><code>1.Gaussian Naive Bayes\n\n2.Multinomial Naive Bayes\n\n3.Bernoulli Naive Bayes</code></pre> <p>S\u00e3o muiiiitttooo utilizados em aplica\u00e7\u00e3o com texto e NLP e aplica\u00e7\u00f5es como:</p> <pre><code>[X] Filtro de Spam\n[X] Classifica\u00e7\u00e3o de Texto\n[X] Analise de sentimento\n[X] Sistemas de recomenda\u00e7\u00e3o</code></pre> <p>Para mais refer\u00eancias: https://en.wikipedia.org/wiki/Naive_Bayes_classifier</p>"},{"location":"aulas/IA/lab-04/aula8.html#compare-o-resultado-de-acuracia-com-pelo-menos-1-outro-metodo-de-machine-learning","title":"Compare o resultado de acuracia com pelo menos 1 outro m\u00e9todo de machine learning.\u00b6","text":""},{"location":"aulas/IA/lab01/dataframe.html","title":"Dataframe","text":"<p>Para instalar</p> <ul> <li>pandas: <code>pip install pandas</code></li> </ul> <p>LEIA A DOCUMENTA\u00c7\u00c3O: https://pandas.pydata.org/docs/index.html</p> In\u00a0[\u00a0]: Copied! <pre>import pandas as pd\n</pre> import pandas as pd In\u00a0[\u00a0]: Copied! <pre># Caminho do arquivo\nurl = \"https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data\"\n\n# L\u00ea e carrega o arquivo para a mem\u00f3ria\ndf = pd.read_csv(url)\n</pre> # Caminho do arquivo url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data\"  # L\u00ea e carrega o arquivo para a mem\u00f3ria df = pd.read_csv(url) In\u00a0[\u00a0]: Copied! <pre>df.head()\n</pre> df.head() Out[\u00a0]: 5.1 3.5 1.4 0.2 Iris-setosa 0 4.9 3.0 1.4 0.2 Iris-setosa 1 4.7 3.2 1.3 0.2 Iris-setosa 2 4.6 3.1 1.5 0.2 Iris-setosa 3 5.0 3.6 1.4 0.2 Iris-setosa 4 5.4 3.9 1.7 0.4 Iris-setosa <p>Note que a primeira linha n\u00e3o contem os nomes das colunas ou <code>atributos</code>(variaveis) e sim, dados (valores).</p> <p>Dependendo da base dados utilizada e como voc\u00ea carrega no pandas, os dados da primeira linha s\u00e3o importados como atributos.</p> <p>Vamos adicionar um cabe\u00e7ario ao nosso dataframe. Mas o que podemos adicionar???</p> <p>Vamos dar uma olhada no reposit\u00f3rio oficial onde dadas informa\u00e7\u00f5es sobre o dataset e \u00e9 dito que as variaveis s\u00e3o:</p> <pre><code>Attribute Information:\n\n1. sepal length in cm\n2. sepal width in cm\n3. petal length in cm\n4. petal width in cm\n5. class:\n-- Iris Setosa\n-- Iris Versicolour\n-- Iris Virginica\n</code></pre> In\u00a0[\u00a0]: Copied! <pre># Define o nome das colunas\nheader = ['sepal_length', 'sepal_width', 'petal_length', 'petal_width', 'species']\n# L\u00ea e carrega o arquivo para a mem\u00f3ria\ndf = pd.read_csv(url, header=None, names=header)\n</pre> # Define o nome das colunas header = ['sepal_length', 'sepal_width', 'petal_length', 'petal_width', 'species'] # L\u00ea e carrega o arquivo para a mem\u00f3ria df = pd.read_csv(url, header=None, names=header) In\u00a0[\u00a0]: Copied! <pre># Retorna um trecho com as 5 primeiras linhas do dataframe\ndf.head()\n</pre> # Retorna um trecho com as 5 primeiras linhas do dataframe df.head() Out[\u00a0]: sepal_length sepal_width petal_length petal_width species 0 5.1 3.5 1.4 0.2 Iris-setosa 1 4.9 3.0 1.4 0.2 Iris-setosa 2 4.7 3.2 1.3 0.2 Iris-setosa 3 4.6 3.1 1.5 0.2 Iris-setosa 4 5.0 3.6 1.4 0.2 Iris-setosa In\u00a0[\u00a0]: Copied! <pre># Mostra informa\u00e7\u00f5es sobre o dataframe em si\ndf.info()\n</pre> # Mostra informa\u00e7\u00f5es sobre o dataframe em si df.info() <pre>&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 150 entries, 0 to 149\nData columns (total 5 columns):\n #   Column        Non-Null Count  Dtype  \n---  ------        --------------  -----  \n 0   sepal_length  150 non-null    float64\n 1   sepal_width   150 non-null    float64\n 2   petal_length  150 non-null    float64\n 3   petal_width   150 non-null    float64\n 4   species       150 non-null    object \ndtypes: float64(4), object(1)\nmemory usage: 6.0+ KB\n</pre> In\u00a0[\u00a0]: Copied! <pre># exibe o shape (dimenso\u1ebds) do dataframe\ndf.shape\n</pre> # exibe o shape (dimenso\u1ebds) do dataframe df.shape Out[\u00a0]: <pre>(150, 5)</pre> In\u00a0[\u00a0]: Copied! <pre>## Suas respostas....\n</pre> ## Suas respostas....       <p>S\u00e3o 150 exemplares de flor de \u00edris, pertencentes a tr\u00eas esp\u00e9cies diferentes: setosa, versicolor e virginica, sendo 50 amostras de cada esp\u00e9cie.</p> <p>Os atributos de <code>largura e comprimento de s\u00e9pala</code> e <code>largura e comprimento de p\u00e9tala</code> de cada flor fooram medidos manualmente.</p> In\u00a0[\u00a0]: Copied! <pre>df.describe()\n</pre> df.describe() Out[\u00a0]: sepal_length sepal_width petal_length petal_width count 150.000000 150.000000 150.000000 150.000000 mean 5.843333 3.054000 3.758667 1.198667 std 0.828066 0.433594 1.764420 0.763161 min 4.300000 2.000000 1.000000 0.100000 25% 5.100000 2.800000 1.600000 0.300000 50% 5.800000 3.000000 4.350000 1.300000 75% 6.400000 3.300000 5.100000 1.800000 max 7.900000 4.400000 6.900000 2.500000 <p>Note que o m\u00e9todo describe() n\u00e3o exibe a coluna species, pois se trata de uma coluna n\u00e3o-num\u00e9rica.</p> <p>Apenas as colunas num\u00e9ricas est\u00e3o presentes, o atributo species indica r\u00f3tulos - trata-se de dados categ\u00f3ricos.</p> In\u00a0[\u00a0]: Copied! <pre># retorna a quantiade de classes da coluna\n\ndf.species.unique()\n</pre> # retorna a quantiade de classes da coluna  df.species.unique() Out[\u00a0]: <pre>array(['Iris-setosa', 'Iris-versicolor', 'Iris-virginica'], dtype=object)</pre> In\u00a0[\u00a0]: Copied! <pre># agrupamento por m\u00e9dia\n\ndf.groupby('species').mean()\n</pre> # agrupamento por m\u00e9dia  df.groupby('species').mean() Out[\u00a0]: sepal_length sepal_width petal_length petal_width species Iris-setosa 5.006 3.418 1.464 0.244 Iris-versicolor 5.936 2.770 4.260 1.326 Iris-virginica 6.588 2.974 5.552 2.026 In\u00a0[\u00a0]: Copied! <pre>#  Quantidade de cada categoria\ndf.groupby('species').size()\n</pre> #  Quantidade de cada categoria df.groupby('species').size() Out[\u00a0]: <pre>species\nIris-setosa        50\nIris-versicolor    50\nIris-virginica     50\ndtype: int64</pre> In\u00a0[\u00a0]: Copied! <pre>import numpy as np\n\n# c\u00f3pia de df\ndf_iris = df\n\n# Gera dados faltante no dataset\nfor col in df_iris.columns[:-1]:\n    df_iris.loc[np.random.choice(df_iris.index, 5), col] = np.nan\n</pre> import numpy as np  # c\u00f3pia de df df_iris = df  # Gera dados faltante no dataset for col in df_iris.columns[:-1]:     df_iris.loc[np.random.choice(df_iris.index, 5), col] = np.nan  In\u00a0[\u00a0]: Copied! <pre>df_iris.info()\n</pre> df_iris.info() <pre>&lt;class 'pandas.core.frame.DataFrame'&gt;\nInt64Index: 131 entries, 0 to 149\nData columns (total 5 columns):\n #   Column        Non-Null Count  Dtype  \n---  ------        --------------  -----  \n 0   sepal_length  121 non-null    float64\n 1   sepal_width   121 non-null    float64\n 2   petal_length  122 non-null    float64\n 3   petal_width   121 non-null    float64\n 4   species       131 non-null    object \ndtypes: float64(4), object(1)\nmemory usage: 10.2+ KB\n</pre> In\u00a0[\u00a0]: Copied! <pre># Verifica os valores ausentes\n\ndf_iris.isnull().sum()\n</pre> # Verifica os valores ausentes  df_iris.isnull().sum()  Out[\u00a0]: <pre>sepal_length    10\nsepal_width     10\npetal_length     9\npetal_width     10\nspecies          0\ndtype: int64</pre> In\u00a0[\u00a0]: Copied! <pre>df_iris.dropna(axis=0, inplace=True)\n</pre> df_iris.dropna(axis=0, inplace=True) In\u00a0[\u00a0]: Copied! <pre># Tratamento de valores faltantes: imputa\u00e7\u00e3o m\u00e9dia\n\nfor col in df_iris.columns[:-1]:  # a coluna de especie n\u00e3o entra\n    mean_val = df_iris[col].mean()\n    df_iris[col].fillna(mean_val, inplace=True)\n</pre> # Tratamento de valores faltantes: imputa\u00e7\u00e3o m\u00e9dia  for col in df_iris.columns[:-1]:  # a coluna de especie n\u00e3o entra     mean_val = df_iris[col].mean()     df_iris[col].fillna(mean_val, inplace=True) In\u00a0[\u00a0]: Copied! <pre>df_iris.info()\n</pre> df_iris.info()  <pre>&lt;class 'pandas.core.frame.DataFrame'&gt;\nInt64Index: 131 entries, 0 to 149\nData columns (total 5 columns):\n #   Column        Non-Null Count  Dtype  \n---  ------        --------------  -----  \n 0   sepal_length  131 non-null    float64\n 1   sepal_width   131 non-null    float64\n 2   petal_length  131 non-null    float64\n 3   petal_width   131 non-null    float64\n 4   species       131 non-null    object \ndtypes: float64(4), object(1)\nmemory usage: 10.2+ KB\n</pre> In\u00a0[\u00a0]: Copied! <pre>import matplotlib.pyplot as plt\nimport seaborn as sns\n</pre> import matplotlib.pyplot as plt import seaborn as sns In\u00a0[\u00a0]: Copied! <pre># Gr\u00e1fico de linha para a m\u00e9dia do comprimento da s\u00e9pala de cada esp\u00e9cie\n\ngrouped = df_iris.groupby('species')['sepal_length'].mean()\ngrouped.plot(kind='line', marker='o')\n\n\nplt.title('M\u00e9dia do Comprimento da S\u00e9pala por Esp\u00e9cie')\nplt.ylabel('Comprimento da S\u00e9pala (cm)')\nplt.grid(True)\nplt.show()\n</pre> # Gr\u00e1fico de linha para a m\u00e9dia do comprimento da s\u00e9pala de cada esp\u00e9cie  grouped = df_iris.groupby('species')['sepal_length'].mean() grouped.plot(kind='line', marker='o')   plt.title('M\u00e9dia do Comprimento da S\u00e9pala por Esp\u00e9cie') plt.ylabel('Comprimento da S\u00e9pala (cm)') plt.grid(True) plt.show()  In\u00a0[\u00a0]: Copied! <pre># Gr\u00e1fico de Barras\n\nspecies_count = df['species'].value_counts()\nspecies_count.plot(kind='bar')\n\nplt.title('Contagem de Esp\u00e9cies')\nplt.xlabel('Esp\u00e9cie')\nplt.ylabel('Contagem')\nplt.show()\n</pre> # Gr\u00e1fico de Barras  species_count = df['species'].value_counts() species_count.plot(kind='bar')  plt.title('Contagem de Esp\u00e9cies') plt.xlabel('Esp\u00e9cie') plt.ylabel('Contagem') plt.show()  In\u00a0[\u00a0]: Copied! <pre># Lembra de histograma, que exibe uma gr\u00e1fico de frequ\u00eancia.\ndf.hist(bins=100, figsize=(15, 15))\nplt.show()\n</pre> # Lembra de histograma, que exibe uma gr\u00e1fico de frequ\u00eancia. df.hist(bins=100, figsize=(15, 15)) plt.show() In\u00a0[\u00a0]: Copied! <pre># Histograma apenas de um atributo\n\nplt.hist(df['sepal_length'], bins=100)\n\n\nplt.title('Histograma de Sepal Length')\nplt.xlabel('Sepal Length')\nplt.ylabel('Contagem')\nplt.show()\n</pre> # Histograma apenas de um atributo  plt.hist(df['sepal_length'], bins=100)   plt.title('Histograma de Sepal Length') plt.xlabel('Sepal Length') plt.ylabel('Contagem') plt.show()  In\u00a0[\u00a0]: Copied! <pre># box plot\ndf.plot(kind='box', subplots=True, layout=(2,2), sharex=False, sharey=False, figsize=(15, 15))\nplt.show()\n</pre> # box plot df.plot(kind='box', subplots=True, layout=(2,2), sharex=False, sharey=False, figsize=(15, 15)) plt.show() In\u00a0[\u00a0]: Copied! <pre># Grafico de dispers\u00e3o\n\nplt.scatter(df_iris['sepal_length'], df_iris['petal_length'])\n\nplt.title('Sepal Length vs Petal Length')\nplt.xlabel('Sepal Length (cm)')\nplt.ylabel('Petal Length (cm)')\nplt.show()\n</pre> # Grafico de dispers\u00e3o  plt.scatter(df_iris['sepal_length'], df_iris['petal_length'])  plt.title('Sepal Length vs Petal Length') plt.xlabel('Sepal Length (cm)') plt.ylabel('Petal Length (cm)') plt.show() In\u00a0[\u00a0]: Copied! <pre># Os mesmos dados mas agora cada classe de uma cor diferente\n\ncolors = {'Iris-setosa':'red', 'Iris-versicolor':'blue', 'Iris-virginica':'green'}\n\nplt.scatter(df['sepal_length'], df['petal_length'], c=df['species'].map(colors), label=colors)\n\nplt.title('Sepal Length vs Petal Length')\nplt.xlabel('Sepal Length (cm)')\nplt.ylabel('Petal Length (cm)')\nplt.legend(handles=[plt.Line2D([0], [0], marker='o', color='w', markerfacecolor=color, markersize=10) for color in colors.values()], labels=colors.keys())\nplt.show()\n</pre> # Os mesmos dados mas agora cada classe de uma cor diferente  colors = {'Iris-setosa':'red', 'Iris-versicolor':'blue', 'Iris-virginica':'green'}  plt.scatter(df['sepal_length'], df['petal_length'], c=df['species'].map(colors), label=colors)  plt.title('Sepal Length vs Petal Length') plt.xlabel('Sepal Length (cm)') plt.ylabel('Petal Length (cm)') plt.legend(handles=[plt.Line2D([0], [0], marker='o', color='w', markerfacecolor=color, markersize=10) for color in colors.values()], labels=colors.keys()) plt.show() In\u00a0[\u00a0]: Copied! <pre># scatter plot matrix\n# tudo junto e misturado\n\nfrom pandas.plotting import scatter_matrix\n\nscatter_matrix(df,figsize=(15, 15))\n\nplt.show()\n</pre> # scatter plot matrix # tudo junto e misturado  from pandas.plotting import scatter_matrix  scatter_matrix(df,figsize=(15, 15))  plt.show() <p>Vamos utilizar o <code>seaborn</code> para visualizar gr\u00e1ficos mais bonitos</p> In\u00a0[\u00a0]: Copied! <pre>import seaborn as sns\n\n# A cor vem do campo `species` do dataframe\n\nsns.pairplot(df, hue='species', height=5)\n\nplt.show()\n</pre> import seaborn as sns  # A cor vem do campo `species` do dataframe  sns.pairplot(df, hue='species', height=5)  plt.show() <p>O Violin plot \u00e9 similar ao box plot, exibe a distribui\u00e7\u00e3o de variaveis num\u00e9ricas em niveis, pode ser configurada de muitas formas e \u00e9 uma forma de visualiza\u00e7\u00e3o interessante de dados.</p> <p>Saiba mais em: https://seaborn.pydata.org/generated/seaborn.violinplot.html</p> In\u00a0[\u00a0]: Copied! <pre># Violin plot\ng = sns.violinplot(y='species', x='sepal_length', data=df, inner='quartile')\nplt.show()\ng = sns.violinplot(y='species', x='sepal_width', data=df, inner='quartile')\nplt.show()\ng = sns.violinplot(y='species', x='petal_length', data=df, inner='quartile')\nplt.show()\ng = sns.violinplot(y='species', x='petal_width', data=df, inner='quartile')\nplt.show()\n</pre> # Violin plot g = sns.violinplot(y='species', x='sepal_length', data=df, inner='quartile') plt.show() g = sns.violinplot(y='species', x='sepal_width', data=df, inner='quartile') plt.show() g = sns.violinplot(y='species', x='petal_length', data=df, inner='quartile') plt.show() g = sns.violinplot(y='species', x='petal_width', data=df, inner='quartile') plt.show() In\u00a0[\u00a0]: Copied! <pre>cols = ['sepal_length', 'sepal_width', 'petal_length','petal_width']\ncorr_matx = df[cols].corr()\n\nheatmap = sns.heatmap(corr_matx,cbar=True,annot=True,square=True,fmt='.2f',annot_kws={'size': 15},yticklabels=cols,xticklabels=cols,cmap='Dark2')\n</pre> cols = ['sepal_length', 'sepal_width', 'petal_length','petal_width'] corr_matx = df[cols].corr()  heatmap = sns.heatmap(corr_matx,cbar=True,annot=True,square=True,fmt='.2f',annot_kws={'size': 15},yticklabels=cols,xticklabels=cols,cmap='Dark2') In\u00a0[\u00a0]: Copied! <pre>### Implemente sua solu\u00e7\u00e3o e apresente sua an\u00e1lise....\n</pre> ### Implemente sua solu\u00e7\u00e3o e apresente sua an\u00e1lise....     In\u00a0[\u00a0]: Copied! <pre>df['petal_length'].head()\n</pre> df['petal_length'].head() Out[\u00a0]: <pre>0    1.4\n1    1.4\n2    1.3\n3    1.5\n4    1.4\nName: petal_length, dtype: float64</pre> <p>Por outro lado, se dentro dos colchetes passamos uma lista de nomes de coluna, o reultado \u00e9 outro <code>DataFrame</code> contendo aquelas colunas. Isso vale inclusive para uma coluna simples:</p> In\u00a0[\u00a0]: Copied! <pre># Mostra apenas a coluna petal_len\ndf[['petal_length']].head()\n</pre> # Mostra apenas a coluna petal_len df[['petal_length']].head() Out[\u00a0]: petal_length 0 1.4 1 1.4 2 1.3 3 1.5 4 1.4 In\u00a0[\u00a0]: Copied! <pre># Mostra as colunas petal_length e petal_width\ndf[['petal_length', 'petal_width']].head()\n</pre> # Mostra as colunas petal_length e petal_width df[['petal_length', 'petal_width']].head() Out[\u00a0]: petal_length petal_width 0 1.4 0.2 1 1.4 0.2 2 1.3 0.2 3 1.5 0.2 4 1.4 0.2 In\u00a0[\u00a0]: Copied! <pre># Criando uma nova caracter\u00edstica: \u00e1rea da s\u00e9pala\n\ndf['sepal_area'] = df['sepal_length'] * df['sepal_width']\n\ndf.head()\n</pre> # Criando uma nova caracter\u00edstica: \u00e1rea da s\u00e9pala  df['sepal_area'] = df['sepal_length'] * df['sepal_width']  df.head()  Out[\u00a0]: sepal_length sepal_width petal_length petal_width species sepal_area 0 5.1 3.5 1.4 0.2 Iris-setosa 17.85 1 4.9 3.0 1.4 0.2 Iris-setosa 14.70 2 4.7 3.2 1.3 0.2 Iris-setosa 15.04 3 4.6 3.1 1.5 0.2 Iris-setosa 14.26 4 5.0 3.6 1.4 0.2 Iris-setosa 18.00 In\u00a0[\u00a0]: Copied! <pre>## suas respostas aqui.....\n</pre> ## suas respostas aqui.....      In\u00a0[\u00a0]: Copied! <pre>### Implemente sua sua solu\u00e7\u00e3o e an\u00e1lise de dados. :)\n</pre> ### Implemente sua sua solu\u00e7\u00e3o e an\u00e1lise de dados. :)"},{"location":"aulas/IA/lab01/dataframe.html#objetivos","title":"Objetivos\u00b6","text":"<ul> <li>Apresentar e utilizar o pacote pandas</li> <li>Como carregar uma base dados</li> <li>Como visualizar os dados</li> <li>Intui\u00e7\u00e3o de an\u00e1lise explorat\u00f3ria de dados</li> </ul>"},{"location":"aulas/IA/lab01/dataframe.html#introducao-a-analise-de-dados-usando-pandas","title":"Introdu\u00e7\u00e3o a an\u00e1lise de dados usando Pandas\u00b6","text":"<p>Vamos come\u00e7ar pelo come\u00e7o! Vamos escolher um dataset (conjunto de dados) para analisar.</p> <p>Vamos utilizar um pacote do python capaz de trabalhar com tabelas de dados chamada pandas, para essas tabelas chamamos de dataframe.</p> <p>Veja mais em: https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.html</p>"},{"location":"aulas/IA/lab01/dataframe.html#hello-world-do-mundo-dos-dados","title":"Hello World! do mundo dos dados\u00b6","text":""},{"location":"aulas/IA/lab01/dataframe.html#conjunto-de-dados-dataset","title":"Conjunto de dados <code>Dataset</code>\u00b6","text":"<p>Para trabalhar com an\u00e1lise de dados precisamos de.... <code>DADOS</code>.</p> <p>Podemos escolher qualquer base de dados disponivel na internet, ou at\u00e9 mesmo criar nosso proprio dataset.</p> <p>Vamos simplificar essa etapa e come\u00e7ar analisando uma base pequena e muito famosa chamada iris que esta disponivel em:</p> <p>ref: https://archive.ics.uci.edu/ml/datasets/Iris</p> <p>Conhe\u00e7a outros datasets: https://archive.ics.uci.edu/ml/datasets.php</p>"},{"location":"aulas/IA/lab01/dataframe.html#conhecendo-os-dados","title":"Conhecendo os dados\u00b6","text":"<p>Essa etapa \u00e9 muito importante, CONHECER OS DADOS!</p> <p>Quanto mais voc\u00ea conhece a base de DADOS maior a possibilidade de extrair INFORMA\u00c7\u00d5ES \u00fateis para tomada de decis\u00e3o.</p>"},{"location":"aulas/IA/lab01/dataframe.html#analisando-o-dataset","title":"an\u00e1lisando o dataset\u00b6","text":"<p>Agora que j\u00e1 carregamos o dataset corretamente, vamos come\u00e7ar a analisa-lo. o m\u00e9todo <code>info()</code> \u00e9 um bom ponto de partida para isso.</p>"},{"location":"aulas/IA/lab01/dataframe.html#desafio-1","title":"Desafio 1\u00b6","text":"<p>Analisando as informa\u00e7\u00f5es do dataset iris, responda:</p> <ol> <li><p>Quantos dados existem nesse dataset?</p> </li> <li><p>Qual a quantidade de atributos?</p> </li> <li><p>Existe valores faltantes?</p> </li> <li><p>De que tipo s\u00e3o os dados (dtype)?</p> </li> </ol>"},{"location":"aulas/IA/lab01/dataframe.html#analisando-os-dados-mais-a-fundo","title":"An\u00e1lisando os dados mais a fundo\u00b6","text":""},{"location":"aulas/IA/lab01/dataframe.html#resumo-estatistico","title":"Resumo estat\u00edstico\u00b6","text":"<p>O m\u00e9todo <code>describe()</code> gera um resumo estat\u00edstico dos dados contidos em um DataFrame ou Series.</p> <p>Retorna estat\u00edsticas descritivas como <code>m\u00e9dia, desvio padr\u00e3o, valor m\u00ednimo, quartis e valor m\u00e1ximo</code> para as colunas num\u00e9ricas do DataFrame</p>"},{"location":"aulas/IA/lab01/dataframe.html#agrupando-dados","title":"Agrupando dados\u00b6","text":"<p>O m\u00e9todo <code>groupby</code> \u00e9 usada para agrupar dados com base em valores espec\u00edficos de uma ou mais colunas.</p> <p>Permite realizar opera\u00e7\u00f5es em grupos de dados e \u00e9 muito \u00fatil e versatil para an\u00e1lise e agrega\u00e7\u00e3o de dado.</p>"},{"location":"aulas/IA/lab01/dataframe.html#limpeza-de-dados","title":"Limpeza de Dados\u00b6","text":"<p>Base de dados do mundo real podem conter diversos problemas, \u00e9 muito comum o lidar com valores faltantes em um dataset.</p> <p>Como exemplo, vamos usar o conjunto de dados Iris, mas introduzimos algumas 'imperfei\u00e7\u00f5es' para fins de demonstra\u00e7\u00e3o.</p> <p>Para introduzir valores faltantes, podemos usar o seguinte c\u00f3digo:</p> <pre>## Gera dados faltante no dataset\nfor col in df_iris.columns[:-1]:\n    df_iris.loc[np.random.choice(df_iris.index, 5), col] = np.nan\n</pre>"},{"location":"aulas/IA/lab01/dataframe.html#excluindo-linhas","title":"Excluindo linhas\u00b6","text":"<p>Podemos simplismente excluir as linhas ou colunas que contenham dados faltantes, basta usar a fun\u00e7\u00e3o dropna pandas, utilizando como par\u00e2metros o axis = 1 para dizer que queremos deletar a coluna ou axis = 0 para linha e inplace = True para aplicarmos no dataset e n\u00e3o criarmos uma c\u00f3pia deste:</p> <ul> <li><code>axis=0</code> --&gt; exclui linha</li> <li><code>axis=1</code> --&gt; exclui coluna</li> </ul> <p><code>Pense bemmmm!!!!</code> A decis\u00e3o por qual vai excluir depende do problema que voc\u00ea est\u00e1 atacando...</p>"},{"location":"aulas/IA/lab01/dataframe.html#preenchimento-com-valores","title":"Preenchimento com valores\u00b6","text":"<p>Voc\u00ea pode preencher os valores faltantes com m\u00e9dias, medianas, modas ou outros valores relevantes.</p> <p>Isso ajuda a manter o tamanho do conjunto de dados, mas pode introduzir vi\u00e9s nos resultados.</p> <p><code>Pense bemmmm!!!!</code> A decis\u00e3o por qual valor preencher depende do problema que voc\u00ea est\u00e1 atacando...</p>"},{"location":"aulas/IA/lab01/dataframe.html#analisando-informacoes-em-graficos","title":"Analisando informa\u00e7\u00f5es em gr\u00e1ficos\u00b6","text":"<p>Uma an\u00e1lise gr\u00e1fica pode ajudar a compreeder melhor os dados que estamos trabalhando....</p> <p>Vamos explorar diferentes tipos de visualiza\u00e7\u00f5es que podem nos ajudar a entender melhor nossos dados.</p> <p>Vamos usar o <code>matplotlib</code> e o  <code>seaborn</code> para nos ajudar.</p> <p>Se precisar instalar:</p> <ul> <li>pip install matplotlib seaborn</li> </ul>"},{"location":"aulas/IA/lab01/dataframe.html#correlacao-entre-atributos","title":"Correla\u00e7\u00e3o entre atributos\u00b6","text":"<p>A matriz de correla\u00e7\u00e3o  avalia a rela\u00e7\u00e3o entre duas ou mais variaveis (correla\u00e7\u00e3o).</p> <p>valores:</p> <ul> <li>0.9 a 1 positivo ou negativo indica uma correla\u00e7\u00e3o muito forte.</li> <li>0.7 a 0.9 positivo ou negativo indica uma correla\u00e7\u00e3o forte.</li> <li>0.5 a 0.7 positivo ou negativo indica uma correla\u00e7\u00e3o moderada.</li> <li>0.3 a 0.5 positivo ou negativo indica uma correla\u00e7\u00e3o fraca.</li> <li>0 a 0.3 positivo ou negativo indica uma correla\u00e7\u00e3o desprez\u00edvel.</li> </ul> <p>lembre-se que: alta correla\u00e7\u00e3o n\u00e3o implica em causa. (causa e consequ\u00eancia). Para entender melhor vale a pena dar uma olhada nesse site que mostra correla\u00e7\u00f5es absurdas...'spurious correlations'</p>"},{"location":"aulas/IA/lab01/dataframe.html#desafio-2","title":"Desafio 2\u00b6","text":"<p>Analise os gr\u00e1ficos gerados at\u00e9 o momento para responder as quest\u00f5es abaixo:</p> <ol> <li><p>A especie que possui na m\u00e9dia a menor sepala \u00e9 a mesma que possui a menor petala?</p> </li> <li><p>Existe sobreposi\u00e7\u00e3o entre as medi\u00e7\u00f5es, ou seja, uma petala de tamanho x pode ser tanto da especie versicolor ou da virginica?</p> </li> <li><p>\u00c9 possivel classificar as especies de iris com base apenas em suas dimens\u00f5es?</p> </li> </ol>"},{"location":"aulas/IA/lab01/dataframe.html#acessando-dados-de-um-dataframe","title":"Acessando dados de um Dataframe\u00b6","text":"<p>H\u00e1 v\u00e1rias maneiras de acessar o conte\u00fado de um <code>DataFrame</code>. Os mais simples s\u00e3o aqueles que usam a nota\u00e7\u00e3o de colchetes. Primeiramente, podemos acessar uma coluna atrav\u00e9s do seu \u00edndice, retornando uma <code>Series</code>, ou seja, uma coluna do dataframe.</p>"},{"location":"aulas/IA/lab01/dataframe.html#desafios-3","title":"Desafios 3\u00b6","text":"<ol> <li>Limpeza de Dados: Introduza valores faltantes no dataset Iris. Tente usar diferentes m\u00e9todos para tratar essas imperfei\u00e7\u00f5es e compare os resultados.</li> <li>Manipula\u00e7\u00e3o de Dados: Use as fun\u00e7\u00f5es do pandas para responder \u00e0s seguintes perguntas sobre o dataset Iris:<ul> <li>Qual \u00e9 a m\u00e9dia da largura da s\u00e9pala para cada esp\u00e9cie?</li> <li>Quantas flores t\u00eam uma \u00e1rea da s\u00e9pala maior que 20 cm^2?</li> </ul> </li> <li>feature engineering: Pense em outras caracter\u00edsticas que podem ser criadas a partir do dataset Iris. Por exemplo, uma caracter\u00edstica que represente a propor\u00e7\u00e3o entre a largura e o comprimento da s\u00e9pala.</li> </ol>"},{"location":"aulas/IA/lab01/dataframe.html#desafio-4","title":"Desafio 4\u00b6","text":"<p>Fa\u00e7a agora uma explora\u00e7\u00e3o de dados em outra base, conhe\u00e7a a base, e crie hipoteses de teste.</p> <ol> <li>Importar os dados do dataset <code>Breast Cancer Data Set</code> acesse o site:<code>https://archive.ics.uci.edu/ml/datasets/breast+cancer</code></li> <li>Nomear as colunas de acordo com o arquivo <code>breast-cancer.names</code></li> <li>Ralizar a An\u00e1lise Explorat\u00f3ria de Dados (EDA):</li> <li>Visualize a distribui\u00e7\u00e3o de cada caracter\u00edstica do conjunto de dados.</li> <li>Determine quais caracter\u00edsticas t\u00eam maior correla\u00e7\u00e3o com a classifica\u00e7\u00e3o de malignidade.</li> <li>Crie novas caracter\u00edsticas a partir das existentes.</li> <li>Crie representa\u00e7\u00e3oes gr\u00e1ficas do dataset para contribuir para sua an\u00e1lise</li> </ol>"},{"location":"aulas/IA/lab01/dataframeold.html","title":"Dataframeold","text":"In\u00a0[\u00a0]: Copied! <pre>import pandas as pd\n\n# Cria uma dataframe\ndata = {\n  \"Nome\": [\"Riu\", \"M\u00e1rio\", \"Gogu\"],\n  \"Idade\": [50, 40, 45]\n}\n\n# Carrega o dataframe\ndf = pd.DataFrame(data)\n\nprint(df) \n</pre> import pandas as pd  # Cria uma dataframe data = {   \"Nome\": [\"Riu\", \"M\u00e1rio\", \"Gogu\"],   \"Idade\": [50, 40, 45] }  # Carrega o dataframe df = pd.DataFrame(data)  print(df)     <pre>    Nome  Idade\n0    Riu     50\n1  M\u00e1rio     40\n2   Gogu     45\n</pre> In\u00a0[\u00a0]: Copied! <pre>import pandas as pd\n\n# Cria uma dataframe\ndata = [[\"Riu\", 50],[\"Gogu\",15],[\"M\u00e1rio\",80]]\n\n# Carrega o dataframe\ndf = pd.DataFrame(data)\n\nprint(df)\n</pre> import pandas as pd  # Cria uma dataframe data = [[\"Riu\", 50],[\"Gogu\",15],[\"M\u00e1rio\",80]]  # Carrega o dataframe df = pd.DataFrame(data)  print(df) <pre>       0   1\n0    Riu  50\n1   Gogu  15\n2  M\u00e1rio  80\n</pre> <p>Para instalar</p> <ul> <li>pandas: <code>pip install pandas</code></li> </ul> <p>LEIA A DOCUMENTA\u00c7\u00c3O: https://pandas.pydata.org/docs/index.html</p> In\u00a0[\u00a0]: Copied! <pre># Inicializ\u00e7\u00e3o das bibliotecas\n%matplotlib inline\n\nimport pandas as pd\nimport matplotlib.pyplot as plt\n</pre> # Inicializ\u00e7\u00e3o das bibliotecas %matplotlib inline  import pandas as pd import matplotlib.pyplot as plt  In\u00a0[\u00a0]: Copied! <pre># Caminho do arquivo\nurl = \"https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data\"\n\n# L\u00ea e carrega o arquivo para a mem\u00f3ria\ndf = pd.read_csv(url)\n</pre> # Caminho do arquivo url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data\"  # L\u00ea e carrega o arquivo para a mem\u00f3ria df = pd.read_csv(url) In\u00a0[\u00a0]: Copied! <pre>df.head()\n</pre> df.head() Out[\u00a0]: 5.1 3.5 1.4 0.2 Iris-setosa 0 4.9 3.0 1.4 0.2 Iris-setosa 1 4.7 3.2 1.3 0.2 Iris-setosa 2 4.6 3.1 1.5 0.2 Iris-setosa 3 5.0 3.6 1.4 0.2 Iris-setosa 4 5.4 3.9 1.7 0.4 Iris-setosa <p>Note que a primeira linha n\u00e3o \u00e9 com os nomes das colunas ou atributos(variaveis) e sim de dados (valores). Por padr\u00e3o os dados da primeira linha s\u00e3o importados como atributos.</p> <p>Vamos adicionar um cabe\u00e7ario ao nosso dataframe. No reposit\u00f3rio oficial \u00e9 dito que as variaveis s\u00e3o:</p> <pre><code>Attribute Information:\n\n1. sepal length in cm\n2. sepal width in cm\n3. petal length in cm\n4. petal width in cm\n5. class:\n-- Iris Setosa\n-- Iris Versicolour\n-- Iris Virginica\n</code></pre> In\u00a0[\u00a0]: Copied! <pre># Define o nome das colunas\nheader = ['sepal_length', 'sepal_width', 'petal_length', 'petal_width', 'species']\n# L\u00ea e carrega o arquivo para a mem\u00f3ria\ndf = pd.read_csv(url, header=None, names=header)\n</pre> # Define o nome das colunas header = ['sepal_length', 'sepal_width', 'petal_length', 'petal_width', 'species'] # L\u00ea e carrega o arquivo para a mem\u00f3ria df = pd.read_csv(url, header=None, names=header) In\u00a0[\u00a0]: Copied! <pre># Retorna um trecho com as 5 primeiras linhas do dataframe\ndf.head()\n</pre> # Retorna um trecho com as 5 primeiras linhas do dataframe df.head() Out[\u00a0]: sepal_length sepal_width petal_length petal_width species 0 5.1 3.5 1.4 0.2 Iris-setosa 1 4.9 3.0 1.4 0.2 Iris-setosa 2 4.7 3.2 1.3 0.2 Iris-setosa 3 4.6 3.1 1.5 0.2 Iris-setosa 4 5.0 3.6 1.4 0.2 Iris-setosa In\u00a0[\u00a0]: Copied! <pre># Mostra informa\u00e7\u00f5es sobre o dataframe em si\ndf.info()\n</pre> # Mostra informa\u00e7\u00f5es sobre o dataframe em si df.info() <pre>&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 150 entries, 0 to 149\nData columns (total 5 columns):\n #   Column        Non-Null Count  Dtype  \n---  ------        --------------  -----  \n 0   sepal_length  150 non-null    float64\n 1   sepal_width   150 non-null    float64\n 2   petal_length  150 non-null    float64\n 3   petal_width   150 non-null    float64\n 4   species       150 non-null    object \ndtypes: float64(4), object(1)\nmemory usage: 6.0+ KB\n</pre> In\u00a0[\u00a0]: Copied! <pre># exibe o shape (dimenso\u1ebds) do dataframe\ndf.shape\n</pre> # exibe o shape (dimenso\u1ebds) do dataframe df.shape Out[\u00a0]: <pre>(150, 5)</pre> In\u00a0[\u00a0]: Copied! <pre># class distribution\nprint(df.groupby('species').size())\n</pre> # class distribution print(df.groupby('species').size()) <pre>species\nIris-setosa        50\nIris-versicolor    50\nIris-virginica     50\ndtype: int64\n</pre> In\u00a0[\u00a0]: Copied! <pre>## Suas respostas....\n</pre> ## Suas respostas....       <p>S\u00e3o 150 exemplares de flor de \u00edris, pertencentes a tr\u00eas esp\u00e9cies diferentes: setosa, versicolor e virginica, sendo 50 amostras de cada esp\u00e9cie. Os atributos de largura e comprimento de s\u00e9pala e largura e comprimento de p\u00e9tala de cada flor fooram medidos manualmente.</p> In\u00a0[\u00a0]: Copied! <pre>df.describe()\n</pre> df.describe() Out[\u00a0]: sepal_length sepal_width petal_length petal_width count 150.000000 150.000000 150.000000 150.000000 mean 5.843333 3.054000 3.758667 1.198667 std 0.828066 0.433594 1.764420 0.763161 min 4.300000 2.000000 1.000000 0.100000 25% 5.100000 2.800000 1.600000 0.300000 50% 5.800000 3.000000 4.350000 1.300000 75% 6.400000 3.300000 5.100000 1.800000 max 7.900000 4.400000 6.900000 2.500000 <p>Note que o m\u00e9todo describe() n\u00e3o exibe a coluna species, pois se trata de uma coluna n\u00e3o-num\u00e9rica. Apenas as colunas num\u00e9ricas est\u00e3o presentes, e a coluna *species** indica r\u00f3tulos - trata-se de dados categ\u00f3ricos.</p> In\u00a0[\u00a0]: Copied! <pre>df.species.unique()\n</pre> df.species.unique() Out[\u00a0]: <pre>array(['Iris-setosa', 'Iris-versicolor', 'Iris-virginica'], dtype=object)</pre> In\u00a0[\u00a0]: Copied! <pre># box and whisker plots\ndf.plot(kind='box', subplots=True, layout=(2,2), sharex=False, sharey=False, figsize=(15, 15))\nplt.show()\n</pre> # box and whisker plots df.plot(kind='box', subplots=True, layout=(2,2), sharex=False, sharey=False, figsize=(15, 15)) plt.show() In\u00a0[\u00a0]: Copied! <pre># Lembra de histograma, que exibe uma gr\u00e1fico de frequ\u00eancia.\ndf.hist(bins=100, figsize=(15, 15))\nplt.show()\n</pre> # Lembra de histograma, que exibe uma gr\u00e1fico de frequ\u00eancia. df.hist(bins=100, figsize=(15, 15)) plt.show() In\u00a0[\u00a0]: Copied! <pre># scatter plot matrix\nfrom pandas.plotting import scatter_matrix\nscatter_matrix(df,figsize=(15, 15))\nplt.show()\n</pre> # scatter plot matrix from pandas.plotting import scatter_matrix scatter_matrix(df,figsize=(15, 15)) plt.show() <p>Vamos instalar o pacote seaborn para visualizar gr\u00e1ficos de dispers\u00e3o entre todos os campos da tabela</p> <ul> <li>seaborn: <code>pip3 install seaborn</code></li> </ul> In\u00a0[\u00a0]: Copied! <pre>import matplotlib.pyplot as plt\nimport seaborn as sns\n\n# A cor vem do campo `species` do dataframe\nsns.pairplot(df, hue='species', height=5)\nplt.show()\n</pre> import matplotlib.pyplot as plt import seaborn as sns  # A cor vem do campo `species` do dataframe sns.pairplot(df, hue='species', height=5) plt.show() <p>O Violin plot \u00e9 similar ao box plot, exibe a distribui\u00e7\u00e3o de variaveis num\u00e9ricas em niveis, pode ser configurada de muitas formas e \u00e9 uma forma de visualiza\u00e7\u00e3o interessante de dados.</p> <p>Saiba mais em: https://seaborn.pydata.org/generated/seaborn.violinplot.html</p> In\u00a0[\u00a0]: Copied! <pre># Violin plot\ng = sns.violinplot(y='species', x='sepal_length', data=df, inner='quartile')\nplt.show()\ng = sns.violinplot(y='species', x='sepal_width', data=df, inner='quartile')\nplt.show()\ng = sns.violinplot(y='species', x='petal_length', data=df, inner='quartile')\nplt.show()\ng = sns.violinplot(y='species', x='petal_width', data=df, inner='quartile')\nplt.show()\n</pre> # Violin plot g = sns.violinplot(y='species', x='sepal_length', data=df, inner='quartile') plt.show() g = sns.violinplot(y='species', x='sepal_width', data=df, inner='quartile') plt.show() g = sns.violinplot(y='species', x='petal_length', data=df, inner='quartile') plt.show() g = sns.violinplot(y='species', x='petal_width', data=df, inner='quartile') plt.show() In\u00a0[\u00a0]: Copied! <pre>cols = ['sepal_length', 'sepal_width', 'petal_length','petal_width']\ncorr_matx = df[cols].corr()\nheatmap = sns.heatmap(corr_matx,cbar=True,annot=True,square=True,fmt='.2f',annot_kws={'size': 15},yticklabels=cols,xticklabels=cols,cmap='Dark2')\n</pre> cols = ['sepal_length', 'sepal_width', 'petal_length','petal_width'] corr_matx = df[cols].corr() heatmap = sns.heatmap(corr_matx,cbar=True,annot=True,square=True,fmt='.2f',annot_kws={'size': 15},yticklabels=cols,xticklabels=cols,cmap='Dark2') In\u00a0[\u00a0]: Copied! <pre>### Implemente sua solu\u00e7\u00e3o e apresente sua an\u00e1lise....\n</pre> ### Implemente sua solu\u00e7\u00e3o e apresente sua an\u00e1lise....     In\u00a0[\u00a0]: Copied! <pre>df['petal_length'].head()\n</pre> df['petal_length'].head() Out[\u00a0]: <pre>0    1.4\n1    1.4\n2    1.3\n3    1.5\n4    1.4\nName: petal_length, dtype: float64</pre> <p>Por outro lado, se dentro dos colchetes passamos uma lista de nomes de coluna, o reultado \u00e9 outro <code>DataFrame</code> contendo aquelas colunas. Isso vale inclusive para uma coluna simples:</p> In\u00a0[\u00a0]: Copied! <pre># Mostra apenas a coluna petal_len\ndf[['petal_length']].head()\n</pre> # Mostra apenas a coluna petal_len df[['petal_length']].head() Out[\u00a0]: petal_length 0 1.4 1 1.4 2 1.3 3 1.5 4 1.4 In\u00a0[\u00a0]: Copied! <pre># Mostra as colunas petal_length e petal_width\ndf[['petal_length', 'petal_width']].head()\n</pre> # Mostra as colunas petal_length e petal_width df[['petal_length', 'petal_width']].head() Out[\u00a0]: petal_length petal_width 0 1.4 0.2 1 1.4 0.2 2 1.3 0.2 3 1.5 0.2 4 1.4 0.2 In\u00a0[\u00a0]: Copied! <pre>### Implemente sua sua solu\u00e7\u00e3o e an\u00e1lise de dados. :)\n</pre> ### Implemente sua sua solu\u00e7\u00e3o e an\u00e1lise de dados. :)"},{"location":"aulas/IA/lab01/dataframeold.html#objetivos","title":"Objetivos\u00b6","text":"<ul> <li>Apresentar e utilizar o pacote pandas</li> <li>Como carregar uma base dados</li> <li>Como visualizar os dados</li> <li>Intui\u00e7\u00e3o de an\u00e1lise explorat\u00f3ria de dados</li> </ul>"},{"location":"aulas/IA/lab01/dataframeold.html#introducao","title":"Introdu\u00e7\u00e3o\u00b6","text":"<p>Vamos come\u00e7ar pelo come\u00e7o! Vamos escolher um dataset (conjunto de dados) para analisar.</p> <p>Vamos utilizar um pacote do python capaz de trabalhar com tabelas de dados chamada pandas, para essas tabelas chamamos de dataframe.</p> <p>Veja mais em: https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.html</p>"},{"location":"aulas/IA/lab01/dataframeold.html#dataset","title":"Dataset\u00b6","text":"<p>Podemos escolher qualquer base de dados disponivel na internet, ou at\u00e9 mesmo criar nosso proprio dataset.</p> <p>Vamos simplificar essa etapa e come\u00e7ar analisando uma base pequena e muito famosa chamada iris que esta disponivel em:</p> <p>ref: https://archive.ics.uci.edu/ml/datasets/Iris</p> <p>Conhe\u00e7a outros datasets: https://archive.ics.uci.edu/ml/datasets.php</p>"},{"location":"aulas/IA/lab01/dataframeold.html#conhecendo-os-dados","title":"Conhecendo os dados\u00b6","text":"<p>Essa etapa \u00e9 muito importante, CONHECER OS DADOS!</p> <p>Quanto mais voc\u00ea conhece a base de DADOS maior a possibilidade de extrair INFORMA\u00c7\u00d5ES \u00fateis para tomada de decis\u00e3o.</p>"},{"location":"aulas/IA/lab01/dataframeold.html#desafio-1","title":"Desafio 1\u00b6","text":"<ol> <li><p>Analisando as informa\u00e7\u00f5es do df e no repositorio do dataset, responda:</p> </li> <li><p>Quantos dados existem nesse dataset?</p> </li> <li><p>Qual a quantidade de atributos?</p> </li> <li><p>Existe valores faltantes?</p> </li> <li><p>De que tipo s\u00e3o os dados (dtype)?</p> </li> </ol>"},{"location":"aulas/IA/lab01/dataframeold.html#analisando-dos-dados-mais-a-fundo","title":"An\u00e1lisando dos dados mais a fundo\u00b6","text":""},{"location":"aulas/IA/lab01/dataframeold.html#analisando-informacoes-em-graficos","title":"Analisando informa\u00e7\u00f5es em gr\u00e1ficos\u00b6","text":"<p>Uma an\u00e1lise gr\u00e1fica pode ajudar a compreeder melhor os dados que estamos trabalhando....</p>"},{"location":"aulas/IA/lab01/dataframeold.html#correlacao-entre-atributos","title":"Correla\u00e7\u00e3o entre atributos\u00b6","text":"<p>A matriz de correla\u00e7\u00e3o  avalia a rela\u00e7\u00e3o entre duas ou mais variaveis (correla\u00e7\u00e3o).</p> <p>valores:</p> <ul> <li>0.9 a 1 positivo ou negativo indica uma correla\u00e7\u00e3o muito forte.</li> <li>0.7 a 0.9 positivo ou negativo indica uma correla\u00e7\u00e3o forte.</li> <li>0.5 a 0.7 positivo ou negativo indica uma correla\u00e7\u00e3o moderada.</li> <li>0.3 a 0.5 positivo ou negativo indica uma correla\u00e7\u00e3o fraca.</li> <li>0 a 0.3 positivo ou negativo indica uma correla\u00e7\u00e3o desprez\u00edvel.</li> </ul> <p>lembre-se que: alta correla\u00e7\u00e3o n\u00e3o implica em causa. (causa e consequ\u00eancia). Para entender melhor vale a pena dar uma olhada nesse site que mostra correla\u00e7\u00f5es absurdas...'spurious correlations'</p>"},{"location":"aulas/IA/lab01/dataframeold.html#desafio-2","title":"Desafio 2\u00b6","text":"<p>Analise os gr\u00e1ficos gerados at\u00e9 o momento para responder as quest\u00f5es abaixo:</p> <ol> <li><p>A especie que possui na m\u00e9dia a menor sepala \u00e9 a mesma que possui a menor petala?</p> </li> <li><p>Existe sobreposi\u00e7\u00e3o entre as medi\u00e7\u00f5es, ou seja, uma petala de tamanho x pode ser tanto da especie versicolor ou da virginica?</p> </li> <li><p>\u00c9 possivel classificar as especies de iris com base apenas em suas dimens\u00f5es?</p> </li> </ol>"},{"location":"aulas/IA/lab01/dataframeold.html#acessando-dados-de-um-dataframe","title":"Acessando dados de um Dataframe\u00b6","text":"<p>H\u00e1 v\u00e1rias maneiras de acessar o conte\u00fado de um <code>DataFrame</code>. Os mais simples s\u00e3o aqueles que usam a nota\u00e7\u00e3o de colchetes. Primeiramente, podemos acessar uma coluna atrav\u00e9s do seu \u00edndice, retornando uma <code>Series</code>, ou seja, uma coluna do dataframe.</p>"},{"location":"aulas/IA/lab01/dataframeold.html#desafio-3","title":"Desafio 3\u00b6","text":"<p>Fa\u00e7a agora uma explora\u00e7\u00e3o de dados em outra base, conhe\u00e7a a base, e crie hipoteses de teste.</p> <ol> <li>Importar os dados do dataset Breast Cancer Data Set: <code>https://archive.ics.uci.edu/ml/datasets/breast+cancer</code></li> <li>Nomear as colunas de acordo com o arquivo <code>breast-cancer.names</code></li> <li>Criar um subdataframe contendo apenas o conte\u00fado das colunas <code>Class</code>, <code>age</code>, <code>menopause</code> e <code>tumor-size</code></li> <li>Visualizar os dados usando pelo menos <code>head()</code> e <code>pairplot()</code></li> </ol>"},{"location":"aulas/IA/lab02/classificador-knn-old.html","title":"Classificador knn old","text":"<p>S\u00e3o 150 exemplares de flor de \u00edris, pertencentes a tr\u00eas esp\u00e9cies diferentes: setosa, versicolor e virginica, sendo 50 amostras de cada esp\u00e9cie. Os atributos de largura e comprimento de s\u00e9pala e largura e comprimento de p\u00e9tala de cada flor fooram medidos manualmente.</p> In\u00a0[\u00a0]: Copied! <pre>### Sua resposta.....\n</pre> ### Sua resposta.....   In\u00a0[\u00a0]: Copied! <pre># Inicializ\u00e7\u00e3o das bibliotecas\n%matplotlib inline\n\nimport pandas as pd\nimport matplotlib.pyplot as plt\n</pre> # Inicializ\u00e7\u00e3o das bibliotecas %matplotlib inline  import pandas as pd import matplotlib.pyplot as plt  In\u00a0[\u00a0]: Copied! <pre># Caminho do arquivo\nurl = \"https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data\"\n# Define o nome das colunas\nheader = ['sepal_length', 'sepal_width', 'petal_length', 'petal_width', 'species']\n# L\u00ea e carrega o arquivo para a mem\u00f3ria\ndf = pd.read_csv(url, header=None, names=header)\n</pre> # Caminho do arquivo url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data\" # Define o nome das colunas header = ['sepal_length', 'sepal_width', 'petal_length', 'petal_width', 'species'] # L\u00ea e carrega o arquivo para a mem\u00f3ria df = pd.read_csv(url, header=None, names=header) In\u00a0[\u00a0]: Copied! <pre># Retorna um trecho com as 5 primeiras linhas do dataframe\ndf.head()\n</pre> # Retorna um trecho com as 5 primeiras linhas do dataframe df.head() Out[\u00a0]: sepal_length sepal_width petal_length petal_width species 0 5.1 3.5 1.4 0.2 Iris-setosa 1 4.9 3.0 1.4 0.2 Iris-setosa 2 4.7 3.2 1.3 0.2 Iris-setosa 3 4.6 3.1 1.5 0.2 Iris-setosa 4 5.0 3.6 1.4 0.2 Iris-setosa In\u00a0[\u00a0]: Copied! <pre>df.tail()\n</pre> df.tail() Out[\u00a0]: sepal_length sepal_width petal_length petal_width species 145 6.7 3.0 5.2 2.3 Iris-virginica 146 6.3 2.5 5.0 1.9 Iris-virginica 147 6.5 3.0 5.2 2.0 Iris-virginica 148 6.2 3.4 5.4 2.3 Iris-virginica 149 5.9 3.0 5.1 1.8 Iris-virginica In\u00a0[\u00a0]: Copied! <pre># Mostra informa\u00e7\u00f5es sobre o dataframe em si\ndf.info()\n</pre> # Mostra informa\u00e7\u00f5es sobre o dataframe em si df.info() <pre>&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 150 entries, 0 to 149\nData columns (total 5 columns):\n #   Column        Non-Null Count  Dtype  \n---  ------        --------------  -----  \n 0   sepal_length  150 non-null    float64\n 1   sepal_width   150 non-null    float64\n 2   petal_length  150 non-null    float64\n 3   petal_width   150 non-null    float64\n 4   species       150 non-null    object \ndtypes: float64(4), object(1)\nmemory usage: 6.0+ KB\n</pre> In\u00a0[\u00a0]: Copied! <pre># class distribution\nprint(df.groupby('species').size())\n</pre> # class distribution print(df.groupby('species').size()) <pre>species\nIris-setosa        50\nIris-versicolor    50\nIris-virginica     50\ndtype: int64\n</pre> In\u00a0[\u00a0]: Copied! <pre>## Sua resposta e seus gr\u00e1ficos para an\u00e1lisar..\n</pre> ## Sua resposta e seus gr\u00e1ficos para an\u00e1lisar..       In\u00a0[\u00a0]: Copied! <pre># Selecionando um sub-dataframe com os campos petal_length e petal_width, \n# e outro com a vari\u00e1vel de classes\nentradas = df[['petal_length', 'petal_width']]\nclasses = df['species']\nprint(f\"Formato das tabelas de dados {entradas.shape} e classes {classes.shape}\")\n</pre> # Selecionando um sub-dataframe com os campos petal_length e petal_width,  # e outro com a vari\u00e1vel de classes entradas = df[['petal_length', 'petal_width']] classes = df['species'] print(f\"Formato das tabelas de dados {entradas.shape} e classes {classes.shape}\") <pre>Formato das tabelas de dados (150, 2) e classes (150,)\n</pre> In\u00a0[\u00a0]: Copied! <pre># Separamos 20% para o teste\nfrom sklearn.model_selection import train_test_split\n\nentradas_treino, entradas_teste, classes_treino, classes_teste = train_test_split(entradas, classes, test_size=0.2)\n\nprint(f\"Formato das tabelas de dados de treino {entradas_treino.shape} e teste {entradas_teste.shape}\")\n</pre> # Separamos 20% para o teste from sklearn.model_selection import train_test_split  entradas_treino, entradas_teste, classes_treino, classes_teste = train_test_split(entradas, classes, test_size=0.2)  print(f\"Formato das tabelas de dados de treino {entradas_treino.shape} e teste {entradas_teste.shape}\") <pre>Formato das tabelas de dados de treino (120, 2) e teste (30, 2)\n</pre> In\u00a0[\u00a0]: Copied! <pre>#Primeiras linhas do dataframe \nentradas_treino.head()\n</pre> #Primeiras linhas do dataframe  entradas_treino.head() Out[\u00a0]: petal_length petal_width 31 1.5 0.4 120 5.7 2.3 93 3.3 1.0 5 1.7 0.4 102 5.9 2.1 In\u00a0[\u00a0]: Copied! <pre>classes_treino.head()\n</pre> classes_treino.head() Out[\u00a0]: <pre>31         Iris-setosa\n120     Iris-virginica\n93     Iris-versicolor\n5          Iris-setosa\n102     Iris-virginica\nName: species, dtype: object</pre> In\u00a0[\u00a0]: Copied! <pre># Importa a biblioteca\nfrom sklearn.neighbors import KNeighborsClassifier\n\n# Cria o classificar KNN\nk = 9\nmodelo = KNeighborsClassifier(n_neighbors=k)\n\n# Cria o modelo de machine learning\nmodelo.fit(entradas_treino, classes_treino)\n</pre> # Importa a biblioteca from sklearn.neighbors import KNeighborsClassifier  # Cria o classificar KNN k = 9 modelo = KNeighborsClassifier(n_neighbors=k)  # Cria o modelo de machine learning modelo.fit(entradas_treino, classes_treino)    Out[\u00a0]: <pre>KNeighborsClassifier(n_neighbors=9)</pre> <p>Pronto!! bora testar se esta funcionando....</p> In\u00a0[\u00a0]: Copied! <pre># Para obter as previs\u00f5es, basta chamar o m\u00e9todo predict()\nclasses_encontradas = modelo.predict(entradas_teste)\nprint(\"Predi\u00e7\u00e3o: {}\".format(classes_encontradas))\n</pre> # Para obter as previs\u00f5es, basta chamar o m\u00e9todo predict() classes_encontradas = modelo.predict(entradas_teste) print(\"Predi\u00e7\u00e3o: {}\".format(classes_encontradas)) <pre>Predi\u00e7\u00e3o: ['Iris-virginica' 'Iris-virginica' 'Iris-virginica' 'Iris-virginica'\n 'Iris-virginica' 'Iris-virginica' 'Iris-versicolor' 'Iris-virginica'\n 'Iris-versicolor' 'Iris-versicolor' 'Iris-versicolor' 'Iris-versicolor'\n 'Iris-virginica' 'Iris-setosa' 'Iris-versicolor' 'Iris-setosa'\n 'Iris-versicolor' 'Iris-setosa' 'Iris-virginica' 'Iris-setosa'\n 'Iris-virginica' 'Iris-setosa' 'Iris-versicolor' 'Iris-versicolor'\n 'Iris-setosa' 'Iris-virginica' 'Iris-versicolor' 'Iris-virginica'\n 'Iris-versicolor' 'Iris-virginica']\n</pre> In\u00a0[\u00a0]: Copied! <pre># Para determinar a quantidade de acertos (acuracia)\n\nfrom sklearn.metrics import accuracy_score\nacertos = accuracy_score(classes_teste, classes_encontradas)\nprint(\"Acerto m\u00e9dio de classifica\u00e7\u00e3o: \", acertos)\n</pre> # Para determinar a quantidade de acertos (acuracia)  from sklearn.metrics import accuracy_score acertos = accuracy_score(classes_teste, classes_encontradas) print(\"Acerto m\u00e9dio de classifica\u00e7\u00e3o: \", acertos) <pre>Acerto m\u00e9dio de classifica\u00e7\u00e3o:  0.9666666666666667\n</pre> In\u00a0[\u00a0]: Copied! <pre># Criamos um modelo utilizando duas entradas e uma saida, logo temos que passar duas entradas para o modelo fa\u00e7a a predi\u00e7\u00e3o. \n\nmodelo.predict([[3.3, 3.2]])\n</pre> # Criamos um modelo utilizando duas entradas e uma saida, logo temos que passar duas entradas para o modelo fa\u00e7a a predi\u00e7\u00e3o.   modelo.predict([[3.3, 3.2]]) Out[\u00a0]: <pre>array(['Iris-versicolor'], dtype=object)</pre> In\u00a0[\u00a0]: Copied! <pre># Unificamos os dados de entrada e as classes de treino e teste em um daframe cada\ndf_treino = pd.concat((entradas_treino, classes_treino), axis=1)\n\nnovas_classes = pd.Series(classes_encontradas, name=\"species\", index=entradas_teste.index)\ndf_teste = pd.concat((entradas_teste, novas_classes), axis=1)\n</pre> # Unificamos os dados de entrada e as classes de treino e teste em um daframe cada df_treino = pd.concat((entradas_treino, classes_treino), axis=1)  novas_classes = pd.Series(classes_encontradas, name=\"species\", index=entradas_teste.index) df_teste = pd.concat((entradas_teste, novas_classes), axis=1) In\u00a0[\u00a0]: Copied! <pre>import seaborn as sns\n## Unificamos os dataframes de treinamento e teste em um novo DataFrame\n# indicando a origem dos dados\nnovo_df = pd.concat((df_treino, df_teste), keys=['train', 'test'])\nnovo_df['origin'] = ''\nnovo_df.loc['train','origin'] = 'Treino'\nnovo_df.loc['test','origin'] = 'Teste'\n\n# Usamos o scatterplot do seaborn, informando mudando o marcador de acordo com a origem do dado\nsns.scatterplot('petal_length', 'petal_width', hue='species', style='origin', data=novo_df)\n\nplt.show()\n</pre> import seaborn as sns ## Unificamos os dataframes de treinamento e teste em um novo DataFrame # indicando a origem dos dados novo_df = pd.concat((df_treino, df_teste), keys=['train', 'test']) novo_df['origin'] = '' novo_df.loc['train','origin'] = 'Treino' novo_df.loc['test','origin'] = 'Teste'  # Usamos o scatterplot do seaborn, informando mudando o marcador de acordo com a origem do dado sns.scatterplot('petal_length', 'petal_width', hue='species', style='origin', data=novo_df)  plt.show() <pre>c:\\Users\\junior\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\seaborn\\_decorators.py:36: FutureWarning: Pass the following variables as keyword args: x, y. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n  warnings.warn(\n</pre> In\u00a0[\u00a0]: Copied! <pre>### Implemente sua sua solu\u00e7\u00e3o.....\n</pre> ### Implemente sua sua solu\u00e7\u00e3o.....       In\u00a0[\u00a0]: Copied! <pre>#### Resposta loop for para diferntes k\nk_range = list(range(1,26))\nacertos = []\nfor k in k_range:\n    modelo = KNeighborsClassifier(n_neighbors=k)\n    modelo.fit(entradas_treino, classes_treino)\n    classes_encontradas = modelo.predict(entradas_teste)\n    acertos.append(accuracy_score(classes_teste, classes_encontradas))\n  \n  \nplt.plot(k_range, acertos)\nplt.xlabel('Valor de k do KNN')\nplt.ylabel('Taxa de acertos')\nplt.title('Taxa de acertos x valor de k do KNN')\nplt.show()\n</pre> #### Resposta loop for para diferntes k k_range = list(range(1,26)) acertos = [] for k in k_range:     modelo = KNeighborsClassifier(n_neighbors=k)     modelo.fit(entradas_treino, classes_treino)     classes_encontradas = modelo.predict(entradas_teste)     acertos.append(accuracy_score(classes_teste, classes_encontradas))       plt.plot(k_range, acertos) plt.xlabel('Valor de k do KNN') plt.ylabel('Taxa de acertos') plt.title('Taxa de acertos x valor de k do KNN') plt.show()  In\u00a0[\u00a0]: Copied! <pre>## implemente sua sua solu\u00e7\u00e3o....\n</pre> ## implemente sua sua solu\u00e7\u00e3o....     In\u00a0[\u00a0]: Copied! <pre># implemente sua solu\u00e7\u00e3o......\n</pre> # implemente sua solu\u00e7\u00e3o......"},{"location":"aulas/IA/lab02/classificador-knn-old.html#objetivos","title":"Objetivos\u00b6","text":"<ul> <li>Apresentar e utilizar o classificador k-nearest neighbours (kNN)</li> <li>Apresentar a t\u00e9cnica de separa\u00e7\u00e3o de dados (treino e teste)</li> <li>Avaliar Aprendizagem do modelo</li> </ul>"},{"location":"aulas/IA/lab02/classificador-knn-old.html#comecando","title":"Come\u00e7ando\u00b6","text":"<p>Vamos dar continuidade ao nosso estudo de aprendizagem de m\u00e1quina, j\u00e1 vimos:</p> <ul> <li>Tudo come\u00e7a, conhecendo os dados dispon\u00edveis.</li> <li>Como carregar um data frame</li> <li>Como visualizar os dados em gr\u00e1ficos (histograma, box plot, violin plot, matriz de confus\u00e3o)</li> <li>Fizemos uma breve introdu\u00e7\u00e3o sobre an\u00e1lise explorat\u00f3ria buscando correlacionar os dados para gerar informa\u00e7\u00f5es.</li> </ul> <p>Hoje, vamos seguir nossa jornada e finalizar nosso estudo aplicando a t\u00e9cnica de KNN.</p>"},{"location":"aulas/IA/lab02/classificador-knn-old.html#k-nearest-neighbors","title":"k-Nearest Neighbors\u00b6","text":"<p>O KNN(K vizinhos mais pr\u00f3ximos) \u00e9 considerado um dos algoritmos mais simples dentro da categoria de aprendizagem supervisionada sendo muito utilizado para problemas de classifica\u00e7\u00e3o, por\u00e9m tamb\u00e9m pode ser utilizado em problemas de regress\u00e3o.</p> <p>Problemas de classifica\u00e7\u00e3o = Vale lembrar que em problemas de classifica\u00e7\u00e3o n\u00e3o estamos interessados em valores exatos, queremos apenas saber se um dado pertence ou n\u00e3o a uma dada classe.</p>"},{"location":"aulas/IA/lab02/classificador-knn-old.html#uma-intuicao-sobre-o-metodo","title":"Uma intui\u00e7\u00e3o sobre o m\u00e9todo\u00b6","text":"<p>Para realizar a classifica\u00e7\u00e3o o KNN calcula a dist\u00e2ncia objeto desconhecido (target) para todos os outros elementos, encontra os mais K vizinhos mais pr\u00f3ximos faz uma contagem dos r\u00f3tulos e considera que o objeto desconhecido pertence ao r\u00f3tulo de maior contagem.</p> <p>A imagem abaixo exemplifica o funcionamento, mas se ficou um pouco complicado de entender, rode o script python iknn.py e fa\u00e7a algumas simula\u00e7\u00f5es para compreender.</p> <p> </p>"},{"location":"aulas/IA/lab02/classificador-knn-old.html#bora-la","title":"Bora l\u00e1!!\u00b6","text":"<p>Vamos juntos realizar nosso primeiro projeto, do come\u00e7o ao fim, de aprendizagem de m\u00e1quina.</p>"},{"location":"aulas/IA/lab02/classificador-knn-old.html#definicao-do-problema","title":"Defini\u00e7\u00e3o do problema\u00b6","text":"<p>A primeira coisa que precisamos fazer \u00e9 a defini\u00e7\u00e3o do problema. Neste primeiro caso vamos trabalhar com o mesmo dataset da \u00faltima aula, dataset iris. Vamos desenvolver um sistema de machine learning capaz de classificar sua esp\u00e9cie com base nos dimensionais da p\u00e9tala.</p>"},{"location":"aulas/IA/lab02/classificador-knn-old.html#desafio-1","title":"Desafio 1\u00b6","text":"<p>Do ponto de vista de machine learning, que problema \u00e9 esse:</p> <pre><code>Aprendizado supervisionado ou n\u00e3o-supervisionado?</code></pre> <p>R:</p> <pre><code>Classifica\u00e7\u00e3o ou regress\u00e3o?</code></pre> <p>R:</p>"},{"location":"aulas/IA/lab02/classificador-knn-old.html#desafio-2","title":"Desafio 2\u00b6","text":"<p>Aplique os m\u00e9todos que achar conveniente (vimos algumas op\u00e7\u00f5es na \u00faltima aula) para visualizar os dados de forma gr\u00e1fica.</p>"},{"location":"aulas/IA/lab02/classificador-knn-old.html#pare","title":"PARE!!!\u00b6","text":"<p>A an\u00e1lise feita no desafio 2 \u00e9 uma das etapas mais importantes. Caso voc\u00ea tenha pulado essa etapa, volte e fa\u00e7a suas an\u00e1lises.</p> <p>Com essa etapa conclu\u00edda, vamos criar um sub-dataset com os atributos que ser\u00e3o utilizados.</p>"},{"location":"aulas/IA/lab02/classificador-knn-old.html#dividindo-os-dados-em-conjunto-de-treinamento-e-de-testes","title":"Dividindo os dados em conjunto de treinamento e de testes\u00b6","text":"<p>Dividir nosso dataset em dois conjuntos de dados.</p> <pre><code>Treinamento - Representa 80% das amostras do conjunto de dados original,\nTeste - com 20% das amostras</code></pre> <p>Vamos escolher aleatoriamente algumas amostras do conjunto original. Isto pode ser feito com Scikit-Learn usando a fun\u00e7\u00e3o train_test_split()</p> <p>scikit-learn: pip3 install scikit-learn</p>"},{"location":"aulas/IA/lab02/classificador-knn-old.html#chegou-a-hora-de-aplicar-o-modelo-preditivo","title":"Chegou a hora de aplicar o modelo preditivo\u00b6","text":"<p>Treinar um modelo no python \u00e9 simples se usar o Scikit-Learn. Treinar um modelo no Scikit-Learn \u00e9 simples: basta criar o classificador, e chamar o m\u00e9todo fit().</p> <p>Uma observa\u00e7\u00e3o sobre a sintaxe dos classificadores do <code>scikit-learn</code></p> <ul> <li>O m\u00e9todo <code>fit(X,Y)</code> recebe uma matriz ou dataframe X onde cada linha \u00e9 uma amostra de aprendizado, e um array Y contendo as sa\u00eddas esperadas do classificador, seja na forma de texto ou de inteiros</li> <li>O m\u00e9todo <code>predict(X)</code> recebe uma matriz ou dataframe X onde cada linha \u00e9 uma amostra de teste, retornando um array de classes</li> </ul>"},{"location":"aulas/IA/lab02/classificador-knn-old.html#utilizando-o-modelo-treinado-com-amostras-fora-do-dataset","title":"Utilizando o modelo treinado com amostras fora do dataset\u00b6","text":"<p>Vamos colocar alguns valores e ver a predi\u00e7\u00e3o do classificador.</p>"},{"location":"aulas/IA/lab02/classificador-knn-old.html#visualizando-o-modelo-de-forma-grafica","title":"Visualizando o modelo de forma gr\u00e1fica\u00b6","text":""},{"location":"aulas/IA/lab02/classificador-knn-old.html#desafio-3","title":"Desafio 3\u00b6","text":"<p>Fizemos o treinamento para k=3, mude o valor de k e an\u00e1lise a acur\u00e1cia do modelo.</p> <p>Dica: Fa\u00e7a um loop for que varre um range de k, a sa\u00edda pode ser armazenada em uma lista. No final do loop exiba em um gr\u00e1fico.</p>"},{"location":"aulas/IA/lab02/classificador-knn-old.html#desafio-4","title":"Desafio 4\u00b6","text":"<p>Refa\u00e7a os notebook substituindo as entradas (variaveis independentes) e analise se o modelo obtido ficou melhor ou pior.</p>"},{"location":"aulas/IA/lab02/classificador-knn-old.html#desafio-5","title":"Desafio 5\u00b6","text":"<p>Lembra o dataset 'breast_cancer', fa\u00e7a um modelo de predi\u00e7\u00e3o que informa se o c\u00e2ncer \u00e9 maligno ou n\u00e3o.</p>"},{"location":"aulas/IA/lab02/classificador_knn.html","title":"lab1","text":"<p>S\u00e3o 150 exemplares de flor de \u00edris, pertencentes a tr\u00eas esp\u00e9cies diferentes: setosa, versicolor e virginica, sendo 50 amostras de cada esp\u00e9cie. Os atributos de largura e comprimento de s\u00e9pala e largura e comprimento de p\u00e9tala de cada flor fooram medidos manualmente.</p> In\u00a0[\u00a0]: Copied! <pre>### Sua resposta.....\n</pre> ### Sua resposta.....   In\u00a0[\u00a0]: Copied! <pre># Inicializ\u00e7\u00e3o das bibliotecas\n%matplotlib inline\n\nimport pandas as pd\nimport matplotlib.pyplot as plt\n</pre> # Inicializ\u00e7\u00e3o das bibliotecas %matplotlib inline  import pandas as pd import matplotlib.pyplot as plt  In\u00a0[\u00a0]: Copied! <pre># Caminho do arquivo\nurl = \"https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data\"\n# Define o nome das colunas\nheader = ['sepal_length', 'sepal_width', 'petal_length', 'petal_width', 'species']\n# L\u00ea e carrega o arquivo para a mem\u00f3ria\ndf = pd.read_csv(url, header=None, names=header)\n</pre> # Caminho do arquivo url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data\" # Define o nome das colunas header = ['sepal_length', 'sepal_width', 'petal_length', 'petal_width', 'species'] # L\u00ea e carrega o arquivo para a mem\u00f3ria df = pd.read_csv(url, header=None, names=header) In\u00a0[\u00a0]: Copied! <pre># Retorna um trecho com as 5 primeiras linhas do dataframe\ndf.head()\n</pre> # Retorna um trecho com as 5 primeiras linhas do dataframe df.head() Out[\u00a0]: sepal_length sepal_width petal_length petal_width species 0 5.1 3.5 1.4 0.2 Iris-setosa 1 4.9 3.0 1.4 0.2 Iris-setosa 2 4.7 3.2 1.3 0.2 Iris-setosa 3 4.6 3.1 1.5 0.2 Iris-setosa 4 5.0 3.6 1.4 0.2 Iris-setosa In\u00a0[\u00a0]: Copied! <pre>df.tail()\n</pre> df.tail() Out[\u00a0]: sepal_length sepal_width petal_length petal_width species 145 6.7 3.0 5.2 2.3 Iris-virginica 146 6.3 2.5 5.0 1.9 Iris-virginica 147 6.5 3.0 5.2 2.0 Iris-virginica 148 6.2 3.4 5.4 2.3 Iris-virginica 149 5.9 3.0 5.1 1.8 Iris-virginica In\u00a0[\u00a0]: Copied! <pre># Mostra informa\u00e7\u00f5es sobre o dataframe em si\ndf.info()\n</pre> # Mostra informa\u00e7\u00f5es sobre o dataframe em si df.info() <pre>&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 150 entries, 0 to 149\nData columns (total 5 columns):\n #   Column        Non-Null Count  Dtype  \n---  ------        --------------  -----  \n 0   sepal_length  150 non-null    float64\n 1   sepal_width   150 non-null    float64\n 2   petal_length  150 non-null    float64\n 3   petal_width   150 non-null    float64\n 4   species       150 non-null    object \ndtypes: float64(4), object(1)\nmemory usage: 6.0+ KB\n</pre> In\u00a0[\u00a0]: Copied! <pre># class distribution\nprint(df.groupby('species').size())\n</pre> # class distribution print(df.groupby('species').size()) <pre>species\nIris-setosa        50\nIris-versicolor    50\nIris-virginica     50\ndtype: int64\n</pre> In\u00a0[\u00a0]: Copied! <pre>## Sua resposta e seus gr\u00e1ficos para an\u00e1lisar..\n</pre> ## Sua resposta e seus gr\u00e1ficos para an\u00e1lisar..       In\u00a0[\u00a0]: Copied! <pre># Selecionando um sub-dataframe com os campos petal_length e petal_width,\n# e outro com a vari\u00e1vel de classes\nentradas = df[['petal_length', 'petal_width']]\nclasses = df['species']\nprint(f\"Formato das tabelas de dados {entradas.shape} e classes {classes.shape}\")\n</pre> # Selecionando um sub-dataframe com os campos petal_length e petal_width, # e outro com a vari\u00e1vel de classes entradas = df[['petal_length', 'petal_width']] classes = df['species'] print(f\"Formato das tabelas de dados {entradas.shape} e classes {classes.shape}\") <pre>Formato das tabelas de dados (150, 2) e classes (150,)\n</pre> In\u00a0[\u00a0]: Copied! <pre># Separamos 20% para o teste\nfrom sklearn.model_selection import train_test_split\n\nentradas_treino, entradas_teste, classes_treino, classes_teste = train_test_split(entradas, classes, test_size=0.2)\n\nprint(f\"Formato das tabelas de dados de treino {entradas_treino.shape} e teste {entradas_teste.shape}\")\n</pre> # Separamos 20% para o teste from sklearn.model_selection import train_test_split  entradas_treino, entradas_teste, classes_treino, classes_teste = train_test_split(entradas, classes, test_size=0.2)  print(f\"Formato das tabelas de dados de treino {entradas_treino.shape} e teste {entradas_teste.shape}\") <pre>Formato das tabelas de dados de treino (120, 2) e teste (30, 2)\n</pre> In\u00a0[\u00a0]: Copied! <pre>#Primeiras linhas do dataframe\nentradas_treino.head()\n</pre> #Primeiras linhas do dataframe entradas_treino.head() Out[\u00a0]: petal_length petal_width 71 4.0 1.3 78 4.5 1.5 129 5.8 1.6 48 1.5 0.2 148 5.4 2.3 In\u00a0[\u00a0]: Copied! <pre>classes_treino.head()\n</pre> classes_treino.head() Out[\u00a0]: species 71 Iris-versicolor 78 Iris-versicolor 129 Iris-virginica 48 Iris-setosa 148 Iris-virginica dtype: object In\u00a0[\u00a0]: Copied! <pre># Importa a biblioteca\nfrom sklearn.neighbors import KNeighborsClassifier\n\n# Cria o classificar KNN\nk = 9\nmodelo = KNeighborsClassifier(n_neighbors=k)\n\n# Cria o modelo de machine learning\nmodelo.fit(entradas_treino, classes_treino)\n</pre> # Importa a biblioteca from sklearn.neighbors import KNeighborsClassifier  # Cria o classificar KNN k = 9 modelo = KNeighborsClassifier(n_neighbors=k)  # Cria o modelo de machine learning modelo.fit(entradas_treino, classes_treino)    Out[\u00a0]: <pre>KNeighborsClassifier(n_neighbors=9)</pre>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.KNeighborsClassifier<pre>KNeighborsClassifier(n_neighbors=9)</pre> <p>Pronto!! bora testar se esta funcionando....</p> In\u00a0[\u00a0]: Copied! <pre># Para obter as previs\u00f5es, basta chamar o m\u00e9todo predict()\nclasses_encontradas = modelo.predict(entradas_teste)\nprint(\"Predi\u00e7\u00e3o: {}\".format(classes_encontradas))\n</pre> # Para obter as previs\u00f5es, basta chamar o m\u00e9todo predict() classes_encontradas = modelo.predict(entradas_teste) print(\"Predi\u00e7\u00e3o: {}\".format(classes_encontradas)) <pre>Predi\u00e7\u00e3o: ['Iris-setosa' 'Iris-versicolor' 'Iris-setosa' 'Iris-setosa'\n 'Iris-versicolor' 'Iris-versicolor' 'Iris-versicolor' 'Iris-versicolor'\n 'Iris-setosa' 'Iris-setosa' 'Iris-versicolor' 'Iris-versicolor'\n 'Iris-virginica' 'Iris-setosa' 'Iris-versicolor' 'Iris-setosa'\n 'Iris-versicolor' 'Iris-versicolor' 'Iris-virginica' 'Iris-setosa'\n 'Iris-versicolor' 'Iris-virginica' 'Iris-versicolor' 'Iris-versicolor'\n 'Iris-setosa' 'Iris-virginica' 'Iris-setosa' 'Iris-versicolor'\n 'Iris-virginica' 'Iris-setosa']\n</pre> In\u00a0[\u00a0]: Copied! <pre># Para determinar a quantidade de acertos (acuracia)\n\nfrom sklearn.metrics import accuracy_score\nacertos = accuracy_score(classes_teste, classes_encontradas)\nprint(\"Acerto m\u00e9dio de classifica\u00e7\u00e3o: \", acertos)\n</pre> # Para determinar a quantidade de acertos (acuracia)  from sklearn.metrics import accuracy_score acertos = accuracy_score(classes_teste, classes_encontradas) print(\"Acerto m\u00e9dio de classifica\u00e7\u00e3o: \", acertos) <pre>Acerto m\u00e9dio de classifica\u00e7\u00e3o:  0.9333333333333333\n</pre> In\u00a0[\u00a0]: Copied! <pre># Criamos um modelo utilizando duas entradas e uma saida, logo temos que passar duas entradas para o modelo fa\u00e7a a predi\u00e7\u00e3o.\n\nmodelo.predict([[3.3, 3.2]])\n</pre> # Criamos um modelo utilizando duas entradas e uma saida, logo temos que passar duas entradas para o modelo fa\u00e7a a predi\u00e7\u00e3o.  modelo.predict([[3.3, 3.2]]) <pre>/usr/local/lib/python3.10/dist-packages/sklearn/base.py:465: UserWarning: X does not have valid feature names, but KNeighborsClassifier was fitted with feature names\n  warnings.warn(\n</pre> Out[\u00a0]: <pre>array(['Iris-versicolor'], dtype=object)</pre> In\u00a0[\u00a0]: Copied! <pre># Unificamos os dados de entrada e as classes de treino e teste em um daframe cada\ndf_treino = pd.concat((entradas_treino, classes_treino), axis=1)\n\nnovas_classes = pd.Series(classes_encontradas, name=\"species\", index=entradas_teste.index)\ndf_teste = pd.concat((entradas_teste, novas_classes), axis=1)\n</pre> # Unificamos os dados de entrada e as classes de treino e teste em um daframe cada df_treino = pd.concat((entradas_treino, classes_treino), axis=1)  novas_classes = pd.Series(classes_encontradas, name=\"species\", index=entradas_teste.index) df_teste = pd.concat((entradas_teste, novas_classes), axis=1) In\u00a0[\u00a0]: Copied! <pre>import seaborn as sns\n## Unificamos os dataframes de treinamento e teste em um novo DataFrame\n# indicando a origem dos dados\nnovo_df = pd.concat((df_treino, df_teste), keys=['train', 'test'])\nnovo_df['origin'] = ''\nnovo_df.loc['train','origin'] = 'Treino'\nnovo_df.loc['test','origin'] = 'Teste'\n\n# Usamos o scatterplot do seaborn, informando mudando o marcador de acordo com a origem do dado\nsns.scatterplot(x='petal_length', y='petal_width', hue='species', style='origin', data=novo_df)\n\nplt.show()\n</pre> import seaborn as sns ## Unificamos os dataframes de treinamento e teste em um novo DataFrame # indicando a origem dos dados novo_df = pd.concat((df_treino, df_teste), keys=['train', 'test']) novo_df['origin'] = '' novo_df.loc['train','origin'] = 'Treino' novo_df.loc['test','origin'] = 'Teste'  # Usamos o scatterplot do seaborn, informando mudando o marcador de acordo com a origem do dado sns.scatterplot(x='petal_length', y='petal_width', hue='species', style='origin', data=novo_df)  plt.show() In\u00a0[\u00a0]: Copied! <pre>### Implemente sua sua solu\u00e7\u00e3o.....\n</pre> ### Implemente sua sua solu\u00e7\u00e3o.....       In\u00a0[\u00a0]: Copied! <pre>#### Resposta loop for para diferntes k\nk_range = list(range(1,26))\nacertos = []\nfor k in k_range:\n    modelo = KNeighborsClassifier(n_neighbors=k)\n    modelo.fit(entradas_treino, classes_treino)\n    classes_encontradas = modelo.predict(entradas_teste)\n    acertos.append(accuracy_score(classes_teste, classes_encontradas))\n\n\nplt.plot(k_range, acertos)\nplt.xlabel('Valor de k do KNN')\nplt.ylabel('Taxa de acertos')\nplt.title('Taxa de acertos x valor de k do KNN')\nplt.show()\n</pre> #### Resposta loop for para diferntes k k_range = list(range(1,26)) acertos = [] for k in k_range:     modelo = KNeighborsClassifier(n_neighbors=k)     modelo.fit(entradas_treino, classes_treino)     classes_encontradas = modelo.predict(entradas_teste)     acertos.append(accuracy_score(classes_teste, classes_encontradas))   plt.plot(k_range, acertos) plt.xlabel('Valor de k do KNN') plt.ylabel('Taxa de acertos') plt.title('Taxa de acertos x valor de k do KNN') plt.show()  In\u00a0[\u00a0]: Copied! <pre>## implemente sua sua solu\u00e7\u00e3o....\n</pre> ## implemente sua sua solu\u00e7\u00e3o....     In\u00a0[\u00a0]: Copied! <pre># implemente sua solu\u00e7\u00e3o......\n</pre> # implemente sua solu\u00e7\u00e3o......    In\u00a0[\u00a0]: Copied! <pre>### uma solu\u00e7\u00e3o possivel usando o Arvore de decis\u00e3o.\n\nfrom sklearn.tree import DecisionTreeClassifier, plot_tree\n\n# Criando o modelo de \u00e1rvore de decis\u00e3o\ntree_classifier = DecisionTreeClassifier(max_depth=3)\ntree_classifier.fit(entradas_treino, classes_treino)\n\n# Avaliando o modelo\ny_pred = tree_classifier.predict(entradas_teste)\naccuracy = accuracy_score(classes_teste, y_pred)\nprint(\"Acur\u00e1cia do modelo:\", accuracy)\n\nfeature_names = ['sepal length (cm)', 'sepal width (cm)', 'petal length (cm)', 'petal width (cm)']\nclass_names = ['setosa', 'versicolor', 'virginica']\n# Visualizando a \u00e1rvore de decis\u00e3o\nplt.figure(figsize=(20,10))\nplot_tree(tree_classifier, filled=True, feature_names=feature_names, class_names=class_names)\nplt.title('Visualiza\u00e7\u00e3o da \u00c1rvore de Decis\u00e3o do Dataset Iris')\nplt.show()\n</pre>   ### uma solu\u00e7\u00e3o possivel usando o Arvore de decis\u00e3o.  from sklearn.tree import DecisionTreeClassifier, plot_tree  # Criando o modelo de \u00e1rvore de decis\u00e3o tree_classifier = DecisionTreeClassifier(max_depth=3) tree_classifier.fit(entradas_treino, classes_treino)  # Avaliando o modelo y_pred = tree_classifier.predict(entradas_teste) accuracy = accuracy_score(classes_teste, y_pred) print(\"Acur\u00e1cia do modelo:\", accuracy)  feature_names = ['sepal length (cm)', 'sepal width (cm)', 'petal length (cm)', 'petal width (cm)'] class_names = ['setosa', 'versicolor', 'virginica'] # Visualizando a \u00e1rvore de decis\u00e3o plt.figure(figsize=(20,10)) plot_tree(tree_classifier, filled=True, feature_names=feature_names, class_names=class_names) plt.title('Visualiza\u00e7\u00e3o da \u00c1rvore de Decis\u00e3o do Dataset Iris') plt.show()  <pre>Acur\u00e1cia do modelo: 0.9\n</pre>"},{"location":"aulas/IA/lab02/classificador_knn.html#objetivos","title":"Objetivos\u00b6","text":"<ul> <li>Apresentar e utilizar o classificador k-nearest neighbours (kNN)</li> <li>Apresentar a t\u00e9cnica de separa\u00e7\u00e3o de dados (treino e teste)</li> <li>Avaliar Aprendizagem do modelo</li> </ul>"},{"location":"aulas/IA/lab02/classificador_knn.html#comecando","title":"Come\u00e7ando\u00b6","text":"<p>Vamos dar continuidade ao nosso estudo de aprendizagem de m\u00e1quina, j\u00e1 vimos:</p> <ul> <li>Tudo come\u00e7a, conhecendo os dados dispon\u00edveis.</li> <li>Como carregar um data frame</li> <li>Como visualizar os dados em gr\u00e1ficos (histograma, box plot, violin plot, matriz de confus\u00e3o)</li> <li>Fizemos uma breve introdu\u00e7\u00e3o sobre an\u00e1lise explorat\u00f3ria buscando correlacionar os dados para gerar informa\u00e7\u00f5es.</li> </ul> <p>Hoje, vamos seguir nossa jornada e finalizar nosso estudo aplicando a t\u00e9cnica de KNN.</p>"},{"location":"aulas/IA/lab02/classificador_knn.html#k-nearest-neighbors","title":"k-Nearest Neighbors\u00b6","text":"<p>O KNN(K vizinhos mais pr\u00f3ximos) \u00e9 considerado um dos algoritmos mais simples dentro da categoria de aprendizagem supervisionada sendo muito utilizado para problemas de classifica\u00e7\u00e3o, por\u00e9m tamb\u00e9m pode ser utilizado em problemas de regress\u00e3o.</p> <p>Problemas de classifica\u00e7\u00e3o = Vale lembrar que em problemas de classifica\u00e7\u00e3o n\u00e3o estamos interessados em valores exatos, queremos apenas saber se um dado pertence ou n\u00e3o a uma dada classe.</p>"},{"location":"aulas/IA/lab02/classificador_knn.html#uma-intuicao-sobre-o-metodo","title":"Uma intui\u00e7\u00e3o sobre o m\u00e9todo\u00b6","text":"<p>Para realizar a classifica\u00e7\u00e3o o KNN calcula a dist\u00e2ncia objeto desconhecido (target) para todos os outros elementos, encontra os mais K vizinhos mais pr\u00f3ximos faz uma contagem dos r\u00f3tulos e considera que o objeto desconhecido pertence ao r\u00f3tulo de maior contagem.</p> <p>A imagem abaixo exemplifica o funcionamento, mas se ficou um pouco complicado de entender, rode o script python iknn.py e fa\u00e7a algumas simula\u00e7\u00f5es para compreender.</p> <p></p>"},{"location":"aulas/IA/lab02/classificador_knn.html#bora-la","title":"Bora l\u00e1!!\u00b6","text":"<p>Vamos juntos realizar nosso primeiro projeto, do come\u00e7o ao fim, de aprendizagem de m\u00e1quina.</p>"},{"location":"aulas/IA/lab02/classificador_knn.html#definicao-do-problema","title":"Defini\u00e7\u00e3o do problema\u00b6","text":"<p>A primeira coisa que precisamos fazer \u00e9 a defini\u00e7\u00e3o do problema. Neste primeiro caso vamos trabalhar com o mesmo dataset da \u00faltima aula, dataset iris. Vamos desenvolver um sistema de machine learning capaz de classificar sua esp\u00e9cie com base nos dimensionais da p\u00e9tala.</p>"},{"location":"aulas/IA/lab02/classificador_knn.html#desafio-1","title":"Desafio 1\u00b6","text":"<p>Do ponto de vista de machine learning, que problema \u00e9 esse:</p> <pre><code>Aprendizado supervisionado ou n\u00e3o-supervisionado?</code></pre> <p>R:</p> <pre><code>Classifica\u00e7\u00e3o ou regress\u00e3o?</code></pre> <p>R:</p>"},{"location":"aulas/IA/lab02/classificador_knn.html#desafio-2","title":"Desafio 2\u00b6","text":"<p>Aplique os m\u00e9todos que achar conveniente (vimos algumas op\u00e7\u00f5es na \u00faltima aula) para visualizar os dados de forma gr\u00e1fica.</p>"},{"location":"aulas/IA/lab02/classificador_knn.html#pare","title":"PARE!!!\u00b6","text":"<p>A an\u00e1lise feita no desafio 2 \u00e9 uma das etapas mais importantes. Caso voc\u00ea tenha pulado essa etapa, volte e fa\u00e7a suas an\u00e1lises.</p> <p>Com essa etapa conclu\u00edda, vamos criar um sub-dataset com os atributos que ser\u00e3o utilizados.</p>"},{"location":"aulas/IA/lab02/classificador_knn.html#dividindo-os-dados-em-conjunto-de-treinamento-e-de-testes","title":"Dividindo os dados em conjunto de treinamento e de testes\u00b6","text":"<p>Dividir nosso dataset em dois conjuntos de dados.</p> <pre><code>Treinamento - Representa 80% das amostras do conjunto de dados original,\nTeste - com 20% das amostras</code></pre> <p>Vamos escolher aleatoriamente algumas amostras do conjunto original. Isto pode ser feito com Scikit-Learn usando a fun\u00e7\u00e3o train_test_split()</p> <p>scikit-learn: pip3 install scikit-learn</p>"},{"location":"aulas/IA/lab02/classificador_knn.html#chegou-a-hora-de-aplicar-o-modelo-preditivo","title":"Chegou a hora de aplicar o modelo preditivo\u00b6","text":"<p>Treinar um modelo no python \u00e9 simples se usar o Scikit-Learn. Treinar um modelo no Scikit-Learn \u00e9 simples: basta criar o classificador, e chamar o m\u00e9todo fit().</p> <p>Uma observa\u00e7\u00e3o sobre a sintaxe dos classificadores do <code>scikit-learn</code></p> <ul> <li>O m\u00e9todo <code>fit(X,Y)</code> recebe uma matriz ou dataframe X onde cada linha \u00e9 uma amostra de aprendizado, e um array Y contendo as sa\u00eddas esperadas do classificador, seja na forma de texto ou de inteiros</li> <li>O m\u00e9todo <code>predict(X)</code> recebe uma matriz ou dataframe X onde cada linha \u00e9 uma amostra de teste, retornando um array de classes</li> </ul>"},{"location":"aulas/IA/lab02/classificador_knn.html#utilizando-o-modelo-treinado-com-amostras-fora-do-dataset","title":"Utilizando o modelo treinado com amostras fora do dataset\u00b6","text":"<p>Vamos colocar alguns valores e ver a predi\u00e7\u00e3o do classificador.</p>"},{"location":"aulas/IA/lab02/classificador_knn.html#visualizando-o-modelo-de-forma-grafica","title":"Visualizando o modelo de forma gr\u00e1fica\u00b6","text":""},{"location":"aulas/IA/lab02/classificador_knn.html#desafio-3","title":"Desafio 3\u00b6","text":"<p>Fizemos o treinamento para k=3, mude o valor de k e an\u00e1lise a acur\u00e1cia do modelo.</p> <p>Dica: Fa\u00e7a um loop for que varre um range de k, a sa\u00edda pode ser armazenada em uma lista. No final do loop exiba em um gr\u00e1fico.</p>"},{"location":"aulas/IA/lab02/classificador_knn.html#desafio-4","title":"Desafio 4\u00b6","text":"<p>Refa\u00e7a os notebook substituindo as entradas (variaveis independentes) e analise se o modelo obtido ficou melhor ou pior.</p>"},{"location":"aulas/IA/lab02/classificador_knn.html#desafio-5","title":"Desafio 5\u00b6","text":"<p>Fa\u00e7a o treinamento utilizando um algoritimo de ML difernte do KNN, ao final compare os resultados e an\u00e1lise qual modelo obteve uma performance melhor.</p>"},{"location":"aulas/IA/lab02/iknn.html","title":"Iknn","text":"In\u00a0[\u00a0]: Copied! <pre># adaptado de: https://pysource.com/2018/05/22/k-nearest-neighbour-classification-opencv-3-4-with-python-3-tutorial-33/\nimport cv2\nimport numpy as np\n</pre> # adaptado de: https://pysource.com/2018/05/22/k-nearest-neighbour-classification-opencv-3-4-with-python-3-tutorial-33/ import cv2 import numpy as np In\u00a0[\u00a0]: Copied! <pre>def mouse_pos(event, x, y, flags, params):\n\tglobal squares, color, new_element\n\n\tif event == cv2.EVENT_LBUTTONDOWN:\n\t\tif color == \"b\":\n\t\t\tblue_squares.append([x, y])\n\t\telif color == \"r\":\n\t\t\tred_squares.append([x, y])\n\t\telse:\n\t\t\tnew_element = [x, y]\n</pre> def mouse_pos(event, x, y, flags, params): \tglobal squares, color, new_element  \tif event == cv2.EVENT_LBUTTONDOWN: \t\tif color == \"b\": \t\t\tblue_squares.append([x, y]) \t\telif color == \"r\": \t\t\tred_squares.append([x, y]) \t\telse: \t\t\tnew_element = [x, y] In\u00a0[\u00a0]: Copied! <pre># Create Window and Set mouse events\ncv2.namedWindow(\"KNN\")\ncv2.setMouseCallback(\"KNN\", mouse_pos)\n</pre> # Create Window and Set mouse events cv2.namedWindow(\"KNN\") cv2.setMouseCallback(\"KNN\", mouse_pos) In\u00a0[\u00a0]: Copied! <pre># Create an empty image\nimg = np.zeros([500, 700, 3], dtype=np.uint8)\nimg[:] = (255, 255, 255)\n</pre> # Create an empty image img = np.zeros([500, 700, 3], dtype=np.uint8) img[:] = (255, 255, 255) In\u00a0[\u00a0]: Copied! <pre># Load KNN algorythm\nknn = cv2.ml.KNearest_create()\n</pre> # Load KNN algorythm knn = cv2.ml.KNearest_create() In\u00a0[\u00a0]: Copied! <pre># Store all the elements\nblue_squares = []\nred_squares = []\nnew_element = []\nnew_comer = False\ncolor = \"b\"\n</pre> # Store all the elements blue_squares = [] red_squares = [] new_element = [] new_comer = False color = \"b\" In\u00a0[\u00a0]: Copied! <pre># Text Data\nfont = cv2.FONT_HERSHEY_SIMPLEX\nresult = \"None\"\nk = 1\nneighbours = \"None\"\ndist = \"None\"\nwhile True:\n\timg[:] = (255, 255, 255)\n    \n\tcv2.line(img, (0, 330),(700, 330),(0, 0, 0),2)\n\n\tcv2.putText(img, \"CALCULO KNN\", (10, 360), font, 1, (0, 0, 0), 2)\n\tcv2.putText(img, \"Resultado: \" + str(result), (10, 400), font, 1, (0, 0, 0), 2)\n\tcv2.putText(img, \"K: \" + str(k), (10, 440), font, 1, (0, 0, 0), 2)\n\tcv2.putText(img, \"Neighbours: \" + str(neighbours), (10, 470), font, 0.5, (0, 0, 0), 1)\n\tcv2.putText(img, \"Distance: \" + str(dist), (10, 490), font, 0.5, (0, 0, 0), 1)\n\n\tcv2.putText(img, \"Manual:\", (440, 350), font, 0.5, (0, 0, 0), 1)\n\tcv2.putText(img, \"B: Ponto AZUL\", (440, 370), font, 0.5, (0, 0, 0), 1)\n\tcv2.putText(img, \"R: Ponto Vermelho\", (440, 390), font, 0.5, (0, 0, 0), 1)\n\tcv2.putText(img, \"G: Ponto Verde\", (440, 410), font, 0.5, (0, 0, 0), 1)\n\tcv2.putText(img, \"1, 3, 5, 7, 9: muda K\", (440, 430), font, 0.5, (0, 0, 0), 1)\n\tcv2.putText(img, \"C: Calcula\", (440, 450), font, 0.5, (0, 0, 0), 1)\n\tcv2.putText(img, \"D: Deleta, limpa\", (440, 470), font, 0.5, (0, 0, 0), 1)\n\n\t# Show the Squares\n\tfor s in blue_squares:\n\t\tcv2.rectangle(img, (s[0] - 5, s[1] - 5), (s[0] + 5, s[1] + 5), (255, 0, 0), -1)\n\tfor s in red_squares:\n\t\tcv2.rectangle(img, (s[0] - 5, s[1] - 5), (s[0] + 5, s[1] + 5), (0, 0, 255), -1)\n\tif new_element != []:\n\t\tcv2.rectangle(img, (new_element[0] - 5, new_element[1] - 5),\n\t\t(new_element[0] + 5, new_element[1] + 5), (0, 255, 0), -1)\n\n\t# Create element to show\n\n\tcv2.imshow(\"KNN\", img)\n\n\t# Key events to break the loop and to select the color of the squares\n\tkey = cv2.waitKey(25)\n\tif key == 27 or key == ord(\"q\") :\n\t\tbreak\n\telif key == ord(\"b\"):\n\t\tcolor = \"b\"\n\telif key == ord(\"r\"):\n\t\tcolor = \"r\"\n\telif key == ord(\"g\"):\n\t\tcolor = \"g\"\n\t\tnew_comer = True\n\telif key == ord(\"1\"):\n\t\tk = 1\n\telif key == ord(\"2\"):\n\t\tk = 2\n\telif key == ord(\"3\"):\n\t\tk = 3\n\telif key == ord(\"4\"):\n\t\tk = 4\n\telif key == ord(\"5\"):\n\t\tk = 5\n\telif key == ord(\"6\"):\n\t\tk = 6\n\telif key == ord(\"7\"):\n\t\tk = 7\n\telif key == ord(\"8\"):\n\t\tk = 8\n\telif key == ord(\"9\"):\n\t\tk = 9\n\telif key == ord(\"d\"):\n\t\tblue_squares = []\n\t\tred_squares = []\n\t\tnew_element = []\n\telif key == ord(\"c\"):\n\t\ttraindata = np.array(blue_squares + red_squares, dtype=np.float32)\n\t\tblue_responses = np.zeros(len(blue_squares), dtype=np.float32)\n\t\tred_resposnes = np.ones(len(red_squares), dtype=np.float32)\n\t\tresponses = np.concatenate((blue_responses, red_resposnes))\n\n\t\tknn.train(traindata, cv2.ml.ROW_SAMPLE, responses)\n\t\tif new_comer:\n\t\t\tgreen_square = np.array([new_element], dtype=np.float32)\n\n\t\t\tret, results, neighbours, dist = knn.findNearest(green_square, k)\n\n\t\t\tprint(results[0][0])\n\t\t\tprint (results)\n\n\t\t\tif results[0][0] &gt; 0:\n\t\t\t\tresult = \"Red\"\n\t\t\telse:\n\t\t\t\tresult = \"Blue\"\n</pre> # Text Data font = cv2.FONT_HERSHEY_SIMPLEX result = \"None\" k = 1 neighbours = \"None\" dist = \"None\" while True: \timg[:] = (255, 255, 255)      \tcv2.line(img, (0, 330),(700, 330),(0, 0, 0),2)  \tcv2.putText(img, \"CALCULO KNN\", (10, 360), font, 1, (0, 0, 0), 2) \tcv2.putText(img, \"Resultado: \" + str(result), (10, 400), font, 1, (0, 0, 0), 2) \tcv2.putText(img, \"K: \" + str(k), (10, 440), font, 1, (0, 0, 0), 2) \tcv2.putText(img, \"Neighbours: \" + str(neighbours), (10, 470), font, 0.5, (0, 0, 0), 1) \tcv2.putText(img, \"Distance: \" + str(dist), (10, 490), font, 0.5, (0, 0, 0), 1)  \tcv2.putText(img, \"Manual:\", (440, 350), font, 0.5, (0, 0, 0), 1) \tcv2.putText(img, \"B: Ponto AZUL\", (440, 370), font, 0.5, (0, 0, 0), 1) \tcv2.putText(img, \"R: Ponto Vermelho\", (440, 390), font, 0.5, (0, 0, 0), 1) \tcv2.putText(img, \"G: Ponto Verde\", (440, 410), font, 0.5, (0, 0, 0), 1) \tcv2.putText(img, \"1, 3, 5, 7, 9: muda K\", (440, 430), font, 0.5, (0, 0, 0), 1) \tcv2.putText(img, \"C: Calcula\", (440, 450), font, 0.5, (0, 0, 0), 1) \tcv2.putText(img, \"D: Deleta, limpa\", (440, 470), font, 0.5, (0, 0, 0), 1)  \t# Show the Squares \tfor s in blue_squares: \t\tcv2.rectangle(img, (s[0] - 5, s[1] - 5), (s[0] + 5, s[1] + 5), (255, 0, 0), -1) \tfor s in red_squares: \t\tcv2.rectangle(img, (s[0] - 5, s[1] - 5), (s[0] + 5, s[1] + 5), (0, 0, 255), -1) \tif new_element != []: \t\tcv2.rectangle(img, (new_element[0] - 5, new_element[1] - 5), \t\t(new_element[0] + 5, new_element[1] + 5), (0, 255, 0), -1)  \t# Create element to show  \tcv2.imshow(\"KNN\", img)  \t# Key events to break the loop and to select the color of the squares \tkey = cv2.waitKey(25) \tif key == 27 or key == ord(\"q\") : \t\tbreak \telif key == ord(\"b\"): \t\tcolor = \"b\" \telif key == ord(\"r\"): \t\tcolor = \"r\" \telif key == ord(\"g\"): \t\tcolor = \"g\" \t\tnew_comer = True \telif key == ord(\"1\"): \t\tk = 1 \telif key == ord(\"2\"): \t\tk = 2 \telif key == ord(\"3\"): \t\tk = 3 \telif key == ord(\"4\"): \t\tk = 4 \telif key == ord(\"5\"): \t\tk = 5 \telif key == ord(\"6\"): \t\tk = 6 \telif key == ord(\"7\"): \t\tk = 7 \telif key == ord(\"8\"): \t\tk = 8 \telif key == ord(\"9\"): \t\tk = 9 \telif key == ord(\"d\"): \t\tblue_squares = [] \t\tred_squares = [] \t\tnew_element = [] \telif key == ord(\"c\"): \t\ttraindata = np.array(blue_squares + red_squares, dtype=np.float32) \t\tblue_responses = np.zeros(len(blue_squares), dtype=np.float32) \t\tred_resposnes = np.ones(len(red_squares), dtype=np.float32) \t\tresponses = np.concatenate((blue_responses, red_resposnes))  \t\tknn.train(traindata, cv2.ml.ROW_SAMPLE, responses) \t\tif new_comer: \t\t\tgreen_square = np.array([new_element], dtype=np.float32)  \t\t\tret, results, neighbours, dist = knn.findNearest(green_square, k)  \t\t\tprint(results[0][0]) \t\t\tprint (results)  \t\t\tif results[0][0] &gt; 0: \t\t\t\tresult = \"Red\" \t\t\telse: \t\t\t\tresult = \"Blue\" In\u00a0[\u00a0]: Copied! <pre>cv2.destroyAllWindows()\n</pre> cv2.destroyAllWindows()"},{"location":"aulas/IA/lab02/ml-classificador.html","title":"Ml classificador","text":"In\u00a0[1]: Copied! <pre># Inicializ\u00e7\u00e3o das bibliotecas\n%matplotlib inline\n\nimport pandas as pd\nimport matplotlib.pyplot as plt\n</pre> # Inicializ\u00e7\u00e3o das bibliotecas %matplotlib inline  import pandas as pd import matplotlib.pyplot as plt  In\u00a0[2]: Copied! <pre># Caminho do arquivo\nurl = \"https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data\"\n# Define o nome das colunas\nheader = ['sepal_length', 'sepal_width', 'petal_length', 'petal_width', 'species']\n# L\u00ea e carrega o arquivo para a mem\u00f3ria\ndf = pd.read_csv(url, header=None, names=header)\n</pre> # Caminho do arquivo url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data\" # Define o nome das colunas header = ['sepal_length', 'sepal_width', 'petal_length', 'petal_width', 'species'] # L\u00ea e carrega o arquivo para a mem\u00f3ria df = pd.read_csv(url, header=None, names=header) In\u00a0[3]: Copied! <pre># Retorna um trecho com as 5 primeiras linhas do dataframe\ndf.head()\n</pre> # Retorna um trecho com as 5 primeiras linhas do dataframe df.head() Out[3]: sepal_length sepal_width petal_length petal_width species 0 5.1 3.5 1.4 0.2 Iris-setosa 1 4.9 3.0 1.4 0.2 Iris-setosa 2 4.7 3.2 1.3 0.2 Iris-setosa 3 4.6 3.1 1.5 0.2 Iris-setosa 4 5.0 3.6 1.4 0.2 Iris-setosa In\u00a0[4]: Copied! <pre>df.tail()\n</pre> df.tail() Out[4]: sepal_length sepal_width petal_length petal_width species 145 6.7 3.0 5.2 2.3 Iris-virginica 146 6.3 2.5 5.0 1.9 Iris-virginica 147 6.5 3.0 5.2 2.0 Iris-virginica 148 6.2 3.4 5.4 2.3 Iris-virginica 149 5.9 3.0 5.1 1.8 Iris-virginica In\u00a0[5]: Copied! <pre># Mostra informa\u00e7\u00f5es sobre o dataframe em si\ndf.info()\n</pre> # Mostra informa\u00e7\u00f5es sobre o dataframe em si df.info() <pre>&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 150 entries, 0 to 149\nData columns (total 5 columns):\n #   Column        Non-Null Count  Dtype  \n---  ------        --------------  -----  \n 0   sepal_length  150 non-null    float64\n 1   sepal_width   150 non-null    float64\n 2   petal_length  150 non-null    float64\n 3   petal_width   150 non-null    float64\n 4   species       150 non-null    object \ndtypes: float64(4), object(1)\nmemory usage: 6.0+ KB\n</pre> In\u00a0[6]: Copied! <pre># class distribution\nprint(df.groupby('species').size())\n</pre> # class distribution print(df.groupby('species').size()) <pre>species\nIris-setosa        50\nIris-versicolor    50\nIris-virginica     50\ndtype: int64\n</pre> In\u00a0[7]: Copied! <pre>## Sua resposta e seus gr\u00e1ficos para an\u00e1lisar..\n</pre> ## Sua resposta e seus gr\u00e1ficos para an\u00e1lisar..       In\u00a0[8]: Copied! <pre># Codificando os r\u00f3tulos de especies\n\nfrom sklearn.preprocessing import LabelEncoder\n\nle = LabelEncoder()\ndf['species'] = le.fit_transform(df['species'])\n</pre> # Codificando os r\u00f3tulos de especies  from sklearn.preprocessing import LabelEncoder  le = LabelEncoder() df['species'] = le.fit_transform(df['species']) In\u00a0[9]: Copied! <pre># Separamos 20% para o teste\nfrom sklearn.model_selection import train_test_split\n\n## define entradas de dados e o target\n\nX = df.iloc[:, :-1]\ny = df['species']\n\n# Separando os dados em conjunto de treinamento e teste\nX_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.2, random_state=42)\n\nprint(f\"Formato das tabelas de dados de treino {X_train.shape} e teste {y_train.shape}\")\n</pre> # Separamos 20% para o teste from sklearn.model_selection import train_test_split  ## define entradas de dados e o target  X = df.iloc[:, :-1] y = df['species']  # Separando os dados em conjunto de treinamento e teste X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.2, random_state=42)  print(f\"Formato das tabelas de dados de treino {X_train.shape} e teste {y_train.shape}\") <pre>Formato das tabelas de dados de treino (120, 4) e teste (120,)\n</pre> In\u00a0[10]: Copied! <pre>#Primeiras linhas do dataframe de treino \nX_train.head()\n</pre> #Primeiras linhas do dataframe de treino  X_train.head() Out[10]: sepal_length sepal_width petal_length petal_width 22 4.6 3.6 1.0 0.2 15 5.7 4.4 1.5 0.4 65 6.7 3.1 4.4 1.4 11 4.8 3.4 1.6 0.2 42 4.4 3.2 1.3 0.2 In\u00a0[11]: Copied! <pre>y_train.tail()\n</pre> y_train.tail() Out[11]: <pre>71     1\n106    2\n14     0\n92     1\n102    2\nName: species, dtype: int32</pre> In\u00a0[12]: Copied! <pre># Importa a biblioteca\nfrom sklearn.neighbors import KNeighborsClassifier\n\n# Cria o classificar KNN\nk = 3\nknn = KNeighborsClassifier(n_neighbors=k)\n\n# Cria o modelo de machine learning\nknn.fit(X_train, y_train)\n</pre> # Importa a biblioteca from sklearn.neighbors import KNeighborsClassifier  # Cria o classificar KNN k = 3 knn = KNeighborsClassifier(n_neighbors=k)  # Cria o modelo de machine learning knn.fit(X_train, y_train) Out[12]: <pre>KNeighborsClassifier(n_neighbors=3)</pre> <p>Pronto!! bora testar se esta funcionando....</p> In\u00a0[13]: Copied! <pre># Realizando previs\u00f5es\n\ny_pred = knn.predict(X_test)\n\n\n# Avaliando o modelo\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n\nprint(\"Acur\u00e1cia: \", accuracy_score(y_test, y_pred))\nprint(\"Precis\u00e3o: \", precision_score(y_test, y_pred, average='macro'))\nprint(\"Recall: \", recall_score(y_test, y_pred, average='macro'))\nprint(\"F1-score: \", f1_score(y_test, y_pred, average='macro'))\n\n## average='macro': m\u00e9trica \u00e9 calculada para cada classe individualmente e, em seguida, a m\u00e9dia n\u00e3o ponderada das m\u00e9tricas de cada classe \u00e9 retornada.\n##  Isso significa que todas as classes t\u00eam a mesma import\u00e2ncia no c\u00e1lculo da m\u00e9trica.\n</pre> # Realizando previs\u00f5es  y_pred = knn.predict(X_test)   # Avaliando o modelo from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score  print(\"Acur\u00e1cia: \", accuracy_score(y_test, y_pred)) print(\"Precis\u00e3o: \", precision_score(y_test, y_pred, average='macro')) print(\"Recall: \", recall_score(y_test, y_pred, average='macro')) print(\"F1-score: \", f1_score(y_test, y_pred, average='macro'))  ## average='macro': m\u00e9trica \u00e9 calculada para cada classe individualmente e, em seguida, a m\u00e9dia n\u00e3o ponderada das m\u00e9tricas de cada classe \u00e9 retornada. ##  Isso significa que todas as classes t\u00eam a mesma import\u00e2ncia no c\u00e1lculo da m\u00e9trica. <pre>Acur\u00e1cia:  1.0\nPrecis\u00e3o:  1.0\nRecall:  1.0\nF1-score:  1.0\n</pre> In\u00a0[14]: Copied! <pre>from sklearn.model_selection import GridSearchCV\n\n\n# Definindo os valores para os hiperpar\u00e2metros\nparam_grid = {'n_neighbors': [3, 5, 7, 9], 'weights': ['uniform', 'distance'], 'algorithm': ['ball_tree', 'kd_tree', 'brute'], 'p': [1, 2]}\n\n# Criando o objeto GridSearchCV\ngrid = GridSearchCV(KNeighborsClassifier(), param_grid, verbose=1, cv=5, n_jobs=-1)\n\n# Ajustando o modelo com os dados de treinamento\ngrid.fit(X_train, y_train)\n\n# Imprimindo os melhores hiperpar\u00e2metros encontrados\nprint(\"Melhores hiperpar\u00e2metros: \", grid.best_params_)\n\n# Realizando previs\u00f5es e avaliando o modelo com os melhores hiperpar\u00e2metros\ny_pred = grid.predict(X_test)\nprint(\"Acur\u00e1cia: \", accuracy_score(y_test, y_pred))\nprint(\"Precis\u00e3o: \", precision_score(y_test, y_pred, average='macro'))\nprint(\"Recall: \", recall_score(y_test, y_pred, average='macro'))\nprint(\"F1-score: \", f1_score(y_test, y_pred, average='macro'))\n</pre> from sklearn.model_selection import GridSearchCV   # Definindo os valores para os hiperpar\u00e2metros param_grid = {'n_neighbors': [3, 5, 7, 9], 'weights': ['uniform', 'distance'], 'algorithm': ['ball_tree', 'kd_tree', 'brute'], 'p': [1, 2]}  # Criando o objeto GridSearchCV grid = GridSearchCV(KNeighborsClassifier(), param_grid, verbose=1, cv=5, n_jobs=-1)  # Ajustando o modelo com os dados de treinamento grid.fit(X_train, y_train)  # Imprimindo os melhores hiperpar\u00e2metros encontrados print(\"Melhores hiperpar\u00e2metros: \", grid.best_params_)  # Realizando previs\u00f5es e avaliando o modelo com os melhores hiperpar\u00e2metros y_pred = grid.predict(X_test) print(\"Acur\u00e1cia: \", accuracy_score(y_test, y_pred)) print(\"Precis\u00e3o: \", precision_score(y_test, y_pred, average='macro')) print(\"Recall: \", recall_score(y_test, y_pred, average='macro')) print(\"F1-score: \", f1_score(y_test, y_pred, average='macro')) <pre>Fitting 5 folds for each of 48 candidates, totalling 240 fits\nMelhores hiperpar\u00e2metros:  {'algorithm': 'ball_tree', 'n_neighbors': 3, 'p': 1, 'weights': 'uniform'}\nAcur\u00e1cia:  1.0\nPrecis\u00e3o:  1.0\nRecall:  1.0\nF1-score:  1.0\n</pre> In\u00a0[15]: Copied! <pre>from sklearn.tree import DecisionTreeClassifier\n\n# Definindo o modelo de \u00e1rvore de decis\u00e3o com hiperpar\u00e2metros padr\u00e3o\ntree = DecisionTreeClassifier(criterion='gini', max_depth=None, min_samples_split=2, min_samples_leaf=1, random_state=42)\ntree.fit(X_train, y_train)\n\n# Realizando previs\u00f5es e avaliando o modelo\ny_pred = tree.predict(X_test)\nprint(\"Acur\u00e1cia: \", accuracy_score(y_test, y_pred))\nprint(\"Precis\u00e3o: \", precision_score(y_test, y_pred, average='macro'))\nprint(\"Recall: \", recall_score(y_test, y_pred, average='macro'))\nprint(\"F1-score: \", f1_score(y_test, y_pred, average='macro'))\n</pre> from sklearn.tree import DecisionTreeClassifier  # Definindo o modelo de \u00e1rvore de decis\u00e3o com hiperpar\u00e2metros padr\u00e3o tree = DecisionTreeClassifier(criterion='gini', max_depth=None, min_samples_split=2, min_samples_leaf=1, random_state=42) tree.fit(X_train, y_train)  # Realizando previs\u00f5es e avaliando o modelo y_pred = tree.predict(X_test) print(\"Acur\u00e1cia: \", accuracy_score(y_test, y_pred)) print(\"Precis\u00e3o: \", precision_score(y_test, y_pred, average='macro')) print(\"Recall: \", recall_score(y_test, y_pred, average='macro')) print(\"F1-score: \", f1_score(y_test, y_pred, average='macro')) <pre>Acur\u00e1cia:  1.0\nPrecis\u00e3o:  1.0\nRecall:  1.0\nF1-score:  1.0\n</pre> In\u00a0[16]: Copied! <pre># Definindo os valores para os hiperpar\u00e2metros\nparam_grid = {'criterion': ['gini', 'entropy'], 'max_depth': [None, 3, 5, 7], 'min_samples_split': [2, 5, 10], 'min_samples_leaf': [1, 2, 4]}\n\n# Criando o objeto GridSearchCV\ngrid = GridSearchCV(DecisionTreeClassifier(), param_grid, verbose=1, cv=5, n_jobs=-1)\n\n# Ajustando o modelo com os dados de treinamento\ngrid.fit(X_train, y_train)\n\n# Imprimindo os melhores hiperpar\u00e2metros encontrados\nprint(\"Melhores hiperpar\u00e2metros: \", grid.best_params_)\n\n# Realizando previs\u00f5es e avaliando o modelo com os melhores hiperpar\u00e2metros\ny_pred = grid.predict(X_test)\nprint(\"Acur\u00e1cia: \", accuracy_score(y_test, y_pred))\nprint(\"Precis\u00e3o: \", precision_score(y_test, y_pred, average='macro'))\nprint(\"Recall: \", recall_score(y_test, y_pred, average='macro'))\nprint(\"F1-score: \", f1_score(y_test, y_pred, average='macro'))\n</pre> # Definindo os valores para os hiperpar\u00e2metros param_grid = {'criterion': ['gini', 'entropy'], 'max_depth': [None, 3, 5, 7], 'min_samples_split': [2, 5, 10], 'min_samples_leaf': [1, 2, 4]}  # Criando o objeto GridSearchCV grid = GridSearchCV(DecisionTreeClassifier(), param_grid, verbose=1, cv=5, n_jobs=-1)  # Ajustando o modelo com os dados de treinamento grid.fit(X_train, y_train)  # Imprimindo os melhores hiperpar\u00e2metros encontrados print(\"Melhores hiperpar\u00e2metros: \", grid.best_params_)  # Realizando previs\u00f5es e avaliando o modelo com os melhores hiperpar\u00e2metros y_pred = grid.predict(X_test) print(\"Acur\u00e1cia: \", accuracy_score(y_test, y_pred)) print(\"Precis\u00e3o: \", precision_score(y_test, y_pred, average='macro')) print(\"Recall: \", recall_score(y_test, y_pred, average='macro')) print(\"F1-score: \", f1_score(y_test, y_pred, average='macro')) <pre>Fitting 5 folds for each of 72 candidates, totalling 360 fits\nMelhores hiperpar\u00e2metros:  {'criterion': 'entropy', 'max_depth': None, 'min_samples_leaf': 4, 'min_samples_split': 2}\nAcur\u00e1cia:  1.0\nPrecis\u00e3o:  1.0\nRecall:  1.0\nF1-score:  1.0\n</pre> In\u00a0[17]: Copied! <pre># Criando os modelos ( altere os parametros para os melhores hiperpar\u00e2metros encontrados)\nknn = KNeighborsClassifier(n_neighbors=5, weights='uniform', algorithm='ball_tree', p=2) \ntree = DecisionTreeClassifier(criterion='entropy', max_depth=None, min_samples_split=2, min_samples_leaf=1)\n\n# Ajustando os modelos com os dados de treinamento\nknn.fit(X_train, y_train)\ntree.fit(X_train, y_train)\n\n# Realizando previs\u00f5es e avaliando os modelos com os dados de teste\nknn_pred = knn.predict(X_test)\ntree_pred = tree.predict(X_test)\n\nprint(\"KNN - Acur\u00e1cia: \", accuracy_score(y_test, knn_pred))\nprint(\"KNN - Precis\u00e3o: \", precision_score(y_test, knn_pred, average='macro'))\nprint(\"KNN - Recall: \", recall_score(y_test, knn_pred, average='macro'))\nprint(\"KNN - F1-score: \", f1_score(y_test, knn_pred, average='macro'))\n\nprint(\"\u00c1rvore de Decis\u00e3o - Acur\u00e1cia: \", accuracy_score(y_test, tree_pred))\nprint(\"\u00c1rvore de Decis\u00e3o - Precis\u00e3o: \", precision_score(y_test, tree_pred, average='macro'))\nprint(\"\u00c1rvore de Decis\u00e3o - Recall: \", recall_score(y_test, tree_pred, average='macro'))\nprint(\"\u00c1rvore de Decis\u00e3o - F1-score: \", f1_score(y_test, tree_pred, average='macro'))\n</pre> # Criando os modelos ( altere os parametros para os melhores hiperpar\u00e2metros encontrados) knn = KNeighborsClassifier(n_neighbors=5, weights='uniform', algorithm='ball_tree', p=2)  tree = DecisionTreeClassifier(criterion='entropy', max_depth=None, min_samples_split=2, min_samples_leaf=1)  # Ajustando os modelos com os dados de treinamento knn.fit(X_train, y_train) tree.fit(X_train, y_train)  # Realizando previs\u00f5es e avaliando os modelos com os dados de teste knn_pred = knn.predict(X_test) tree_pred = tree.predict(X_test)  print(\"KNN - Acur\u00e1cia: \", accuracy_score(y_test, knn_pred)) print(\"KNN - Precis\u00e3o: \", precision_score(y_test, knn_pred, average='macro')) print(\"KNN - Recall: \", recall_score(y_test, knn_pred, average='macro')) print(\"KNN - F1-score: \", f1_score(y_test, knn_pred, average='macro'))  print(\"\u00c1rvore de Decis\u00e3o - Acur\u00e1cia: \", accuracy_score(y_test, tree_pred)) print(\"\u00c1rvore de Decis\u00e3o - Precis\u00e3o: \", precision_score(y_test, tree_pred, average='macro')) print(\"\u00c1rvore de Decis\u00e3o - Recall: \", recall_score(y_test, tree_pred, average='macro')) print(\"\u00c1rvore de Decis\u00e3o - F1-score: \", f1_score(y_test, tree_pred, average='macro')) <pre>KNN - Acur\u00e1cia:  1.0\nKNN - Precis\u00e3o:  1.0\nKNN - Recall:  1.0\nKNN - F1-score:  1.0\n\u00c1rvore de Decis\u00e3o - Acur\u00e1cia:  1.0\n\u00c1rvore de Decis\u00e3o - Precis\u00e3o:  1.0\n\u00c1rvore de Decis\u00e3o - Recall:  1.0\n\u00c1rvore de Decis\u00e3o - F1-score:  1.0\n</pre> In\u00a0[18]: Copied! <pre>from sklearn.datasets import load_digits\n\ndigits = load_digits()\nX, y = digits.data, digits.target\n</pre> from sklearn.datasets import load_digits  digits = load_digits() X, y = digits.data, digits.target  In\u00a0[19]: Copied! <pre># Separando os dados em conjunto de treinamento e teste\nX_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.2)\n\nprint(f\"Formato das tabelas de dados de treino {X_train.shape} e teste {y_train.shape}\")\n</pre> # Separando os dados em conjunto de treinamento e teste X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.2)  print(f\"Formato das tabelas de dados de treino {X_train.shape} e teste {y_train.shape}\") <pre>Formato das tabelas de dados de treino (1437, 64) e teste (1437,)\n</pre> In\u00a0[20]: Copied! <pre># Criando os modelos ( altere os parametros para os melhores hiperpar\u00e2metros encontrados)\nknn = KNeighborsClassifier(n_neighbors=3, weights='uniform', algorithm='ball_tree', p=2) \ntree = DecisionTreeClassifier(criterion='entropy', max_depth=None, min_samples_split=2, min_samples_leaf=1)\n\n# Ajustando os modelos com os dados de treinamento\nknn.fit(X_train, y_train)\ntree.fit(X_train, y_train)\n\n# Realizando previs\u00f5es e avaliando os modelos com os dados de teste\nknn_pred = knn.predict(X_test)\ntree_pred = tree.predict(X_test)\n\nprint(\"KNN - Acur\u00e1cia: \", accuracy_score(y_test, knn_pred))\nprint(\"KNN - Precis\u00e3o: \", precision_score(y_test, knn_pred, average='macro'))\nprint(\"KNN - Recall: \", recall_score(y_test, knn_pred, average='macro'))\nprint(\"KNN - F1-score: \", f1_score(y_test, knn_pred, average='macro'))\n\nprint(\"\u00c1rvore de Decis\u00e3o - Acur\u00e1cia: \", accuracy_score(y_test, tree_pred))\nprint(\"\u00c1rvore de Decis\u00e3o - Precis\u00e3o: \", precision_score(y_test, tree_pred, average='macro'))\nprint(\"\u00c1rvore de Decis\u00e3o - Recall: \", recall_score(y_test, tree_pred, average='macro'))\nprint(\"\u00c1rvore de Decis\u00e3o - F1-score: \", f1_score(y_test, tree_pred, average='macro'))\n</pre> # Criando os modelos ( altere os parametros para os melhores hiperpar\u00e2metros encontrados) knn = KNeighborsClassifier(n_neighbors=3, weights='uniform', algorithm='ball_tree', p=2)  tree = DecisionTreeClassifier(criterion='entropy', max_depth=None, min_samples_split=2, min_samples_leaf=1)  # Ajustando os modelos com os dados de treinamento knn.fit(X_train, y_train) tree.fit(X_train, y_train)  # Realizando previs\u00f5es e avaliando os modelos com os dados de teste knn_pred = knn.predict(X_test) tree_pred = tree.predict(X_test)  print(\"KNN - Acur\u00e1cia: \", accuracy_score(y_test, knn_pred)) print(\"KNN - Precis\u00e3o: \", precision_score(y_test, knn_pred, average='macro')) print(\"KNN - Recall: \", recall_score(y_test, knn_pred, average='macro')) print(\"KNN - F1-score: \", f1_score(y_test, knn_pred, average='macro'))  print(\"\u00c1rvore de Decis\u00e3o - Acur\u00e1cia: \", accuracy_score(y_test, tree_pred)) print(\"\u00c1rvore de Decis\u00e3o - Precis\u00e3o: \", precision_score(y_test, tree_pred, average='macro')) print(\"\u00c1rvore de Decis\u00e3o - Recall: \", recall_score(y_test, tree_pred, average='macro')) print(\"\u00c1rvore de Decis\u00e3o - F1-score: \", f1_score(y_test, tree_pred, average='macro'))    <pre>KNN - Acur\u00e1cia:  0.9916666666666667\nKNN - Precis\u00e3o:  0.9916107948555768\nKNN - Recall:  0.9924263674614305\nKNN - F1-score:  0.9918829564341367\n\u00c1rvore de Decis\u00e3o - Acur\u00e1cia:  0.8638888888888889\n\u00c1rvore de Decis\u00e3o - Precis\u00e3o:  0.8696557411216153\n\u00c1rvore de Decis\u00e3o - Recall:  0.8609678867182373\n\u00c1rvore de Decis\u00e3o - F1-score:  0.8636191869030079\n</pre> In\u00a0[21]: Copied! <pre>from sklearn.metrics import classification_report\n\nprint(classification_report(y_test, knn_pred))\nprint(classification_report(y_test, tree_pred))\n</pre> from sklearn.metrics import classification_report  print(classification_report(y_test, knn_pred)) print(classification_report(y_test, tree_pred)) <pre>              precision    recall  f1-score   support\n\n           0       1.00      1.00      1.00        40\n           1       0.98      1.00      0.99        44\n           2       1.00      1.00      1.00        35\n           3       1.00      0.96      0.98        46\n           4       1.00      1.00      1.00        26\n           5       1.00      1.00      1.00        36\n           6       1.00      1.00      1.00        39\n           7       0.97      1.00      0.98        30\n           8       1.00      0.97      0.98        31\n           9       0.97      1.00      0.99        33\n\n    accuracy                           0.99       360\n   macro avg       0.99      0.99      0.99       360\nweighted avg       0.99      0.99      0.99       360\n\n              precision    recall  f1-score   support\n\n           0       0.97      0.90      0.94        40\n           1       0.87      0.89      0.88        44\n           2       0.97      0.83      0.89        35\n           3       0.82      0.87      0.84        46\n           4       0.92      0.88      0.90        26\n           5       0.80      0.92      0.86        36\n           6       0.92      0.87      0.89        39\n           7       0.93      0.83      0.88        30\n           8       0.65      0.71      0.68        31\n           9       0.86      0.91      0.88        33\n\n    accuracy                           0.86       360\n   macro avg       0.87      0.86      0.86       360\nweighted avg       0.87      0.86      0.87       360\n\n</pre> In\u00a0[23]: Copied! <pre>from skimage import exposure\nimport imutils\nimport numpy as np\nimport cv2\nfrom matplotlib import pyplot as plt\n\n\nmodel = knn\n\n# loop over a few random digits\nfor i in list(map(int, np.random.randint(0, high=len(y_test), size=(5,)))):\n\t# grab the image and classify it\n\timage = X_test[i]\n\tprediction = model.predict(image.reshape(1, -1))[0]\n\n\t# convert the image for a 64-dim array to an 8 x 8 image compatible with OpenCV,\n\t# then resize it to 32 x 32 pixels so we can see it better\n\timage = image.reshape((8, 8)).astype(\"uint8\")\n\timage = exposure.rescale_intensity(image, out_range=(0, 255))\n\timage = imutils.resize(image, width=32, inter=cv2.INTER_CUBIC)\n\n\t# show the prediction\n\tprint(\"I think that digit is: {}\".format(prediction))\n\tplt.imshow(image, cmap=\"gray\")\n\tplt.show()\n\t#cv2.imshow(\"Image\", image)\n\t#cv2.waitKey(0)\n</pre> from skimage import exposure import imutils import numpy as np import cv2 from matplotlib import pyplot as plt   model = knn  # loop over a few random digits for i in list(map(int, np.random.randint(0, high=len(y_test), size=(5,)))): \t# grab the image and classify it \timage = X_test[i] \tprediction = model.predict(image.reshape(1, -1))[0]  \t# convert the image for a 64-dim array to an 8 x 8 image compatible with OpenCV, \t# then resize it to 32 x 32 pixels so we can see it better \timage = image.reshape((8, 8)).astype(\"uint8\") \timage = exposure.rescale_intensity(image, out_range=(0, 255)) \timage = imutils.resize(image, width=32, inter=cv2.INTER_CUBIC)  \t# show the prediction \tprint(\"I think that digit is: {}\".format(prediction)) \tplt.imshow(image, cmap=\"gray\") \tplt.show() \t#cv2.imshow(\"Image\", image) \t#cv2.waitKey(0) <pre>I think that digit is: 3\n</pre> <pre>I think that digit is: 9\n</pre> <pre>I think that digit is: 1\n</pre> <pre>I think that digit is: 6\n</pre> <pre>I think that digit is: 7\n</pre> <p>Tente ajustar os hiperpar\u00e2metros dos modelos de KNN e \u00e1rvore de decis\u00e3o para melhorar ainda mais a performance dos modelos.</p> <p>Tente aplicar os modelos em outros conjuntos de dados de classifica\u00e7\u00e3o para ver como eles se saem.</p> <p>Pesquise sobre outros modelos de classifica\u00e7\u00e3o e compare-os com o KNN e \u00e1rvore de decis\u00e3o. Qual modelo \u00e9 o mais adequado para diferentes tipos de problemas de classifica\u00e7\u00e3o?</p>"},{"location":"aulas/IA/lab02/ml-classificador.html#objetivos","title":"Objetivos\u00b6","text":"<ul> <li>Compara\u00e7\u00e3o entre dois algoritmos de classifica\u00e7\u00e3o populares, K-Nearest Neighbors (KNN) e \u00c1rvore de Decis\u00e3o;</li> <li>Como aplicar o Grid Search para encontrar os melhores par\u00e2metros para esses modelos.</li> </ul>"},{"location":"aulas/IA/lab02/ml-classificador.html#problemas-de-classicacao","title":"Problemas de classica\u00e7\u00e3o\u00b6","text":"<p>A classifica\u00e7\u00e3o \u00e9 uma das principais tarefas em aprendizado de m\u00e1quina e envolve a atribui\u00e7\u00e3o de um r\u00f3tulo ou categoria a um conjunto de dados. Por exemplo, podemos usar a classifica\u00e7\u00e3o para identificar se um e-mail \u00e9 spam ou n\u00e3o, se uma transa\u00e7\u00e3o financeira \u00e9 fraudulenta ou leg\u00edtima, ou para prever se um paciente desenvolver\u00e1 uma doen\u00e7a com base em seus dados m\u00e9dicos.</p> <p>Existem muitos desafios em problemas de classica\u00e7\u00e3o que o an\u00e1lista de dados deve levar em considera\u00e7\u00e3o, como a escolha do modelo de aprendizado de m\u00e1quina adequado, o ajuste dos hiperpar\u00e2metros do modelo, a sele\u00e7\u00e3o de features relevantes, o tratamento de dados adequado ao problema, o cuidado com overfitting e a avalia\u00e7\u00e3o correta do modelo.</p> <p>Al\u00e9m disso, diferentes modelos de classifica\u00e7\u00e3o t\u00eam seus pr\u00f3prios pontos fortes e fracos, e escolher o modelo certo para um problema espec\u00edfico pode ser dif\u00edcil.</p>"},{"location":"aulas/IA/lab02/ml-classificador.html#resumo-sobre-knn-e-arvore-de-decisao","title":"Resumo sobre KNN e \u00c1rvore de Decis\u00e3o\u00b6","text":"Algoritmo Aplica\u00e7\u00e3o Vantagens Desvantagens Contexto de uso \u00c1rvores de Decis\u00e3o Classifica\u00e7\u00e3o/Regress\u00e3o F\u00e1cil interpretabilidade, lida bem com dados faltantes, captura rela\u00e7\u00f5es n\u00e3o lineares Tend\u00eancia ao overfitting, pode ser sens\u00edvel a ru\u00eddo Problemas de classifica\u00e7\u00e3o/regress\u00e3o com rela\u00e7\u00f5es n\u00e3o lineares K-Nearest Neighbors (KNN) Classifica\u00e7\u00e3o/Regress\u00e3o F\u00e1cil de entender e implementar, lida bem com dados com muitas vari\u00e1veis de entrada Requer muita mem\u00f3ria para grandes conjuntos de dados, sens\u00edvel a outliers Problemas de classifica\u00e7\u00e3o/regress\u00e3o com muitas vari\u00e1veis de entrada e poucas classes poss\u00edveis <p>O KNN (K-Nearest Neighbors) \u00e9 um algoritmo de classifica\u00e7\u00e3o simples e popular que usa a dist\u00e2ncia entre pontos para classificar novos dados. O algoritmo funciona encontrando os \"k\" pontos mais pr\u00f3ximos a uma nova inst\u00e2ncia de dados e, em seguida, atribuindo a essa inst\u00e2ncia a classe mais comum entre seus k vizinhos mais pr\u00f3ximos. O valor de k \u00e9 um hiperpar\u00e2metro que pode ser ajustado para melhorar a precis\u00e3o do modelo.</p> <p>J\u00e1 a \u00c1rvore de Decis\u00e3o \u00e9 um algoritmo de classifica\u00e7\u00e3o/regress\u00e3o que usa uma estrutura em forma de \u00e1rvore para representar poss\u00edveis decis\u00f5es e seus resultados. A \u00e1rvore \u00e9 constru\u00edda recursivamente, come\u00e7ando com um n\u00f3 raiz que cont\u00e9m todo o conjunto de dados. Em seguida, o algoritmo seleciona a melhor vari\u00e1vel para dividir o conjunto de dados em dois, com base em algum crit\u00e9rio de impureza, como a entropia ou o \u00edndice Gini. Esse processo \u00e9 repetido para cada subconjunto de dados resultante, criando um ramo de decis\u00e3o na \u00e1rvore. Quando a \u00e1rvore \u00e9 constru\u00edda, novos dados podem ser classificados percorrendo a \u00e1rvore de decis\u00e3o a partir da raiz at\u00e9 chegar a uma folha, onde a classe \u00e9 atribu\u00edda.</p>"},{"location":"aulas/IA/lab02/ml-classificador.html#definicao-do-problema","title":"Defini\u00e7\u00e3o do problema\u00b6","text":"<p>A primeira coisa que precisamos fazer \u00e9 a defini\u00e7\u00e3o do problema. Neste primeiro caso vamos trabalhar com o mesmo dataset da \u00faltima aula, dataset iris. Vamos desenvolver um sistema de machine learning capaz de classificar a especie de flor Iris com base nos dimensionais da p\u00e9tala e sepala.</p>"},{"location":"aulas/IA/lab02/ml-classificador.html#relembrando-o-dataset-iris","title":"Relembrando o dataset Iris\u00b6","text":"<p>Iris \u00e9 um dataset de flor com 150 linhas, divididos em tr\u00eas esp\u00e9cies diferentes: setosa, versicolor e virginica, sendo 50 amostras de cada esp\u00e9cie. Os atributos de largura e comprimento de s\u00e9pala e largura e comprimento de p\u00e9tala de cada flor foram anotados manualmente.</p>"},{"location":"aulas/IA/lab02/ml-classificador.html#desafio-1","title":"Desafio 1\u00b6","text":"<p>Aplique os m\u00e9todos que achar conveniente (vimos algumas op\u00e7\u00f5es na \u00faltima aula) para visualizar os dados de forma gr\u00e1fica.</p>"},{"location":"aulas/IA/lab02/ml-classificador.html#pare","title":"PARE!!!\u00b6","text":"<p>A an\u00e1lise feita no desafio 1 \u00e9 uma das etapas mais importantes. Caso voc\u00ea tenha pulado essa etapa, volte e fa\u00e7a suas an\u00e1lises.</p>"},{"location":"aulas/IA/lab02/ml-classificador.html#codificando-os-dados","title":"Codificando os dados\u00b6","text":"<p>Com essa etapa conclu\u00edda, vamos codificar os r\u00f3tulos de especie para que possam ser usados pelos modelos que vamos treinar.</p>"},{"location":"aulas/IA/lab02/ml-classificador.html#dividindo-os-dados-em-conjunto-de-treinamento-e-de-testes","title":"Dividindo os dados em conjunto de treinamento e de testes\u00b6","text":"<p>Dividir nosso dataset em dois conjuntos de dados.</p> <pre><code>Treinamento - Representa 80% das amostras do conjunto de dados original,\nTeste - com 20% das amostras</code></pre> <p>Vamos escolher aleatoriamente algumas amostras do conjunto original. Isto pode ser feito com Scikit-Learn usando a fun\u00e7\u00e3o train_test_split()</p>"},{"location":"aulas/IA/lab02/ml-classificador.html#chegou-a-hora-de-treinar-os-modelos","title":"Chegou a hora de treinar os modelos\u00b6","text":"<p>Treinar um modelo no python \u00e9 simples se usar o Scikit-Learn. Treinar um modelo no Scikit-Learn \u00e9 simples: basta criar o classificador, e chamar o m\u00e9todo fit().</p> <p>Uma observa\u00e7\u00e3o sobre a sintaxe dos classificadores do <code>scikit-learn</code></p> <ul> <li>O m\u00e9todo <code>fit(X,Y)</code> recebe uma matriz ou dataframe X onde cada linha \u00e9 uma amostra de aprendizado, e um array Y contendo as sa\u00eddas esperadas do classificador, seja na forma de texto ou de inteiros</li> <li>O m\u00e9todo <code>predict(X)</code> recebe uma matriz ou dataframe X onde cada linha \u00e9 uma amostra de teste, retornando um array de classes</li> </ul>"},{"location":"aulas/IA/lab02/ml-classificador.html#treinamento-usando-algoritmo-knn","title":"Treinamento usando algoritmo KNN\u00b6","text":""},{"location":"aulas/IA/lab02/ml-classificador.html#ajustando-os-hiperparametros-do-modelo-knn","title":"Ajustando os hiperpar\u00e2metros do modelo KNN\u00b6","text":"<p>Ao ajustar esses hiperpar\u00e2metros usando o Grid Search, podemos encontrar a combina\u00e7\u00e3o ideal de hiperpar\u00e2metros que leva \u00e0 melhor performance do modelo em um conjunto de dados espec\u00edfico.</p> <p>Existem v\u00e1rios hiperpar\u00e2metros do modelo K-Nearest Neighbors (KNN) que podem ser ajustados usando o Grid Search. Alguns dos hiperpar\u00e2metros mais comuns s\u00e3o:</p> <ul> <li><p><code>n_neighbors</code>: o n\u00famero de vizinhos mais pr\u00f3ximos a serem considerados no modelo.</p> </li> <li><p><code>weights</code>: como ponderar a contribui\u00e7\u00e3o dos vizinhos mais pr\u00f3ximos. Op\u00e7\u00f5es comuns s\u00e3o <code>uniform</code>, onde todos os vizinhos t\u00eam peso igual, e <code>distance</code>, onde o peso \u00e9 inversamente proporcional \u00e0 dist\u00e2ncia do ponto de consulta aos vizinhos.</p> </li> <li><p><code>p</code>: a m\u00e9trica de dist\u00e2ncia a ser usada. O valor padr\u00e3o \u00e9 <code>p=2</code>, que corresponde \u00e0 dist\u00e2ncia Euclidiana. Outras op\u00e7\u00f5es incluem <code>p=1</code>, que corresponde \u00e0 dist\u00e2ncia de Manhattan, e <code>p=inf</code>, que corresponde \u00e0 dist\u00e2ncia m\u00e1xima.</p> </li> <li><p><code>algorithm</code>: o algoritmo usado para calcular os vizinhos mais pr\u00f3ximos. As op\u00e7\u00f5es comuns s\u00e3o <code>brute</code>, que for\u00e7a uma busca exaustiva sobre todos os pontos de treinamento, e <code>kd_tree</code> e <code>ball_tree</code>, que usam estruturas de dados mais eficientes para acelerar a busca.</p> </li> <li><p><code>leaf_size</code>: o tamanho da folha para a \u00e1rvore de busca, que afeta a efici\u00eancia do algoritmo.</p> </li> </ul>"},{"location":"aulas/IA/lab02/ml-classificador.html#treinamento-usando-algoritmo-arvore-de-decisao","title":"Treinamento usando algoritmo \u00c1rvore de Decis\u00e3o\u00b6","text":""},{"location":"aulas/IA/lab02/ml-classificador.html#ajustando-os-hiperparametros-do-modelo-de-arvore-de-decisao","title":"Ajustando os hiperpar\u00e2metros do modelo de \u00e1rvore de decis\u00e3o\u00b6","text":"<p>Existem v\u00e1rios hiperpar\u00e2metros da \u00c1rvore de Decis\u00e3o que podem ser ajustados usando o Grid Search. Alguns dos hiperpar\u00e2metros mais comuns s\u00e3o:</p> <ul> <li><p><code>criterion</code>: a fun\u00e7\u00e3o usada para medir a qualidade da divis\u00e3o em cada n\u00f3 da \u00e1rvore. As op\u00e7\u00f5es comuns s\u00e3o <code>gini</code> e <code>entropy</code>.</p> </li> <li><p><code>splitter</code>: a estrat\u00e9gia usada para escolher a vari\u00e1vel que divide o conjunto de dados em cada n\u00f3. As op\u00e7\u00f5es comuns s\u00e3o <code>best</code>, que escolhe a melhor divis\u00e3o poss\u00edvel, e <code>random</code>, que escolhe uma divis\u00e3o aleat\u00f3ria.</p> </li> <li><p><code>max_depth</code>: a profundidade m\u00e1xima da \u00e1rvore. Se definido como <code>None</code>, os n\u00f3s ser\u00e3o expandidos at\u00e9 que todas as folhas contenham menos de min_samples_split amostras ou todas as amostras sejam classificadas.</p> </li> <li><p><code>min_samples_split</code>: o n\u00famero m\u00ednimo de amostras necess\u00e1rias para dividir um n\u00f3 interno.</p> </li> <li><p><code>min_samples_leaf</code>: o n\u00famero m\u00ednimo de amostras necess\u00e1rias para ser uma folha.</p> </li> <li><p><code>max_features</code>: o n\u00famero m\u00e1ximo de recursos que podem ser considerados em cada divis\u00e3o.</p> </li> <li><p><code>max_leaf_nodes</code>: o n\u00famero m\u00e1ximo de folhas permitidas na \u00e1rvore.</p> </li> </ul>"},{"location":"aulas/IA/lab02/ml-classificador.html#comparando-os-melhores-modelos-treinados-de-cada-algoritmo","title":"Comparando os melhores modelos treinados de cada algoritmo\u00b6","text":"<p>Por fim, podemos comparar a performance dos modelos de KNN e \u00e1rvore de decis\u00e3o.</p>"},{"location":"aulas/IA/lab02/ml-classificador.html#novo-exemplo-com-o-dataset-load_digits","title":"Novo exemplo com o dataset load_Digits\u00b6","text":"<p>Carrega um dataset de imagens de digits 8x8px.</p>"},{"location":"aulas/IA/lab03/preco-notebook.html","title":"lab2","text":"In\u00a0[62]: Copied! <pre># Inicializ\u00e7\u00e3o das bibliotecas\n%matplotlib inline\n\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n</pre> # Inicializ\u00e7\u00e3o das bibliotecas %matplotlib inline  import pandas as pd import matplotlib.pyplot as plt import seaborn as sns  In\u00a0[63]: Copied! <pre>df = pd.read_csv('laptop_data.csv')\n</pre> df = pd.read_csv('laptop_data.csv') In\u00a0[65]: Copied! <pre># Verifique se o dataset foi carregado corretamente, \n# imprimindo o nome das colunas do dataset e as primeiras linhas do dataset \n# use o comando head() para visualizar as primeiras linhas do dataset\n\ndf.head()\n</pre> # Verifique se o dataset foi carregado corretamente,  # imprimindo o nome das colunas do dataset e as primeiras linhas do dataset  # use o comando head() para visualizar as primeiras linhas do dataset  df.head()      Out[65]: Unnamed: 0 Company TypeName Inches ScreenResolution Cpu Ram Memory Gpu OpSys Weight Price 0 0 Apple Ultrabook 13.3 IPS Panel Retina Display 2560x1600 Intel Core i5 2.3GHz 8GB 128GB SSD Intel Iris Plus Graphics 640 macOS 1.37kg 71378.6832 1 1 Apple Ultrabook 13.3 1440x900 Intel Core i5 1.8GHz 8GB 128GB Flash Storage Intel HD Graphics 6000 macOS 1.34kg 47895.5232 2 2 HP Notebook 15.6 Full HD 1920x1080 Intel Core i5 7200U 2.5GHz 8GB 256GB SSD Intel HD Graphics 620 No OS 1.86kg 30636.0000 3 3 Apple Ultrabook 15.4 IPS Panel Retina Display 2880x1800 Intel Core i7 2.7GHz 16GB 512GB SSD AMD Radeon Pro 455 macOS 1.83kg 135195.3360 4 4 Apple Ultrabook 13.3 IPS Panel Retina Display 2560x1600 Intel Core i5 3.1GHz 8GB 256GB SSD Intel Iris Plus Graphics 650 macOS 1.37kg 96095.8080 In\u00a0[66]: Copied! <pre># verificando se existem valores duplicados \n\ndf.duplicated().sum()\n\n# dropando as linhas duplicadas\n\ndf.drop_duplicates(inplace=True)\n</pre> # verificando se existem valores duplicados   df.duplicated().sum()  # dropando as linhas duplicadas  df.drop_duplicates(inplace=True) In\u00a0[67]: Copied! <pre># drop a coluna Unnamed: 0 do dataset e imprima novamente as primeiras linhas do dataset\n\ndf.drop(columns=['Unnamed: 0'],inplace=True)\n</pre> # drop a coluna Unnamed: 0 do dataset e imprima novamente as primeiras linhas do dataset  df.drop(columns=['Unnamed: 0'],inplace=True) In\u00a0[68]: Copied! <pre># use o comando info() para visualizar as informa\u00e7\u00f5es do dataset\ndf.info()\n</pre> # use o comando info() para visualizar as informa\u00e7\u00f5es do dataset df.info() <pre>&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 1303 entries, 0 to 1302\nData columns (total 11 columns):\n #   Column            Non-Null Count  Dtype  \n---  ------            --------------  -----  \n 0   Company           1303 non-null   object \n 1   TypeName          1303 non-null   object \n 2   Inches            1303 non-null   float64\n 3   ScreenResolution  1303 non-null   object \n 4   Cpu               1303 non-null   object \n 5   Ram               1303 non-null   object \n 6   Memory            1303 non-null   object \n 7   Gpu               1303 non-null   object \n 8   OpSys             1303 non-null   object \n 9   Weight            1303 non-null   object \n 10  Price             1303 non-null   float64\ndtypes: float64(2), object(9)\nmemory usage: 112.1+ KB\n</pre> In\u00a0[69]: Copied! <pre># use o comando describe() para visualizar as estat\u00edsticas do dataset\ndf.describe()\n</pre> # use o comando describe() para visualizar as estat\u00edsticas do dataset df.describe() Out[69]: Inches Price count 1303.000000 1303.000000 mean 15.017191 59870.042910 std 1.426304 37243.201786 min 10.100000 9270.720000 25% 14.000000 31914.720000 50% 15.600000 52054.560000 75% 15.600000 79274.246400 max 18.400000 324954.720000 <p>Dentre outras an\u00e1lises, \u00e9 esperado que voc\u00ea tenha reparado que os atributos <code>Ram</code> e <code>Weight</code> est\u00e3o como object. Como sugest\u00e3o, podemos converter esses atributos para dado num\u00e9rico.</p> In\u00a0[70]: Copied! <pre># usamos o comando str.replace() para remover a unidade de medida dos valores\ndf['Ram'] = df['Ram'].str.replace('GB','')\ndf['Weight'] = df['Weight'].str.replace('kg','')\n\n# usamos o comando astype() para converter os valores para o tipo num\u00e9rico\ndf['Ram'] = df['Ram'].astype('int32')\ndf['Weight'] = df['Weight'].astype('float32')\n</pre> # usamos o comando str.replace() para remover a unidade de medida dos valores df['Ram'] = df['Ram'].str.replace('GB','') df['Weight'] = df['Weight'].str.replace('kg','')  # usamos o comando astype() para converter os valores para o tipo num\u00e9rico df['Ram'] = df['Ram'].astype('int32') df['Weight'] = df['Weight'].astype('float32')  In\u00a0[71]: Copied! <pre># use o comando info() para visualizar as informa\u00e7\u00f5es do dataset ap\u00f3s a convers\u00e3o\ndf.info()\n</pre> # use o comando info() para visualizar as informa\u00e7\u00f5es do dataset ap\u00f3s a convers\u00e3o df.info()    <pre>&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 1303 entries, 0 to 1302\nData columns (total 11 columns):\n #   Column            Non-Null Count  Dtype  \n---  ------            --------------  -----  \n 0   Company           1303 non-null   object \n 1   TypeName          1303 non-null   object \n 2   Inches            1303 non-null   float64\n 3   ScreenResolution  1303 non-null   object \n 4   Cpu               1303 non-null   object \n 5   Ram               1303 non-null   int32  \n 6   Memory            1303 non-null   object \n 7   Gpu               1303 non-null   object \n 8   OpSys             1303 non-null   object \n 9   Weight            1303 non-null   float32\n 10  Price             1303 non-null   float64\ndtypes: float32(1), float64(2), int32(1), object(7)\nmemory usage: 101.9+ KB\n</pre> In\u00a0[72]: Copied! <pre># use o comando describe() para visualizar as estat\u00edsticas do dataset ap\u00f3s a convers\u00e3o \ndf.describe()\n</pre> # use o comando describe() para visualizar as estat\u00edsticas do dataset ap\u00f3s a convers\u00e3o  df.describe()    Out[72]: Inches Ram Weight Price count 1303.000000 1303.000000 1303.000000 1303.000000 mean 15.017191 8.382195 2.038734 59870.042910 std 1.426304 5.084665 0.665475 37243.201786 min 10.100000 2.000000 0.690000 9270.720000 25% 14.000000 4.000000 1.500000 31914.720000 50% 15.600000 8.000000 2.040000 52054.560000 75% 15.600000 8.000000 2.300000 79274.246400 max 18.400000 64.000000 4.700000 324954.720000 In\u00a0[8]: Copied! <pre>## Sua resposta e seus gr\u00e1ficos para an\u00e1lisar..\n</pre> ## Sua resposta e seus gr\u00e1ficos para an\u00e1lisar..       In\u00a0[\u00a0]: Copied! <pre>## Sua resposta e seus gr\u00e1ficos para an\u00e1lisar..\n</pre> ## Sua resposta e seus gr\u00e1ficos para an\u00e1lisar.. In\u00a0[\u00a0]: Copied! <pre>## Sua resposta e seus gr\u00e1ficos para an\u00e1lisar..\n</pre> ## Sua resposta e seus gr\u00e1ficos para an\u00e1lisar.. In\u00a0[\u00a0]: Copied! <pre>## Sua resposta e seus gr\u00e1ficos para an\u00e1lisar..\n</pre> ## Sua resposta e seus gr\u00e1ficos para an\u00e1lisar.. In\u00a0[\u00a0]: Copied! <pre>## Sua resposta e seus gr\u00e1ficos para an\u00e1lisar..\n</pre> ## Sua resposta e seus gr\u00e1ficos para an\u00e1lisar.. In\u00a0[73]: Copied! <pre># vamos explorar o atributo ScreenResolution\n# use o comando value_counts() para visualizar a frequ\u00eancia dos valores do atributo ScreenResolution\n\ndf['ScreenResolution'].value_counts()\n</pre> # vamos explorar o atributo ScreenResolution # use o comando value_counts() para visualizar a frequ\u00eancia dos valores do atributo ScreenResolution  df['ScreenResolution'].value_counts()   Out[73]: <pre>ScreenResolution\nFull HD 1920x1080                                507\n1366x768                                         281\nIPS Panel Full HD 1920x1080                      230\nIPS Panel Full HD / Touchscreen 1920x1080         53\nFull HD / Touchscreen 1920x1080                   47\n1600x900                                          23\nTouchscreen 1366x768                              16\nQuad HD+ / Touchscreen 3200x1800                  15\nIPS Panel 4K Ultra HD 3840x2160                   12\nIPS Panel 4K Ultra HD / Touchscreen 3840x2160     11\n4K Ultra HD / Touchscreen 3840x2160               10\n4K Ultra HD 3840x2160                              7\nTouchscreen 2560x1440                              7\nIPS Panel 1366x768                                 7\nIPS Panel Quad HD+ / Touchscreen 3200x1800         6\nIPS Panel Retina Display 2560x1600                 6\nIPS Panel Retina Display 2304x1440                 6\nTouchscreen 2256x1504                              6\nIPS Panel Touchscreen 2560x1440                    5\nIPS Panel Retina Display 2880x1800                 4\nIPS Panel Touchscreen 1920x1200                    4\n1440x900                                           4\nIPS Panel 2560x1440                                4\nIPS Panel Quad HD+ 2560x1440                       3\nQuad HD+ 3200x1800                                 3\n1920x1080                                          3\nTouchscreen 2400x1600                              3\n2560x1440                                          3\nIPS Panel Touchscreen 1366x768                     3\nIPS Panel Touchscreen / 4K Ultra HD 3840x2160      2\nIPS Panel Full HD 2160x1440                        2\nIPS Panel Quad HD+ 3200x1800                       2\nIPS Panel Retina Display 2736x1824                 1\nIPS Panel Full HD 1920x1200                        1\nIPS Panel Full HD 2560x1440                        1\nIPS Panel Full HD 1366x768                         1\nTouchscreen / Full HD 1920x1080                    1\nTouchscreen / Quad HD+ 3200x1800                   1\nTouchscreen / 4K Ultra HD 3840x2160                1\nIPS Panel Touchscreen 2400x1600                    1\nName: count, dtype: int64</pre> <p>Vamos aplicar uma transforma\u00e7\u00e3o em nossos dados:</p> <ul> <li>Vamos realizar uma transforma\u00e7\u00e3o em nossos dados usando o atributo ScreenResolution.</li> <li>Vamos analisar os valores presentes nessa coluna e verificar se eles cont\u00eam a informa\u00e7\u00e3o sobre a presen\u00e7a de uma tela touchscreen.</li> <li>A partir dessa verifica\u00e7\u00e3o, criaremos uma nova coluna <code>Touchscreen</code> que indicar\u00e1, de forma bin\u00e1ria, se o laptop possui ou n\u00e3o uma tela touchscreen (1 para sim e 0 para n\u00e3o).</li> </ul> In\u00a0[74]: Copied! <pre># Vamos criar uma nova coluna chamada 'Touchscreen' que recebe 1 se o valor da coluna 'ScreenResolution' cont\u00e9m a palavra 'Touchscreen' e 0 caso contr\u00e1rio\ndf['Touchscreen'] = df['ScreenResolution'].apply(lambda x:1 if 'Touchscreen' in x else 0)\n</pre> # Vamos criar uma nova coluna chamada 'Touchscreen' que recebe 1 se o valor da coluna 'ScreenResolution' cont\u00e9m a palavra 'Touchscreen' e 0 caso contr\u00e1rio df['Touchscreen'] = df['ScreenResolution'].apply(lambda x:1 if 'Touchscreen' in x else 0)  In\u00a0[75]: Copied! <pre># podemos visualizar graficamente a quantidade de laptops com e sem touchscreen\ndf['Touchscreen'].value_counts().plot(kind='bar')\n</pre> # podemos visualizar graficamente a quantidade de laptops com e sem touchscreen df['Touchscreen'].value_counts().plot(kind='bar') Out[75]: <pre>&lt;Axes: xlabel='Touchscreen'&gt;</pre> In\u00a0[76]: Copied! <pre># avaliando o pre\u00e7o com e sem touchscreen\nsns.barplot(x=df['Touchscreen'],y=df['Price'])\n</pre> # avaliando o pre\u00e7o com e sem touchscreen sns.barplot(x=df['Touchscreen'],y=df['Price']) Out[76]: <pre>&lt;Axes: xlabel='Touchscreen', ylabel='Price'&gt;</pre> In\u00a0[\u00a0]: Copied! <pre>## Sua resposta aqui\n</pre> ## Sua resposta aqui In\u00a0[\u00a0]: Copied! <pre>## Sua resposta aqui\n</pre> ## Sua resposta aqui In\u00a0[\u00a0]: Copied! <pre>## Sua resposta aqui\n</pre> ## Sua resposta aqui In\u00a0[\u00a0]: Copied! <pre>## Sua resposta aqui\n</pre> ## Sua resposta aqui In\u00a0[77]: Copied! <pre># Vamos explorar o atributo 'OpSys'\ndf['OpSys'].value_counts()\n</pre> # Vamos explorar o atributo 'OpSys' df['OpSys'].value_counts() Out[77]: <pre>OpSys\nWindows 10      1072\nNo OS             66\nLinux             62\nWindows 7         45\nChrome OS         27\nmacOS             13\nMac OS X           8\nWindows 10 S       8\nAndroid            2\nName: count, dtype: int64</pre> In\u00a0[78]: Copied! <pre># podemos visualizar graficamente a quantidade de laptops com cada sistema operacional\nsns.barplot(x=df['OpSys'],y=df['Price'])\nplt.xticks(rotation='vertical')\nplt.show()\n</pre> # podemos visualizar graficamente a quantidade de laptops com cada sistema operacional sns.barplot(x=df['OpSys'],y=df['Price']) plt.xticks(rotation='vertical') plt.show() In\u00a0[79]: Copied! <pre># vamos criar uma nova coluna chamada 'OS' que recebe o valor 'Windows' se o valor da coluna 'OpSys' for 'Windows 10', 'Windows 7' ou 'Windows 10 S', 'Mac' se o valor for 'macOS' ou 'Mac OS X' e 'Others/No OS/Linux' caso contr\u00e1rio\n\ndef cat_os(inp):\n    if inp == 'Windows 10' or inp == 'Windows 7' or inp == 'Windows 10 S':\n        return 'Windows'\n    elif inp == 'macOS' or inp == 'Mac OS X':\n        return 'Mac'\n    else:\n        return 'Others/No OS/Linux'\n\ndf['OS'] = df['OpSys'].apply(cat_os)\n</pre> # vamos criar uma nova coluna chamada 'OS' que recebe o valor 'Windows' se o valor da coluna 'OpSys' for 'Windows 10', 'Windows 7' ou 'Windows 10 S', 'Mac' se o valor for 'macOS' ou 'Mac OS X' e 'Others/No OS/Linux' caso contr\u00e1rio  def cat_os(inp):     if inp == 'Windows 10' or inp == 'Windows 7' or inp == 'Windows 10 S':         return 'Windows'     elif inp == 'macOS' or inp == 'Mac OS X':         return 'Mac'     else:         return 'Others/No OS/Linux'  df['OS'] = df['OpSys'].apply(cat_os) In\u00a0[80]: Copied! <pre># podemos visualizar graficamente a quantidade de laptops com cada sistema operacional\nsns.barplot(x=df['OS'],y=df['Price'])\nplt.xticks(rotation='vertical')\nplt.show()\n</pre> # podemos visualizar graficamente a quantidade de laptops com cada sistema operacional sns.barplot(x=df['OS'],y=df['Price']) plt.xticks(rotation='vertical') plt.show() In\u00a0[81]: Copied! <pre># Vamos explorar o atributo 'OS'\ndf['OS'].value_counts()\n</pre> # Vamos explorar o atributo 'OS' df['OS'].value_counts() Out[81]: <pre>OS\nWindows               1125\nOthers/No OS/Linux     157\nMac                     21\nName: count, dtype: int64</pre> In\u00a0[82]: Copied! <pre>df.head()\n</pre> df.head() Out[82]: Company TypeName Inches ScreenResolution Cpu Ram Memory Gpu OpSys Weight Price Touchscreen OS 0 Apple Ultrabook 13.3 IPS Panel Retina Display 2560x1600 Intel Core i5 2.3GHz 8 128GB SSD Intel Iris Plus Graphics 640 macOS 1.37 71378.6832 0 Mac 1 Apple Ultrabook 13.3 1440x900 Intel Core i5 1.8GHz 8 128GB Flash Storage Intel HD Graphics 6000 macOS 1.34 47895.5232 0 Mac 2 HP Notebook 15.6 Full HD 1920x1080 Intel Core i5 7200U 2.5GHz 8 256GB SSD Intel HD Graphics 620 No OS 1.86 30636.0000 0 Others/No OS/Linux 3 Apple Ultrabook 15.4 IPS Panel Retina Display 2880x1800 Intel Core i7 2.7GHz 16 512GB SSD AMD Radeon Pro 455 macOS 1.83 135195.3360 0 Mac 4 Apple Ultrabook 13.3 IPS Panel Retina Display 2560x1600 Intel Core i5 3.1GHz 8 256GB SSD Intel Iris Plus Graphics 650 macOS 1.37 96095.8080 0 Mac In\u00a0[27]: Copied! <pre>## Sua resposta aqui\n</pre> ## Sua resposta aqui    In\u00a0[83]: Copied! <pre>df.info()\n</pre> df.info() <pre>&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 1303 entries, 0 to 1302\nData columns (total 13 columns):\n #   Column            Non-Null Count  Dtype  \n---  ------            --------------  -----  \n 0   Company           1303 non-null   object \n 1   TypeName          1303 non-null   object \n 2   Inches            1303 non-null   float64\n 3   ScreenResolution  1303 non-null   object \n 4   Cpu               1303 non-null   object \n 5   Ram               1303 non-null   int32  \n 6   Memory            1303 non-null   object \n 7   Gpu               1303 non-null   object \n 8   OpSys             1303 non-null   object \n 9   Weight            1303 non-null   float32\n 10  Price             1303 non-null   float64\n 11  Touchscreen       1303 non-null   int64  \n 12  OS                1303 non-null   object \ndtypes: float32(1), float64(2), int32(1), int64(1), object(8)\nmemory usage: 122.3+ KB\n</pre> In\u00a0[88]: Copied! <pre># exibe a correla\u00e7\u00e3o entre as vari\u00e1veis num\u00e9ricas\n\n# Calcula a matriz de correla\u00e7\u00e3o\ncorrelation_matrix = df[['Inches', 'Ram', 'Weight', 'Price','Touchscreen']].corr()\n\n# exibe a matriz de correla\u00e7\u00e3o\nplt.figure(figsize=(10, 8))\nsns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt=\".2f\", linewidths=.5)\nplt.title('Correlation Matrix')\nplt.show()\n</pre> # exibe a correla\u00e7\u00e3o entre as vari\u00e1veis num\u00e9ricas  # Calcula a matriz de correla\u00e7\u00e3o correlation_matrix = df[['Inches', 'Ram', 'Weight', 'Price','Touchscreen']].corr()  # exibe a matriz de correla\u00e7\u00e3o plt.figure(figsize=(10, 8)) sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt=\".2f\", linewidths=.5) plt.title('Correlation Matrix') plt.show()   In\u00a0[94]: Copied! <pre># Vamos treinar nosso modelo com base no dataset de laptops e prever o pre\u00e7o de um laptop com as seguintes caracter\u00edsticas:\n\n\nX = df[['Inches', 'Ram', 'Weight','Touchscreen']]\n# X = df.drop(['Price'], axis=1)     ### teste com todas as entradas\n\nY = df['Price']             \n\nprint(f\"Formato das tabelas de dados {X.shape} e saidas {Y.shape}\")\n</pre> # Vamos treinar nosso modelo com base no dataset de laptops e prever o pre\u00e7o de um laptop com as seguintes caracter\u00edsticas:   X = df[['Inches', 'Ram', 'Weight','Touchscreen']] # X = df.drop(['Price'], axis=1)     ### teste com todas as entradas  Y = df['Price']               print(f\"Formato das tabelas de dados {X.shape} e saidas {Y.shape}\") <pre>Formato das tabelas de dados (1303, 4) e saidas (1303,)\n</pre> In\u00a0[95]: Copied! <pre># Separamos 20% para o teste\nfrom sklearn.model_selection import train_test_split\n\nX_treino, X_teste, Y_treino, Y_teste = train_test_split(X, Y, test_size=0.2)\n\nprint(X_treino.shape)\nprint(X_teste.shape)\nprint(Y_treino.shape)\nprint(Y_teste.shape)\n</pre> # Separamos 20% para o teste from sklearn.model_selection import train_test_split  X_treino, X_teste, Y_treino, Y_teste = train_test_split(X, Y, test_size=0.2)  print(X_treino.shape) print(X_teste.shape) print(Y_treino.shape) print(Y_teste.shape) <pre>(1042, 4)\n(261, 4)\n(1042,)\n(261,)\n</pre> In\u00a0[96]: Copied! <pre>#Primeiras linhas do dataframe \nX_treino.head()\n</pre> #Primeiras linhas do dataframe  X_treino.head() Out[96]: Inches Ram Weight Touchscreen 119 15.6 8 1.70 0 438 14.0 24 1.32 0 24 15.6 8 1.91 0 1010 15.6 8 2.65 0 631 15.6 16 2.62 0 In\u00a0[97]: Copied! <pre>Y_treino.head()\n</pre> Y_treino.head() Out[97]: <pre>119      59567.04\n438     126912.96\n24       35111.52\n1010     50562.72\n631      78801.12\nName: Price, dtype: float64</pre> In\u00a0[98]: Copied! <pre># Importa a biblioteca\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import mean_squared_error\n\n# Cria o modelo de regress\u00e3o \nlin_model = LinearRegression()\n\n# Cria o modelo de machine learning\nlin_model.fit(X_treino, Y_treino)\n</pre> # Importa a biblioteca from sklearn.linear_model import LinearRegression from sklearn.metrics import mean_squared_error  # Cria o modelo de regress\u00e3o  lin_model = LinearRegression()  # Cria o modelo de machine learning lin_model.fit(X_treino, Y_treino)    Out[98]: <pre>LinearRegression()</pre>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.\u00a0\u00a0LinearRegression?Documentation for LinearRegressioniFitted<pre>LinearRegression()</pre> <p>Pronto!! bora testar se esta funcionando....</p> In\u00a0[99]: Copied! <pre># Para obter as previs\u00f5es, basta chamar o m\u00e9todo predict()\ny_teste_predito = lin_model.predict(X_teste)\nprint(\"Predi\u00e7\u00e3o usando regress\u00e3o, retorna valores continuos: {}\".format(y_teste_predito))\n</pre> # Para obter as previs\u00f5es, basta chamar o m\u00e9todo predict() y_teste_predito = lin_model.predict(X_teste) print(\"Predi\u00e7\u00e3o usando regress\u00e3o, retorna valores continuos: {}\".format(y_teste_predito))  <pre>Predi\u00e7\u00e3o usando regress\u00e3o, retorna valores continuos: [100034.37969786  59932.48674075  28480.27437865  59685.46857027\n  54085.85527543  99275.47252861  43184.31534678  32354.91705733\n  36263.18833347  63602.67213891  64228.45109843  62957.03363296\n  58323.48378503 107077.6245361   50573.50573024  60228.9082705\n  99470.31655009  54448.14840892  32667.80663524  32519.59596852\n  54481.08411263  54514.01981635  54711.63443126  32338.44920547\n  54184.66258289  68103.09397342  57697.70482551  54596.35907564\n  31959.68841644  99458.0040976   60320.1800186   58685.77691852\n  54777.50583869  32848.9533983   21374.17318158  31959.68841644\n  50655.84498953  65771.58264672  54942.18435727  36526.6741595\n  28480.27437865  59932.48674075  50738.18424882  58027.06205897\n  99622.6830088   31959.68841644  37634.10560752  59932.48674075\n  54184.66258289  32354.91705733  54415.2127052   53405.97899809\n  32848.9533983   32190.23853875  36427.86704835 183667.48320055\n  37699.97701495  32354.91705733 109859.23784614  32519.59596852\n  33260.65008736  65969.19706532  32190.23853875  55518.55995753\n  32190.23853875 104612.98499966  59932.48674075  39609.22931373\n  36049.10606301  35686.81292952 107822.0703495   65458.69306881\n  58570.50175921  56424.29259494 100281.39747572  99243.92202346\n  32519.59596852  55106.86326847  98354.65704159  25216.57265767\n  97460.69810117  36954.83870042 104440.77092174  36839.56373741\n  51676.04011968  32519.59596852  32684.2744871   32305.51350175\n  59800.74372958  39609.22931373  65359.88595766  32519.59596852\n  31943.22056458  55271.54178704  36839.56373741  55370.34889819\n  65969.19706532  32354.91705733  32486.66026481  50557.03787839\n  31959.68841644  54942.18435727 103613.29334792  38152.14496708\n 105638.76988583  54942.18435727  41970.54122826  36510.20630764\n  59463.85093677  98218.22007186  66002.13276904  65376.35380952\n  77035.41570886  51298.09199722  57747.10838109  99622.6830088\n  55419.75245376  51726.25653814  32848.9533983   32437.25670924\n  32848.9533983   77051.88356072  32354.91705733  32519.59596852\n  32519.59596852  99787.36152738  31490.67596647  97559.50521232\n  58586.96961106  60064.22955561  42561.67150314 102542.88179931\n  54250.53399032  32585.46737595 109760.43053868  31959.68841644\n  54925.71650541  54777.50583869  98218.22007186  60261.84397421\n  32354.91705733  60344.18342981  58685.77691852  43632.08305175\n 102822.83567351  60261.84397421  99935.57219409  32042.02767572\n  55469.15600933  50738.18424882  96867.85504168 100956.58018713\n  53954.11246057  32848.9533983   94595.28952223  54826.90939427\n  54612.82692749  58521.09820363  32568.9995241   98634.61071948\n  54530.48766821  54448.14840892  67297.55364572  95418.68290035\n  62561.80479576 109974.51280914  38069.80570779  55106.86326847\n  32289.0456499  100940.11233527  54514.01981635  77200.09422744\n  28480.27437865  50573.50573024  55436.22030562  32190.23853875\n  54777.50583869  31860.88110898  32684.2744871   43813.22942218\n  99293.32557903  59767.80802587  43236.85421455  32025.55982386\n  94644.6930778   60163.03686307  32848.9533983  100582.59609492\n  55271.54178704  36164.38102601  54217.5982866   58323.48378503\n  43648.55090361  67495.16806432  32256.10994618  54777.50583869\n  55271.54178704  57747.10838109  60080.69740747  54744.57013498\n  32354.91705733  54448.14840892  65936.26136161  54777.50583869\n  36839.56373741  54991.58791284  99293.32557903  65244.61079835\n  58586.96961106  54777.50583869  35999.70250744  31959.68841644\n  54448.14840892 101121.2587057   95418.68290035  59892.01547769\n  97230.14817517  96159.73662656  54217.5982866  104201.2883106\n  54448.14840892  98766.35373065  54777.50583869  50573.50573024\n  42751.37391273  97822.99162729  54365.80914963  65326.95025395\n  71060.38425964  58422.29089618  51298.09199722  32519.59596852\n  54826.90939427  43977.90833338  54777.50583869  32042.02767572\n  99787.36152738 104925.87457758  28809.63180842  65376.35380952\n  36329.0597409   58768.11617781  65590.43607998  97724.18451614\n  32009.09197201  60410.05483724  59924.9511814   37921.59484476\n  31860.88110898  60410.05483724 102279.39597328  36786.33236852\n  62561.80479576  95138.72902615 100034.37969786  54942.18435727\n  99787.36152738  50458.23076724 193472.41040241  32025.55982386\n  32717.21019081]\n</pre> In\u00a0[100]: Copied! <pre>from sklearn.metrics import r2_score, mean_squared_error,mean_absolute_error\nimport numpy as np\n\nprint(\"Soma dos Erros ao Quadrado (SSE): %2.f \" % np.sum((y_teste_predito - Y_teste)**2))\nprint(\"Erro Quadr\u00e1tico M\u00e9dio (MSE): %.2f\" % mean_squared_error(Y_teste, y_teste_predito))\nprint(\"Erro M\u00e9dio Absoluto (MAE): %.2f\" % mean_absolute_error(Y_teste, y_teste_predito))\nprint (\"Raiz do Erro Quadr\u00e1tico M\u00e9dio (RMSE): %.2f \" % np.sqrt(mean_squared_error(Y_teste, y_teste_predito)))\nprint(\"R2-score: %.2f\" % r2_score(y_teste_predito , Y_teste) )\n</pre> from sklearn.metrics import r2_score, mean_squared_error,mean_absolute_error import numpy as np  print(\"Soma dos Erros ao Quadrado (SSE): %2.f \" % np.sum((y_teste_predito - Y_teste)**2)) print(\"Erro Quadr\u00e1tico M\u00e9dio (MSE): %.2f\" % mean_squared_error(Y_teste, y_teste_predito)) print(\"Erro M\u00e9dio Absoluto (MAE): %.2f\" % mean_absolute_error(Y_teste, y_teste_predito)) print (\"Raiz do Erro Quadr\u00e1tico M\u00e9dio (RMSE): %.2f \" % np.sqrt(mean_squared_error(Y_teste, y_teste_predito))) print(\"R2-score: %.2f\" % r2_score(y_teste_predito , Y_teste) ) <pre>Soma dos Erros ao Quadrado (SSE): 177032003697 \nErro Quadr\u00e1tico M\u00e9dio (MSE): 678283539.07\nErro M\u00e9dio Absoluto (MAE): 19312.26\nRaiz do Erro Quadr\u00e1tico M\u00e9dio (RMSE): 26043.88 \nR2-score: 0.02\n</pre> In\u00a0[21]: Copied! <pre>## implemente sua sua solu\u00e7\u00e3o....\n</pre> ## implemente sua sua solu\u00e7\u00e3o....    In\u00a0[101]: Copied! <pre>import joblib\n\n# Supondo que seu modelo treinado seja armazenado na vari\u00e1vel `model`\njoblib.dump(lin_model, 'modelo_treinado.joblib')\n</pre> import joblib  # Supondo que seu modelo treinado seja armazenado na vari\u00e1vel `model` joblib.dump(lin_model, 'modelo_treinado.joblib')  Out[101]: <pre>['modelo_treinado.joblib']</pre> In\u00a0[102]: Copied! <pre># Para carregar o modelo posteriormente\n\nmodel = joblib.load('modelo_treinado.joblib')\n</pre> # Para carregar o modelo posteriormente  model = joblib.load('modelo_treinado.joblib')  In\u00a0[103]: Copied! <pre>import operator\n\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n\n# importa feature polinomial\nfrom sklearn.preprocessing import PolynomialFeatures\n\n#####----------- vou gerar alguns numeros aleat\u00f3rios ------------------\n\n#gerando numeros aleatorios, apenas para este exemplo\nnp.random.seed(42)\nx = 2 - 3 * np.random.normal(0, 1, 30)\ny = x - 3 * (x ** 2) + 0.8 * (x ** 3)+ 0.2 * (x ** 4) + np.random.normal(-20, 20, 30)\n\n# ajuste nos dados, pois estamos trabalhando com a numpy \nx = x[:, np.newaxis]\ny = y[:, np.newaxis]\n####---------------pronto j\u00e1 temos os dados para treinar -------------\n\n\n#----\u00c9 aqui que o seu c\u00f3digo muda ------------------------------------\n\n# Chama a fun\u00e7\u00e3o definindo o grau do polinomio e aplica o modelo\n\ngrau_poly = 1\npolynomial_features= PolynomialFeatures(degree = grau_poly)\nx_poly = polynomial_features.fit_transform(x)\n\n#----Pronto agora \u00e9 tudo como era antes, com regress\u00e3o linear\n\n\nmodel = LinearRegression()\nmodel.fit(x_poly, y)\ny_poly_pred = model.predict(x_poly)\n\n# M\u00e9trica de avalia\u00e7\u00e3o do modelo\nprint(\"Soma dos Erros ao Quadrado (SSE): %2.f \" % np.sum((y_poly_pred - y)**2))\nprint(\"Erro Quadr\u00e1tico M\u00e9dio (MSE): %.2f\" % mean_squared_error(y,y_poly_pred))\nprint(\"Erro M\u00e9dio Absoluto (MAE): %.2f\" % mean_absolute_error(y, y_poly_pred))\nprint (\"Raiz do Erro Quadr\u00e1tico M\u00e9dio (RMSE): %.2f \" % np.sqrt(mean_squared_error(y, y_poly_pred)))\nprint(\"R2-score: %.2f\" % r2_score(y,y_poly_pred) )\n\n\nplt.scatter(x, y, s=10)\n# ordena os valores de x antes de plotar\nsort_axis = operator.itemgetter(0)\nsorted_zip = sorted(zip(x,y_poly_pred), key=sort_axis)\nx, y_poly_pred = zip(*sorted_zip)\n\nplt.plot(x, y_poly_pred, color='r')\nplt.show()\n</pre> import operator  import numpy as np import matplotlib.pyplot as plt  from sklearn.linear_model import LinearRegression from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error  # importa feature polinomial from sklearn.preprocessing import PolynomialFeatures  #####----------- vou gerar alguns numeros aleat\u00f3rios ------------------  #gerando numeros aleatorios, apenas para este exemplo np.random.seed(42) x = 2 - 3 * np.random.normal(0, 1, 30) y = x - 3 * (x ** 2) + 0.8 * (x ** 3)+ 0.2 * (x ** 4) + np.random.normal(-20, 20, 30)  # ajuste nos dados, pois estamos trabalhando com a numpy  x = x[:, np.newaxis] y = y[:, np.newaxis] ####---------------pronto j\u00e1 temos os dados para treinar -------------   #----\u00c9 aqui que o seu c\u00f3digo muda ------------------------------------  # Chama a fun\u00e7\u00e3o definindo o grau do polinomio e aplica o modelo  grau_poly = 1 polynomial_features= PolynomialFeatures(degree = grau_poly) x_poly = polynomial_features.fit_transform(x)  #----Pronto agora \u00e9 tudo como era antes, com regress\u00e3o linear   model = LinearRegression() model.fit(x_poly, y) y_poly_pred = model.predict(x_poly)  # M\u00e9trica de avalia\u00e7\u00e3o do modelo print(\"Soma dos Erros ao Quadrado (SSE): %2.f \" % np.sum((y_poly_pred - y)**2)) print(\"Erro Quadr\u00e1tico M\u00e9dio (MSE): %.2f\" % mean_squared_error(y,y_poly_pred)) print(\"Erro M\u00e9dio Absoluto (MAE): %.2f\" % mean_absolute_error(y, y_poly_pred)) print (\"Raiz do Erro Quadr\u00e1tico M\u00e9dio (RMSE): %.2f \" % np.sqrt(mean_squared_error(y, y_poly_pred))) print(\"R2-score: %.2f\" % r2_score(y,y_poly_pred) )   plt.scatter(x, y, s=10) # ordena os valores de x antes de plotar sort_axis = operator.itemgetter(0) sorted_zip = sorted(zip(x,y_poly_pred), key=sort_axis) x, y_poly_pred = zip(*sorted_zip)  plt.plot(x, y_poly_pred, color='r') plt.show() <pre>Soma dos Erros ao Quadrado (SSE): 602124 \nErro Quadr\u00e1tico M\u00e9dio (MSE): 20070.81\nErro M\u00e9dio Absoluto (MAE): 104.66\nRaiz do Erro Quadr\u00e1tico M\u00e9dio (RMSE): 141.67 \nR2-score: 0.55\n</pre> In\u00a0[23]: Copied! <pre>## Implemente sua solu\u00e7\u00e3o\n</pre> ## Implemente sua solu\u00e7\u00e3o"},{"location":"aulas/IA/lab03/preco-notebook.html#objetivos","title":"Objetivos\u00b6","text":"<ul> <li>Praticar o conceito de tratamento de dados em problemas de regress\u00e3o</li> </ul>"},{"location":"aulas/IA/lab03/preco-notebook.html#bora-la","title":"Bora l\u00e1!!\u00b6","text":"<p>Vamos desenvolver um projeto completo de regress\u00e3o, desde a explora\u00e7\u00e3o inicial dos dados at\u00e9 a constru\u00e7\u00e3o e avalia\u00e7\u00e3o do modelo final.</p>"},{"location":"aulas/IA/lab03/preco-notebook.html#definicao-do-problema","title":"Defini\u00e7\u00e3o do problema\u00b6","text":""},{"location":"aulas/IA/lab03/preco-notebook.html#faca-o-download-do-dataset-aqui-httpsdrivegooglecomfiled1pqtec5sx9zz4qi2q3zp2k-gi2pjclgj9viewuspsharing","title":"Fa\u00e7a o download do dataset aqui: https://drive.google.com/file/d/1pqtEc5sx9Zz4QI2Q3zP2k-Gi2PJClGJ9/view?usp=sharing\u00b6","text":"<p>Vamos explorar um dataset que cont\u00e9m informa\u00e7\u00f5es detalhadas sobre 1303 modelos de notebooks. Este dataset foi compilado para nos ajudar a entender as caracter\u00edsticas t\u00e9cnicas e de mercado.</p> <p>Informa\u00e7\u00f5es importantes sobre o significado de cada um dos atributos</p> <ul> <li><p>O dataset \"laptop_data.csv\" cont\u00e9m 1303 entradas e 12 colunas.</p> </li> <li><p>As colunas incluem:</p> <ul> <li>Unnamed: 0: Um \u00edndice ou identificador num\u00e9rico para cada entrada.</li> <li>Company: A marca ou fabricante do laptop.</li> <li>TypeName: O tipo ou categoria do laptop (por exemplo, Notebook, Ultrabook, etc.).</li> <li>Inches: O tamanho da tela do laptop em polegadas.</li> <li>ScreenResolution: A resolu\u00e7\u00e3o da tela do laptop.</li> <li>Cpu: O modelo e a especifica\u00e7\u00e3o da CPU do laptop.</li> <li>Ram: A quantidade de RAM no laptop.</li> <li>Memory: O tipo e a capacidade de armazenamento (por exemplo, HDD, SSD).</li> <li>Gpu: A unidade de processamento gr\u00e1fico (GPU) do laptop.</li> <li>OpSys: O sistema operacional instalado no laptop.</li> <li>Weight: O peso do laptop.</li> <li>Price: O pre\u00e7o do laptop.</li> </ul> </li> </ul>"},{"location":"aulas/IA/lab03/preco-notebook.html#objetivo","title":"Objetivo\u00b6","text":"<p><code>Queremos desenvolver um modelo capaz de predizer o valor de um notebook.</code></p>"},{"location":"aulas/IA/lab03/preco-notebook.html#desafio-1","title":"Desafio 1\u00b6","text":"<p>Do ponto de vista de machine learning, que problema \u00e9 esse:</p> <pre><code>Aprendizado supervisionado, n\u00e3o-supervisionado ou aprendizado por refor\u00e7o?</code></pre> <p>R:</p> <pre><code>Classifica\u00e7\u00e3o, regress\u00e3o ou clusteriza\u00e7\u00e3o?</code></pre> <p>R:</p>"},{"location":"aulas/IA/lab03/preco-notebook.html#desafio-2","title":"Desafio 2\u00b6","text":"<p>Use os metodos info() e describe() para exibir as informa\u00e7\u00f5es do dataframe e responda:</p> <p>Existe dados faltantes?</p> <p>Qual o tipo de dados dos atributos, isso faz sentido?</p>"},{"location":"aulas/IA/lab03/preco-notebook.html#explorando-os-dados-visualmente","title":"Explorando os Dados Visualmente\u00b6","text":"<p>Agora, vamos mergulhar nos dados para descobrir padr\u00f5es, tend\u00eancias e insights que s\u00f3 podem ser revelados por uma an\u00e1lise visual. Elabore an\u00e1lises para tentar responder algumas das seguintes perguntas:</p> <ul> <li>Como o tamanho da tela influencia o pre\u00e7o?</li> <li>Qual a marca de notebook que mais vende?</li> <li>A marca que mais vende \u00e9 a que possui os maiores pre\u00e7os?</li> <li>Existe uma correla\u00e7\u00e3o entre a marca do laptop e o tipo de GPU utilizado?</li> <li>Quais s\u00e3o as faixas de pre\u00e7os mais comuns? Certos tipos de laptops dominam o mercado?</li> <li>Ser\u00e1 que a distribui\u00e7\u00e3o de pre\u00e7os varia muito entre diferentes marcas? E entre diferentes tipos de mem\u00f3ria?</li> <li>Existem laptops com pre\u00e7os ou especifica\u00e7\u00f5es muito fora do comum?</li> </ul> <p>Aplique os m\u00e9todos que achar conveniente (j\u00e1 vimos algumas op\u00e7\u00f5es em aula) para visualizar os dados de forma gr\u00e1fica. Use esses gr\u00e1ficos para identificar padr\u00f5es e rela\u00e7\u00f5es que podem ser explorados em an\u00e1lises mais profundas.</p>"},{"location":"aulas/IA/lab03/preco-notebook.html#pre-processamento-de-dados","title":"Pr\u00e9-processamento de dados\u00b6","text":"<p>Vamos imaginar que estamos interessados em saber se a presen\u00e7a de uma tela touchscreen influencia o pre\u00e7o de um laptop.</p> <ul> <li><code>Como voc\u00ea extrairia informa\u00e7\u00e3o dos dados que temos em formato de texto e a transformaria em algo que possa ser visualizado ou modelado?</code></li> </ul>"},{"location":"aulas/IA/lab03/preco-notebook.html#desafio-3","title":"Desafio 3\u00b6","text":"<p>Implemente as seguintes transforma\u00e7\u00f5es nos dados:</p> <ul> <li>criar uma nova coluna chamada 'Ips' que recebe 1 se o valor da coluna 'ScreenResolution' cont\u00e9m a palavra 'IPS' e 0 caso contr\u00e1rio.</li> </ul>"},{"location":"aulas/IA/lab03/preco-notebook.html#desafio-4","title":"Desafio 4\u00b6","text":"<ul> <li>criar uma nova coluna chamada 'Cpu Name' que recebe da coluna 'Cpu' o nome do fabricante da cpu, Intel, AMD e outros...</li> </ul>"},{"location":"aulas/IA/lab03/preco-notebook.html#desafio-5","title":"Desafio 5\u00b6","text":"<ul> <li>criar uma nova coluna chamada 'Cpu Name' que recebe da coluna 'Cpu' o nome do fabricante da cpu, Intel, AMD e outros...</li> </ul>"},{"location":"aulas/IA/lab03/preco-notebook.html#desafio-6","title":"Desafio 6\u00b6","text":"<ul> <li>criar uma nova coluna chamada 'Gpu Name' que recebe da coluna 'Gpu' o nome do fabricante da cpu, Nvidia, Intel e AMD.</li> </ul>"},{"location":"aulas/IA/lab03/preco-notebook.html#desafio-resolvido","title":"Desafio resolvido\u00b6","text":"<ul> <li>criar uma nova coluna chamada 'os' que recebe da coluna 'OpSys' o nome do fabricante do sistema operacional: Windows, MAC, Linux.</li> </ul>"},{"location":"aulas/IA/lab03/preco-notebook.html#desafio-7","title":"Desafio 7\u00b6","text":"<ul> <li><p>An\u00e1lise o atributo <code>Memory</code>, visualize os tipos de memoria existentes: \u00c9 espeperado que voc\u00ea consiga observar 4 tipos de memoria, s\u00e3o elas:</p> <ul> <li>HDD</li> <li>SSD</li> <li>Hybrid</li> <li>Flash_Storage</li> </ul> </li> <li><p>Fa\u00e7a a convers\u00e3o de unidade: Note que a capacidade de armazenamento variam bastante e devem ser padronizadas em GB, os valores em TB devem ser convertidos para GB, ou seja 1TB = 1000GB.</p> </li> <li><p>Crie novas colunas chamadas 'SSD', 'HDD', 'Hybrid' e 'Flash_Storage' que recebe da coluna 'Memory' o valor da capacidade de memoria.</p> </li> <li><p>Note que em alguns casos uma entrada de dados possui mais de um tipo de memoria '512GB SSD +  2TB HDD' e nesse caso deve ser alocado o valor correto nas duas colunas.</p> </li> </ul>"},{"location":"aulas/IA/lab03/preco-notebook.html#avaliacao-de-correlacao","title":"Avalia\u00e7\u00e3o de correla\u00e7\u00e3o\u00b6","text":"<p>Vamos explorar a correla\u00e7\u00e3o entre os atributos num\u00e9ricos</p>"},{"location":"aulas/IA/lab03/preco-notebook.html#desafio-8","title":"Desafio 8\u00b6","text":"<p>Analisando a matriz de correla\u00e7\u00e3o acima responda:</p> <p>Qual(is) feature possue a maior correla\u00e7\u00e3o com o target?</p> <p>Qual(is) feature n\u00e3o possue correla\u00e7\u00e3o com o target?</p>"},{"location":"aulas/IA/lab03/preco-notebook.html#pare","title":"PARE!!!\u00b6","text":"<p>Podemos pensar em outras diversas transforma\u00e7\u00f5es em nossos dados, por hora j\u00e1 est\u00e1 bom. Vamos avan\u00e7ar e criar um sub-dataset com os atributos que ser\u00e3o utilizados para treinar nosso modelo de Machine Learning.</p>"},{"location":"aulas/IA/lab03/preco-notebook.html#desafio-9","title":"Desafio 9\u00b6","text":"<ul> <li>Identifica\u00e7\u00e3o do Atributo Alvo: Qual \u00e9 o atributo que queremos prever ou analisar como nossa vari\u00e1vel de interesse principal neste conjunto de dados?</li> </ul>"},{"location":"aulas/IA/lab03/preco-notebook.html#dividindo-os-dados-em-conjunto-de-treinamento-e-de-testes","title":"Dividindo os dados em conjunto de treinamento e de testes\u00b6","text":"<p>Dividir nosso dataset em dois conjuntos de dados.</p> <pre><code>Treinamento - Representa 80% das amostras do conjunto de dados original,\nTeste - com 20% das amostras</code></pre> <p>Vamos escolher aleatoriamente algumas amostras do conjunto original. Isto pode ser feito com Scikit-Learn usando a fun\u00e7\u00e3o train_test_split()</p> <p>scikit-learn Caso ainda n\u00e3o tenha instalado, no terminal digite:</p> <ul> <li>pip install scikit-learn</li> </ul>"},{"location":"aulas/IA/lab03/preco-notebook.html#chegou-a-hora-de-aplicar-o-modelo-preditivo","title":"Chegou a hora de aplicar o modelo preditivo\u00b6","text":"<p>Treinar um modelo no python \u00e9 simples se usar o Scikit-Learn. Treinar um modelo no Scikit-Learn \u00e9 simples: basta criar o regressor, e chamar o m\u00e9todo fit().</p> <p>Uma observa\u00e7\u00e3o sobre a sintaxe dos classificadores do <code>scikit-learn</code></p> <ul> <li>O m\u00e9todo <code>fit(X,Y)</code> recebe uma matriz ou dataframe X onde cada linha \u00e9 uma amostra de aprendizado, e um array Y contendo as sa\u00eddas esperadas do classificador, seja na forma de texto ou de inteiros</li> <li>O m\u00e9todo <code>predict(X)</code> recebe uma matriz ou dataframe X onde cada linha \u00e9 uma amostra de teste, retornando um array de classes</li> </ul>"},{"location":"aulas/IA/lab03/preco-notebook.html#avaliando-o-modelo-treinado","title":"Avaliando o modelo treinado\u00b6","text":"<p>Vamos colocar alguns valores e ver a predi\u00e7\u00e3o do classificador.</p>"},{"location":"aulas/IA/lab03/preco-notebook.html#desafio-10","title":"Desafio 10\u00b6","text":"<p>Refa\u00e7a o notebook substituindo o algoritmo de regress\u00e3o linear por outro algoritmo de regress\u00e3o e compare os resultados obtidos.</p> <p>Sugest\u00e3o de alguns algoritmos de ML para problemas de regress\u00e3o:</p> Nome Vantagem Desvantagem Exemplo sklearn Regress\u00e3o Linear F\u00e1cil de entender e implementar Pode n\u00e3o ser adequado para problemas mais complexos from sklearn.linear_model import LinearRegressionmodel = LinearRegression()model.fit(X, y)prediction = model.predict([X_teste]) \u00c1rvores de decis\u00e3o F\u00e1cil de entender e visualizar Pode levar a overfitting se a \u00e1rvore for muito grande from sklearn.tree import DecisionTreeRegressormodel = DecisionTreeRegressor()model.fit(X, y)prediction = model.predict([X_teste]) Random Forest Mais robusto e geralmente mais preciso do que uma \u00fanica \u00e1rvore de decis\u00e3o Pode ser mais lento e mais dif\u00edcil de ajustar from sklearn.ensemble import RandomForestRegressormodel = RandomForestRegressor(n_estimators=100)model.fit(X, y)prediction = model.predict([X_teste]) Support Vector Regression (SVR) Lida bem com dados multidimensionais e n\u00e3o lineares Pode ser dif\u00edcil de escolher o kernel correto e ajustar os hiperpar\u00e2metros from sklearn.svm import SVRmodel = SVR(kernel='rbf')model.fit(X, y)prediction = model.predict([X_teste]) Gradient Boosting Preciso e lida bem com dados multidimensionais e n\u00e3o lineares Pode ser mais lento e mais dif\u00edcil de ajustar from sklearn.ensemble import GradientBoostingRegressormodel = GradientBoostingRegressor(n_estimators=100)model.fit(X, y)prediction = model.predict([X_teste])"},{"location":"aulas/IA/lab03/preco-notebook.html#exportando-o-modelo","title":"Exportando o Modelo\u00b6","text":"<p>Agora que conclu\u00edmos o treinamento do nosso modelo, \u00e9 hora de salv\u00e1-lo para que possamos reutiliz\u00e1-lo posteriormente. Isso nos permitir\u00e1 aplicar o modelo a novos dados sem precisar trein\u00e1-lo novamente, economizando tempo e recursos.</p>"},{"location":"aulas/IA/lab03/preco-notebook.html#regressao-polinomial","title":"Regress\u00e3o Polinomial\u00b6","text":"<p>$$ Y = A + BX + C X\u00b2 \\\\ $$ A, B e C s\u00e3o constantes que determinam a posi\u00e7\u00e3o e inclina\u00e7\u00e3o da curva, o 2 indica o grau do polin\u00f4mio. Para cada valor de X temos um Y associado.</p> <pre><code>Em machine learning aprendemos que uma Regress\u00e3o Polinomial \u00e9:</code></pre> <p>$$ Y_{predito} = \\beta_o + \\beta_1X + \\beta_2X\u00b2 \\\\ $$</p> <p>$ \\beta_o $ , $ \\beta_1 $ e $ \\beta_2 $ s\u00e3o par\u00e2metros que determinam o peso da rede. Para cada entrada $ X $ temos um $ Y_{predito} $ aproximado predito.</p> <p>Essa ideia se estende para polin\u00f4mio de graus maiores:</p> <p>$$ Y_{predito} = \\beta_o + \\beta_1X + \\beta_2X\u00b2 + ... + \\beta_nX^n\\\\ $$</p>"},{"location":"aulas/IA/lab03/preco-notebook.html#desafio-11","title":"Desafio 11\u00b6","text":"<p>Fa\u00e7a uma fun\u00e7\u00e3o que calcula a regress\u00e3o polinomial (basicamente colocar o codigo acima em uma fun\u00e7\u00e3o), agora fa\u00e7a um c\u00f3digo que chama essa fun\u00e7\u00e3o alterando o grau do polinomio de 2 at\u00e9 10, basicamente um loop for que chama a fun\u00e7\u00e3o criada.</p> <p>An\u00e1lise os resultados obtidos e determine qual o melhor grau polinomio do seu modelo.</p>"},{"location":"aulas/IA/lab03/regressao.html","title":"lab1","text":"In\u00a0[1]: Copied! <pre># Inicializ\u00e7\u00e3o das bibliotecas\n%matplotlib inline\n\nimport pandas as pd\nimport matplotlib.pyplot as plt\n</pre> # Inicializ\u00e7\u00e3o das bibliotecas %matplotlib inline  import pandas as pd import matplotlib.pyplot as plt  In\u00a0[15]: Copied! <pre>import pandas as pd\n\n# Carregando o dataset com o delimitador correto\ndf = pd.read_csv('housing.csv', delim_whitespace=True, header=None)\n\n# Atribuindo nomes \u00e0s colunas\ndf.columns = ['CRIM', 'ZN', 'INDUS', 'CHAS', 'NOX', 'RM', 'AGE', 'DIS', 'RAD', 'TAX', 'PTRATIO', 'B', 'LSTAT', 'MEDV']\n</pre> import pandas as pd  # Carregando o dataset com o delimitador correto df = pd.read_csv('housing.csv', delim_whitespace=True, header=None)  # Atribuindo nomes \u00e0s colunas df.columns = ['CRIM', 'ZN', 'INDUS', 'CHAS', 'NOX', 'RM', 'AGE', 'DIS', 'RAD', 'TAX', 'PTRATIO', 'B', 'LSTAT', 'MEDV'] In\u00a0[17]: Copied! <pre>df.head()\n</pre> df.head() Out[17]: CRIM ZN INDUS CHAS NOX RM AGE DIS RAD TAX PTRATIO B LSTAT MEDV 0 0.00632 18.0 2.31 0 0.538 6.575 65.2 4.0900 1 296.0 15.3 396.90 4.98 24.0 1 0.02731 0.0 7.07 0 0.469 6.421 78.9 4.9671 2 242.0 17.8 396.90 9.14 21.6 2 0.02729 0.0 7.07 0 0.469 7.185 61.1 4.9671 2 242.0 17.8 392.83 4.03 34.7 3 0.03237 0.0 2.18 0 0.458 6.998 45.8 6.0622 3 222.0 18.7 394.63 2.94 33.4 4 0.06905 0.0 2.18 0 0.458 7.147 54.2 6.0622 3 222.0 18.7 396.90 5.33 36.2 In\u00a0[18]: Copied! <pre># Mostra informa\u00e7\u00f5es sobre o dataframe em si\ndf.info()\n</pre> # Mostra informa\u00e7\u00f5es sobre o dataframe em si df.info() <pre>&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 506 entries, 0 to 505\nData columns (total 14 columns):\n #   Column   Non-Null Count  Dtype  \n---  ------   --------------  -----  \n 0   CRIM     506 non-null    float64\n 1   ZN       506 non-null    float64\n 2   INDUS    506 non-null    float64\n 3   CHAS     506 non-null    int64  \n 4   NOX      506 non-null    float64\n 5   RM       506 non-null    float64\n 6   AGE      506 non-null    float64\n 7   DIS      506 non-null    float64\n 8   RAD      506 non-null    int64  \n 9   TAX      506 non-null    float64\n 10  PTRATIO  506 non-null    float64\n 11  B        506 non-null    float64\n 12  LSTAT    506 non-null    float64\n 13  MEDV     506 non-null    float64\ndtypes: float64(12), int64(2)\nmemory usage: 55.5 KB\n</pre> In\u00a0[19]: Copied! <pre>df.describe()\n</pre> df.describe() Out[19]: CRIM ZN INDUS CHAS NOX RM AGE DIS RAD TAX PTRATIO B LSTAT MEDV count 506.000000 506.000000 506.000000 506.000000 506.000000 506.000000 506.000000 506.000000 506.000000 506.000000 506.000000 506.000000 506.000000 506.000000 mean 3.613524 11.363636 11.136779 0.069170 0.554695 6.284634 68.574901 3.795043 9.549407 408.237154 18.455534 356.674032 12.653063 22.532806 std 8.601545 23.322453 6.860353 0.253994 0.115878 0.702617 28.148861 2.105710 8.707259 168.537116 2.164946 91.294864 7.141062 9.197104 min 0.006320 0.000000 0.460000 0.000000 0.385000 3.561000 2.900000 1.129600 1.000000 187.000000 12.600000 0.320000 1.730000 5.000000 25% 0.082045 0.000000 5.190000 0.000000 0.449000 5.885500 45.025000 2.100175 4.000000 279.000000 17.400000 375.377500 6.950000 17.025000 50% 0.256510 0.000000 9.690000 0.000000 0.538000 6.208500 77.500000 3.207450 5.000000 330.000000 19.050000 391.440000 11.360000 21.200000 75% 3.677083 12.500000 18.100000 0.000000 0.624000 6.623500 94.075000 5.188425 24.000000 666.000000 20.200000 396.225000 16.955000 25.000000 max 88.976200 100.000000 27.740000 1.000000 0.871000 8.780000 100.000000 12.126500 24.000000 711.000000 22.000000 396.900000 37.970000 50.000000 In\u00a0[8]: Copied! <pre>## Sua resposta e seus gr\u00e1ficos para an\u00e1lisar..\n</pre> ## Sua resposta e seus gr\u00e1ficos para an\u00e1lisar..       In\u00a0[20]: Copied! <pre>#Vamos explorar um pouco uma matrix de correla\u00e7\u00e3o\n\nimport seaborn as sns \ncorrelation_matrix = df.corr().round(2)\n\nfig, ax = plt.subplots(figsize=(10,10))    \nsns.heatmap(data=correlation_matrix, annot=True, linewidths=.5, ax=ax)\n</pre> #Vamos explorar um pouco uma matrix de correla\u00e7\u00e3o  import seaborn as sns  correlation_matrix = df.corr().round(2)  fig, ax = plt.subplots(figsize=(10,10))     sns.heatmap(data=correlation_matrix, annot=True, linewidths=.5, ax=ax) Out[20]: <pre>&lt;Axes: &gt;</pre> In\u00a0[21]: Copied! <pre>df.plot.scatter('RM', 'MEDV')\n</pre> df.plot.scatter('RM', 'MEDV') Out[21]: <pre>&lt;Axes: xlabel='RM', ylabel='MEDV'&gt;</pre> In\u00a0[22]: Copied! <pre>df.plot.scatter('LSTAT', 'MEDV')\n</pre> df.plot.scatter('LSTAT', 'MEDV') Out[22]: <pre>&lt;Axes: xlabel='LSTAT', ylabel='MEDV'&gt;</pre> In\u00a0[23]: Copied! <pre># Vamos treinar nosso modelo com 2 dois atributos independentes\n# para predizer o valor de saida\nX = df[['LSTAT', 'RM']]   ### teste com duas entradas\n#X = df[['RM']]            ### teste com uma entrada\n#X = df.drop(['MEDV'], axis=1)     ### teste com todas as entradas\n\nY = df['MEDV']             \nprint(f\"Formato das tabelas de dados {X.shape} e saidas {Y.shape}\")\n</pre> # Vamos treinar nosso modelo com 2 dois atributos independentes # para predizer o valor de saida X = df[['LSTAT', 'RM']]   ### teste com duas entradas #X = df[['RM']]            ### teste com uma entrada #X = df.drop(['MEDV'], axis=1)     ### teste com todas as entradas  Y = df['MEDV']              print(f\"Formato das tabelas de dados {X.shape} e saidas {Y.shape}\") <pre>Formato das tabelas de dados (506, 2) e saidas (506,)\n</pre> In\u00a0[24]: Copied! <pre># Separamos 20% para o teste\nfrom sklearn.model_selection import train_test_split\n\nX_treino, X_teste, Y_treino, Y_teste = train_test_split(X, Y, test_size=0.2)\n\nprint(X_treino.shape)\nprint(X_teste.shape)\nprint(Y_treino.shape)\nprint(Y_teste.shape)\n</pre> # Separamos 20% para o teste from sklearn.model_selection import train_test_split  X_treino, X_teste, Y_treino, Y_teste = train_test_split(X, Y, test_size=0.2)  print(X_treino.shape) print(X_teste.shape) print(Y_treino.shape) print(Y_teste.shape) <pre>(404, 2)\n(102, 2)\n(404,)\n(102,)\n</pre> In\u00a0[25]: Copied! <pre>#Primeiras linhas do dataframe \nX_treino.head()\n</pre> #Primeiras linhas do dataframe  X_treino.head() Out[25]: LSTAT RM 378 23.69 6.380 312 11.72 6.023 480 10.74 6.242 48 30.81 5.399 359 12.67 6.112 In\u00a0[26]: Copied! <pre>Y_treino.head()\n</pre> Y_treino.head() Out[26]: <pre>378    13.1\n312    19.4\n480    23.0\n48     14.4\n359    22.6\nName: MEDV, dtype: float64</pre> In\u00a0[27]: Copied! <pre># Importa a biblioteca\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import mean_squared_error\n\n# Cria o modelo de regress\u00e3o \nlin_model = LinearRegression()\n\n# Cria o modelo de machine learning\nlin_model.fit(X_treino, Y_treino)\n</pre> # Importa a biblioteca from sklearn.linear_model import LinearRegression from sklearn.metrics import mean_squared_error  # Cria o modelo de regress\u00e3o  lin_model = LinearRegression()  # Cria o modelo de machine learning lin_model.fit(X_treino, Y_treino)    Out[27]: <pre>LinearRegression()</pre>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.\u00a0\u00a0LinearRegression?Documentation for LinearRegressioniFitted<pre>LinearRegression()</pre> <p>Pronto!! bora testar se esta funcionando....</p> In\u00a0[36]: Copied! <pre># Para obter as previs\u00f5es, basta chamar o m\u00e9todo predict()\ny_teste_predito = lin_model.predict(X_teste)\nprint(\"Predi\u00e7\u00e3o usando regress\u00e3o, retorna valores continuos: {}\".format(y_teste_predito))\n</pre> # Para obter as previs\u00f5es, basta chamar o m\u00e9todo predict() y_teste_predito = lin_model.predict(X_teste) print(\"Predi\u00e7\u00e3o usando regress\u00e3o, retorna valores continuos: {}\".format(y_teste_predito))  <pre>Predi\u00e7\u00e3o usando regress\u00e3o, retorna valores continuos: [20.26730472 30.46254362 24.8618173  32.43404913 39.86365469 23.66539013\n 20.77667386 29.75623863 30.44876087 18.5168171  19.63100525 18.74845677\n 23.7281014  27.56448461 22.52117732 18.46185252 22.38157688 26.86156941\n 20.6400214  19.98413697 33.09717059 19.85816854 32.53875855 32.57407067\n 31.32460254 20.38296853 -1.42097188 30.44060351 31.13876155 20.88665514\n 26.44421354 23.68892112 29.17773736 16.88751481 26.47090039 26.69899429\n 25.62037302 30.97988295 26.78880834 25.9065042  19.81451712 27.6467912\n 23.10809072  7.31666945 19.91170866 25.16501706 18.41082354 28.31491416\n 19.71012485 31.53337666 21.41108083 18.647106   18.79161952 21.85406815\n 29.78369494 28.11559716 32.00451181 19.20874148 19.60710514 25.48742742\n 33.17219328 37.93723556 18.13487736 19.68062523  8.94822295 19.71055637\n 36.87667587 16.22855265 32.12840062  8.63270666 40.77399223 18.15030821\n 37.36130782 35.56637856 22.41001584 20.43674263 16.88155149 20.54739459\n 26.7389648  24.91083941 21.49886199 18.11454897 29.67041747 15.20263957\n 11.35784948 36.23439232 20.13915265 16.54518163 30.86536289 13.68864763\n 20.81033789 31.06110293  9.95109888 23.66605564 18.38867028 21.75517654\n 14.85669305 25.86164138 23.90419415 33.09669227 25.29625217 20.97907392]\n</pre> In\u00a0[31]: Copied! <pre># Vamos avaliar os par\u00e2metros do nosso modelo\nprint('(A) Intercepto: ', lin_model.intercept_)\nprint('(B) Inclina\u00e7\u00e3o: ', lin_model.coef_)\n\n# Verificando a quantidade de coeficientes e exibindo a equa\u00e7\u00e3o correspondente\nif len(lin_model.coef_) &gt; 1:\n    print(f'Nossa equa\u00e7\u00e3o \u00e9: Y_pred = {lin_model.intercept_.round(2)} + {lin_model.coef_[0].round(2)} * X_LSTAT + {lin_model.coef_[1].round(2)} * X_RM')\nelse:\n    print(f'Nossa equa\u00e7\u00e3o \u00e9: Y_pred = {lin_model.intercept_.round(2)} + {lin_model.coef_[0].round(2)} * X_LSTAT')\n</pre> # Vamos avaliar os par\u00e2metros do nosso modelo print('(A) Intercepto: ', lin_model.intercept_) print('(B) Inclina\u00e7\u00e3o: ', lin_model.coef_)  # Verificando a quantidade de coeficientes e exibindo a equa\u00e7\u00e3o correspondente if len(lin_model.coef_) &gt; 1:     print(f'Nossa equa\u00e7\u00e3o \u00e9: Y_pred = {lin_model.intercept_.round(2)} + {lin_model.coef_[0].round(2)} * X_LSTAT + {lin_model.coef_[1].round(2)} * X_RM') else:     print(f'Nossa equa\u00e7\u00e3o \u00e9: Y_pred = {lin_model.intercept_.round(2)} + {lin_model.coef_[0].round(2)} * X_LSTAT')  <pre>(A) Intercepto:  -5.170015525018201\n(B) Inclina\u00e7\u00e3o:  [-0.57969707  5.57341034]\nNossa equa\u00e7\u00e3o \u00e9: Y_pred = -5.17 + -0.58 * X_LSTAT + 5.57 * X_RM\n</pre> In\u00a0[37]: Copied! <pre>import matplotlib.pyplot as plt\nimport numpy as np\n\n# Gr\u00e1fico de dispers\u00e3o para X_LSTAT vs Y_pred\nplt.figure(figsize=(12, 5))\n\n# Plot para X_LSTAT\nplt.subplot(1, 2, 1)\nplt.scatter(X_teste['LSTAT'], y_teste_predito, color='blue', alpha=0.6, s=50, label='Valores Preditos')\nplt.plot(X_teste['LSTAT'], lin_model.intercept_ + lin_model.coef_[0] * X_teste['LSTAT'], color='red', linestyle='--', label='Linha de Regress\u00e3o')\nplt.xlabel('% Status de Menor Classe (X_LSTAT)')\nplt.ylabel('Valor Predito (Y_pred)')\nplt.title('Rela\u00e7\u00e3o entre X_LSTAT e Y_pred')\nplt.legend()\n\n# Plot para X_RM\nplt.subplot(1, 2, 2)\nplt.scatter(X_teste['RM'], y_teste_predito, color='green', alpha=0.6, s=50, label='Valores Preditos')\nplt.plot(X_teste['RM'], lin_model.intercept_ + lin_model.coef_[1] * X_teste['RM'], color='red', linestyle='--', label='Linha de Regress\u00e3o')\nplt.xlabel('N\u00famero M\u00e9dio de Quartos (X_RM)')\nplt.ylabel('Valor Predito (Y_pred)')\nplt.title('Rela\u00e7\u00e3o entre X_RM e Y_pred')\nplt.legend()\n\nplt.tight_layout()\nplt.show()\n</pre> import matplotlib.pyplot as plt import numpy as np  # Gr\u00e1fico de dispers\u00e3o para X_LSTAT vs Y_pred plt.figure(figsize=(12, 5))  # Plot para X_LSTAT plt.subplot(1, 2, 1) plt.scatter(X_teste['LSTAT'], y_teste_predito, color='blue', alpha=0.6, s=50, label='Valores Preditos') plt.plot(X_teste['LSTAT'], lin_model.intercept_ + lin_model.coef_[0] * X_teste['LSTAT'], color='red', linestyle='--', label='Linha de Regress\u00e3o') plt.xlabel('% Status de Menor Classe (X_LSTAT)') plt.ylabel('Valor Predito (Y_pred)') plt.title('Rela\u00e7\u00e3o entre X_LSTAT e Y_pred') plt.legend()  # Plot para X_RM plt.subplot(1, 2, 2) plt.scatter(X_teste['RM'], y_teste_predito, color='green', alpha=0.6, s=50, label='Valores Preditos') plt.plot(X_teste['RM'], lin_model.intercept_ + lin_model.coef_[1] * X_teste['RM'], color='red', linestyle='--', label='Linha de Regress\u00e3o') plt.xlabel('N\u00famero M\u00e9dio de Quartos (X_RM)') plt.ylabel('Valor Predito (Y_pred)') plt.title('Rela\u00e7\u00e3o entre X_RM e Y_pred') plt.legend()  plt.tight_layout() plt.show()  In\u00a0[38]: Copied! <pre>from sklearn.metrics import r2_score, mean_squared_error,mean_absolute_error\nimport numpy as np\n\nprint(\"Soma dos Erros ao Quadrado (SSE): %2.f \" % np.sum((y_teste_predito - Y_teste)**2))\nprint(\"Erro Quadr\u00e1tico M\u00e9dio (MSE): %.2f\" % mean_squared_error(Y_teste, y_teste_predito))\nprint(\"Erro M\u00e9dio Absoluto (MAE): %.2f\" % mean_absolute_error(Y_teste, y_teste_predito))\nprint (\"Raiz do Erro Quadr\u00e1tico M\u00e9dio (RMSE): %.2f \" % np.sqrt(mean_squared_error(Y_teste, y_teste_predito)))\nprint(\"R2-score: %.2f\" % r2_score(y_teste_predito , Y_teste) )\n</pre> from sklearn.metrics import r2_score, mean_squared_error,mean_absolute_error import numpy as np  print(\"Soma dos Erros ao Quadrado (SSE): %2.f \" % np.sum((y_teste_predito - Y_teste)**2)) print(\"Erro Quadr\u00e1tico M\u00e9dio (MSE): %.2f\" % mean_squared_error(Y_teste, y_teste_predito)) print(\"Erro M\u00e9dio Absoluto (MAE): %.2f\" % mean_absolute_error(Y_teste, y_teste_predito)) print (\"Raiz do Erro Quadr\u00e1tico M\u00e9dio (RMSE): %.2f \" % np.sqrt(mean_squared_error(Y_teste, y_teste_predito))) print(\"R2-score: %.2f\" % r2_score(y_teste_predito , Y_teste) ) <pre>Soma dos Erros ao Quadrado (SSE): 3400 \nErro Quadr\u00e1tico M\u00e9dio (MSE): 33.34\nErro M\u00e9dio Absoluto (MAE): 3.90\nRaiz do Erro Quadr\u00e1tico M\u00e9dio (RMSE): 5.77 \nR2-score: 0.38\n</pre> In\u00a0[21]: Copied! <pre>## implemente sua sua solu\u00e7\u00e3o....\n</pre> ## implemente sua sua solu\u00e7\u00e3o....    In\u00a0[39]: Copied! <pre>import operator\n\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n\n# importa feature polinomial\nfrom sklearn.preprocessing import PolynomialFeatures\n\n#####----------- vou gerar alguns numeros aleat\u00f3rios ------------------\n\n#gerando numeros aleatorios, apenas para este exemplo\nnp.random.seed(42)\nx = 2 - 3 * np.random.normal(0, 1, 30)\ny = x - 3 * (x ** 2) + 0.8 * (x ** 3)+ 0.2 * (x ** 4) + np.random.normal(-20, 20, 30)\n\n# ajuste nos dados, pois estamos trabalhando com a numpy \nx = x[:, np.newaxis]\ny = y[:, np.newaxis]\n####---------------pronto j\u00e1 temos os dados para treinar -------------\n\n\n#----\u00c9 aqui que o seu c\u00f3digo muda ------------------------------------\n\n# Chama a fun\u00e7\u00e3o definindo o grau do polinomio e aplica o modelo\n\ngrau_poly = 1\npolynomial_features= PolynomialFeatures(degree = grau_poly)\nx_poly = polynomial_features.fit_transform(x)\n\n#----Pronto agora \u00e9 tudo como era antes, com regress\u00e3o linear\n\n\nmodel = LinearRegression()\nmodel.fit(x_poly, y)\ny_poly_pred = model.predict(x_poly)\n\n# M\u00e9trica de avalia\u00e7\u00e3o do modelo\nprint(\"Soma dos Erros ao Quadrado (SSE): %2.f \" % np.sum((y_poly_pred - y)**2))\nprint(\"Erro Quadr\u00e1tico M\u00e9dio (MSE): %.2f\" % mean_squared_error(y,y_poly_pred))\nprint(\"Erro M\u00e9dio Absoluto (MAE): %.2f\" % mean_absolute_error(y, y_poly_pred))\nprint (\"Raiz do Erro Quadr\u00e1tico M\u00e9dio (RMSE): %.2f \" % np.sqrt(mean_squared_error(y, y_poly_pred)))\nprint(\"R2-score: %.2f\" % r2_score(y,y_poly_pred) )\n\n\nplt.scatter(x, y, s=10)\n# ordena os valores de x antes de plotar\nsort_axis = operator.itemgetter(0)\nsorted_zip = sorted(zip(x,y_poly_pred), key=sort_axis)\nx, y_poly_pred = zip(*sorted_zip)\n\nplt.plot(x, y_poly_pred, color='r')\nplt.show()\n</pre> import operator  import numpy as np import matplotlib.pyplot as plt  from sklearn.linear_model import LinearRegression from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error  # importa feature polinomial from sklearn.preprocessing import PolynomialFeatures  #####----------- vou gerar alguns numeros aleat\u00f3rios ------------------  #gerando numeros aleatorios, apenas para este exemplo np.random.seed(42) x = 2 - 3 * np.random.normal(0, 1, 30) y = x - 3 * (x ** 2) + 0.8 * (x ** 3)+ 0.2 * (x ** 4) + np.random.normal(-20, 20, 30)  # ajuste nos dados, pois estamos trabalhando com a numpy  x = x[:, np.newaxis] y = y[:, np.newaxis] ####---------------pronto j\u00e1 temos os dados para treinar -------------   #----\u00c9 aqui que o seu c\u00f3digo muda ------------------------------------  # Chama a fun\u00e7\u00e3o definindo o grau do polinomio e aplica o modelo  grau_poly = 1 polynomial_features= PolynomialFeatures(degree = grau_poly) x_poly = polynomial_features.fit_transform(x)  #----Pronto agora \u00e9 tudo como era antes, com regress\u00e3o linear   model = LinearRegression() model.fit(x_poly, y) y_poly_pred = model.predict(x_poly)  # M\u00e9trica de avalia\u00e7\u00e3o do modelo print(\"Soma dos Erros ao Quadrado (SSE): %2.f \" % np.sum((y_poly_pred - y)**2)) print(\"Erro Quadr\u00e1tico M\u00e9dio (MSE): %.2f\" % mean_squared_error(y,y_poly_pred)) print(\"Erro M\u00e9dio Absoluto (MAE): %.2f\" % mean_absolute_error(y, y_poly_pred)) print (\"Raiz do Erro Quadr\u00e1tico M\u00e9dio (RMSE): %.2f \" % np.sqrt(mean_squared_error(y, y_poly_pred))) print(\"R2-score: %.2f\" % r2_score(y,y_poly_pred) )   plt.scatter(x, y, s=10) # ordena os valores de x antes de plotar sort_axis = operator.itemgetter(0) sorted_zip = sorted(zip(x,y_poly_pred), key=sort_axis) x, y_poly_pred = zip(*sorted_zip)  plt.plot(x, y_poly_pred, color='r') plt.show() <pre>Soma dos Erros ao Quadrado (SSE): 602124 \nErro Quadr\u00e1tico M\u00e9dio (MSE): 20070.81\nErro M\u00e9dio Absoluto (MAE): 104.66\nRaiz do Erro Quadr\u00e1tico M\u00e9dio (RMSE): 141.67 \nR2-score: 0.55\n</pre> In\u00a0[23]: Copied! <pre>## Implemente sua solu\u00e7\u00e3o\n</pre> ## Implemente sua solu\u00e7\u00e3o"},{"location":"aulas/IA/lab03/regressao.html#objetivos","title":"Objetivos\u00b6","text":"<ul> <li>Apresentar o conceito de Regress\u00e3o</li> <li>Apresentar e utilizar algoritmo de Regress\u00e3o linear</li> <li>Apresentar e utilizar Regress\u00e3o Polinomial</li> <li>Apresentar e discutir a matriz de correla\u00e7\u00e3o</li> <li>Apresentar uma intui\u00e7\u00e3o sobre m\u00e9tricas de avalia\u00e7\u00e3o (MSE, RMSE e $ R\u00b2 $ )</li> </ul>"},{"location":"aulas/IA/lab03/regressao.html#comecando","title":"Come\u00e7ando\u00b6","text":"<p>Sabemos que dentro de aprendizado supervisionado vamos trabalhar com dois tipos de problemas:</p> <ul> <li>Classifica\u00e7\u00e3o - (J\u00e1 conhecemos o KNN)</li> <li>Regress\u00e3o - (Objetivo de hoje)</li> </ul>"},{"location":"aulas/IA/lab03/regressao.html#uma-intuicao-sobre-problemas-que-envolvem-cada-um-deles","title":"Uma intui\u00e7\u00e3o sobre problemas que envolvem cada um deles:\u00b6","text":"<pre><code>    Classifica\u00e7\u00e3o --&gt; Resultados discretos (categ\u00f3ricos).\n    Regress\u00e3o --&gt; Resultados num\u00e9ricos e cont\u00ednuos.</code></pre>"},{"location":"aulas/IA/lab03/regressao.html#regressao-linear","title":"Regress\u00e3o linear\u00b6","text":"<p>\u00c9 uma t\u00e9cnica que consiste em representar um conjunto de dados por meio de uma reta.</p> <pre><code>Na matem\u00e1tica aprendemos que a equa\u00e7\u00e3o de uma reta \u00e9:</code></pre> <p>$$ Y = A + BX \\\\ $$ A e B s\u00e3o constantes que determinam a posi\u00e7\u00e3o e inclina\u00e7\u00e3o da reta. Para cada valor de X temos um Y associado.</p> <pre><code>Em machine learning aprendemos que uma Regress\u00e3o linear \u00e9:</code></pre> <p>$$ Y_{predito} = \\beta_o + \\beta_1X \\\\ $$</p> <p>$ \\beta_o $ e $ \\beta_1 $ s\u00e3o par\u00e2metros que determinam o peso e bias da rede. Para cada entrada $ X $ temos um $ Y_{predito} $ aproximado predito.</p> <p> </p> <p>Essa ideia se estende para mais de um par\u00e2metro independente, mas nesse caso n\u00e3o estamos associando a uma reta e sim a um plano ou hiperplano:</p> <p>$$ Y_{predito} = \\beta_o + \\beta_1X_1 + \\beta_2X_2 + ... + \\beta_nX_n\\\\ $$</p> <p> </p> <p>Em outras palavras, modelos de regress\u00e3o linear s\u00e3o intuitivos, f\u00e1ceis de interpretar e se ajustam aos dados razoavelmente bem em muitos problemas.</p>"},{"location":"aulas/IA/lab03/regressao.html#bora-la","title":"Bora l\u00e1!!\u00b6","text":"<p>Vamos juntos realizar um projeto, do come\u00e7o ao fim, usando regress\u00e3o.</p>"},{"location":"aulas/IA/lab03/regressao.html#definicao-do-problema","title":"Defini\u00e7\u00e3o do problema\u00b6","text":"<p>Vamos trabalhar com um dataset com informa\u00e7\u00f5es coletadas U.S Census Service (tipo IBGE americano) sobre habita\u00e7\u00e3o na \u00e1rea de Boston Mass.</p>"},{"location":"aulas/IA/lab03/regressao.html#faca-o-download-do-dataset-aqui-httpsdrivegooglecomfiled1jdbx09otyosdowzldify4ksapr23befiviewuspsharing","title":"Fa\u00e7a o download do dataset aqui: https://drive.google.com/file/d/1JDbx09otYOsDOWZlDiFY4ksaPr23befi/view?usp=sharing\u00b6","text":"<p>informa\u00e7\u00e3o importante sobre o significado de cada um dos atributos</p> <ol> <li><p>Attribute Information:</p> <ol> <li>CRIM      per capita crime rate by town</li> <li>ZN        proportion of residential land zoned for lots over 25,000 sq.ft.</li> <li>INDUS     proportion of non-retail business acres per town</li> <li>CHAS      Charles River dummy variable (= 1 if tract bounds river; 0 otherwise)</li> <li>NOX       nitric oxides concentration (parts per 10 million)</li> <li>RM        average number of rooms per dwelling</li> <li>AGE       proportion of owner-occupied units built prior to 1940</li> <li>DIS       weighted distances to five Boston employment centres</li> <li>RAD       index of accessibility to radial highways</li> <li>TAX      full-value property-tax rate per $10,000</li> <li>PTRATIO  pupil-teacher ratio by town</li> <li>B        1000(Bk - 0.63)^2 where Bk is the proportion of blacks by town</li> <li>LSTAT    % lower status of the population</li> <li>MEDV     Median value of owner-occupied homes in $1000's</li> </ol> <p>Queremos desenvolver um modelo capaz de predizer o valor de um imovel em Boston.</p> </li> </ol>"},{"location":"aulas/IA/lab03/regressao.html#desafio-1","title":"Desafio 1\u00b6","text":"<p>Do ponto de vista de machine learning, que problema \u00e9 esse:</p> <pre><code>Aprendizado supervisionado, n\u00e3o-supervisionado ou aprendizado por refor\u00e7o?</code></pre> <p>R:</p> <pre><code>Classifica\u00e7\u00e3o, regress\u00e3o ou clusteriza\u00e7\u00e3o?</code></pre> <p>R:</p>"},{"location":"aulas/IA/lab03/regressao.html#desafio-2","title":"Desafio 2\u00b6","text":"<p>Use os metodos info() e describe() para exibir as informa\u00e7\u00f5es do dataframe e responda:</p> <p>Existe dados faltantes?</p> <p>Qual o tamanho do dataset, quantas linhas e quantas colunas?</p>"},{"location":"aulas/IA/lab03/regressao.html#desafio-3","title":"Desafio 3\u00b6","text":"<p>Aplique os m\u00e9todos que achar conveniente (vimos algumas op\u00e7\u00f5es na \u00faltima aula) para visualizar os dados de forma gr\u00e1fica.</p>"},{"location":"aulas/IA/lab03/regressao.html#desafio-4","title":"Desafio 4\u00b6","text":"<p>Analisando a matriz de correla\u00e7\u00e3o acima responda:</p> <p>Qual feature possue a maior correla\u00e7\u00e3o positiva com o target?</p> <p>Qual feature possue a maior correla\u00e7\u00e3o negativa com o target?</p>"},{"location":"aulas/IA/lab03/regressao.html#pare","title":"PARE!!!\u00b6","text":"<p>A an\u00e1lise feita no desafio 2 e 3 \u00e9 uma das etapas mais importantes. Caso voc\u00ea tenha pulado essa etapa, volte e fa\u00e7a suas an\u00e1lises.</p> <p>Com essa etapa conclu\u00edda, vamos criar um sub-dataset com os atributos que ser\u00e3o utilizados.</p>"},{"location":"aulas/IA/lab03/regressao.html#dividindo-os-dados-em-conjunto-de-treinamento-e-de-testes","title":"Dividindo os dados em conjunto de treinamento e de testes\u00b6","text":"<p>Dividir nosso dataset em dois conjuntos de dados.</p> <pre><code>Treinamento - Representa 80% das amostras do conjunto de dados original,\nTeste - com 20% das amostras</code></pre> <p>Vamos escolher aleatoriamente algumas amostras do conjunto original. Isto pode ser feito com Scikit-Learn usando a fun\u00e7\u00e3o train_test_split()</p> <p>scikit-learn Caso ainda n\u00e3o tenha instalado, no terminal digite:</p> <ul> <li>pip install scikit-learn</li> </ul>"},{"location":"aulas/IA/lab03/regressao.html#chegou-a-hora-de-aplicar-o-modelo-preditivo","title":"Chegou a hora de aplicar o modelo preditivo\u00b6","text":"<p>Treinar um modelo no python \u00e9 simples se usar o Scikit-Learn. Treinar um modelo no Scikit-Learn \u00e9 simples: basta criar o regressor, e chamar o m\u00e9todo fit().</p> <p>Uma observa\u00e7\u00e3o sobre a sintaxe dos classificadores do <code>scikit-learn</code></p> <ul> <li>O m\u00e9todo <code>fit(X,Y)</code> recebe uma matriz ou dataframe X onde cada linha \u00e9 uma amostra de aprendizado, e um array Y contendo as sa\u00eddas esperadas do classificador, seja na forma de texto ou de inteiros</li> <li>O m\u00e9todo <code>predict(X)</code> recebe uma matriz ou dataframe X onde cada linha \u00e9 uma amostra de teste, retornando um array de classes</li> </ul>"},{"location":"aulas/IA/lab03/regressao.html#avaliando-o-modelo-treinado","title":"Avaliando o modelo treinado\u00b6","text":"<p>Vamos colocar alguns valores e ver a predi\u00e7\u00e3o do classificador.</p>"},{"location":"aulas/IA/lab03/regressao.html#desafio-5","title":"Desafio 5\u00b6","text":"<p>Refa\u00e7a o notebook substituindo o algoritmo de regress\u00e3o linear por outro algoritmo de regress\u00e3o e compare os resultados obtidos.</p> <p>Sugest\u00e3o de alguns algoritmos de ML para problemas de regress\u00e3o:</p> Nome Vantagem Desvantagem Exemplo sklearn Regress\u00e3o Linear F\u00e1cil de entender e implementar Pode n\u00e3o ser adequado para problemas mais complexos from sklearn.linear_model import LinearRegressionmodel = LinearRegression()model.fit(X, y)prediction = model.predict([X_teste]) \u00c1rvores de decis\u00e3o F\u00e1cil de entender e visualizar Pode levar a overfitting se a \u00e1rvore for muito grande from sklearn.tree import DecisionTreeRegressormodel = DecisionTreeRegressor()model.fit(X, y)prediction = model.predict([X_teste]) Random Forest Mais robusto e geralmente mais preciso do que uma \u00fanica \u00e1rvore de decis\u00e3o Pode ser mais lento e mais dif\u00edcil de ajustar from sklearn.ensemble import RandomForestRegressormodel = RandomForestRegressor(n_estimators=100)model.fit(X, y)prediction = model.predict([X_teste]) Support Vector Regression (SVR) Lida bem com dados multidimensionais e n\u00e3o lineares Pode ser dif\u00edcil de escolher o kernel correto e ajustar os hiperpar\u00e2metros from sklearn.svm import SVRmodel = SVR(kernel='rbf')model.fit(X, y)prediction = model.predict([X_teste]) Gradient Boosting Preciso e lida bem com dados multidimensionais e n\u00e3o lineares Pode ser mais lento e mais dif\u00edcil de ajustar from sklearn.ensemble import GradientBoostingRegressormodel = GradientBoostingRegressor(n_estimators=100)model.fit(X, y)prediction = model.predict([X_teste])"},{"location":"aulas/IA/lab03/regressao.html#regressao-polinomial","title":"Regress\u00e3o Polinomial\u00b6","text":"<p>$$ Y = A + BX + C X\u00b2 \\\\ $$ A, B e C s\u00e3o constantes que determinam a posi\u00e7\u00e3o e inclina\u00e7\u00e3o da curva, o 2 indica o grau do polin\u00f4mio. Para cada valor de X temos um Y associado.</p> <pre><code>Em machine learning aprendemos que uma Regress\u00e3o Polinomial \u00e9:</code></pre> <p>$$ Y_{predito} = \\beta_o + \\beta_1X + \\beta_2X\u00b2 \\\\ $$</p> <p>$ \\beta_o $ , $ \\beta_1 $ e $ \\beta_2 $ s\u00e3o par\u00e2metros que determinam o peso da rede. Para cada entrada $ X $ temos um $ Y_{predito} $ aproximado predito.</p> <p>Essa ideia se estende para polin\u00f4mio de graus maiores:</p> <p>$$ Y_{predito} = \\beta_o + \\beta_1X + \\beta_2X\u00b2 + ... + \\beta_nX^n\\\\ $$</p>"},{"location":"aulas/IA/lab03/regressao.html#desafio-6","title":"Desafio 6\u00b6","text":"<p>Fa\u00e7a uma fun\u00e7\u00e3o que calcula a regress\u00e3o polinomial (basicamente colocar o codigo acima em uma fun\u00e7\u00e3o), agora fa\u00e7a um c\u00f3digo que chama essa fun\u00e7\u00e3o alterando o grau do polinomio de 2 at\u00e9 10, basicamente um loop for que chama a fun\u00e7\u00e3o criada.</p> <p>An\u00e1lise os resultados obtidos e determine qual o melhor grau polinomio do seu modelo.</p>"},{"location":"aulas/IA/lab04/dicasDePreprocessamento.html","title":"Pr\u00e9-processamento","text":"<p>Exemplo: Vamos criar um lista com 3 atributos e vamos normalizar.</p> <ul> <li>Atributos:<ul> <li>altura (cm)</li> <li>massa (Kg)</li> <li>idade (anos)</li> </ul> </li> </ul> In\u00a0[1]: Copied! <pre>import numpy as np\nimport pandas as pd\n\ncols = ['altura (cm)', 'massa (kg)', 'idade (anos)']\ndf = pd.DataFrame(np.array([\n                            [170, 90, 20], # altura (cm), massa (Kg), idade (anos)\n                            [168, 55, 33],\n                            [173, 84, 57],\n                            [189, 98, 41]\n                        ]),columns=cols)\n\ndf.head()                  \n</pre> import numpy as np import pandas as pd  cols = ['altura (cm)', 'massa (kg)', 'idade (anos)'] df = pd.DataFrame(np.array([                             [170, 90, 20], # altura (cm), massa (Kg), idade (anos)                             [168, 55, 33],                             [173, 84, 57],                             [189, 98, 41]                         ]),columns=cols)  df.head()                   Out[1]: altura (cm) massa (kg) idade (anos) 0 170 90 20 1 168 55 33 2 173 84 57 3 189 98 41 <p>No nosso exemplo vamos usar o m\u00e9todo min-m\u00e1x:</p> <p>$$ valor_{normalizado}=\\dfrac{valor - min_{valores}}{(max_{valores} - min_{valores})}(max_{feature_range} - min_{feature_range}) + min_{feature_range} $$</p> In\u00a0[2]: Copied! <pre>from sklearn.preprocessing import MinMaxScaler\n\n#Cria o objeto da classe MinMaxScaler\nscaler_minmax = MinMaxScaler(feature_range=(0,1))\n\nscaled_data = scaler_minmax.fit_transform(df[cols])\n\nscaled_data\n</pre> from sklearn.preprocessing import MinMaxScaler  #Cria o objeto da classe MinMaxScaler scaler_minmax = MinMaxScaler(feature_range=(0,1))  scaled_data = scaler_minmax.fit_transform(df[cols])  scaled_data Out[2]: <pre>array([[0.0952381 , 0.81395349, 0.        ],\n       [0.        , 0.        , 0.35135135],\n       [0.23809524, 0.6744186 , 1.        ],\n       [1.        , 1.        , 0.56756757]])</pre> <p>Agora que os dados j\u00e1 est\u00e3o normalizados, podemos aplicar est\u00e1 transforma\u00e7\u00e3o em novos dados inseridos pelos usuario. Para isso, basta usar a fun\u00e7\u00e3o <code>transform()</code> do scaler j\u00e1 treinado.</p> In\u00a0[3]: Copied! <pre># Dados definidos pelo usu\u00e1rio\nnovos_dados = pd.DataFrame({'altura (cm)': [180, 90, 30],\n                            'massa (kg)': [185, 80, 40],\n                            'idade (anos)': [165, 57, 25]})\n# Aplicando o scaler nos novos dados\nscaled_novos_dados = scaler_minmax.transform(novos_dados)\n\nprint(scaled_novos_dados)\n</pre> # Dados definidos pelo usu\u00e1rio novos_dados = pd.DataFrame({'altura (cm)': [180, 90, 30],                             'massa (kg)': [185, 80, 40],                             'idade (anos)': [165, 57, 25]}) # Aplicando o scaler nos novos dados scaled_novos_dados = scaler_minmax.transform(novos_dados)  print(scaled_novos_dados) <pre>[[ 0.57142857  3.02325581  3.91891892]\n [-3.71428571  0.58139535  1.        ]\n [-6.57142857 -0.34883721  0.13513514]]\n</pre> <p>Outra t\u00e9cnica muito utilzada \u00e9 o <code>StandardScaler</code> que normaliza valores com m\u00e9dia 0 e desvio padr\u00e3o igual a 1.</p> In\u00a0[4]: Copied! <pre>cols = ['altura (cm)', 'massa (kg)', 'idade (anos)']\ndf = pd.DataFrame(np.array([\n                            [170, 90, 20], # altura (cm), massa (Kg), idade (anos)\n                            [168, 55, 33],\n                            [173, 84, 57],\n                            [189, 98, 41]\n                        ]),columns=cols)\n\ndf.head() \n\nfrom sklearn.preprocessing import StandardScaler\n\n#Cria o objeto da classe standardScaler\nscaler_standard = StandardScaler()\n\nscaled_data = scaler_standard.fit_transform(df[cols])\n\nscaled_data\n</pre> cols = ['altura (cm)', 'massa (kg)', 'idade (anos)'] df = pd.DataFrame(np.array([                             [170, 90, 20], # altura (cm), massa (Kg), idade (anos)                             [168, 55, 33],                             [173, 84, 57],                             [189, 98, 41]                         ]),columns=cols)  df.head()   from sklearn.preprocessing import StandardScaler  #Cria o objeto da classe standardScaler scaler_standard = StandardScaler()  scaled_data = scaler_standard.fit_transform(df[cols])  scaled_data Out[4]: <pre>array([[-0.60412209,  0.50853555, -1.32415683],\n       [-0.84577093, -1.648888  , -0.35435183],\n       [-0.24164884,  0.13869151,  1.4360574 ],\n       [ 1.69154186,  1.00166093,  0.24245125]])</pre> <p>Da mesma forma que o anterior, podemos aplicar est\u00e1 transforma\u00e7\u00e3o em novos dados inseridos pelos usuario. Para isso, basta usar a fun\u00e7\u00e3o transform() do scaler j\u00e1 treinado.</p> In\u00a0[5]: Copied! <pre># Dados definidos pelo usu\u00e1rio\nnovos_dados2 = pd.DataFrame({'altura (cm)': [180, 90, 30],\n                            'massa (kg)': [185, 80, 40],\n                            'idade (anos)': [165, 57, 25]})\n# Aplicando o scaler nos novos dados\nscaled_novos_dados2 = scaler_standard.transform(novos_dados2)\n\nprint(scaled_novos_dados2)\n</pre> # Dados definidos pelo usu\u00e1rio novos_dados2 = pd.DataFrame({'altura (cm)': [180, 90, 30],                             'massa (kg)': [185, 80, 40],                             'idade (anos)': [165, 57, 25]}) # Aplicando o scaler nos novos dados scaled_novos_dados2 = scaler_standard.transform(novos_dados2)  print(scaled_novos_dados2) <pre>[[  0.60412209   6.36439947   9.49289895]\n [-10.27007559  -0.10787118   1.4360574 ]\n [-17.51954071  -2.57349809  -0.9511549 ]]\n</pre> In\u00a0[6]: Copied! <pre># transforma\u00e7\u00f5es diferentes em no mesmo dataset\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.preprocessing import StandardScaler\n\n\ncols = ['altura', 'massa', 'idade']\ndf = pd.DataFrame(np.array([\n                            [170, 90, 20], # altura (cm), massa (Kg), idade (anos)\n                            [168, 55, 33],\n                            [173, 84, 57],\n                            [189, 98, 41]\n                        ]),columns=cols)\n\n#Cria o objeto da classe standardScaler e MinMaxScaler\nscaler_standard = StandardScaler()\nscaler_minmax = MinMaxScaler(feature_range=(0,1))\n\n# Aplica as transforma\u00e7\u00f5es\nscaled_standard = scaler_standard.fit_transform(df[['altura']])\nscaled_minmax = scaler_minmax.fit_transform(df[['massa']])\n\n# atualiza o valor e mostra o resultado\ndf[['altura']] = scaled_standard\ndf[['massa']] = scaled_minmax\n\ndf.head()\n</pre> # transforma\u00e7\u00f5es diferentes em no mesmo dataset from sklearn.preprocessing import MinMaxScaler from sklearn.preprocessing import StandardScaler   cols = ['altura', 'massa', 'idade'] df = pd.DataFrame(np.array([                             [170, 90, 20], # altura (cm), massa (Kg), idade (anos)                             [168, 55, 33],                             [173, 84, 57],                             [189, 98, 41]                         ]),columns=cols)  #Cria o objeto da classe standardScaler e MinMaxScaler scaler_standard = StandardScaler() scaler_minmax = MinMaxScaler(feature_range=(0,1))  # Aplica as transforma\u00e7\u00f5es scaled_standard = scaler_standard.fit_transform(df[['altura']]) scaled_minmax = scaler_minmax.fit_transform(df[['massa']])  # atualiza o valor e mostra o resultado df[['altura']] = scaled_standard df[['massa']] = scaled_minmax  df.head() Out[6]: altura massa idade 0 -0.604122 0.813953 20 1 -0.845771 0.000000 33 2 -0.241649 0.674419 57 3 1.691542 1.000000 41 In\u00a0[7]: Copied! <pre>### seu c\u00f3digo aqui.....\n</pre> ### seu c\u00f3digo aqui.....      In\u00a0[8]: Copied! <pre>import numpy as np\nimport pandas as pd\n\ncols = ['altura (cm)', 'massa (kg)', 'qualificacao']\ndf = pd.DataFrame(np.array([\n                            [170, 90, \"junior\"], # altura (cm), massa (Kg), g\u00eanero (f/m)\n                            [168, 55, \"pleno\"],\n                            [173, 84, \"junior\"],\n                            [189, 98, \"senior\"]\n                        ]),columns=cols)\n\ndf.head()\n</pre> import numpy as np import pandas as pd  cols = ['altura (cm)', 'massa (kg)', 'qualificacao'] df = pd.DataFrame(np.array([                             [170, 90, \"junior\"], # altura (cm), massa (Kg), g\u00eanero (f/m)                             [168, 55, \"pleno\"],                             [173, 84, \"junior\"],                             [189, 98, \"senior\"]                         ]),columns=cols)  df.head() Out[8]: altura (cm) massa (kg) qualificacao 0 170 90 junior 1 168 55 pleno 2 173 84 junior 3 189 98 senior In\u00a0[9]: Copied! <pre>from sklearn.preprocessing import LabelEncoder\n\n#Cria o objeto labelEncoder\nlabelencoder = LabelEncoder()\n\n# treina\nlabelencoder.fit(df['qualificacao'])\n# aplica transforma\u00e7\u00e3o\ndf['qualificacao'] = labelencoder.transform(df['qualificacao'])\n\n# ou treina e aplica no mesmo comando\n#df['qualificacao'] = labelencoder.fit_transform(df['qualificacao'])\ndf.head()\n</pre> from sklearn.preprocessing import LabelEncoder  #Cria o objeto labelEncoder labelencoder = LabelEncoder()  # treina labelencoder.fit(df['qualificacao']) # aplica transforma\u00e7\u00e3o df['qualificacao'] = labelencoder.transform(df['qualificacao'])  # ou treina e aplica no mesmo comando #df['qualificacao'] = labelencoder.fit_transform(df['qualificacao']) df.head() Out[9]: altura (cm) massa (kg) qualificacao 0 170 90 0 1 168 55 1 2 173 84 0 3 189 98 2 In\u00a0[10]: Copied! <pre>novos_dados2 = pd.DataFrame({'qualificao': [\"junior\", \"pleno\", \"junior\",\"senior\",\"senior\"]})\nencoded_data = labelencoder.transform(novos_dados2)\n\nprint('qualifica\u00e7\u00e3o codificada:', encoded_data)\n\n# para voltar aos atributos originais\n\nprint(labelencoder.inverse_transform(encoded_data) )\n</pre> novos_dados2 = pd.DataFrame({'qualificao': [\"junior\", \"pleno\", \"junior\",\"senior\",\"senior\"]}) encoded_data = labelencoder.transform(novos_dados2)  print('qualifica\u00e7\u00e3o codificada:', encoded_data)  # para voltar aos atributos originais  print(labelencoder.inverse_transform(encoded_data) ) <pre>qualifica\u00e7\u00e3o codificada: [0 1 0 2 2]\n['junior' 'pleno' 'junior' 'senior' 'senior']\n</pre> <pre>c:\\Users\\junior\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  return f(*args, **kwargs)\n</pre> <p>O problema aqui \u00e9 que, uma vez que existem n\u00fameros diferentes na mesma coluna, o modelo interpretar\u00e1 mal os dados como estando em algum tipo de ordem, 0 &lt;1 &lt;2.</p> <p>Voc\u00ea como desenvolvedor deve estar atento a este ponto e saber se faz sentido ou n\u00e3o, note que para qualifica\u00e7\u00e3o n\u00e3o tem problema, logo, este n\u00e3o \u00e9 o caso.</p> <p>Caso exista algum problema desta natureza, como um atributo genero, estado..., pode ser util usar One Hot Encoder.</p> In\u00a0[11]: Copied! <pre>import numpy as np\nimport pandas as pd\n\ncols = ['altura (cm)', 'massa (kg)', 'qualificacao']\ndf = pd.DataFrame(np.array([\n                            [170, 90, \"junior\"], # altura (cm), massa (Kg), g\u00eanero (f/m)\n                            [168, 55, \"pleno\"],\n                            [173, 84, \"junior\"],\n                            [189, 98, \"senior\"]\n                        ]),columns=cols)\n\ndf.head()\n</pre> import numpy as np import pandas as pd  cols = ['altura (cm)', 'massa (kg)', 'qualificacao'] df = pd.DataFrame(np.array([                             [170, 90, \"junior\"], # altura (cm), massa (Kg), g\u00eanero (f/m)                             [168, 55, \"pleno\"],                             [173, 84, \"junior\"],                             [189, 98, \"senior\"]                         ]),columns=cols)  df.head() Out[11]: altura (cm) massa (kg) qualificacao 0 170 90 junior 1 168 55 pleno 2 173 84 junior 3 189 98 senior In\u00a0[12]: Copied! <pre>from sklearn.preprocessing import OneHotEncoder\n\nohe = OneHotEncoder()\n\nponte_ohe = ohe.fit_transform(df[['qualificacao']]).toarray()\n\nponte_ohe\n</pre> from sklearn.preprocessing import OneHotEncoder  ohe = OneHotEncoder()  ponte_ohe = ohe.fit_transform(df[['qualificacao']]).toarray()  ponte_ohe Out[12]: <pre>array([[1., 0., 0.],\n       [0., 1., 0.],\n       [1., 0., 0.],\n       [0., 0., 1.]])</pre> In\u00a0[13]: Copied! <pre>#transforma o o np.arry em um dataframe\nponte_ohe = pd.DataFrame(ponte_ohe,columns=[\"qualificacao\"+str(int(i)) for i in range(df.shape[1])])\n\n#adiciona as novas colunas ao dataframe original\ndf = pd.concat([df,ponte_ohe], axis=1)\n\ndf.head()\n</pre> #transforma o o np.arry em um dataframe ponte_ohe = pd.DataFrame(ponte_ohe,columns=[\"qualificacao\"+str(int(i)) for i in range(df.shape[1])])  #adiciona as novas colunas ao dataframe original df = pd.concat([df,ponte_ohe], axis=1)  df.head() Out[13]: altura (cm) massa (kg) qualificacao qualificacao0 qualificacao1 qualificacao2 0 170 90 junior 1.0 0.0 0.0 1 168 55 pleno 0.0 1.0 0.0 2 173 84 junior 1.0 0.0 0.0 3 189 98 senior 0.0 0.0 1.0 In\u00a0[14]: Copied! <pre># faz o drop da coluna original qualificacao\n\ndf = df.drop([\"qualificacao\"], axis=1)\n\ndf.head()\n</pre> # faz o drop da coluna original qualificacao  df = df.drop([\"qualificacao\"], axis=1)  df.head() Out[14]: altura (cm) massa (kg) qualificacao0 qualificacao1 qualificacao2 0 170 90 1.0 0.0 0.0 1 168 55 0.0 1.0 0.0 2 173 84 1.0 0.0 0.0 3 189 98 0.0 0.0 1.0 <p>Note que agora temos a adi\u00e7\u00e3o de 3 novas colunas, onde cada uma corresponde a uma classifica\u00e7\u00e3o do atributo (\"junior\", \"pleno\", \"senior\")</p> In\u00a0[15]: Copied! <pre>##### seu c\u00f3digo aqui........\n</pre> ##### seu c\u00f3digo aqui........        <ul> <li><p>O PCA \u00e9 uma transforma\u00e7\u00e3o linear, ou seja, multiplica os vetores de atributos de entradas de N posi\u00e7\u00f5es por uma matriz com MxN, com M \u2264 N, resultando em um novo vetor de N dimens\u00f5es</p> </li> <li><p>O elemento que se destaca \u00e9 a da vari\u00e2ncia</p> </li> <li><p>Essa transforma\u00e7\u00e3o \u00e9 obtida por meio dos vetores de treinamento. A redu\u00e7\u00e3o na dimensionalidade \u00e9 controlada pelo par\u00e2metro que define a porcentagem de variabilidade que ser\u00e1 mantida nos novos dados</p> </li> <li><p>No Python, fazemos:</p> </li> </ul> In\u00a0[16]: Copied! <pre>from sklearn.decomposition import PCA\n\nmedidas_pca = PCA(0.5).fit_transform(df) # Mantem 50% de variabilidade\nprint(medidas_pca)\n\nprint(\"shape original: \" , df.shape, \"shape PCA: \" ,  medidas_pca.shape)\n</pre> from sklearn.decomposition import PCA  medidas_pca = PCA(0.5).fit_transform(df) # Mantem 50% de variabilidade print(medidas_pca)  print(\"shape original: \" , df.shape, \"shape PCA: \" ,  medidas_pca.shape)   <pre>[[ -5.81469106]\n [ 27.45356145]\n [ -1.35358402]\n [-20.28528637]]\nshape original:  (4, 5) shape PCA:  (4, 1)\n</pre> <ul> <li>Cada linha nessa matriz corresponde a uma vetor com N dimens\u00f5es, com um significado especial, denominado de auto-vetor</li> <li>No caso dos vetores serem imagens, essas \u201cauto-imagens\u201d guardam caracter\u00edsticas que ser\u00e3o usadas para identificar as imagens de teste</li> </ul> In\u00a0[17]: Copied! <pre>#Instale os pacotes e faz o download dos arquivos, se ja estiver na pasta n\u00e3o precisa rodar essa celula.\n\n#!pip3 install --user python-mnist\n#!pip install wget\n\n\nimport wget\nwget.download('http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz')\nwget.download('http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz')\nwget.download('http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz')\nwget.download('http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz')\n</pre> #Instale os pacotes e faz o download dos arquivos, se ja estiver na pasta n\u00e3o precisa rodar essa celula.  #!pip3 install --user python-mnist #!pip install wget   import wget wget.download('http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz') wget.download('http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz') wget.download('http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz') wget.download('http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz') Out[17]: <pre>'t10k-labels-idx1-ubyte.gz'</pre> In\u00a0[18]: Copied! <pre>import time\nimport numpy as np\n# API MNIST\nfrom mnist import MNIST\n\nt0 = time.time()\n\n# Importa os dados do dieret\u00f3rio local\nmndata = MNIST('.')\n# Habilita abrir arquivos compactados\nmndata.gz = True \n\n# Carrega os dados de treinamento\nentradas_treino, classes_treino = mndata.load_training()\n# Carrega os dados de treinamento\nentradas_teste, classes_teste = mndata.load_testing()\n\n#Transformando em array do numpy\nentradas_treino = np.array(entradas_treino)\nclasses_treino = np.array(classes_treino)\nentradas_teste = np.array(entradas_teste)\nclasses_teste = np.array(classes_teste)\n\ndados_reduzidos = False\n\nprint(\"Tempo para carregamento das imagens: {}s\".format(time.time()-t0))\n\nprint(\"Dimens\u00f5es da matriz dos dados de treinamento: \", entradas_treino.shape)\nprint(\"Dimens\u00f5es da matriz dos dados de teste: \", entradas_teste.shape)\n</pre> import time import numpy as np # API MNIST from mnist import MNIST  t0 = time.time()  # Importa os dados do dieret\u00f3rio local mndata = MNIST('.') # Habilita abrir arquivos compactados mndata.gz = True   # Carrega os dados de treinamento entradas_treino, classes_treino = mndata.load_training() # Carrega os dados de treinamento entradas_teste, classes_teste = mndata.load_testing()  #Transformando em array do numpy entradas_treino = np.array(entradas_treino) classes_treino = np.array(classes_treino) entradas_teste = np.array(entradas_teste) classes_teste = np.array(classes_teste)  dados_reduzidos = False  print(\"Tempo para carregamento das imagens: {}s\".format(time.time()-t0))  print(\"Dimens\u00f5es da matriz dos dados de treinamento: \", entradas_treino.shape) print(\"Dimens\u00f5es da matriz dos dados de teste: \", entradas_teste.shape)  <pre>Tempo para carregamento das imagens: 14.753993034362793s\nDimens\u00f5es da matriz dos dados de treinamento:  (60000, 784)\nDimens\u00f5es da matriz dos dados de teste:  (10000, 784)\n</pre> In\u00a0[19]: Copied! <pre># Fun\u00e7\u00e3o que visualiza a linha lin da matriz\nimport matplotlib.pyplot as plt\nimport math\ndef visualiza_linha_mnist(matriz, lin):\n  size = int(math.sqrt(matriz.shape[1]))\n  img = np.reshape(matriz[lin], (size, size))\n  plt.imshow(img, cmap=\"gray\")\n  \n# Visualiza\u00e7\u00e3o da linha 0\nvisualiza_linha_mnist(entradas_treino, 0)\nplt.show()\n</pre> # Fun\u00e7\u00e3o que visualiza a linha lin da matriz import matplotlib.pyplot as plt import math def visualiza_linha_mnist(matriz, lin):   size = int(math.sqrt(matriz.shape[1]))   img = np.reshape(matriz[lin], (size, size))   plt.imshow(img, cmap=\"gray\")    # Visualiza\u00e7\u00e3o da linha 0 visualiza_linha_mnist(entradas_treino, 0) plt.show() In\u00a0[20]: Copied! <pre>from sklearn.preprocessing import StandardScaler\n# PCA\nfrom sklearn.decomposition import PCA\n\nt0 = time.time()\n\nnormalizador = StandardScaler()\nredutor_dim = PCA(0.85)\n\nentradas_treino_norm = normalizador.fit_transform(entradas_treino)\nentradas_treino_norm = redutor_dim.fit_transform(entradas_treino_norm)\n\nentradas_teste_norm = normalizador.transform(entradas_teste)\nentradas_teste_norm = redutor_dim.transform(entradas_teste_norm)\n\nprint(\"Tempo para o processamento (normaliza\u00e7\u00e3o + PCA) das imagens: {}s\".format(time.time()-t0))\nprint(\"Novas dimensoes das matrizes de dados e classes (labels) de treinamento\")\nprint(entradas_treino_norm.shape, entradas_teste_norm.shape)\n</pre> from sklearn.preprocessing import StandardScaler # PCA from sklearn.decomposition import PCA  t0 = time.time()  normalizador = StandardScaler() redutor_dim = PCA(0.85)  entradas_treino_norm = normalizador.fit_transform(entradas_treino) entradas_treino_norm = redutor_dim.fit_transform(entradas_treino_norm)  entradas_teste_norm = normalizador.transform(entradas_teste) entradas_teste_norm = redutor_dim.transform(entradas_teste_norm)  print(\"Tempo para o processamento (normaliza\u00e7\u00e3o + PCA) das imagens: {}s\".format(time.time()-t0)) print(\"Novas dimensoes das matrizes de dados e classes (labels) de treinamento\") print(entradas_treino_norm.shape, entradas_teste_norm.shape) <pre>Tempo para o processamento (normaliza\u00e7\u00e3o + PCA) das imagens: 19.009876012802124s\nNovas dimensoes das matrizes de dados e classes (labels) de treinamento\n(60000, 185) (10000, 185)\n</pre> In\u00a0[21]: Copied! <pre>print(\"Dimens\u00f5es da matriz dos dados de treinamento: \", entradas_treino.shape)\nprint(\"Dimens\u00f5es da matriz dos dados de teste: \", entradas_teste.shape)\nprint(28*28)\n</pre> print(\"Dimens\u00f5es da matriz dos dados de treinamento: \", entradas_treino.shape) print(\"Dimens\u00f5es da matriz dos dados de teste: \", entradas_teste.shape) print(28*28)  <pre>Dimens\u00f5es da matriz dos dados de treinamento:  (60000, 784)\nDimens\u00f5es da matriz dos dados de teste:  (10000, 784)\n784\n</pre> In\u00a0[22]: Copied! <pre>##Avalia\u00e7\u00e3o PCA\n\nprint (len(entradas_treino_norm), len(entradas_treino_norm))\n\nprint (\"taxa de variancia explicada: \" , len(redutor_dim.explained_variance_ratio_), redutor_dim.explained_variance_ratio_)\nprint (\"valores de cada um dos componentes: \", len(redutor_dim.singular_values_), redutor_dim.singular_values_)\n</pre> ##Avalia\u00e7\u00e3o PCA  print (len(entradas_treino_norm), len(entradas_treino_norm))  print (\"taxa de variancia explicada: \" , len(redutor_dim.explained_variance_ratio_), redutor_dim.explained_variance_ratio_) print (\"valores de cada um dos componentes: \", len(redutor_dim.singular_values_), redutor_dim.singular_values_) <pre>60000 60000\ntaxa de variancia explicada:  185 [0.05646717 0.04078272 0.0373938  0.02885115 0.02521109 0.0219427\n 0.01923344 0.01745799 0.01535092 0.0140172  0.01341743 0.01203742\n 0.0111457  0.01089924 0.01028649 0.00994487 0.00936383 0.00921046\n 0.00893437 0.00869913 0.00827363 0.00803417 0.00764846 0.00741772\n 0.00715293 0.00691847 0.00684136 0.00656675 0.00631677 0.0061292\n 0.00596255 0.00587716 0.00571592 0.00562307 0.00554682 0.00538418\n 0.00531182 0.00519606 0.00508211 0.00480006 0.00476456 0.00469139\n 0.00454349 0.00451346 0.00446963 0.00443383 0.00438215 0.00430382\n 0.00426878 0.00423647 0.00404696 0.00399447 0.00397456 0.00393821\n 0.00385814 0.00379043 0.00375403 0.00370776 0.00364944 0.00359301\n 0.00352382 0.00347794 0.00344411 0.00339868 0.00335955 0.00334886\n 0.00331864 0.00323026 0.00316277 0.00313244 0.00310731 0.00307243\n 0.00304914 0.00302717 0.00299485 0.00297761 0.00295052 0.00290438\n 0.00286856 0.00285678 0.00283398 0.00282627 0.00279551 0.00279305\n 0.00278519 0.00277455 0.00275901 0.00274227 0.00271411 0.00269263\n 0.00266484 0.00263581 0.00262962 0.00261034 0.00258827 0.00256176\n 0.00253846 0.00250447 0.00247829 0.00245034 0.00242347 0.00242064\n 0.00238875 0.00237455 0.00235608 0.00233053 0.0022798  0.00226174\n 0.00222832 0.00222442 0.00218169 0.00217257 0.00214277 0.00211938\n 0.00210972 0.0020733  0.00204761 0.00204368 0.00202409 0.00200462\n 0.00198822 0.00195216 0.00193737 0.00192103 0.00191716 0.00189802\n 0.00187089 0.00186536 0.0018132  0.00180005 0.00179194 0.00178973\n 0.0017695  0.00176158 0.00174797 0.00172985 0.00172017 0.00168727\n 0.00168517 0.00166842 0.00164718 0.00164575 0.00164294 0.00161486\n 0.0016049  0.00158912 0.0015749  0.00155918 0.00155638 0.00154666\n 0.00154043 0.00151605 0.00150272 0.00148761 0.00147505 0.0014682\n 0.00145803 0.00145568 0.00144737 0.00142895 0.00141058 0.00139939\n 0.00139709 0.00139533 0.00139355 0.00139225 0.00138773 0.0013834\n 0.00137816 0.00136845 0.00136165 0.00135822 0.00133701 0.00132905\n 0.00131059 0.00130293 0.00129324 0.00128241 0.00127407 0.00126822\n 0.00125322 0.00124045 0.00122984 0.00121618 0.00121506]\nvalores de cada um dos componentes:  185 [1558.59475775 1324.56506425 1268.33806904 1114.08096949 1041.4321537\n  971.58372712  909.62781125  866.6272717   812.64796157  776.54347762\n  759.74854205  719.61780297  692.45059052  684.75186297  665.2254475\n  654.08571283  634.6905444   629.47108378  619.96491977  611.74864821\n  596.60000904  587.90318277  573.61706238  564.89867585  554.72424844\n  545.55706108  542.50833328  531.50859803  521.29389656  513.4959735\n  506.46720335  502.82760665  495.88178934  491.83803286  488.4917578\n  481.27703518  478.03201127  472.79417281  467.58152416  454.42094643\n  452.73755506  449.24798572  442.10962544  440.64606814  438.50160223\n  436.74183847  434.18923818  430.29086602  428.53573113  426.91093544\n  417.25324612  414.53862665  413.50407786  411.60868344  407.40275713\n  403.81203369  401.86842781  399.38423688  396.23108492  393.15532131\n  389.35177902  386.80851333  384.92303762  382.37581508  380.16791664\n  379.56282447  377.84621102  372.78112287  368.86630886  367.09355234\n  365.61819099  363.56002954  362.17963536  360.87245819  358.94092281\n  357.90621176  356.27402823  353.47770091  351.29123623  350.56891845\n  349.16718716  348.69212323  346.78936634  346.6369362   346.14874915\n  345.48710725  344.51781742  343.47138797  341.70285667  340.34823393\n  338.58759852  336.73828279  336.34220011  335.10707121  333.68749917\n  331.97454025  330.46102411  328.24139239  326.52136861  324.67435089\n  322.88936082  322.70086024  320.56858096  319.61385191  318.36887157\n  316.63780238  313.1725175   311.92971598  309.61609571  309.34544735\n  306.360028    305.71862309  303.61468514  301.95298194  301.26427292\n  298.6527374   296.79663011  296.51171699  295.08666108  293.66447678\n  292.46061956  289.79603176  288.69671405  287.47662373  287.18664393\n  285.74965273  283.70035923  283.28015727  279.29169961  278.27731866\n  277.64955632  277.47843311  275.90592833  275.28720761  274.22175433\n  272.7966822   272.03227791  269.41865042  269.25082545  267.90897203\n  266.19893845  266.08295896  265.85540571  263.57386832  262.7601788\n  261.46521492  260.29213116  258.9899899   258.75750421  257.94798876\n  257.42815671  255.38269599  254.25740548  252.97587879  251.90640352\n  251.32057934  250.44831234  250.24628968  249.53113324  247.93848294\n  246.33934447  245.36012105  245.15894614  245.00431129  244.84794458\n  244.73387616  244.33626317  243.95435627  243.49224383  242.63262475\n  242.0297457   241.72463554  239.82975985  239.11486781  237.44845681\n  236.75327822  235.87142391  234.8811359   234.11618726  233.57844421\n  232.19261652  231.00662861  230.01633731  228.73575127  228.63068847]\n</pre> In\u00a0[23]: Copied! <pre>plt.figure(figsize=(10,10))\nplt.subplot(4,4,1)\nfor i in range(4):\n  for j in range(4):\n    plt.subplot(4,4,i*4+j+1)\n    visualiza_linha_mnist(redutor_dim.components_, i*4 + j)\nplt.show()\n</pre> plt.figure(figsize=(10,10)) plt.subplot(4,4,1) for i in range(4):   for j in range(4):     plt.subplot(4,4,i*4+j+1)     visualiza_linha_mnist(redutor_dim.components_, i*4 + j) plt.show() <pre>&lt;ipython-input-23-e7a2857a4126&gt;:5: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n  plt.subplot(4,4,i*4+j+1)\n</pre> In\u00a0[24]: Copied! <pre>## Seu c\u00f3digo aqui.....\n</pre> ## Seu c\u00f3digo aqui....."},{"location":"aulas/IA/lab04/dicasDePreprocessamento.html#2-aprendizagem-de-maquina","title":"2. Aprendizagem de m\u00e1quina\u00b6","text":""},{"location":"aulas/IA/lab04/dicasDePreprocessamento.html#objetivos","title":"Objetivos\u00b6","text":"<ul> <li>Dicas de pr\u00e9-processamento de dados</li> <li>Entender e praticar a normaliza\u00e7\u00e3o dos dados</li> <li>Entender e praticar codifica\u00e7\u00e3o Label Encoder e One Hot Encoder.</li> <li>Redu\u00e7\u00e3o de dimensionalidade: PCA</li> </ul>"},{"location":"aulas/IA/lab04/dicasDePreprocessamento.html#pre-processamento","title":"Pr\u00e9-processamento\u00b6","text":"<p>Nesta etapa estamos interessados em tratar os dados que servir\u00e3o de entrada do nosso modelo de Machine Learning seja ele predi\u00e7\u00e3o, agrupamento ou classifica\u00e7\u00e3o. Existem diversas t\u00e9cnicas que podem (e devem) ser aplicadas, j\u00e1 conhecemos algumas e hoje veremos outras t\u00e9cnicas.</p>"},{"location":"aulas/IA/lab04/dicasDePreprocessamento.html#normalizacao-de-dados","title":"Normaliza\u00e7\u00e3o de dados\u00b6","text":"<p>O conceito de normaliza\u00e7\u00e3o \u00e9 simples, a id\u00e9ia \u00e9 deixar os dados todos na mesma ordem de grandeza, desta forma evita-se gerar discrep\u00e2ncias entre os atributos (colunas).</p> <p>Os m\u00e9todos mais populares s\u00e3o:</p> <ul> <li>Normaliza\u00e7\u00e3o Min-M\u00e1x: transforma os dados em um escala linear entre 0 e 1</li> <li>Normaliza\u00e7\u00e3o de pontua\u00e7\u00e3o Z: Escala de dados com base na m\u00e9dia e desvio padr\u00e3o (tambem chamado de padroniza\u00e7\u00e3o)</li> <li>Dimensionamento decimal: Dimensiona os dados movendo o ponto decimal do atributo (muito utilizado em sistemas embarcados).</li> </ul>"},{"location":"aulas/IA/lab04/dicasDePreprocessamento.html#desafio-1","title":"Desafio 1\u00b6","text":"<p>Lembra o dataset 'breast_cancer'. Aplique essas transforma\u00e7\u00f5es necess\u00e1rias aprendidas nos atributos num\u00e9ricos.</p>"},{"location":"aulas/IA/lab04/dicasDePreprocessamento.html#codificacao-label-encoder-e-one-hot-encoder","title":"Codifica\u00e7\u00e3o Label Encoder e One Hot Encoder\u00b6","text":"<p>Em muitos casos vamos nos deparar com atributos categoricos, que n\u00e3o possuem numeros e sim textos. Como por exemplo um atributo chamado Cidade, ser\u00e1 pararecido com [\"cotia\",\"S\u00e3o Paulo\",\"Pouso Alegre\"] ou um atributo de qualifica\u00e7\u00e3o profissional, ser\u00e1 paracido com [\"junior\",\"Pleno\",\"Senior\"].</p> <p>Para esses tipos de casos manter o atributo como esta para realizar um aprendizado de maquina pode n\u00e3o ser uma boa id\u00e9ia, para isso, podemos trocar os textos por valores numericos. Vamos ver algumas formas para realizar esse processo.</p>"},{"location":"aulas/IA/lab04/dicasDePreprocessamento.html#label-encoder","title":"Label Encoder\u00b6","text":"<p>Uma forma simples de trocar um atributo categorico de texto para numero \u00e9 associar um valor num\u00e9rico para cada texto do atributo.</p> <ul> <li><p>Exemplo:</p> <p>[\"cotia\",\"S\u00e3o Paulo\",\"Pouso Alegre\"] == [0,2,1]</p> <p>[\"junior\",\"Pleno\",\"Senior\"] == [0,1,2]</p> </li> </ul> <p>Observa\u00e7\u00e3o: Note que os indices est\u00e3o em <code>ordem alfab\u00e9tica</code>.</p>"},{"location":"aulas/IA/lab04/dicasDePreprocessamento.html#one-hot-encoder","title":"One Hot Encoder\u00b6","text":"<p>Podemos associar cada valor de um atribuco como uma nova coluna e preencher com 0 ou 1 o valor desta coluna, \u00e9 desta forma que o one hot encoder funciona.</p> <ul> <li>Exemplo:</li> </ul>"},{"location":"aulas/IA/lab04/dicasDePreprocessamento.html#desafio-2","title":"Desafio 2\u00b6","text":"<p>Vamos avaliar o efeito de transforma\u00e7\u00e3o de variavel no treinamento de um dataset, para isso:</p> <p>Treine e avalie duas vezes um classificador kNN para o dataset Wine: https://archive.ics.uci.edu/ml/datasets/Wine.</p> <p>Considere como dados de entrada apenas as colunas 'Flavanoids\u2019 e 'Proline\u2019.</p> <p>Compare o efeito da normaliza\u00e7\u00e3o na avalia\u00e7\u00e3o do classificador. Use k = 5.</p>"},{"location":"aulas/IA/lab04/dicasDePreprocessamento.html#reducao-de-dimensionalidade","title":"Redu\u00e7\u00e3o de dimensionalidade\u00b6","text":"<ul> <li>Para o bom desempenho da tarefa de classifica\u00e7\u00e3o \u00e9 importante um conjunto suficientemente grande de atributos.<ul> <li>Em muitos casos, especialmente quando se trabalha diretamente com os pixels das imagens, a informa\u00e7\u00e3o necess\u00e1ria para a classifica\u00e7\u00e3o de padr\u00f5es est\u00e1 espalhada por praticamente todos os atributos</li> </ul> </li> <li>No entanto, um n\u00famero muito grande de atributos atrapalha o desempenho dos classificadores, num efeito conhecido como a maldi\u00e7\u00e3o da dimensionalidade, curse of dimensionality.</li> <li>Frequentemente um n\u00famero grande de atributos est\u00e1 associado \u00e0 redund\u00e2ncia da informa\u00e7\u00e3o, ou seja, os valores dos tributos est\u00e3o fortemente ligados entre si.<ul> <li>Por exemplo, nas imagens de d\u00edgitos, pixels pr\u00f3ximos tendem a ter tonalidades semelhantes</li> </ul> </li> <li>Uma sa\u00edda para aproveitar a maior parte da informa\u00e7\u00e3o espalhada pelos atributos \u00e9 encontrar uma transforma\u00e7\u00e3o dos dados que use atributos o t\u00e3o independentes quanto poss\u00edvel.<ul> <li>Dessa forma, alguns atributos ter\u00e3o mais relev\u00e2ncia do que outros, pois ao desfazer a interdepend\u00eancia, conseguimos \u201cseparar\u201d a informa\u00e7\u00e3o relevante da informa\u00e7\u00e3o redundante</li> </ul> </li> </ul>"},{"location":"aulas/IA/lab04/dicasDePreprocessamento.html#pca-principal-component-analysis","title":"PCA : Principal Component Analysis\u00b6","text":"<p>(An\u00e1lise de Componentes Principais)</p>"},{"location":"aulas/IA/lab04/dicasDePreprocessamento.html#1-gera-a-matriz-de-dados-de-entradas-e-o-vetor-de-classes-alvo-para-treinamento","title":"1 - Gera a matriz de dados de entradas e o vetor de classes alvo para treinamento\u00b6","text":"<p>Cada linha da matriz de entradas (atributos) cont\u00e9m os pixels da  imagem.</p> <p>Cada posi\u00e7\u00e3o do array de r\u00f3tulos (labels) cont\u00e9m a classe alvo da imgem.</p> <p>No caso deste dataset, as imagens de trenamento e de teste j\u00e1 est\u00e3o separadas, e vamos adotar a separa\u00e7\u00e3o sugerida pelo autor da base de dados.</p>"},{"location":"aulas/IA/lab04/dicasDePreprocessamento.html#11-visualizcao-de-uma-imagem","title":"1.1 Visualiz\u00e7\u00e3o de uma imagem\u00b6","text":"<p>Neste dataset cada imagem est\u00e1 armazenada como uma linha da matriz de entrada. Para visualizar a imagem que est\u00e1 na linha <code>i</code> da matriz, temos que convert\u00ea-la novamente em uma matriz quadrada, e usar a biblioteca <code>matplotlib</code></p>"},{"location":"aulas/IA/lab04/dicasDePreprocessamento.html#2-faz-a-normalizacao-e-a-reducao-da-dimensionalidade-com-pca","title":"2 - Faz a normaliza\u00e7\u00e3o e a redu\u00e7\u00e3o da dimensionalidade com PCA\u00b6","text":"<p>Instancia o modelo PCA de forma que 85% da variabilidade de dados seja mantida. O m\u00e9todo <code>fit_transform(X)</code> treina o PCA e j\u00e1 traz os dados <code>X</code> transformados. Para reaproveitar o mesmo modelo PCA sem trein\u00e1-o novamente, usamos <code>transform()</code>.</p> <p>Uma vez que os dados de treinamento e teste j\u00e1 est\u00e3o separados,treinamos o normalizador e o PCA com os dados de treinamento, e apenas aplicamos a transforma\u00e7\u00e3o nos dados de teste.</p>"},{"location":"aulas/IA/lab04/dicasDePreprocessamento.html#21-visualizacao-das-16-primairas-imagens-principais","title":"2.1 - Visualiza\u00e7\u00e3o das 16 primairas imagens principais\u00b6","text":"<p>O PCA neste caso transforma um array (entrada ou linha da matriz) composta por um conjunto de pixels em um outro array que indica a composi\u00e7\u00e3o da imagem em termos de \"imagens principais\"</p>"},{"location":"aulas/IA/lab04/dicasDePreprocessamento.html#desafio-3","title":"Desafio 3\u00b6","text":"<p>Agora \u00e9 com voc\u00ea termine a implementa\u00e7ao deste classificador de digitos usando o KNN. Usar as novas matrizes no treinamento, teste e avalia\u00e7\u00e3o do classificador</p>"},{"location":"aulas/IA/lab04/reducao_dimensionalidade_pca.html","title":"PCA","text":"<ul> <li><p>O PCA \u00e9 uma transforma\u00e7\u00e3o linear, ou seja, multiplica os vetores de atributos de entradas de N posi\u00e7\u00f5es por uma matriz com MxN, com M \u2264 N, resultando em um novo vetor de N dimens\u00f5es</p> </li> <li><p>O elemento que se destaca \u00e9 a da vari\u00e2ncia</p> </li> <li><p>Essa transforma\u00e7\u00e3o \u00e9 obtida por meio dos vetores de treinamento. A redu\u00e7\u00e3o na dimensionalidade \u00e9 controlada pelo par\u00e2metro que define a porcentagem de variabilidade que ser\u00e1 mantida nos novos dados</p> </li> <li><p>No Python, fazemos:</p> </li> </ul> In\u00a0[16]: Copied! <pre>from sklearn.decomposition import PCA\n\nmedidas_pca = PCA(0.5).fit_transform(df) # Mantem 50% de variabilidade\nprint(medidas_pca)\n\nprint(\"shape original: \" , df.shape, \"shape PCA: \" ,  medidas_pca.shape)\n</pre> from sklearn.decomposition import PCA  medidas_pca = PCA(0.5).fit_transform(df) # Mantem 50% de variabilidade print(medidas_pca)  print(\"shape original: \" , df.shape, \"shape PCA: \" ,  medidas_pca.shape)   <pre>[[ -5.81469106]\n [ 27.45356145]\n [ -1.35358402]\n [-20.28528637]]\nshape original:  (4, 5) shape PCA:  (4, 1)\n</pre> <ul> <li>Cada linha nessa matriz corresponde a uma vetor com N dimens\u00f5es, com um significado especial, denominado de auto-vetor</li> <li>No caso dos vetores serem imagens, essas \u201cauto-imagens\u201d guardam caracter\u00edsticas que ser\u00e3o usadas para identificar as imagens de teste</li> </ul> In\u00a0[17]: Copied! <pre>#Instale os pacotes e faz o download dos arquivos, se ja estiver na pasta n\u00e3o precisa rodar essa celula.\n\n#!pip3 install --user python-mnist\n#!pip install wget\n\n\nimport wget\nwget.download('http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz')\nwget.download('http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz')\nwget.download('http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz')\nwget.download('http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz')\n</pre> #Instale os pacotes e faz o download dos arquivos, se ja estiver na pasta n\u00e3o precisa rodar essa celula.  #!pip3 install --user python-mnist #!pip install wget   import wget wget.download('http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz') wget.download('http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz') wget.download('http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz') wget.download('http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz') Out[17]: <pre>'t10k-labels-idx1-ubyte.gz'</pre> In\u00a0[18]: Copied! <pre>import time\nimport numpy as np\n# API MNIST\nfrom mnist import MNIST\n\nt0 = time.time()\n\n# Importa os dados do dieret\u00f3rio local\nmndata = MNIST('.')\n# Habilita abrir arquivos compactados\nmndata.gz = True \n\n# Carrega os dados de treinamento\nentradas_treino, classes_treino = mndata.load_training()\n# Carrega os dados de treinamento\nentradas_teste, classes_teste = mndata.load_testing()\n\n#Transformando em array do numpy\nentradas_treino = np.array(entradas_treino)\nclasses_treino = np.array(classes_treino)\nentradas_teste = np.array(entradas_teste)\nclasses_teste = np.array(classes_teste)\n\ndados_reduzidos = False\n\nprint(\"Tempo para carregamento das imagens: {}s\".format(time.time()-t0))\n\nprint(\"Dimens\u00f5es da matriz dos dados de treinamento: \", entradas_treino.shape)\nprint(\"Dimens\u00f5es da matriz dos dados de teste: \", entradas_teste.shape)\n</pre> import time import numpy as np # API MNIST from mnist import MNIST  t0 = time.time()  # Importa os dados do dieret\u00f3rio local mndata = MNIST('.') # Habilita abrir arquivos compactados mndata.gz = True   # Carrega os dados de treinamento entradas_treino, classes_treino = mndata.load_training() # Carrega os dados de treinamento entradas_teste, classes_teste = mndata.load_testing()  #Transformando em array do numpy entradas_treino = np.array(entradas_treino) classes_treino = np.array(classes_treino) entradas_teste = np.array(entradas_teste) classes_teste = np.array(classes_teste)  dados_reduzidos = False  print(\"Tempo para carregamento das imagens: {}s\".format(time.time()-t0))  print(\"Dimens\u00f5es da matriz dos dados de treinamento: \", entradas_treino.shape) print(\"Dimens\u00f5es da matriz dos dados de teste: \", entradas_teste.shape)  <pre>Tempo para carregamento das imagens: 14.753993034362793s\nDimens\u00f5es da matriz dos dados de treinamento:  (60000, 784)\nDimens\u00f5es da matriz dos dados de teste:  (10000, 784)\n</pre> In\u00a0[19]: Copied! <pre># Fun\u00e7\u00e3o que visualiza a linha lin da matriz\nimport matplotlib.pyplot as plt\nimport math\ndef visualiza_linha_mnist(matriz, lin):\n  size = int(math.sqrt(matriz.shape[1]))\n  img = np.reshape(matriz[lin], (size, size))\n  plt.imshow(img, cmap=\"gray\")\n  \n# Visualiza\u00e7\u00e3o da linha 0\nvisualiza_linha_mnist(entradas_treino, 0)\nplt.show()\n</pre> # Fun\u00e7\u00e3o que visualiza a linha lin da matriz import matplotlib.pyplot as plt import math def visualiza_linha_mnist(matriz, lin):   size = int(math.sqrt(matriz.shape[1]))   img = np.reshape(matriz[lin], (size, size))   plt.imshow(img, cmap=\"gray\")    # Visualiza\u00e7\u00e3o da linha 0 visualiza_linha_mnist(entradas_treino, 0) plt.show() In\u00a0[20]: Copied! <pre>from sklearn.preprocessing import StandardScaler\n# PCA\nfrom sklearn.decomposition import PCA\n\nt0 = time.time()\n\nnormalizador = StandardScaler()\nredutor_dim = PCA(0.85)\n\nentradas_treino_norm = normalizador.fit_transform(entradas_treino)\nentradas_treino_norm = redutor_dim.fit_transform(entradas_treino_norm)\n\nentradas_teste_norm = normalizador.transform(entradas_teste)\nentradas_teste_norm = redutor_dim.transform(entradas_teste_norm)\n\nprint(\"Tempo para o processamento (normaliza\u00e7\u00e3o + PCA) das imagens: {}s\".format(time.time()-t0))\nprint(\"Novas dimensoes das matrizes de dados e classes (labels) de treinamento\")\nprint(entradas_treino_norm.shape, entradas_teste_norm.shape)\n</pre> from sklearn.preprocessing import StandardScaler # PCA from sklearn.decomposition import PCA  t0 = time.time()  normalizador = StandardScaler() redutor_dim = PCA(0.85)  entradas_treino_norm = normalizador.fit_transform(entradas_treino) entradas_treino_norm = redutor_dim.fit_transform(entradas_treino_norm)  entradas_teste_norm = normalizador.transform(entradas_teste) entradas_teste_norm = redutor_dim.transform(entradas_teste_norm)  print(\"Tempo para o processamento (normaliza\u00e7\u00e3o + PCA) das imagens: {}s\".format(time.time()-t0)) print(\"Novas dimensoes das matrizes de dados e classes (labels) de treinamento\") print(entradas_treino_norm.shape, entradas_teste_norm.shape) <pre>Tempo para o processamento (normaliza\u00e7\u00e3o + PCA) das imagens: 19.009876012802124s\nNovas dimensoes das matrizes de dados e classes (labels) de treinamento\n(60000, 185) (10000, 185)\n</pre> In\u00a0[21]: Copied! <pre>print(\"Dimens\u00f5es da matriz dos dados de treinamento: \", entradas_treino.shape)\nprint(\"Dimens\u00f5es da matriz dos dados de teste: \", entradas_teste.shape)\nprint(28*28)\n</pre> print(\"Dimens\u00f5es da matriz dos dados de treinamento: \", entradas_treino.shape) print(\"Dimens\u00f5es da matriz dos dados de teste: \", entradas_teste.shape) print(28*28)  <pre>Dimens\u00f5es da matriz dos dados de treinamento:  (60000, 784)\nDimens\u00f5es da matriz dos dados de teste:  (10000, 784)\n784\n</pre> In\u00a0[22]: Copied! <pre>##Avalia\u00e7\u00e3o PCA\n\nprint (len(entradas_treino_norm), len(entradas_treino_norm))\n\nprint (\"taxa de variancia explicada: \" , len(redutor_dim.explained_variance_ratio_), redutor_dim.explained_variance_ratio_)\nprint (\"valores de cada um dos componentes: \", len(redutor_dim.singular_values_), redutor_dim.singular_values_)\n</pre> ##Avalia\u00e7\u00e3o PCA  print (len(entradas_treino_norm), len(entradas_treino_norm))  print (\"taxa de variancia explicada: \" , len(redutor_dim.explained_variance_ratio_), redutor_dim.explained_variance_ratio_) print (\"valores de cada um dos componentes: \", len(redutor_dim.singular_values_), redutor_dim.singular_values_) <pre>60000 60000\ntaxa de variancia explicada:  185 [0.05646717 0.04078272 0.0373938  0.02885115 0.02521109 0.0219427\n 0.01923344 0.01745799 0.01535092 0.0140172  0.01341743 0.01203742\n 0.0111457  0.01089924 0.01028649 0.00994487 0.00936383 0.00921046\n 0.00893437 0.00869913 0.00827363 0.00803417 0.00764846 0.00741772\n 0.00715293 0.00691847 0.00684136 0.00656675 0.00631677 0.0061292\n 0.00596255 0.00587716 0.00571592 0.00562307 0.00554682 0.00538418\n 0.00531182 0.00519606 0.00508211 0.00480006 0.00476456 0.00469139\n 0.00454349 0.00451346 0.00446963 0.00443383 0.00438215 0.00430382\n 0.00426878 0.00423647 0.00404696 0.00399447 0.00397456 0.00393821\n 0.00385814 0.00379043 0.00375403 0.00370776 0.00364944 0.00359301\n 0.00352382 0.00347794 0.00344411 0.00339868 0.00335955 0.00334886\n 0.00331864 0.00323026 0.00316277 0.00313244 0.00310731 0.00307243\n 0.00304914 0.00302717 0.00299485 0.00297761 0.00295052 0.00290438\n 0.00286856 0.00285678 0.00283398 0.00282627 0.00279551 0.00279305\n 0.00278519 0.00277455 0.00275901 0.00274227 0.00271411 0.00269263\n 0.00266484 0.00263581 0.00262962 0.00261034 0.00258827 0.00256176\n 0.00253846 0.00250447 0.00247829 0.00245034 0.00242347 0.00242064\n 0.00238875 0.00237455 0.00235608 0.00233053 0.0022798  0.00226174\n 0.00222832 0.00222442 0.00218169 0.00217257 0.00214277 0.00211938\n 0.00210972 0.0020733  0.00204761 0.00204368 0.00202409 0.00200462\n 0.00198822 0.00195216 0.00193737 0.00192103 0.00191716 0.00189802\n 0.00187089 0.00186536 0.0018132  0.00180005 0.00179194 0.00178973\n 0.0017695  0.00176158 0.00174797 0.00172985 0.00172017 0.00168727\n 0.00168517 0.00166842 0.00164718 0.00164575 0.00164294 0.00161486\n 0.0016049  0.00158912 0.0015749  0.00155918 0.00155638 0.00154666\n 0.00154043 0.00151605 0.00150272 0.00148761 0.00147505 0.0014682\n 0.00145803 0.00145568 0.00144737 0.00142895 0.00141058 0.00139939\n 0.00139709 0.00139533 0.00139355 0.00139225 0.00138773 0.0013834\n 0.00137816 0.00136845 0.00136165 0.00135822 0.00133701 0.00132905\n 0.00131059 0.00130293 0.00129324 0.00128241 0.00127407 0.00126822\n 0.00125322 0.00124045 0.00122984 0.00121618 0.00121506]\nvalores de cada um dos componentes:  185 [1558.59475775 1324.56506425 1268.33806904 1114.08096949 1041.4321537\n  971.58372712  909.62781125  866.6272717   812.64796157  776.54347762\n  759.74854205  719.61780297  692.45059052  684.75186297  665.2254475\n  654.08571283  634.6905444   629.47108378  619.96491977  611.74864821\n  596.60000904  587.90318277  573.61706238  564.89867585  554.72424844\n  545.55706108  542.50833328  531.50859803  521.29389656  513.4959735\n  506.46720335  502.82760665  495.88178934  491.83803286  488.4917578\n  481.27703518  478.03201127  472.79417281  467.58152416  454.42094643\n  452.73755506  449.24798572  442.10962544  440.64606814  438.50160223\n  436.74183847  434.18923818  430.29086602  428.53573113  426.91093544\n  417.25324612  414.53862665  413.50407786  411.60868344  407.40275713\n  403.81203369  401.86842781  399.38423688  396.23108492  393.15532131\n  389.35177902  386.80851333  384.92303762  382.37581508  380.16791664\n  379.56282447  377.84621102  372.78112287  368.86630886  367.09355234\n  365.61819099  363.56002954  362.17963536  360.87245819  358.94092281\n  357.90621176  356.27402823  353.47770091  351.29123623  350.56891845\n  349.16718716  348.69212323  346.78936634  346.6369362   346.14874915\n  345.48710725  344.51781742  343.47138797  341.70285667  340.34823393\n  338.58759852  336.73828279  336.34220011  335.10707121  333.68749917\n  331.97454025  330.46102411  328.24139239  326.52136861  324.67435089\n  322.88936082  322.70086024  320.56858096  319.61385191  318.36887157\n  316.63780238  313.1725175   311.92971598  309.61609571  309.34544735\n  306.360028    305.71862309  303.61468514  301.95298194  301.26427292\n  298.6527374   296.79663011  296.51171699  295.08666108  293.66447678\n  292.46061956  289.79603176  288.69671405  287.47662373  287.18664393\n  285.74965273  283.70035923  283.28015727  279.29169961  278.27731866\n  277.64955632  277.47843311  275.90592833  275.28720761  274.22175433\n  272.7966822   272.03227791  269.41865042  269.25082545  267.90897203\n  266.19893845  266.08295896  265.85540571  263.57386832  262.7601788\n  261.46521492  260.29213116  258.9899899   258.75750421  257.94798876\n  257.42815671  255.38269599  254.25740548  252.97587879  251.90640352\n  251.32057934  250.44831234  250.24628968  249.53113324  247.93848294\n  246.33934447  245.36012105  245.15894614  245.00431129  244.84794458\n  244.73387616  244.33626317  243.95435627  243.49224383  242.63262475\n  242.0297457   241.72463554  239.82975985  239.11486781  237.44845681\n  236.75327822  235.87142391  234.8811359   234.11618726  233.57844421\n  232.19261652  231.00662861  230.01633731  228.73575127  228.63068847]\n</pre> In\u00a0[23]: Copied! <pre>plt.figure(figsize=(10,10))\nplt.subplot(4,4,1)\nfor i in range(4):\n  for j in range(4):\n    plt.subplot(4,4,i*4+j+1)\n    visualiza_linha_mnist(redutor_dim.components_, i*4 + j)\nplt.show()\n</pre> plt.figure(figsize=(10,10)) plt.subplot(4,4,1) for i in range(4):   for j in range(4):     plt.subplot(4,4,i*4+j+1)     visualiza_linha_mnist(redutor_dim.components_, i*4 + j) plt.show() <pre>&lt;ipython-input-23-e7a2857a4126&gt;:5: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n  plt.subplot(4,4,i*4+j+1)\n</pre> In\u00a0[24]: Copied! <pre>## Seu c\u00f3digo aqui.....\n</pre> ## Seu c\u00f3digo aqui....."},{"location":"aulas/IA/lab04/reducao_dimensionalidade_pca.html#aprendizagem-de-maquina","title":"Aprendizagem de m\u00e1quina\u00b6","text":""},{"location":"aulas/IA/lab04/reducao_dimensionalidade_pca.html#objetivos","title":"Objetivos\u00b6","text":"<ul> <li>Intui\u00e7\u00e3o sobre Redu\u00e7\u00e3o de dimensionalidade</li> <li>Conhecer o algoritmo PCA</li> </ul>"},{"location":"aulas/IA/lab04/reducao_dimensionalidade_pca.html#reducao-de-dimensionalidade","title":"Redu\u00e7\u00e3o de dimensionalidade\u00b6","text":"<ul> <li>Para o bom desempenho da tarefa de classifica\u00e7\u00e3o \u00e9 importante um conjunto suficientemente grande de atributos.<ul> <li>Em muitos casos, especialmente quando se trabalha diretamente com os pixels das imagens, a informa\u00e7\u00e3o necess\u00e1ria para a classifica\u00e7\u00e3o de padr\u00f5es est\u00e1 espalhada por praticamente todos os atributos</li> </ul> </li> <li>No entanto, um n\u00famero muito grande de atributos atrapalha o desempenho dos classificadores, num efeito conhecido como a maldi\u00e7\u00e3o da dimensionalidade, curse of dimensionality.</li> <li>Frequentemente um n\u00famero grande de atributos est\u00e1 associado \u00e0 redund\u00e2ncia da informa\u00e7\u00e3o, ou seja, os valores dos tributos est\u00e3o fortemente ligados entre si.<ul> <li>Por exemplo, nas imagens de d\u00edgitos, pixels pr\u00f3ximos tendem a ter tonalidades semelhantes</li> </ul> </li> <li>Uma sa\u00edda para aproveitar a maior parte da informa\u00e7\u00e3o espalhada pelos atributos \u00e9 encontrar uma transforma\u00e7\u00e3o dos dados que use atributos o t\u00e3o independentes quanto poss\u00edvel.<ul> <li>Dessa forma, alguns atributos ter\u00e3o mais relev\u00e2ncia do que outros, pois ao desfazer a interdepend\u00eancia, conseguimos \u201cseparar\u201d a informa\u00e7\u00e3o relevante da informa\u00e7\u00e3o redundante</li> </ul> </li> </ul>"},{"location":"aulas/IA/lab04/reducao_dimensionalidade_pca.html#pca-principal-component-analysis","title":"PCA : Principal Component Analysis\u00b6","text":"<p>(An\u00e1lise de Componentes Principais)</p>"},{"location":"aulas/IA/lab04/reducao_dimensionalidade_pca.html#1-gera-a-matriz-de-dados-de-entradas-e-o-vetor-de-classes-alvo-para-treinamento","title":"1 - Gera a matriz de dados de entradas e o vetor de classes alvo para treinamento\u00b6","text":"<p>Cada linha da matriz de entradas (atributos) cont\u00e9m os pixels da  imagem.</p> <p>Cada posi\u00e7\u00e3o do array de r\u00f3tulos (labels) cont\u00e9m a classe alvo da imgem.</p> <p>No caso deste dataset, as imagens de trenamento e de teste j\u00e1 est\u00e3o separadas, e vamos adotar a separa\u00e7\u00e3o sugerida pelo autor da base de dados.</p>"},{"location":"aulas/IA/lab04/reducao_dimensionalidade_pca.html#11-visualizcao-de-uma-imagem","title":"1.1 Visualiz\u00e7\u00e3o de uma imagem\u00b6","text":"<p>Neste dataset cada imagem est\u00e1 armazenada como uma linha da matriz de entrada. Para visualizar a imagem que est\u00e1 na linha <code>i</code> da matriz, temos que convert\u00ea-la novamente em uma matriz quadrada, e usar a biblioteca <code>matplotlib</code></p>"},{"location":"aulas/IA/lab04/reducao_dimensionalidade_pca.html#2-faz-a-normalizacao-e-a-reducao-da-dimensionalidade-com-pca","title":"2 - Faz a normaliza\u00e7\u00e3o e a redu\u00e7\u00e3o da dimensionalidade com PCA\u00b6","text":"<p>Instancia o modelo PCA de forma que 85% da variabilidade de dados seja mantida. O m\u00e9todo <code>fit_transform(X)</code> treina o PCA e j\u00e1 traz os dados <code>X</code> transformados. Para reaproveitar o mesmo modelo PCA sem trein\u00e1-o novamente, usamos <code>transform()</code>.</p> <p>Uma vez que os dados de treinamento e teste j\u00e1 est\u00e3o separados,treinamos o normalizador e o PCA com os dados de treinamento, e apenas aplicamos a transforma\u00e7\u00e3o nos dados de teste.</p>"},{"location":"aulas/IA/lab04/reducao_dimensionalidade_pca.html#21-visualizacao-das-16-primairas-imagens-principais","title":"2.1 - Visualiza\u00e7\u00e3o das 16 primairas imagens principais\u00b6","text":"<p>O PCA neste caso transforma um array (entrada ou linha da matriz) composta por um conjunto de pixels em um outro array que indica a composi\u00e7\u00e3o da imagem em termos de \"imagens principais\"</p>"},{"location":"aulas/IA/lab04/reducao_dimensionalidade_pca.html#desafio-3","title":"Desafio 3\u00b6","text":"<p>Agora \u00e9 com voc\u00ea termine a implementa\u00e7ao deste classificador de digitos usando o KNN. Usar as novas matrizes no treinamento, teste e avalia\u00e7\u00e3o do classificador</p>"},{"location":"aulas/IA/lab05/validacaocruzada.html","title":"Valida\u00e7\u00e3o de Modelos","text":"In\u00a0[52]: Copied! <pre>from sklearn.datasets import load_iris\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn import metrics                 \n</pre> from sklearn.datasets import load_iris from sklearn.model_selection import train_test_split from sklearn.neighbors import KNeighborsClassifier from sklearn import metrics                  In\u00a0[53]: Copied! <pre># importa o dataset iris\niris = load_iris()\n\n# separa os dados em atributos (x) e alvo (y)\nX = iris.data\ny = iris.target\n</pre> # importa o dataset iris iris = load_iris()  # separa os dados em atributos (x) e alvo (y) X = iris.data y = iris.target In\u00a0[78]: Copied! <pre># divide os dados em treino e teste\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=7)\n\n# treina o modelo com knn=15\nknn = KNeighborsClassifier(n_neighbors=15)\nknn.fit(X_train, y_train)\ny_pred = knn.predict(X_test)\n\n# resultado da acuracia\nmetrics.accuracy_score(y_test, y_pred)\n</pre> # divide os dados em treino e teste X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=7)  # treina o modelo com knn=15 knn = KNeighborsClassifier(n_neighbors=15) knn.fit(X_train, y_train) y_pred = knn.predict(X_test)  # resultado da acuracia metrics.accuracy_score(y_test, y_pred) Out[78]: <pre>0.9</pre> In\u00a0[85]: Copied! <pre>from sklearn.model_selection import KFold\n\ncrossvalidation = KFold(n_splits=10,shuffle=True, random_state=7)\n\nknn = KNeighborsClassifier(n_neighbors=5)\n</pre> from sklearn.model_selection import KFold  crossvalidation = KFold(n_splits=10,shuffle=True, random_state=7)  knn = KNeighborsClassifier(n_neighbors=5) In\u00a0[86]: Copied! <pre>from sklearn.model_selection import cross_val_score\n\nscores = cross_val_score(knn, X, y, cv=crossvalidation, scoring='accuracy')\nprint(\"Array do kfold com os resultados: \",scores)\n</pre> from sklearn.model_selection import cross_val_score  scores = cross_val_score(knn, X, y, cv=crossvalidation, scoring='accuracy') print(\"Array do kfold com os resultados: \",scores) <pre>Array do kfold com os resultados:  [0.86666667 0.86666667 1.         1.         1.         1.\n 1.         0.93333333 0.93333333 0.93333333]\n</pre> In\u00a0[87]: Copied! <pre>print(\"Acuracia m\u00e9dia com kfold: \",scores.mean())\n</pre> print(\"Acuracia m\u00e9dia com kfold: \",scores.mean()) <pre>Acuracia m\u00e9dia com kfold:  0.9533333333333334\n</pre> In\u00a0[88]: Copied! <pre>## implemente aqui....\n</pre> ## implemente aqui....     In\u00a0[\u00a0]: Copied! <pre>from sklearn.model_selection import KFold, StratifiedKFold, ShuffleSplit\n</pre> from sklearn.model_selection import KFold, StratifiedKFold, ShuffleSplit"},{"location":"aulas/IA/lab05/validacaocruzada.html#2-aprendizagem-de-maquina","title":"2. Aprendizagem de m\u00e1quina\u00b6","text":""},{"location":"aulas/IA/lab05/validacaocruzada.html#objetivos","title":"Objetivos\u00b6","text":"<ul> <li>Entender e praticar valida\u00e7\u00e3o cruzada: kfold.</li> </ul>"},{"location":"aulas/IA/lab05/validacaocruzada.html#validacao-cruzada","title":"Valida\u00e7\u00e3o Cruzada\u00b6","text":"<p>A t\u00e9cnica de valida\u00e7\u00e3o cruzada consiste em dividir em partes pequenas (fold) a base de dados e realizar diversos treinamentos e valida\u00e7\u00f5es com partes diferente de treinamento e teste, ao final \u00e9 feita a m\u00e9dia e o desvio padr\u00e3o do aprendizado.</p> <p>Pr\u00f3s:</p> <ul> <li>Normalmente aumenta a performance do modelo.</li> <li>Reduz aleatoriedade, reduz viez.</li> </ul> <p>Contra:</p> <ul> <li>Mais processamento computacional.</li> </ul> <p>Dicas:</p> <ul> <li>A escolha do <code>k</code> numero de folds \u00e9 determinada tipicamente como sendo 5 ou 10.</li> </ul>"},{"location":"aulas/IA/lab05/validacaocruzada.html#diagrama-do-kfold","title":"Diagrama do kfold\u00b6","text":""},{"location":"aulas/IA/lab05/validacaocruzada.html#melhorando-o-modelo","title":"Melhorando o modelo\u00b6","text":"<p>At\u00e9 aqui, sem novidades! Mas... como ficaria o resultado se os grupos de teste e treino fossem alterados? vamos descobrir usando o kfold.</p>"},{"location":"aulas/IA/lab05/validacaocruzada.html#pergunta-o-resultado-foi-praticamente-o-mesmo-por-que","title":"Pergunta: O Resultado foi praticamente o mesmo, por que?\u00b6","text":""},{"location":"aulas/IA/lab05/validacaocruzada.html#desafio-implementamos-kfold-para-o-classificador-knn-implemente-kfold-para-um-modelo-de-regressao","title":"Desafio: Implementamos kfold para o classificador KNN, implemente kfold para um modelo de regress\u00e3o\u00b6","text":""},{"location":"aulas/IA/lab05/validacaocruzada.html#bonus-outras-tecnicas-de-avaliacao-de-modelo","title":"Bonus: Outras t\u00e9cnicas de avalia\u00e7\u00e3o de modelo\u00b6","text":"<ul> <li><p><code>StratifiedKFold</code> = Lida melhor com dados desbalanceados, ou seja, possui uma difer\u00e7a grande entre as frequencias das classes, pois tentar manter a mesma propor\u00e7\u00e3o em todos os folds.</p> </li> <li><p><code>ShuffleSplit</code> = Gera folds aleatorios de treino e teste a cada itera\u00e7\u00e3o. Um cuidado, pode ser que entre uma itera\u00e7\u00e3o e outra os mesmos dados sejam selecionados</p> </li> </ul>"},{"location":"aulas/IA/lab06/rna.html","title":"Lab06 - Redes Neurais - Percepton","text":"<p>A rede Perceptron possui um algoritmo de aprendizado supervisionado que consegue definir um classificador que encontra a superf\u00edcie de separa\u00e7\u00e3o entre quaisquer duas classes linearmente separ\u00e1veis</p> In\u00a0[1]: Copied! <pre>import pandas as pd\n\n\nurl = \"https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data\"\nheader = ['sepal_length', 'sepal_width', 'petal_length', 'petal_width', 'species']\ndf = pd.read_csv(url, header=None, names=header)\n</pre> import pandas as pd   url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data\" header = ['sepal_length', 'sepal_width', 'petal_length', 'petal_width', 'species'] df = pd.read_csv(url, header=None, names=header) In\u00a0[2]: Copied! <pre># Selecionando um sub-dataframe com os campos petal_length e petal_width, \n# e outro com a vari\u00e1vel de classes\nentradas = df[['petal_length', 'petal_width']]\nclasses = df['species']\nprint(f\"Formato das tabelas de dados {entradas.shape} e classes {classes.shape}\")\n</pre> # Selecionando um sub-dataframe com os campos petal_length e petal_width,  # e outro com a vari\u00e1vel de classes entradas = df[['petal_length', 'petal_width']] classes = df['species'] print(f\"Formato das tabelas de dados {entradas.shape} e classes {classes.shape}\") <pre>Formato das tabelas de dados (150, 2) e classes (150,)\n</pre> In\u00a0[3]: Copied! <pre># Separamos 20 % para o teste\nfrom sklearn.model_selection import train_test_split\nentradas_treino, entradas_teste, classes_treino, classes_teste = train_test_split(entradas, classes, test_size=0.2)\nprint(f\"Formato das tabelas de dados de treino {entradas_treino.shape} e teste {entradas_teste.shape}\")\n</pre> # Separamos 20 % para o teste from sklearn.model_selection import train_test_split entradas_treino, entradas_teste, classes_treino, classes_teste = train_test_split(entradas, classes, test_size=0.2) print(f\"Formato das tabelas de dados de treino {entradas_treino.shape} e teste {entradas_teste.shape}\") <pre>Formato das tabelas de dados de treino (120, 2) e teste (30, 2)\n</pre> In\u00a0[4]: Copied! <pre>from sklearn.linear_model import Perceptron\n\n\nmodelo = Perceptron(tol=1.7)\nmodelo.fit(entradas_treino, classes_treino)\n</pre> from sklearn.linear_model import Perceptron   modelo = Perceptron(tol=1.7) modelo.fit(entradas_treino, classes_treino) Out[4]: <pre>Perceptron(tol=1.7)</pre>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.Perceptron<pre>Perceptron(tol=1.7)</pre> In\u00a0[5]: Copied! <pre>classes_encontradas = modelo.predict(entradas_teste)\n</pre> classes_encontradas = modelo.predict(entradas_teste) In\u00a0[6]: Copied! <pre>from sklearn.metrics import accuracy_score\n\nclasses_encontradas_train = modelo.predict(entradas_treino)\nprint(\"Acerto m\u00e9dio de classifica\u00e7\u00e3o treino: \",accuracy_score(classes_encontradas_train, classes_treino))\n\nclasses_encontradas = modelo.predict(entradas_teste)\nprint(\"Acerto m\u00e9dio de classifica\u00e7\u00e3o teste: \",accuracy_score(classes_encontradas, classes_teste))\n</pre> from sklearn.metrics import accuracy_score  classes_encontradas_train = modelo.predict(entradas_treino) print(\"Acerto m\u00e9dio de classifica\u00e7\u00e3o treino: \",accuracy_score(classes_encontradas_train, classes_treino))  classes_encontradas = modelo.predict(entradas_teste) print(\"Acerto m\u00e9dio de classifica\u00e7\u00e3o teste: \",accuracy_score(classes_encontradas, classes_teste)) <pre>Acerto m\u00e9dio de classifica\u00e7\u00e3o treino:  0.675\nAcerto m\u00e9dio de classifica\u00e7\u00e3o teste:  0.6333333333333333\n</pre> In\u00a0[7]: Copied! <pre>from sklearn.metrics import classification_report\n\nprint(classification_report(classes_encontradas, classes_teste))\n</pre>  from sklearn.metrics import classification_report  print(classification_report(classes_encontradas, classes_teste)) <pre>                 precision    recall  f1-score   support\n\n    Iris-setosa       1.00      0.77      0.87        13\nIris-versicolor       0.00      0.00      0.00         0\n Iris-virginica       1.00      0.53      0.69        17\n\n       accuracy                           0.63        30\n      macro avg       0.67      0.43      0.52        30\n   weighted avg       1.00      0.63      0.77        30\n\n</pre> <pre>/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n</pre> In\u00a0[8]: Copied! <pre>from sklearn.neural_network import MLPClassifier\n\ncamadas = [4,3]\nepocas = 1000\nbatch_size = 10\nativacao = 'relu' # Escolha dentre 'logistic', 'tanh' ou 'relu'\n\nmodelo = MLPClassifier(hidden_layer_sizes=camadas,\n                    batch_size=batch_size,\n                    activation=ativacao,\n                    max_iter=epocas)\n</pre> from sklearn.neural_network import MLPClassifier  camadas = [4,3] epocas = 1000 batch_size = 10 ativacao = 'relu' # Escolha dentre 'logistic', 'tanh' ou 'relu'  modelo = MLPClassifier(hidden_layer_sizes=camadas,                     batch_size=batch_size,                     activation=ativacao,                     max_iter=epocas) In\u00a0[9]: Copied! <pre>modelo.fit(entradas_treino, classes_treino)\n</pre>  modelo.fit(entradas_treino, classes_treino) Out[9]: <pre>MLPClassifier(batch_size=10, hidden_layer_sizes=[4, 3], max_iter=1000)</pre>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.MLPClassifier<pre>MLPClassifier(batch_size=10, hidden_layer_sizes=[4, 3], max_iter=1000)</pre> In\u00a0[10]: Copied! <pre>from sklearn.metrics import accuracy_score\n\n\nclasses_encontradas_train = modelo.predict(entradas_treino)\nprint(\"Acerto m\u00e9dio de classifica\u00e7\u00e3o treino: \",accuracy_score(classes_encontradas_train, classes_treino))\n\nclasses_encontradas = modelo.predict(entradas_teste)\nprint(\"Acerto m\u00e9dio de classifica\u00e7\u00e3o teste: \",accuracy_score(classes_encontradas, classes_teste))\n</pre> from sklearn.metrics import accuracy_score   classes_encontradas_train = modelo.predict(entradas_treino) print(\"Acerto m\u00e9dio de classifica\u00e7\u00e3o treino: \",accuracy_score(classes_encontradas_train, classes_treino))  classes_encontradas = modelo.predict(entradas_teste) print(\"Acerto m\u00e9dio de classifica\u00e7\u00e3o teste: \",accuracy_score(classes_encontradas, classes_teste))  <pre>Acerto m\u00e9dio de classifica\u00e7\u00e3o treino:  0.9666666666666667\nAcerto m\u00e9dio de classifica\u00e7\u00e3o teste:  0.9666666666666667\n</pre> In\u00a0[11]: Copied! <pre>from sklearn.metrics import classification_report\n\nprint(classification_report(classes_encontradas, classes_teste))\n</pre> from sklearn.metrics import classification_report  print(classification_report(classes_encontradas, classes_teste)) <pre>                 precision    recall  f1-score   support\n\n    Iris-setosa       1.00      1.00      1.00        10\nIris-versicolor       1.00      0.92      0.96        12\n Iris-virginica       0.89      1.00      0.94         8\n\n       accuracy                           0.97        30\n      macro avg       0.96      0.97      0.97        30\n   weighted avg       0.97      0.97      0.97        30\n\n</pre> In\u00a0[\u00a0]: Copied! <pre>## Seu c\u00f3digo aqui.......\n</pre> ## Seu c\u00f3digo aqui......."},{"location":"aulas/IA/lab06/rna.html#2-aprendizagem-de-maquina","title":"2. Aprendizagem de m\u00e1quina\u00b6","text":""},{"location":"aulas/IA/lab06/rna.html#objetivos","title":"Objetivos\u00b6","text":"<ul> <li>Conhecer uma intui\u00e7\u00e3o sobre Redes Neurais Artificiais RNA</li> <li>Praticar os algoritmos Perceptron e multilayer Perceptron (MLP)</li> </ul>"},{"location":"aulas/IA/lab06/rna.html#redes-neurais-artificiais","title":"Redes Neurais Artificiais\u00b6","text":"<p>As redes neurais s\u00e3o modelos computacionais inspirados pelo sistema nervoso de um animal capazes de realizar o aprendizado de m\u00e1quina bem como o reconhecimento de padr\u00f5es.</p> <p>Tais modelos s\u00e3o muitas vezes utilizados para a tarefa de classifica\u00e7\u00e3o de padr\u00f5es, podendo gerar classificadores com caracter\u00edsticas variadas.</p> <p>As redes neurais artificiais possuem em comum o fato de serem constitu\u00eddas por neur\u00f4nios que se conectam entre si atrav\u00e9s de atrav\u00e9s de sinapses. A rede neural mais conhecida s\u00e3o as baseadas em Perceptron multicamada (MLP) embora existam outras redes como rede de Kohonem, as redes de base radial e a rede de Hopfield.</p>"},{"location":"aulas/IA/lab06/rna.html#os-principais-componentes-dos-neuronios-sao","title":"Os principais componentes dos neur\u00f4nios s\u00e3o:\u00b6","text":"<ul> <li>Os <code>dendritos</code>, que t\u00eam por fun\u00e7\u00e3o receber os est\u00edmulos transmitidos pelos outros neur\u00f4nios;</li> <li>O <code>corpo</code> de neur\u00f4nio, tamb\u00e9m chamado de soma, que \u00e9 respons\u00e1vel por coletar e combinar informa\u00e7\u00f5es vindas de outros neur\u00f4nios;</li> <li>O <code>ax\u00f4nio</code>, que \u00e9 constitu\u00eddo de uma fibra tubular que pode alcan\u00e7ar at\u00e9 alguns metros, e \u00e9 respons\u00e1vel por transmitir os est\u00edmulos para outras c\u00e9lulas.</li> </ul>"},{"location":"aulas/IA/lab06/rna.html#perceptron","title":"Perceptron\u00b6","text":"<p>O classificador Perceptron foi o primeiro classificador baseado em redes neurais que empregou uma regra de aprendizado capaz de garantir a correta separa\u00e7\u00e3o de classes linearmente separ\u00e1veis.</p> <p>No in\u00edcio do treinamento, os pesos dos neur\u00f4nios recebem valores aleat\u00f3rios. Ent\u00e3o, para cada amostra de treinamento com erro de classifica\u00e7\u00e3o, os pesos dos neur\u00f4nios s\u00e3o ajustados de modo a tentar corrigir a classe.</p> <p>Ap\u00f3s o treinamento, cada neur\u00f4nio na camada de sa\u00edda testa a pertin\u00eancia da amostra a uma classe. No caso de mais de um neur\u00f4nio fornecer resposta positiva a amostra, a classe correspondente ao neur\u00f4nio de maior resposta vence.</p> <p> </p>"},{"location":"aulas/IA/lab06/rna.html#instanciar-o-classificador-e-treina-lo-com-as-amostras-de-treinamento","title":"Instanciar o classificador e trein\u00e1-lo com as amostras de treinamento\u00b6","text":"<p>https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Perceptron.html</p>"},{"location":"aulas/IA/lab06/rna.html#analise-f1-score","title":"An\u00e1lise F1-Score\u00b6","text":"<p>A pontua\u00e7\u00e3o F1 pode ser interpretada como uma m\u00e9dia ponderada da precision e recall.</p> <ul> <li>Melhor valor = 1</li> <li>Pior valor = 0</li> </ul> <p>A contribui\u00e7\u00e3o relativa de precision e recall para a pontua\u00e7\u00e3o F1 s\u00e3o iguais. A f\u00f3rmula para a pontua\u00e7\u00e3o F1 \u00e9:</p> <p>F1 = 2 * (precision * recall) / (precision + recall)</p>"},{"location":"aulas/IA/lab06/rna.html#multilayer-perceptron-mlp","title":"Multilayer Perceptron (MLP)\u00b6","text":"<ul> <li>O acr\u00e9scimo de uma nova camada de neur\u00f4nios, denominada camada oculta, permite criar superf\u00edcies de separa\u00e7\u00e3o n\u00e3o lineares, permitindo a classifica\u00e7\u00e3o de classes n\u00e3o-linearmente separ\u00e1veis</li> <li>A rede MLP \u00e9 considerada uma rede do tipo feed-forward, j\u00e1 que as sa\u00eddas dos neur\u00f4nios das camadas posteriores dependem apenas dos neur\u00f4nios das camadas anteriores</li> <li>Em uma rede MLP, n\u00e3o h\u00e1 regra para o n\u00famero de neur\u00f4nios a ser usado na camada oculta, e nem h\u00e1 limites para o n\u00famero de camadas ocultas a serem usadas</li> <li>Aparentemente, um bom chute inicial \u00e9 considerar o dobro de neur\u00f4nios na camada oculta com rela\u00e7\u00e3o ao tamanho da entrada</li> <li>\u00c9 conhecido que com uma \u00fanica camada oculta com um n\u00famero suficientemente grande de n\u00f3s \u00e9 poss\u00edvel representar qualquer fun\u00e7\u00e3o cont\u00ednua, e por isso essa estrutura \u00e9 conhecida como aproximador universal</li> </ul> <p>https://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPClassifier.html</p>"},{"location":"aulas/IA/lab06/rna.html#desafio1","title":"Desafio1\u00b6","text":"<p>Escolha uma dos exemplos dados em sala de aula e implemente um MLP com pelo menos 10 neuronios na camada escondida:</p> <p>OBS: S\u00f3 n\u00e3o vale o data da Iris, pois acabamos de usar...</p>"},{"location":"aulas/IA/lab07/index.html","title":"Deep Learning e Vis\u00e3o Computacional usando TensorFlow","text":"<p>Este tutorial \u00e9 um guia r\u00e1pido de consulta para o mundo do deep learning. </p> <p>Aqui voc\u00ea encontra por meio de exemplos um pouco de teoria para comprees\u00e3o e aplica\u00e7\u00e3o dos conceitos.</p>"},{"location":"aulas/IA/lab07/index.html#objetivos","title":"Objetivos","text":"<ol> <li>Introdu\u00e7\u00e3o</li> <li>Configura\u00e7\u00e3o e Instala\u00e7\u00e3o</li> <li>Entendendo os Conceitos B\u00e1sicos</li> <li>Perceptron</li> <li>Perceptron de M\u00faltiplas Camadas (MLP)</li> <li>Retropropaga\u00e7\u00e3o</li> <li>Otimizadores</li> <li>Redes Neurais Convolucionais (CNN)</li> <li>Implementando uma MLP Simples</li> <li>Treinando o Modelo</li> <li>Avalia\u00e7\u00e3o e Conclus\u00e3o</li> </ol>"},{"location":"aulas/IA/lab07/index.html#introducao","title":"Introdu\u00e7\u00e3o","text":"<p>Deep learning \u00e9 um subconjunto de aprendizado de m\u00e1quina onde redes neurais artificiais, algoritmos inspirados no c\u00e9rebro humano, aprendem a partir de grandes quantidades de dados. Da mesma forma, vis\u00e3o computacional \u00e9 um campo da intelig\u00eancia artificial que treina computadores para interpretar e compreender o mundo visual.</p>"},{"location":"aulas/IA/lab07/index.html#configuracao-e-instalacao","title":"Configura\u00e7\u00e3o e Instala\u00e7\u00e3o","text":"<p>Primeiro, certifique-se de que Python e TensorFlow est\u00e3o instalados em seu sistema. Voc\u00ea pode instalar o TensorFlow com o seguinte comando:</p> <pre><code>pip install tensorflow\n</code></pre>"},{"location":"aulas/IA/lab07/index.html#entendendo-os-conceitos-basicos","title":"Entendendo os Conceitos B\u00e1sicos","text":""},{"location":"aulas/IA/lab07/index.html#perceptron","title":"Perceptron","text":"<p>O Perceptron \u00e9 um modelo de rede neural simples, geralmente utilizado para classifica\u00e7\u00e3o bin\u00e1ria. Consiste em uma \u00fanica camada de neur\u00f4nios, e sua opera\u00e7\u00e3o pode ser descrita pela f\u00f3rmula:</p> <p></p> <p>Podemos calcular o valor de um neuronio da seguinte forma:</p> <p>output = activation_function(weighted_sum + bias)</p> <p>O perceptron \u00e9 uma das formas mais simples de uma rede neural, utilizado para classifica\u00e7\u00e3o bin\u00e1ria. A sa\u00edda de um neur\u00f4nio no perceptron pode ser calculada usando a seguinte f\u00f3rmula:</p> <pre><code>output = activation_function(weighted_sum + bias)\n</code></pre> <p>Onde: </p> <ul> <li><code>weighted_sum</code>: \u00e9 a soma ponderada das entradas (inputs) multiplicadas pelos respectivos pesos (weights).</li> <li><code>activation_function</code>: refere-se \u00e0 fun\u00e7\u00e3o que define o limiar de ativa\u00e7\u00e3o do neur\u00f4nio, como sigmoid, relu ou softmax.</li> <li><code>bias</code>: \u00e9 um termo adicional que permite ajustar a sa\u00edda ao longo da fun\u00e7\u00e3o de ativa\u00e7\u00e3o para melhor adapta\u00e7\u00e3o dos dados</li> </ul>"},{"location":"aulas/IA/lab07/index.html#perceptron-de-multiplas-camadas-mlp","title":"Perceptron de M\u00faltiplas Camadas (MLP)","text":"<p>O <code>MLP (Multilayer Perceptron)</code> \u00e9 uma extens\u00e3o do modelo perceptron que inclui m\u00faltiplas camadas. A estrutura t\u00edpica de um MLP consiste em:</p> <ul> <li><code>Uma camada de entrada</code>, que recebe os dados.</li> <li><code>Uma ou mais camadas ocultas</code>, que transformam os dados de entrada atrav\u00e9s de pesos, biases e fun\u00e7\u00f5es de ativa\u00e7\u00e3o.</li> <li><code>Uma camada de sa\u00edda</code>, que produz a previs\u00e3o final do modelo.</li> </ul> <p>Cada camada \u00e9 <code>totalmente conectada</code> \u00e0 pr\u00f3xima, o que significa que cada neur\u00f4nio em uma camada est\u00e1 conectado a todos os neur\u00f4nios na camada seguinte. O MLP \u00e9 capaz de aprender representa\u00e7\u00f5es n\u00e3o-lineares dos dados, o que o torna adequado para problemas complexos de classifica\u00e7\u00e3o e regress\u00e3o.</p> <p></p>"},{"location":"aulas/IA/lab07/index.html#funcoes-de-ativacao","title":"Fun\u00e7\u00f5es de Ativa\u00e7\u00e3o","text":"<p>As fun\u00e7\u00f5es de ativa\u00e7\u00e3o s\u00e3o componentes essenciais nas redes neurais, respons\u00e1veis por introduzir n\u00e3o-linearidades no modelo. Sem elas, a rede seria essencialmente um modelo linear e incapaz de aprender e representar dados complexos que requerem n\u00e3o-linearidade para sua modelagem. As fun\u00e7\u00f5es de ativa\u00e7\u00e3o decidem se um neur\u00f4nio deve ser ativado ou n\u00e3o, com base no valor da soma ponderada de suas entradas.</p>"},{"location":"aulas/IA/lab07/index.html#exemplos-comuns","title":"Exemplos Comuns:","text":"<ul> <li><code>ReLU (Rectified Linear Unit)</code>: Oferece uma resposta linear para todos os valores positivos e zero para valores negativos. \u00c9 a mais usada devido \u00e0 sua efici\u00eancia computacional e \u00e0 capacidade de mitigar o problema do desaparecimento do gradiente em redes profundas.</li> <li><code>Sigmoid</code>: Transforma os valores em uma faixa entre 0 e 1, \u00fatil especialmente para modelos onde precisamos de uma probabilidade como sa\u00edda; contudo, \u00e9 menos usada em camadas ocultas devido a problemas de desaparecimento de gradiente.</li> <li><code>Tanh (Tangente Hiperb\u00f3lica)</code>: Semelhante \u00e0 sigmoid, mas transforma os valores em uma faixa entre -1 e 1, centrando os dados e, portanto, melhorando a efici\u00eancia do aprendizado nas camadas ocultas.</li> </ul>"},{"location":"aulas/IA/lab07/index.html#retropropagacao-backpropagation","title":"Retropropaga\u00e7\u00e3o (Backpropagation)","text":"<p>A Retropropaga\u00e7\u00e3o \u00e9 uma t\u00e9cnica para treinar redes neurais, permitindo o ajuste dos pesos de conex\u00e3o ap\u00f3s cada itera\u00e7\u00e3o de treinamento. Este m\u00e9todo utiliza o <code>c\u00e1lculo do gradiente</code> da <code>fun\u00e7\u00e3o de perda</code> em rela\u00e7\u00e3o a cada peso, propagando o erro de sa\u00edda de volta pela rede para atualizar os pesos. Isso minimiza a fun\u00e7\u00e3o de perda ao longo do tempo, melhorando a precis\u00e3o do modelo ao ajust\u00e1-lo mais eficazmente aos dados de treinamento.</p>"},{"location":"aulas/IA/lab07/index.html#funcionamento","title":"Funcionamento:","text":"<ul> <li>Calcula-se o gradiente da fun\u00e7\u00e3o de perda para determinar a dire\u00e7\u00e3o na qual os pesos devem ser ajustados para minimizar o erro.</li> <li>Os pesos s\u00e3o atualizados utilizando este gradiente, geralmente com a ajuda de um otimizador como SGD, Adam, entre outros.</li> <li>Este processo \u00e9 repetido para cada lote de dados (batch) durante v\u00e1rias \u00e9pocas, ajustando progressivamente os pesos para melhorar o desempenho do modelo.</li> </ul> <p>Esses ajustes permitem que a rede aprenda de forma eficiente, refinando seus pesos para reduzir o erro total e aumentar a precis\u00e3o nas tarefas de classifica\u00e7\u00e3o ou regress\u00e3o.</p>"},{"location":"aulas/IA/lab07/index.html#otimizadores","title":"Otimizadores","text":"<p>Otimizadores s\u00e3o algoritmos projetados para otimizar o processo de treinamento de uma rede neural, ajustando os pesos e a taxa de aprendizagem. \u00c9 importante para determinar a rapidez e efic\u00e1cia com que uma rede neural aprende. </p> <p>Alguns exemplos comuns incluem:</p> <ul> <li>SGD (Descida do Gradiente Estoc\u00e1stico)</li> <li>Adam</li> <li>RMSprop</li> <li>Dentre outros, cada um com suas pr\u00f3prias caracter\u00edsticas e adequa\u00e7\u00f5es a diferentes tipos de problemas e conjuntos de dados.</li> </ul> <p></p>"},{"location":"aulas/IA/lab07/index.html#redes-neurais-convolucionais-cnn","title":"Redes Neurais Convolucionais (CNN)","text":"<p>Redes Neurais Convolucionais (CNNs) s\u00e3o uma classe especializada de redes neurais profundas que s\u00e3o particularmente para tarefas de processamento de imagem e v\u00eddeo. Utilizam o processo de convolu\u00e7\u00e3o para capturar caracter\u00edsticas visuais importantes como bordas, texturas e padr\u00f5es mais complexos sem a necessidade de interven\u00e7\u00e3o ou extra\u00e7\u00e3o manual de caracter\u00edsticas.</p>"},{"location":"aulas/IA/lab07/index.html#principais-componentes","title":"Principais Componentes","text":"<ul> <li>Camadas Convolucionais: O cora\u00e7\u00e3o de uma CNN. Estas camadas utilizam filtros que realizam a convolu\u00e7\u00e3o sobre a entrada para criar mapas de caracter\u00edsticas que resumem as presen\u00e7as de caracter\u00edsticas espec\u00edficas na entrada.</li> <li>Fun\u00e7\u00e3o de Ativa\u00e7\u00e3o: Normalmente, uma fun\u00e7\u00e3o ReLU \u00e9 aplicada ap\u00f3s cada convolu\u00e7\u00e3o para introduzir n\u00e3o-linearidades ao modelo, ajudando-o a aprender mais complexidades.</li> <li>Camadas de Pooling: Seguem as camadas convolucionais e s\u00e3o usadas para reduzir as dimens\u00f5es dos mapas de caracter\u00edsticas, o que ajuda a diminuir o c\u00e1lculo necess\u00e1rio e tamb\u00e9m controla o overfitting.</li> <li>Camadas Densas (Fully Connected Layers): Ap\u00f3s v\u00e1rias camadas convolucionais e de pooling, a rede utiliza uma ou mais camadas densas onde a classifica\u00e7\u00e3o final \u00e9 realizada baseada nas caracter\u00edsticas extra\u00eddas anteriormente.</li> </ul>"},{"location":"aulas/IA/lab07/index.html#funcionamento_1","title":"Funcionamento","text":"<p>Uma CNN recebe uma imagem como entrada, que \u00e9 passada atrav\u00e9s de uma s\u00e9rie de camadas convolucionais com filtros (kernels), camadas de pooling, e eventualmente camadas densas para produzir uma sa\u00edda, que pode ser uma classifica\u00e7\u00e3o ou outra interpreta\u00e7\u00e3o da imagem. Em cada camada convolucional, a rede aprende a identificar caracter\u00edsticas cada vez mais complexas. \u00c0 medida que os dados avan\u00e7am pela rede, a \"vis\u00e3o\" da rede torna-se cada vez mais abstrata, permitindo que ela reconhe\u00e7a grandes padr\u00f5es compostos por caracter\u00edsticas menores capturadas nas primeiras camadas.</p>"},{"location":"aulas/IA/lab07/index.html#aplicacoes","title":"Aplica\u00e7\u00f5es","text":"<p>As CNNs t\u00eam sido usadas com grande sucesso em uma variedade de aplica\u00e7\u00f5es de vis\u00e3o computacional:</p> <ul> <li><code>Reconhecimento de Imagens</code>: Identifica\u00e7\u00e3o de objetos, pessoas, cenas e atividades em imagens.</li> <li><code>Classifica\u00e7\u00e3o de Imagens</code>: Classificar imagens em categorias pr\u00e9-definidas.</li> <li><code>Detec\u00e7\u00e3o de Objetos</code>: Localizar e identificar m\u00faltiplos objetos dentro de uma \u00fanica imagem.</li> <li><code>Segmenta\u00e7\u00e3o Sem\u00e2ntica</code>: Classificar cada pixel de uma imagem em uma categoria de objeto, permitindo uma compreens\u00e3o detalhada da cena.</li> </ul>"},{"location":"aulas/IA/lab07/index.html#implementando-um-mlp-simples","title":"Implementando um MLP Simples","text":"<p>Vamos implementar um exemplo simples de uma rede neural multicamadas (MLP) usando TensorFlow, aplicada ao conjunto de dados <code>MNIST</code>, que consiste em <code>imagens de d\u00edgitos escritos \u00e0 m\u00e3o</code>:</p> <p></p>"},{"location":"aulas/IA/lab07/index.html#importando-o-dataset-e-bibliotecas","title":"Importando o dataset e bibliotecas","text":"<p>Come\u00e7amos importando a biblioteca <code>tensorflow</code> e o dataset mninst. Esse dataset \u00e9 bem famoso e faz parte dos do da biblioteca tensorflow. Precisamos fazer uma transforma\u00e7\u00e3o simples nas imagens de entrada para normalizar entre 0 e 1.</p> <pre><code>import tensorflow as tf\n\n# Carregando o conjunto de dados MNIST\nmnist = tf.keras.datasets.mnist\n(x_train, y_train), (x_test, y_test) = mnist.load_data()\n\n# Normalizando os dados\nx_train, x_test = x_train / 255.0, x_test / 255.0\n</code></pre>"},{"location":"aulas/IA/lab07/index.html#criando-a-rede-neural","title":"Criando a Rede Neural","text":"<p>Para construir nossa rede neural, utilizaremos a classe Sequential do TensorFlow, que permite compor modelos camada por camada de maneira simples e direta. Aqui est\u00e1 o detalhamento de cada componente utilizado:</p> <p>Warning</p> <p>Substitua os campos <code>&lt;QUANTIDADE_NEURONIOS&gt;</code>e <code>&lt;FUNCAO_ATIVACAO&gt;</code> nos lugares indicados para configurar o n\u00famero de neur\u00f4nios e as fun\u00e7\u00f5es de ativa\u00e7\u00e3o.</p> <p>Tip</p> <p>A quantidade de neur\u00f4nios na <code>camada de sa\u00edda</code> deve ser igual \u00e0 quantidade de classes a serem preditas no MNIST, que s\u00e3o 10 (d\u00edgitos de 0 a 9).</p> <p>Tip</p> <p>Utilize a fun\u00e7\u00e3o de ativa\u00e7\u00e3o <code>relu</code> para as camadas intermedi\u00e1rias, pois ajuda a resolver o problema do desaparecimento do gradiente em redes profundas. Para a camada de sa\u00edda, use <code>softmax</code> para converter as sa\u00eddas em probabilidades de pertencimento \u00e0s classes.</p>"},{"location":"aulas/IA/lab07/index.html#componentes-do-modelo","title":"Componentes do Modelo","text":"<ul> <li><code>Sequential</code>: Esta \u00e9 a classe base para definir uma pilha de camadas de rede neural. Voc\u00ea come\u00e7a com uma lista vazia e adiciona camadas usando a nota\u00e7\u00e3o de lista. Cada camada adicionada \u00e9 empilhada sobre a anterior, o que facilita a modelagem de um fluxo de dados direto (feedforward).</li> <li><code>Flatten</code>: Transforma a matriz 2D de entrada (28x28 pixels da imagem) em um vetor 1D. Isso \u00e9 necess\u00e1rio porque a primeira camada densa (Dense) espera um vetor como entrada.</li> <li><code>Dense</code>: \u00c9 a camada de neur\u00f4nios densamente conectados ou completamente conectados. Cada neur\u00f4nio recebe entrada de todos os neur\u00f4nios da camada anterior, mantendo uma conex\u00e3o densa.</li> <li>: Aqui voc\u00ea define quantos neur\u00f4nios deseja nesta camada. <li>: Define a fun\u00e7\u00e3o de ativa\u00e7\u00e3o a ser usada. A fun\u00e7\u00e3o relu \u00e9 comum para camadas internas. <pre><code># Criando o modelo MLP\nmodel = tf.keras.models.Sequential([\n  tf.keras.layers.Flatten(input_shape=(28, 28)),\n  tf.keras.layers.Dense(&lt;QUANTIDADE_NEURONIOS&gt;, activation=&lt;FUNCAO_ATIVACAO&gt;),\n  tf.keras.layers.Dense(&lt;QUANTIDADE_NEURONIOS&gt;, activation=&lt;FUNCAO_ATIVACAO&gt;)\n])\n</code></pre>"},{"location":"aulas/IA/lab07/index.html#compilando-o-modelo","title":"Compilando o Modelo","text":"<p>Agora, vamos compilar o modelo utilizando o <code>otimizador Adam</code> e a fun\u00e7\u00e3o de perda <code>sparse_categorical_crossentropy</code>, adequada para classifica\u00e7\u00e3o de m\u00faltiplas classes onde as classes s\u00e3o fornecidas como n\u00fameros inteiros:</p> <p>Warning</p> <p>Substitua os campos <code>&lt;KEY&gt;</code> por valores convenientes. Para <code>&lt;METRICA&gt;</code> utilize <code>accuracy</code>.</p> <pre><code>model.compile(optimizer=&lt;OTIMIZADOR&gt;, \n              loss=&lt;LOSS&gt;, \n              metrics=[&lt;METRICA&gt;])\n</code></pre>"},{"location":"aulas/IA/lab07/index.html#compilando-o-modelo_1","title":"Compilando o Modelo","text":"<p>Agora, vamos compilar o modelo passando os conjuntos de dados <code>x_train</code> e <code>y_train</code>, definindo a quantidade \u00e9pocas de treinamento e ajustando um subset de 20% para valida\u00e7\u00e3o. </p> <p>Warning</p> <p>Substitua os campos <code>&lt;KEY&gt;</code> por valores convenientes. Defina 30 \u00e9pocas e 0.2 de vali\u00e7ao.</p> <pre><code># Treinando o modelo\nepocas_hist = model.fit(&lt;X_TREINO&gt;, &lt;Y_TREINO&gt;, epochs=&lt;EPOCAS&gt;, validation_split=&lt;VALIDACAO&gt;)\n</code></pre>"},{"location":"aulas/IA/lab07/index.html#visualizando-o-historico-de-treinamento","title":"Visualizando o historico de treinamento","text":"<p>O historico de treinamento \u00e9 salvo na variavel <code>epocas_hist</code>, podemos visualizar utlizando o pandas</p> <pre><code>import pandas as pd\n\ndf_historico = pd.DataFrame(epocas_hist.history)\ndf_historico.info()\n\ndf_historico[['loss','val_loss']].plot(); plt.show();\ndf_historico[['accuracy','val_accuracy']].plot(); plt.show();\n</code></pre>"},{"location":"aulas/IA/lab07/index.html#avaliacao-e-conclusao","title":"Avalia\u00e7\u00e3o e Conclus\u00e3o","text":"<p>Ap\u00f3s o treinamento, avaliamos o modelo no conjunto de teste para verificar sua acur\u00e1cia e a perda:</p> <p>Warning</p> <p>Substitua os campos <code>&lt;KEY&gt;</code> por valores convenientes. </p> <pre><code>test_loss, test_acc = model.evaluate(&lt;X_TESTE&gt;, &lt;Y_TESTE&gt;)\nprint(f\"Teste Acur\u00e1cia: {test_acc:.3f}, Teste Loss: {test_loss:.3f}\")\n</code></pre>"},{"location":"aulas/IA/lab07/index.html#salvando-o-modelo","title":"Salvando o modelo","text":"<pre><code># Salvando o modelo treinado\nmodel.save('mnist_mlp_model.h5')\n</code></pre>"},{"location":"aulas/IA/lab07/index.html#importando-uma-imagem-e-usando-com-o-modelo-treinado","title":"Importando uma Imagem e Usando com o Modelo Treinado","text":"<p>Para usar uma imagem pr\u00f3pria e verificar como o modelo MLP prev\u00ea o d\u00edgito, precisamos garantir que a imagem seja processada de maneira semelhante ao conjunto de dados MNIST. A imagem deve ser em escala de cinza, de tamanho 28x28 pixels, e normalizada.</p> <pre><code>import tensorflow as tf\nfrom tensorflow.keras.preprocessing import image\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# Carregando o modelo treinado (certifique-se de que o modelo est\u00e1 dispon\u00edvel)\nmodel = tf.keras.models.load_model('mnist_mlp_model.h5')\n\n# Fun\u00e7\u00e3o para carregar e preparar a imagem\ndef load_and_prepare_image(filepath):\n    img = image.load_img(filepath, color_mode='grayscale', target_size=(28, 28))\n    img = image.img_to_array(img)\n    img = img.reshape(1, 28, 28)\n    img = img.astype('float32')\n    img /= 255.0\n    return img\n\n# Caminho para a sua imagem\nfilepath = 'path_to_your_image.png' # escolha uma imagem com um numero simples \n\n# Carregando e preparando a imagem\nimg = load_and_prepare_image(filepath)\n\n# Fazendo a previs\u00e3o\npredictions = model.predict(img)\npredicted_digit = np.argmax(predictions)\n\n# Mostrando a imagem e a previs\u00e3o\nplt.imshow(img.reshape(28, 28), cmap='gray')\nplt.title(f'Previs\u00e3o: {predicted_digit}')\nplt.show()\n</code></pre>"},{"location":"aulas/IA/lab07/mlp.html","title":"Lab07b - Redes Neurais - MLP","text":"In\u00a0[23]: Copied! <pre>import tensorflow as tf\nfrom tensorflow import keras\n</pre> import tensorflow as tf from tensorflow import keras  In\u00a0[25]: Copied! <pre>from tensorflow.keras import layers\n\n\nmodel = keras.Sequential([\n    layers.Dense(units=1, input_shape=[1])\n])\n\nmodel.summary()\n</pre> from tensorflow.keras import layers   model = keras.Sequential([     layers.Dense(units=1, input_shape=[1]) ])  model.summary()  <pre>Model: \"sequential_4\"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\n dense_4 (Dense)             (None, 1)                 2         \n                                                                 \n=================================================================\nTotal params: 2 (8.00 Byte)\nTrainable params: 2 (8.00 Byte)\nNon-trainable params: 0 (0.00 Byte)\n_________________________________________________________________\n</pre> In\u00a0[\u00a0]: Copied! <pre>## Sua resposta aqui...\n</pre> ## Sua resposta aqui...      In\u00a0[26]: Copied! <pre>model.compile(optimizer=tf.keras.optimizers.Adam(0.1), loss = 'mse')\n</pre> model.compile(optimizer=tf.keras.optimizers.Adam(0.1), loss = 'mse') In\u00a0[7]: Copied! <pre>!wget https://raw.githubusercontent.com/arnaldojr/cognitivecomputing/master/material/aulas/IA/lab07/SalesData.csv /content\n</pre> !wget https://raw.githubusercontent.com/arnaldojr/cognitivecomputing/master/material/aulas/IA/lab07/SalesData.csv /content  <pre>--2023-10-02 12:57:46--  https://raw.githubusercontent.com/arnaldojr/cognitivecomputing/master/material/aulas/IA/lab07/SalesData.csv\nResolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.110.133, 185.199.109.133, ...\nConnecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 11884 (12K) [text/plain]\nSaving to: \u2018SalesData.csv\u2019\n\n\r\nSalesData.csv         0%[                    ]       0  --.-KB/s               \r\nSalesData.csv       100%[===================&gt;]  11.61K  --.-KB/s    in 0s      \n\n2023-10-02 12:57:46 (39.1 MB/s) - \u2018SalesData.csv\u2019 saved [11884/11884]\n\n/content: Scheme missing.\nFINISHED --2023-10-02 12:57:46--\nTotal wall clock time: 0.2s\nDownloaded: 1 files, 12K in 0s (39.1 MB/s)\n</pre> In\u00a0[27]: Copied! <pre>import pandas as pd\nimport numpy as np\ndf = pd.read_csv('SalesData.csv')\ndf.info()\n\nX_train = df['Temperature']\ny_train = df['Revenue']\n\nprint(X_train)\n</pre> import pandas as pd import numpy as np df = pd.read_csv('SalesData.csv') df.info()  X_train = df['Temperature'] y_train = df['Revenue']  print(X_train) <pre>&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 500 entries, 0 to 499\nData columns (total 2 columns):\n #   Column       Non-Null Count  Dtype  \n---  ------       --------------  -----  \n 0   Temperature  500 non-null    float64\n 1   Revenue      500 non-null    float64\ndtypes: float64(2)\nmemory usage: 7.9 KB\n0      24.566884\n1      26.005191\n2      27.790554\n3      20.595335\n4      11.503498\n         ...    \n495    22.274899\n496    32.893092\n497    12.588157\n498    22.362402\n499    28.957736\nName: Temperature, Length: 500, dtype: float64\n</pre> In\u00a0[28]: Copied! <pre>import seaborn as sns\n\nsns.scatterplot(x=X_train, y=y_train);\n</pre> import seaborn as sns  sns.scatterplot(x=X_train, y=y_train); In\u00a0[\u00a0]: Copied! <pre>epochs_hist = model.fit(X_train, y_train, epochs=1000)\n</pre> epochs_hist = model.fit(X_train, y_train, epochs=1000) In\u00a0[30]: Copied! <pre>import pandas as pd\n\nhistory_df = pd.DataFrame(epochs_hist.history)\n\nhistory_df['loss'].plot();\n</pre> import pandas as pd  history_df = pd.DataFrame(epochs_hist.history)  history_df['loss'].plot(); In\u00a0[31]: Copied! <pre># Previs\u00f5es com o modelo treinado\ntemp = 5\nrevenue = model.predict([temp])\nprint('Revenue Predictions Using Trained ANN =', revenue)\n</pre> # Previs\u00f5es com o modelo treinado temp = 5 revenue = model.predict([temp]) print('Revenue Predictions Using Trained ANN =', revenue) <pre>1/1 [==============================] - 0s 160ms/step\nRevenue Predictions Using Trained ANN = [[152.05663]]\n</pre> In\u00a0[33]: Copied! <pre>from matplotlib import pyplot as plt\n\nplt.scatter(X_train, y_train, color = 'gray')\nplt.plot(X_train, model.predict(X_train), color = 'red')\nplt.ylabel('Revenue [dollars]')\nplt.xlabel('Temperature [degC]')\nplt.title('Revenue Generated vs. Temperature @Ice Cream Stand');\n</pre> from matplotlib import pyplot as plt  plt.scatter(X_train, y_train, color = 'gray') plt.plot(X_train, model.predict(X_train), color = 'red') plt.ylabel('Revenue [dollars]') plt.xlabel('Temperature [degC]') plt.title('Revenue Generated vs. Temperature @Ice Cream Stand'); <pre>16/16 [==============================] - 0s 3ms/step\n</pre> In\u00a0[\u00a0]: Copied! <pre>import pandas as pd\nimport numpy as np\nimport seaborn as sns\nfrom matplotlib import pyplot as plt\nfrom tensorflow.keras import layers\nimport tensorflow as tf\nfrom tensorflow import keras\n\ndef carregar_e_visualizar_dados():\n    # Carregar os dados\n    #!wget https://raw.githubusercontent.com/arnaldojr/cognitivecomputing/master/material/aulas/IA/lab07/SalesData.csv /content\n    df = pd.read_csv('SalesData.csv')\n    df.info()\n\n    # Separar os dados\n    X_train = df['Temperature']\n    y_train = df['Revenue']\n\n    # Visualizar os dados\n    sns.scatterplot(x=X_train, y=y_train)\n    plt.show()\n\n    return X_train, y_train\n\ndef criar_e_compilar_modelo():\n    # Criar o modelo\n    model = keras.Sequential([\n        layers.Dense(units=1, input_shape=[1])\n    ])\n\n    # Compilar o modelo\n    model.compile(optimizer=tf.keras.optimizers.Adam(0.1), loss='mse')\n    model.summary()\n\n    return model\n\ndef treinar_modelo(model, X_train, y_train, epochs=100):\n    historico_epochs = model.fit(X_train, y_train, epochs=epochs)\n    df_historico = pd.DataFrame(historico_epochs.history)\n    df_historico['loss'].plot()\n    plt.show()\n    return model\n\ndef avaliar_e_prever(model, X_train, y_train):\n    # Visualizar as predi\u00e7\u00f5es do modelo\n    plt.scatter(X_train, y_train, color='gray')\n    plt.plot(X_train, model.predict(X_train), color='red')\n    plt.ylabel('Receita [d\u00f3lares]')\n    plt.xlabel('Temperatura [\u00b0C]')\n    plt.title('Receita Gerada vs. Temperatura no Ponto de Venda de Sorvetes')\n    plt.show()\n\n    # Fazer uma previs\u00e3o\n    temp = 5\n    receita = model.predict([temp])\n    print('Previs\u00e3o de Receita Usando a ANN Treinada =', receita)\n\n# Carregar e visualizar os dados\nX_train, y_train = carregar_e_visualizar_dados()\n\n# Criar e compilar o modelo\nmodel = criar_e_compilar_modelo()\n\n# Treinar o modelo\nmodel = treinar_modelo(model, X_train, y_train)\n\n# Avaliar e fazer predi\u00e7\u00f5es\navaliar_e_prever(model, X_train, y_train)\n</pre> import pandas as pd import numpy as np import seaborn as sns from matplotlib import pyplot as plt from tensorflow.keras import layers import tensorflow as tf from tensorflow import keras  def carregar_e_visualizar_dados():     # Carregar os dados     #!wget https://raw.githubusercontent.com/arnaldojr/cognitivecomputing/master/material/aulas/IA/lab07/SalesData.csv /content     df = pd.read_csv('SalesData.csv')     df.info()      # Separar os dados     X_train = df['Temperature']     y_train = df['Revenue']      # Visualizar os dados     sns.scatterplot(x=X_train, y=y_train)     plt.show()      return X_train, y_train  def criar_e_compilar_modelo():     # Criar o modelo     model = keras.Sequential([         layers.Dense(units=1, input_shape=[1])     ])      # Compilar o modelo     model.compile(optimizer=tf.keras.optimizers.Adam(0.1), loss='mse')     model.summary()      return model  def treinar_modelo(model, X_train, y_train, epochs=100):     historico_epochs = model.fit(X_train, y_train, epochs=epochs)     df_historico = pd.DataFrame(historico_epochs.history)     df_historico['loss'].plot()     plt.show()     return model  def avaliar_e_prever(model, X_train, y_train):     # Visualizar as predi\u00e7\u00f5es do modelo     plt.scatter(X_train, y_train, color='gray')     plt.plot(X_train, model.predict(X_train), color='red')     plt.ylabel('Receita [d\u00f3lares]')     plt.xlabel('Temperatura [\u00b0C]')     plt.title('Receita Gerada vs. Temperatura no Ponto de Venda de Sorvetes')     plt.show()      # Fazer uma previs\u00e3o     temp = 5     receita = model.predict([temp])     print('Previs\u00e3o de Receita Usando a ANN Treinada =', receita)  # Carregar e visualizar os dados X_train, y_train = carregar_e_visualizar_dados()  # Criar e compilar o modelo model = criar_e_compilar_modelo()  # Treinar o modelo model = treinar_modelo(model, X_train, y_train)  # Avaliar e fazer predi\u00e7\u00f5es avaliar_e_prever(model, X_train, y_train)   In\u00a0[\u00a0]: Copied! <pre>### Seu c\u00f3digo aqui.....\n</pre> ### Seu c\u00f3digo aqui....."},{"location":"aulas/IA/lab07/mlp.html#2-aprendizagem-de-maquina","title":"2. Aprendizagem de m\u00e1quina\u00b6","text":""},{"location":"aulas/IA/lab07/mlp.html#objetivos","title":"Objetivos\u00b6","text":"<ul> <li>Praticar os algoritmos Perceptron e multilayer Perceptron (MLP)</li> <li>Conhecer uma intui\u00e7\u00e3o sobre fun\u00e7\u00e3o de ativa\u00e7\u00e3o, backpropagation</li> <li>Conhecer e praticar o framework TensorFlow</li> </ul>"},{"location":"aulas/IA/lab07/mlp.html#perceptron","title":"Perceptron\u00b6","text":"<p>Relembrando o neuronio artificial:</p>"},{"location":"aulas/IA/lab07/mlp.html#desafio1","title":"Desafio1\u00b6","text":"<p>Calcule a saida do perceptron abaixo:</p> <p>x0 = 2; x1 = 0; x2 = -1,24; bias = 1; w0 = 0; w1 = 2; w3 = 1; fun\u00e7\u00e3o de ativa\u00e7\u00e3o = Heaviside</p>"},{"location":"aulas/IA/lab07/mlp.html#resposta","title":"Resposta:\u00b6","text":""},{"location":"aulas/IA/lab07/mlp.html#implementacao-de-uma-rede-perceptron","title":"Implementa\u00e7\u00e3o de uma rede perceptron\u00b6","text":"<p>Vamos usar um framework de machine learnning chamado TensorFlow/keras para fazer esta implementa\u00e7\u00e3o.</p> <p>pip install tensorflow</p>"},{"location":"aulas/IA/lab07/mlp.html#layers","title":"Layers\u00b6","text":"<p>O arranjo de neuronios define a quantidade de camadas ou <code>layers</code> que a rede neural possui na rede perceptron possui apenas uma camada. Em uma rede MLP (multlayer perceptron) possui al\u00e9m das camadas de entrada e sa\u00edda, camadas ocultas ou <code>hiden layers</code>, essas redes tambem s\u00e3o conhecidas por redes densas ou fully-connected.</p>"},{"location":"aulas/IA/lab07/mlp.html#funao-de-ativacao","title":"Fun\u00e3o de ativa\u00e7\u00e3o\u00b6","text":"<p>\u00c9 basicamente uma fun\u00e7\u00e3o matematica que \u00e9 responsavel por ativar ou n\u00e3o a sa\u00edda do neuronio. Dentre as mais comuns se destaca a fun\u00e7\u00e3o ReLU (Rectifier linear unit)</p> <p>Outras fun\u00e7\u00f5es de ativa\u00e7\u00e3o muito utilizadas s\u00e3o:</p> <ul> <li>softplus</li> <li>elu</li> <li>sigmoid</li> <li>tanh</li> </ul>"},{"location":"aulas/IA/lab07/mlp.html#desafio-2","title":"Desafio 2\u00b6","text":"<p>Implemente a rede MLP abaixo usando TensorFlor/keras: fun\u00e7\u00e3o de ativa\u00e7\u00e3o Relu</p>"},{"location":"aulas/IA/lab07/mlp.html#backpropagation","title":"Backpropagation\u00b6","text":"<p>Trata-se de uma t\u00e9cnica para realizar o ajuste dos pesos de uma rede neural. O objetivo de um rede neural \u00e9 sempre minimar o seu erro, tendo a menor <code>Loss</code>para guiar o modelo para a dire\u00e7\u00e3o certa.</p> <p>A fun\u00e7\u00e3o Loss mede o qu\u00e3o boa est\u00e3o as predi\u00e7\u00f5es darede, para problemas de regress\u00e3o s\u00e3o mais utilizados o MSE, ou MAE. J\u00e1 par classifia\u00e7\u00e3o, s\u00e3o utlizados BCE.</p> <p>Os algoritimos otimizadores s\u00e3o utilzados para ajustar os pesos das redes, o passo dado na descida do gradiente \u00e9 chamada de taxa de aprendizado e mais utilizados s\u00e3o:</p> <ul> <li>SGD</li> <li>RMSprop</li> <li>Adam</li> <li>Adadelta</li> <li>Adagrad</li> <li>Adamax</li> <li>Nadam</li> <li>Ftrl</li> </ul> <p></p> <p></p> <p>Cada itera\u00e7\u00e3o das amostras de treinamento \u00e9 chamada de bach e uma rodada completa de treinamento \u00e9 chamada de epoch. O numero</p>"},{"location":"aulas/IA/lab07/mlp.html#em-resumo-nos-fizemos-o-seguinte","title":"em resumo nos fizemos o seguinte:\u00b6","text":"<ul> <li>Carregar e Visualizar os Dados</li> <li>Criar e Compilar o Modelo</li> <li>Treinamento</li> <li>Avalia\u00e7\u00e3o e Predi\u00e7\u00e3o</li> </ul>"},{"location":"aulas/IA/lab07/mlp.html#desafio-implementacao-end-to-end-mlp","title":"Desafio: Implementa\u00e7\u00e3o end-to-end MLP\u00b6","text":"<p>Realize o treinamento de uma rede MLP para o dataset Fashion MNIST. Um guia passo a passo pode ser encontrado no link https://www.tensorflow.org/tutorials/keras/classification.</p>"},{"location":"aulas/IA/lab08/Exemplo_CNN_Dataset_CIFAR10_com_Salvamento_no_GDrive.html","title":"O keras passa a salvar o melhor modelo pela acur\u00e1cia de valida\u00e7\u00e3o","text":"In\u00a0[1]: Copied! <pre>from keras.datasets import cifar10\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom keras.models import Sequential,load_model\nfrom keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, AveragePooling2D\n#from keras.utils import np_utils\nfrom keras.utils import to_categorical\n#from keras.utils import plot_model\nfrom keras.utils import plot_model\n\nimport tensorflow as tf\n</pre> from keras.datasets import cifar10 import numpy as np import matplotlib.pyplot as plt from keras.models import Sequential,load_model from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, AveragePooling2D #from keras.utils import np_utils from keras.utils import to_categorical #from keras.utils import plot_model from keras.utils import plot_model  import tensorflow as tf <p>Inicializa o Google Drive. \u00c9 necess\u00e1rio entrar com as credenciais do Gmail</p> In\u00a0[2]: Copied! <pre>from google.colab import drive\ndrive.mount('/content/drive')\n</pre> from google.colab import drive drive.mount('/content/drive') <pre>Mounted at /content/drive\n</pre> In\u00a0[3]: Copied! <pre>(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n</pre> (x_train, y_train), (x_test, y_test) = cifar10.load_data() <pre>Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n170498071/170498071 [==============================] - 13s 0us/step\n</pre> In\u00a0[4]: Copied! <pre>print(f'Train: X={x_train.shape}, y={y_train.shape}')\nprint(f'Test: X={x_test.shape}, y={y_test.shape}')\n# plot first few images\nfor i in range(9):\n\t# define subplot\n\tplt.subplot(330 + 1 + i)\n\t# plot raw pixel data\n\tplt.imshow(x_train[i])\n# show the figure\nplt.show()\n</pre> print(f'Train: X={x_train.shape}, y={y_train.shape}') print(f'Test: X={x_test.shape}, y={y_test.shape}') # plot first few images for i in range(9): \t# define subplot \tplt.subplot(330 + 1 + i) \t# plot raw pixel data \tplt.imshow(x_train[i]) # show the figure plt.show() <pre>Train: X=(50000, 32, 32, 3), y=(50000, 1)\nTest: X=(10000, 32, 32, 3), y=(10000, 1)\n</pre> In\u00a0[5]: Copied! <pre>x_train = x_train.astype('float32')/255\nx_test = x_test.astype('float32')/255\n</pre> x_train = x_train.astype('float32')/255 x_test = x_test.astype('float32')/255 <p>\"One-hot encoding\" aplicado aos r\u00f3tulos</p> In\u00a0[6]: Copied! <pre>num_classes = len(np.unique(y_train))\ny_train = to_categorical(y_train, num_classes)\ny_test = to_categorical(y_test, num_classes)\n</pre> num_classes = len(np.unique(y_train)) y_train = to_categorical(y_train, num_classes) y_test = to_categorical(y_test, num_classes) In\u00a0[7]: Copied! <pre>y_train\n</pre> y_train Out[7]: <pre>array([[0., 0., 0., ..., 0., 0., 0.],\n       [0., 0., 0., ..., 0., 0., 1.],\n       [0., 0., 0., ..., 0., 0., 1.],\n       ...,\n       [0., 0., 0., ..., 0., 0., 1.],\n       [0., 1., 0., ..., 0., 0., 0.],\n       [0., 1., 0., ..., 0., 0., 0.]], dtype=float32)</pre> In\u00a0[8]: Copied! <pre>num_classes\n</pre> num_classes Out[8]: <pre>10</pre> <p>divindo dataset de treinamento em treinamento, teste e valida\u00e7\u00e3o - Apenas para exemplo em um ambiente real as amostras devem ser seleciondas de forma aleat\u00f3ria</p> In\u00a0[9]: Copied! <pre>(x_train, x_valid) = x_train[5000:], x_train[:5000]\n(y_train, y_valid) = y_train[5000:], y_train[:5000]\n</pre> (x_train, x_valid) = x_train[5000:], x_train[:5000] (y_train, y_valid) = y_train[5000:], y_train[:5000] <p>Impress\u00e3o da forma do conjunto de treino</p> In\u00a0[10]: Copied! <pre>print('x_train shape:', x_train.shape)\n</pre> print('x_train shape:', x_train.shape) <pre>x_train shape: (45000, 32, 32, 3)\n</pre> In\u00a0[11]: Copied! <pre>print('x_valid shape:', x_valid.shape)\n</pre> print('x_valid shape:', x_valid.shape) <pre>x_valid shape: (5000, 32, 32, 3)\n</pre> <p>Impress\u00e3o do n\u00famero de imagens nos datasets de treinamento, teste e valida\u00e7\u00e3o</p> In\u00a0[12]: Copied! <pre>print(x_train.shape[0], 'train samples')\nprint(x_test.shape[0], 'test samples')\nprint(x_valid.shape[0], 'validation samples')\n</pre> print(x_train.shape[0], 'train samples') print(x_test.shape[0], 'test samples') print(x_valid.shape[0], 'validation samples') <pre>45000 train samples\n10000 test samples\n5000 validation samples\n</pre> <p>Um pouquinho de novos conceitos.</p> <p>Dropout: T\u00e9cnica de regulariza\u00e7\u00e3o usada para prevenir o overfitting em redes neurais. Consiste em \"desligar\" aleatoriamente alguns neur\u00f4nios durante o treinamento, for\u00e7ando a rede a n\u00e3o depender excessivamente de caracter\u00edsticas espec\u00edficas de entrada. Utilize dropout principalmente em redes densas (fully connected) e convolucionais para melhorar a generaliza\u00e7\u00e3o do modelo.</p> <p>Saiba mais em: https://www.deeplearningbook.com.br/capitulo-23-como-funciona-o-dropout/</p> <p>Batch Normalization: M\u00e9todo que normaliza as ativa\u00e7\u00f5es de uma camada para m\u00e9dia zero e vari\u00e2ncia unit\u00e1ria, utilizando estat\u00edsticas do mini-lote. Ajuda a acelerar o treinamento e a estabilizar a converg\u00eancia ao mitigar o problema de deslocamento interno das distribui\u00e7\u00f5es das ativa\u00e7\u00f5es. \u00c9 \u00fatil em praticamente todos os tipos de redes neurais, especialmente em redes profundas, para facilitar um treinamento mais r\u00e1pido e est\u00e1vel.</p> <p>Saiba mais em: https://machinelearningmastery.com/batch-normalization-for-training-of-deep-neural-networks/</p> In\u00a0[13]: Copied! <pre>## primeira tentativa\nmodel = Sequential()\n## CNN\nmodel.add(Conv2D(filters=64, kernel_size=3,  activation='relu', input_shape=(32, 32, 3), padding='same'))\nmodel.add(MaxPooling2D(pool_size=2))\nmodel.add(Conv2D(filters=128, kernel_size=3,  activation='relu'))\nmodel.add(MaxPooling2D(pool_size=2))\n\n## MLP\nmodel.add(Flatten())\nmodel.add(Dense(256, activation='relu'))\nmodel.add(Dropout(0.2))\nmodel.add(Dense(128, activation='relu'))\nmodel.add(Dropout(0.2))\nmodel.add(Dense(num_classes, activation='softmax'))\n</pre> ## primeira tentativa model = Sequential() ## CNN model.add(Conv2D(filters=64, kernel_size=3,  activation='relu', input_shape=(32, 32, 3), padding='same')) model.add(MaxPooling2D(pool_size=2)) model.add(Conv2D(filters=128, kernel_size=3,  activation='relu')) model.add(MaxPooling2D(pool_size=2))  ## MLP model.add(Flatten()) model.add(Dense(256, activation='relu')) model.add(Dropout(0.2)) model.add(Dense(128, activation='relu')) model.add(Dropout(0.2)) model.add(Dense(num_classes, activation='softmax'))  <p>Tentem executar a rede configurando outras fun\u00e7\u00f5es de ativa\u00e7\u00e3o (como visto em nossa Aula 3) mais informa\u00e7\u00f5es em https://keras.io/activations/</p> In\u00a0[14]: Copied! <pre>plot_model(model, to_file='cnn-CIFAR10.png', show_shapes=True, show_layer_names=True)\n</pre> plot_model(model, to_file='cnn-CIFAR10.png', show_shapes=True, show_layer_names=True) Out[14]: <p>Compilando o modelo escolhendo como se dar\u00e1 nossa perda, otimiza\u00e7\u00e3o e m\u00e9tricas (par\u00e2metros do Keras)</p> <ul> <li>mais informa\u00e7\u00f5es em https://keras.io/losses/</li> <li>mais informa\u00e7\u00f5es em https://keras.io/optimizers/</li> <li>mais informa\u00e7\u00f5es em https://keras.io/metrics/</li> </ul> In\u00a0[15]: Copied! <pre>model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n</pre> model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy']) In\u00a0[16]: Copied! <pre>from keras.callbacks import ModelCheckpoint\n</pre> from keras.callbacks import ModelCheckpoint In\u00a0[17]: Copied! <pre>checkpointer = ModelCheckpoint(filepath='/content/drive/My Drive/modelocifar.h5', verbose=1,  save_best_only=True, monitor='val_accuracy') #\n\nhist = model.fit(x_train, y_train, batch_size=100, epochs=30, validation_data=(x_valid, y_valid), callbacks=[checkpointer], verbose=1, shuffle=True)\n</pre> checkpointer = ModelCheckpoint(filepath='/content/drive/My Drive/modelocifar.h5', verbose=1,  save_best_only=True, monitor='val_accuracy') #  hist = model.fit(x_train, y_train, batch_size=100, epochs=30, validation_data=(x_valid, y_valid), callbacks=[checkpointer], verbose=1, shuffle=True) <pre>Epoch 1/30\n450/450 [==============================] - ETA: 0s - loss: 1.6596 - accuracy: 0.3873\nEpoch 1: val_accuracy improved from -inf to 0.54340, saving model to /content/drive/My Drive/modelocifar.h5\n</pre> <pre>/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n  saving_api.save_model(\n</pre> <pre>\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r450/450 [==============================] - 23s 34ms/step - loss: 1.6596 - accuracy: 0.3873 - val_loss: 1.2678 - val_accuracy: 0.5434\nEpoch 2/30\n449/450 [============================&gt;.] - ETA: 0s - loss: 1.2054 - accuracy: 0.5708\nEpoch 2: val_accuracy improved from 0.54340 to 0.64180, saving model to /content/drive/My Drive/modelocifar.h5\n450/450 [==============================] - 15s 33ms/step - loss: 1.2050 - accuracy: 0.5710 - val_loss: 1.0195 - val_accuracy: 0.6418\nEpoch 3/30\n449/450 [============================&gt;.] - ETA: 0s - loss: 0.9949 - accuracy: 0.6510\nEpoch 3: val_accuracy improved from 0.64180 to 0.67520, saving model to /content/drive/My Drive/modelocifar.h5\n450/450 [==============================] - 14s 31ms/step - loss: 0.9948 - accuracy: 0.6510 - val_loss: 0.9110 - val_accuracy: 0.6752\nEpoch 4/30\n449/450 [============================&gt;.] - ETA: 0s - loss: 0.8725 - accuracy: 0.6961\nEpoch 4: val_accuracy improved from 0.67520 to 0.71120, saving model to /content/drive/My Drive/modelocifar.h5\n450/450 [==============================] - 15s 32ms/step - loss: 0.8724 - accuracy: 0.6962 - val_loss: 0.8161 - val_accuracy: 0.7112\nEpoch 5/30\n449/450 [============================&gt;.] - ETA: 0s - loss: 0.7531 - accuracy: 0.7382\nEpoch 5: val_accuracy improved from 0.71120 to 0.75360, saving model to /content/drive/My Drive/modelocifar.h5\n450/450 [==============================] - 14s 31ms/step - loss: 0.7537 - accuracy: 0.7379 - val_loss: 0.7239 - val_accuracy: 0.7536\nEpoch 6/30\n449/450 [============================&gt;.] - ETA: 0s - loss: 0.6821 - accuracy: 0.7607\nEpoch 6: val_accuracy improved from 0.75360 to 0.75420, saving model to /content/drive/My Drive/modelocifar.h5\n450/450 [==============================] - 14s 30ms/step - loss: 0.6823 - accuracy: 0.7607 - val_loss: 0.7095 - val_accuracy: 0.7542\nEpoch 7/30\n449/450 [============================&gt;.] - ETA: 0s - loss: 0.6144 - accuracy: 0.7873\nEpoch 7: val_accuracy did not improve from 0.75420\n450/450 [==============================] - 13s 29ms/step - loss: 0.6145 - accuracy: 0.7872 - val_loss: 0.7180 - val_accuracy: 0.7518\nEpoch 8/30\n449/450 [============================&gt;.] - ETA: 0s - loss: 0.5596 - accuracy: 0.8047\nEpoch 8: val_accuracy improved from 0.75420 to 0.75560, saving model to /content/drive/My Drive/modelocifar.h5\n450/450 [==============================] - 14s 31ms/step - loss: 0.5596 - accuracy: 0.8046 - val_loss: 0.7373 - val_accuracy: 0.7556\nEpoch 9/30\n449/450 [============================&gt;.] - ETA: 0s - loss: 0.5109 - accuracy: 0.8213\nEpoch 9: val_accuracy improved from 0.75560 to 0.76760, saving model to /content/drive/My Drive/modelocifar.h5\n450/450 [==============================] - 14s 31ms/step - loss: 0.5108 - accuracy: 0.8213 - val_loss: 0.7121 - val_accuracy: 0.7676\nEpoch 10/30\n449/450 [============================&gt;.] - ETA: 0s - loss: 0.4656 - accuracy: 0.8360\nEpoch 10: val_accuracy improved from 0.76760 to 0.78060, saving model to /content/drive/My Drive/modelocifar.h5\n450/450 [==============================] - 15s 33ms/step - loss: 0.4662 - accuracy: 0.8358 - val_loss: 0.6823 - val_accuracy: 0.7806\nEpoch 11/30\n449/450 [============================&gt;.] - ETA: 0s - loss: 0.4193 - accuracy: 0.8531\nEpoch 11: val_accuracy improved from 0.78060 to 0.78720, saving model to /content/drive/My Drive/modelocifar.h5\n450/450 [==============================] - 14s 31ms/step - loss: 0.4195 - accuracy: 0.8531 - val_loss: 0.6579 - val_accuracy: 0.7872\nEpoch 12/30\n449/450 [============================&gt;.] - ETA: 0s - loss: 0.3839 - accuracy: 0.8664\nEpoch 12: val_accuracy did not improve from 0.78720\n450/450 [==============================] - 13s 28ms/step - loss: 0.3836 - accuracy: 0.8664 - val_loss: 0.6945 - val_accuracy: 0.7870\nEpoch 13/30\n449/450 [============================&gt;.] - ETA: 0s - loss: 0.3553 - accuracy: 0.8731\nEpoch 13: val_accuracy did not improve from 0.78720\n450/450 [==============================] - 13s 29ms/step - loss: 0.3552 - accuracy: 0.8732 - val_loss: 0.7023 - val_accuracy: 0.7844\nEpoch 14/30\n449/450 [============================&gt;.] - ETA: 0s - loss: 0.3315 - accuracy: 0.8841\nEpoch 14: val_accuracy improved from 0.78720 to 0.78940, saving model to /content/drive/My Drive/modelocifar.h5\n450/450 [==============================] - 14s 31ms/step - loss: 0.3314 - accuracy: 0.8841 - val_loss: 0.7158 - val_accuracy: 0.7894\nEpoch 15/30\n449/450 [============================&gt;.] - ETA: 0s - loss: 0.3022 - accuracy: 0.8936\nEpoch 15: val_accuracy did not improve from 0.78940\n450/450 [==============================] - 13s 29ms/step - loss: 0.3022 - accuracy: 0.8937 - val_loss: 0.7378 - val_accuracy: 0.7864\nEpoch 16/30\n449/450 [============================&gt;.] - ETA: 0s - loss: 0.2873 - accuracy: 0.8997\nEpoch 16: val_accuracy did not improve from 0.78940\n450/450 [==============================] - 13s 28ms/step - loss: 0.2874 - accuracy: 0.8996 - val_loss: 0.7250 - val_accuracy: 0.7884\nEpoch 17/30\n449/450 [============================&gt;.] - ETA: 0s - loss: 0.2698 - accuracy: 0.9057\nEpoch 17: val_accuracy improved from 0.78940 to 0.79020, saving model to /content/drive/My Drive/modelocifar.h5\n450/450 [==============================] - 14s 31ms/step - loss: 0.2700 - accuracy: 0.9056 - val_loss: 0.7565 - val_accuracy: 0.7902\nEpoch 18/30\n449/450 [============================&gt;.] - ETA: 0s - loss: 0.2494 - accuracy: 0.9104\nEpoch 18: val_accuracy did not improve from 0.79020\n450/450 [==============================] - 13s 29ms/step - loss: 0.2496 - accuracy: 0.9103 - val_loss: 0.7710 - val_accuracy: 0.7846\nEpoch 19/30\n449/450 [============================&gt;.] - ETA: 0s - loss: 0.2389 - accuracy: 0.9173\nEpoch 19: val_accuracy did not improve from 0.79020\n450/450 [==============================] - 13s 29ms/step - loss: 0.2387 - accuracy: 0.9174 - val_loss: 0.8072 - val_accuracy: 0.7792\nEpoch 20/30\n449/450 [============================&gt;.] - ETA: 0s - loss: 0.2214 - accuracy: 0.9230\nEpoch 20: val_accuracy did not improve from 0.79020\n450/450 [==============================] - 13s 29ms/step - loss: 0.2213 - accuracy: 0.9230 - val_loss: 0.8105 - val_accuracy: 0.7858\nEpoch 21/30\n449/450 [============================&gt;.] - ETA: 0s - loss: 0.2198 - accuracy: 0.9239\nEpoch 21: val_accuracy did not improve from 0.79020\n450/450 [==============================] - 13s 28ms/step - loss: 0.2199 - accuracy: 0.9238 - val_loss: 0.8193 - val_accuracy: 0.7760\nEpoch 22/30\n449/450 [============================&gt;.] - ETA: 0s - loss: 0.2105 - accuracy: 0.9277\nEpoch 22: val_accuracy did not improve from 0.79020\n450/450 [==============================] - 13s 29ms/step - loss: 0.2103 - accuracy: 0.9278 - val_loss: 0.8385 - val_accuracy: 0.7788\nEpoch 23/30\n449/450 [============================&gt;.] - ETA: 0s - loss: 0.1959 - accuracy: 0.9337\nEpoch 23: val_accuracy did not improve from 0.79020\n450/450 [==============================] - 14s 31ms/step - loss: 0.1960 - accuracy: 0.9337 - val_loss: 0.8522 - val_accuracy: 0.7844\nEpoch 24/30\n450/450 [==============================] - ETA: 0s - loss: 0.1879 - accuracy: 0.9356\nEpoch 24: val_accuracy did not improve from 0.79020\n450/450 [==============================] - 14s 31ms/step - loss: 0.1879 - accuracy: 0.9356 - val_loss: 0.8254 - val_accuracy: 0.7874\nEpoch 25/30\n450/450 [==============================] - ETA: 0s - loss: 0.1892 - accuracy: 0.9346\nEpoch 25: val_accuracy did not improve from 0.79020\n450/450 [==============================] - 14s 31ms/step - loss: 0.1892 - accuracy: 0.9346 - val_loss: 0.8485 - val_accuracy: 0.7842\nEpoch 26/30\n449/450 [============================&gt;.] - ETA: 0s - loss: 0.1756 - accuracy: 0.9394\nEpoch 26: val_accuracy did not improve from 0.79020\n450/450 [==============================] - 13s 28ms/step - loss: 0.1754 - accuracy: 0.9395 - val_loss: 0.8510 - val_accuracy: 0.7872\nEpoch 27/30\n449/450 [============================&gt;.] - ETA: 0s - loss: 0.1663 - accuracy: 0.9429\nEpoch 27: val_accuracy did not improve from 0.79020\n450/450 [==============================] - 13s 30ms/step - loss: 0.1663 - accuracy: 0.9429 - val_loss: 0.9397 - val_accuracy: 0.7748\nEpoch 28/30\n449/450 [============================&gt;.] - ETA: 0s - loss: 0.1638 - accuracy: 0.9445\nEpoch 28: val_accuracy did not improve from 0.79020\n450/450 [==============================] - 14s 31ms/step - loss: 0.1640 - accuracy: 0.9444 - val_loss: 0.9216 - val_accuracy: 0.7844\nEpoch 29/30\n449/450 [============================&gt;.] - ETA: 0s - loss: 0.1631 - accuracy: 0.9444\nEpoch 29: val_accuracy did not improve from 0.79020\n450/450 [==============================] - 13s 29ms/step - loss: 0.1630 - accuracy: 0.9444 - val_loss: 0.8593 - val_accuracy: 0.7868\nEpoch 30/30\n449/450 [============================&gt;.] - ETA: 0s - loss: 0.1556 - accuracy: 0.9484\nEpoch 30: val_accuracy improved from 0.79020 to 0.79040, saving model to /content/drive/My Drive/modelocifar.h5\n450/450 [==============================] - 14s 30ms/step - loss: 0.1556 - accuracy: 0.9484 - val_loss: 0.8718 - val_accuracy: 0.7904\n</pre> In\u00a0[18]: Copied! <pre>plt.figure(1)\nplt.plot(hist.history['accuracy'])\nplt.plot(hist.history['val_accuracy'])\nplt.title('model accuracy')\nplt.ylabel('accuracy')\nplt.xlabel('epoch')\nplt.legend(['train', 'validation'], loc='upper left')\nplt.show()\n</pre> plt.figure(1) plt.plot(hist.history['accuracy']) plt.plot(hist.history['val_accuracy']) plt.title('model accuracy') plt.ylabel('accuracy') plt.xlabel('epoch') plt.legend(['train', 'validation'], loc='upper left') plt.show() <p>Carregar o melhor modelo que obteve a melhor acur\u00e1cia de valida\u00e7\u00e3o no treinamento</p> In\u00a0[19]: Copied! <pre>model = load_model(\"/content/drive/My Drive/modelocifar.h5\")\n</pre> model = load_model(\"/content/drive/My Drive/modelocifar.h5\") <p>Avaliar e imprimir a precis\u00e3o do teste</p> In\u00a0[20]: Copied! <pre>score = model.evaluate(x_test, y_test, verbose=0)\nprint('\\n', 'Test accuracy:', score[1])\n</pre> score = model.evaluate(x_test, y_test, verbose=0) print('\\n', 'Test accuracy:', score[1]) <pre>\n Test accuracy: 0.7854999899864197\n</pre> In\u00a0[21]: Copied! <pre>y_hat = model.predict(x_test)\n</pre> y_hat = model.predict(x_test) <pre>313/313 [==============================] - 1s 3ms/step\n</pre> In\u00a0[22]: Copied! <pre>y_hat[100,:]\n</pre> y_hat[100,:] Out[22]: <pre>array([1.03396337e-06, 3.92779587e-09, 2.90912110e-03, 1.52367875e-05,\n       6.07605755e-01, 2.14876439e-02, 6.69553160e-08, 3.67980659e-01,\n       3.33775603e-07, 6.63219666e-08], dtype=float32)</pre> In\u00a0[23]: Copied! <pre>np.argmax(y_hat[100,:])\n</pre> np.argmax(y_hat[100,:]) Out[23]: <pre>4</pre> <p>Definindo r\u00f3tulos de texto (r\u00f3tulos dispon\u00edveis na fonte original: https://www.cs.toronto.edu/~kriz/cifar.html)</p> In\u00a0[24]: Copied! <pre>cifar10_labels = ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n</pre> cifar10_labels = ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck'] <p>Plot de amostra aleat\u00f3ria de imagens de teste, r\u00f3tulos preditos e a \"ground truth\" advinda do dataset CIFAR-10</p> In\u00a0[25]: Copied! <pre>fig = plt.figure(figsize=(20, 8))\nfor i, idx in enumerate(np.random.choice(x_test.shape[0], size=32, replace=False)):\n    ax = fig.add_subplot(4, 8, i + 1, xticks=[], yticks=[])\n    ax.imshow(np.squeeze(x_test[idx]))\n    pred_idx = np.argmax(y_hat[idx])\n    true_idx = np.argmax(y_test[idx])\n    ax.set_title(\"{} ({})\".format(cifar10_labels[pred_idx], cifar10_labels[true_idx]),\n                 color=(\"green\" if pred_idx == true_idx else \"red\"))\n    # amostras corretamente classificadas em verde, incorretamente classificadas em vermelho\n</pre> fig = plt.figure(figsize=(20, 8)) for i, idx in enumerate(np.random.choice(x_test.shape[0], size=32, replace=False)):     ax = fig.add_subplot(4, 8, i + 1, xticks=[], yticks=[])     ax.imshow(np.squeeze(x_test[idx]))     pred_idx = np.argmax(y_hat[idx])     true_idx = np.argmax(y_test[idx])     ax.set_title(\"{} ({})\".format(cifar10_labels[pred_idx], cifar10_labels[true_idx]),                  color=(\"green\" if pred_idx == true_idx else \"red\"))     # amostras corretamente classificadas em verde, incorretamente classificadas em vermelho"},{"location":"aulas/IA/lab08/Exemplo_CNN_Dataset_CIFAR10_com_Salvamento_no_GDrive.html#1-carregando-bibliotecas","title":"1. Carregando Bibliotecas\u00b6","text":""},{"location":"aulas/IA/lab08/Exemplo_CNN_Dataset_CIFAR10_com_Salvamento_no_GDrive.html#2-carregando-o-dataset-pre-embaralhado-de-treinamento-bem-como-os-dados-de-teste","title":"2. Carregando o dataset pr\u00e9-embaralhado de treinamento bem como os dados de teste\u00b6","text":""},{"location":"aulas/IA/lab08/Exemplo_CNN_Dataset_CIFAR10_com_Salvamento_no_GDrive.html#3-redimensionando-as-imagens-e-dividindo-cada-pixel-em-cada-imagem-por-255","title":"3. Redimensionando as imagens e dividindo cada pixel em cada imagem por 255\u00b6","text":""},{"location":"aulas/IA/lab08/Exemplo_CNN_Dataset_CIFAR10_com_Salvamento_no_GDrive.html#4-dividindo-o-dataset-em-treinamento-teste-e-validacao","title":"4.  Dividindo o dataset em treinamento, teste e valida\u00e7\u00e3o\u00b6","text":""},{"location":"aulas/IA/lab08/Exemplo_CNN_Dataset_CIFAR10_com_Salvamento_no_GDrive.html#5-definindo-a-arquitetura-do-modelo-importante","title":"5. Definindo a arquitetura do modelo (IMPORTANTE!)\u00b6","text":"<p>Defina uma rede simples, vou sugerir a seguinte: LeNet-5</p> <ul> <li><p>2 camadas convolucionais de tamanho progressivamente crescente</p> </li> <li><p>Com \"maxpooling\" (2x2)</p> </li> <li><p>Uma camada do tipo totalmente conectada de 120 neur\u00f4nios</p> </li> <li><p>Uma camada do tipo totalmente conectada de 84 neur\u00f4nios</p> </li> <li><p>Ultimas camadas do tipo totalmente conectadas de 10 sa\u00eddas (10 classes de categoria de imagem)</p> </li> <li><p>\"Dropout\" de 0,2-0,3</p> </li> </ul>"},{"location":"aulas/IA/lab08/Exemplo_CNN_Dataset_CIFAR10_com_Salvamento_no_GDrive.html#6-compilando-o-modelo","title":"6. Compilando o modelo\u00b6","text":""},{"location":"aulas/IA/lab08/Exemplo_CNN_Dataset_CIFAR10_com_Salvamento_no_GDrive.html#7-treinando-o-modelo","title":"7. Treinando o modelo\u00b6","text":""},{"location":"aulas/IA/lab08/Exemplo_CNN_Dataset_CIFAR10_com_Salvamento_no_GDrive.html#o-keras-passa-a-salvar-o-melhor-modelo-pela-acuracia-de-validacao","title":"O keras passa a salvar o melhor modelo pela acur\u00e1cia de valida\u00e7\u00e3o\u00b6","text":""},{"location":"aulas/IA/lab08/Exemplo_CNN_Dataset_CIFAR10_com_Salvamento_no_GDrive.html#8-calculo-da-precisao-de-classificacao-no-dataset-de-testes","title":"8. C\u00e1lculo da precis\u00e3o de classifica\u00e7\u00e3o no dataset de testes\u00b6","text":""},{"location":"aulas/IA/lab08/Exemplo_CNN_Dataset_CIFAR10_com_Salvamento_no_GDrive.html#9-visualizar-algumas-predicoes","title":"9. Visualizar algumas predi\u00e7\u00f5es\u00b6","text":"<p>As visualiza\u00e7\u00f5es podem nos dar algumas dicas sobre por que a rede classifica erroneamente alguns objetos. Obtendo previs\u00f5es no conjunto de testes:</p>"},{"location":"aulas/IA/lab08/cnn.html","title":"Lab08 - Redes Neurais - CNN parte1","text":"In\u00a0[\u00a0]: Copied! <pre>import tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\n\n\nmodel = keras.Sequential([\n    layers.Flatten(input_shape=(800,600)),\n    layers.Dense(units=100)\n])\n\nmodel.summary()\n</pre> import tensorflow as tf from tensorflow import keras from tensorflow.keras import layers   model = keras.Sequential([     layers.Flatten(input_shape=(800,600)),     layers.Dense(units=100) ])  model.summary()  <pre>Model: \"sequential_1\"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\n flatten_1 (Flatten)         (None, 480000)            0         \n                                                                 \n dense_1 (Dense)             (None, 100)               48000100  \n                                                                 \n=================================================================\nTotal params: 48,000,100\nTrainable params: 48,000,100\nNon-trainable params: 0\n_________________________________________________________________\n</pre> In\u00a0[\u00a0]: Copied! <pre>import tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\n\n\nmodel = keras.Sequential([\n    layers.Conv2D(filters = 100, kernel_size = (3, 3), activation='relu', input_shape=(800,600, 3)),\n])\n\nmodel.summary()\n</pre> import tensorflow as tf from tensorflow import keras from tensorflow.keras import layers   model = keras.Sequential([     layers.Conv2D(filters = 100, kernel_size = (3, 3), activation='relu', input_shape=(800,600, 3)), ])  model.summary()  <pre>Model: \"sequential_9\"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\n conv2d_10 (Conv2D)          (None, 798, 598, 100)     2800      \n                                                                 \n=================================================================\nTotal params: 2,800\nTrainable params: 2,800\nNon-trainable params: 0\n_________________________________________________________________\n</pre> In\u00a0[\u00a0]: Copied! <pre>### Sua resposta aqui...\n</pre> ### Sua resposta aqui...    In\u00a0[\u00a0]: Copied! <pre>import tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\n\n\nmodel = keras.Sequential([\n    layers.Conv2D(filters = 100, kernel_size = (3, 3), activation='relu', input_shape=(800,600, 3)), # camada de convolu\u00e7\u00e3o\n    layers.MaxPool2D(pool_size=2, strides=2) # camada de pooling\n\n])\n\nmodel.summary()\n</pre> import tensorflow as tf from tensorflow import keras from tensorflow.keras import layers   model = keras.Sequential([     layers.Conv2D(filters = 100, kernel_size = (3, 3), activation='relu', input_shape=(800,600, 3)), # camada de convolu\u00e7\u00e3o     layers.MaxPool2D(pool_size=2, strides=2) # camada de pooling  ])  model.summary() <pre>Model: \"sequential_8\"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\n conv2d_9 (Conv2D)           (None, 798, 598, 100)     2800      \n                                                                 \n max_pooling2d_5 (MaxPooling  (None, 399, 299, 100)    0         \n 2D)                                                             \n                                                                 \n=================================================================\nTotal params: 2,800\nTrainable params: 2,800\nNon-trainable params: 0\n_________________________________________________________________\n</pre> In\u00a0[\u00a0]: Copied! <pre>'''\n### suas respostas.....\n\n1.\n\n\n2.\n\n\n'''\n</pre> ''' ### suas respostas.....  1.   2.   ''' Out[\u00a0]: <pre>'\\n### suas respostas.....\\n\\n1.\\n\\n\\n2.\\n\\n\\n'</pre> In\u00a0[\u00a0]: Copied! <pre>import tensorflow as tf\nfrom tensorflow import keras\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom tensorflow.keras import layers\n</pre> import tensorflow as tf from tensorflow import keras import numpy as np import matplotlib.pyplot as plt from tensorflow.keras import layers In\u00a0[\u00a0]: Copied! <pre># Importa o dataset Fashion Mnist\nfashion_mnist = keras.datasets.fashion_mnist\n(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()\n\n#normaliza os dados para o pixel ficar com valores entre 0 e 1\ntrain_images = train_images / 255.0\ntest_images = test_images / 255.0\nclass_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n               'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\n</pre> # Importa o dataset Fashion Mnist fashion_mnist = keras.datasets.fashion_mnist (train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()  #normaliza os dados para o pixel ficar com valores entre 0 e 1 train_images = train_images / 255.0 test_images = test_images / 255.0 class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',                'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot'] In\u00a0[\u00a0]: Copied! <pre>train_images = train_images.reshape(-1,28,28,1)\nprint(train_images.shape)\ntest_images = test_images.reshape(-1,28,28,1)\ntest_images.shape\n</pre> train_images = train_images.reshape(-1,28,28,1) print(train_images.shape) test_images = test_images.reshape(-1,28,28,1) test_images.shape <pre>(60000, 28, 28, 1)\n</pre> Out[\u00a0]: <pre>(10000, 28, 28, 1)</pre> In\u00a0[\u00a0]: Copied! <pre>###### montar a arquitetura da rede neural\n\nfrom tensorflow.keras import layers\n\nmodel = keras.Sequential([\n\n#####-------CNN-------#####\n\n    layers.Conv2D(5, (3,3), activation='relu', padding=\"same\", input_shape=(28, 28,1)),\n    layers.MaxPooling2D((2,2)),\n\n\n #######------ MLP-----####\n    layers.Flatten(),\n    layers.Dense(120, activation='relu'),\n    layers.Dense(10, activation='softmax')  ###### neuroniios especialistasss\n])\n\n\nmodel.summary()\n</pre> ###### montar a arquitetura da rede neural  from tensorflow.keras import layers  model = keras.Sequential([  #####-------CNN-------#####      layers.Conv2D(5, (3,3), activation='relu', padding=\"same\", input_shape=(28, 28,1)),     layers.MaxPooling2D((2,2)),    #######------ MLP-----####     layers.Flatten(),     layers.Dense(120, activation='relu'),     layers.Dense(10, activation='softmax')  ###### neuroniios especialistasss ])   model.summary()  <pre>Model: \"sequential_11\"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\n conv2d_12 (Conv2D)          (None, 28, 28, 5)         50        \n                                                                 \n max_pooling2d_7 (MaxPooling  (None, 14, 14, 5)        0         \n 2D)                                                             \n                                                                 \n flatten_5 (Flatten)         (None, 980)               0         \n                                                                 \n dense_9 (Dense)             (None, 120)               117720    \n                                                                 \n dense_10 (Dense)            (None, 10)                1210      \n                                                                 \n=================================================================\nTotal params: 118,980\nTrainable params: 118,980\nNon-trainable params: 0\n_________________________________________________________________\n</pre> In\u00a0[\u00a0]: Copied! <pre>model.compile(optimizer='adam',\n              loss='sparse_categorical_crossentropy',\n              metrics=['accuracy'])\n\nepochs_hist = model.fit(train_images, train_labels, epochs=3, validation_split=0.2)\n</pre> model.compile(optimizer='adam',               loss='sparse_categorical_crossentropy',               metrics=['accuracy'])  epochs_hist = model.fit(train_images, train_labels, epochs=3, validation_split=0.2)  <pre>Epoch 1/3\n1500/1500 [==============================] - 23s 15ms/step - loss: 0.2374 - accuracy: 0.9128 - val_loss: 0.2589 - val_accuracy: 0.9027\nEpoch 2/3\n1500/1500 [==============================] - 24s 16ms/step - loss: 0.2136 - accuracy: 0.9217 - val_loss: 0.2328 - val_accuracy: 0.9143\nEpoch 3/3\n1500/1500 [==============================] - 21s 14ms/step - loss: 0.1950 - accuracy: 0.9287 - val_loss: 0.2393 - val_accuracy: 0.9117\n</pre> In\u00a0[\u00a0]: Copied! <pre>## exibe os graficos da fun\u00e7\u00e3o loss e acuracia\n\nhistory_df = pd.DataFrame(epochs_hist.history)\n\nhistory_df[['loss','val_loss']].plot();\nhistory_df[['accuracy','val_accuracy']].plot();\n</pre> ## exibe os graficos da fun\u00e7\u00e3o loss e acuracia  history_df = pd.DataFrame(epochs_hist.history)  history_df[['loss','val_loss']].plot(); history_df[['accuracy','val_accuracy']].plot();  In\u00a0[\u00a0]: Copied! <pre>#Validad\u00e7\u00e3o\ntrain_loss, train_acc = model.evaluate(train_images,  train_labels, verbose=2)\ntest_loss, test_acc = model.evaluate(test_images,  test_labels, verbose=2)\n</pre> #Validad\u00e7\u00e3o train_loss, train_acc = model.evaluate(train_images,  train_labels, verbose=2) test_loss, test_acc = model.evaluate(test_images,  test_labels, verbose=2)  <pre>1875/1875 - 10s - loss: 0.1883 - accuracy: 0.9318 - 10s/epoch - 5ms/step\n313/313 - 4s - loss: 0.2789 - accuracy: 0.8977 - 4s/epoch - 12ms/step\n</pre> In\u00a0[\u00a0]: Copied! <pre># Previs\u00f5es com o modelo treinado\n\npredictions = model.predict(test_images)\n</pre> # Previs\u00f5es com o modelo treinado  predictions = model.predict(test_images) <pre>313/313 [==============================] - 2s 6ms/step\n</pre> In\u00a0[\u00a0]: Copied! <pre>#Verica\u00e7\u00e3o dos itens preditos\n\nitem = 4000\n\nprint(\"\\nClasse predita foi {} com {:2.0f}%. Classe correta \u00e9 {}, {}.\".format(np.argmax(predictions[item]),\n                                                                 100*np.max(predictions[item]),\n                                                                 test_labels[item],\n                                                                 class_names[test_labels[item]]))\n\na=100*np.max(predictions[item])\n</pre> #Verica\u00e7\u00e3o dos itens preditos  item = 4000  print(\"\\nClasse predita foi {} com {:2.0f}%. Classe correta \u00e9 {}, {}.\".format(np.argmax(predictions[item]),                                                                  100*np.max(predictions[item]),                                                                  test_labels[item],                                                                  class_names[test_labels[item]]))  a=100*np.max(predictions[item]) <pre>\nClasse predita foi 0 com 100%. Classe correta \u00e9 0, T-shirt/top.\n</pre> In\u00a0[\u00a0]: Copied! <pre>def plot_image(i, predictions_array, true_label, img):\n  predictions_array, true_label, img = predictions_array[i], true_label[i], img[i]\n  plt.grid(False)\n  plt.xticks([])\n  plt.yticks([])\n\n  plt.imshow(img, cmap=plt.cm.binary)\n\n  predicted_label = np.argmax(predictions_array)\n  if predicted_label == true_label:\n    color = 'blue'\n  else:\n    color = 'red'\n\n  plt.xlabel(\"{} {:2.0f}% ({})\".format(class_names[predicted_label],\n                                100*np.max(predictions_array),\n                                class_names[true_label]),\n                                color=color)\n</pre> def plot_image(i, predictions_array, true_label, img):   predictions_array, true_label, img = predictions_array[i], true_label[i], img[i]   plt.grid(False)   plt.xticks([])   plt.yticks([])    plt.imshow(img, cmap=plt.cm.binary)    predicted_label = np.argmax(predictions_array)   if predicted_label == true_label:     color = 'blue'   else:     color = 'red'    plt.xlabel(\"{} {:2.0f}% ({})\".format(class_names[predicted_label],                                 100*np.max(predictions_array),                                 class_names[true_label]),                                 color=color) In\u00a0[\u00a0]: Copied! <pre>plt.figure(figsize=(6,3))\nplt.subplot(1,2,1)\nplot_image(item, predictions, test_labels, test_images)\nplt.show()\n</pre> plt.figure(figsize=(6,3)) plt.subplot(1,2,1) plot_image(item, predictions, test_labels, test_images) plt.show() In\u00a0[\u00a0]: Copied! <pre>###### Seu c\u00f3digo aqui......\n</pre> ###### Seu c\u00f3digo aqui......      In\u00a0[\u00a0]: Copied! <pre>#### seu c\u00f3digo aqui......\n</pre> #### seu c\u00f3digo aqui......"},{"location":"aulas/IA/lab08/cnn.html#2-redes-neurais","title":"2. Redes Neurais\u00b6","text":""},{"location":"aulas/IA/lab08/cnn.html#objetivos","title":"Objetivos\u00b6","text":"<ul> <li>Conhecer e praticar Redes Neurais Convolucionais</li> <li>Conhecer uma intui\u00e7\u00e3o sobre Convolu\u00e7\u00e3o, Pooling</li> <li>Praticar a classifica\u00e7\u00e3o de objeto usando Keras/TensorFlow</li> </ul>"},{"location":"aulas/IA/lab08/cnn.html#redes-neurais-convolucionais","title":"Redes Neurais Convolucionais\u00b6","text":"<p>A Redes Neurais Convolucionais ou CNN (Convolutional Neural Network) ou at\u00e9 mesmo ConvNet, s\u00e3o redes neurais de aprendizado profundo, <code>Deep Learning</code> muito utilizadas na \u00e1rea de Vis\u00e3o Computacional <code>classifica\u00e7\u00e3o</code>,<code>detec\u00e7\u00e3o de objetos</code> ou <code>segmenta\u00e7\u00e3o sem\u00e2ntica</code>.</p> <p>Para compreender uma CNN, precisamos compreender o funcionamento de alguns blocos novos fundamentais.</p> <ul> <li>Extra\u00e7\u00e3o de caracteristicas</li> <li>Convolu\u00e7\u00e3o</li> <li>Pooling</li> </ul>"},{"location":"aulas/IA/lab08/cnn.html#diferenca-de-mlp-para-cnn","title":"Diferen\u00e7a de MLP para CNN\u00b6","text":"<ul> <li><p>Em uma rede MLP, cada pixel \u00e9 tratado de forma isolada, sem considerar os demais pixels, dificultando a caracteriza\u00e7\u00e3o de features mais complexas. N\u00e3o \u00e9 levado em considera\u00e7\u00e3o se o pixel est\u00e1 na borda ou centro da imagem. Em um CNN o processo de convolu\u00e7\u00e3o leva em considera\u00e7\u00e3o esta condi\u00e7\u00e3o.</p> </li> <li><p>Outro ponto importante est\u00e1 relacionado a quantidade de par\u00e2metros para treinamento para uma imagem. Exemplo: uma imagem de 400x600 na escala de cinza e 100 neur\u00f4nios na primeira camada. Par\u00e2metros = (400x600*100 +100) = 24.000.100 de par\u00e2metros para treinamento, apenas na primeira camada.</p> </li> </ul>"},{"location":"aulas/IA/lab08/cnn.html#convolucao","title":"Convolu\u00e7\u00e3o\u00b6","text":"<p>A convolu\u00e7\u00e3o  permite uma filtragem no dom\u00ednio espacial. Esse processo ocorre com a aplica\u00e7\u00e3o de filtros (pequenas matrizes), posicionadas sob cada pixel da imagem. Estes filtros, normalmente, s\u00e3o chamados de kernels (ou n\u00facleos). O resultado final do valor do pixel \u00e9 calculado atrav\u00e9s de um produto de convolu\u00e7\u00e3o.</p> <p>Normalmente os kernels s\u00e3o matrizes 3x3. E os pesos s\u00e3o ajustados a cada itera\u00e7\u00e3o pelo backpropagation</p> <p>Nesta imagem temos a imagem original em azul, o kernel em cinza varrendo a imagem e o resultado da convolu\u00e7\u00e3o em verde.</p> <p>Vamos analizar o que acontece em apenas um pixel da imagem:</p> <p>O resultado para cada pixel \u00e9 esse:</p> <p>O resultado em uma imagem \u00e9 o seguinte:</p>"},{"location":"aulas/IA/lab08/cnn.html#implementacao-em-codigo","title":"Implementa\u00e7\u00e3o em c\u00f3digo\u00b6","text":"<p>Para implementar \u00e9 simples.</p> <p><code>layers.Conv2D(100, (3, 3))</code></p> <p>-&gt; 100 \u00e9 a quantidade de filtros (kernels) que ser\u00e3o criados</p> <p>-&gt; (3,3) \u00e9 o tamanho do filtro que ser\u00e1 usado.</p> <p>-&gt; outros argumentos como activation, input_shape tambem podem ser utlilizados.</p>"},{"location":"aulas/IA/lab08/cnn.html#desafio-1","title":"Desafio 1\u00b6","text":"<p>Compare a quantidade de <code>Total params</code>, em uma rede CNN esse valor \u00e9 menor ou maior comparado com uma rede MLP?</p>"},{"location":"aulas/IA/lab08/cnn.html#pooling","title":"Pooling\u00b6","text":"<p>De forma geral a camada de <code>pooling</code> realiza uma opera\u00e7\u00e3o de redu\u00e7\u00e3o da imagem de entrada tentando manter as caracteristicas mais relevantes. Por consequ\u00eancia, o custo computacional diminui, al\u00e9m disso, \u00e9 nesta etapa que s\u00e3o extra\u00eddas as caracter\u00edstica <code>features</code> mais importantes da imagem.</p> <p>O pooling mais comum \u00e9 utilizando um kernel 2x2, e um passo <code>stride</code> de 2, por consequ\u00eancia a imagem de sa\u00edda ter\u00e1 a metade da imagem de entrada. A opera\u00e7\u00e3o de pooling ir\u00e1 selecionar dentro da janela do kernel o valor que ser\u00e1 aplicado na pr\u00f3xima camada, pode ser o maior valor <code>Maxpooling()</code> ou a m\u00e9dia <code>AveragePooling()</code></p> <p>O resultado visual \u00e9 o seguinte:</p>"},{"location":"aulas/IA/lab08/cnn.html#implementacao-em-codigo","title":"Implementa\u00e7\u00e3o em c\u00f3digo\u00b6","text":"<p>Para implementar \u00e9 simples.</p> <p><code>layers.MaxPool2D(pool_size=2, strides=2)</code></p> <p>-&gt; pool_size \u00e9 o tamanho do filtro (2,2) que ser\u00e1 usado.</p> <p>-&gt; strides \u00e9 o passo 2 para percorrer a imagem</p> <p>-&gt; Existem outros argumentos que podem ser utlilizados (da uma olhada na documenta\u00e7\u00e3o).</p>"},{"location":"aulas/IA/lab08/cnn.html#desafio-2","title":"Desafio 2\u00b6","text":"<ol> <li><p>Qual o dimensional da imagem antes e depois do pooling ?</p> </li> <li><p>Com a camada de pooling teve altera\u00e7\u00e3o <code>total params</code>?</p> </li> </ol>"},{"location":"aulas/IA/lab08/cnn.html#extrator-de-caracteristicas","title":"Extrator de caracteristicas\u00b6","text":"<p>A extra\u00e7\u00e3o de caracter\u00edsticas \u00e9 o processo pelo qual a CNN identifica padr\u00f5es e caracter\u00edsticas relevantes em uma imagem. As caracter\u00edsticas s\u00e3o extra\u00eddas usando camadas convolucionais seguidas de camadas de pooling.</p> <p>Ap\u00f3s a extra\u00e7\u00e3o de caracter\u00edsticas \u00e9 aplicado uma rede MLP para realizar a etapa de classica\u00e7\u00e3o da imagem.</p>"},{"location":"aulas/IA/lab08/cnn.html#exemplo-pratico-fashion-mnist","title":"Exemplo pr\u00e1tico - Fashion MNIST\u00b6","text":"<p>Vamos utilizar novamente o dataset do Fashion MNIST para classifica\u00e7\u00e3o de imagens, mas desta vez vamos utilizar uma CNN para realizar a extra\u00e7\u00e3o de caracteristicas da imagem seguida de um classificador MLP.</p>"},{"location":"aulas/IA/lab08/cnn.html#desafio-3","title":"Desafio 3\u00b6","text":"<p>O resultado n\u00e3o ficou muito bom, mas podemos melhorar!</p> <p>Implemente a arquitetura da rede LeNet-5. Para treinar o Fashion MNIST.</p> <p>A leNet-5 foi publicada por leCun em 1998. E \u00e9 composta basicamente por:</p> <ul> <li>Convolutional Layers (CONV);</li> <li>Pooling Layers (POOL);</li> <li>Fully-Connected Layers (FC).</li> </ul> <p>Um exemplo de aplica\u00e7\u00e3o: https://github.com/gary30404/convolutional-neural-network-from-scratch-python</p>"},{"location":"aulas/IA/lab08/cnn.html#desafio-extra","title":"Desafio Extra\u00b6","text":"<p>Use uma rede CNN para treinar o cifar-10 usado na rodada3 da batalha das redes.</p>"},{"location":"aulas/IA/lab08/cnn_drive.html","title":"Lab08 - Redes Neurais - CNN parte2","text":"In\u00a0[\u00a0]: Copied! <pre>from keras.datasets import cifar10\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom keras.models import Sequential,load_model\nfrom keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, AveragePooling2D\nfrom keras.layers import BatchNormalization\n#from keras.utils import np_utils\nfrom keras.utils import to_categorical\n#from keras.utils import plot_model\nfrom keras.utils import plot_model\n\nimport tensorflow as tf\n</pre> from keras.datasets import cifar10 import numpy as np import matplotlib.pyplot as plt from keras.models import Sequential,load_model from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, AveragePooling2D from keras.layers import BatchNormalization #from keras.utils import np_utils from keras.utils import to_categorical #from keras.utils import plot_model from keras.utils import plot_model  import tensorflow as tf <p>Inicializa o Google Drive. \u00c9 necess\u00e1rio entrar com as credenciais do Gmail</p> In\u00a0[\u00a0]: Copied! <pre>from google.colab import drive\ndrive.mount('/content/drive')\n</pre> from google.colab import drive drive.mount('/content/drive') <pre>Mounted at /content/drive\n</pre> In\u00a0[\u00a0]: Copied! <pre>(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n</pre> (x_train, y_train), (x_test, y_test) = cifar10.load_data() <pre>Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n170498071/170498071 [==============================] - 4s 0us/step\n</pre> In\u00a0[\u00a0]: Copied! <pre>print('Train: X=%s, y=%s' % (x_train.shape, y_train.shape))\nprint('Test: X=%s, y=%s' % (x_test.shape, y_test.shape))\n# plot first few images\nfor i in range(9):\n\t# define subplot\n\tplt.subplot(330 + 1 + i)\n\t# plot raw pixel data\n\tplt.imshow(x_train[i])\n# show the figure\nplt.show()\n</pre> print('Train: X=%s, y=%s' % (x_train.shape, y_train.shape)) print('Test: X=%s, y=%s' % (x_test.shape, y_test.shape)) # plot first few images for i in range(9): \t# define subplot \tplt.subplot(330 + 1 + i) \t# plot raw pixel data \tplt.imshow(x_train[i]) # show the figure plt.show() <pre>Train: X=(50000, 32, 32, 3), y=(50000, 1)\nTest: X=(10000, 32, 32, 3), y=(10000, 1)\n</pre> In\u00a0[\u00a0]: Copied! <pre>x_train = x_train.astype('float32')/255\nx_test = x_test.astype('float32')/255\n</pre> x_train = x_train.astype('float32')/255 x_test = x_test.astype('float32')/255 <p>\"One-hot encoding\" aplicado aos r\u00f3tulos</p> In\u00a0[\u00a0]: Copied! <pre>num_classes = len(np.unique(y_train))\ny_train = to_categorical(y_train, num_classes)\ny_test = to_categorical(y_test, num_classes)\n</pre> num_classes = len(np.unique(y_train)) y_train = to_categorical(y_train, num_classes) y_test = to_categorical(y_test, num_classes) In\u00a0[\u00a0]: Copied! <pre>y_train\n</pre> y_train Out[\u00a0]: <pre>array([[0., 0., 0., ..., 0., 0., 0.],\n       [0., 0., 0., ..., 0., 0., 1.],\n       [0., 0., 0., ..., 0., 0., 1.],\n       ...,\n       [0., 0., 0., ..., 0., 0., 1.],\n       [0., 1., 0., ..., 0., 0., 0.],\n       [0., 1., 0., ..., 0., 0., 0.]], dtype=float32)</pre> In\u00a0[\u00a0]: Copied! <pre>num_classes\n</pre> num_classes Out[\u00a0]: <pre>10</pre> <p>divindo dataset de treinamento em treinamento, teste e valida\u00e7\u00e3o - Apenas para exemplo em um ambiente real as amostras devem ser seleciondas de forma aleat\u00f3ria</p> In\u00a0[\u00a0]: Copied! <pre>(x_train, x_valid) = x_train[5000:], x_train[:5000]\n(y_train, y_valid) = y_train[5000:], y_train[:5000]\n</pre> (x_train, x_valid) = x_train[5000:], x_train[:5000] (y_train, y_valid) = y_train[5000:], y_train[:5000] <p>Impress\u00e3o da forma do conjunto de treino</p> In\u00a0[\u00a0]: Copied! <pre>print('x_train shape:', x_train.shape)\n</pre> print('x_train shape:', x_train.shape) <pre>x_train shape: (45000, 32, 32, 3)\n</pre> In\u00a0[\u00a0]: Copied! <pre>print('x_valid shape:', x_valid.shape)\n</pre> print('x_valid shape:', x_valid.shape) <pre>x_valid shape: (5000, 32, 32, 3)\n</pre> <p>Impress\u00e3o do n\u00famero de imagens nos datasets de treinamento, teste e valida\u00e7\u00e3o</p> In\u00a0[\u00a0]: Copied! <pre>print(x_train.shape[0], 'train samples')\nprint(x_test.shape[0], 'test samples')\nprint(x_valid.shape[0], 'validation samples')\n</pre> print(x_train.shape[0], 'train samples') print(x_test.shape[0], 'test samples') print(x_valid.shape[0], 'validation samples') <pre>45000 train samples\n10000 test samples\n5000 validation samples\n</pre> In\u00a0[\u00a0]: Copied! <pre>## primeira tentativa\nmodel = Sequential()\nmodel.add(Conv2D(filters=128, kernel_size=3,  activation='relu', input_shape=(32, 32, 3), padding='same'))\nmodel.add(Conv2D(filters=128, kernel_size=3,  activation='relu'))\nmodel.add(MaxPooling2D(pool_size=2))\nmodel.add(Conv2D(filters=128, kernel_size=3,  activation='relu'))\nmodel.add(Conv2D(filters=128, kernel_size=3,  activation='relu'))\nmodel.add(MaxPooling2D(pool_size=2))\n\nmodel.add(Dropout(0.2))\nmodel.add(Flatten())\nmodel.add(Dense(256, activation='relu'))\nmodel.add(Dropout(0.2))\nmodel.add(Dense(128, activation='relu'))\nmodel.add(Dropout(0.2))\nmodel.add(Dense(num_classes, activation='softmax'))\n\n\n\n## Segunda tentativa\n\n# from keras.layers import BatchNormalization\n# model = Sequential()\n\n# model.add(Conv2D(filters=32, kernel_size=(3,3),  activation='relu', input_shape=(32, 32, 3), padding='same'))\n# model.add(BatchNormalization())\n# model.add(Conv2D(filters=32, kernel_size=(3,3), activation='relu', padding='same'))\n# model.add(BatchNormalization())\n# model.add(MaxPooling2D(pool_size=(2,2)))\n# model.add(Dropout(0.3))\n\n# model.add(Conv2D(64, (3,3), padding='same', activation='relu'))\n# model.add(BatchNormalization())\n# model.add(Conv2D(64, (3,3), padding='same', activation='relu'))\n# model.add(BatchNormalization())\n# model.add(MaxPooling2D(pool_size=(2,2)))\n# model.add(Dropout(0.5))\n\n# model.add(Conv2D(128, (3,3), padding='same', activation='relu'))\n# model.add(BatchNormalization())\n# model.add(Conv2D(128, (3,3), padding='same', activation='relu'))\n# model.add(BatchNormalization())\n# model.add(MaxPooling2D(pool_size=(2,2)))\n# model.add(Dropout(0.5))\n\n# model.add(Flatten())\n# model.add(Dense(128, activation='relu'))\n# model.add(BatchNormalization())\n# model.add(Dropout(0.5))\n# model.add(Dense(num_classes, activation='softmax'))\n</pre> ## primeira tentativa model = Sequential() model.add(Conv2D(filters=128, kernel_size=3,  activation='relu', input_shape=(32, 32, 3), padding='same')) model.add(Conv2D(filters=128, kernel_size=3,  activation='relu')) model.add(MaxPooling2D(pool_size=2)) model.add(Conv2D(filters=128, kernel_size=3,  activation='relu')) model.add(Conv2D(filters=128, kernel_size=3,  activation='relu')) model.add(MaxPooling2D(pool_size=2))  model.add(Dropout(0.2)) model.add(Flatten()) model.add(Dense(256, activation='relu')) model.add(Dropout(0.2)) model.add(Dense(128, activation='relu')) model.add(Dropout(0.2)) model.add(Dense(num_classes, activation='softmax'))    ## Segunda tentativa  # from keras.layers import BatchNormalization # model = Sequential()  # model.add(Conv2D(filters=32, kernel_size=(3,3),  activation='relu', input_shape=(32, 32, 3), padding='same')) # model.add(BatchNormalization()) # model.add(Conv2D(filters=32, kernel_size=(3,3), activation='relu', padding='same')) # model.add(BatchNormalization()) # model.add(MaxPooling2D(pool_size=(2,2))) # model.add(Dropout(0.3))  # model.add(Conv2D(64, (3,3), padding='same', activation='relu')) # model.add(BatchNormalization()) # model.add(Conv2D(64, (3,3), padding='same', activation='relu')) # model.add(BatchNormalization()) # model.add(MaxPooling2D(pool_size=(2,2))) # model.add(Dropout(0.5))  # model.add(Conv2D(128, (3,3), padding='same', activation='relu')) # model.add(BatchNormalization()) # model.add(Conv2D(128, (3,3), padding='same', activation='relu')) # model.add(BatchNormalization()) # model.add(MaxPooling2D(pool_size=(2,2))) # model.add(Dropout(0.5))  # model.add(Flatten()) # model.add(Dense(128, activation='relu')) # model.add(BatchNormalization()) # model.add(Dropout(0.5)) # model.add(Dense(num_classes, activation='softmax')) <p>Tentem executar a rede configurando outras fun\u00e7\u00f5es de ativa\u00e7\u00e3o (como visto em nossa Aula 3) mais informa\u00e7\u00f5es em https://keras.io/activations/</p> In\u00a0[\u00a0]: Copied! <pre>plot_model(model, to_file='cnn-CIFAR10.png', show_shapes=True, show_layer_names=True)\n</pre> plot_model(model, to_file='cnn-CIFAR10.png', show_shapes=True, show_layer_names=True) Out[\u00a0]: <p>Compilando o modelo escolhendo como se dar\u00e1 nossa perda, otimiza\u00e7\u00e3o e m\u00e9tricas (par\u00e2metros do Keras)</p> <ul> <li>mais informa\u00e7\u00f5es em https://keras.io/losses/</li> <li>mais informa\u00e7\u00f5es em https://keras.io/optimizers/</li> <li>mais informa\u00e7\u00f5es em https://keras.io/metrics/</li> </ul> In\u00a0[\u00a0]: Copied! <pre>model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n</pre> model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy']) In\u00a0[\u00a0]: Copied! <pre>from keras.callbacks import ModelCheckpoint\n</pre> from keras.callbacks import ModelCheckpoint <p>O keras passa a salvar o melhor modelo pela acur\u00e1cia de valida\u00e7\u00e3o</p> In\u00a0[\u00a0]: Copied! <pre>checkpointer = ModelCheckpoint(filepath='/content/drive/My Drive/checkpoints/modelocifar.h5', verbose=1,  save_best_only=True, monitor='val_accuracy') #\n\nhist = model.fit(x_train, y_train, batch_size=100, epochs=30, validation_data=(x_valid, y_valid), callbacks=[checkpointer], verbose=1, shuffle=True)\n</pre> checkpointer = ModelCheckpoint(filepath='/content/drive/My Drive/checkpoints/modelocifar.h5', verbose=1,  save_best_only=True, monitor='val_accuracy') #  hist = model.fit(x_train, y_train, batch_size=100, epochs=30, validation_data=(x_valid, y_valid), callbacks=[checkpointer], verbose=1, shuffle=True) <pre>Epoch 1/30\n450/450 [==============================] - ETA: 0s - loss: 1.8334 - accuracy: 0.3789\nEpoch 1: val_accuracy improved from -inf to 0.33460, saving model to /content/drive/My Drive/checkpoints/modelocifar_FIAP_Shift.hdf5\n450/450 [==============================] - 14s 18ms/step - loss: 1.8334 - accuracy: 0.3789 - val_loss: 2.0108 - val_accuracy: 0.3346\nEpoch 2/30\n448/450 [============================&gt;.] - ETA: 0s - loss: 1.2611 - accuracy: 0.5463\nEpoch 2: val_accuracy improved from 0.33460 to 0.62680, saving model to /content/drive/My Drive/checkpoints/modelocifar_FIAP_Shift.hdf5\n450/450 [==============================] - 9s 19ms/step - loss: 1.2608 - accuracy: 0.5466 - val_loss: 1.0417 - val_accuracy: 0.6268\nEpoch 3/30\n450/450 [==============================] - ETA: 0s - loss: 1.0718 - accuracy: 0.6208\nEpoch 3: val_accuracy improved from 0.62680 to 0.66700, saving model to /content/drive/My Drive/checkpoints/modelocifar_FIAP_Shift.hdf5\n450/450 [==============================] - 7s 16ms/step - loss: 1.0718 - accuracy: 0.6208 - val_loss: 0.9174 - val_accuracy: 0.6670\nEpoch 4/30\n447/450 [============================&gt;.] - ETA: 0s - loss: 0.9540 - accuracy: 0.6639\nEpoch 4: val_accuracy improved from 0.66700 to 0.68700, saving model to /content/drive/My Drive/checkpoints/modelocifar_FIAP_Shift.hdf5\n450/450 [==============================] - 8s 17ms/step - loss: 0.9543 - accuracy: 0.6639 - val_loss: 0.8978 - val_accuracy: 0.6870\nEpoch 5/30\n449/450 [============================&gt;.] - ETA: 0s - loss: 0.8712 - accuracy: 0.6943\nEpoch 5: val_accuracy did not improve from 0.68700\n450/450 [==============================] - 7s 16ms/step - loss: 0.8711 - accuracy: 0.6942 - val_loss: 0.9451 - val_accuracy: 0.6798\nEpoch 6/30\n448/450 [============================&gt;.] - ETA: 0s - loss: 0.8112 - accuracy: 0.7161\nEpoch 6: val_accuracy improved from 0.68700 to 0.71700, saving model to /content/drive/My Drive/checkpoints/modelocifar_FIAP_Shift.hdf5\n450/450 [==============================] - 8s 18ms/step - loss: 0.8113 - accuracy: 0.7161 - val_loss: 0.8033 - val_accuracy: 0.7170\nEpoch 7/30\n448/450 [============================&gt;.] - ETA: 0s - loss: 0.7626 - accuracy: 0.7341\nEpoch 7: val_accuracy improved from 0.71700 to 0.76720, saving model to /content/drive/My Drive/checkpoints/modelocifar_FIAP_Shift.hdf5\n450/450 [==============================] - 8s 18ms/step - loss: 0.7623 - accuracy: 0.7342 - val_loss: 0.6699 - val_accuracy: 0.7672\nEpoch 8/30\n450/450 [==============================] - ETA: 0s - loss: 0.7229 - accuracy: 0.7507\nEpoch 8: val_accuracy did not improve from 0.76720\n450/450 [==============================] - 7s 16ms/step - loss: 0.7229 - accuracy: 0.7507 - val_loss: 0.9428 - val_accuracy: 0.6904\nEpoch 9/30\n450/450 [==============================] - ETA: 0s - loss: 0.6865 - accuracy: 0.7623\nEpoch 9: val_accuracy did not improve from 0.76720\n450/450 [==============================] - 8s 17ms/step - loss: 0.6865 - accuracy: 0.7623 - val_loss: 0.7274 - val_accuracy: 0.7484\nEpoch 10/30\n448/450 [============================&gt;.] - ETA: 0s - loss: 0.6619 - accuracy: 0.7719\nEpoch 10: val_accuracy improved from 0.76720 to 0.79100, saving model to /content/drive/My Drive/checkpoints/modelocifar_FIAP_Shift.hdf5\n450/450 [==============================] - 8s 18ms/step - loss: 0.6614 - accuracy: 0.7721 - val_loss: 0.6355 - val_accuracy: 0.7910\nEpoch 11/30\n447/450 [============================&gt;.] - ETA: 0s - loss: 0.6306 - accuracy: 0.7842\nEpoch 11: val_accuracy improved from 0.79100 to 0.80300, saving model to /content/drive/My Drive/checkpoints/modelocifar_FIAP_Shift.hdf5\n450/450 [==============================] - 8s 18ms/step - loss: 0.6310 - accuracy: 0.7840 - val_loss: 0.5668 - val_accuracy: 0.8030\nEpoch 12/30\n447/450 [============================&gt;.] - ETA: 0s - loss: 0.6087 - accuracy: 0.7903\nEpoch 12: val_accuracy did not improve from 0.80300\n450/450 [==============================] - 8s 17ms/step - loss: 0.6090 - accuracy: 0.7903 - val_loss: 0.5881 - val_accuracy: 0.8002\nEpoch 13/30\n449/450 [============================&gt;.] - ETA: 0s - loss: 0.5870 - accuracy: 0.7985\nEpoch 13: val_accuracy improved from 0.80300 to 0.81220, saving model to /content/drive/My Drive/checkpoints/modelocifar_FIAP_Shift.hdf5\n450/450 [==============================] - 8s 18ms/step - loss: 0.5869 - accuracy: 0.7985 - val_loss: 0.5339 - val_accuracy: 0.8122\nEpoch 14/30\n449/450 [============================&gt;.] - ETA: 0s - loss: 0.5685 - accuracy: 0.8063\nEpoch 14: val_accuracy improved from 0.81220 to 0.82560, saving model to /content/drive/My Drive/checkpoints/modelocifar_FIAP_Shift.hdf5\n450/450 [==============================] - 8s 17ms/step - loss: 0.5687 - accuracy: 0.8062 - val_loss: 0.5192 - val_accuracy: 0.8256\nEpoch 15/30\n448/450 [============================&gt;.] - ETA: 0s - loss: 0.5509 - accuracy: 0.8112\nEpoch 15: val_accuracy improved from 0.82560 to 0.82700, saving model to /content/drive/My Drive/checkpoints/modelocifar_FIAP_Shift.hdf5\n450/450 [==============================] - 8s 17ms/step - loss: 0.5516 - accuracy: 0.8111 - val_loss: 0.5204 - val_accuracy: 0.8270\nEpoch 16/30\n450/450 [==============================] - ETA: 0s - loss: 0.5372 - accuracy: 0.8141\nEpoch 16: val_accuracy did not improve from 0.82700\n450/450 [==============================] - 8s 17ms/step - loss: 0.5372 - accuracy: 0.8141 - val_loss: 0.5340 - val_accuracy: 0.8150\nEpoch 17/30\n448/450 [============================&gt;.] - ETA: 0s - loss: 0.5219 - accuracy: 0.8201\nEpoch 17: val_accuracy improved from 0.82700 to 0.83160, saving model to /content/drive/My Drive/checkpoints/modelocifar_FIAP_Shift.hdf5\n450/450 [==============================] - 8s 18ms/step - loss: 0.5218 - accuracy: 0.8202 - val_loss: 0.4938 - val_accuracy: 0.8316\nEpoch 18/30\n450/450 [==============================] - ETA: 0s - loss: 0.5073 - accuracy: 0.8267\nEpoch 18: val_accuracy improved from 0.83160 to 0.83600, saving model to /content/drive/My Drive/checkpoints/modelocifar_FIAP_Shift.hdf5\n450/450 [==============================] - 8s 17ms/step - loss: 0.5073 - accuracy: 0.8267 - val_loss: 0.4806 - val_accuracy: 0.8360\nEpoch 19/30\n450/450 [==============================] - ETA: 0s - loss: 0.5002 - accuracy: 0.8286\nEpoch 19: val_accuracy did not improve from 0.83600\n450/450 [==============================] - 7s 16ms/step - loss: 0.5002 - accuracy: 0.8286 - val_loss: 0.5290 - val_accuracy: 0.8166\nEpoch 20/30\n450/450 [==============================] - ETA: 0s - loss: 0.4842 - accuracy: 0.8338\nEpoch 20: val_accuracy improved from 0.83600 to 0.84180, saving model to /content/drive/My Drive/checkpoints/modelocifar_FIAP_Shift.hdf5\n450/450 [==============================] - 8s 18ms/step - loss: 0.4842 - accuracy: 0.8338 - val_loss: 0.4589 - val_accuracy: 0.8418\nEpoch 21/30\n449/450 [============================&gt;.] - ETA: 0s - loss: 0.4767 - accuracy: 0.8372\nEpoch 21: val_accuracy did not improve from 0.84180\n450/450 [==============================] - 7s 16ms/step - loss: 0.4765 - accuracy: 0.8373 - val_loss: 0.4804 - val_accuracy: 0.8394\nEpoch 22/30\n450/450 [==============================] - ETA: 0s - loss: 0.4654 - accuracy: 0.8406\nEpoch 22: val_accuracy improved from 0.84180 to 0.84900, saving model to /content/drive/My Drive/checkpoints/modelocifar_FIAP_Shift.hdf5\n450/450 [==============================] - 8s 18ms/step - loss: 0.4654 - accuracy: 0.8406 - val_loss: 0.4492 - val_accuracy: 0.8490\nEpoch 23/30\n448/450 [============================&gt;.] - ETA: 0s - loss: 0.4577 - accuracy: 0.8414\nEpoch 23: val_accuracy did not improve from 0.84900\n450/450 [==============================] - 7s 17ms/step - loss: 0.4577 - accuracy: 0.8414 - val_loss: 0.5467 - val_accuracy: 0.8178\nEpoch 24/30\n447/450 [============================&gt;.] - ETA: 0s - loss: 0.4514 - accuracy: 0.8440\nEpoch 24: val_accuracy did not improve from 0.84900\n450/450 [==============================] - 7s 16ms/step - loss: 0.4516 - accuracy: 0.8438 - val_loss: 0.4474 - val_accuracy: 0.8462\nEpoch 25/30\n448/450 [============================&gt;.] - ETA: 0s - loss: 0.4457 - accuracy: 0.8461\nEpoch 25: val_accuracy did not improve from 0.84900\n450/450 [==============================] - 8s 17ms/step - loss: 0.4460 - accuracy: 0.8460 - val_loss: 0.4541 - val_accuracy: 0.8456\nEpoch 26/30\n447/450 [============================&gt;.] - ETA: 0s - loss: 0.4319 - accuracy: 0.8517\nEpoch 26: val_accuracy improved from 0.84900 to 0.85200, saving model to /content/drive/My Drive/checkpoints/modelocifar_FIAP_Shift.hdf5\n450/450 [==============================] - 8s 18ms/step - loss: 0.4315 - accuracy: 0.8518 - val_loss: 0.4302 - val_accuracy: 0.8520\nEpoch 27/30\n447/450 [============================&gt;.] - ETA: 0s - loss: 0.4217 - accuracy: 0.8535\nEpoch 27: val_accuracy improved from 0.85200 to 0.85920, saving model to /content/drive/My Drive/checkpoints/modelocifar_FIAP_Shift.hdf5\n450/450 [==============================] - 8s 17ms/step - loss: 0.4219 - accuracy: 0.8536 - val_loss: 0.4242 - val_accuracy: 0.8592\nEpoch 28/30\n449/450 [============================&gt;.] - ETA: 0s - loss: 0.4214 - accuracy: 0.8552\nEpoch 28: val_accuracy did not improve from 0.85920\n450/450 [==============================] - 7s 16ms/step - loss: 0.4215 - accuracy: 0.8552 - val_loss: 0.4665 - val_accuracy: 0.8438\nEpoch 29/30\n447/450 [============================&gt;.] - ETA: 0s - loss: 0.4081 - accuracy: 0.8589\nEpoch 29: val_accuracy improved from 0.85920 to 0.86180, saving model to /content/drive/My Drive/checkpoints/modelocifar_FIAP_Shift.hdf5\n450/450 [==============================] - 9s 19ms/step - loss: 0.4086 - accuracy: 0.8589 - val_loss: 0.4131 - val_accuracy: 0.8618\nEpoch 30/30\n447/450 [============================&gt;.] - ETA: 0s - loss: 0.4077 - accuracy: 0.8592\nEpoch 30: val_accuracy did not improve from 0.86180\n450/450 [==============================] - 7s 17ms/step - loss: 0.4075 - accuracy: 0.8592 - val_loss: 0.4369 - val_accuracy: 0.8532\n</pre> In\u00a0[\u00a0]: Copied! <pre>plt.figure(1)\nplt.plot(hist.history['accuracy'])\nplt.plot(hist.history['val_accuracy'])\nplt.title('model accuracy')\nplt.ylabel('accuracy')\nplt.xlabel('epoch')\nplt.legend(['train', 'validation'], loc='upper left')\nplt.show()\n</pre> plt.figure(1) plt.plot(hist.history['accuracy']) plt.plot(hist.history['val_accuracy']) plt.title('model accuracy') plt.ylabel('accuracy') plt.xlabel('epoch') plt.legend(['train', 'validation'], loc='upper left') plt.show() <p>Carregar o melhor modelo que obteve a melhor acur\u00e1cia de valida\u00e7\u00e3o no treinamento</p> In\u00a0[\u00a0]: Copied! <pre>model = load_model(\"/content/drive/My Drive/checkpoints/modelocifar.h5\")\n</pre> model = load_model(\"/content/drive/My Drive/checkpoints/modelocifar.h5\") <p>Avaliar e imprimir a precis\u00e3o do teste</p> In\u00a0[\u00a0]: Copied! <pre>score = model.evaluate(x_test, y_test, verbose=0)\nprint('\\n', 'Test accuracy:', score[1])\n</pre> score = model.evaluate(x_test, y_test, verbose=0) print('\\n', 'Test accuracy:', score[1]) <pre>\n Test accuracy: 0.7767000198364258\n</pre> In\u00a0[\u00a0]: Copied! <pre>y_hat = model.predict(x_test)\n</pre> y_hat = model.predict(x_test) <pre>313/313 [==============================] - 1s 3ms/step\n</pre> In\u00a0[\u00a0]: Copied! <pre>y_hat[100,:]\n</pre> y_hat[100,:] Out[\u00a0]: <pre>array([5.8770423e-05, 9.3314156e-08, 5.6933337e-03, 1.1897533e-04,\n       3.1580424e-01, 3.2564318e-03, 6.1175911e-08, 6.7506504e-01,\n       1.1326588e-06, 1.8971995e-06], dtype=float32)</pre> In\u00a0[\u00a0]: Copied! <pre>np.argmax(y_hat[100,:])\n</pre> np.argmax(y_hat[100,:]) Out[\u00a0]: <pre>7</pre> <p>Definindo r\u00f3tulos de texto (r\u00f3tulos dispon\u00edveis na fonte original: https://www.cs.toronto.edu/~kriz/cifar.html)</p> In\u00a0[\u00a0]: Copied! <pre>cifar10_labels = ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n</pre> cifar10_labels = ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck'] <p>Plot de amostra aleat\u00f3ria de imagens de teste, r\u00f3tulos preditos e a \"ground truth\" advinda do dataset CIFAR-10</p> In\u00a0[\u00a0]: Copied! <pre>fig = plt.figure(figsize=(20, 8))\nfor i, idx in enumerate(np.random.choice(x_test.shape[0], size=32, replace=False)):\n    ax = fig.add_subplot(4, 8, i + 1, xticks=[], yticks=[])\n    ax.imshow(np.squeeze(x_test[idx]))\n    pred_idx = np.argmax(y_hat[idx])\n    true_idx = np.argmax(y_test[idx])\n    ax.set_title(\"{} ({})\".format(cifar10_labels[pred_idx], cifar10_labels[true_idx]),\n                 color=(\"green\" if pred_idx == true_idx else \"red\"))\n    # amostras corretamente classificadas em verde, incorretamente classificadas em vermelho\n</pre> fig = plt.figure(figsize=(20, 8)) for i, idx in enumerate(np.random.choice(x_test.shape[0], size=32, replace=False)):     ax = fig.add_subplot(4, 8, i + 1, xticks=[], yticks=[])     ax.imshow(np.squeeze(x_test[idx]))     pred_idx = np.argmax(y_hat[idx])     true_idx = np.argmax(y_test[idx])     ax.set_title(\"{} ({})\".format(cifar10_labels[pred_idx], cifar10_labels[true_idx]),                  color=(\"green\" if pred_idx == true_idx else \"red\"))     # amostras corretamente classificadas em verde, incorretamente classificadas em vermelho"},{"location":"aulas/IA/lab08/cnn_drive.html#2-redes-neurais","title":"2. Redes Neurais\u00b6","text":""},{"location":"aulas/IA/lab08/cnn_drive.html#objetivos","title":"Objetivos\u00b6","text":"<ul> <li>Conhecer e praticar t\u00e9cnicas de Dropout, BatchNormalization e AveragePooling2D</li> <li>Aprender e aplicar a estr\u00e1t\u00e9gia de treinamento com ModelCheckpoint</li> <li>conhecer e utilizar o google drive em conjunto com o colab</li> </ul>"},{"location":"aulas/IA/lab08/cnn_drive.html#1-carregando-bibliotecas","title":"1. Carregando Bibliotecas\u00b6","text":""},{"location":"aulas/IA/lab08/cnn_drive.html#2-carregando-o-dataset-pre-embaralhado-de-treinamento-bem-como-os-dados-de-teste","title":"2. Carregando o dataset pr\u00e9-embaralhado de treinamento bem como os dados de teste\u00b6","text":""},{"location":"aulas/IA/lab08/cnn_drive.html#3-redimensionando-as-imagens-e-dividindo-cada-pixel-em-cada-imagem-por-255","title":"3. Redimensionando as imagens e dividindo cada pixel em cada imagem por 255\u00b6","text":""},{"location":"aulas/IA/lab08/cnn_drive.html#4-dividindo-o-dataset-em-treinamento-teste-e-validacao","title":"4.  Dividindo o dataset em treinamento, teste e valida\u00e7\u00e3o\u00b6","text":""},{"location":"aulas/IA/lab08/cnn_drive.html#5-definindo-a-arquitetura-do-modelo-importante","title":"5. Definindo a arquitetura do modelo (IMPORTANTE!)\u00b6","text":"<ul> <li><p>Use camadas convolucionais de tamanho progressivamente crescente: Utilize m\u00faltiplas camadas convolucionais com um n\u00famero crescente de filtros (por exemplo, 32, 64, 128). Isso ajuda a capturar caracter\u00edsticas mais complexas nas imagens \u00e0 medida que se aprofunda na rede.</p> </li> <li><p>M\u00e1ximo de camadas de \"pooling\" (2x2): Insira camadas de pooling (m\u00e1ximo pooling) ap\u00f3s grupos de camadas convolucionais para reduzir as dimens\u00f5es espaciais da entrada (por exemplo, 2x2 pooling). Isso ajuda a reduzir a complexidade computacional e controlar o overfitting.</p> </li> <li><p>Camadas totalmente conectadas: Adicione uma ou mais camadas totalmente conectadas (fully connected layers) ap\u00f3s as camadas convolucionais e de pooling para combinar as caracter\u00edsticas extra\u00eddas e realizar a classifica\u00e7\u00e3o.</p> </li> <li><p>\u00daltima camada totalmente conectada com 10 sa\u00eddas (10 classes de categoria de imagem): A \u00faltima camada da rede deve ser uma camada totalmente conectada com 10 neur\u00f4nios (unidades) de sa\u00edda, correspondendo \u00e0s 10 classes de imagem no seu problema de classifica\u00e7\u00e3o. Use a fun\u00e7\u00e3o de ativa\u00e7\u00e3o softmax para obter as probabilidades das classes.</p> </li> <li><p>\"Dropout\" de 0,2-0,5: Aplique a t\u00e9cnica de Dropout entre as camadas, especialmente nas camadas totalmente conectadas, com uma taxa de dropout entre 0,2 e 0,5. Isso ajuda a prevenir overfitting, desligando aleatoriamente neur\u00f4nios durante o treinamento.</p> </li> <li><p>\"BatchNormalization\" ap\u00f3s convolu\u00e7\u00e3o: Utilize camadas de Batch Normalization ap\u00f3s as camadas convolucionais para normalizar as ativa\u00e7\u00f5es da camada anterior. Isso ajuda a acelerar o treinamento e a estabilizar a rede neural.</p> </li> </ul>"},{"location":"aulas/IA/lab08/cnn_drive.html#6-compilando-o-modelo","title":"6. Compilando o modelo\u00b6","text":""},{"location":"aulas/IA/lab08/cnn_drive.html#7-treinando-o-modelo","title":"7. Treinando o modelo\u00b6","text":"<p>Treinar modelos de aprendizado profundo pode ser uma tarefa demorada, especialmente para modelos complexos e conjuntos de dados grandes. Para garantir que voc\u00ea n\u00e3o perca o progresso e consiga restaurar o melhor modelo encontrado durante o treinamento, o Keras oferece a callback ModelCheckpoint. Esta ferramenta permite salvar o modelo atual ap\u00f3s cada \u00e9poca, ou quando uma m\u00e9trica espec\u00edfica melhora, facilitando a recupera\u00e7\u00e3o do melhor modelo</p>"},{"location":"aulas/IA/lab08/cnn_drive.html#8-calculo-da-precisao-de-classificacao-no-dataset-de-testes","title":"8. C\u00e1lculo da precis\u00e3o de classifica\u00e7\u00e3o no dataset de testes\u00b6","text":""},{"location":"aulas/IA/lab08/cnn_drive.html#9-visualizar-algumas-predicoes","title":"9. Visualizar algumas predi\u00e7\u00f5es\u00b6","text":"<p>As visualiza\u00e7\u00f5es podem nos dar algumas dicas sobre por que a rede classifica erroneamente alguns objetos. Obtendo previs\u00f5es no conjunto de testes:</p>"},{"location":"aulas/IA/lab09/transferlearning.html","title":"Transferlearning","text":"In\u00a0[1]: Copied! <pre>import numpy as np\nfrom tensorflow.keras.preprocessing import image\n\n\n## importa o modelo da VGG16 pr\u00e9-treinado\nfrom tensorflow.keras.applications.vgg16 import VGG16, preprocess_input, decode_predictions\n</pre> import numpy as np from tensorflow.keras.preprocessing import image   ## importa o modelo da VGG16 pr\u00e9-treinado from tensorflow.keras.applications.vgg16 import VGG16, preprocess_input, decode_predictions   In\u00a0[2]: Copied! <pre># Carrega o modelo VGG16 pr\u00e9-treinado com ImageNet:\nmodel = VGG16()\n</pre> # Carrega o modelo VGG16 pr\u00e9-treinado com ImageNet: model = VGG16()  <pre>Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels.h5\n553467096/553467096 [==============================] - 24s 0us/step\n</pre> In\u00a0[18]: Copied! <pre># Carrega uma imagem e prepara para ser predita pela VGG16\n\n## teste 1\n!wget https://images.tcdn.com.br/img/img_prod/777105/bicicleta_29_hope_21_velocidades_shimano_freios_disco_tamanho_17_12475_1_ac0b7c63eee851b87bcc9832033c9826.jpg -O /content/bike.jpg\nimg_path = 'bike.jpg'\n\n# teste 2\n#!wget https://liberal.com.br/wp-content/uploads/2019/11/buraco-rua-dos-anturios.jpg -O /content/buraco.jpg\n#img_path = 'buraco.jpg'\n\n\n# teste 3\n#img_path = 'COLOQUE_UMA_IMAGEM.jpg'\n\n\nimg = image.load_img(img_path, target_size=(224, 224))\nx = image.img_to_array(img)\nx = np.expand_dims(x, axis=0)\nx = preprocess_input(x)\nprint(\"A imagem \u00e9 carregada e transformada de {}, para {}\".format(img.size,x.shape))\n</pre> # Carrega uma imagem e prepara para ser predita pela VGG16  ## teste 1 !wget https://images.tcdn.com.br/img/img_prod/777105/bicicleta_29_hope_21_velocidades_shimano_freios_disco_tamanho_17_12475_1_ac0b7c63eee851b87bcc9832033c9826.jpg -O /content/bike.jpg img_path = 'bike.jpg'  # teste 2 #!wget https://liberal.com.br/wp-content/uploads/2019/11/buraco-rua-dos-anturios.jpg -O /content/buraco.jpg #img_path = 'buraco.jpg'   # teste 3 #img_path = 'COLOQUE_UMA_IMAGEM.jpg'   img = image.load_img(img_path, target_size=(224, 224)) x = image.img_to_array(img) x = np.expand_dims(x, axis=0) x = preprocess_input(x) print(\"A imagem \u00e9 carregada e transformada de {}, para {}\".format(img.size,x.shape)) <pre>--2023-05-02 11:35:17--  https://images.tcdn.com.br/img/img_prod/777105/bicicleta_29_hope_21_velocidades_shimano_freios_disco_tamanho_17_12475_1_ac0b7c63eee851b87bcc9832033c9826.jpg\nResolving images.tcdn.com.br (images.tcdn.com.br)... 152.199.40.152\nConnecting to images.tcdn.com.br (images.tcdn.com.br)|152.199.40.152|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 286478 (280K) [image/jpeg]\nSaving to: \u2018/content/bike.jpg\u2019\n\n/content/bike.jpg   100%[===================&gt;] 279.76K  --.-KB/s    in 0.005s  \n\n2023-05-02 11:35:18 (57.9 MB/s) - \u2018/content/bike.jpg\u2019 saved [286478/286478]\n\nA imagem \u00e9 carregada e transformada de (224, 224), para (1, 224, 224, 3)\n</pre> In\u00a0[19]: Copied! <pre>## faz a predi\u00e7\u00e3o da imagem\n\npreds = model.predict(x)\n</pre> ## faz a predi\u00e7\u00e3o da imagem  preds = model.predict(x)  <pre>1/1 [==============================] - 0s 21ms/step\n</pre> In\u00a0[20]: Copied! <pre>decoded_preds = decode_predictions(preds)[0]\n\nfor i, (imagenet_id, label, score) in enumerate(decoded_preds):\n    print(f\"{i+1}. {label}: {score * 100:.2f}%\")\n</pre> decoded_preds = decode_predictions(preds)[0]  for i, (imagenet_id, label, score) in enumerate(decoded_preds):     print(f\"{i+1}. {label}: {score * 100:.2f}%\")  <pre>1. mountain_bike: 81.59%\n2. alp: 3.85%\n3. crash_helmet: 1.89%\n4. bicycle-built-for-two: 1.80%\n5. tricycle: 1.75%\n</pre> In\u00a0[21]: Copied! <pre>from tensorflow.keras.applications.resnet50 import ResNet50, preprocess_input, decode_predictions\n\nmodel = ResNet50(weights='imagenet')\n\n\n#### seu c\u00f3digo aqui....\n</pre> from tensorflow.keras.applications.resnet50 import ResNet50, preprocess_input, decode_predictions  model = ResNet50(weights='imagenet')   #### seu c\u00f3digo aqui....    <pre>Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels.h5\n102967424/102967424 [==============================] - 5s 0us/step\n</pre> In\u00a0[47]: Copied! <pre>import os\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport tensorflow as tf\nfrom tensorflow.keras import layers, models\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\n\n# Configura\u00e7\u00e3o dos diret\u00f3rios e par\u00e2metros do conjunto de dados\n_URL = 'https://storage.googleapis.com/mledu-datasets/cats_and_dogs_filtered.zip'\npath_to_zip = tf.keras.utils.get_file('cats_and_dogs.zip', origin=_URL, extract=True)\nPATH = os.path.join(os.path.dirname(path_to_zip), 'cats_and_dogs_filtered')\n\ntrain_dir = os.path.join(PATH, 'train')\nvalidation_dir = os.path.join(PATH, 'validation')\n\nbatch_size = 32\nimage_size = (224, 224)\n</pre> import os import numpy as np import matplotlib.pyplot as plt import tensorflow as tf from tensorflow.keras import layers, models from tensorflow.keras.preprocessing.image import ImageDataGenerator  # Configura\u00e7\u00e3o dos diret\u00f3rios e par\u00e2metros do conjunto de dados _URL = 'https://storage.googleapis.com/mledu-datasets/cats_and_dogs_filtered.zip' path_to_zip = tf.keras.utils.get_file('cats_and_dogs.zip', origin=_URL, extract=True) PATH = os.path.join(os.path.dirname(path_to_zip), 'cats_and_dogs_filtered')  train_dir = os.path.join(PATH, 'train') validation_dir = os.path.join(PATH, 'validation')  batch_size = 32 image_size = (224, 224)  In\u00a0[43]: Copied! <pre># Fun\u00e7\u00e3o para exibir algumas imagens do conjunto de dados\ndef plot_images(images, labels, class_names):\n    plt.figure(figsize=(10, 10))\n    for i, (img, label) in enumerate(zip(images, labels)):\n        plt.subplot(3, 3, i + 1)\n        plt.imshow(img)\n        plt.title(class_names[label])\n        plt.axis(\"off\")\n    plt.show()\n\n# Carregar imagens e r\u00f3tulos do conjunto de dados de treinamento\ntrain_datagen = ImageDataGenerator(preprocessing_function=preprocess_input)\nvalidation_datagen = ImageDataGenerator(preprocessing_function=preprocess_input)\n\ntrain_generator = train_datagen.flow_from_directory(\n    train_dir,\n    target_size=image_size,\n    batch_size=batch_size,\n    class_mode='binary'\n)\n\n# Carregar imagens e r\u00f3tulos do conjunto de dados de valida\u00e7\u00e3o\nvalidation_generator = validation_datagen.flow_from_directory(\n    validation_dir,\n    target_size=image_size,\n    batch_size=batch_size,\n    class_mode='binary'\n)\n\n# Carregar algumas imagens e r\u00f3tulos do conjunto de dados de treinamento\nsample_datagen = ImageDataGenerator(rescale=1./255)\nsample_generator = sample_datagen.flow_from_directory(\n    train_dir,\n    target_size=image_size,\n    batch_size=9,\n    class_mode='binary'\n)\n\nsample_images, sample_labels = next(sample_generator)\nclass_names = {v: k for k, v in sample_generator.class_indices.items()}\nplot_images(sample_images, sample_labels, class_names)\n</pre> # Fun\u00e7\u00e3o para exibir algumas imagens do conjunto de dados def plot_images(images, labels, class_names):     plt.figure(figsize=(10, 10))     for i, (img, label) in enumerate(zip(images, labels)):         plt.subplot(3, 3, i + 1)         plt.imshow(img)         plt.title(class_names[label])         plt.axis(\"off\")     plt.show()  # Carregar imagens e r\u00f3tulos do conjunto de dados de treinamento train_datagen = ImageDataGenerator(preprocessing_function=preprocess_input) validation_datagen = ImageDataGenerator(preprocessing_function=preprocess_input)  train_generator = train_datagen.flow_from_directory(     train_dir,     target_size=image_size,     batch_size=batch_size,     class_mode='binary' )  # Carregar imagens e r\u00f3tulos do conjunto de dados de valida\u00e7\u00e3o validation_generator = validation_datagen.flow_from_directory(     validation_dir,     target_size=image_size,     batch_size=batch_size,     class_mode='binary' )  # Carregar algumas imagens e r\u00f3tulos do conjunto de dados de treinamento sample_datagen = ImageDataGenerator(rescale=1./255) sample_generator = sample_datagen.flow_from_directory(     train_dir,     target_size=image_size,     batch_size=9,     class_mode='binary' )  sample_images, sample_labels = next(sample_generator) class_names = {v: k for k, v in sample_generator.class_indices.items()} plot_images(sample_images, sample_labels, class_names) <pre>Found 2000 images belonging to 2 classes.\nFound 1000 images belonging to 2 classes.\nFound 2000 images belonging to 2 classes.\n</pre> In\u00a0[87]: Copied! <pre>from tensorflow.keras.applications.mobilenet_v2 import MobileNetV2, preprocess_input\n\n# Cria o base_model referente a MobileNet V2, sem a camada de classifica\u00e7\u00e3o\nbase_model = MobileNetV2(input_shape=(224, 224, 3),\n                        include_top=False,\n                        weights='imagenet')\n</pre> from tensorflow.keras.applications.mobilenet_v2 import MobileNetV2, preprocess_input  # Cria o base_model referente a MobileNet V2, sem a camada de classifica\u00e7\u00e3o base_model = MobileNetV2(input_shape=(224, 224, 3),                         include_top=False,                         weights='imagenet') In\u00a0[\u00a0]: Copied! <pre>base_model.summary()\n</pre> base_model.summary() In\u00a0[90]: Copied! <pre>#Congela a base_model para n\u00e3o atuaizar os pesos quando treinar.\n\nbase_model.trainable = False\n</pre> #Congela a base_model para n\u00e3o atuaizar os pesos quando treinar.  base_model.trainable = False In\u00a0[\u00a0]: Copied! <pre>base_model.summary()\n</pre> base_model.summary() In\u00a0[92]: Copied! <pre>#Camada  para gerar um vetor de 1280 elementos \nglobal_average_layer = layers.GlobalAveragePooling2D()\n\n# O Classificador para gato cachorro com 1 neuronio \nsaida_layer = layers.Dense(1, activation='sigmoid')\n</pre> #Camada  para gerar um vetor de 1280 elementos  global_average_layer = layers.GlobalAveragePooling2D()  # O Classificador para gato cachorro com 1 neuronio  saida_layer = layers.Dense(1, activation='sigmoid') In\u00a0[93]: Copied! <pre>model = tf.keras.Sequential([\n  base_model,   #### cnn mobilenet\n  global_average_layer, ###flatten\n  saida_layer ### especiallista\n])\n\nmodel.summary()\n</pre> model = tf.keras.Sequential([   base_model,   #### cnn mobilenet   global_average_layer, ###flatten   saida_layer ### especiallista ])  model.summary() <pre>Model: \"sequential_1\"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\n mobilenetv2_1.00_224 (Funct  (None, 7, 7, 1280)       2257984   \n ional)                                                          \n                                                                 \n global_average_pooling2d_5   (None, 1280)             0         \n (GlobalAveragePooling2D)                                        \n                                                                 \n dense_4 (Dense)             (None, 1)                 1281      \n                                                                 \n=================================================================\nTotal params: 2,259,265\nTrainable params: 1,281\nNon-trainable params: 2,257,984\n_________________________________________________________________\n</pre> <p>Pronto! J\u00e1 criamos a nossa rede para classifica\u00e7\u00e3o. Agora podemos treinar nossa rede e testar.</p> In\u00a0[94]: Copied! <pre>model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n</pre>  model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy']) In\u00a0[95]: Copied! <pre>#Avalia\u00e7\u00e3o do modelo antes de trein\u00e1-lo com novas imagens\nvalidation_steps=20\n\nloss0,accuracy0 = model.evaluate(train_generator, steps = validation_steps)\n</pre> #Avalia\u00e7\u00e3o do modelo antes de trein\u00e1-lo com novas imagens validation_steps=20  loss0,accuracy0 = model.evaluate(train_generator, steps = validation_steps) <pre>20/20 [==============================] - 5s 178ms/step - loss: 0.8159 - accuracy: 0.5125\n</pre> In\u00a0[62]: Copied! <pre># Treinamento da nova CNN\n\nhistory = model.fit(train_generator, epochs=5, validation_data=validation_generator)\n</pre> # Treinamento da nova CNN  history = model.fit(train_generator, epochs=5, validation_data=validation_generator)  <pre>Epoch 1/5\n63/63 [==============================] - 19s 232ms/step - loss: 0.6893 - accuracy: 0.6200 - val_loss: 0.5397 - val_accuracy: 0.7490\nEpoch 2/5\n63/63 [==============================] - 13s 205ms/step - loss: 0.4975 - accuracy: 0.7575 - val_loss: 0.4721 - val_accuracy: 0.7780\nEpoch 3/5\n63/63 [==============================] - 13s 206ms/step - loss: 0.4484 - accuracy: 0.7880 - val_loss: 0.4458 - val_accuracy: 0.7980\nEpoch 4/5\n63/63 [==============================] - 13s 202ms/step - loss: 0.4176 - accuracy: 0.8005 - val_loss: 0.4327 - val_accuracy: 0.8020\nEpoch 5/5\n63/63 [==============================] - 13s 204ms/step - loss: 0.3953 - accuracy: 0.8235 - val_loss: 0.4159 - val_accuracy: 0.8180\n</pre> In\u00a0[64]: Copied! <pre>import pandas as pd\n\nmetrics_df = pd.DataFrame(history.history)\nmetrics_df[[\"loss\",\"val_loss\"]].plot();\nmetrics_df[[\"accuracy\", \"val_accuracy\"]].plot();\n</pre> import pandas as pd  metrics_df = pd.DataFrame(history.history) metrics_df[[\"loss\",\"val_loss\"]].plot(); metrics_df[[\"accuracy\", \"val_accuracy\"]].plot(); In\u00a0[67]: Copied! <pre>import numpy as np\nfrom tensorflow.keras.preprocessing import image\n\ndef predict_cat_or_dog(img_path):\n    img = image.load_img(img_path, target_size=image_size)\n    img_array = image.img_to_array(img)\n    img_array = np.expand_dims(img_array, axis=0)\n    img_array = preprocess_input(img_array)\n\n    prediction = model.predict(img_array)\n    \n    if prediction[0][0] &lt; 0.5:\n        return \"gatinhooooo\"\n    else:\n        return \"cachorrinho\"\n\n# Teste a fun\u00e7\u00e3o de previs\u00e3o com uma imagem\n\n!wget https://uploads.metropoles.com/wp-content/uploads/2022/07/21154234/como-identificar-que-um-cachorro-esta-sendo-vitima-de-maus-tratos-1.jpg -O /content/cachorro.jpg\nimg_path = \"cachorro.jpg\"\nresult = predict_cat_or_dog(img_path)\nprint(\"Essa foto \u00e9 de um \", result)\n</pre> import numpy as np from tensorflow.keras.preprocessing import image  def predict_cat_or_dog(img_path):     img = image.load_img(img_path, target_size=image_size)     img_array = image.img_to_array(img)     img_array = np.expand_dims(img_array, axis=0)     img_array = preprocess_input(img_array)      prediction = model.predict(img_array)          if prediction[0][0] &lt; 0.5:         return \"gatinhooooo\"     else:         return \"cachorrinho\"  # Teste a fun\u00e7\u00e3o de previs\u00e3o com uma imagem  !wget https://uploads.metropoles.com/wp-content/uploads/2022/07/21154234/como-identificar-que-um-cachorro-esta-sendo-vitima-de-maus-tratos-1.jpg -O /content/cachorro.jpg img_path = \"cachorro.jpg\" result = predict_cat_or_dog(img_path) print(\"Essa foto \u00e9 de um \", result) <pre>--2023-05-02 12:32:46--  https://uploads.metropoles.com/wp-content/uploads/2022/07/21154234/como-identificar-que-um-cachorro-esta-sendo-vitima-de-maus-tratos-1.jpg\nResolving uploads.metropoles.com (uploads.metropoles.com)... 179.191.175.68, 179.191.175.67, 179.191.177.66, ...\nConnecting to uploads.metropoles.com (uploads.metropoles.com)|179.191.175.68|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 47409 (46K) [image/jpeg]\nSaving to: \u2018/content/cachorro.jpg\u2019\n\n/content/cachorro.j 100%[===================&gt;]  46.30K   200KB/s    in 0.2s    \n\n2023-05-02 12:32:47 (200 KB/s) - \u2018/content/cachorro.jpg\u2019 saved [47409/47409]\n\n1/1 [==============================] - 0s 23ms/step\nEssa foto \u00e9 de um  cachorrinho\n</pre> In\u00a0[69]: Copied! <pre># Salvando a rede \nmodel.save(\"dogs_vs_cats.h5\")\n\n#Carregando uma rede .h5\nnew_model = models.load_model('dogs_vs_cats.h5')\n</pre> # Salvando a rede  model.save(\"dogs_vs_cats.h5\")  #Carregando uma rede .h5 new_model = models.load_model('dogs_vs_cats.h5') In\u00a0[\u00a0]: Copied! <pre>### Seu c\u00f3digo aqui....\n</pre> ### Seu c\u00f3digo aqui...."},{"location":"aulas/IA/lab09/transferlearning.html#2-redes-neurais","title":"2. Redes Neurais\u00b6","text":""},{"location":"aulas/IA/lab09/transferlearning.html#objetivos","title":"Objetivos\u00b6","text":"<ul> <li>Conhecer e praticar Arquiteturas complexas de Redes Neurais Convolucionais</li> <li>Aprendizagem por transfer\u00eancia</li> <li>Praticar a classifica\u00e7\u00e3o de objeto usando framework TensorFlow</li> </ul>"},{"location":"aulas/IA/lab09/transferlearning.html#arquitetura-de-redes-neurais-convolucionais","title":"Arquitetura de Redes Neurais Convolucionais\u00b6","text":"<p>Existem diversas arquitetura de CNN, cada rede com suas pr\u00f3prias caracter\u00edsticas, principalmente para vis\u00e3o computacional. Mas todas ter\u00e3o em comum camadas de convolu\u00e7\u00e3o e maxpooling, dropout e algumas coisas a mais...</p>"},{"location":"aulas/IA/lab09/transferlearning.html#por-que-utilizar-uma-arquitetura-cnn","title":"Por que utilizar uma arquitetura CNN\u00b6","text":"<p>Utilizar uma arquitetura de CNN possibilita reduzir o tempo de pesquisa com o desenvolvimento de novas arquiteturas uma vez que essas arquiteturas j\u00e1 foram sistematicamente revisadas.</p>"},{"location":"aulas/IA/lab09/transferlearning.html#exemplos-de-arquiteturas","title":"Exemplos de arquiteturas:\u00b6","text":"<p><code>LeNET</code>: Desenvolvida em 1998 por Yann LeCun, a LeNet foi pioneira no uso de camadas de convolu\u00e7\u00e3o com filtros 5x5 e passo 1, al\u00e9m de camadas de agrupamento com filtros 2x2 e passo 2, intercaladas por camadas totalmente conectadas (FC). A ordem das camadas \u00e9: CONV-POOL-CONV-POOL-FC-FC. Essa arquitetura teve um papel fundamental no reconhecimento de d\u00edgitos manuscritos.</p> <p></p> <p><code>AlexNET</code>: Criada em 2012 por Alex Krizhevsky, Ilya Sutskever e Geoffrey Hinton, a AlexNet \u00e9 uma arquitetura mais avan\u00e7ada que a LeNet. Possui cinco camadas convolucionais seguidas de tr\u00eas camadas FC, e emprega a fun\u00e7\u00e3o de ativa\u00e7\u00e3o ReLU. Vencedora da competi\u00e7\u00e3o ImageNet de 2012, marcou o in\u00edcio da populariza\u00e7\u00e3o das redes neurais convolucionais profundas.</p> <p></p> <p><code>VGG</code>: A arquitetura VGG, concebida em 2014 pelo Visual Geometry Group da Universidade de Oxford, prop\u00f4s o uso de filtros menores (3x3) em redes mais profundas, com no m\u00ednimo 16 camadas convolucionais e maxpooling com filtros 2x2. Apesar de os filtros menores gerarem menos par\u00e2metros, as camadas FC e as convolu\u00e7\u00f5es iniciais demandavam grande quantidade de mem\u00f3ria RAM, resultando em uma rede pesada.</p> <p></p> <p><code>GoogleNET</code>: Paralelamente \u00e0 VGG, em 2014, pesquisadores do Google desenvolveram a GoogleNet, que introduziu o m\u00f3dulo Inception como elemento fundamental. Com nove m\u00f3dulos Inception em sequ\u00eancia, a arquitetura utiliza convolu\u00e7\u00f5es 3x3 e 5x5 precedidas por convolu\u00e7\u00f5es 1x1 para diminuir o custo computacional. A GoogleNet foi projetada para ser eficiente em termos de recursos e venceu a competi\u00e7\u00e3o ImageNet de 2014.</p> <p></p> <p><code>ResNET</code>: A rede residual, proposta em 2015 por Kaiming He e colaboradores, tem como caracter\u00edstica principal a inclus\u00e3o de conex\u00f5es residuais (curto-circuitos) a cada duas convolu\u00e7\u00f5es, adicionando um resultado anterior ao resultado futuro. Isso permite treinar redes mais profundas sem problemas de degrada\u00e7\u00e3o do desempenho. ResNets com 50, 101 e 152 camadas utilizam blocos residuais com \"bottleneck\", que consistem em duas convolu\u00e7\u00f5es 3x3 intercaladas por convolu\u00e7\u00f5es 1x1, diminuindo o custo computacional.</p> <p></p> <p><code>MobileNet</code>: Proposta em 2017, \u00e9 uma arquitetura otimizada para dispositivos m\u00f3veis e aplicativos com limita\u00e7\u00f5es de recursos computacionais. Utiliza convolu\u00e7\u00f5es separ\u00e1veis por profundidade para reduzir o n\u00famero de par\u00e2metros e o consumo de mem\u00f3ria.</p> <p><code>EfficientNet</code>: Proposta em 2019, \u00e9 uma fam\u00edlia de redes neurais convolucionais que busca melhorar a efici\u00eancia em termos de recursos computacionais e desempenho, atrav\u00e9s do ajuste coordenado da largura, profundidade e resolu\u00e7\u00e3o das redes.</p> <p><code>InceptionV3</code>: Uma evolu\u00e7\u00e3o do GoogleNet, a InceptionV3 \u00e9 uma arquitetura desenvolvida em 2015 que aprimora o m\u00f3dulo Inception e implementa t\u00e9cnicas de normaliza\u00e7\u00e3o em lotes. Essa arquitetura alcan\u00e7a um desempenho superior com menos par\u00e2metros e menor custo computacional.</p> <p><code>DenseNet</code>: Proposta em 2016, a DenseNet \u00e9 uma arquitetura que introduz conex\u00f5es densas entre as camadas. Cada camada recebe as caracter\u00edsticas de todas as camadas anteriores, o que melhora o fluxo de informa\u00e7\u00f5es e gradientes durante o treinamento. Isso permite a constru\u00e7\u00e3o de redes mais profundas e eficientes.</p> <p><code>YOLO</code> (You Only Look Once): \u00c9 uma arquitetura de rede neural focada em detec\u00e7\u00e3o de objetos em tempo real. Proposta em 2016, a YOLO divide a imagem em regi\u00f5es e prev\u00ea, de uma s\u00f3 vez, as probabilidades de classes e as coordenadas das caixas delimitadoras. A YOLO \u00e9 conhecida por sua velocidade e capacidade de detectar objetos em tempo real.</p> <p><code>Transformer</code>: Embora n\u00e3o seja uma arquitetura de rede neural convolucional, o Transformer, proposto em 2017, \u00e9 uma arquitetura de rede neural not\u00e1vel para processamento de linguagem natural e outras tarefas sequenciais. O Transformer introduziu o conceito de aten\u00e7\u00e3o auto-regressiva, que permite que a rede aprenda relacionamentos complexos entre as entradas, e tem sido a base para modelos de linguagem de \u00faltima gera\u00e7\u00e3o, como BERT e GPT.</p> <p>Parace que s\u00e3o muitas, mas essas s\u00e3o apenas algumas arquiteturas de redes neurais desenvolvidas nos \u00faltimos anos. Dependendo da aplica\u00e7\u00e3o e das restri\u00e7\u00f5es de recursos, voc\u00ea pode encontrar uma arquitetura adequada \u00e0s suas necessidades espec\u00edficas.</p>"},{"location":"aulas/IA/lab09/transferlearning.html#modelos-de-cnn-pre-treinados","title":"Modelos de CNN pr\u00e9-treinados\u00b6","text":"<p>O treinamento de uma boa CNN n\u00e3o \u00e9 simples, al\u00e9m de muitos dados (milhares de imagens) e muito tempo de processamento.</p> <p>Mas usar essas redes \u00e9 super super facil!!</p> <p>Vamos usar o VGG16 para fazer a classifica\u00e7\u00e3o de uma imagem.</p> <p>Recomendo dar uma olhada na documenta\u00e7\u00e3o oficial do Keras:  https://keras.io/api/applications/</p>"},{"location":"aulas/IA/lab09/transferlearning.html#desafio-1","title":"Desafio 1\u00b6","text":"<p>Agora avalie outras arquiteturas de redes neurais dispon\u00edveis no Keras, como ResNet50, InceptionV3, MobileNet e EfficientNet.</p> <p>Basta substituir a importa\u00e7\u00e3o e a fun\u00e7\u00e3o de carregamento do modelo conforme necess\u00e1rio. Por exemplo, para usar a ResNet50:</p>"},{"location":"aulas/IA/lab09/transferlearning.html#introducao-ao-transfer-learning-com-redes-pre-treinadas","title":"Introdu\u00e7\u00e3o ao Transfer Learning com redes pr\u00e9-treinadas\u00b6","text":"<p>Excelente! Agora que j\u00e1 sabemos como utilizar uma rede pr\u00e9-treinada, vamos explorar uma t\u00e9cnica poderosa chamada Transfer Learning (Aprendizagem por Transfer\u00eancia). Essa abordagem nos permite tirar proveito das arquiteturas de redes neurais existentes e trein\u00e1-las para classificar objetos personalizados ou novas categorias de imagens.</p> <p>O Transfer Learning \u00e9 uma t\u00e9cnica em que um modelo de aprendizado profundo, treinado previamente em um conjunto de dados maior e mais diversificado, \u00e9 adaptado para ser aplicado a um novo problema. O conhecimento adquirido pelo modelo original \u00e9 transferido para o novo problema, permitindo um treinamento mais r\u00e1pido e, muitas vezes, um desempenho melhor do que treinar uma rede neural do zero.</p> <p>A ideia por tr\u00e1s do Transfer Learning \u00e9 que as redes neurais pr\u00e9-treinadas, como VGG, ResNet e Inception, j\u00e1 aprenderam a <code>extrair caracter\u00edsticas</code> importantes das imagens em seus primeiros est\u00e1gios. Essas caracter\u00edsticas podem ser comuns a muitos problemas de classifica\u00e7\u00e3o de imagens, como detec\u00e7\u00e3o de bordas, texturas e padr\u00f5es. Ao aproveitar esse conhecimento pr\u00e9vio, podemos nos concentrar no treinamento das \u00faltimas camadas do modelo, que s\u00e3o respons\u00e1veis por aprender caracter\u00edsticas espec\u00edficas do novo problema.</p> <p>Ao utilizar o Transfer Learning, podemos economizar tempo e recursos computacionais, al\u00e9m de obter melhores resultados do que treinar uma rede do zero para um conjunto de dados menor e espec\u00edfico. Portanto, \u00e9 uma t\u00e9cnica amplamente utilizada em aplica\u00e7\u00f5es pr\u00e1ticas de aprendizado profundo e processamento de imagens.</p>"},{"location":"aulas/IA/lab09/transferlearning.html#combinando-a-rede-pre-treinada-com-um-classificador-mlp","title":"Combinando a rede pr\u00e9-treinada com um classificador MLP\u00b6","text":"<p>Ao aplicar o Transfer Learning, nossa rede convolucional ser\u00e1 composta por duas partes principais: o extrator de caracter\u00edsticas e o classificador. O extrator de caracter\u00edsticas ser\u00e1 baseado em uma rede pr\u00e9-treinada, como VGG16, ResNet50 ou InceptionV3. Essa parte da rede j\u00e1 aprendeu a extrair caracter\u00edsticas relevantes de imagens, como bordas, texturas e padr\u00f5es, durante o treinamento em um grande conjunto de dados, como o ImageNet.</p> <p>Em seguida, adicionaremos um classificador MLP (Multilayer Perceptron) personalizado para resolver o nosso problema espec\u00edfico de classifica\u00e7\u00e3o de imagens. Esse classificador ser\u00e1 respons\u00e1vel por aprender as caracter\u00edsticas espec\u00edficas do novo conjunto de dados e classificar as imagens nas categorias desejadas.</p> <p>Dessa forma, a rede ajustada combina o poder das redes pr\u00e9-treinadas, que j\u00e1 aprenderam a extrair caracter\u00edsticas gerais de imagens, com um classificador personalizado que aprender\u00e1 a distinguir as categorias espec\u00edficas do nosso problema. Como mostra a figura abaixo:</p> <p></p> <p>Agora que entendemos os conceitos b\u00e1sicos de Transfer Learning, podemos prosseguir com os passos para aplicar o Transfer Learning e adaptar a rede pr\u00e9-treinada ao nosso problema de classifica\u00e7\u00e3o de imagens.</p>"},{"location":"aulas/IA/lab09/transferlearning.html#passo-a-passo-para-aplicar-transfer-learning","title":"Passo a passo para aplicar Transfer Learning\u00b6","text":"<ol> <li><p>Escolha uma rede pr\u00e9-treinada: Selecione uma rede neural pr\u00e9-treinada dispon\u00edvel no Keras (por exemplo, VGG16, ResNet50, InceptionV3) com base nas caracter\u00edsticas e requisitos do seu problema. Cada arquitetura tem suas pr\u00f3prias vantagens e desvantagens, portanto, escolha aquela que melhor se adapta \u00e0s suas necessidades.</p> </li> <li><p>Remova a camada de classifica\u00e7\u00e3o: Carregue a rede neural pr\u00e9-treinada sem a camada de classifica\u00e7\u00e3o final. Isso pode ser feito usando o argumento include_top=False ao carregar o modelo no Keras. Isso permitir\u00e1 que voc\u00ea adicione suas pr\u00f3prias camadas personalizadas para classificar as novas categorias.</p> </li> <li><p>Adicione camadas personalizadas: Adicione camadas espec\u00edficas para o seu problema de classifica\u00e7\u00e3o. Normalmente, isso inclui uma camada de GlobalAveragePooling2D, seguida por uma camada densa com uma fun\u00e7\u00e3o de ativa\u00e7\u00e3o softmax e o n\u00famero de neuronios igual ao n\u00famero de classes do novo problema.</p> </li> <li><p>Congele as camadas pr\u00e9-treinadas: \u00c9 uma boa pr\u00e1tica congelar as camadas pr\u00e9-treinadas da rede neural, especialmente durante as primeiras \u00e9pocas do treinamento. Isso evitar\u00e1 que os pesos dessas camadas sejam atualizados e preservar\u00e1 o conhecimento pr\u00e9vio que elas possuem. No Keras, voc\u00ea pode fazer isso com o modelxxx.trainable = False</p> </li> <li><p>Pr\u00e9-processamento dos dados: Prepare os dados de acordo com a rede pr\u00e9-treinada escolhida. Isso inclui redimensionar as imagens, normalizar os valores dos pixels e codificar as etiquetas das categorias. Lembre-se de aplicar as mesmas transforma\u00e7\u00f5es usadas no conjunto de dados original da rede pr\u00e9-treinada.</p> </li> <li><p>Treine o modelo: Treine o modelo ajustado no seu conjunto de dados. Durante as primeiras \u00e9pocas, com as camadas pr\u00e9-treinadas congeladas, o modelo aprender\u00e1 as caracter\u00edsticas espec\u00edficas do novo problema.</p> </li> <li><p>Avalie e otimize: Avalie o desempenho do modelo ajustado em um conjunto de teste e otimize os hiperpar\u00e2metros conforme necess\u00e1rio. Voc\u00ea pode experimentar diferentes arquiteturas de redes neurais, taxas de aprendizado, otimizadores e outros hiperpar\u00e2metros para encontrar a melhor configura\u00e7\u00e3o para o seu problema.</p> </li> </ol>"},{"location":"aulas/IA/lab09/transferlearning.html#aplicando-transfer-learning-em-um-dataset-ja-preparado-pelo-tensorflow","title":"Aplicando transfer learning em um dataset j\u00e1 preparado pelo tensorflow\u00b6","text":"<p>Vamos usar o dataset <code>cats_vs_dogs</code> que \u00e9 disponibilizado pelo proprio tensorflow, desta forma focamos apenas no entendimento da tecnica de transfer learning e menos em preprocessamento e cria\u00e7\u00e3o de dados. nas proximas aulas vamos criar nosso proprio dataset...</p>"},{"location":"aulas/IA/lab09/transferlearning.html#escolhendo-um-modelo-pre-treinado","title":"Escolhendo um modelo pr\u00e9-treinado\u00b6","text":"<p>A <code>MobileNet V2</code> desenvolvido no Google e foi treinado com <code>1,4 milh\u00e3o de imagens</code> e possui <code>1000 classes diferentes</code> com pesos predeterminados do imagenet (Googles dataset).</p> <p>Carregue a rede neural pr\u00e9-treinada sem a camada de classifica\u00e7\u00e3o final. Isso pode ser feito usando o argumento <code>include_top=False</code></p>"},{"location":"aulas/IA/lab09/transferlearning.html#adicionando-um-classificador","title":"Adicionando um Classificador\u00b6","text":""},{"location":"aulas/IA/lab09/transferlearning.html#desafio-2","title":"Desafio 2\u00b6","text":"<p>Vamos entender o que acabamos de fazer. Avalie a quantidade de parametros total, treinaveis e n\u00e3o treinaveis. O que foi identificado?</p>"},{"location":"aulas/IA/lab09/transferlearning.html#sua-resposta-aqui","title":"sua resposta aqui.....\u00b6","text":"<p>.</p>"},{"location":"aulas/IA/lab09/transferlearning.html#treinamento-do-modelo","title":"Treinamento do modelo\u00b6","text":""},{"location":"aulas/IA/lab09/transferlearning.html#fazendo-predicoes","title":"Fazendo predi\u00e7\u00f5es\u00b6","text":""},{"location":"aulas/IA/lab09/transferlearning.html#salvando-o-modelo-da-rede-treinada","title":"Salvando o modelo da rede treinada\u00b6","text":"<p>Agora que j\u00e1 temos um modelo treinado e ajustado para resolver o problema especifico que temos, podemos salver a arquitetura e os pesos em um arquivo com extens\u00e3o .h5</p> <p>para usar esta rede, basta carregar o arquivo.h5</p>"},{"location":"aulas/IA/lab09/transferlearning.html#desafio-3","title":"Desafio 3\u00b6","text":"<p>Aplicar o Transfer Learning usando a rede pr\u00e9-treinada ResNet50 e o conjunto de dados CIFAR-10, que possui 10 classes de objetos.</p>"},{"location":"aulas/IA/lab09/transferlearning_1.html","title":"Lab9 - Redes Neurais - Pr\u00e9-treinadas","text":"In\u00a0[3]: Copied! <pre>import numpy as np\nfrom tensorflow.keras.preprocessing import image\n\n\n## importa o modelo da VGG16 pr\u00e9-treinado\nfrom tensorflow.keras.applications.vgg16 import VGG16, preprocess_input, decode_predictions\n</pre> import numpy as np from tensorflow.keras.preprocessing import image   ## importa o modelo da VGG16 pr\u00e9-treinado from tensorflow.keras.applications.vgg16 import VGG16, preprocess_input, decode_predictions   <pre>/Users/arnaldoalvesvianajunior/Library/Python/3.9/lib/python/site-packages/urllib3/__init__.py:34: NotOpenSSLWarning: urllib3 v2.0 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n  warnings.warn(\n</pre> In\u00a0[13]: Copied! <pre># Carrega o modelo VGG16 pr\u00e9-treinado com ImageNet:\nmodel = VGG16()\n</pre> # Carrega o modelo VGG16 pr\u00e9-treinado com ImageNet: model = VGG16()  <pre>Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels.h5\n553467096/553467096 \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 75s 0us/step\n</pre> In\u00a0[15]: Copied! <pre>import matplotlib.pyplot as plt\n\n# Fun\u00e7\u00e3o para visualizar imagem\ndef display_image(img_path):\n    img = image.load_img(img_path)\n    plt.imshow(img)\n    plt.axis('off')\n    plt.show()\n</pre> import matplotlib.pyplot as plt  # Fun\u00e7\u00e3o para visualizar imagem def display_image(img_path):     img = image.load_img(img_path)     plt.imshow(img)     plt.axis('off')     plt.show() In\u00a0[16]: Copied! <pre># Carrega uma imagem e prepara para ser predita pela VGG16\n\n## teste 1\n# !wget https://images.tcdn.com.br/img/img_prod/777105/bicicleta_29_hope_21_velocidades_shimano_freios_disco_tamanho_17_12475_1_ac0b7c63eee851b87bcc9832033c9826.jpg -O /content/bike.jpg\n# img_path = 'bike.jpg'\n\n# teste 2\n#!wget https://liberal.com.br/wp-content/uploads/2019/11/buraco-rua-dos-anturios.jpg -O /content/buraco.jpg\n#img_path = 'buraco.jpg'\n\n# teste 3\n#img_path = 'COLOQUE_UMA_IMAGEM.jpg'\n\n# se estiver rodando localmente, descomente a linha abaixo\n#img_path = 'COLOQUE_UMA_IMAGEM.jpg'\nimg_path = 'bicicleta.png'\n\n\n\nimg = image.load_img(img_path, target_size=(224, 224))\nx = image.img_to_array(img)\nx = np.expand_dims(x, axis=0)\nx = preprocess_input(x)\nprint(\"A imagem \u00e9 carregada e transformada de {}, para {}\".format(img.size,x.shape))\ndisplay_image(img_path)\n</pre> # Carrega uma imagem e prepara para ser predita pela VGG16  ## teste 1 # !wget https://images.tcdn.com.br/img/img_prod/777105/bicicleta_29_hope_21_velocidades_shimano_freios_disco_tamanho_17_12475_1_ac0b7c63eee851b87bcc9832033c9826.jpg -O /content/bike.jpg # img_path = 'bike.jpg'  # teste 2 #!wget https://liberal.com.br/wp-content/uploads/2019/11/buraco-rua-dos-anturios.jpg -O /content/buraco.jpg #img_path = 'buraco.jpg'  # teste 3 #img_path = 'COLOQUE_UMA_IMAGEM.jpg'  # se estiver rodando localmente, descomente a linha abaixo #img_path = 'COLOQUE_UMA_IMAGEM.jpg' img_path = 'bicicleta.png'    img = image.load_img(img_path, target_size=(224, 224)) x = image.img_to_array(img) x = np.expand_dims(x, axis=0) x = preprocess_input(x) print(\"A imagem \u00e9 carregada e transformada de {}, para {}\".format(img.size,x.shape)) display_image(img_path) <pre>A imagem \u00e9 carregada e transformada de (224, 224), para (1, 224, 224, 3)\n</pre> In\u00a0[17]: Copied! <pre>## faz a predi\u00e7\u00e3o da imagem\n\npreds = model.predict(x)\n</pre> ## faz a predi\u00e7\u00e3o da imagem  preds = model.predict(x)  <pre>1/1 \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 0s 327ms/step\n</pre> In\u00a0[18]: Copied! <pre>decoded_preds = decode_predictions(preds)[0]\n\nfor i, (imagenet_id, label, score) in enumerate(decoded_preds):\n    print(f\"{i+1}. {label}: {score * 100:.2f}%\")\n</pre> decoded_preds = decode_predictions(preds)[0]  for i, (imagenet_id, label, score) in enumerate(decoded_preds):     print(f\"{i+1}. {label}: {score * 100:.2f}%\")  <pre>Downloading data from https://storage.googleapis.com/download.tensorflow.org/data/imagenet_class_index.json\n35363/35363 \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 0s 1us/step\n1. mountain_bike: 82.86%\n2. alp: 3.89%\n3. crash_helmet: 1.95%\n4. bicycle-built-for-two: 1.51%\n5. tricycle: 1.51%\n</pre> In\u00a0[21]: Copied! <pre>from tensorflow.keras.applications.resnet50 import ResNet50, preprocess_input, decode_predictions\n\nmodel = ResNet50(weights='imagenet')\n\n\n#### seu c\u00f3digo aqui....\n</pre> from tensorflow.keras.applications.resnet50 import ResNet50, preprocess_input, decode_predictions  model = ResNet50(weights='imagenet')   #### seu c\u00f3digo aqui....     <pre>Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels.h5\n102967424/102967424 [==============================] - 5s 0us/step\n</pre>"},{"location":"aulas/IA/lab09/transferlearning_1.html#2-redes-neurais","title":"2. Redes Neurais\u00b6","text":""},{"location":"aulas/IA/lab09/transferlearning_1.html#objetivos","title":"Objetivos\u00b6","text":"<ul> <li>Conhecer e praticar Arquiteturas complexas de Redes Neurais Convolucionais</li> </ul>"},{"location":"aulas/IA/lab09/transferlearning_1.html#arquitetura-de-redes-neurais-convolucionais","title":"Arquitetura de Redes Neurais Convolucionais\u00b6","text":"<p>Existem diversas arquitetura de CNN, cada rede com suas pr\u00f3prias caracter\u00edsticas, principalmente para vis\u00e3o computacional. Mas todas ter\u00e3o em comum camadas de convolu\u00e7\u00e3o e maxpooling, dropout e algumas coisas a mais...</p>"},{"location":"aulas/IA/lab09/transferlearning_1.html#por-que-utilizar-uma-arquitetura-cnn","title":"Por que utilizar uma arquitetura CNN\u00b6","text":"<p>Utilizar uma arquitetura de CNN possibilita reduzir o tempo de pesquisa com o desenvolvimento de novas arquiteturas uma vez que essas arquiteturas j\u00e1 foram sistematicamente revisadas.</p>"},{"location":"aulas/IA/lab09/transferlearning_1.html#exemplos-de-arquiteturas","title":"Exemplos de arquiteturas:\u00b6","text":"<p><code>LeNET</code>: Desenvolvida em 1998 por Yann LeCun, a LeNet foi pioneira no uso de camadas de convolu\u00e7\u00e3o com filtros 5x5 e passo 1, al\u00e9m de camadas de agrupamento com filtros 2x2 e passo 2, intercaladas por camadas totalmente conectadas (FC). A ordem das camadas \u00e9: CONV-POOL-CONV-POOL-FC-FC. Essa arquitetura teve um papel fundamental no reconhecimento de d\u00edgitos manuscritos.</p> <p></p> <p><code>AlexNET</code>: Criada em 2012 por Alex Krizhevsky, Ilya Sutskever e Geoffrey Hinton, a AlexNet \u00e9 uma arquitetura mais avan\u00e7ada que a LeNet. Possui cinco camadas convolucionais seguidas de tr\u00eas camadas FC, e emprega a fun\u00e7\u00e3o de ativa\u00e7\u00e3o ReLU. Vencedora da competi\u00e7\u00e3o ImageNet de 2012, marcou o in\u00edcio da populariza\u00e7\u00e3o das redes neurais convolucionais profundas.</p> <p></p> <p><code>VGG</code>: A arquitetura VGG, concebida em 2014 pelo Visual Geometry Group da Universidade de Oxford, prop\u00f4s o uso de filtros menores (3x3) em redes mais profundas, com no m\u00ednimo 16 camadas convolucionais e maxpooling com filtros 2x2. Apesar de os filtros menores gerarem menos par\u00e2metros, as camadas FC e as convolu\u00e7\u00f5es iniciais demandavam grande quantidade de mem\u00f3ria RAM, resultando em uma rede pesada.</p> <p></p> <p><code>GoogleNET</code>: Paralelamente \u00e0 VGG, em 2014, pesquisadores do Google desenvolveram a GoogleNet, que introduziu o m\u00f3dulo Inception como elemento fundamental. Com nove m\u00f3dulos Inception em sequ\u00eancia, a arquitetura utiliza convolu\u00e7\u00f5es 3x3 e 5x5 precedidas por convolu\u00e7\u00f5es 1x1 para diminuir o custo computacional. A GoogleNet foi projetada para ser eficiente em termos de recursos e venceu a competi\u00e7\u00e3o ImageNet de 2014.</p> <p></p> <p><code>ResNET</code>: A rede residual, proposta em 2015 por Kaiming He e colaboradores, tem como caracter\u00edstica principal a inclus\u00e3o de conex\u00f5es residuais (curto-circuitos) a cada duas convolu\u00e7\u00f5es, adicionando um resultado anterior ao resultado futuro. Isso permite treinar redes mais profundas sem problemas de degrada\u00e7\u00e3o do desempenho. ResNets com 50, 101 e 152 camadas utilizam blocos residuais com \"bottleneck\", que consistem em duas convolu\u00e7\u00f5es 3x3 intercaladas por convolu\u00e7\u00f5es 1x1, diminuindo o custo computacional.</p> <p></p> <p><code>MobileNet</code>: Proposta em 2017, \u00e9 uma arquitetura otimizada para dispositivos m\u00f3veis e aplicativos com limita\u00e7\u00f5es de recursos computacionais. Utiliza convolu\u00e7\u00f5es separ\u00e1veis por profundidade para reduzir o n\u00famero de par\u00e2metros e o consumo de mem\u00f3ria.</p> <p><code>EfficientNet</code>: Proposta em 2019, \u00e9 uma fam\u00edlia de redes neurais convolucionais que busca melhorar a efici\u00eancia em termos de recursos computacionais e desempenho, atrav\u00e9s do ajuste coordenado da largura, profundidade e resolu\u00e7\u00e3o das redes.</p> <p><code>InceptionV3</code>: Uma evolu\u00e7\u00e3o do GoogleNet, a InceptionV3 \u00e9 uma arquitetura desenvolvida em 2015 que aprimora o m\u00f3dulo Inception e implementa t\u00e9cnicas de normaliza\u00e7\u00e3o em lotes. Essa arquitetura alcan\u00e7a um desempenho superior com menos par\u00e2metros e menor custo computacional.</p> <p><code>DenseNet</code>: Proposta em 2016, a DenseNet \u00e9 uma arquitetura que introduz conex\u00f5es densas entre as camadas. Cada camada recebe as caracter\u00edsticas de todas as camadas anteriores, o que melhora o fluxo de informa\u00e7\u00f5es e gradientes durante o treinamento. Isso permite a constru\u00e7\u00e3o de redes mais profundas e eficientes.</p> <p><code>YOLO</code> (You Only Look Once): \u00c9 uma arquitetura de rede neural focada em detec\u00e7\u00e3o de objetos em tempo real. Proposta em 2016, a YOLO divide a imagem em regi\u00f5es e prev\u00ea, de uma s\u00f3 vez, as probabilidades de classes e as coordenadas das caixas delimitadoras. A YOLO \u00e9 conhecida por sua velocidade e capacidade de detectar objetos em tempo real.</p> <p><code>Transformer</code>: Embora n\u00e3o seja uma arquitetura de rede neural convolucional, o Transformer, proposto em 2017, \u00e9 uma arquitetura de rede neural not\u00e1vel para processamento de linguagem natural e outras tarefas sequenciais. O Transformer introduziu o conceito de aten\u00e7\u00e3o auto-regressiva, que permite que a rede aprenda relacionamentos complexos entre as entradas, e tem sido a base para modelos de linguagem de \u00faltima gera\u00e7\u00e3o, como BERT e GPT.</p> <p>Parace que s\u00e3o muitas, mas essas s\u00e3o apenas algumas arquiteturas de redes neurais desenvolvidas nos \u00faltimos anos. Dependendo da aplica\u00e7\u00e3o e das restri\u00e7\u00f5es de recursos, voc\u00ea pode encontrar uma arquitetura adequada \u00e0s suas necessidades espec\u00edficas.</p>"},{"location":"aulas/IA/lab09/transferlearning_1.html#modelos-de-cnn-pre-treinados","title":"Modelos de CNN pr\u00e9-treinados\u00b6","text":"<p>O treinamento de uma boa CNN n\u00e3o \u00e9 simples, al\u00e9m de muitos dados (milhares de imagens) e muito tempo de processamento.</p> <p>Mas usar essas redes \u00e9 super super facil!!</p> <p>Vamos usar o VGG16 para fazer a classifica\u00e7\u00e3o de uma imagem.</p> <p>Recomendo dar uma olhada na documenta\u00e7\u00e3o oficial do Keras:  https://keras.io/api/applications/</p>"},{"location":"aulas/IA/lab09/transferlearning_1.html#desafio-1","title":"Desafio 1\u00b6","text":"<p>Agora avalie outras arquiteturas de redes neurais dispon\u00edveis no Keras, como ResNet50, InceptionV3, MobileNet e EfficientNet.</p> <p>Basta substituir a importa\u00e7\u00e3o e a fun\u00e7\u00e3o de carregamento do modelo conforme necess\u00e1rio. Por exemplo, para usar a ResNet50:</p>"},{"location":"aulas/IA/lab09/transferlearning_2.html","title":"Lab9 - Redes Neurais - Transfer learning","text":"In\u00a0[4]: Copied! <pre>import os\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport tensorflow as tf\nfrom tensorflow.keras import layers, models\nfrom tensorflow.keras.applications.mobilenet_v2 import MobileNetV2, preprocess_input\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\n\n# Configura\u00e7\u00e3o dos diret\u00f3rios e par\u00e2metros do conjunto de dados\n_URL = 'https://storage.googleapis.com/mledu-datasets/cats_and_dogs_filtered.zip'\npath_to_zip = tf.keras.utils.get_file('cats_and_dogs.zip', origin=_URL, extract=True)\nPATH = os.path.join(os.path.dirname(path_to_zip), 'cats_and_dogs_filtered')\n\ntrain_dir = os.path.join(PATH, 'train')\nvalidation_dir = os.path.join(PATH, 'validation')\n\nbatch_size = 32\nimage_size = (224, 224)\n</pre> import os import numpy as np import matplotlib.pyplot as plt import tensorflow as tf from tensorflow.keras import layers, models from tensorflow.keras.applications.mobilenet_v2 import MobileNetV2, preprocess_input from tensorflow.keras.preprocessing.image import ImageDataGenerator  # Configura\u00e7\u00e3o dos diret\u00f3rios e par\u00e2metros do conjunto de dados _URL = 'https://storage.googleapis.com/mledu-datasets/cats_and_dogs_filtered.zip' path_to_zip = tf.keras.utils.get_file('cats_and_dogs.zip', origin=_URL, extract=True) PATH = os.path.join(os.path.dirname(path_to_zip), 'cats_and_dogs_filtered')  train_dir = os.path.join(PATH, 'train') validation_dir = os.path.join(PATH, 'validation')  batch_size = 32 image_size = (224, 224)  In\u00a0[5]: Copied! <pre># Fun\u00e7\u00e3o para exibir algumas imagens do conjunto de dados\ndef plot_images(images, labels, class_names):\n    plt.figure(figsize=(10, 10))\n    for i, (img, label) in enumerate(zip(images, labels)):\n        plt.subplot(3, 3, i + 1)\n        plt.imshow(img)\n        plt.title(class_names[label])\n        plt.axis(\"off\")\n    plt.show()\n\n# Carregar imagens e r\u00f3tulos do conjunto de dados de treinamento\ntrain_datagen = ImageDataGenerator(preprocessing_function=preprocess_input)\nvalidation_datagen = ImageDataGenerator(preprocessing_function=preprocess_input)\n\ntrain_generator = train_datagen.flow_from_directory(\n    train_dir,\n    target_size=image_size,\n    batch_size=batch_size,\n    class_mode='binary'\n)\n\n# Carregar imagens e r\u00f3tulos do conjunto de dados de valida\u00e7\u00e3o\nvalidation_generator = validation_datagen.flow_from_directory(\n    validation_dir,\n    target_size=image_size,\n    batch_size=batch_size,\n    class_mode='binary'\n)\n\n# Carregar algumas imagens e r\u00f3tulos do conjunto de dados de treinamento\nsample_datagen = ImageDataGenerator(rescale=1./255)\nsample_generator = sample_datagen.flow_from_directory(\n    train_dir,\n    target_size=image_size,\n    batch_size=9,\n    class_mode='binary'\n)\n\nsample_images, sample_labels = next(sample_generator)\nclass_names = {v: k for k, v in sample_generator.class_indices.items()}\nplot_images(sample_images, sample_labels, class_names)\n</pre> # Fun\u00e7\u00e3o para exibir algumas imagens do conjunto de dados def plot_images(images, labels, class_names):     plt.figure(figsize=(10, 10))     for i, (img, label) in enumerate(zip(images, labels)):         plt.subplot(3, 3, i + 1)         plt.imshow(img)         plt.title(class_names[label])         plt.axis(\"off\")     plt.show()  # Carregar imagens e r\u00f3tulos do conjunto de dados de treinamento train_datagen = ImageDataGenerator(preprocessing_function=preprocess_input) validation_datagen = ImageDataGenerator(preprocessing_function=preprocess_input)  train_generator = train_datagen.flow_from_directory(     train_dir,     target_size=image_size,     batch_size=batch_size,     class_mode='binary' )  # Carregar imagens e r\u00f3tulos do conjunto de dados de valida\u00e7\u00e3o validation_generator = validation_datagen.flow_from_directory(     validation_dir,     target_size=image_size,     batch_size=batch_size,     class_mode='binary' )  # Carregar algumas imagens e r\u00f3tulos do conjunto de dados de treinamento sample_datagen = ImageDataGenerator(rescale=1./255) sample_generator = sample_datagen.flow_from_directory(     train_dir,     target_size=image_size,     batch_size=9,     class_mode='binary' )  sample_images, sample_labels = next(sample_generator) class_names = {v: k for k, v in sample_generator.class_indices.items()} plot_images(sample_images, sample_labels, class_names) <pre>Found 2000 images belonging to 2 classes.\nFound 1000 images belonging to 2 classes.\nFound 2000 images belonging to 2 classes.\n</pre> In\u00a0[6]: Copied! <pre># Cria o base_model referente a MobileNet V2, sem a camada de classifica\u00e7\u00e3o\nbase_model = MobileNetV2(input_shape=(224, 224, 3),\n                        include_top=False,\n                        weights='imagenet')\n</pre> # Cria o base_model referente a MobileNet V2, sem a camada de classifica\u00e7\u00e3o base_model = MobileNetV2(input_shape=(224, 224, 3),                         include_top=False,                         weights='imagenet') <pre>Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet_v2/mobilenet_v2_weights_tf_dim_ordering_tf_kernels_1.0_224_no_top.h5\n9406464/9406464 \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 2s 0us/step\n</pre> In\u00a0[\u00a0]: Copied! <pre>base_model.summary()\n</pre> base_model.summary() In\u00a0[7]: Copied! <pre>#Congela a base_model para n\u00e3o atuaizar os pesos quando treinar.\n\nbase_model.trainable = False\n</pre> #Congela a base_model para n\u00e3o atuaizar os pesos quando treinar.  base_model.trainable = False In\u00a0[8]: Copied! <pre>base_model.summary()\n</pre> base_model.summary() <pre>Model: \"mobilenetv2_1.00_224\"\n</pre> <pre>\u250f\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2513\n\u2503 Layer (type)        \u2503 Output Shape      \u2503    Param # \u2503 Connected to      \u2503\n\u2521\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2529\n\u2502 input_layer         \u2502 (None, 224, 224,  \u2502          0 \u2502 -                 \u2502\n\u2502 (InputLayer)        \u2502 3)                \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 Conv1 (Conv2D)      \u2502 (None, 112, 112,  \u2502        864 \u2502 input_layer[0][0] \u2502\n\u2502                     \u2502 32)               \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 bn_Conv1            \u2502 (None, 112, 112,  \u2502        128 \u2502 Conv1[0][0]       \u2502\n\u2502 (BatchNormalizatio\u2026 \u2502 32)               \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 Conv1_relu (ReLU)   \u2502 (None, 112, 112,  \u2502          0 \u2502 bn_Conv1[0][0]    \u2502\n\u2502                     \u2502 32)               \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 expanded_conv_dept\u2026 \u2502 (None, 112, 112,  \u2502        288 \u2502 Conv1_relu[0][0]  \u2502\n\u2502 (DepthwiseConv2D)   \u2502 32)               \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 expanded_conv_dept\u2026 \u2502 (None, 112, 112,  \u2502        128 \u2502 expanded_conv_de\u2026 \u2502\n\u2502 (BatchNormalizatio\u2026 \u2502 32)               \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 expanded_conv_dept\u2026 \u2502 (None, 112, 112,  \u2502          0 \u2502 expanded_conv_de\u2026 \u2502\n\u2502 (ReLU)              \u2502 32)               \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 expanded_conv_proj\u2026 \u2502 (None, 112, 112,  \u2502        512 \u2502 expanded_conv_de\u2026 \u2502\n\u2502 (Conv2D)            \u2502 16)               \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 expanded_conv_proj\u2026 \u2502 (None, 112, 112,  \u2502         64 \u2502 expanded_conv_pr\u2026 \u2502\n\u2502 (BatchNormalizatio\u2026 \u2502 16)               \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_1_expand      \u2502 (None, 112, 112,  \u2502      1,536 \u2502 expanded_conv_pr\u2026 \u2502\n\u2502 (Conv2D)            \u2502 96)               \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_1_expand_BN   \u2502 (None, 112, 112,  \u2502        384 \u2502 block_1_expand[0\u2026 \u2502\n\u2502 (BatchNormalizatio\u2026 \u2502 96)               \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_1_expand_relu \u2502 (None, 112, 112,  \u2502          0 \u2502 block_1_expand_B\u2026 \u2502\n\u2502 (ReLU)              \u2502 96)               \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_1_pad         \u2502 (None, 113, 113,  \u2502          0 \u2502 block_1_expand_r\u2026 \u2502\n\u2502 (ZeroPadding2D)     \u2502 96)               \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_1_depthwise   \u2502 (None, 56, 56,    \u2502        864 \u2502 block_1_pad[0][0] \u2502\n\u2502 (DepthwiseConv2D)   \u2502 96)               \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_1_depthwise_\u2026 \u2502 (None, 56, 56,    \u2502        384 \u2502 block_1_depthwis\u2026 \u2502\n\u2502 (BatchNormalizatio\u2026 \u2502 96)               \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_1_depthwise_\u2026 \u2502 (None, 56, 56,    \u2502          0 \u2502 block_1_depthwis\u2026 \u2502\n\u2502 (ReLU)              \u2502 96)               \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_1_project     \u2502 (None, 56, 56,    \u2502      2,304 \u2502 block_1_depthwis\u2026 \u2502\n\u2502 (Conv2D)            \u2502 24)               \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_1_project_BN  \u2502 (None, 56, 56,    \u2502         96 \u2502 block_1_project[\u2026 \u2502\n\u2502 (BatchNormalizatio\u2026 \u2502 24)               \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_2_expand      \u2502 (None, 56, 56,    \u2502      3,456 \u2502 block_1_project_\u2026 \u2502\n\u2502 (Conv2D)            \u2502 144)              \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_2_expand_BN   \u2502 (None, 56, 56,    \u2502        576 \u2502 block_2_expand[0\u2026 \u2502\n\u2502 (BatchNormalizatio\u2026 \u2502 144)              \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_2_expand_relu \u2502 (None, 56, 56,    \u2502          0 \u2502 block_2_expand_B\u2026 \u2502\n\u2502 (ReLU)              \u2502 144)              \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_2_depthwise   \u2502 (None, 56, 56,    \u2502      1,296 \u2502 block_2_expand_r\u2026 \u2502\n\u2502 (DepthwiseConv2D)   \u2502 144)              \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_2_depthwise_\u2026 \u2502 (None, 56, 56,    \u2502        576 \u2502 block_2_depthwis\u2026 \u2502\n\u2502 (BatchNormalizatio\u2026 \u2502 144)              \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_2_depthwise_\u2026 \u2502 (None, 56, 56,    \u2502          0 \u2502 block_2_depthwis\u2026 \u2502\n\u2502 (ReLU)              \u2502 144)              \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_2_project     \u2502 (None, 56, 56,    \u2502      3,456 \u2502 block_2_depthwis\u2026 \u2502\n\u2502 (Conv2D)            \u2502 24)               \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_2_project_BN  \u2502 (None, 56, 56,    \u2502         96 \u2502 block_2_project[\u2026 \u2502\n\u2502 (BatchNormalizatio\u2026 \u2502 24)               \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_2_add (Add)   \u2502 (None, 56, 56,    \u2502          0 \u2502 block_1_project_\u2026 \u2502\n\u2502                     \u2502 24)               \u2502            \u2502 block_2_project_\u2026 \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_3_expand      \u2502 (None, 56, 56,    \u2502      3,456 \u2502 block_2_add[0][0] \u2502\n\u2502 (Conv2D)            \u2502 144)              \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_3_expand_BN   \u2502 (None, 56, 56,    \u2502        576 \u2502 block_3_expand[0\u2026 \u2502\n\u2502 (BatchNormalizatio\u2026 \u2502 144)              \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_3_expand_relu \u2502 (None, 56, 56,    \u2502          0 \u2502 block_3_expand_B\u2026 \u2502\n\u2502 (ReLU)              \u2502 144)              \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_3_pad         \u2502 (None, 57, 57,    \u2502          0 \u2502 block_3_expand_r\u2026 \u2502\n\u2502 (ZeroPadding2D)     \u2502 144)              \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_3_depthwise   \u2502 (None, 28, 28,    \u2502      1,296 \u2502 block_3_pad[0][0] \u2502\n\u2502 (DepthwiseConv2D)   \u2502 144)              \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_3_depthwise_\u2026 \u2502 (None, 28, 28,    \u2502        576 \u2502 block_3_depthwis\u2026 \u2502\n\u2502 (BatchNormalizatio\u2026 \u2502 144)              \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_3_depthwise_\u2026 \u2502 (None, 28, 28,    \u2502          0 \u2502 block_3_depthwis\u2026 \u2502\n\u2502 (ReLU)              \u2502 144)              \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_3_project     \u2502 (None, 28, 28,    \u2502      4,608 \u2502 block_3_depthwis\u2026 \u2502\n\u2502 (Conv2D)            \u2502 32)               \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_3_project_BN  \u2502 (None, 28, 28,    \u2502        128 \u2502 block_3_project[\u2026 \u2502\n\u2502 (BatchNormalizatio\u2026 \u2502 32)               \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_4_expand      \u2502 (None, 28, 28,    \u2502      6,144 \u2502 block_3_project_\u2026 \u2502\n\u2502 (Conv2D)            \u2502 192)              \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_4_expand_BN   \u2502 (None, 28, 28,    \u2502        768 \u2502 block_4_expand[0\u2026 \u2502\n\u2502 (BatchNormalizatio\u2026 \u2502 192)              \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_4_expand_relu \u2502 (None, 28, 28,    \u2502          0 \u2502 block_4_expand_B\u2026 \u2502\n\u2502 (ReLU)              \u2502 192)              \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_4_depthwise   \u2502 (None, 28, 28,    \u2502      1,728 \u2502 block_4_expand_r\u2026 \u2502\n\u2502 (DepthwiseConv2D)   \u2502 192)              \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_4_depthwise_\u2026 \u2502 (None, 28, 28,    \u2502        768 \u2502 block_4_depthwis\u2026 \u2502\n\u2502 (BatchNormalizatio\u2026 \u2502 192)              \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_4_depthwise_\u2026 \u2502 (None, 28, 28,    \u2502          0 \u2502 block_4_depthwis\u2026 \u2502\n\u2502 (ReLU)              \u2502 192)              \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_4_project     \u2502 (None, 28, 28,    \u2502      6,144 \u2502 block_4_depthwis\u2026 \u2502\n\u2502 (Conv2D)            \u2502 32)               \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_4_project_BN  \u2502 (None, 28, 28,    \u2502        128 \u2502 block_4_project[\u2026 \u2502\n\u2502 (BatchNormalizatio\u2026 \u2502 32)               \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_4_add (Add)   \u2502 (None, 28, 28,    \u2502          0 \u2502 block_3_project_\u2026 \u2502\n\u2502                     \u2502 32)               \u2502            \u2502 block_4_project_\u2026 \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_5_expand      \u2502 (None, 28, 28,    \u2502      6,144 \u2502 block_4_add[0][0] \u2502\n\u2502 (Conv2D)            \u2502 192)              \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_5_expand_BN   \u2502 (None, 28, 28,    \u2502        768 \u2502 block_5_expand[0\u2026 \u2502\n\u2502 (BatchNormalizatio\u2026 \u2502 192)              \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_5_expand_relu \u2502 (None, 28, 28,    \u2502          0 \u2502 block_5_expand_B\u2026 \u2502\n\u2502 (ReLU)              \u2502 192)              \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_5_depthwise   \u2502 (None, 28, 28,    \u2502      1,728 \u2502 block_5_expand_r\u2026 \u2502\n\u2502 (DepthwiseConv2D)   \u2502 192)              \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_5_depthwise_\u2026 \u2502 (None, 28, 28,    \u2502        768 \u2502 block_5_depthwis\u2026 \u2502\n\u2502 (BatchNormalizatio\u2026 \u2502 192)              \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_5_depthwise_\u2026 \u2502 (None, 28, 28,    \u2502          0 \u2502 block_5_depthwis\u2026 \u2502\n\u2502 (ReLU)              \u2502 192)              \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_5_project     \u2502 (None, 28, 28,    \u2502      6,144 \u2502 block_5_depthwis\u2026 \u2502\n\u2502 (Conv2D)            \u2502 32)               \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_5_project_BN  \u2502 (None, 28, 28,    \u2502        128 \u2502 block_5_project[\u2026 \u2502\n\u2502 (BatchNormalizatio\u2026 \u2502 32)               \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_5_add (Add)   \u2502 (None, 28, 28,    \u2502          0 \u2502 block_4_add[0][0\u2026 \u2502\n\u2502                     \u2502 32)               \u2502            \u2502 block_5_project_\u2026 \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_6_expand      \u2502 (None, 28, 28,    \u2502      6,144 \u2502 block_5_add[0][0] \u2502\n\u2502 (Conv2D)            \u2502 192)              \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_6_expand_BN   \u2502 (None, 28, 28,    \u2502        768 \u2502 block_6_expand[0\u2026 \u2502\n\u2502 (BatchNormalizatio\u2026 \u2502 192)              \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_6_expand_relu \u2502 (None, 28, 28,    \u2502          0 \u2502 block_6_expand_B\u2026 \u2502\n\u2502 (ReLU)              \u2502 192)              \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_6_pad         \u2502 (None, 29, 29,    \u2502          0 \u2502 block_6_expand_r\u2026 \u2502\n\u2502 (ZeroPadding2D)     \u2502 192)              \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_6_depthwise   \u2502 (None, 14, 14,    \u2502      1,728 \u2502 block_6_pad[0][0] \u2502\n\u2502 (DepthwiseConv2D)   \u2502 192)              \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_6_depthwise_\u2026 \u2502 (None, 14, 14,    \u2502        768 \u2502 block_6_depthwis\u2026 \u2502\n\u2502 (BatchNormalizatio\u2026 \u2502 192)              \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_6_depthwise_\u2026 \u2502 (None, 14, 14,    \u2502          0 \u2502 block_6_depthwis\u2026 \u2502\n\u2502 (ReLU)              \u2502 192)              \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_6_project     \u2502 (None, 14, 14,    \u2502     12,288 \u2502 block_6_depthwis\u2026 \u2502\n\u2502 (Conv2D)            \u2502 64)               \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_6_project_BN  \u2502 (None, 14, 14,    \u2502        256 \u2502 block_6_project[\u2026 \u2502\n\u2502 (BatchNormalizatio\u2026 \u2502 64)               \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_7_expand      \u2502 (None, 14, 14,    \u2502     24,576 \u2502 block_6_project_\u2026 \u2502\n\u2502 (Conv2D)            \u2502 384)              \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_7_expand_BN   \u2502 (None, 14, 14,    \u2502      1,536 \u2502 block_7_expand[0\u2026 \u2502\n\u2502 (BatchNormalizatio\u2026 \u2502 384)              \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_7_expand_relu \u2502 (None, 14, 14,    \u2502          0 \u2502 block_7_expand_B\u2026 \u2502\n\u2502 (ReLU)              \u2502 384)              \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_7_depthwise   \u2502 (None, 14, 14,    \u2502      3,456 \u2502 block_7_expand_r\u2026 \u2502\n\u2502 (DepthwiseConv2D)   \u2502 384)              \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_7_depthwise_\u2026 \u2502 (None, 14, 14,    \u2502      1,536 \u2502 block_7_depthwis\u2026 \u2502\n\u2502 (BatchNormalizatio\u2026 \u2502 384)              \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_7_depthwise_\u2026 \u2502 (None, 14, 14,    \u2502          0 \u2502 block_7_depthwis\u2026 \u2502\n\u2502 (ReLU)              \u2502 384)              \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_7_project     \u2502 (None, 14, 14,    \u2502     24,576 \u2502 block_7_depthwis\u2026 \u2502\n\u2502 (Conv2D)            \u2502 64)               \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_7_project_BN  \u2502 (None, 14, 14,    \u2502        256 \u2502 block_7_project[\u2026 \u2502\n\u2502 (BatchNormalizatio\u2026 \u2502 64)               \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_7_add (Add)   \u2502 (None, 14, 14,    \u2502          0 \u2502 block_6_project_\u2026 \u2502\n\u2502                     \u2502 64)               \u2502            \u2502 block_7_project_\u2026 \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_8_expand      \u2502 (None, 14, 14,    \u2502     24,576 \u2502 block_7_add[0][0] \u2502\n\u2502 (Conv2D)            \u2502 384)              \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_8_expand_BN   \u2502 (None, 14, 14,    \u2502      1,536 \u2502 block_8_expand[0\u2026 \u2502\n\u2502 (BatchNormalizatio\u2026 \u2502 384)              \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_8_expand_relu \u2502 (None, 14, 14,    \u2502          0 \u2502 block_8_expand_B\u2026 \u2502\n\u2502 (ReLU)              \u2502 384)              \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_8_depthwise   \u2502 (None, 14, 14,    \u2502      3,456 \u2502 block_8_expand_r\u2026 \u2502\n\u2502 (DepthwiseConv2D)   \u2502 384)              \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_8_depthwise_\u2026 \u2502 (None, 14, 14,    \u2502      1,536 \u2502 block_8_depthwis\u2026 \u2502\n\u2502 (BatchNormalizatio\u2026 \u2502 384)              \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_8_depthwise_\u2026 \u2502 (None, 14, 14,    \u2502          0 \u2502 block_8_depthwis\u2026 \u2502\n\u2502 (ReLU)              \u2502 384)              \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_8_project     \u2502 (None, 14, 14,    \u2502     24,576 \u2502 block_8_depthwis\u2026 \u2502\n\u2502 (Conv2D)            \u2502 64)               \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_8_project_BN  \u2502 (None, 14, 14,    \u2502        256 \u2502 block_8_project[\u2026 \u2502\n\u2502 (BatchNormalizatio\u2026 \u2502 64)               \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_8_add (Add)   \u2502 (None, 14, 14,    \u2502          0 \u2502 block_7_add[0][0\u2026 \u2502\n\u2502                     \u2502 64)               \u2502            \u2502 block_8_project_\u2026 \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_9_expand      \u2502 (None, 14, 14,    \u2502     24,576 \u2502 block_8_add[0][0] \u2502\n\u2502 (Conv2D)            \u2502 384)              \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_9_expand_BN   \u2502 (None, 14, 14,    \u2502      1,536 \u2502 block_9_expand[0\u2026 \u2502\n\u2502 (BatchNormalizatio\u2026 \u2502 384)              \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_9_expand_relu \u2502 (None, 14, 14,    \u2502          0 \u2502 block_9_expand_B\u2026 \u2502\n\u2502 (ReLU)              \u2502 384)              \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_9_depthwise   \u2502 (None, 14, 14,    \u2502      3,456 \u2502 block_9_expand_r\u2026 \u2502\n\u2502 (DepthwiseConv2D)   \u2502 384)              \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_9_depthwise_\u2026 \u2502 (None, 14, 14,    \u2502      1,536 \u2502 block_9_depthwis\u2026 \u2502\n\u2502 (BatchNormalizatio\u2026 \u2502 384)              \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_9_depthwise_\u2026 \u2502 (None, 14, 14,    \u2502          0 \u2502 block_9_depthwis\u2026 \u2502\n\u2502 (ReLU)              \u2502 384)              \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_9_project     \u2502 (None, 14, 14,    \u2502     24,576 \u2502 block_9_depthwis\u2026 \u2502\n\u2502 (Conv2D)            \u2502 64)               \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_9_project_BN  \u2502 (None, 14, 14,    \u2502        256 \u2502 block_9_project[\u2026 \u2502\n\u2502 (BatchNormalizatio\u2026 \u2502 64)               \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_9_add (Add)   \u2502 (None, 14, 14,    \u2502          0 \u2502 block_8_add[0][0\u2026 \u2502\n\u2502                     \u2502 64)               \u2502            \u2502 block_9_project_\u2026 \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_10_expand     \u2502 (None, 14, 14,    \u2502     24,576 \u2502 block_9_add[0][0] \u2502\n\u2502 (Conv2D)            \u2502 384)              \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_10_expand_BN  \u2502 (None, 14, 14,    \u2502      1,536 \u2502 block_10_expand[\u2026 \u2502\n\u2502 (BatchNormalizatio\u2026 \u2502 384)              \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_10_expand_re\u2026 \u2502 (None, 14, 14,    \u2502          0 \u2502 block_10_expand_\u2026 \u2502\n\u2502 (ReLU)              \u2502 384)              \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_10_depthwise  \u2502 (None, 14, 14,    \u2502      3,456 \u2502 block_10_expand_\u2026 \u2502\n\u2502 (DepthwiseConv2D)   \u2502 384)              \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_10_depthwise\u2026 \u2502 (None, 14, 14,    \u2502      1,536 \u2502 block_10_depthwi\u2026 \u2502\n\u2502 (BatchNormalizatio\u2026 \u2502 384)              \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_10_depthwise\u2026 \u2502 (None, 14, 14,    \u2502          0 \u2502 block_10_depthwi\u2026 \u2502\n\u2502 (ReLU)              \u2502 384)              \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_10_project    \u2502 (None, 14, 14,    \u2502     36,864 \u2502 block_10_depthwi\u2026 \u2502\n\u2502 (Conv2D)            \u2502 96)               \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_10_project_BN \u2502 (None, 14, 14,    \u2502        384 \u2502 block_10_project\u2026 \u2502\n\u2502 (BatchNormalizatio\u2026 \u2502 96)               \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_11_expand     \u2502 (None, 14, 14,    \u2502     55,296 \u2502 block_10_project\u2026 \u2502\n\u2502 (Conv2D)            \u2502 576)              \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_11_expand_BN  \u2502 (None, 14, 14,    \u2502      2,304 \u2502 block_11_expand[\u2026 \u2502\n\u2502 (BatchNormalizatio\u2026 \u2502 576)              \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_11_expand_re\u2026 \u2502 (None, 14, 14,    \u2502          0 \u2502 block_11_expand_\u2026 \u2502\n\u2502 (ReLU)              \u2502 576)              \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_11_depthwise  \u2502 (None, 14, 14,    \u2502      5,184 \u2502 block_11_expand_\u2026 \u2502\n\u2502 (DepthwiseConv2D)   \u2502 576)              \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_11_depthwise\u2026 \u2502 (None, 14, 14,    \u2502      2,304 \u2502 block_11_depthwi\u2026 \u2502\n\u2502 (BatchNormalizatio\u2026 \u2502 576)              \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_11_depthwise\u2026 \u2502 (None, 14, 14,    \u2502          0 \u2502 block_11_depthwi\u2026 \u2502\n\u2502 (ReLU)              \u2502 576)              \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_11_project    \u2502 (None, 14, 14,    \u2502     55,296 \u2502 block_11_depthwi\u2026 \u2502\n\u2502 (Conv2D)            \u2502 96)               \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_11_project_BN \u2502 (None, 14, 14,    \u2502        384 \u2502 block_11_project\u2026 \u2502\n\u2502 (BatchNormalizatio\u2026 \u2502 96)               \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_11_add (Add)  \u2502 (None, 14, 14,    \u2502          0 \u2502 block_10_project\u2026 \u2502\n\u2502                     \u2502 96)               \u2502            \u2502 block_11_project\u2026 \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_12_expand     \u2502 (None, 14, 14,    \u2502     55,296 \u2502 block_11_add[0][\u2026 \u2502\n\u2502 (Conv2D)            \u2502 576)              \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_12_expand_BN  \u2502 (None, 14, 14,    \u2502      2,304 \u2502 block_12_expand[\u2026 \u2502\n\u2502 (BatchNormalizatio\u2026 \u2502 576)              \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_12_expand_re\u2026 \u2502 (None, 14, 14,    \u2502          0 \u2502 block_12_expand_\u2026 \u2502\n\u2502 (ReLU)              \u2502 576)              \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_12_depthwise  \u2502 (None, 14, 14,    \u2502      5,184 \u2502 block_12_expand_\u2026 \u2502\n\u2502 (DepthwiseConv2D)   \u2502 576)              \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_12_depthwise\u2026 \u2502 (None, 14, 14,    \u2502      2,304 \u2502 block_12_depthwi\u2026 \u2502\n\u2502 (BatchNormalizatio\u2026 \u2502 576)              \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_12_depthwise\u2026 \u2502 (None, 14, 14,    \u2502          0 \u2502 block_12_depthwi\u2026 \u2502\n\u2502 (ReLU)              \u2502 576)              \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_12_project    \u2502 (None, 14, 14,    \u2502     55,296 \u2502 block_12_depthwi\u2026 \u2502\n\u2502 (Conv2D)            \u2502 96)               \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_12_project_BN \u2502 (None, 14, 14,    \u2502        384 \u2502 block_12_project\u2026 \u2502\n\u2502 (BatchNormalizatio\u2026 \u2502 96)               \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_12_add (Add)  \u2502 (None, 14, 14,    \u2502          0 \u2502 block_11_add[0][\u2026 \u2502\n\u2502                     \u2502 96)               \u2502            \u2502 block_12_project\u2026 \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_13_expand     \u2502 (None, 14, 14,    \u2502     55,296 \u2502 block_12_add[0][\u2026 \u2502\n\u2502 (Conv2D)            \u2502 576)              \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_13_expand_BN  \u2502 (None, 14, 14,    \u2502      2,304 \u2502 block_13_expand[\u2026 \u2502\n\u2502 (BatchNormalizatio\u2026 \u2502 576)              \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_13_expand_re\u2026 \u2502 (None, 14, 14,    \u2502          0 \u2502 block_13_expand_\u2026 \u2502\n\u2502 (ReLU)              \u2502 576)              \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_13_pad        \u2502 (None, 15, 15,    \u2502          0 \u2502 block_13_expand_\u2026 \u2502\n\u2502 (ZeroPadding2D)     \u2502 576)              \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_13_depthwise  \u2502 (None, 7, 7, 576) \u2502      5,184 \u2502 block_13_pad[0][\u2026 \u2502\n\u2502 (DepthwiseConv2D)   \u2502                   \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_13_depthwise\u2026 \u2502 (None, 7, 7, 576) \u2502      2,304 \u2502 block_13_depthwi\u2026 \u2502\n\u2502 (BatchNormalizatio\u2026 \u2502                   \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_13_depthwise\u2026 \u2502 (None, 7, 7, 576) \u2502          0 \u2502 block_13_depthwi\u2026 \u2502\n\u2502 (ReLU)              \u2502                   \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_13_project    \u2502 (None, 7, 7, 160) \u2502     92,160 \u2502 block_13_depthwi\u2026 \u2502\n\u2502 (Conv2D)            \u2502                   \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_13_project_BN \u2502 (None, 7, 7, 160) \u2502        640 \u2502 block_13_project\u2026 \u2502\n\u2502 (BatchNormalizatio\u2026 \u2502                   \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_14_expand     \u2502 (None, 7, 7, 960) \u2502    153,600 \u2502 block_13_project\u2026 \u2502\n\u2502 (Conv2D)            \u2502                   \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_14_expand_BN  \u2502 (None, 7, 7, 960) \u2502      3,840 \u2502 block_14_expand[\u2026 \u2502\n\u2502 (BatchNormalizatio\u2026 \u2502                   \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_14_expand_re\u2026 \u2502 (None, 7, 7, 960) \u2502          0 \u2502 block_14_expand_\u2026 \u2502\n\u2502 (ReLU)              \u2502                   \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_14_depthwise  \u2502 (None, 7, 7, 960) \u2502      8,640 \u2502 block_14_expand_\u2026 \u2502\n\u2502 (DepthwiseConv2D)   \u2502                   \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_14_depthwise\u2026 \u2502 (None, 7, 7, 960) \u2502      3,840 \u2502 block_14_depthwi\u2026 \u2502\n\u2502 (BatchNormalizatio\u2026 \u2502                   \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_14_depthwise\u2026 \u2502 (None, 7, 7, 960) \u2502          0 \u2502 block_14_depthwi\u2026 \u2502\n\u2502 (ReLU)              \u2502                   \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_14_project    \u2502 (None, 7, 7, 160) \u2502    153,600 \u2502 block_14_depthwi\u2026 \u2502\n\u2502 (Conv2D)            \u2502                   \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_14_project_BN \u2502 (None, 7, 7, 160) \u2502        640 \u2502 block_14_project\u2026 \u2502\n\u2502 (BatchNormalizatio\u2026 \u2502                   \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_14_add (Add)  \u2502 (None, 7, 7, 160) \u2502          0 \u2502 block_13_project\u2026 \u2502\n\u2502                     \u2502                   \u2502            \u2502 block_14_project\u2026 \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_15_expand     \u2502 (None, 7, 7, 960) \u2502    153,600 \u2502 block_14_add[0][\u2026 \u2502\n\u2502 (Conv2D)            \u2502                   \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_15_expand_BN  \u2502 (None, 7, 7, 960) \u2502      3,840 \u2502 block_15_expand[\u2026 \u2502\n\u2502 (BatchNormalizatio\u2026 \u2502                   \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_15_expand_re\u2026 \u2502 (None, 7, 7, 960) \u2502          0 \u2502 block_15_expand_\u2026 \u2502\n\u2502 (ReLU)              \u2502                   \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_15_depthwise  \u2502 (None, 7, 7, 960) \u2502      8,640 \u2502 block_15_expand_\u2026 \u2502\n\u2502 (DepthwiseConv2D)   \u2502                   \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_15_depthwise\u2026 \u2502 (None, 7, 7, 960) \u2502      3,840 \u2502 block_15_depthwi\u2026 \u2502\n\u2502 (BatchNormalizatio\u2026 \u2502                   \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_15_depthwise\u2026 \u2502 (None, 7, 7, 960) \u2502          0 \u2502 block_15_depthwi\u2026 \u2502\n\u2502 (ReLU)              \u2502                   \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_15_project    \u2502 (None, 7, 7, 160) \u2502    153,600 \u2502 block_15_depthwi\u2026 \u2502\n\u2502 (Conv2D)            \u2502                   \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_15_project_BN \u2502 (None, 7, 7, 160) \u2502        640 \u2502 block_15_project\u2026 \u2502\n\u2502 (BatchNormalizatio\u2026 \u2502                   \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_15_add (Add)  \u2502 (None, 7, 7, 160) \u2502          0 \u2502 block_14_add[0][\u2026 \u2502\n\u2502                     \u2502                   \u2502            \u2502 block_15_project\u2026 \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_16_expand     \u2502 (None, 7, 7, 960) \u2502    153,600 \u2502 block_15_add[0][\u2026 \u2502\n\u2502 (Conv2D)            \u2502                   \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_16_expand_BN  \u2502 (None, 7, 7, 960) \u2502      3,840 \u2502 block_16_expand[\u2026 \u2502\n\u2502 (BatchNormalizatio\u2026 \u2502                   \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_16_expand_re\u2026 \u2502 (None, 7, 7, 960) \u2502          0 \u2502 block_16_expand_\u2026 \u2502\n\u2502 (ReLU)              \u2502                   \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_16_depthwise  \u2502 (None, 7, 7, 960) \u2502      8,640 \u2502 block_16_expand_\u2026 \u2502\n\u2502 (DepthwiseConv2D)   \u2502                   \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_16_depthwise\u2026 \u2502 (None, 7, 7, 960) \u2502      3,840 \u2502 block_16_depthwi\u2026 \u2502\n\u2502 (BatchNormalizatio\u2026 \u2502                   \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_16_depthwise\u2026 \u2502 (None, 7, 7, 960) \u2502          0 \u2502 block_16_depthwi\u2026 \u2502\n\u2502 (ReLU)              \u2502                   \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_16_project    \u2502 (None, 7, 7, 320) \u2502    307,200 \u2502 block_16_depthwi\u2026 \u2502\n\u2502 (Conv2D)            \u2502                   \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_16_project_BN \u2502 (None, 7, 7, 320) \u2502      1,280 \u2502 block_16_project\u2026 \u2502\n\u2502 (BatchNormalizatio\u2026 \u2502                   \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 Conv_1 (Conv2D)     \u2502 (None, 7, 7,      \u2502    409,600 \u2502 block_16_project\u2026 \u2502\n\u2502                     \u2502 1280)             \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 Conv_1_bn           \u2502 (None, 7, 7,      \u2502      5,120 \u2502 Conv_1[0][0]      \u2502\n\u2502 (BatchNormalizatio\u2026 \u2502 1280)             \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 out_relu (ReLU)     \u2502 (None, 7, 7,      \u2502          0 \u2502 Conv_1_bn[0][0]   \u2502\n\u2502                     \u2502 1280)             \u2502            \u2502                   \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</pre> <pre> Total params: 2,257,984 (8.61 MB)\n</pre> <pre> Trainable params: 0 (0.00 B)\n</pre> <pre> Non-trainable params: 2,257,984 (8.61 MB)\n</pre> In\u00a0[9]: Copied! <pre>#Camada  para gerar um vetor de 1280 elementos \nglobal_average_layer = layers.GlobalAveragePooling2D()\n\n# O Classificador para gato cachorro com 1 neuronio \nsaida_layer = layers.Dense(1, activation='sigmoid')\n</pre> #Camada  para gerar um vetor de 1280 elementos  global_average_layer = layers.GlobalAveragePooling2D()  # O Classificador para gato cachorro com 1 neuronio  saida_layer = layers.Dense(1, activation='sigmoid') In\u00a0[10]: Copied! <pre>model = tf.keras.Sequential([\n  base_model,   #### cnn mobilenet\n  global_average_layer, ###flatten\n  saida_layer ### especiallista\n])\n\nmodel.summary()\n</pre> model = tf.keras.Sequential([   base_model,   #### cnn mobilenet   global_average_layer, ###flatten   saida_layer ### especiallista ])  model.summary() <pre>Model: \"sequential\"\n</pre> <pre>\u250f\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2513\n\u2503 Layer (type)                    \u2503 Output Shape           \u2503       Param # \u2503\n\u2521\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2529\n\u2502 mobilenetv2_1.00_224            \u2502 ?                      \u2502     2,257,984 \u2502\n\u2502 (Functional)                    \u2502                        \u2502               \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 global_average_pooling2d        \u2502 ?                      \u2502   0 (unbuilt) \u2502\n\u2502 (GlobalAveragePooling2D)        \u2502                        \u2502               \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 dense (Dense)                   \u2502 ?                      \u2502   0 (unbuilt) \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</pre> <pre> Total params: 2,257,984 (8.61 MB)\n</pre> <pre> Trainable params: 0 (0.00 B)\n</pre> <pre> Non-trainable params: 2,257,984 (8.61 MB)\n</pre> <p>Pronto! J\u00e1 criamos a nossa rede para classifica\u00e7\u00e3o. Agora podemos treinar nossa rede e testar.</p> In\u00a0[11]: Copied! <pre>model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n</pre>  model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy']) In\u00a0[12]: Copied! <pre>#Avalia\u00e7\u00e3o do modelo antes de trein\u00e1-lo com novas imagens\nvalidation_steps=20\n\nloss0,accuracy0 = model.evaluate(train_generator, steps = validation_steps)\n</pre> #Avalia\u00e7\u00e3o do modelo antes de trein\u00e1-lo com novas imagens validation_steps=20  loss0,accuracy0 = model.evaluate(train_generator, steps = validation_steps) <pre>/Users/arnaldoalvesvianajunior/Library/Python/3.9/lib/python/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n  self._warn_if_super_not_called()\n</pre> <pre>20/20 \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 12s 532ms/step - accuracy: 0.4012 - loss: 0.8502\n</pre> In\u00a0[13]: Copied! <pre># Treinamento da nova CNN\n\nhistory = model.fit(train_generator, epochs=5, validation_data=validation_generator)\n</pre> # Treinamento da nova CNN  history = model.fit(train_generator, epochs=5, validation_data=validation_generator)  <pre>Epoch 1/5\n63/63 \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 57s 839ms/step - accuracy: 0.7936 - loss: 0.4272 - val_accuracy: 0.9800 - val_loss: 0.0941\nEpoch 2/5\n63/63 \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 51s 808ms/step - accuracy: 0.9750 - loss: 0.0902 - val_accuracy: 0.9820 - val_loss: 0.0717\nEpoch 3/5\n63/63 \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 51s 799ms/step - accuracy: 0.9825 - loss: 0.0656 - val_accuracy: 0.9830 - val_loss: 0.0602\nEpoch 4/5\n63/63 \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 50s 801ms/step - accuracy: 0.9880 - loss: 0.0511 - val_accuracy: 0.9840 - val_loss: 0.0511\nEpoch 5/5\n63/63 \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 50s 794ms/step - accuracy: 0.9904 - loss: 0.0442 - val_accuracy: 0.9830 - val_loss: 0.0503\n</pre> In\u00a0[14]: Copied! <pre>import pandas as pd\n\nmetrics_df = pd.DataFrame(history.history)\nmetrics_df[[\"loss\",\"val_loss\"]].plot();\nmetrics_df[[\"accuracy\", \"val_accuracy\"]].plot();\n</pre> import pandas as pd  metrics_df = pd.DataFrame(history.history) metrics_df[[\"loss\",\"val_loss\"]].plot(); metrics_df[[\"accuracy\", \"val_accuracy\"]].plot(); In\u00a0[16]: Copied! <pre>import numpy as np\nfrom tensorflow.keras.preprocessing import image\n\ndef predict_cat_or_dog(img_path):\n    img = image.load_img(img_path, target_size=image_size)\n    img_array = image.img_to_array(img)\n    img_array = np.expand_dims(img_array, axis=0)\n    img_array = preprocess_input(img_array)\n\n    prediction = model.predict(img_array)\n    \n    if prediction[0][0] &lt; 0.5:\n        return \"gatinhooooo\"\n    else:\n        return \"cachorrinho\"\n\n# Teste a fun\u00e7\u00e3o de previs\u00e3o com uma imagem\n\n# !wget https://uploads.metropoles.com/wp-content/uploads/2022/07/21154234/como-identificar-que-um-cachorro-esta-sendo-vitima-de-maus-tratos-1.jpg -O /content/cachorro.jpg\n# img_path = \"cachorro.jpg\"\nimg_path = \"dog.png\"\n\nresult = predict_cat_or_dog(img_path)\nprint(\"Essa foto \u00e9 de um \", result)\n</pre> import numpy as np from tensorflow.keras.preprocessing import image  def predict_cat_or_dog(img_path):     img = image.load_img(img_path, target_size=image_size)     img_array = image.img_to_array(img)     img_array = np.expand_dims(img_array, axis=0)     img_array = preprocess_input(img_array)      prediction = model.predict(img_array)          if prediction[0][0] &lt; 0.5:         return \"gatinhooooo\"     else:         return \"cachorrinho\"  # Teste a fun\u00e7\u00e3o de previs\u00e3o com uma imagem  # !wget https://uploads.metropoles.com/wp-content/uploads/2022/07/21154234/como-identificar-que-um-cachorro-esta-sendo-vitima-de-maus-tratos-1.jpg -O /content/cachorro.jpg # img_path = \"cachorro.jpg\" img_path = \"dog.png\"  result = predict_cat_or_dog(img_path) print(\"Essa foto \u00e9 de um \", result) <pre>1/1 \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 1s 899ms/step\nEssa foto \u00e9 de um  cachorrinho\n</pre> In\u00a0[\u00a0]: Copied! <pre># Salvando a rede \nmodel.save(\"dogs_vs_cats.h5\")\n\n#Carregando uma rede .h5\nnew_model = models.load_model('dogs_vs_cats.h5')\n</pre> # Salvando a rede  model.save(\"dogs_vs_cats.h5\")  #Carregando uma rede .h5 new_model = models.load_model('dogs_vs_cats.h5') In\u00a0[\u00a0]: Copied! <pre>### Seu c\u00f3digo aqui....\n</pre> ### Seu c\u00f3digo aqui...."},{"location":"aulas/IA/lab09/transferlearning_2.html#2-redes-neurais","title":"2. Redes Neurais\u00b6","text":""},{"location":"aulas/IA/lab09/transferlearning_2.html#objetivos","title":"Objetivos\u00b6","text":"<ul> <li>Conhecer e praticar Aprendizagem por transfer\u00eancia</li> <li>Praticar a classifica\u00e7\u00e3o de objeto usando framework TensorFlow</li> </ul>"},{"location":"aulas/IA/lab09/transferlearning_2.html#introducao-ao-transfer-learning-com-redes-pre-treinadas","title":"Introdu\u00e7\u00e3o ao Transfer Learning com redes pr\u00e9-treinadas\u00b6","text":"<p>Excelente! Agora que j\u00e1 sabemos como utilizar uma rede pr\u00e9-treinada, vamos explorar uma t\u00e9cnica poderosa chamada Transfer Learning (Aprendizagem por Transfer\u00eancia). Essa abordagem nos permite tirar proveito das arquiteturas de redes neurais existentes e trein\u00e1-las para classificar objetos personalizados ou novas categorias de imagens.</p> <p>O Transfer Learning \u00e9 uma t\u00e9cnica em que um modelo de aprendizado profundo, treinado previamente em um conjunto de dados maior e mais diversificado, \u00e9 adaptado para ser aplicado a um novo problema. O conhecimento adquirido pelo modelo original \u00e9 transferido para o novo problema, permitindo um treinamento mais r\u00e1pido e, muitas vezes, um desempenho melhor do que treinar uma rede neural do zero.</p> <p>A ideia por tr\u00e1s do Transfer Learning \u00e9 que as redes neurais pr\u00e9-treinadas, como VGG, ResNet e Inception, j\u00e1 aprenderam a <code>extrair caracter\u00edsticas</code> importantes das imagens em seus primeiros est\u00e1gios. Essas caracter\u00edsticas podem ser comuns a muitos problemas de classifica\u00e7\u00e3o de imagens, como detec\u00e7\u00e3o de bordas, texturas e padr\u00f5es. Ao aproveitar esse conhecimento pr\u00e9vio, podemos nos concentrar no treinamento das \u00faltimas camadas do modelo, que s\u00e3o respons\u00e1veis por aprender caracter\u00edsticas espec\u00edficas do novo problema.</p> <p>Ao utilizar o Transfer Learning, podemos economizar tempo e recursos computacionais, al\u00e9m de obter melhores resultados do que treinar uma rede do zero para um conjunto de dados menor e espec\u00edfico. Portanto, \u00e9 uma t\u00e9cnica amplamente utilizada em aplica\u00e7\u00f5es pr\u00e1ticas de aprendizado profundo e processamento de imagens.</p>"},{"location":"aulas/IA/lab09/transferlearning_2.html#combinando-a-rede-pre-treinada-com-um-classificador-mlp","title":"Combinando a rede pr\u00e9-treinada com um classificador MLP\u00b6","text":"<p>Ao aplicar o Transfer Learning, nossa rede convolucional ser\u00e1 composta por duas partes principais: o extrator de caracter\u00edsticas e o classificador. O extrator de caracter\u00edsticas ser\u00e1 baseado em uma rede pr\u00e9-treinada, como VGG16, ResNet50 ou InceptionV3. Essa parte da rede j\u00e1 aprendeu a extrair caracter\u00edsticas relevantes de imagens, como bordas, texturas e padr\u00f5es, durante o treinamento em um grande conjunto de dados, como o ImageNet.</p> <p>Em seguida, adicionaremos um classificador MLP (Multilayer Perceptron) personalizado para resolver o nosso problema espec\u00edfico de classifica\u00e7\u00e3o de imagens. Esse classificador ser\u00e1 respons\u00e1vel por aprender as caracter\u00edsticas espec\u00edficas do novo conjunto de dados e classificar as imagens nas categorias desejadas.</p> <p>Dessa forma, a rede ajustada combina o poder das redes pr\u00e9-treinadas, que j\u00e1 aprenderam a extrair caracter\u00edsticas gerais de imagens, com um classificador personalizado que aprender\u00e1 a distinguir as categorias espec\u00edficas do nosso problema. Como mostra a figura abaixo:</p> <p></p> <p>Agora que entendemos os conceitos b\u00e1sicos de Transfer Learning, podemos prosseguir com os passos para aplicar o Transfer Learning e adaptar a rede pr\u00e9-treinada ao nosso problema de classifica\u00e7\u00e3o de imagens.</p>"},{"location":"aulas/IA/lab09/transferlearning_2.html#passo-a-passo-para-aplicar-transfer-learning","title":"Passo a passo para aplicar Transfer Learning\u00b6","text":"<ol> <li><p>Escolha uma rede pr\u00e9-treinada: Selecione uma rede neural pr\u00e9-treinada dispon\u00edvel no Keras (por exemplo, VGG16, ResNet50, InceptionV3) com base nas caracter\u00edsticas e requisitos do seu problema. Cada arquitetura tem suas pr\u00f3prias vantagens e desvantagens, portanto, escolha aquela que melhor se adapta \u00e0s suas necessidades.</p> </li> <li><p>Remova a camada de classifica\u00e7\u00e3o: Carregue a rede neural pr\u00e9-treinada sem a camada de classifica\u00e7\u00e3o final. Isso pode ser feito usando o argumento include_top=False ao carregar o modelo no Keras. Isso permitir\u00e1 que voc\u00ea adicione suas pr\u00f3prias camadas personalizadas para classificar as novas categorias.</p> </li> <li><p>Adicione camadas personalizadas: Adicione camadas espec\u00edficas para o seu problema de classifica\u00e7\u00e3o. Normalmente, isso inclui uma camada de GlobalAveragePooling2D, seguida por uma camada densa com uma fun\u00e7\u00e3o de ativa\u00e7\u00e3o softmax e o n\u00famero de neuronios igual ao n\u00famero de classes do novo problema.</p> </li> <li><p>Congele as camadas pr\u00e9-treinadas: \u00c9 uma boa pr\u00e1tica congelar as camadas pr\u00e9-treinadas da rede neural, especialmente durante as primeiras \u00e9pocas do treinamento. Isso evitar\u00e1 que os pesos dessas camadas sejam atualizados e preservar\u00e1 o conhecimento pr\u00e9vio que elas possuem. No Keras, voc\u00ea pode fazer isso com o modelxxx.trainable = False</p> </li> <li><p>Pr\u00e9-processamento dos dados: Prepare os dados de acordo com a rede pr\u00e9-treinada escolhida. Isso inclui redimensionar as imagens, normalizar os valores dos pixels e codificar as etiquetas das categorias. Lembre-se de aplicar as mesmas transforma\u00e7\u00f5es usadas no conjunto de dados original da rede pr\u00e9-treinada.</p> </li> <li><p>Treine o modelo: Treine o modelo ajustado no seu conjunto de dados. Durante as primeiras \u00e9pocas, com as camadas pr\u00e9-treinadas congeladas, o modelo aprender\u00e1 as caracter\u00edsticas espec\u00edficas do novo problema.</p> </li> <li><p>Avalie e otimize: Avalie o desempenho do modelo ajustado em um conjunto de teste e otimize os hiperpar\u00e2metros conforme necess\u00e1rio. Voc\u00ea pode experimentar diferentes arquiteturas de redes neurais, taxas de aprendizado, otimizadores e outros hiperpar\u00e2metros para encontrar a melhor configura\u00e7\u00e3o para o seu problema.</p> </li> </ol>"},{"location":"aulas/IA/lab09/transferlearning_2.html#aplicando-transfer-learning-em-um-dataset-ja-preparado-pelo-tensorflow","title":"Aplicando transfer learning em um dataset j\u00e1 preparado pelo tensorflow\u00b6","text":"<p>Vamos usar o dataset <code>cats_vs_dogs</code> que \u00e9 disponibilizado pelo proprio tensorflow, desta forma focamos apenas no entendimento da tecnica de transfer learning e menos em preprocessamento e cria\u00e7\u00e3o de dados. nas proximas aulas vamos criar nosso proprio dataset...</p>"},{"location":"aulas/IA/lab09/transferlearning_2.html#escolhendo-um-modelo-pre-treinado","title":"Escolhendo um modelo pr\u00e9-treinado\u00b6","text":"<p>A <code>MobileNet V2</code> desenvolvido no Google e foi treinado com <code>1,4 milh\u00e3o de imagens</code> e possui <code>1000 classes diferentes</code> com pesos predeterminados do imagenet (Googles dataset).</p> <p>Carregue a rede neural pr\u00e9-treinada sem a camada de classifica\u00e7\u00e3o final. Isso pode ser feito usando o argumento <code>include_top=False</code></p>"},{"location":"aulas/IA/lab09/transferlearning_2.html#adicionando-um-classificador","title":"Adicionando um Classificador\u00b6","text":""},{"location":"aulas/IA/lab09/transferlearning_2.html#desafio-2","title":"Desafio 2\u00b6","text":"<p>Vamos entender o que acabamos de fazer. Avalie a quantidade de parametros total, treinaveis e n\u00e3o treinaveis. O que foi identificado?</p>"},{"location":"aulas/IA/lab09/transferlearning_2.html#sua-resposta-aqui","title":"sua resposta aqui.....\u00b6","text":"<p>.</p>"},{"location":"aulas/IA/lab09/transferlearning_2.html#treinamento-do-modelo","title":"Treinamento do modelo\u00b6","text":""},{"location":"aulas/IA/lab09/transferlearning_2.html#fazendo-predicoes","title":"Fazendo predi\u00e7\u00f5es\u00b6","text":""},{"location":"aulas/IA/lab09/transferlearning_2.html#salvando-o-modelo-da-rede-treinada","title":"Salvando o modelo da rede treinada\u00b6","text":"<p>Agora que j\u00e1 temos um modelo treinado e ajustado para resolver o problema especifico que temos, podemos salver a arquitetura e os pesos em um arquivo com extens\u00e3o .h5</p> <p>para usar esta rede, basta carregar o arquivo.h5</p>"},{"location":"aulas/IA/lab09/transferlearning_2.html#desafio-3","title":"Desafio 3\u00b6","text":"<p>Aplicar o Transfer Learning usando a rede pr\u00e9-treinada ResNet50 e o conjunto de dados CIFAR-10, que possui 10 classes de objetos.</p>"},{"location":"aulas/IA/lab10/data-augmentation.html","title":"Lab10 - Redes Neurais - Data Augmentation","text":"In\u00a0[1]: Copied! <pre># Carrega os dados\nfrom keras.datasets import cifar10\n\n(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n</pre> # Carrega os dados from keras.datasets import cifar10  (x_train, y_train), (x_test, y_test) = cifar10.load_data() <pre>Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n170498071/170498071 [==============================] - 10s 0us/step\n</pre> In\u00a0[2]: Copied! <pre>import matplotlib.pyplot as plt\n\nclass_names = ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n\n# Fun\u00e7\u00e3o para exibir imagens do conjunto de dados\ndef show_images(images, labels, n_rows=2, n_cols=5):\n    fig, axes = plt.subplots(n_rows, n_cols, figsize=(10, 4))\n    for i, ax in enumerate(axes.flat):\n        ax.imshow(images[i])\n        ax.set_title(class_names[labels[i][0]])\n        ax.axis('off')\n    plt.show()\n\nshow_images(x_train, y_train)\n</pre> import matplotlib.pyplot as plt  class_names = ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']  # Fun\u00e7\u00e3o para exibir imagens do conjunto de dados def show_images(images, labels, n_rows=2, n_cols=5):     fig, axes = plt.subplots(n_rows, n_cols, figsize=(10, 4))     for i, ax in enumerate(axes.flat):         ax.imshow(images[i])         ax.set_title(class_names[labels[i][0]])         ax.axis('off')     plt.show()  show_images(x_train, y_train) <p>No Keras usamos o pacote <code>ImageDataGenerator</code>.</p> <p>A partir dele vamos aplicar v\u00e1rias transforma\u00e7\u00f5es nas imagens do conjunto de dados durante o treinamento do modelo.</p> <p><code>rotation_range</code> = 15</p> <ul> <li>Isso permitir\u00e1 que as imagens sejam rotacionadas aleatoriamente em um intervalo de at\u00e9 \u00b115 graus.</li> </ul> <p><code>width_shift_range</code> = 0.1</p> <ul> <li>Este par\u00e2metro permite que as imagens sejam deslocadas horizontalmente. O valor 0.1 significa que a imagem pode ser deslocada aleatoriamente at\u00e9 10% de sua largura.</li> </ul> <p><code>height_shift_range</code> = 0.1</p> <ul> <li>Similar ao par\u00e2metro anterior, mas para deslocamento vertical. As imagens podem ser deslocadas aleatoriamente at\u00e9 10% de sua altura.</li> </ul> <p><code>shear_range</code> = 0.1</p> <ul> <li>Este par\u00e2metro permite que uma distor\u00e7\u00e3o de cisalhamento seja aplicada \u00e0s imagens. Um cisalhamento \u00e9 uma transforma\u00e7\u00e3o que desliza uma parte da imagem em uma dire\u00e7\u00e3o, enquanto a outra parte \u00e9 deslizada na dire\u00e7\u00e3o oposta. O valor 0.1 indica a intensidade do cisalhamento.</li> </ul> <p><code>zoom_range</code> = 0.1</p> <ul> <li>Isso permite que as imagens sejam ampliadas ou reduzidas aleatoriamente. O valor 0.1 indica que o zoom pode variar de 0,9 (zoom out) a 1,1 (zoom in).</li> </ul> <p><code>horizontal_flip</code> = True</p> <ul> <li>Isso permite que as imagens sejam espelhadas horizontalmente (ou seja, invertidas de esquerda para direita) com uma probabilidade de 50%.</li> </ul> <p><code>fill_mode</code> = 'nearest'</p> <ul> <li>Durante transforma\u00e7\u00f5es como rota\u00e7\u00e3o ou deslocamento, podem aparecer alguns pixels vazios na imagem. O fill_mode determina como preencher esses pixels. O valor 'nearest' significa que ele usar\u00e1 o valor do pixel mais pr\u00f3ximo para preencher os pixels vazios.</li> </ul> <p><code>rescale</code> = 1./255</p> <ul> <li>Este \u00e9 um passo importante de pr\u00e9-processamento. As imagens geralmente t\u00eam valores de pixel no intervalo [0, 255]. Este par\u00e2metro ir\u00e1 reescalar esses valores para o intervalo [0, 1], dividindo cada pixel por 255. Isso \u00e9 comumente feito para facilitar a converg\u00eancia durante o treinamento de redes neurais.</li> </ul> <p>Existem outros parametros e n\u00e3o \u00e9 obrigat\u00f3rio o uso de todos s\u00e3o necess\u00e1rios, vai depender do problema que est\u00e1 sendo atacado.</p> In\u00a0[3]: Copied! <pre>from keras.preprocessing.image import ImageDataGenerator\n\ndata_gen = ImageDataGenerator(\n    rotation_range=15,\n    width_shift_range=0.1,\n    height_shift_range=0.1,\n    shear_range=0.1,\n    zoom_range=0.1,\n    horizontal_flip=True,\n    fill_mode='nearest',\n    rescale=1./255)\n</pre> from keras.preprocessing.image import ImageDataGenerator  data_gen = ImageDataGenerator(     rotation_range=15,     width_shift_range=0.1,     height_shift_range=0.1,     shear_range=0.1,     zoom_range=0.1,     horizontal_flip=True,     fill_mode='nearest',     rescale=1./255)  In\u00a0[4]: Copied! <pre>import numpy as np\n\ndef show_augmented_images(data_gen, image, label, n_rows=2, n_cols=5):\n    fig, axes = plt.subplots(n_rows, n_cols, figsize=(10, 4))\n    img_iterator = data_gen.flow(np.array([image]), np.array([label]))\n\n    for i, ax in enumerate(axes.flat):\n        img, lbl = next(img_iterator)\n        ax.imshow(img[0])\n        ax.set_title(class_names[lbl[0].item()])\n        ax.axis('off')\n    plt.show()\n\n\n# Selecionar uma imagem do conjunto de dados\nimage_index = 0\nimage = x_train[image_index]\nlabel = y_train[image_index]\n\n# Exibir imagens aumentadas\nshow_augmented_images(data_gen, image, label)\n</pre> import numpy as np  def show_augmented_images(data_gen, image, label, n_rows=2, n_cols=5):     fig, axes = plt.subplots(n_rows, n_cols, figsize=(10, 4))     img_iterator = data_gen.flow(np.array([image]), np.array([label]))      for i, ax in enumerate(axes.flat):         img, lbl = next(img_iterator)         ax.imshow(img[0])         ax.set_title(class_names[lbl[0].item()])         ax.axis('off')     plt.show()   # Selecionar uma imagem do conjunto de dados image_index = 0 image = x_train[image_index] label = y_train[image_index]  # Exibir imagens aumentadas show_augmented_images(data_gen, image, label)  <p>Note nas varia\u00e7\u00f5es criadas a partir de uma \u00fanica imagem.</p> In\u00a0[6]: Copied! <pre>## Vamos treinar com um modelo de arquitetura simples e generico apenas para testes\n\nfrom keras.models import Sequential\nfrom keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n\nmodel = Sequential()\n\nmodel.add(Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3)))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\n\nmodel.add(Conv2D(64, (3, 3), activation='relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\n\nmodel.add(Flatten())\nmodel.add(Dense(512, activation='relu'))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(10, activation='softmax'))\n\nmodel.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n</pre> ## Vamos treinar com um modelo de arquitetura simples e generico apenas para testes  from keras.models import Sequential from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout  model = Sequential()  model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3))) model.add(MaxPooling2D(pool_size=(2, 2)))  model.add(Conv2D(64, (3, 3), activation='relu')) model.add(MaxPooling2D(pool_size=(2, 2)))  model.add(Flatten()) model.add(Dense(512, activation='relu')) model.add(Dropout(0.5)) model.add(Dense(10, activation='softmax'))  model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])  In\u00a0[7]: Copied! <pre># Definir o n\u00famero de imagens aumentadas por imagem original\naugmentation_factor = 5\n\n# Criar listas vazias para armazenar as imagens e r\u00f3tulos aumentados\nx_train_augmented = []\ny_train_augmented = []\n\n# Aplicar a augmenta\u00e7\u00e3o de dados\nfor img, lbl in zip(x_train, y_train):\n    x_train_augmented.append(img)  # Adicionar a imagem original\n    y_train_augmented.append(lbl)  # Adicionar o r\u00f3tulo original\n\n    for _ in range(augmentation_factor - 1):\n        # Gerar uma imagem aumentada\n        augmented_img = data_gen.random_transform(img)\n\n        # Adicionar a imagem e o r\u00f3tulo aumentado \u00e0s listas\n        x_train_augmented.append(augmented_img)\n        y_train_augmented.append(lbl)\n\n# Converter as listas em arrays numpy\nx_train_augmented = np.array(x_train_augmented)\ny_train_augmented = np.array(y_train_augmented)\n\n# Normalizar as imagens\nx_train_augmented = x_train_augmented / 255.0\n</pre> # Definir o n\u00famero de imagens aumentadas por imagem original augmentation_factor = 5  # Criar listas vazias para armazenar as imagens e r\u00f3tulos aumentados x_train_augmented = [] y_train_augmented = []  # Aplicar a augmenta\u00e7\u00e3o de dados for img, lbl in zip(x_train, y_train):     x_train_augmented.append(img)  # Adicionar a imagem original     y_train_augmented.append(lbl)  # Adicionar o r\u00f3tulo original      for _ in range(augmentation_factor - 1):         # Gerar uma imagem aumentada         augmented_img = data_gen.random_transform(img)          # Adicionar a imagem e o r\u00f3tulo aumentado \u00e0s listas         x_train_augmented.append(augmented_img)         y_train_augmented.append(lbl)  # Converter as listas em arrays numpy x_train_augmented = np.array(x_train_augmented) y_train_augmented = np.array(y_train_augmented)  # Normalizar as imagens x_train_augmented = x_train_augmented / 255.0  In\u00a0[\u00a0]: Copied! <pre>batch_size = 64\nsteps_per_epoch = len(x_train) // batch_size\n\nhistory = model.fit_generator(data_gen.flow(x_train, y_train, batch_size=batch_size),\n                              steps_per_epoch=steps_per_epoch,\n                              epochs=20,\n                              validation_data=(x_test / 255, y_test))\n</pre> batch_size = 64 steps_per_epoch = len(x_train) // batch_size  history = model.fit_generator(data_gen.flow(x_train, y_train, batch_size=batch_size),                               steps_per_epoch=steps_per_epoch,                               epochs=20,                               validation_data=(x_test / 255, y_test))"},{"location":"aulas/IA/lab10/data-augmentation.html#2-redes-neurais","title":"2. Redes Neurais\u00b6","text":""},{"location":"aulas/IA/lab10/data-augmentation.html#objetivos","title":"Objetivos\u00b6","text":"<ul> <li>Conhecer e praticar Aumento de dados</li> </ul>"},{"location":"aulas/IA/lab10/data-augmentation.html#data-augmentation","title":"Data Augmentation\u00b6","text":"<p>O aumento de dados \u00e9 uma t\u00e9cnica amplamente utilizada no campo do aprendizado profundo e da vis\u00e3o computacional para melhorar a generaliza\u00e7\u00e3o e o desempenho dos modelos de aprendizado de m\u00e1quina. Essa t\u00e9cnica \u00e9 especialmente \u00fatil em cen\u00e1rios onde os conjuntos de dados s\u00e3o limitados ou desequilibrados, pois ajuda a criar varia\u00e7\u00f5es nos dados existentes, aumentando assim a quantidade de dados dispon\u00edveis para treinamento e reduzindo o overfitting.</p> <p>O overfitting ocorre quando um modelo de aprendizado de m\u00e1quina aprende padr\u00f5es espec\u00edficos do conjunto de dados de treinamento e n\u00e3o consegue generalizar adequadamente para novos dados. Isso pode levar a um desempenho ruim quando o modelo \u00e9 exposto a dados n\u00e3o vistos anteriormente. A t\u00e9cnica de aumento de dados aborda esse problema criando exemplos sint\u00e9ticos, aplicando transforma\u00e7\u00f5es \u00e0s imagens originais, como rota\u00e7\u00e3o, transla\u00e7\u00e3o, redimensionamento e invers\u00e3o. Essas transforma\u00e7\u00f5es geram varia\u00e7\u00f5es das imagens originais que podem ajudar o modelo a aprender caracter\u00edsticas mais generaliz\u00e1veis e a se tornar mais robusto a poss\u00edveis varia\u00e7\u00f5es nos dados de entrada.</p> <p>De forma geral em imagens pode ser aplicado as transforma\u00e7\u00f5s:</p> <ul> <li>Rota\u00e7\u00e3o</li> <li>Transla\u00e7\u00e3o (deslocamento horizontal e vertical)</li> <li>Zoom (in e out)</li> <li>Invers\u00e3o horizontal e vertical</li> <li>Ajuste de brilho e contraste</li> <li>Ru\u00eddo (adicionar ru\u00eddo gaussiano ou salt-and-pepper)</li> <li>Corte aleat\u00f3rio (Random Cropping)</li> <li>Existem mais....</li> </ul>"},{"location":"aulas/IA/lab10/data-augmentation.html#como-usar-data-augmentation","title":"Como usar Data Augmentation\u00b6","text":"<p>Para demonstrar, vamos aplicar essa t\u00e9cnica no dataset do Cifar10.</p>"},{"location":"aulas/IA/lab11/index.html","title":"Lab11 - Redes Neurais - resumo","text":""},{"location":"aulas/IA/lab11/index.html#resumo-sobre-redes-neurais","title":"Resumo sobre redes neurais","text":"<p>A cria\u00e7\u00e3o de redes neurais envolve muitas etapas onde devem ser consideradow diversos pontos e aspectos de complexidade do problema envolvido, tratando-se de modelos para vis\u00e3o computacional tivemos contato com alguns tipos de arquitetura, otimiza\u00e7\u00e3o, dados, e implementa\u00e7\u00e3o.</p>"},{"location":"aulas/IA/lab11/index.html#notebook-completo","title":"Notebook completo","text":"<p>No link a seguir tem um notebook completo com sugest\u00f5es de implemeta\u00e7\u00e3o</p> <ul> <li>LINK o notebook completo</li> </ul>"},{"location":"aulas/IA/lab11/index.html#etapas-de-construcao-de-redes-neurais","title":"Etapas de constru\u00e7\u00e3o de redes neurais","text":"<ul> <li>Arquitetura de Rede: Escolha arquiteturas como VGG, ResNet, ou Mobilenet para aproveitar modelos pr\u00e9-treinados atrav\u00e9s de fine-tuning.</li> <li>Ajuste Fino (Fine-Tuning): Utilize transfer\u00eancia de aprendizado para acelerar o treinamento.</li> <li>Dados: Augmenta\u00e7\u00e3o de dados e normaliza\u00e7\u00e3o s\u00e3o essenciais para a prepara\u00e7\u00e3o eficaz de dados.</li> <li>Otimiza\u00e7\u00e3o: Otimizadores como Adam ou SGD (com momento), taxas de aprendizado ajust\u00e1veis e schedules s\u00e3o importantes.</li> <li>Regulariza\u00e7\u00e3o: Utilize t\u00e9cnicas como early stopping e L2 regularization para promover a generaliza\u00e7\u00e3o.</li> </ul>"},{"location":"aulas/IA/lab11/index.html#pipeline-de-treinamento","title":"Pipeline de Treinamento","text":"<p>A cria\u00e7\u00e3o de uma rede neural envolve um pipeline de treinamento bem definido para garantir um modelo eficaz e robusto. A seguir est\u00e3o as <code>etapas t\u00edpicas que podem ou n\u00e3o fazer parte</code> de um pipeline de treinamento:</p> <ol> <li> <p>Prepara\u00e7\u00e3o de Dados:</p> <ul> <li>Coleta e Limpeza: Reunir dados de diversas fontes e garantir que est\u00e3o limpos e livres de ru\u00eddos.</li> <li>Augmenta\u00e7\u00e3o: Aplicar t\u00e9cnicas de augmenta\u00e7\u00e3o, como rota\u00e7\u00e3o, corte, ajuste de brilho e contraste, e distor\u00e7\u00f5es geom\u00e9tricas para aumentar a variedade dos dados de treino.</li> <li>Divis\u00e3o: Dividir os dados em conjuntos de treino, valida\u00e7\u00e3o e teste.</li> </ul> </li> <li> <p>Defini\u00e7\u00e3o do Modelo:</p> <ul> <li>Arquitetura: Escolher a arquitetura da rede neural com base na complexidade do problema e recursos dispon\u00edveis.</li> <li>Camadas e Par\u00e2metros: Definir a quantidade de camadas, neur\u00f4nios, filtros de convolu\u00e7\u00e3o, e outros par\u00e2metros.</li> </ul> </li> <li> <p>Compila\u00e7\u00e3o:</p> <ul> <li>Fun\u00e7\u00e3o de Perda: Selecionar a fun\u00e7\u00e3o de perda apropriada (ex.: cross-entropy para classifica\u00e7\u00e3o).</li> <li>Otimiza\u00e7\u00e3o: Escolher o otimizador (ex.: Adam, SGD).</li> <li>M\u00e9tricas: Definir m\u00e9tricas para avaliar o desempenho do modelo (ex.: precis\u00e3o, recall).</li> </ul> </li> <li> <p>Treinamento:</p> <ul> <li>Batch Size: Determinar o tamanho do batch para o treinamento.</li> <li>\u00c9pocas: Definir o n\u00famero de \u00e9pocas para o treinamento.</li> <li>Callback Functions: Utilizar callbacks como early stopping, redu\u00e7\u00e3o da taxa de aprendizado on plateau, etc.</li> </ul> </li> <li> <p>Valida\u00e7\u00e3o:</p> <ul> <li>Monitoramento: Avaliar o desempenho do modelo no conjunto de valida\u00e7\u00e3o ap\u00f3s cada \u00e9poca.</li> <li>Ajuste de Hiperpar\u00e2metros: Ajustar hiperpar\u00e2metros com base no desempenho de valida\u00e7\u00e3o.</li> </ul> </li> <li> <p>Avalia\u00e7\u00e3o:</p> <ul> <li>Teste: Avaliar o modelo final no conjunto de teste para medir sua performance.</li> <li>M\u00e9tricas de Avalia\u00e7\u00e3o: Utilizar m\u00e9tricas como precis\u00e3o, recall, F1-score, e AUC-ROC.</li> </ul> </li> <li> <p>Deploy de Modelos:</p> <ul> <li>Exporta\u00e7\u00e3o: Salvar o modelo treinado em um formato apropriado.</li> <li>Servi\u00e7o de Modelo: Utilizar frameworks como TensorFlow Serving ou ONNX para colocar o modelo em produ\u00e7\u00e3o.</li> <li>Monitoramento em Produ\u00e7\u00e3o: Monitorar o desempenho do modelo em produ\u00e7\u00e3o e realizar ajustes conforme necess\u00e1rio.</li> </ul> </li> </ol>"},{"location":"aulas/IA/lab11/index.html#elementos-de-redes-neurais","title":"Elementos de Redes Neurais","text":"<p>Elementos como dropout e batch normalization s\u00e3o fundamentais para o desempenho e a estabilidade do treinamento.</p> Elemento Descri\u00e7\u00e3o e Casos de Uso Dropout Use para reduzir o overfitting, aplic\u00e1vel em redes densas ou MLPs, com taxa de 0.2 a 0.5. Batch Normalization Utilize para estabilizar e acelerar o treinamento, aplic\u00e1vel tanto em camadas convolucionais quanto densas. Quantidade de Filtros de Convolu\u00e7\u00e3o Inicie com menos filtros e aumente nas camadas profundas. Exemplos: comece com 32 ou 64 e dobre em camadas subsequentes. Max Pooling Reduz a dimensionalidade espacial ap\u00f3s camadas convolucionais. Pooling de 2x2 \u00e9 comum. Quantidade de Camadas e Neur\u00f4nios em MLP Comece com uma ou duas camadas escondidas, com 100 a 300 neur\u00f4nios por camada, ajustando conforme a necessidade."},{"location":"aulas/IA/lab11/index.html#funcoes-de-ativacao","title":"Fun\u00e7\u00f5es de Ativa\u00e7\u00e3o","text":"<p>A escolha da fun\u00e7\u00e3o de ativa\u00e7\u00e3o \u00e9 crucial no desenvolvimento de modelos de redes neurais para vis\u00e3o computacional.</p> Fun\u00e7\u00e3o de Ativa\u00e7\u00e3o Local de Uso Descri\u00e7\u00e3o e Casos de Uso Relu Camadas intermedi\u00e1rias Ideal em problemas de vis\u00e3o computacional, pois adicionam n\u00e3o linearidades que colaboram para o treinamento. SIGMOID \u00daltima camada Usada na \u00faltima camada para problemas de classifica\u00e7\u00e3o bin\u00e1ria, onde a sa\u00edda \u00e9 interpretada como uma probabilidade. N\u00e3o \u00e9 ideal para multiclasses devido \u00e0 satura\u00e7\u00e3o do gradiente. SOFTMAX \u00daltima camada Indicada para a \u00faltima camada em problemas de classifica\u00e7\u00e3o multiclasse, convertendo logits em probabilidades condicionais para cada classe. A soma das probabilidades \u00e9 1. <pre><code>import tensorflow as tf\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization\nfrom tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n\n# Definindo o modelo\nmodel = Sequential()\n\n# Camadas convolucionais com n\u00famero crescente de filtros\nmodel.add(Conv2D(32, (3, 3), activation='relu', input_shape=(64, 64, 3)))\nmodel.add(BatchNormalization())\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\n\nmodel.add(Conv2D(64, (3, 3), activation='relu'))\nmodel.add(BatchNormalization())\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\n\nmodel.add(Conv2D(128, (3, 3), activation='relu'))\nmodel.add(BatchNormalization())\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\n\n# Camada Flatten para converter a sa\u00edda das camadas convolucionais em um vetor 1D\nmodel.add(Flatten())\n\n# Camadas totalmente conectadas\nmodel.add(Dense(128, activation='relu'))\nmodel.add(Dropout(0.5))\n\nmodel.add(Dense(64, activation='relu'))\nmodel.add(Dropout(0.5))\n\n# \u00daltima camada totalmente conectada com 10 sa\u00eddas (10 classes de categoria de imagem)\nmodel.add(Dense(10, activation='softmax'))\n\n# Compilando o modelo\nmodel.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n\n# Configurando a callback ModelCheckpoint\ncheckpoint = ModelCheckpoint('best_model.h5', \n                             monitor='val_accuracy', \n                             save_best_only=True, \n                             mode='max', \n                             verbose=1)\n\n# Configurando a callback EarlyStopping\nearly_stopping = EarlyStopping(monitor='val_loss', \n                               patience=10, \n                               verbose=1, \n                               restore_best_weights=True)\n\n# Configurando a callback ReduceLROnPlateau\nreduce_lr = ReduceLROnPlateau(monitor='val_loss', \n                              factor=0.2, \n                              patience=5, \n                              min_lr=0.001, \n                              verbose=1)\n\n# Treinando o modelo com as callbacks\nhistory = model.fit(x_train, y_train, \n                    epochs=100, \n                    validation_data=(x_val, y_val), \n                    callbacks=[checkpoint, early_stopping, reduce_lr])\n\n# Resumo do modelo\nmodel.summary()\n</code></pre>"},{"location":"aulas/IA/lab11/index.html#data-augmentation","title":"Data Augmentation:","text":"<p>Data augmentation \u00e9 uma t\u00e9cnica usada para aumentar a diversidade do conjunto de dados de treinamento sem realmente coletar novos dados. Isso \u00e9 feito aplicando v\u00e1rias transforma\u00e7\u00f5es (como rota\u00e7\u00f5es, transla\u00e7\u00f5es, flip horizontal/vertical, zoom, etc.) \u00e0s imagens de treinamento, o que ajuda a melhorar a generaliza\u00e7\u00e3o do modelo.</p> <p>Podemos usar a classe <code>ImageDataGenerator</code> para aplicar data augmentation. Ela permite configurar e aplicar transforma\u00e7\u00f5es \u00e0s imagens em tempo real durante o treinamento.</p>"},{"location":"aulas/IA/lab11/index.html#imagedatagenerator","title":"ImageDataGenerator:","text":"<ul> <li>rotation_range: Grau de rota\u00e7\u00e3o aleat\u00f3ria das imagens.</li> <li>width_shift_range: Fra\u00e7\u00e3o do total da largura para deslocamento horizontal aleat\u00f3rio.</li> <li>height_shift_range: Fra\u00e7\u00e3o do total da altura para deslocamento vertical aleat\u00f3rio.</li> <li>horizontal_flip: Permite flip horizontal aleat\u00f3rio.</li> <li>zoom_range: Faixa de zoom aleat\u00f3rio.</li> </ul> <p>Existem outros parametros....</p>"},{"location":"aulas/IA/lab11/index.html#train_generator","title":"train_generator:","text":"<p>Usamos <code>flow</code> para criar um gerador que fornece lotes de dados augmentados durante o treinamento.</p> <pre><code>import tensorflow as tf\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization\nfrom tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nimport numpy as np\n\n# Definindo o modelo\nmodel = Sequential()\n\n# Camadas convolucionais com n\u00famero crescente de filtros\nmodel.add(Conv2D(32, (3, 3), activation='relu', input_shape=(64, 64, 3)))\nmodel.add(BatchNormalization())\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\n\nmodel.add(Conv2D(64, (3, 3), activation='relu'))\nmodel.add(BatchNormalization())\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\n\nmodel.add(Conv2D(128, (3, 3), activation='relu'))\nmodel.add(BatchNormalization())\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\n\n# Camada Flatten para converter a sa\u00edda das camadas convolucionais em um vetor 1D\nmodel.add(Flatten())\n\n# Camadas totalmente conectadas\nmodel.add(Dense(128, activation='relu'))\nmodel.add(Dropout(0.5))\n\nmodel.add(Dense(64, activation='relu'))\nmodel.add(Dropout(0.5))\n\n# \u00daltima camada totalmente conectada com 10 sa\u00eddas (10 classes de categoria de imagem)\nmodel.add(Dense(10, activation='softmax'))\n\n# Compilando o modelo\nmodel.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n\n# Configurando a callback ModelCheckpoint\ncheckpoint = ModelCheckpoint('best_model.h5', \n                             monitor='val_accuracy', \n                             save_best_only=True, \n                             mode='max', \n                             verbose=1)\n\n# Configurando a callback EarlyStopping\nearly_stopping = EarlyStopping(monitor='val_loss', \n                               patience=10, \n                               verbose=1, \n                               restore_best_weights=True)\n\n# Configurando a callback ReduceLROnPlateau\nreduce_lr = ReduceLROnPlateau(monitor='val_loss', \n                              factor=0.2, \n                              patience=5, \n                              min_lr=0.001, \n                              verbose=1)\n\n# Configurando o data augmentation\ndatagen = ImageDataGenerator(\n    rotation_range=20,\n    width_shift_range=0.2,\n    height_shift_range=0.2,\n    horizontal_flip=True,\n    zoom_range=0.2\n)\n\n# Gerando dados de treinamento augmentados\ntrain_generator = datagen.flow(x_train, y_train, batch_size=32)\n\n# Treinando o modelo com as callbacks e data augmentation\nhistory = model.fit(train_generator, \n                    epochs=100, \n                    validation_data=(x_val, y_val), \n                    callbacks=[checkpoint, early_stopping, reduce_lr])\n\n# Resumo do modelo\nmodel.summary()\n</code></pre>"},{"location":"aulas/IA/lab11/index.html#carregando-imagens-de-um-diretorio","title":"Carregando imagens de um diret\u00f3rio","text":"<p>Podemos utilizar o TensorFlow para carregar e pr\u00e9-processar os dados com o <code>image_dataset_from_directory</code>. </p> <p>Para funcionar corretamente as imagens devem estar dispostas da seguinte forma:</p> <pre><code> dataset_dir/\n    \u251c\u2500\u2500 class_1/\n    \u2502   \u251c\u2500\u2500 image1.jpg\n    \u2502   \u251c\u2500\u2500 image2.jpg\n    \u2502   \u2514\u2500\u2500 ...\n    \u251c\u2500\u2500 class_2/\n    \u2502   \u251c\u2500\u2500 image1.jpg\n    \u2502   \u251c\u2500\u2500 image2.jpg\n    \u2502   \u2514\u2500\u2500 ...\n    \u2514\u2500\u2500 class_n/\n        \u251c\u2500\u2500 image1.jpg\n        \u251c\u2500\u2500 image2.jpg\n        \u2514\u2500\u2500 ...\n</code></pre> <p>Aqui est\u00e1 um exemplo de como fazer isso:</p> <pre><code>import tensorflow as tf\nfrom tensorflow.keras.preprocessing import image_dataset_from_directory\n\n# Define o caminho para o diret\u00f3rio onde as imagens est\u00e3o organizadas em subpastas\ndataset_dir = \"caminho/para/seu/dataset\"\n\n# Carrega o dataset e divide em treino e valida\u00e7\u00e3o\ntrain_dataset = image_dataset_from_directory(\n    dataset_dir,\n    validation_split=0.2,\n    subset=\"training\",\n    seed=123,\n    image_size=(224, 224),  # Redimensiona as imagens para 224x224\n    batch_size=32\n)\n\nvalidation_dataset = image_dataset_from_directory(\n    dataset_dir,\n    validation_split=0.2,\n    subset=\"validation\",\n    seed=123,\n    image_size=(224, 224),\n    batch_size=32\n)\n\n# Normaliza os valores dos pixels para o intervalo [0, 1]\nnormalization_layer = tf.keras.layers.Rescaling(1./255)\n\nnormalized_train_dataset = train_dataset.map(lambda x, y: (normalization_layer(x), y))\nnormalized_validation_dataset = validation_dataset.map(lambda x, y: (normalization_layer(x), y))\n</code></pre>"},{"location":"aulas/IA/lab11/cnn_completo.html","title":"Cnn completo","text":"In\u00a0[5]: Copied! <pre>from google.colab import drive\ndrive.mount('/content/drive')\n\n# Vamos definir o caminho onde o modelo ser\u00e1 salvo no Google Drive\nmodel_save_path = '/content/drive/MyDrive/checkpoints/cifar10_best_model.h5'\n</pre> from google.colab import drive drive.mount('/content/drive')  # Vamos definir o caminho onde o modelo ser\u00e1 salvo no Google Drive model_save_path = '/content/drive/MyDrive/checkpoints/cifar10_best_model.h5'  <pre>Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n</pre> In\u00a0[6]: Copied! <pre>import tensorflow as tf\nfrom tensorflow.keras.datasets import cifar10\nfrom tensorflow.keras.utils import to_categorical\n\n# Carregando o conjunto de dados CIFAR-10\n(x_train, y_train), (x_val, y_val) = cifar10.load_data()\n\n# Normalizando os valores dos pixels para o intervalo [0, 1]\nx_train = x_train.astype('float32') / 255.0\nx_val = x_val.astype('float32') / 255.0\n\n# Convertendo os r\u00f3tulos para vetores one-hot\ny_train = to_categorical(y_train, 10)\ny_val = to_categorical(y_val, 10)\n</pre> import tensorflow as tf from tensorflow.keras.datasets import cifar10 from tensorflow.keras.utils import to_categorical  # Carregando o conjunto de dados CIFAR-10 (x_train, y_train), (x_val, y_val) = cifar10.load_data()  # Normalizando os valores dos pixels para o intervalo [0, 1] x_train = x_train.astype('float32') / 255.0 x_val = x_val.astype('float32') / 255.0  # Convertendo os r\u00f3tulos para vetores one-hot y_train = to_categorical(y_train, 10) y_val = to_categorical(y_val, 10)  In\u00a0[7]: Copied! <pre>from tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization\nfrom tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\n\n# Definindo o modelo\nmodel = Sequential()\n\n# Camadas convolucionais com n\u00famero crescente de filtros\nmodel.add(Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3)))\nmodel.add(BatchNormalization())\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\n\nmodel.add(Conv2D(64, (3, 3), activation='relu'))\nmodel.add(BatchNormalization())\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\n\nmodel.add(Conv2D(128, (3, 3), activation='relu'))\nmodel.add(BatchNormalization())\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\n\n# Camada Flatten para converter a sa\u00edda das camadas convolucionais em um vetor 1D\nmodel.add(Flatten())\n\n# Camadas totalmente conectadas\nmodel.add(Dense(128, activation='relu'))\nmodel.add(Dropout(0.5))\n\nmodel.add(Dense(64, activation='relu'))\nmodel.add(Dropout(0.5))\n\n# \u00daltima camada totalmente conectada com 10 sa\u00eddas (10 classes de categoria de imagem)\nmodel.add(Dense(10, activation='softmax'))\n\n# Compilando o modelo\nmodel.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n\n# Resumo do modelo\nmodel.summary()\n</pre> from tensorflow.keras.models import Sequential from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau from tensorflow.keras.preprocessing.image import ImageDataGenerator  # Definindo o modelo model = Sequential()  # Camadas convolucionais com n\u00famero crescente de filtros model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3))) model.add(BatchNormalization()) model.add(MaxPooling2D(pool_size=(2, 2)))  model.add(Conv2D(64, (3, 3), activation='relu')) model.add(BatchNormalization()) model.add(MaxPooling2D(pool_size=(2, 2)))  model.add(Conv2D(128, (3, 3), activation='relu')) model.add(BatchNormalization()) model.add(MaxPooling2D(pool_size=(2, 2)))  # Camada Flatten para converter a sa\u00edda das camadas convolucionais em um vetor 1D model.add(Flatten())  # Camadas totalmente conectadas model.add(Dense(128, activation='relu')) model.add(Dropout(0.5))  model.add(Dense(64, activation='relu')) model.add(Dropout(0.5))  # \u00daltima camada totalmente conectada com 10 sa\u00eddas (10 classes de categoria de imagem) model.add(Dense(10, activation='softmax'))  # Compilando o modelo model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])  # Resumo do modelo model.summary()  <pre>Model: \"sequential_1\"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\n conv2d_3 (Conv2D)           (None, 30, 30, 32)        896       \n                                                                 \n batch_normalization_3 (Bat  (None, 30, 30, 32)        128       \n chNormalization)                                                \n                                                                 \n max_pooling2d_3 (MaxPoolin  (None, 15, 15, 32)        0         \n g2D)                                                            \n                                                                 \n conv2d_4 (Conv2D)           (None, 13, 13, 64)        18496     \n                                                                 \n batch_normalization_4 (Bat  (None, 13, 13, 64)        256       \n chNormalization)                                                \n                                                                 \n max_pooling2d_4 (MaxPoolin  (None, 6, 6, 64)          0         \n g2D)                                                            \n                                                                 \n conv2d_5 (Conv2D)           (None, 4, 4, 128)         73856     \n                                                                 \n batch_normalization_5 (Bat  (None, 4, 4, 128)         512       \n chNormalization)                                                \n                                                                 \n max_pooling2d_5 (MaxPoolin  (None, 2, 2, 128)         0         \n g2D)                                                            \n                                                                 \n flatten_1 (Flatten)         (None, 512)               0         \n                                                                 \n dense_3 (Dense)             (None, 128)               65664     \n                                                                 \n dropout_2 (Dropout)         (None, 128)               0         \n                                                                 \n dense_4 (Dense)             (None, 64)                8256      \n                                                                 \n dropout_3 (Dropout)         (None, 64)                0         \n                                                                 \n dense_5 (Dense)             (None, 10)                650       \n                                                                 \n=================================================================\nTotal params: 168714 (659.04 KB)\nTrainable params: 168266 (657.29 KB)\nNon-trainable params: 448 (1.75 KB)\n_________________________________________________________________\n</pre> In\u00a0[8]: Copied! <pre># Configurando a callback ModelCheckpoint para salvar o modelo no google drive\ncheckpoint = ModelCheckpoint(model_save_path,\n                             monitor='val_accuracy',\n                             save_best_only=True,\n                             mode='max',\n                             verbose=1)\n\n# Configurando a callback EarlyStopping\nearly_stopping = EarlyStopping(monitor='val_loss',\n                               patience=10,\n                               verbose=1,\n                               restore_best_weights=True)\n\n# Configurando a callback ReduceLROnPlateau\nreduce_lr = ReduceLROnPlateau(monitor='val_loss',\n                              factor=0.2,\n                              patience=5,\n                              min_lr=0.001,\n                              verbose=1)\n</pre> # Configurando a callback ModelCheckpoint para salvar o modelo no google drive checkpoint = ModelCheckpoint(model_save_path,                              monitor='val_accuracy',                              save_best_only=True,                              mode='max',                              verbose=1)  # Configurando a callback EarlyStopping early_stopping = EarlyStopping(monitor='val_loss',                                patience=10,                                verbose=1,                                restore_best_weights=True)  # Configurando a callback ReduceLROnPlateau reduce_lr = ReduceLROnPlateau(monitor='val_loss',                               factor=0.2,                               patience=5,                               min_lr=0.001,                               verbose=1)  In\u00a0[9]: Copied! <pre># Configurando o data augmentation\ndatagen = ImageDataGenerator(\n    rotation_range=20,\n    width_shift_range=0.2,\n    height_shift_range=0.2,\n    horizontal_flip=True,\n    zoom_range=0.2\n)\n\n# Gerando dados de treinamento augmentados\ntrain_generator = datagen.flow(x_train, y_train, batch_size=32)\n</pre> # Configurando o data augmentation datagen = ImageDataGenerator(     rotation_range=20,     width_shift_range=0.2,     height_shift_range=0.2,     horizontal_flip=True,     zoom_range=0.2 )  # Gerando dados de treinamento augmentados train_generator = datagen.flow(x_train, y_train, batch_size=32)  In\u00a0[10]: Copied! <pre># Treinando o modelo com as callbacks e data augmentation\nhistory = model.fit(train_generator,\n                    epochs=100,\n                    validation_data=(x_val, y_val),\n                    callbacks=[checkpoint, early_stopping, reduce_lr])\n</pre> # Treinando o modelo com as callbacks e data augmentation history = model.fit(train_generator,                     epochs=100,                     validation_data=(x_val, y_val),                     callbacks=[checkpoint, early_stopping, reduce_lr])  <pre>Epoch 1/100\n1562/1563 [============================&gt;.] - ETA: 0s - loss: 2.0423 - accuracy: 0.2451\nEpoch 1: val_accuracy improved from -inf to 0.28590, saving model to /content/drive/MyDrive/checkpoints/cifar10_best_model.h5\n1563/1563 [==============================] - 43s 23ms/step - loss: 2.0421 - accuracy: 0.2451 - val_loss: 2.0514 - val_accuracy: 0.2859 - lr: 0.0010\nEpoch 2/100\n   1/1563 [..............................] - ETA: 52s - loss: 1.8313 - accuracy: 0.1562</pre> <pre>/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n  saving_api.save_model(\n</pre> <pre>1561/1563 [============================&gt;.] - ETA: 0s - loss: 1.7979 - accuracy: 0.3332\nEpoch 2: val_accuracy improved from 0.28590 to 0.45100, saving model to /content/drive/MyDrive/checkpoints/cifar10_best_model.h5\n1563/1563 [==============================] - 36s 23ms/step - loss: 1.7977 - accuracy: 0.3333 - val_loss: 1.4733 - val_accuracy: 0.4510 - lr: 0.0010\nEpoch 3/100\n1561/1563 [============================&gt;.] - ETA: 0s - loss: 1.6728 - accuracy: 0.3916\nEpoch 3: val_accuracy improved from 0.45100 to 0.48650, saving model to /content/drive/MyDrive/checkpoints/cifar10_best_model.h5\n1563/1563 [==============================] - 37s 23ms/step - loss: 1.6729 - accuracy: 0.3917 - val_loss: 1.3924 - val_accuracy: 0.4865 - lr: 0.0010\nEpoch 4/100\n1562/1563 [============================&gt;.] - ETA: 0s - loss: 1.6007 - accuracy: 0.4219\nEpoch 4: val_accuracy did not improve from 0.48650\n1563/1563 [==============================] - 37s 23ms/step - loss: 1.6007 - accuracy: 0.4219 - val_loss: 1.5411 - val_accuracy: 0.4524 - lr: 0.0010\nEpoch 5/100\n1563/1563 [==============================] - ETA: 0s - loss: 1.5361 - accuracy: 0.4527\nEpoch 5: val_accuracy improved from 0.48650 to 0.49570, saving model to /content/drive/MyDrive/checkpoints/cifar10_best_model.h5\n1563/1563 [==============================] - 36s 23ms/step - loss: 1.5361 - accuracy: 0.4527 - val_loss: 1.4323 - val_accuracy: 0.4957 - lr: 0.0010\nEpoch 6/100\n1562/1563 [============================&gt;.] - ETA: 0s - loss: 1.4981 - accuracy: 0.4708\nEpoch 6: val_accuracy did not improve from 0.49570\n1563/1563 [==============================] - 35s 22ms/step - loss: 1.4981 - accuracy: 0.4708 - val_loss: 1.4484 - val_accuracy: 0.4790 - lr: 0.0010\nEpoch 7/100\n1562/1563 [============================&gt;.] - ETA: 0s - loss: 1.4468 - accuracy: 0.4942\nEpoch 7: val_accuracy improved from 0.49570 to 0.56870, saving model to /content/drive/MyDrive/checkpoints/cifar10_best_model.h5\n1563/1563 [==============================] - 35s 23ms/step - loss: 1.4468 - accuracy: 0.4941 - val_loss: 1.1967 - val_accuracy: 0.5687 - lr: 0.0010\nEpoch 8/100\n1563/1563 [==============================] - ETA: 0s - loss: 1.4102 - accuracy: 0.5118\nEpoch 8: val_accuracy improved from 0.56870 to 0.60030, saving model to /content/drive/MyDrive/checkpoints/cifar10_best_model.h5\n1563/1563 [==============================] - 36s 23ms/step - loss: 1.4102 - accuracy: 0.5118 - val_loss: 1.1149 - val_accuracy: 0.6003 - lr: 0.0010\nEpoch 9/100\n1562/1563 [============================&gt;.] - ETA: 0s - loss: 1.3760 - accuracy: 0.5249\nEpoch 9: val_accuracy did not improve from 0.60030\n1563/1563 [==============================] - 34s 22ms/step - loss: 1.3763 - accuracy: 0.5249 - val_loss: 1.2569 - val_accuracy: 0.5386 - lr: 0.0010\nEpoch 10/100\n1562/1563 [============================&gt;.] - ETA: 0s - loss: 1.3509 - accuracy: 0.5376\nEpoch 10: val_accuracy improved from 0.60030 to 0.63180, saving model to /content/drive/MyDrive/checkpoints/cifar10_best_model.h5\n1563/1563 [==============================] - 35s 22ms/step - loss: 1.3510 - accuracy: 0.5376 - val_loss: 1.0326 - val_accuracy: 0.6318 - lr: 0.0010\nEpoch 11/100\n1563/1563 [==============================] - ETA: 0s - loss: 1.3254 - accuracy: 0.5463\nEpoch 11: val_accuracy did not improve from 0.63180\n1563/1563 [==============================] - 36s 23ms/step - loss: 1.3254 - accuracy: 0.5463 - val_loss: 1.0348 - val_accuracy: 0.6258 - lr: 0.0010\nEpoch 12/100\n1562/1563 [============================&gt;.] - ETA: 0s - loss: 1.3049 - accuracy: 0.5532\nEpoch 12: val_accuracy did not improve from 0.63180\n1563/1563 [==============================] - 35s 23ms/step - loss: 1.3051 - accuracy: 0.5532 - val_loss: 1.1351 - val_accuracy: 0.6115 - lr: 0.0010\nEpoch 13/100\n1562/1563 [============================&gt;.] - ETA: 0s - loss: 1.2862 - accuracy: 0.5637\nEpoch 13: val_accuracy improved from 0.63180 to 0.63310, saving model to /content/drive/MyDrive/checkpoints/cifar10_best_model.h5\n1563/1563 [==============================] - 35s 22ms/step - loss: 1.2863 - accuracy: 0.5636 - val_loss: 1.0346 - val_accuracy: 0.6331 - lr: 0.0010\nEpoch 14/100\n1563/1563 [==============================] - ETA: 0s - loss: 1.2669 - accuracy: 0.5699\nEpoch 14: val_accuracy did not improve from 0.63310\n1563/1563 [==============================] - 35s 23ms/step - loss: 1.2669 - accuracy: 0.5699 - val_loss: 1.2640 - val_accuracy: 0.5506 - lr: 0.0010\nEpoch 15/100\n1561/1563 [============================&gt;.] - ETA: 0s - loss: 1.2572 - accuracy: 0.5741\nEpoch 15: val_accuracy did not improve from 0.63310\n1563/1563 [==============================] - 34s 22ms/step - loss: 1.2573 - accuracy: 0.5740 - val_loss: 1.1206 - val_accuracy: 0.6215 - lr: 0.0010\nEpoch 16/100\n1562/1563 [============================&gt;.] - ETA: 0s - loss: 1.2447 - accuracy: 0.5805\nEpoch 16: val_accuracy did not improve from 0.63310\n1563/1563 [==============================] - 35s 23ms/step - loss: 1.2446 - accuracy: 0.5805 - val_loss: 1.1991 - val_accuracy: 0.6057 - lr: 0.0010\nEpoch 17/100\n1562/1563 [============================&gt;.] - ETA: 0s - loss: 1.2226 - accuracy: 0.5873\nEpoch 17: val_accuracy improved from 0.63310 to 0.64720, saving model to /content/drive/MyDrive/checkpoints/cifar10_best_model.h5\n1563/1563 [==============================] - 35s 22ms/step - loss: 1.2227 - accuracy: 0.5873 - val_loss: 0.9827 - val_accuracy: 0.6472 - lr: 0.0010\nEpoch 18/100\n1562/1563 [============================&gt;.] - ETA: 0s - loss: 1.2050 - accuracy: 0.5965\nEpoch 18: val_accuracy did not improve from 0.64720\n1563/1563 [==============================] - 35s 22ms/step - loss: 1.2047 - accuracy: 0.5966 - val_loss: 1.0118 - val_accuracy: 0.6391 - lr: 0.0010\nEpoch 19/100\n1563/1563 [==============================] - ETA: 0s - loss: 1.1952 - accuracy: 0.5983\nEpoch 19: val_accuracy improved from 0.64720 to 0.65800, saving model to /content/drive/MyDrive/checkpoints/cifar10_best_model.h5\n1563/1563 [==============================] - 37s 23ms/step - loss: 1.1952 - accuracy: 0.5983 - val_loss: 0.9626 - val_accuracy: 0.6580 - lr: 0.0010\nEpoch 20/100\n1561/1563 [============================&gt;.] - ETA: 0s - loss: 1.1898 - accuracy: 0.6032\nEpoch 20: val_accuracy improved from 0.65800 to 0.68460, saving model to /content/drive/MyDrive/checkpoints/cifar10_best_model.h5\n1563/1563 [==============================] - 37s 24ms/step - loss: 1.1898 - accuracy: 0.6032 - val_loss: 0.9178 - val_accuracy: 0.6846 - lr: 0.0010\nEpoch 21/100\n1562/1563 [============================&gt;.] - ETA: 0s - loss: 1.1815 - accuracy: 0.6051\nEpoch 21: val_accuracy did not improve from 0.68460\n1563/1563 [==============================] - 37s 23ms/step - loss: 1.1815 - accuracy: 0.6051 - val_loss: 1.0920 - val_accuracy: 0.6279 - lr: 0.0010\nEpoch 22/100\n1563/1563 [==============================] - ETA: 0s - loss: 1.1674 - accuracy: 0.6085\nEpoch 22: val_accuracy improved from 0.68460 to 0.69460, saving model to /content/drive/MyDrive/checkpoints/cifar10_best_model.h5\n1563/1563 [==============================] - 36s 23ms/step - loss: 1.1674 - accuracy: 0.6085 - val_loss: 0.8778 - val_accuracy: 0.6946 - lr: 0.0010\nEpoch 23/100\n1563/1563 [==============================] - ETA: 0s - loss: 1.1468 - accuracy: 0.6188\nEpoch 23: val_accuracy improved from 0.69460 to 0.71950, saving model to /content/drive/MyDrive/checkpoints/cifar10_best_model.h5\n1563/1563 [==============================] - 36s 23ms/step - loss: 1.1468 - accuracy: 0.6188 - val_loss: 0.8091 - val_accuracy: 0.7195 - lr: 0.0010\nEpoch 24/100\n1563/1563 [==============================] - ETA: 0s - loss: 1.1462 - accuracy: 0.6197\nEpoch 24: val_accuracy did not improve from 0.71950\n1563/1563 [==============================] - 35s 23ms/step - loss: 1.1462 - accuracy: 0.6197 - val_loss: 0.9789 - val_accuracy: 0.6681 - lr: 0.0010\nEpoch 25/100\n1563/1563 [==============================] - ETA: 0s - loss: 1.1482 - accuracy: 0.6186\nEpoch 25: val_accuracy did not improve from 0.71950\n1563/1563 [==============================] - 36s 23ms/step - loss: 1.1482 - accuracy: 0.6186 - val_loss: 0.9466 - val_accuracy: 0.6623 - lr: 0.0010\nEpoch 26/100\n1562/1563 [============================&gt;.] - ETA: 0s - loss: 1.1343 - accuracy: 0.6254\nEpoch 26: val_accuracy did not improve from 0.71950\n1563/1563 [==============================] - 35s 23ms/step - loss: 1.1342 - accuracy: 0.6254 - val_loss: 0.8559 - val_accuracy: 0.7100 - lr: 0.0010\nEpoch 27/100\n1561/1563 [============================&gt;.] - ETA: 0s - loss: 1.1221 - accuracy: 0.6244\nEpoch 27: val_accuracy did not improve from 0.71950\n1563/1563 [==============================] - 36s 23ms/step - loss: 1.1218 - accuracy: 0.6245 - val_loss: 0.9000 - val_accuracy: 0.6829 - lr: 0.0010\nEpoch 28/100\n1562/1563 [============================&gt;.] - ETA: 0s - loss: 1.1122 - accuracy: 0.6333\nEpoch 28: val_accuracy did not improve from 0.71950\n1563/1563 [==============================] - 36s 23ms/step - loss: 1.1123 - accuracy: 0.6333 - val_loss: 0.8558 - val_accuracy: 0.7058 - lr: 0.0010\nEpoch 29/100\n1561/1563 [============================&gt;.] - ETA: 0s - loss: 1.1095 - accuracy: 0.6322\nEpoch 29: val_accuracy did not improve from 0.71950\n1563/1563 [==============================] - 36s 23ms/step - loss: 1.1096 - accuracy: 0.6322 - val_loss: 0.9187 - val_accuracy: 0.6892 - lr: 0.0010\nEpoch 30/100\n1563/1563 [==============================] - ETA: 0s - loss: 1.1052 - accuracy: 0.6344\nEpoch 30: val_accuracy did not improve from 0.71950\n1563/1563 [==============================] - 35s 22ms/step - loss: 1.1052 - accuracy: 0.6344 - val_loss: 0.8275 - val_accuracy: 0.7135 - lr: 0.0010\nEpoch 31/100\n1563/1563 [==============================] - ETA: 0s - loss: 1.1002 - accuracy: 0.6357\nEpoch 31: val_accuracy did not improve from 0.71950\n1563/1563 [==============================] - 35s 23ms/step - loss: 1.1002 - accuracy: 0.6357 - val_loss: 1.0448 - val_accuracy: 0.6508 - lr: 0.0010\nEpoch 32/100\n1563/1563 [==============================] - ETA: 0s - loss: 1.0892 - accuracy: 0.6390\nEpoch 32: val_accuracy did not improve from 0.71950\n1563/1563 [==============================] - 36s 23ms/step - loss: 1.0892 - accuracy: 0.6390 - val_loss: 0.8500 - val_accuracy: 0.7127 - lr: 0.0010\nEpoch 33/100\n1563/1563 [==============================] - ETA: 0s - loss: 1.0825 - accuracy: 0.6395\nEpoch 33: val_accuracy improved from 0.71950 to 0.73240, saving model to /content/drive/MyDrive/checkpoints/cifar10_best_model.h5\n1563/1563 [==============================] - 35s 22ms/step - loss: 1.0825 - accuracy: 0.6395 - val_loss: 0.7995 - val_accuracy: 0.7324 - lr: 0.0010\nEpoch 34/100\n1562/1563 [============================&gt;.] - ETA: 0s - loss: 1.0815 - accuracy: 0.6441\nEpoch 34: val_accuracy did not improve from 0.73240\n1563/1563 [==============================] - 36s 23ms/step - loss: 1.0817 - accuracy: 0.6440 - val_loss: 0.7821 - val_accuracy: 0.7324 - lr: 0.0010\nEpoch 35/100\n1562/1563 [============================&gt;.] - ETA: 0s - loss: 1.0743 - accuracy: 0.6473\nEpoch 35: val_accuracy did not improve from 0.73240\n1563/1563 [==============================] - 36s 23ms/step - loss: 1.0742 - accuracy: 0.6473 - val_loss: 0.7895 - val_accuracy: 0.7282 - lr: 0.0010\nEpoch 36/100\n1562/1563 [============================&gt;.] - ETA: 0s - loss: 1.0695 - accuracy: 0.6486\nEpoch 36: val_accuracy did not improve from 0.73240\n1563/1563 [==============================] - 37s 24ms/step - loss: 1.0693 - accuracy: 0.6487 - val_loss: 0.8054 - val_accuracy: 0.7223 - lr: 0.0010\nEpoch 37/100\n1562/1563 [============================&gt;.] - ETA: 0s - loss: 1.0633 - accuracy: 0.6510\nEpoch 37: val_accuracy improved from 0.73240 to 0.73660, saving model to /content/drive/MyDrive/checkpoints/cifar10_best_model.h5\n1563/1563 [==============================] - 35s 23ms/step - loss: 1.0631 - accuracy: 0.6511 - val_loss: 0.7637 - val_accuracy: 0.7366 - lr: 0.0010\nEpoch 38/100\n1562/1563 [============================&gt;.] - ETA: 0s - loss: 1.0701 - accuracy: 0.6509\nEpoch 38: val_accuracy did not improve from 0.73660\n1563/1563 [==============================] - 37s 23ms/step - loss: 1.0701 - accuracy: 0.6509 - val_loss: 0.8457 - val_accuracy: 0.7136 - lr: 0.0010\nEpoch 39/100\n1561/1563 [============================&gt;.] - ETA: 0s - loss: 1.0467 - accuracy: 0.6584\nEpoch 39: val_accuracy did not improve from 0.73660\n1563/1563 [==============================] - 38s 24ms/step - loss: 1.0463 - accuracy: 0.6585 - val_loss: 0.8873 - val_accuracy: 0.7043 - lr: 0.0010\nEpoch 40/100\n1562/1563 [============================&gt;.] - ETA: 0s - loss: 1.0546 - accuracy: 0.6548\nEpoch 40: val_accuracy did not improve from 0.73660\n1563/1563 [==============================] - 37s 24ms/step - loss: 1.0547 - accuracy: 0.6547 - val_loss: 0.8820 - val_accuracy: 0.6985 - lr: 0.0010\nEpoch 41/100\n1561/1563 [============================&gt;.] - ETA: 0s - loss: 1.0483 - accuracy: 0.6572\nEpoch 41: val_accuracy did not improve from 0.73660\n1563/1563 [==============================] - 37s 24ms/step - loss: 1.0483 - accuracy: 0.6572 - val_loss: 1.1795 - val_accuracy: 0.6351 - lr: 0.0010\nEpoch 42/100\n1563/1563 [==============================] - ETA: 0s - loss: 1.0463 - accuracy: 0.6583\nEpoch 42: val_accuracy improved from 0.73660 to 0.74890, saving model to /content/drive/MyDrive/checkpoints/cifar10_best_model.h5\n1563/1563 [==============================] - 35s 22ms/step - loss: 1.0463 - accuracy: 0.6583 - val_loss: 0.7433 - val_accuracy: 0.7489 - lr: 0.0010\nEpoch 43/100\n1563/1563 [==============================] - ETA: 0s - loss: 1.0436 - accuracy: 0.6599\nEpoch 43: val_accuracy did not improve from 0.74890\n1563/1563 [==============================] - 38s 25ms/step - loss: 1.0436 - accuracy: 0.6599 - val_loss: 0.8552 - val_accuracy: 0.7113 - lr: 0.0010\nEpoch 44/100\n1563/1563 [==============================] - ETA: 0s - loss: 1.0321 - accuracy: 0.6626\nEpoch 44: val_accuracy did not improve from 0.74890\n1563/1563 [==============================] - 36s 23ms/step - loss: 1.0321 - accuracy: 0.6626 - val_loss: 0.7819 - val_accuracy: 0.7274 - lr: 0.0010\nEpoch 45/100\n1562/1563 [============================&gt;.] - ETA: 0s - loss: 1.0337 - accuracy: 0.6601\nEpoch 45: val_accuracy did not improve from 0.74890\n1563/1563 [==============================] - 36s 23ms/step - loss: 1.0336 - accuracy: 0.6602 - val_loss: 0.7743 - val_accuracy: 0.7347 - lr: 0.0010\nEpoch 46/100\n1563/1563 [==============================] - ETA: 0s - loss: 1.0330 - accuracy: 0.6638\nEpoch 46: val_accuracy improved from 0.74890 to 0.75150, saving model to /content/drive/MyDrive/checkpoints/cifar10_best_model.h5\n1563/1563 [==============================] - 36s 23ms/step - loss: 1.0330 - accuracy: 0.6638 - val_loss: 0.7259 - val_accuracy: 0.7515 - lr: 0.0010\nEpoch 47/100\n1561/1563 [============================&gt;.] - ETA: 0s - loss: 1.0208 - accuracy: 0.6666\nEpoch 47: val_accuracy improved from 0.75150 to 0.76160, saving model to /content/drive/MyDrive/checkpoints/cifar10_best_model.h5\n1563/1563 [==============================] - 35s 23ms/step - loss: 1.0209 - accuracy: 0.6665 - val_loss: 0.7046 - val_accuracy: 0.7616 - lr: 0.0010\nEpoch 48/100\n1562/1563 [============================&gt;.] - ETA: 0s - loss: 1.0166 - accuracy: 0.6695\nEpoch 48: val_accuracy did not improve from 0.76160\n1563/1563 [==============================] - 35s 22ms/step - loss: 1.0166 - accuracy: 0.6695 - val_loss: 0.9199 - val_accuracy: 0.6951 - lr: 0.0010\nEpoch 49/100\n1561/1563 [============================&gt;.] - ETA: 0s - loss: 1.0137 - accuracy: 0.6683\nEpoch 49: val_accuracy did not improve from 0.76160\n1563/1563 [==============================] - 35s 23ms/step - loss: 1.0139 - accuracy: 0.6682 - val_loss: 0.7090 - val_accuracy: 0.7582 - lr: 0.0010\nEpoch 50/100\n1561/1563 [============================&gt;.] - ETA: 0s - loss: 1.0255 - accuracy: 0.6638\nEpoch 50: val_accuracy did not improve from 0.76160\n1563/1563 [==============================] - 35s 22ms/step - loss: 1.0254 - accuracy: 0.6638 - val_loss: 0.7449 - val_accuracy: 0.7444 - lr: 0.0010\nEpoch 51/100\n1563/1563 [==============================] - ETA: 0s - loss: 1.0145 - accuracy: 0.6688\nEpoch 51: val_accuracy did not improve from 0.76160\n1563/1563 [==============================] - 38s 24ms/step - loss: 1.0145 - accuracy: 0.6688 - val_loss: 0.8169 - val_accuracy: 0.7207 - lr: 0.0010\nEpoch 52/100\n1563/1563 [==============================] - ETA: 0s - loss: 1.0186 - accuracy: 0.6681\nEpoch 52: val_accuracy did not improve from 0.76160\n1563/1563 [==============================] - 37s 24ms/step - loss: 1.0186 - accuracy: 0.6681 - val_loss: 0.7924 - val_accuracy: 0.7355 - lr: 0.0010\nEpoch 53/100\n1561/1563 [============================&gt;.] - ETA: 0s - loss: 1.0113 - accuracy: 0.6686\nEpoch 53: val_accuracy did not improve from 0.76160\n1563/1563 [==============================] - 36s 23ms/step - loss: 1.0113 - accuracy: 0.6685 - val_loss: 0.7319 - val_accuracy: 0.7498 - lr: 0.0010\nEpoch 54/100\n1563/1563 [==============================] - ETA: 0s - loss: 1.0109 - accuracy: 0.6712\nEpoch 54: val_accuracy did not improve from 0.76160\n1563/1563 [==============================] - 36s 23ms/step - loss: 1.0109 - accuracy: 0.6712 - val_loss: 1.0983 - val_accuracy: 0.6648 - lr: 0.0010\nEpoch 55/100\n1561/1563 [============================&gt;.] - ETA: 0s - loss: 1.0129 - accuracy: 0.6713\nEpoch 55: val_accuracy did not improve from 0.76160\n1563/1563 [==============================] - 36s 23ms/step - loss: 1.0129 - accuracy: 0.6713 - val_loss: 0.8429 - val_accuracy: 0.7179 - lr: 0.0010\nEpoch 56/100\n1561/1563 [============================&gt;.] - ETA: 0s - loss: 0.9992 - accuracy: 0.6728\nEpoch 56: val_accuracy did not improve from 0.76160\n1563/1563 [==============================] - 37s 23ms/step - loss: 0.9993 - accuracy: 0.6729 - val_loss: 0.8258 - val_accuracy: 0.7244 - lr: 0.0010\nEpoch 57/100\n1563/1563 [==============================] - ETA: 0s - loss: 0.9956 - accuracy: 0.6758\nEpoch 57: val_accuracy improved from 0.76160 to 0.77110, saving model to /content/drive/MyDrive/checkpoints/cifar10_best_model.h5\n1563/1563 [==============================] - 37s 24ms/step - loss: 0.9956 - accuracy: 0.6758 - val_loss: 0.6726 - val_accuracy: 0.7711 - lr: 0.0010\nEpoch 58/100\n1563/1563 [==============================] - ETA: 0s - loss: 1.0006 - accuracy: 0.6737\nEpoch 58: val_accuracy did not improve from 0.77110\n1563/1563 [==============================] - 36s 23ms/step - loss: 1.0006 - accuracy: 0.6737 - val_loss: 0.8017 - val_accuracy: 0.7251 - lr: 0.0010\nEpoch 59/100\n1563/1563 [==============================] - ETA: 0s - loss: 0.9981 - accuracy: 0.6732\nEpoch 59: val_accuracy did not improve from 0.77110\n1563/1563 [==============================] - 37s 24ms/step - loss: 0.9981 - accuracy: 0.6732 - val_loss: 0.7429 - val_accuracy: 0.7520 - lr: 0.0010\nEpoch 60/100\n1562/1563 [============================&gt;.] - ETA: 0s - loss: 0.9920 - accuracy: 0.6789\nEpoch 60: val_accuracy did not improve from 0.77110\n1563/1563 [==============================] - 38s 24ms/step - loss: 0.9920 - accuracy: 0.6789 - val_loss: 0.7769 - val_accuracy: 0.7382 - lr: 0.0010\nEpoch 61/100\n1563/1563 [==============================] - ETA: 0s - loss: 0.9926 - accuracy: 0.6794\nEpoch 61: val_accuracy did not improve from 0.77110\n1563/1563 [==============================] - 36s 23ms/step - loss: 0.9926 - accuracy: 0.6794 - val_loss: 0.8365 - val_accuracy: 0.7146 - lr: 0.0010\nEpoch 62/100\n1563/1563 [==============================] - ETA: 0s - loss: 0.9928 - accuracy: 0.6751\nEpoch 62: val_accuracy did not improve from 0.77110\n1563/1563 [==============================] - 37s 23ms/step - loss: 0.9928 - accuracy: 0.6751 - val_loss: 0.7080 - val_accuracy: 0.7619 - lr: 0.0010\nEpoch 63/100\n1562/1563 [============================&gt;.] - ETA: 0s - loss: 0.9901 - accuracy: 0.6787\nEpoch 63: val_accuracy did not improve from 0.77110\n1563/1563 [==============================] - 36s 23ms/step - loss: 0.9901 - accuracy: 0.6787 - val_loss: 0.8295 - val_accuracy: 0.7269 - lr: 0.0010\nEpoch 64/100\n1562/1563 [============================&gt;.] - ETA: 0s - loss: 0.9890 - accuracy: 0.6796\nEpoch 64: val_accuracy did not improve from 0.77110\n1563/1563 [==============================] - 37s 24ms/step - loss: 0.9888 - accuracy: 0.6796 - val_loss: 0.7512 - val_accuracy: 0.7521 - lr: 0.0010\nEpoch 65/100\n1563/1563 [==============================] - ETA: 0s - loss: 0.9867 - accuracy: 0.6767\nEpoch 65: val_accuracy did not improve from 0.77110\n1563/1563 [==============================] - 35s 23ms/step - loss: 0.9867 - accuracy: 0.6767 - val_loss: 0.7518 - val_accuracy: 0.7448 - lr: 0.0010\nEpoch 66/100\n1562/1563 [============================&gt;.] - ETA: 0s - loss: 0.9789 - accuracy: 0.6827\nEpoch 66: val_accuracy did not improve from 0.77110\n1563/1563 [==============================] - 37s 24ms/step - loss: 0.9788 - accuracy: 0.6828 - val_loss: 0.7259 - val_accuracy: 0.7563 - lr: 0.0010\nEpoch 67/100\n1562/1563 [============================&gt;.] - ETA: 0s - loss: 0.9799 - accuracy: 0.6839\nEpoch 67: val_accuracy did not improve from 0.77110\nRestoring model weights from the end of the best epoch: 57.\n1563/1563 [==============================] - 37s 24ms/step - loss: 0.9799 - accuracy: 0.6838 - val_loss: 0.8824 - val_accuracy: 0.7192 - lr: 0.0010\nEpoch 67: early stopping\n</pre> In\u00a0[20]: Copied! <pre>from matplotlib import pyplot as plt\n\n## exibe history com plot de loss e\n#acuracia\ndef plot_history(history):\n  # summarize history for loss\n  plt.plot(history.history['loss'])\n  plt.plot(history.history['val_loss'])\n  plt.title('Model loss')\n  plt.ylabel('loss')\n  plt.xlabel('epoch')\n  plt.legend(['train', 'test'], loc='upper left')\n  plt.show()\n  # summarize history for accuracy\n  plt.plot(history.history['accuracy'])\n  plt.plot(history.history['val_accuracy'])\n  plt.title('model accuracy')\n  plt.ylabel('accuracy')\n  plt.xlabel('epoch')\n  plt.legend(['train', 'test'], loc='upper left')\n  plt.show()\n\nplot_history(history)\n</pre> from matplotlib import pyplot as plt  ## exibe history com plot de loss e #acuracia def plot_history(history):   # summarize history for loss   plt.plot(history.history['loss'])   plt.plot(history.history['val_loss'])   plt.title('Model loss')   plt.ylabel('loss')   plt.xlabel('epoch')   plt.legend(['train', 'test'], loc='upper left')   plt.show()   # summarize history for accuracy   plt.plot(history.history['accuracy'])   plt.plot(history.history['val_accuracy'])   plt.title('model accuracy')   plt.ylabel('accuracy')   plt.xlabel('epoch')   plt.legend(['train', 'test'], loc='upper left')   plt.show()  plot_history(history)  In\u00a0[11]: Copied! <pre># Carregando o conjunto de dados de teste CIFAR-10\n(x_test, y_test) = cifar10.load_data()[1]\n\n# Normalizando os valores dos pixels para o intervalo [0, 1]\nx_test = x_test.astype('float32') / 255.0\n\n# Convertendo os r\u00f3tulos para vetores one-hot\ny_test = to_categorical(y_test, 10)\n</pre> # Carregando o conjunto de dados de teste CIFAR-10 (x_test, y_test) = cifar10.load_data()[1]  # Normalizando os valores dos pixels para o intervalo [0, 1] x_test = x_test.astype('float32') / 255.0  # Convertendo os r\u00f3tulos para vetores one-hot y_test = to_categorical(y_test, 10)  In\u00a0[13]: Copied! <pre># Carregando o melhor modelo salvo durante o treinamento\nbest_model = tf.keras.models.load_model(model_save_path)\n\n# Avaliando o melhor modelo salvo nos dados de teste\nbest_test_loss, best_test_accuracy = best_model.evaluate(x_test, y_test, verbose=2)\nprint(f'Best test loss: {best_test_loss}')\nprint(f'Best test accuracy: {best_test_accuracy}')\n</pre> # Carregando o melhor modelo salvo durante o treinamento best_model = tf.keras.models.load_model(model_save_path)  # Avaliando o melhor modelo salvo nos dados de teste best_test_loss, best_test_accuracy = best_model.evaluate(x_test, y_test, verbose=2) print(f'Best test loss: {best_test_loss}') print(f'Best test accuracy: {best_test_accuracy}')  <pre>313/313 - 1s - loss: 0.6726 - accuracy: 0.7711 - 1s/epoch - 4ms/step\nBest test loss: 0.6726096868515015\nBest test accuracy: 0.7710999846458435\n</pre> In\u00a0[21]: Copied! <pre>import numpy as np\n\n# Fazendo previs\u00f5es no conjunto de dados de teste\npredictions = best_model.predict(x_test)\npredicted_classes = np.argmax(predictions, axis=1)\ntrue_classes = np.argmax(y_test, axis=1)\n\n# Nomes das classes CIFAR-10\nclass_names = ['Airplane', 'Automobile', 'Bird', 'Cat', 'Deer', 'Dog', 'Frog', 'Horse', 'Ship', 'Truck']\n</pre> import numpy as np  # Fazendo previs\u00f5es no conjunto de dados de teste predictions = best_model.predict(x_test) predicted_classes = np.argmax(predictions, axis=1) true_classes = np.argmax(y_test, axis=1)  # Nomes das classes CIFAR-10 class_names = ['Airplane', 'Automobile', 'Bird', 'Cat', 'Deer', 'Dog', 'Frog', 'Horse', 'Ship', 'Truck'] <pre>313/313 [==============================] - 1s 2ms/step\n</pre> In\u00a0[23]: Copied! <pre>import seaborn as sns\nfrom sklearn.metrics import confusion_matrix\n\n# Fun\u00e7\u00e3o para plotar a matriz de confus\u00e3o\ndef plot_confusion_matrix(true_labels, predicted_labels, class_names):\n    cm = confusion_matrix(true_labels, predicted_labels)\n    plt.figure(figsize=(10, 8))\n    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=class_names, yticklabels=class_names)\n    plt.xlabel('Predicted')\n    plt.ylabel('True')\n    plt.show()\n\n\n# Visualizando a matriz de confus\u00e3o\nprint(\"Matriz de Confus\u00e3o:\")\nplot_confusion_matrix(true_classes, predicted_classes, class_names)\n</pre> import seaborn as sns from sklearn.metrics import confusion_matrix  # Fun\u00e7\u00e3o para plotar a matriz de confus\u00e3o def plot_confusion_matrix(true_labels, predicted_labels, class_names):     cm = confusion_matrix(true_labels, predicted_labels)     plt.figure(figsize=(10, 8))     sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=class_names, yticklabels=class_names)     plt.xlabel('Predicted')     plt.ylabel('True')     plt.show()   # Visualizando a matriz de confus\u00e3o print(\"Matriz de Confus\u00e3o:\") plot_confusion_matrix(true_classes, predicted_classes, class_names) <pre>Matriz de Confus\u00e3o:\n</pre> In\u00a0[25]: Copied! <pre>import matplotlib.pyplot as plt\n\n# Fun\u00e7\u00e3o para plotar imagens com r\u00f3tulos verdadeiros e previstos\ndef plot_images(images, true_labels, predicted_labels, class_names, num_images=10):\n    plt.figure(figsize=(15, 15))\n    for i in range(num_images):\n        plt.subplot(5, 5, i + 1)\n        plt.imshow(images[i])\n        plt.title(f'True: {class_names[true_labels[i]]}\\nPred: {class_names[predicted_labels[i]]}')\n        plt.axis('off')\n    plt.show()\n\n# Fun\u00e7\u00e3o para plotar imagens de resultados corretos\ndef plot_correct_predictions(images, true_labels, predicted_labels, class_names):\n    correct_indices = np.where(predicted_labels == true_labels)[0]\n    plot_images(images[correct_indices], true_labels[correct_indices], predicted_labels[correct_indices], class_names)\n\n# Fun\u00e7\u00e3o para plotar imagens de resultados incorretos\ndef plot_incorrect_predictions(images, true_labels, predicted_labels, class_names):\n    incorrect_indices = np.where(predicted_labels != true_labels)[0]\n    plot_images(images[incorrect_indices], true_labels[incorrect_indices], predicted_labels[incorrect_indices], class_names)\n</pre> import matplotlib.pyplot as plt  # Fun\u00e7\u00e3o para plotar imagens com r\u00f3tulos verdadeiros e previstos def plot_images(images, true_labels, predicted_labels, class_names, num_images=10):     plt.figure(figsize=(15, 15))     for i in range(num_images):         plt.subplot(5, 5, i + 1)         plt.imshow(images[i])         plt.title(f'True: {class_names[true_labels[i]]}\\nPred: {class_names[predicted_labels[i]]}')         plt.axis('off')     plt.show()  # Fun\u00e7\u00e3o para plotar imagens de resultados corretos def plot_correct_predictions(images, true_labels, predicted_labels, class_names):     correct_indices = np.where(predicted_labels == true_labels)[0]     plot_images(images[correct_indices], true_labels[correct_indices], predicted_labels[correct_indices], class_names)  # Fun\u00e7\u00e3o para plotar imagens de resultados incorretos def plot_incorrect_predictions(images, true_labels, predicted_labels, class_names):     incorrect_indices = np.where(predicted_labels != true_labels)[0]     plot_images(images[incorrect_indices], true_labels[incorrect_indices], predicted_labels[incorrect_indices], class_names) <p>chamando as fun\u00e7\u00f5es</p> In\u00a0[26]: Copied! <pre># Visualizando algumas imagens de resultados corretos\nprint(\"Imagens de Resultados Corretos:\")\nplot_correct_predictions(x_test, true_classes, predicted_classes, class_names)\n\n# Visualizando algumas imagens de resultados incorretos\nprint(\"Imagens de Resultados Incorretos:\")\nplot_incorrect_predictions(x_test, true_classes, predicted_classes, class_names)\n</pre> # Visualizando algumas imagens de resultados corretos print(\"Imagens de Resultados Corretos:\") plot_correct_predictions(x_test, true_classes, predicted_classes, class_names)  # Visualizando algumas imagens de resultados incorretos print(\"Imagens de Resultados Incorretos:\") plot_incorrect_predictions(x_test, true_classes, predicted_classes, class_names)   <pre>Imagens de Resultados Corretos:\n</pre> <pre>Imagens de Resultados Incorretos:\n</pre>"},{"location":"aulas/IA/lab11/cnn_completo.html#exemplo-completo-juntando-tudo-que-ja-vimos-e-mais-um-pouco","title":"Exemplo completo juntando tudo que j\u00e1 vimos e mais um pouco...\u00b6","text":"<p>Vamos usar o conjunto de dados CIFAR-10, que \u00e9 um conjunto de dados de 60.000 imagens de 10 classes, com 6.000 imagens por classe.</p> <p>As imagens s\u00e3o de tamanho 32x32 pixels com tr\u00eas canais de cores (RGB).</p> <p>Ao longo do notebook vamos relembrar alguns conceitos e conhecer novos.</p> <p><code>LEMBRETE IMPORTANTE</code>: Lembre-se de setar o colab para usar a GPU.</p>"},{"location":"aulas/IA/lab11/cnn_completo.html#configurando-o-google-drive","title":"Configurando o google drive\u00b6","text":"<p>Vamos setar o google drive para salvar o modelo durante o treinamento</p>"},{"location":"aulas/IA/lab11/cnn_completo.html#importando-e-preparando-os-dados-cifar-10","title":"Importando e Preparando os Dados CIFAR-10\u00b6","text":"<p>Primeiro, vamos importar e preparar os dados CIFAR-10:</p>"},{"location":"aulas/IA/lab11/cnn_completo.html#definindo-o-modelo","title":"Definindo o Modelo\u00b6","text":"<p>Vamos definir o modelo para o dataset:</p>"},{"location":"aulas/IA/lab11/cnn_completo.html#configurando-callbacks","title":"Configurando Callbacks\u00b6","text":"<p>Vamos configurar as <code>callbacks</code>: <code>ModelCheckpoint</code>, <code>EarlyStopping</code> e <code>ReduceLROnPlateau</code>:</p>"},{"location":"aulas/IA/lab11/cnn_completo.html#configurando-data-augmentation","title":"Configurando Data Augmentation\u00b6","text":"<p>Vamos configurar a data augmentation usando ImageDataGenerator:</p>"},{"location":"aulas/IA/lab11/cnn_completo.html#treinando-o-modelo","title":"Treinando o Modelo\u00b6","text":"<p>Finalmente chegou o momento de treinar o modelo com as callbacks e data augmentation:</p>"},{"location":"aulas/IA/lab11/cnn_completo.html#avaliando-o-treinamento","title":"avaliando o treinamento\u00b6","text":"<p>Vamos dar uma olhada n curva de loss e acuracia do treinamento</p>"},{"location":"aulas/IA/lab11/cnn_completo.html#avaliando-o-modelo-e-carregando-o-melhor-modelo","title":"Avaliando o Modelo e Carregando o Melhor Modelo\u00b6","text":"<p>Vamos carregar conjunto de dados de teste e normalize os valores dos pixels:</p>"},{"location":"aulas/IA/lab11/cnn_completo.html#avaliacao-do-modelo","title":"Avalia\u00e7\u00e3o do Modelo\u00b6","text":"<p>Vamos avaliar o modelo nos dados de teste.</p> <p>Durante o treinamento salvamos no google drive o modelo para garantir que estamos utilizando o modelo com melhor desempenho:</p>"},{"location":"aulas/IA/lab11/cnn_completo.html#fazendo-predicoes-nas-imagens-de-teste","title":"fazendo predi\u00e7\u00f5es nas imagens de teste\u00b6","text":"<p>vamos fazer previs\u00f5es no conjunto de dados de teste:</p>"},{"location":"aulas/IA/lab11/cnn_completo.html#explorando-a-matriz-de-confusao","title":"Explorando a matriz de confus\u00e3o\u00b6","text":"<p>A matriz de confus\u00e3o \u00e9 uma ferramenta para avaliar a performance de um modelo de classifica\u00e7\u00e3o. Ela apresenta uma tabela que resume os resultados das previs\u00f5es do modelo, comparando os r\u00f3tulos previstos com os r\u00f3tulos reais.</p> <p>Como Interpretar:</p> <ul> <li><code>True Positives (TP)</code>: N\u00famero de previs\u00f5es corretas da classe positiva.</li> <li><code>True Negatives (TN)</code>: N\u00famero de previs\u00f5es corretas da classe negativa.</li> <li><code>False Positives (FP)</code>: N\u00famero de previs\u00f5es incorretas onde a classe negativa foi prevista como positiva (erro tipo I).</li> <li><code>False Negatives (FN)</code>: N\u00famero de previs\u00f5es incorretas onde a classe positiva foi prevista como negativa (erro tipo II).</li> </ul> <p>A matriz de confus\u00e3o ajuda a entender n\u00e3o apenas a acur\u00e1cia do modelo, mas tamb\u00e9m os tipos de erros que ele comete. Isso pode ser \u00fatil para:</p> <ul> <li>Identificar classes que s\u00e3o frequentemente confundidas.</li> <li>Melhorar o modelo ao ajustar os hiperpar\u00e2metros ou coletar mais dados para classes espec\u00edficas.</li> </ul>"},{"location":"aulas/IA/lab11/cnn_completo.html#exibindo-os-resultados","title":"Exibindo os resultados\u00b6","text":"<p>Vamos plotar algumas imagens para visualizar os resultados</p>"},{"location":"aulas/PDI/lab04_quiz.html","title":"Quiz Avan\u00e7ado sobre Filtros de Convolu\u00e7\u00e3o (Lab04)","text":""},{"location":"aulas/PDI/lab04_quiz.html#questoes-teoricas","title":"Quest\u00f5es Te\u00f3ricas","text":"<ol> <li>O que \u00e9 um filtro de convolu\u00e7\u00e3o em processamento de imagens e como ele funciona matematicamente?</li> <li>a) Um m\u00e9todo para aumentar o tamanho da imagem atrav\u00e9s de interpola\u00e7\u00e3o bilinear</li> <li>b) Uma opera\u00e7\u00e3o matem\u00e1tica que aplica uma matriz (kernel) em cada pixel da imagem, calculando a soma ponderada dos valores dos pixels vizinhos</li> <li>c) Um processo para converter imagens coloridas em preto e branco usando limiariza\u00e7\u00e3o adaptativa</li> <li>d) Uma t\u00e9cnica para compress\u00e3o de imagens baseada na transformada de Fourier</li> </ol> <ol> <li>Qual \u00e9 o efeito matem\u00e1tico dos filtros de suaviza\u00e7\u00e3o (blurring) na frequ\u00eancia espacial de uma imagem?</li> <li>a) Atuam como passa-altas, preservando as altas frequ\u00eancias (detalhes)</li> <li>b) N\u00e3o alteram o conte\u00fado de frequ\u00eancia da imagem</li> <li>c) Atuam como passa-baixas, atenuando as altas frequ\u00eancias (detalhes)</li> <li> <p>d) Amplificam seletivamente as frequ\u00eancias m\u00e9dias</p> </li> <li> <p>O que acontece com a resposta ao impulso de um filtro Gaussiano quando aumentamos o valor de sigma?</p> </li> <li>a) A resposta se torna mais estreita, resultando em menos suaviza\u00e7\u00e3o</li> <li>b) A resposta se torna mais ampla, resultando em maior suaviza\u00e7\u00e3o</li> <li>c) A resposta oscila mais, criando efeitos de ringing</li> <li> <p>d) A resposta se torna mais direcional, suavizando apenas em uma dire\u00e7\u00e3o</p> </li> <li> <p>Qual \u00e9 a principal diferen\u00e7a te\u00f3rica entre os operadores de Sobel e Laplaciano para detec\u00e7\u00e3o de bordas?</p> </li> <li>a) Sobel \u00e9 baseado na primeira derivada (gradiente), enquanto Laplaciano \u00e9 baseado na segunda derivada</li> <li>b) Sobel funciona apenas em imagens coloridas, enquanto Laplaciano funciona em escala de cinza</li> <li>c) Sobel detecta apenas bordas horizontais, enquanto Laplaciano detecta bordas em todas as dire\u00e7\u00f5es</li> <li> <p>d) Sobel \u00e9 um filtro n\u00e3o-linear, enquanto Laplaciano \u00e9 linear</p> </li> <li> <p>Por que o detector de bordas de Canny \u00e9 considerado superior a simples operadores de gradiente?</p> </li> <li>a) Porque utiliza cores para destacar as bordas</li> <li>b) Porque implementa m\u00faltiplos est\u00e1gios: suaviza\u00e7\u00e3o, c\u00e1lculo de gradiente, supress\u00e3o n\u00e3o-m\u00e1xima e limiariza\u00e7\u00e3o com histerese</li> <li>c) Porque \u00e9 computacionalmente mais eficiente</li> <li>d) Porque funciona exclusivamente em imagens de alta resolu\u00e7\u00e3o</li> </ol>"},{"location":"aulas/PDI/lab04_quiz.html#questoes-praticas","title":"Quest\u00f5es Pr\u00e1ticas","text":"<ol> <li>Observe as imagens abaixo. Qual filtro foi aplicado na imagem da direita?</li> </ol> <ul> <li>a) Filtro de m\u00e9dia (blur)</li> <li>b) Filtro de Sobel</li> <li>c) Filtro Gaussiano</li> <li> <p>d) Filtro de Canny</p> </li> <li> <p>Qual seria o resultado da aplica\u00e7\u00e3o do seguinte kernel em uma imagem? <pre><code>[-1, -1, -1]\n[-1,  9, -1]\n[-1, -1, -1]\n</code></pre></p> </li> <li>a) Suaviza\u00e7\u00e3o da imagem</li> <li>b) Detec\u00e7\u00e3o de bordas</li> <li>c) Aumento de nitidez (sharpening)</li> <li> <p>d) Emboss (efeito de relevo)</p> </li> <li> <p>Calcule o resultado da convolu\u00e7\u00e3o da seguinte matriz de imagem 3x3 com o kernel 3x3 apresentado, considerando o pixel central: <pre><code>Matriz da imagem:       Kernel:\n[10, 20, 30]            [0, 1, 0]\n[40, 50, 60]            [1, -4, 1]\n[70, 80, 90]            [0, 1, 0]\n</code></pre></p> </li> <li>a) -60</li> <li>b) 0</li> <li>c) 60</li> <li> <p>d) 240</p> </li> <li> <p>Ao implementar um filtro de m\u00e9dia 5x5 no OpenCV, qual seria o c\u00f3digo correto?</p> </li> <li>a) <code>cv2.blur(img, (5, 5))</code></li> <li>b) <code>cv2.filter2D(img, -1, np.ones((5,5))/25)</code></li> <li>c) <code>cv2.boxFilter(img, -1, (5, 5), normalize=True)</code></li> <li> <p>d) Todas as alternativas acima produzem o mesmo resultado</p> </li> <li> <p>Analise o c\u00f3digo abaixo e determine sua fun\u00e7\u00e3o: <pre><code>gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\nsobelx = cv2.Sobel(gray, cv2.CV_64F, 1, 0, ksize=3)\nsobely = cv2.Sobel(gray, cv2.CV_64F, 0, 1, ksize=3)\nmagnitude = np.sqrt(sobelx**2 + sobely**2)\ndirection = np.arctan2(sobely, sobelx) * (180/np.pi)\n</code></pre></p> </li> <li>a) Implementa\u00e7\u00e3o do detector de bordas de Canny</li> <li>b) C\u00e1lculo da magnitude e dire\u00e7\u00e3o do gradiente usando operadores de Sobel</li> <li>c) Aplica\u00e7\u00e3o de um filtro de Gabor para an\u00e1lise de textura</li> <li> <p>d) Implementa\u00e7\u00e3o de um filtro passa-banda direcional</p> </li> <li> <p>Qual seria o efeito da seguinte sequ\u00eancia de opera\u00e7\u00f5es em uma imagem com ru\u00eddo? <pre><code>blurred = cv2.GaussianBlur(img, (5, 5), 0)\nsharpened = cv2.addWeighted(img, 1.5, blurred, -0.5, 0)\n</code></pre></p> <ul> <li>a) Remo\u00e7\u00e3o de ru\u00eddo sem perda significativa de detalhes</li> <li>b) Amplifica\u00e7\u00e3o do ru\u00eddo e aumento da nitidez</li> <li>c) Remo\u00e7\u00e3o completa de bordas e detalhes</li> <li>d) Convers\u00e3o para escala de cinza com preserva\u00e7\u00e3o de bordas</li> </ul> </li> </ul>"},{"location":"aulas/PDI/lab04_quiz.html#questoes-de-desafio","title":"Quest\u00f5es de Desafio","text":"<ol> <li> <p>Observe a imagem abaixo. Qual combina\u00e7\u00e3o de t\u00e9cnicas seria mais eficaz para detectar apenas as linhas do tabuleiro de sudoku?</p> <p></p> <ul> <li>a) Limiariza\u00e7\u00e3o adaptativa seguida de opera\u00e7\u00f5es morfol\u00f3gicas</li> <li>b) Filtro Gaussiano seguido de detector de Canny e Transformada de Hough</li> <li>c) Segmenta\u00e7\u00e3o por watershed ap\u00f3s aplica\u00e7\u00e3o de gradiente morfol\u00f3gico</li> <li>d) K-means clustering seguido de detec\u00e7\u00e3o de contornos</li> </ul> </li> <li> <p>Qual \u00e9 o impacto do \"padding\" em opera\u00e7\u00f5es de convolu\u00e7\u00e3o e como ele afeta o tamanho da imagem resultante?</p> <ul> <li>a) O padding SAME mant\u00e9m as dimens\u00f5es originais da imagem, enquanto o padding VALID reduz as dimens\u00f5es</li> <li>b) O padding n\u00e3o afeta o tamanho da imagem, apenas a intensidade dos pixels de borda</li> <li>c) O padding sempre aumenta o tamanho da imagem final proporcionalmente ao tamanho do kernel</li> <li>d) O padding \u00e9 usado apenas para kernels de tamanho par</li> </ul> <p></p> </li> <li> <p>Considere um filtro bilateral aplicado a uma imagem. O que diferencia este filtro de um filtro Gaussiano tradicional?</p> <ul> <li>a) O filtro bilateral \u00e9 mais r\u00e1pido computacionalmente</li> <li>b) O filtro bilateral preserva bordas enquanto suaviza regi\u00f5es homog\u00eaneas, pois considera tanto a proximidade espacial quanto a similaridade de intensidade</li> <li>c) O filtro bilateral funciona apenas em imagens coloridas</li> <li>d) O filtro bilateral aplica suaviza\u00e7\u00e3o apenas na dire\u00e7\u00e3o do gradiente local</li> </ul> </li> <li> <p>Qual seria o resultado da aplica\u00e7\u00e3o do seguinte kernel em uma imagem em escala de cinza? <pre><code>[ 0, -1,  0]\n[-1,  4, -1]\n[ 0, -1,  0]\n</code></pre></p> <ul> <li>a) Suaviza\u00e7\u00e3o da imagem</li> <li>b) Detec\u00e7\u00e3o de bordas usando aproxima\u00e7\u00e3o do Laplaciano</li> <li>c) Aumento de nitidez (sharpening)</li> <li>d) Detec\u00e7\u00e3o de cantos (corner detection)</li> </ul> </li> <li> <p>Observe a imagem abaixo. Que sequ\u00eancia de opera\u00e7\u00f5es seria mais adequada para isolar apenas o pinguim Tux do fundo?</p> <p></p> <ul> <li>a) Convers\u00e3o para escala de cinza, limiariza\u00e7\u00e3o de Otsu e opera\u00e7\u00f5es morfol\u00f3gicas</li> <li>b) Segmenta\u00e7\u00e3o baseada em cor no espa\u00e7o HSV, seguida de detec\u00e7\u00e3o de contornos</li> <li>c) Aplica\u00e7\u00e3o do algoritmo GrabCut com inicializa\u00e7\u00e3o autom\u00e1tica</li> <li>d) Detector de Canny seguido de preenchimento de contornos fechados</li> </ul> </li> <li> <p>Em processamento de imagens m\u00e9dicas, qual t\u00e9cnica baseada em convolu\u00e7\u00e3o \u00e9 frequentemente usada para real\u00e7ar estruturas tubulares como vasos sangu\u00edneos?</p> <ul> <li>a) Filtros de Gabor em m\u00faltiplas escalas e orienta\u00e7\u00f5es</li> <li>b) Filtros de casamento (matched filters) baseados em perfis gaussianos</li> <li>c) Filtros de difus\u00e3o anisotr\u00f3pica</li> <li>d) Todas as alternativas acima</li> </ul> </li> <li> <p>Qual \u00e9 o princ\u00edpio matem\u00e1tico por tr\u00e1s da implementa\u00e7\u00e3o eficiente de filtros de convolu\u00e7\u00e3o separ\u00e1veis?</p> <ul> <li>a) A decomposi\u00e7\u00e3o do kernel 2D em dois vetores 1D, reduzindo a complexidade computacional de O(n\u00b2) para O(2n)</li> <li>b) A aplica\u00e7\u00e3o da transformada r\u00e1pida de Fourier (FFT) para converter a convolu\u00e7\u00e3o em multiplica\u00e7\u00e3o no dom\u00ednio da frequ\u00eancia</li> <li>c) A utiliza\u00e7\u00e3o de integrais de imagem (summed area tables) para calcular somas em regi\u00f5es retangulares</li> <li>d) A implementa\u00e7\u00e3o de algoritmos paralelos em GPU</li> </ul> </li> <li> <p>Qual destas afirma\u00e7\u00f5es sobre o detector de bordas de Canny \u00e9 FALSA?</p> <ul> <li>a) Utiliza dois limiares para detectar bordas fortes e fracas</li> <li>b) Inclui uma etapa de supress\u00e3o n\u00e3o-m\u00e1xima para afinar as bordas</li> <li>c) \u00c9 invariante a rota\u00e7\u00f5es e mudan\u00e7as de escala</li> <li>d) Geralmente aplica um filtro Gaussiano como pr\u00e9-processamento</li> </ul> </li> </ol>"},{"location":"aulas/PDI/lab04_quiz.html#respostas","title":"Respostas","text":"<ol> <li>b</li> <li>c</li> <li>b</li> <li>a</li> <li>b</li> <li>b</li> <li>c</li> <li>a</li> <li>d</li> <li>b</li> <li>a</li> <li>b</li> <li>a</li> <li>b</li> <li>b</li> <li>b</li> <li>d</li> <li>a</li> <li>c</li> </ol>"},{"location":"aulas/PDI/lab05_quiz.html","title":"Quiz Lab05 - Espa\u00e7o de Cor e Contornos","text":"<p>Este quiz aborda os conceitos de espa\u00e7o de cor HSV, m\u00e1scaras, detec\u00e7\u00e3o de contornos, c\u00e1lculo de centro de massa, e opera\u00e7\u00f5es de desenho em imagens utilizando OpenCV.</p>"},{"location":"aulas/PDI/lab05_quiz.html#questoes-teoricas","title":"Quest\u00f5es Te\u00f3ricas","text":""},{"location":"aulas/PDI/lab05_quiz.html#1-o-que-representa-o-componente-h-no-espaco-de-cores-hsv","title":"1. O que representa o componente H no espa\u00e7o de cores HSV?","text":"<p>a) Brilho (Brightness) b) Satura\u00e7\u00e3o (Saturation) c) Matiz (Hue) d) Valor (Value)</p> <p></p>"},{"location":"aulas/PDI/lab05_quiz.html#2-qual-a-principal-vantagem-do-espaco-de-cor-hsv-em-relacao-ao-rgb-para-segmentacao-de-cores","title":"2. Qual a principal vantagem do espa\u00e7o de cor HSV em rela\u00e7\u00e3o ao RGB para segmenta\u00e7\u00e3o de cores?","text":"<p>a) \u00c9 mais r\u00e1pido para processar b) Separa a informa\u00e7\u00e3o de cor (matiz) da intensidade c) Utiliza menos mem\u00f3ria d) Tem melhor representa\u00e7\u00e3o de cores escuras</p>"},{"location":"aulas/PDI/lab05_quiz.html#3-na-opencv-qual-e-o-intervalo-de-valores-para-o-componente-h-matiz-no-espaco-hsv","title":"3. Na OpenCV, qual \u00e9 o intervalo de valores para o componente H (matiz) no espa\u00e7o HSV?","text":"<p>a) 0 a 100 b) 0 a 255 c) 0 a 179 d) 0 a 360</p>"},{"location":"aulas/PDI/lab05_quiz.html#4-o-que-e-uma-mascara-binaria-no-contexto-de-processamento-de-imagens","title":"4. O que \u00e9 uma m\u00e1scara bin\u00e1ria no contexto de processamento de imagens?","text":"<p>a) Uma imagem que cont\u00e9m apenas pixels pretos e brancos b) Um filtro que aplica efeitos art\u00edsticos c) Um algoritmo para compress\u00e3o de imagens d) Uma t\u00e9cnica para reduzir ru\u00eddo</p>"},{"location":"aulas/PDI/lab05_quiz.html#5-qual-funcao-da-opencv-e-utilizada-para-encontrar-contornos-em-uma-imagem","title":"5. Qual fun\u00e7\u00e3o da OpenCV \u00e9 utilizada para encontrar contornos em uma imagem?","text":"<p>a) cv2.findEdges() b) cv2.detectContours() c) cv2.findContours() d) cv2.getContours()</p>"},{"location":"aulas/PDI/lab05_quiz.html#questoes-praticas","title":"Quest\u00f5es Pr\u00e1ticas","text":""},{"location":"aulas/PDI/lab05_quiz.html#6-observe-a-imagem-abaixo-qual-seria-a-melhor-abordagem-para-detectar-apenas-o-objeto-vermelho","title":"6. Observe a imagem abaixo. Qual seria a melhor abordagem para detectar apenas o objeto vermelho?","text":"<p>a) Aplicar um filtro de suaviza\u00e7\u00e3o e depois detec\u00e7\u00e3o de bordas b) Converter para HSV e criar uma m\u00e1scara para a faixa de vermelho c) Usar apenas o canal R do RGB e aplicar um limiar d) Converter para escala de cinza e aplicar limiariza\u00e7\u00e3o adaptativa</p>"},{"location":"aulas/PDI/lab05_quiz.html#7-para-calcular-o-centro-de-massa-de-um-contorno-detectado-qual-metodo-da-opencv-e-utilizado","title":"7. Para calcular o centro de massa de um contorno detectado, qual m\u00e9todo da OpenCV \u00e9 utilizado?","text":"<p>a) cv2.contourCenter() b) cv2.moments() c) cv2.centerOfMass() d) cv2.contourCentroid()</p>"},{"location":"aulas/PDI/lab05_quiz.html#8-qual-e-o-resultado-da-seguinte-operacao","title":"8. Qual \u00e9 o resultado da seguinte opera\u00e7\u00e3o?","text":"<pre><code>img = cv2.imread('imagem.png')\nhsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\nlower_blue = np.array([110, 50, 50])\nupper_blue = np.array([130, 255, 255])\nmask = cv2.inRange(hsv, lower_blue, upper_blue)\n</code></pre> <p>a) Convers\u00e3o da imagem para tons de cinza b) Cria\u00e7\u00e3o de uma m\u00e1scara que isola pixels azuis c) Aplica\u00e7\u00e3o de um filtro de suaviza\u00e7\u00e3o d) Detec\u00e7\u00e3o de bordas na imagem</p>"},{"location":"aulas/PDI/lab05_quiz.html#9-observe-a-imagem-abaixo-com-contornos-detectados-qual-funcao-foi-usada-para-desenhar-estes-contornos","title":"9. Observe a imagem abaixo com contornos detectados. Qual fun\u00e7\u00e3o foi usada para desenhar estes contornos?","text":"<p>a) cv2.rectangle() b) cv2.line() c) cv2.drawContours() d) cv2.circle()</p>"},{"location":"aulas/PDI/lab05_quiz.html#10-para-desenhar-um-circulo-no-centro-de-massa-de-um-contorno-qual-sequencia-de-funcoes-deve-ser-usada","title":"10. Para desenhar um c\u00edrculo no centro de massa de um contorno, qual sequ\u00eancia de fun\u00e7\u00f5es deve ser usada?","text":"<p>a) cv2.moments(), c\u00e1lculo do centroide, cv2.circle() b) cv2.findContours(), cv2.boundingRect(), cv2.rectangle() c) cv2.Canny(), cv2.HoughCircles(), cv2.circle() d) cv2.findContours(), cv2.approxPolyDP(), cv2.polylines()</p>"},{"location":"aulas/PDI/lab05_quiz.html#questoes-de-desafio","title":"Quest\u00f5es de Desafio","text":""},{"location":"aulas/PDI/lab05_quiz.html#11-observe-a-imagem-abaixo-que-tecnica-foi-utilizada-para-segmentar-apenas-a-parte-vermelha-da-melancia","title":"11. Observe a imagem abaixo. Que t\u00e9cnica foi utilizada para segmentar apenas a parte vermelha da melancia?","text":"<p>a) Limiariza\u00e7\u00e3o simples em escala de cinza b) Segmenta\u00e7\u00e3o no espa\u00e7o de cor HSV c) Detec\u00e7\u00e3o de bordas seguida de preenchimento d) Subtra\u00e7\u00e3o de fundo</p>"},{"location":"aulas/PDI/lab05_quiz.html#12-qual-e-a-diferenca-entre-cv2chain_approx_simple-e-cv2chain_approx_none-no-contexto-da-funcao-cv2findcontours","title":"12. Qual \u00e9 a diferen\u00e7a entre cv2.CHAIN_APPROX_SIMPLE e cv2.CHAIN_APPROX_NONE no contexto da fun\u00e7\u00e3o cv2.findContours()?","text":"<p>a) CHAIN_APPROX_SIMPLE armazena apenas os pontos extremos, enquanto CHAIN_APPROX_NONE armazena todos os pontos do contorno b) CHAIN_APPROX_SIMPLE \u00e9 mais preciso, enquanto CHAIN_APPROX_NONE \u00e9 mais r\u00e1pido c) CHAIN_APPROX_SIMPLE funciona apenas com formas simples, enquanto CHAIN_APPROX_NONE funciona com qualquer forma d) CHAIN_APPROX_SIMPLE detecta apenas contornos externos, enquanto CHAIN_APPROX_NONE detecta todos os contornos</p>"},{"location":"aulas/PDI/lab05_quiz.html#13-ao-utilizar-a-funcao-cv2findcontours-qual-e-o-significado-do-parametro-de-hierarquia-retornado","title":"13. Ao utilizar a fun\u00e7\u00e3o cv2.findContours(), qual \u00e9 o significado do par\u00e2metro de hierarquia retornado?","text":"<p>a) Indica o tamanho relativo dos contornos b) Representa a rela\u00e7\u00e3o pai-filho entre contornos (contornos dentro de outros) c) Determina a ordem em que os contornos foram detectados d) Indica a profundidade de cor dos contornos</p>"},{"location":"aulas/PDI/lab05_quiz.html#14-observe-a-imagem-abaixo-como-voce-identificaria-apenas-o-pinguim-tux-ignorando-o-fundo-branco","title":"14. Observe a imagem abaixo. Como voc\u00ea identificaria apenas o pinguim Tux, ignorando o fundo branco?","text":"<p>a) Aplicar detec\u00e7\u00e3o de bordas com Canny e preencher o interior b) Usar segmenta\u00e7\u00e3o por watershed c) Converter para HSV e criar uma m\u00e1scara para cores n\u00e3o-brancas d) Aplicar limiariza\u00e7\u00e3o adaptativa seguida de opera\u00e7\u00f5es morfol\u00f3gicas</p>"},{"location":"aulas/PDI/lab05_quiz.html#15-qual-tecnica-seria-mais-adequada-para-detectar-e-contar-os-quadrados-em-uma-imagem-de-um-tabuleiro-de-sudoku","title":"15. Qual t\u00e9cnica seria mais adequada para detectar e contar os quadrados em uma imagem de um tabuleiro de sudoku?","text":"<p>a) Transformada de Hough para linhas b) Detec\u00e7\u00e3o de contornos seguida de aproxima\u00e7\u00e3o poligonal c) Template matching com um modelo de quadrado d) Segmenta\u00e7\u00e3o baseada em cor</p>"},{"location":"aulas/PDI/lab05_quiz.html#respostas","title":"Respostas","text":"<ol> <li>c) Matiz (Hue)</li> <li>b) Separa a informa\u00e7\u00e3o de cor (matiz) da intensidade</li> <li>c) 0 a 179</li> <li>a) Uma imagem que cont\u00e9m apenas pixels pretos e brancos</li> <li>c) cv2.findContours()</li> <li>b) Converter para HSV e criar uma m\u00e1scara para a faixa de vermelho</li> <li>b) cv2.moments()</li> <li>b) Cria\u00e7\u00e3o de uma m\u00e1scara que isola pixels azuis</li> <li>c) cv2.drawContours()</li> <li>a) cv2.moments(), c\u00e1lculo do centroide, cv2.circle()</li> <li>b) Segmenta\u00e7\u00e3o no espa\u00e7o de cor HSV</li> <li>a) CHAIN_APPROX_SIMPLE armazena apenas os pontos extremos, enquanto CHAIN_APPROX_NONE armazena todos os pontos do contorno</li> <li>b) Representa a rela\u00e7\u00e3o pai-filho entre contornos (contornos dentro de outros)</li> <li>c) Converter para HSV e criar uma m\u00e1scara para cores n\u00e3o-brancas</li> <li>b) Detec\u00e7\u00e3o de contornos seguida de aproxima\u00e7\u00e3o poligonal</li> </ol>"},{"location":"aulas/PDI/intro/index.html","title":"Processamento Digital de Imagens","text":"<p>Fa\u00e7a o download do pdf de Introdu\u00e7\u00e3o.</p> <ul> <li>arquivo pdf: Introdu\u00e7\u00e3o</li> </ul>"},{"location":"aulas/PDI/lab01/IntroPID.html","title":"Lab01 - Intro PID","text":"<p>Objetivos da aula:</p> <ul> <li>Conhecer o que \u00e9 uma imagem digital</li> <li>Conhecer como fazer leitura e exibi\u00e7\u00e3o de imagens</li> <li>conhecer algumas propriedades de imagens</li> <li>conhecer canais de cores de imagens</li> </ul> In\u00a0[20]: Copied! <pre># Importando a biblioteca OpenCV\nimport cv2 \n\n#import a biblioteca Numpy8 bits\nimport numpy as np\n\n#linha magica para imprimir graficos no notebook\n%matplotlib inline\nfrom matplotlib import pyplot as plt\n\n\nprint (\"OpenCV Vers\u00e3o : %s \" % cv2.__version__)\n</pre> # Importando a biblioteca OpenCV import cv2   #import a biblioteca Numpy8 bits import numpy as np  #linha magica para imprimir graficos no notebook %matplotlib inline from matplotlib import pyplot as plt   print (\"OpenCV Vers\u00e3o : %s \" % cv2.__version__) <pre>OpenCV Vers\u00e3o : 4.6.0 \n</pre> In\u00a0[21]: Copied! <pre># Para facilitar o download das imagens utilizadas neste notebook\n\n!wget \"https://raw.githubusercontent.com/arnaldojr/cognitivecomputing/master/material/aulas/PDI/lab01/NATUREZA_1.jpg\" /content # este link \u00e9 o local onde a imagem est\u00e1 salva\n!wget \"https://raw.githubusercontent.com/arnaldojr/cognitivecomputing/master/material/aulas/PDI/lab01/img3x3.png\" /content\n</pre> # Para facilitar o download das imagens utilizadas neste notebook  !wget \"https://raw.githubusercontent.com/arnaldojr/cognitivecomputing/master/material/aulas/PDI/lab01/NATUREZA_1.jpg\" /content # este link \u00e9 o local onde a imagem est\u00e1 salva !wget \"https://raw.githubusercontent.com/arnaldojr/cognitivecomputing/master/material/aulas/PDI/lab01/img3x3.png\" /content  <pre>--2023-02-10 19:17:06--  https://raw.githubusercontent.com/arnaldojr/cognitivecomputing/master/material/aulas/lab01/NATUREZA_1.jpg\nResolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.110.133, 185.199.111.133, ...\nConnecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 233789 (228K) [image/jpeg]\nSaving to: \u2018NATUREZA_1.jpg\u2019\n\n\rNATUREZA_1.jpg        0%[                    ]       0  --.-KB/s               \rNATUREZA_1.jpg      100%[===================&gt;] 228.31K  --.-KB/s    in 0.03s   \n\n2023-02-10 19:17:07 (8.44 MB/s) - \u2018NATUREZA_1.jpg\u2019 saved [233789/233789]\n\n/content: Scheme missing.\nFINISHED --2023-02-10 19:17:07--\nTotal wall clock time: 0.2s\nDownloaded: 1 files, 228K in 0.03s (8.44 MB/s)\n--2023-02-10 19:17:07--  https://raw.githubusercontent.com/arnaldojr/cognitivecomputing/master/material/aulas/lab01/img3x3.png\nResolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.110.133, 185.199.111.133, 185.199.108.133, ...\nConnecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.110.133|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 171 [image/png]\nSaving to: \u2018img3x3.png\u2019\n\nimg3x3.png          100%[===================&gt;]     171  --.-KB/s    in 0s      \n\n2023-02-10 19:17:07 (7.21 MB/s) - \u2018img3x3.png\u2019 saved [171/171]\n\n/content: Scheme missing.\nFINISHED --2023-02-10 19:17:07--\nTotal wall clock time: 0.1s\nDownloaded: 1 files, 171 in 0s (7.21 MB/s)\n</pre> In\u00a0[22]: Copied! <pre># para nao imprimir os eixos \nimage = cv2.imread(\"NATUREZA_1.jpg\")\n\nplt.imshow(image,interpolation=\"none\")\nplt.axis('off') \nplt.show()\n</pre> # para nao imprimir os eixos  image = cv2.imread(\"NATUREZA_1.jpg\")  plt.imshow(image,interpolation=\"none\") plt.axis('off')  plt.show() <p>A imagem colorida possui tr\u00eas dimens\u00f5es: as linhas e as colunas da matriz, bem como os canais da imagem. Uma imagem colorida geralmente possui tr\u00eas canais: R (Red - vermelho) G (Green - verde) B (Blue - azul)</p> <p>Mas porque a imagem \u00e9 mostrada de modo estranho pelo pacote matplotlib? Porque a OpenCV representa os canais da imagem na ordem B - G - R, e n\u00e3o R - G - B como \u00e9 esperado pela maior parte das bibliotecas.</p> <p>Assim, para podermos visualizar corretamente uma imagem do OpenCV com matplotlib, precisamos inverter os canais, como no c\u00f3digo abaixo:</p> In\u00a0[\u00a0]: Copied! <pre>image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n\nplt.imshow(image_rgb)\n\nplt.axis('off') \nplt.show()\n</pre> image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)  plt.imshow(image_rgb)  plt.axis('off')  plt.show() In\u00a0[\u00a0]: Copied! <pre># Mostrando a representa\u00e7\u00e3o interna da imagem\nprint(\"Dimens\u00f5es da imagem: \", image_rgb.shape)\nprint(\"Quantidade de linhas: \", image_rgb.shape[0])\nprint(\"Quantidade de colunas: \", image_rgb.shape[1])\nprint(\"Camadas de cores: \", image_rgb.shape[2])\n</pre> # Mostrando a representa\u00e7\u00e3o interna da imagem print(\"Dimens\u00f5es da imagem: \", image_rgb.shape) print(\"Quantidade de linhas: \", image_rgb.shape[0]) print(\"Quantidade de colunas: \", image_rgb.shape[1]) print(\"Camadas de cores: \", image_rgb.shape[2]) <pre>Dimens\u00f5es da imagem:  (768, 1024, 3)\nQuantidade de linhas:  768\nQuantidade de colunas:  1024\nCamadas de cores:  3\n</pre> In\u00a0[\u00a0]: Copied! <pre># Mostrando a representa\u00e7\u00e3o interna da imagem\nprint(\"Dimens\u00f5es da imagem: \\n\", image_rgb)\n</pre> # Mostrando a representa\u00e7\u00e3o interna da imagem print(\"Dimens\u00f5es da imagem: \\n\", image_rgb)  <pre>Dimens\u00f5es da imagem: \n [[[ 10  92 194]\n  [ 12  94 196]\n  [ 12  95 197]\n  ...\n  [  6  98 201]\n  [  5  97 200]\n  [  2  95 198]]\n\n [[ 11  93 195]\n  [ 11  94 196]\n  [ 11  94 196]\n  ...\n  [  6  98 201]\n  [  6  98 201]\n  [  4  97 200]]\n\n [[ 11  94 196]\n  [ 11  94 196]\n  [  9  95 196]\n  ...\n  [  5  97 200]\n  [  7  99 202]\n  [  7 100 203]]\n\n ...\n\n [[  0  69 111]\n  [  1  70 112]\n  [  1  70 112]\n  ...\n  [ 11  31   6]\n  [ 17  41  17]\n  [  6  34   9]]\n\n [[  0  67 109]\n  [  0  69 111]\n  [  2  71 113]\n  ...\n  [ 65 105  68]\n  [ 86 135  90]\n  [ 82 136  86]]\n\n [[  0  66 108]\n  [  0  69 111]\n  [  2  71 113]\n  ...\n  [ 53 109  62]\n  [ 72 138  77]\n  [ 74 145  77]]]\n</pre> <p>A matriz acima \u00e9 a representa\u00e7\u00e3o da imagem de forma num\u00e9rica, \u00e9 o valor de cada pixel da imagem. Com esta imagem fica complicado. Vamos tentar analisar separando os canais de cores de um pixel espec\u00edfico.</p> In\u00a0[\u00a0]: Copied! <pre>(b, g, r) = image[450, 50]\nprint('O pixel (50, 50) tem as seguintes cores:')\nprint('Vermelho:',r, 'Verde:', g, 'Azul:', b)\n</pre> (b, g, r) = image[450, 50] print('O pixel (50, 50) tem as seguintes cores:') print('Vermelho:',r, 'Verde:', g, 'Azul:', b) <pre>O pixel (50, 50) tem as seguintes cores:\nVermelho: 2 Verde: 14 Azul: 36\n</pre> In\u00a0[\u00a0]: Copied! <pre># implemente aqui o seu c\u00f3digo.\n</pre> # implemente aqui o seu c\u00f3digo.     In\u00a0[23]: Copied! <pre>import cv2\nimport numpy as np\n\nfrom matplotlib import pyplot as plt\n\n\n# Carregando a imagem na vers\u00e3o tons de cinza (grayscale) de um arquivo\nimagem_cinza = cv2.imread(\"img3x3.png\", cv2.IMREAD_GRAYSCALE)\n\n# ou use o argumento 0, tem o mesmo efeito de importar na escala de cinza\n#imagem_cinza = cv2.imread(\"img3x3.png\", 0)\n\n\nplt.imshow(imagem_cinza)\n\nplt.axis('off') \nplt.show()\nimagem_cinza\n</pre> import cv2 import numpy as np  from matplotlib import pyplot as plt   # Carregando a imagem na vers\u00e3o tons de cinza (grayscale) de um arquivo imagem_cinza = cv2.imread(\"img3x3.png\", cv2.IMREAD_GRAYSCALE)  # ou use o argumento 0, tem o mesmo efeito de importar na escala de cinza #imagem_cinza = cv2.imread(\"img3x3.png\", 0)   plt.imshow(imagem_cinza)  plt.axis('off')  plt.show() imagem_cinza Out[23]: <pre>array([[ 79, 255,  29],\n       [255, 150, 255],\n       [179, 228, 105]], dtype=uint8)</pre> In\u00a0[\u00a0]: Copied! <pre># Coloque aqui sua solu\u00e7\u00e3o. \nimport cv2\nimport numpy as np\n\nfrom matplotlib import pyplot as plt\n\n\n# Carregando a imagem na vers\u00e3o tons de cinza (grayscale) de um arquivo\nimagem_cinza = cv2.imread(\"img3x3.png\", 0)\n\nplt.imshow(imagem_cinza, cmap='gray')\n\nplt.axis('off') \nplt.show()\nimagem_cinza\n</pre> # Coloque aqui sua solu\u00e7\u00e3o.  import cv2 import numpy as np  from matplotlib import pyplot as plt   # Carregando a imagem na vers\u00e3o tons de cinza (grayscale) de um arquivo imagem_cinza = cv2.imread(\"img3x3.png\", 0)  plt.imshow(imagem_cinza, cmap='gray')  plt.axis('off')  plt.show() imagem_cinza  Out[\u00a0]: <pre>array([[ 79, 255,  29],\n       [255, 150, 255],\n       [179, 228, 105]], dtype=uint8)</pre> In\u00a0[\u00a0]: Copied! <pre># Carregando a imagem na vers\u00e3o colorida de um arquivo\nimport cv2\nimport matplotlib.pyplot as plt\n\nimagem = cv2.imread(\"NATUREZA_1.jpg\")\nimage = cv2.cvtColor(imagem, cv2.COLOR_BGR2RGB)\n\nprint(\"Dimens\u00f5es da imagem: \", image.shape)\n\n\nimagem2 = cv2.resize(image, (600,400), cv2.INTER_LINEAR)\nprint(\"Novas dimens\u00f5es da imagem: \", imagem2.shape)\n\n\nplt.imshow(imagem2)\nplt.show()\n</pre> # Carregando a imagem na vers\u00e3o colorida de um arquivo import cv2 import matplotlib.pyplot as plt  imagem = cv2.imread(\"NATUREZA_1.jpg\") image = cv2.cvtColor(imagem, cv2.COLOR_BGR2RGB)  print(\"Dimens\u00f5es da imagem: \", image.shape)   imagem2 = cv2.resize(image, (600,400), cv2.INTER_LINEAR) print(\"Novas dimens\u00f5es da imagem: \", imagem2.shape)   plt.imshow(imagem2) plt.show() <pre>Dimens\u00f5es da imagem:  (768, 1024, 3)\nNovas dimens\u00f5es da imagem:  (400, 600, 3)\n</pre> In\u00a0[\u00a0]: Copied! <pre>#Implemente aqui sua solu\u00e7\u00e3o............\n\n\n\n\n\n\n\n\n\n\n\n\n# Dica para imprimir varias imagens de forma mais organizada com o matplotlib\n\n#plt.figure(figsize = (20,20))\n#plt.subplot(1, 2, 1);plt.imshow(img)\n#plt.subplot(1, 2, 2);plt.imshow(img2)\n#plt.show()\n</pre> #Implemente aqui sua solu\u00e7\u00e3o............             # Dica para imprimir varias imagens de forma mais organizada com o matplotlib  #plt.figure(figsize = (20,20)) #plt.subplot(1, 2, 1);plt.imshow(img) #plt.subplot(1, 2, 2);plt.imshow(img2) #plt.show() In\u00a0[\u00a0]: Copied! <pre>import cv2\nimport numpy as np\n\n\n# Carregando a imagem na vers\u00e3o tons de cinza (grayscale) de um arquivo\nimagem_cinza = cv2.imread(\"img3x3.png\", cv2.IMREAD_COLOR)\n\nplt.imshow(imagem_cinza)\n\nplt.axis('off') \nplt.show()\n</pre> import cv2 import numpy as np   # Carregando a imagem na vers\u00e3o tons de cinza (grayscale) de um arquivo imagem_cinza = cv2.imread(\"img3x3.png\", cv2.IMREAD_COLOR)  plt.imshow(imagem_cinza)  plt.axis('off')  plt.show() In\u00a0[\u00a0]: Copied! <pre># implemente aqui sua solu\u00e7\u00e3o....\n</pre> # implemente aqui sua solu\u00e7\u00e3o....              In\u00a0[\u00a0]: Copied! <pre># Come\u00e7amos importanto as bibliotecas \nimport cv2\nimport numpy as np\nfrom matplotlib import pyplot as plt\n\n# Criamos o array de zero 3x3\nletra = np.zeros((8,5), dtype=int)\n\n# implemente aqui o seu c\u00f3digo.........\n\n\n\n\n\n\n\n\n\n\n# Plota resultado\n\nplt.imshow(letra)\n</pre> # Come\u00e7amos importanto as bibliotecas  import cv2 import numpy as np from matplotlib import pyplot as plt  # Criamos o array de zero 3x3 letra = np.zeros((8,5), dtype=int)  # implemente aqui o seu c\u00f3digo.........           # Plota resultado  plt.imshow(letra) Out[\u00a0]: <pre>&lt;matplotlib.image.AxesImage at 0x1f695118070&gt;</pre> In\u00a0[\u00a0]: Copied! <pre>import cv2\nimagem = cv2.imread(\"NATUREZA_1.jpg\")\nimage = cv2.cvtColor(imagem, cv2.COLOR_BGR2RGB)\n\nfor y in range(0, image.shape[0]):\n  for x in range(0, image.shape[1]):\n    image[y, x] = (255,0,0) #sobreescrevendo todos os pixels da imagem para a cor vermelha\n    #pass\nplt.imshow(image, interpolation=\"none\")\nplt.show()\n</pre> import cv2 imagem = cv2.imread(\"NATUREZA_1.jpg\") image = cv2.cvtColor(imagem, cv2.COLOR_BGR2RGB)  for y in range(0, image.shape[0]):   for x in range(0, image.shape[1]):     image[y, x] = (255,0,0) #sobreescrevendo todos os pixels da imagem para a cor vermelha     #pass plt.imshow(image, interpolation=\"none\") plt.show() In\u00a0[\u00a0]: Copied! <pre>### seu c\u00f3digo aqui\n</pre> ### seu c\u00f3digo aqui"},{"location":"aulas/PDI/lab01/IntroPID.html#representacao-e-visualizacao-de-imagem","title":"Representa\u00e7\u00e3o e visualiza\u00e7\u00e3o de imagem\u00b6","text":"<p>Uma imagem digital nada mais \u00e9 que uma uma matriz de linhas e colunas, onde cada posi\u00e7\u00e3o desta matriz contem o valor de um pixel.</p> <p>O valor de cada pixel representa a intensidade de cor naquele ponto especifico.</p>"},{"location":"aulas/PDI/lab01/IntroPID.html#dica-para-quem-esta-utilizando-o-google-colab","title":"Dica para quem est\u00e1 utilizando o google colab\u00b6","text":"<p>Por ser uma inst\u00e2ncia que \u00e9 alocada temporariamente precisamos carregar as imagens neste se\u00e7\u00e3o.</p> <p>Est\u00e1 etapa pode ser feita de forma manual, fazendo o upload das imagens.</p> <p>Outra forma \u00e9 fazer o download da imagem para o notebook, lempre-se que \u00e9 um linux rodando! :) da uma olhada no exemplo abaixo.</p>"},{"location":"aulas/PDI/lab01/IntroPID.html#desafio-1","title":"Desafio 1\u00b6","text":"<p>Abra a imagem \"img3x3.png\" e plote suas componentes externas (shape) e internas (matriz).</p> <p>Como voc\u00ea esta relacionado as possi\u00e7\u00f5es da matriz com os pixels da imagem??</p>"},{"location":"aulas/PDI/lab01/IntroPID.html#imagem-em-tons-de-cinza","title":"Imagem em tons de cinza\u00b6","text":"<p>Em muitos casos trabalhamos com imagens na escala de cinza, logo, a imagem possui apenas 1 canal de cor.</p>"},{"location":"aulas/PDI/lab01/IntroPID.html#desafio-2","title":"Desafio 2\u00b6","text":"<p>Eita! alguma est\u00e1 errada nesse plot, era esperado uma imagem na escala de cinza. Por que apareceu isso, como corrigir?</p>"},{"location":"aulas/PDI/lab01/IntroPID.html#amostragem-da-imagem","title":"Amostragem da imagem\u00b6","text":"<p>As imagens capturadas por dispositivos digitais possuem as caracter\u00edsticas de resolu\u00e7\u00e3o espacial e resolu\u00e7\u00e3o de cores Enquanto a resolu\u00e7\u00e3o de cores afeta o n\u00famero de cores que podem serr epresentadas na imagem, sua resolu\u00e7\u00e3o espacial afeta o tamanho que a imagem ir\u00e1 ter. Embora n\u00e3o se possa comparar diretamente a resolu\u00e7\u00e3o de duas imagens com tamanhos diferentes, a imagem do mesmo objeto, se possui mais pixels, significar\u00e1 que tam\u00e9m possui maior resolu\u00e7\u00e3o</p>"},{"location":"aulas/PDI/lab01/IntroPID.html#alterando-o-tamanho-de-uma-imagem","title":"Alterando o tamanho de uma imagem\u00b6","text":"<p>O redimensionamento da imagem pode ser feito na OpenCV atrav\u00e9s do comando <code>cv2.resize(imagem, tamanho, interpola\u00e7\u00e3o)</code></p> <p>O tamanho \u00e9 dado por uma tupla (W,H), onde W \u00e9 a largura (n\u00famero de colunas) e H \u00e9 a altura (n\u00famero de linhas)</p>"},{"location":"aulas/PDI/lab01/IntroPID.html#desafio-3","title":"Desafio 3\u00b6","text":"<p>Comparar os diferentes m\u00e9todos de interpola\u00e7\u00e3o (vizinho mais pr\u00f3ximo, bilinear e bic\u00fabica) ao ampliarmos uma imagem em 10 vezes seu tamanho. Escolha uma imagem pequena.</p> <p>Dica de onde encontrar na documenta\u00e7\u00e3o as flags de interpola\u00e7\u00e3o: https://docs.opencv.org/3.4/da/d54/group__imgproc__transform.html#ga5bb5a1fea74ea38e1a5445ca803ff121</p> <p>Para saber mais sobre interpola\u00e7\u00e3o, sugiro assistir ao video: https://www.youtube.com/watch?v=8bTDssnJyZc&amp;ab_channel=S.M.RiazulIslam</p>"},{"location":"aulas/PDI/lab01/IntroPID.html#alterando-os-valores-dos-pixels-de-uma-imagem","title":"Alterando os valores dos pixels de uma imagem\u00b6","text":""},{"location":"aulas/PDI/lab01/IntroPID.html#range-de-valores","title":"Range de valores\u00b6","text":"<p>Antes de alterar os valores dos pixels temos que entender que a OpenCV trabalha com valores de 8 bits para cada componente de cor ou escala de cinza, quer dizer que os valores possiveis est\u00e3o no range entre 0 e 2\u2078-1, que \u00e9 a mesma que dizer entre 0 e 255.</p>"},{"location":"aulas/PDI/lab01/IntroPID.html#desafio-4","title":"Desafio 4\u00b6","text":"<p>Implemente um codigo que faz a altera\u00e7\u00e3o do pixel(0,0) para a a cor Magenta - RGB (255,0,255);</p>"},{"location":"aulas/PDI/lab01/IntroPID.html#desafio-5","title":"Desafio 5\u00b6","text":"<p>Crie uma array de zero com 8 linhas e 5 colunas. E escreva (desenhe) a primeira letra do seu nome ou grupo.</p> <p>Plot a imagem para visualizar o resultado.</p> <p>Dica: Use np.zeros() para criar o array, para facilitar fa\u00e7a em escala de cinza onde o valor de intensidade do pixel 0=branco e 255=preto.</p>"},{"location":"aulas/PDI/lab01/IntroPID.html#varredura-de-uma-imagem","title":"Varredura de uma imagem\u00b6","text":"<p>Desenvolver uma rotina capaz de varrer sua imagem pixel a pixel \u00e9 muito mais interessante para aplica\u00e7\u00f5es mais pr\u00e1ticas, embora exista tecnicas mais otimizadas e r\u00e1pidas para essa aplica\u00e7\u00e3o, podemos utilizar uma estrutura de dois la\u00e7os For para passar sobre todas as linhas e todas as colunas da matriz (imagem).</p>"},{"location":"aulas/PDI/lab01/IntroPID.html#desafio-6","title":"Desafio 6\u00b6","text":"<p>Utilizando a t\u00e9cnica dos 2 for, implemente uma fun\u00e7\u00e3o que desenha um linha branca na vertical no centro da imagem de largura 50 pixeis. Dica: use um if para checar a posi\u00e7\u00e3o (x,y) antes de pintar de branco o pixel.</p>"},{"location":"aulas/PDI/lab01/sol_IntroPID.html","title":"sol IntroPID","text":"<p>Objetivos da aula:</p> <ul> <li>Conhecer o que \u00e9 uma imagem digital</li> <li>Conhecer como fazer leitura e exibi\u00e7\u00e3o de imagens</li> <li>conhecer algumas propriedades de imagens</li> <li>conhecer canais de cores de imagens</li> </ul> In\u00a0[70]: Copied! <pre># Importando a biblioteca OpenCV\nimport cv2 \n\n#import a biblioteca Numpy8 bits\nimport numpy as np\n\n#linha magica para imprimir graficos no notebook\n%matplotlib inline\nfrom matplotlib import pyplot as plt\n\n\nprint (\"OpenCV Vers\u00e3o : %s \" % cv2.__version__)\n</pre> # Importando a biblioteca OpenCV import cv2   #import a biblioteca Numpy8 bits import numpy as np  #linha magica para imprimir graficos no notebook %matplotlib inline from matplotlib import pyplot as plt   print (\"OpenCV Vers\u00e3o : %s \" % cv2.__version__) <pre>OpenCV Vers\u00e3o : 4.9.0 \n</pre> In\u00a0[\u00a0]: Copied! <pre># Para facilitar o download das imagens utilizadas neste notebook\n\n!wget \"https://raw.githubusercontent.com/arnaldojr/cognitivecomputing/master/material/aulas/PDI/lab01/NATUREZA_1.jpg\" /content # este link \u00e9 o local onde a imagem est\u00e1 salva\n!wget \"https://raw.githubusercontent.com/arnaldojr/cognitivecomputing/master/material/aulas/PDI/lab01/img3x3.png\" /content\n</pre> # Para facilitar o download das imagens utilizadas neste notebook  !wget \"https://raw.githubusercontent.com/arnaldojr/cognitivecomputing/master/material/aulas/PDI/lab01/NATUREZA_1.jpg\" /content # este link \u00e9 o local onde a imagem est\u00e1 salva !wget \"https://raw.githubusercontent.com/arnaldojr/cognitivecomputing/master/material/aulas/PDI/lab01/img3x3.png\" /content  In\u00a0[71]: Copied! <pre># para nao imprimir os eixos \nimage = cv2.imread(\"NATUREZA_1.jpg\")\n\nplt.imshow(image,interpolation=\"none\")\nplt.axis('off') \nplt.show()\n</pre> # para nao imprimir os eixos  image = cv2.imread(\"NATUREZA_1.jpg\")  plt.imshow(image,interpolation=\"none\") plt.axis('off')  plt.show() <p>A imagem colorida possui tr\u00eas dimens\u00f5es: as linhas e as colunas da matriz, bem como os canais da imagem. Uma imagem colorida geralmente possui tr\u00eas canais: R (Red - vermelho) G (Green - verde) B (Blue - azul)</p> <p>Mas porque a imagem \u00e9 mostrada de modo estranho pelo pacote matplotlib? Porque a OpenCV representa os canais da imagem na ordem B - G - R, e n\u00e3o R - G - B como \u00e9 esperado pela maior parte das bibliotecas.</p> <p>Assim, para podermos visualizar corretamente uma imagem do OpenCV com matplotlib, precisamos inverter os canais, como no c\u00f3digo abaixo:</p> In\u00a0[72]: Copied! <pre>image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n\nplt.imshow(image_rgb)\n\nplt.axis('off') \nplt.show()\n</pre> image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)  plt.imshow(image_rgb)  plt.axis('off')  plt.show() In\u00a0[73]: Copied! <pre># Mostrando a representa\u00e7\u00e3o interna da imagem\nprint(\"Dimens\u00f5es da imagem: \", image_rgb.shape)\nprint(\"Quantidade de linhas: \", image_rgb.shape[0])\nprint(\"Quantidade de colunas: \", image_rgb.shape[1])\nprint(\"Camadas de cores: \", image_rgb.shape[2])\n</pre> # Mostrando a representa\u00e7\u00e3o interna da imagem print(\"Dimens\u00f5es da imagem: \", image_rgb.shape) print(\"Quantidade de linhas: \", image_rgb.shape[0]) print(\"Quantidade de colunas: \", image_rgb.shape[1]) print(\"Camadas de cores: \", image_rgb.shape[2]) <pre>Dimens\u00f5es da imagem:  (768, 1024, 3)\nQuantidade de linhas:  768\nQuantidade de colunas:  1024\nCamadas de cores:  3\n</pre> In\u00a0[74]: Copied! <pre># Mostrando a representa\u00e7\u00e3o interna da imagem\nprint(\"Dimens\u00f5es da imagem: \\n\", image_rgb)\n</pre> # Mostrando a representa\u00e7\u00e3o interna da imagem print(\"Dimens\u00f5es da imagem: \\n\", image_rgb)  <pre>Dimens\u00f5es da imagem: \n [[[ 10  92 194]\n  [ 12  94 196]\n  [ 12  95 197]\n  ...\n  [  6  98 201]\n  [  5  97 200]\n  [  2  95 198]]\n\n [[ 11  93 195]\n  [ 11  94 196]\n  [ 11  94 196]\n  ...\n  [  6  98 201]\n  [  6  98 201]\n  [  4  97 200]]\n\n [[ 11  94 196]\n  [ 11  94 196]\n  [  9  95 196]\n  ...\n  [  5  97 200]\n  [  7  99 202]\n  [  7 100 203]]\n\n ...\n\n [[  0  69 111]\n  [  1  70 112]\n  [  1  70 112]\n  ...\n  [ 11  31   6]\n  [ 17  41  17]\n  [  6  34   9]]\n\n [[  0  67 109]\n  [  0  69 111]\n  [  2  71 113]\n  ...\n  [ 65 105  68]\n  [ 86 135  90]\n  [ 82 136  86]]\n\n [[  0  66 108]\n  [  0  69 111]\n  [  2  71 113]\n  ...\n  [ 53 109  62]\n  [ 72 138  77]\n  [ 74 145  77]]]\n</pre> <p>A matriz acima \u00e9 a representa\u00e7\u00e3o da imagem de forma num\u00e9rica, \u00e9 o valor de cada pixel da imagem. Com esta imagem fica complicado. Vamos tentar analisar separando os canais de cores de um pixel espec\u00edfico.</p> In\u00a0[75]: Copied! <pre>(b, g, r) = image[450, 50]\nprint('O pixel (50, 50) tem as seguintes cores:')\nprint('Vermelho:',r, 'Verde:', g, 'Azul:', b)\n</pre> (b, g, r) = image[450, 50] print('O pixel (50, 50) tem as seguintes cores:') print('Vermelho:',r, 'Verde:', g, 'Azul:', b) <pre>O pixel (50, 50) tem as seguintes cores:\nVermelho: 2 Verde: 14 Azul: 36\n</pre> In\u00a0[76]: Copied! <pre># implemente aqui o seu c\u00f3digo.\n\n# vou carregar a imagem\nimage = cv2.imread(\"img3x3.png\")\n\n# vou converter a imagem para RGB\nimage_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n\n# vou mostrar a imagem\nplt.imshow(image_rgb)\nplt.axis('off')\nplt.show()\n\n# Mostrando a representa\u00e7\u00e3o interna e externa da imagem\nprint(\"Dimens\u00f5es da imagem: \", image_rgb.shape)\nprint(\"Quantidade de linhas: \", image_rgb.shape[0])\nprint(\"Quantidade de colunas: \", image_rgb.shape[1])\nprint(\"Camadas de cores: \", image_rgb.shape[2])\nprint(image_rgb)\n</pre> # implemente aqui o seu c\u00f3digo.  # vou carregar a imagem image = cv2.imread(\"img3x3.png\")  # vou converter a imagem para RGB image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)  # vou mostrar a imagem plt.imshow(image_rgb) plt.axis('off') plt.show()  # Mostrando a representa\u00e7\u00e3o interna e externa da imagem print(\"Dimens\u00f5es da imagem: \", image_rgb.shape) print(\"Quantidade de linhas: \", image_rgb.shape[0]) print(\"Quantidade de colunas: \", image_rgb.shape[1]) print(\"Camadas de cores: \", image_rgb.shape[2]) print(image_rgb)   <pre>Dimens\u00f5es da imagem:  (3, 3, 3)\nQuantidade de linhas:  3\nQuantidade de colunas:  3\nCamadas de cores:  3\n[[[255   5   5]\n  [255 255 255]\n  [  1   1 255]]\n\n [[255 255 255]\n  [  1 255   1]\n  [255 255 255]]\n\n [[  2 255 255]\n  [255 255  21]\n  [255   1 255]]]\n</pre> In\u00a0[77]: Copied! <pre>import cv2\nimport numpy as np\n\nfrom matplotlib import pyplot as plt\n\n\n# Carregando a imagem na vers\u00e3o tons de cinza (grayscale) de um arquivo\nimagem_cinza = cv2.imread(\"img3x3.png\", cv2.IMREAD_GRAYSCALE)\n\n# ou use o argumento 0, tem o mesmo efeito de importar na escala de cinza\n#imagem_cinza = cv2.imread(\"img3x3.png\", 0)\n\n\nplt.imshow(imagem_cinza)\n\nplt.axis('off') \nplt.show()\nimagem_cinza\n</pre> import cv2 import numpy as np  from matplotlib import pyplot as plt   # Carregando a imagem na vers\u00e3o tons de cinza (grayscale) de um arquivo imagem_cinza = cv2.imread(\"img3x3.png\", cv2.IMREAD_GRAYSCALE)  # ou use o argumento 0, tem o mesmo efeito de importar na escala de cinza #imagem_cinza = cv2.imread(\"img3x3.png\", 0)   plt.imshow(imagem_cinza)  plt.axis('off')  plt.show() imagem_cinza Out[77]: <pre>array([[ 79, 255,  29],\n       [255, 150, 255],\n       [179, 228, 105]], dtype=uint8)</pre> In\u00a0[78]: Copied! <pre># Coloque aqui sua solu\u00e7\u00e3o. \n\n# Importando a biblioteca OpenCV, Numpy e matplotlib\nimport cv2\nimport numpy as np\nfrom matplotlib import pyplot as plt\n\n\n# Carregando a imagem na vers\u00e3o tons de cinza (grayscale) de um arquivo\nimagem_cinza = cv2.imread(\"img3x3.png\", 0)\n\n# por padrao o matplotlib usa o cmap='viridis' para mostrar a imagem em tons de cinza.\n# para mostrar a imagem em tons de cinza com o matplotlib \u00e9 necess\u00e1rio usar o cmap='gray'\n# mas pode ser usado outro cmap para mostrar a imagem em tons de cinza com cores diferentes  \n\n# Mostrando a imagem em tons de cinza\nplt.subplot(1,2,1)\nplt.imshow(imagem_cinza)\nplt.axis('off')\nplt.title('cinza com cmap= viridis (padr\u00e3o)') \n\nplt.subplot(1,2,2)\nplt.imshow(imagem_cinza, cmap='gray')\nplt.axis('off')\nplt.title('Imagem em tons de cinza')\n\nplt.show()\n\n# o plt.subplot \u00e9 usado para mostrar mais de uma imagem na mesma janela do matplotlib \n# o primeiro argumento \u00e9 o n\u00famero de linhas\n# o segundo argumento \u00e9 o n\u00famero de colunas\n# o terceiro argumento \u00e9 o n\u00famero da imagem\n# o plt.title \u00e9 usado para mostrar o t\u00edtulo da imagem\n# o plt.show \u00e9 usado para mostrar a imagem\n</pre> # Coloque aqui sua solu\u00e7\u00e3o.   # Importando a biblioteca OpenCV, Numpy e matplotlib import cv2 import numpy as np from matplotlib import pyplot as plt   # Carregando a imagem na vers\u00e3o tons de cinza (grayscale) de um arquivo imagem_cinza = cv2.imread(\"img3x3.png\", 0)  # por padrao o matplotlib usa o cmap='viridis' para mostrar a imagem em tons de cinza. # para mostrar a imagem em tons de cinza com o matplotlib \u00e9 necess\u00e1rio usar o cmap='gray' # mas pode ser usado outro cmap para mostrar a imagem em tons de cinza com cores diferentes    # Mostrando a imagem em tons de cinza plt.subplot(1,2,1) plt.imshow(imagem_cinza) plt.axis('off') plt.title('cinza com cmap= viridis (padr\u00e3o)')   plt.subplot(1,2,2) plt.imshow(imagem_cinza, cmap='gray') plt.axis('off') plt.title('Imagem em tons de cinza')  plt.show()  # o plt.subplot \u00e9 usado para mostrar mais de uma imagem na mesma janela do matplotlib  # o primeiro argumento \u00e9 o n\u00famero de linhas # o segundo argumento \u00e9 o n\u00famero de colunas # o terceiro argumento \u00e9 o n\u00famero da imagem # o plt.title \u00e9 usado para mostrar o t\u00edtulo da imagem # o plt.show \u00e9 usado para mostrar a imagem In\u00a0[79]: Copied! <pre># Carregando a imagem na vers\u00e3o colorida de um arquivo\nimport cv2\nimport matplotlib.pyplot as plt\n\nimagem = cv2.imread(\"NATUREZA_1.jpg\")\nimage = cv2.cvtColor(imagem, cv2.COLOR_BGR2RGB)\n\nprint(\"Dimens\u00f5es da imagem: \", image.shape)\n\n\nimagem2 = cv2.resize(image, (600,400), cv2.INTER_LINEAR)\nprint(\"Novas dimens\u00f5es da imagem: \", imagem2.shape)\n\n\nplt.imshow(imagem2)\nplt.show()\n</pre> # Carregando a imagem na vers\u00e3o colorida de um arquivo import cv2 import matplotlib.pyplot as plt  imagem = cv2.imread(\"NATUREZA_1.jpg\") image = cv2.cvtColor(imagem, cv2.COLOR_BGR2RGB)  print(\"Dimens\u00f5es da imagem: \", image.shape)   imagem2 = cv2.resize(image, (600,400), cv2.INTER_LINEAR) print(\"Novas dimens\u00f5es da imagem: \", imagem2.shape)   plt.imshow(imagem2) plt.show() <pre>Dimens\u00f5es da imagem:  (768, 1024, 3)\nNovas dimens\u00f5es da imagem:  (400, 600, 3)\n</pre> In\u00a0[80]: Copied! <pre>#Implemente aqui sua solu\u00e7\u00e3o............\n\n# Carregando a imagem na vers\u00e3o colorida de um arquivo\nimport cv2\nimport matplotlib.pyplot as plt\nimagem = cv2.imread(\"img3x3.png\")\nimage = cv2.cvtColor(imagem, cv2.COLOR_BGR2RGB)\n\nprint(\"Dimens\u00f5es da imagem original: \", image.shape)\n\n# para testar diferentes m\u00e9todos de interpola\u00e7\u00e3o, vamos redimensionar a imagem para um tamanho maior\n# e vamos usar diferentes m\u00e9todos de interpola\u00e7\u00e3o para redimensionar a imagem \n# vamos usar os m\u00e9todos cv2.INTER_NEAREST, cv2.INTER_LINEAR, cv2.INTER_AREA, cv2.INTER_CUBIC e cv2.INTER_LANCZOS4 \n# que s\u00e3o os m\u00e9todos de interpola\u00e7\u00e3o dispon\u00edveis no OpenCV\ninterpolacao = [cv2.INTER_NEAREST, cv2.INTER_LINEAR, cv2.INTER_AREA, cv2.INTER_CUBIC, cv2.INTER_LANCZOS4]\n\n# essa fun\u00e7\u00e3o \u00e9 um list comprehension do python que cria uma lista com as imagens redimensionadas com os diferentes m\u00e9todos de interpola\u00e7\u00e3o \nresized_images = [cv2.resize(image, (image.shape[1] * 2, image.shape[0] * 5), interpolation=nome) for nome in interpolacao] \n\n# Vamos exibir as imagens redimensionadas com os diferentes m\u00e9todos de interpola\u00e7\u00e3o usando o matplotlib com o loop for.\ninterpolation_names = ['INTER_NEAREST', 'INTER_LINEAR', 'INTER_AREA', 'INTER_CUBIC', 'INTER_LANCZOS4']\nplt.figure(figsize=(15, 10))\nfor i, resized_image in enumerate(resized_images):\n    plt.subplot(2, 3, i + 1)\n    plt.imshow(resized_image)\n    plt.title(interpolation_names[i])\n    plt.axis('off')\n\nplt.show()\n</pre> #Implemente aqui sua solu\u00e7\u00e3o............  # Carregando a imagem na vers\u00e3o colorida de um arquivo import cv2 import matplotlib.pyplot as plt imagem = cv2.imread(\"img3x3.png\") image = cv2.cvtColor(imagem, cv2.COLOR_BGR2RGB)  print(\"Dimens\u00f5es da imagem original: \", image.shape)  # para testar diferentes m\u00e9todos de interpola\u00e7\u00e3o, vamos redimensionar a imagem para um tamanho maior # e vamos usar diferentes m\u00e9todos de interpola\u00e7\u00e3o para redimensionar a imagem  # vamos usar os m\u00e9todos cv2.INTER_NEAREST, cv2.INTER_LINEAR, cv2.INTER_AREA, cv2.INTER_CUBIC e cv2.INTER_LANCZOS4  # que s\u00e3o os m\u00e9todos de interpola\u00e7\u00e3o dispon\u00edveis no OpenCV interpolacao = [cv2.INTER_NEAREST, cv2.INTER_LINEAR, cv2.INTER_AREA, cv2.INTER_CUBIC, cv2.INTER_LANCZOS4]  # essa fun\u00e7\u00e3o \u00e9 um list comprehension do python que cria uma lista com as imagens redimensionadas com os diferentes m\u00e9todos de interpola\u00e7\u00e3o  resized_images = [cv2.resize(image, (image.shape[1] * 2, image.shape[0] * 5), interpolation=nome) for nome in interpolacao]   # Vamos exibir as imagens redimensionadas com os diferentes m\u00e9todos de interpola\u00e7\u00e3o usando o matplotlib com o loop for. interpolation_names = ['INTER_NEAREST', 'INTER_LINEAR', 'INTER_AREA', 'INTER_CUBIC', 'INTER_LANCZOS4'] plt.figure(figsize=(15, 10)) for i, resized_image in enumerate(resized_images):     plt.subplot(2, 3, i + 1)     plt.imshow(resized_image)     plt.title(interpolation_names[i])     plt.axis('off')  plt.show() <pre>Dimens\u00f5es da imagem original:  (3, 3, 3)\n</pre> In\u00a0[81]: Copied! <pre>import cv2\nimport numpy as np\n\n\n# Carregando a imagem\nimagem_cinza = cv2.imread(\"img3x3.png\", cv2.IMREAD_COLOR)\n\nplt.imshow(imagem_cinza)\n\nplt.axis('off') \nplt.show()\n</pre> import cv2 import numpy as np   # Carregando a imagem imagem_cinza = cv2.imread(\"img3x3.png\", cv2.IMREAD_COLOR)  plt.imshow(imagem_cinza)  plt.axis('off')  plt.show() In\u00a0[82]: Copied! <pre># implemente aqui sua solu\u00e7\u00e3o....\n\nimport cv2\nimport numpy as np\n\n\n# Carregando a imagem na vers\u00e3o colorida de um arquivo\nimagem = cv2.imread(\"img3x3.png\", cv2.IMREAD_COLOR)\nimagem_rgb = cv2.cvtColor(imagem, cv2.COLOR_BGR2RGB)\n\nimagem_rgb[0,0] = [255, 0, 255] # alterando a cor do pixel (0,0) para magenta \n\n\n\n# Mostrando a imagem em tons de cinza\nplt.subplot(1,2,1)\nplt.imshow(cv2.cvtColor(imagem, cv2.COLOR_BGR2RGB))\nplt.axis('off')\nplt.title('original') \n\nplt.subplot(1,2,2)\nplt.imshow(imagem_rgb)\nplt.axis('off')\nplt.title('alterada')\n\nplt.show()\n</pre> # implemente aqui sua solu\u00e7\u00e3o....  import cv2 import numpy as np   # Carregando a imagem na vers\u00e3o colorida de um arquivo imagem = cv2.imread(\"img3x3.png\", cv2.IMREAD_COLOR) imagem_rgb = cv2.cvtColor(imagem, cv2.COLOR_BGR2RGB)  imagem_rgb[0,0] = [255, 0, 255] # alterando a cor do pixel (0,0) para magenta     # Mostrando a imagem em tons de cinza plt.subplot(1,2,1) plt.imshow(cv2.cvtColor(imagem, cv2.COLOR_BGR2RGB)) plt.axis('off') plt.title('original')   plt.subplot(1,2,2) plt.imshow(imagem_rgb) plt.axis('off') plt.title('alterada')  plt.show() In\u00a0[83]: Copied! <pre># Come\u00e7amos importanto as bibliotecas \nimport cv2\nimport numpy as np\nfrom matplotlib import pyplot as plt\n\n# Criamos o array de zero 3x3\nletra = np.zeros((8,5), dtype=int)\n\n# implemente aqui o seu c\u00f3digo.........\n\nletra[0, 2] = 255\nletra[1, 1] = 255\nletra[1, 3] = 255\nletra[2, 0] = 255\nletra[2, 4] = 255\nletra[3, 0] = 255\nletra[3, 4] = 255\nletra[4, 0] = 255\nletra[4, 1] = 255\nletra[4, 2] = 255\nletra[4, 3] = 255\nletra[4, 4] = 255\nletra[5, 0] = 255\nletra[5, 4] = 255\nletra[6, 0] = 255\nletra[6, 4] = 255\nletra[7, 0] = 255\nletra[7, 4] = 255\n# Plota resultado\n\nplt.imshow(letra, cmap='gray')\nplt.show()\n</pre> # Come\u00e7amos importanto as bibliotecas  import cv2 import numpy as np from matplotlib import pyplot as plt  # Criamos o array de zero 3x3 letra = np.zeros((8,5), dtype=int)  # implemente aqui o seu c\u00f3digo.........  letra[0, 2] = 255 letra[1, 1] = 255 letra[1, 3] = 255 letra[2, 0] = 255 letra[2, 4] = 255 letra[3, 0] = 255 letra[3, 4] = 255 letra[4, 0] = 255 letra[4, 1] = 255 letra[4, 2] = 255 letra[4, 3] = 255 letra[4, 4] = 255 letra[5, 0] = 255 letra[5, 4] = 255 letra[6, 0] = 255 letra[6, 4] = 255 letra[7, 0] = 255 letra[7, 4] = 255 # Plota resultado  plt.imshow(letra, cmap='gray') plt.show() In\u00a0[6]: Copied! <pre>import cv2\nimagem = cv2.imread(\"NATUREZA_1.jpg\")\nimage = cv2.cvtColor(imagem, cv2.COLOR_BGR2RGB)\n\nfor y in range(0, image.shape[0]):\n  for x in range(0, image.shape[1]):\n    image[y, x] = (255,0,0) #sobreescrevendo todos os pixels da imagem para a cor vermelha\n    #pass\n    \nplt.imshow(image, interpolation=\"none\")\nplt.show()\n</pre> import cv2 imagem = cv2.imread(\"NATUREZA_1.jpg\") image = cv2.cvtColor(imagem, cv2.COLOR_BGR2RGB)  for y in range(0, image.shape[0]):   for x in range(0, image.shape[1]):     image[y, x] = (255,0,0) #sobreescrevendo todos os pixels da imagem para a cor vermelha     #pass      plt.imshow(image, interpolation=\"none\") plt.show() In\u00a0[5]: Copied! <pre>### seu c\u00f3digo aqui\nimport cv2\nimport matplotlib.pyplot as plt\n\nimagem = cv2.imread(\"NATUREZA_1.jpg\")\nimage = cv2.cvtColor(imagem, cv2.COLOR_BGR2RGB)\n\n# Achar o meio da imagem e o range\nmeio = image.shape[1] // 2 # Divis\u00e3o inteira para achar o meio da imagem (largura)\nfaixa = 50 // 2\nmin = meio - faixa\nmax = meio + faixa\n\nfor y in range(0, image.shape[0]):\n    for x in range(0, image.shape[1]):\n        if x &gt; min and x &lt; max:\n            image[y, x] = (255, 0, 0)  # Sobreescrevendo todos os pixels da imagem para a cor vermelha\n\nplt.imshow(image, interpolation=\"none\")\nplt.show()\n</pre> ### seu c\u00f3digo aqui import cv2 import matplotlib.pyplot as plt  imagem = cv2.imread(\"NATUREZA_1.jpg\") image = cv2.cvtColor(imagem, cv2.COLOR_BGR2RGB)  # Achar o meio da imagem e o range meio = image.shape[1] // 2 # Divis\u00e3o inteira para achar o meio da imagem (largura) faixa = 50 // 2 min = meio - faixa max = meio + faixa  for y in range(0, image.shape[0]):     for x in range(0, image.shape[1]):         if x &gt; min and x &lt; max:             image[y, x] = (255, 0, 0)  # Sobreescrevendo todos os pixels da imagem para a cor vermelha  plt.imshow(image, interpolation=\"none\") plt.show()"},{"location":"aulas/PDI/lab01/sol_IntroPID.html#representacao-e-visualizacao-de-imagem","title":"Representa\u00e7\u00e3o e visualiza\u00e7\u00e3o de imagem\u00b6","text":"<p>Uma imagem digital nada mais \u00e9 que uma uma matriz de linhas e colunas, onde cada posi\u00e7\u00e3o desta matriz contem o valor de um pixel.</p> <p>O valor de cada pixel representa a intensidade de cor naquele ponto especifico.</p>"},{"location":"aulas/PDI/lab01/sol_IntroPID.html#dica-para-quem-esta-utilizando-o-google-colab","title":"Dica para quem est\u00e1 utilizando o google colab\u00b6","text":"<p>Por ser uma inst\u00e2ncia que \u00e9 alocada temporariamente precisamos carregar as imagens neste se\u00e7\u00e3o.</p> <p>Est\u00e1 etapa pode ser feita de forma manual, fazendo o upload das imagens.</p> <p>Outra forma \u00e9 fazer o download da imagem para o notebook, lempre-se que \u00e9 um linux rodando! :) da uma olhada no exemplo abaixo.</p>"},{"location":"aulas/PDI/lab01/sol_IntroPID.html#desafio-1","title":"Desafio 1\u00b6","text":"<p>Abra a imagem \"img3x3.png\" e plote suas componentes externas (shape) e internas (matriz).</p> <p>Como voc\u00ea esta relacionado as possi\u00e7\u00f5es da matriz com os pixels da imagem??</p>"},{"location":"aulas/PDI/lab01/sol_IntroPID.html#imagem-em-tons-de-cinza","title":"Imagem em tons de cinza\u00b6","text":"<p>Em muitos casos trabalhamos com imagens na escala de cinza, logo, a imagem possui apenas 1 canal de cor.</p>"},{"location":"aulas/PDI/lab01/sol_IntroPID.html#desafio-2","title":"Desafio 2\u00b6","text":"<p>Eita! alguma est\u00e1 errada nesse plot, era esperado uma imagem na escala de cinza. Por que apareceu isso, como corrigir?</p>"},{"location":"aulas/PDI/lab01/sol_IntroPID.html#amostragem-da-imagem","title":"Amostragem da imagem\u00b6","text":"<p>As imagens capturadas por dispositivos digitais possuem as caracter\u00edsticas de resolu\u00e7\u00e3o espacial e resolu\u00e7\u00e3o de cores Enquanto a resolu\u00e7\u00e3o de cores afeta o n\u00famero de cores que podem serr epresentadas na imagem, sua resolu\u00e7\u00e3o espacial afeta o tamanho que a imagem ir\u00e1 ter. Embora n\u00e3o se possa comparar diretamente a resolu\u00e7\u00e3o de duas imagens com tamanhos diferentes, a imagem do mesmo objeto, se possui mais pixels, significar\u00e1 que tam\u00e9m possui maior resolu\u00e7\u00e3o</p>"},{"location":"aulas/PDI/lab01/sol_IntroPID.html#alterando-o-tamanho-de-uma-imagem","title":"Alterando o tamanho de uma imagem\u00b6","text":"<p>O redimensionamento da imagem pode ser feito na OpenCV atrav\u00e9s do comando <code>cv2.resize(imagem, tamanho, interpola\u00e7\u00e3o)</code></p> <p>O tamanho \u00e9 dado por uma tupla (W,H), onde W \u00e9 a largura (n\u00famero de colunas) e H \u00e9 a altura (n\u00famero de linhas)</p>"},{"location":"aulas/PDI/lab01/sol_IntroPID.html#desafio-3","title":"Desafio 3\u00b6","text":"<p>Comparar os diferentes m\u00e9todos de interpola\u00e7\u00e3o (vizinho mais pr\u00f3ximo, bilinear e bic\u00fabica) ao ampliarmos uma imagem em 10 vezes seu tamanho. Escolha uma imagem pequena.</p> <p>Dica de onde encontrar na documenta\u00e7\u00e3o as flags de interpola\u00e7\u00e3o: https://docs.opencv.org/3.4/da/d54/group__imgproc__transform.html#ga5bb5a1fea74ea38e1a5445ca803ff121</p> <p>Para saber mais sobre interpola\u00e7\u00e3o, sugiro assistir ao video: https://www.youtube.com/watch?v=8bTDssnJyZc&amp;ab_channel=S.M.RiazulIslam</p>"},{"location":"aulas/PDI/lab01/sol_IntroPID.html#alterando-os-valores-dos-pixels-de-uma-imagem","title":"Alterando os valores dos pixels de uma imagem\u00b6","text":""},{"location":"aulas/PDI/lab01/sol_IntroPID.html#range-de-valores","title":"Range de valores\u00b6","text":"<p>Antes de alterar os valores dos pixels temos que entender que a OpenCV trabalha com valores de 8 bits para cada componente de cor ou escala de cinza, quer dizer que os valores possiveis est\u00e3o no range entre 0 e 2\u2078-1, que \u00e9 a mesma que dizer entre 0 e 255.</p>"},{"location":"aulas/PDI/lab01/sol_IntroPID.html#desafio-4","title":"Desafio 4\u00b6","text":"<p>Implemente um codigo que faz a altera\u00e7\u00e3o do pixel(0,0) para a a cor Magenta - RGB (255,0,255);</p>"},{"location":"aulas/PDI/lab01/sol_IntroPID.html#desafio-5","title":"Desafio 5\u00b6","text":"<p>Crie uma array de zero com 8 linhas e 5 colunas. E escreva (desenhe) a primeira letra do seu nome ou grupo.</p> <p>Plot a imagem para visualizar o resultado.</p> <p>Dica: Use np.zeros() para criar o array, para facilitar fa\u00e7a em escala de cinza onde o valor de intensidade do pixel 0=branco e 255=preto.</p>"},{"location":"aulas/PDI/lab01/sol_IntroPID.html#varredura-de-uma-imagem","title":"Varredura de uma imagem\u00b6","text":"<p>Desenvolver uma rotina capaz de varrer sua imagem pixel a pixel \u00e9 muito mais interessante para aplica\u00e7\u00f5es mais pr\u00e1ticas, embora exista tecnicas mais otimizadas e r\u00e1pidas para essa aplica\u00e7\u00e3o, podemos utilizar uma estrutura de dois la\u00e7os For para passar sobre todas as linhas e todas as colunas da matriz (imagem).</p>"},{"location":"aulas/PDI/lab01/sol_IntroPID.html#desafio-6","title":"Desafio 6\u00b6","text":"<p>Utilizando a t\u00e9cnica dos 2 for, implemente uma fun\u00e7\u00e3o que desenha um linha branca na vertical no centro da imagem de largura 50 pixeis. Dica: use um if para checar a posi\u00e7\u00e3o (x,y) antes de pintar de branco o pixel.</p>"},{"location":"aulas/PDI/lab02/atividade2.html","title":"Lab02 - Seguimenta\u00e7\u00e3o por pixel","text":"<p>Objetivos da aula:</p> <ul> <li>Filtro negativo de imagem</li> <li>Recorte da imagem</li> <li>Seguimenta\u00e7\u00e3o por pixel</li> </ul> In\u00a0[4]: Copied! <pre>%matplotlib inline\n# Importando a biblioteca OpenCV\nimport cv2 \n\n#import a biblioteca Numpy\nimport numpy as np\n\nfrom matplotlib import pyplot as plt\n\n\nprint (\"OpenCV Vers\u00e3o : %s \" % cv2.__version__)\n</pre> %matplotlib inline # Importando a biblioteca OpenCV import cv2   #import a biblioteca Numpy import numpy as np  from matplotlib import pyplot as plt   print (\"OpenCV Vers\u00e3o : %s \" % cv2.__version__) <pre>OpenCV Vers\u00e3o : 4.6.0 \n</pre> In\u00a0[5]: Copied! <pre>!wget \"https://raw.githubusercontent.com/arnaldojr/cognitivecomputing/master/material/aulas/PDI/lab02/cogumelo.png\" /content\n!wget \"https://raw.githubusercontent.com/arnaldojr/cognitivecomputing/master/material/aulas/PDI/lab02/droneinvertido.jpg\" /content\n!wget \"https://raw.githubusercontent.com/arnaldojr/cognitivecomputing/master/material/aulas/PDI/lab02/drone.jpg\" /content\n!wget \"https://raw.githubusercontent.com/arnaldojr/cognitivecomputing/master/material/aulas/PDI/lab02/droneinvertido.jpg\" /content\n!wget \"https://raw.githubusercontent.com/arnaldojr/cognitivecomputing/master/material/aulas/PDI/lab02/goku.jpg\" /content\n!wget \"https://raw.githubusercontent.com/arnaldojr/cognitivecomputing/master/material/aulas/PDI/lab02/gokuinvertido.jpg\" /content\n!wget \"https://raw.githubusercontent.com/arnaldojr/cognitivecomputing/master/material/aulas/PDI/lab02/cogumelo.png\" /content\n</pre> !wget \"https://raw.githubusercontent.com/arnaldojr/cognitivecomputing/master/material/aulas/PDI/lab02/cogumelo.png\" /content !wget \"https://raw.githubusercontent.com/arnaldojr/cognitivecomputing/master/material/aulas/PDI/lab02/droneinvertido.jpg\" /content !wget \"https://raw.githubusercontent.com/arnaldojr/cognitivecomputing/master/material/aulas/PDI/lab02/drone.jpg\" /content !wget \"https://raw.githubusercontent.com/arnaldojr/cognitivecomputing/master/material/aulas/PDI/lab02/droneinvertido.jpg\" /content !wget \"https://raw.githubusercontent.com/arnaldojr/cognitivecomputing/master/material/aulas/PDI/lab02/goku.jpg\" /content !wget \"https://raw.githubusercontent.com/arnaldojr/cognitivecomputing/master/material/aulas/PDI/lab02/gokuinvertido.jpg\" /content !wget \"https://raw.githubusercontent.com/arnaldojr/cognitivecomputing/master/material/aulas/PDI/lab02/cogumelo.png\" /content <pre>--2023-02-10 19:36:13--  https://raw.githubusercontent.com/arnaldojr/cognitivecomputing/master/material/aulas/lab02/cogumelo.png\nResolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.111.133, 185.199.109.133, ...\nConnecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 48478 (47K) [image/png]\nSaving to: \u2018cogumelo.png.2\u2019\n\n\rcogumelo.png.2        0%[                    ]       0  --.-KB/s               \rcogumelo.png.2      100%[===================&gt;]  47.34K  --.-KB/s    in 0.01s   \n\n2023-02-10 19:36:13 (4.58 MB/s) - \u2018cogumelo.png.2\u2019 saved [48478/48478]\n\n/content: Scheme missing.\nFINISHED --2023-02-10 19:36:13--\nTotal wall clock time: 0.06s\nDownloaded: 1 files, 47K in 0.01s (4.58 MB/s)\n--2023-02-10 19:36:13--  https://raw.githubusercontent.com/arnaldojr/cognitivecomputing/master/material/aulas/lab02/droneinvertido.jpg\nResolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.109.133, 185.199.110.133, ...\nConnecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 52937 (52K) [image/jpeg]\nSaving to: \u2018droneinvertido.jpg.2\u2019\n\ndroneinvertido.jpg. 100%[===================&gt;]  51.70K  --.-KB/s    in 0.01s   \n\n2023-02-10 19:36:13 (4.78 MB/s) - \u2018droneinvertido.jpg.2\u2019 saved [52937/52937]\n\n/content: Scheme missing.\nFINISHED --2023-02-10 19:36:13--\nTotal wall clock time: 0.06s\nDownloaded: 1 files, 52K in 0.01s (4.78 MB/s)\n--2023-02-10 19:36:13--  https://raw.githubusercontent.com/arnaldojr/cognitivecomputing/master/material/aulas/lab02/drone.jpg\nResolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\nConnecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 37505 (37K) [image/jpeg]\nSaving to: \u2018drone.jpg.1\u2019\n\ndrone.jpg.1         100%[===================&gt;]  36.63K  --.-KB/s    in 0.003s  \n\n2023-02-10 19:36:13 (11.0 MB/s) - \u2018drone.jpg.1\u2019 saved [37505/37505]\n\n/content: Scheme missing.\nFINISHED --2023-02-10 19:36:13--\nTotal wall clock time: 0.06s\nDownloaded: 1 files, 37K in 0.003s (11.0 MB/s)\n--2023-02-10 19:36:13--  https://raw.githubusercontent.com/arnaldojr/cognitivecomputing/master/material/aulas/lab02/droneinvertido.jpg\nResolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\nConnecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 52937 (52K) [image/jpeg]\nSaving to: \u2018droneinvertido.jpg.3\u2019\n\ndroneinvertido.jpg. 100%[===================&gt;]  51.70K  --.-KB/s    in 0.01s   \n\n2023-02-10 19:36:13 (4.84 MB/s) - \u2018droneinvertido.jpg.3\u2019 saved [52937/52937]\n\n/content: Scheme missing.\nFINISHED --2023-02-10 19:36:13--\nTotal wall clock time: 0.06s\nDownloaded: 1 files, 52K in 0.01s (4.84 MB/s)\n--2023-02-10 19:36:13--  https://raw.githubusercontent.com/arnaldojr/cognitivecomputing/master/material/aulas/lab02/goku.jpg\nResolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\nConnecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 113004 (110K) [image/jpeg]\nSaving to: \u2018goku.jpg.1\u2019\n\ngoku.jpg.1          100%[===================&gt;] 110.36K  --.-KB/s    in 0.02s   \n\n2023-02-10 19:36:13 (5.17 MB/s) - \u2018goku.jpg.1\u2019 saved [113004/113004]\n\n/content: Scheme missing.\nFINISHED --2023-02-10 19:36:13--\nTotal wall clock time: 0.07s\nDownloaded: 1 files, 110K in 0.02s (5.17 MB/s)\n--2023-02-10 19:36:14--  https://raw.githubusercontent.com/arnaldojr/cognitivecomputing/master/material/aulas/lab02/gokuinvertido.jpg\nResolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\nConnecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 154233 (151K) [image/jpeg]\nSaving to: \u2018gokuinvertido.jpg.1\u2019\n\ngokuinvertido.jpg.1 100%[===================&gt;] 150.62K  --.-KB/s    in 0.02s   \n\n2023-02-10 19:36:14 (6.56 MB/s) - \u2018gokuinvertido.jpg.1\u2019 saved [154233/154233]\n\n/content: Scheme missing.\nFINISHED --2023-02-10 19:36:14--\nTotal wall clock time: 0.07s\nDownloaded: 1 files, 151K in 0.02s (6.56 MB/s)\n--2023-02-10 19:36:14--  https://raw.githubusercontent.com/arnaldojr/cognitivecomputing/master/material/aulas/lab02/cogumelo.png\nResolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\nConnecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 48478 (47K) [image/png]\nSaving to: \u2018cogumelo.png.3\u2019\n\ncogumelo.png.3      100%[===================&gt;]  47.34K  --.-KB/s    in 0.01s   \n\n2023-02-10 19:36:14 (4.43 MB/s) - \u2018cogumelo.png.3\u2019 saved [48478/48478]\n\n/content: Scheme missing.\nFINISHED --2023-02-10 19:36:14--\nTotal wall clock time: 0.06s\nDownloaded: 1 files, 47K in 0.01s (4.43 MB/s)\n</pre> In\u00a0[6]: Copied! <pre>import cv2\nimagem = cv2.imread(\"cogumelo.png\")\nimage = cv2.cvtColor(imagem, cv2.COLOR_BGR2GRAY)\n\nplt.imshow(image, interpolation=\"none\", cmap=\"gray\")\nplt.show()\n</pre> import cv2 imagem = cv2.imread(\"cogumelo.png\") image = cv2.cvtColor(imagem, cv2.COLOR_BGR2GRAY)  plt.imshow(image, interpolation=\"none\", cmap=\"gray\") plt.show() In\u00a0[7]: Copied! <pre>import cv2\nimagem = cv2.imread(\"cogumelo.png\")\nimage = cv2.cvtColor(imagem, cv2.COLOR_BGR2GRAY)\n\nfor y in range(0, image.shape[0]):\n  for x in range(0, image.shape[1]):\n    ##### aqui eu inverto o valor do pixel\n    if image[y, x] == 255:\n      image[y,x] = 0\n    else:\n      image[y,x] = 255\n\nplt.imshow(image, interpolation=\"none\", cmap=\"gray\")\nplt.show()\n</pre> import cv2 imagem = cv2.imread(\"cogumelo.png\") image = cv2.cvtColor(imagem, cv2.COLOR_BGR2GRAY)  for y in range(0, image.shape[0]):   for x in range(0, image.shape[1]):     ##### aqui eu inverto o valor do pixel     if image[y, x] == 255:       image[y,x] = 0     else:       image[y,x] = 255  plt.imshow(image, interpolation=\"none\", cmap=\"gray\") plt.show() In\u00a0[8]: Copied! <pre># implemente aqui sua solu\u00e7\u00e3o\n</pre> # implemente aqui sua solu\u00e7\u00e3o      In\u00a0[9]: Copied! <pre># Implemente aqui sua solu\u00e7\u00e3o\n</pre> # Implemente aqui sua solu\u00e7\u00e3o         In\u00a0[10]: Copied! <pre>import cv2\nimagem = cv2.imread(\"drone.jpg\")\nimage = cv2.cvtColor(imagem, cv2.COLOR_BGR2RGB)\n\nplt.imshow(image, interpolation=\"none\")\n\nplt.show()\n</pre> import cv2 imagem = cv2.imread(\"drone.jpg\") image = cv2.cvtColor(imagem, cv2.COLOR_BGR2RGB)  plt.imshow(image, interpolation=\"none\")  plt.show()  In\u00a0[11]: Copied! <pre>image2 = image.copy()\n\n#crop_img = img[y:y+h, x:x+w]\nimage2 = image[50:250,580:950]\n\nplt.imshow(image2, interpolation=\"none\", cmap=\"gray\")\nplt.show()\n</pre> image2 = image.copy()  #crop_img = img[y:y+h, x:x+w] image2 = image[50:250,580:950]  plt.imshow(image2, interpolation=\"none\", cmap=\"gray\") plt.show() In\u00a0[12]: Copied! <pre>import cv2\nimagem = cv2.imread(\"gokuinvertido.jpg\")\nimage = cv2.cvtColor(imagem, cv2.COLOR_BGR2RGB)\n\naltura = image.shape[0]\nlargura = image.shape[1]\n\nprint(\"altura: {} largura: {}\".format(altura, largura))\n\nplt.imshow(image, interpolation=\"none\")\n\nplt.show()\n\n# para salvar imagem\n#cv2.imwrite(\"gokunormal.jpg\", cv2.cvtColor(image2, cv2.COLOR_RGB2BGR))\n</pre> import cv2 imagem = cv2.imread(\"gokuinvertido.jpg\") image = cv2.cvtColor(imagem, cv2.COLOR_BGR2RGB)  altura = image.shape[0] largura = image.shape[1]  print(\"altura: {} largura: {}\".format(altura, largura))  plt.imshow(image, interpolation=\"none\")  plt.show()  # para salvar imagem #cv2.imwrite(\"gokunormal.jpg\", cv2.cvtColor(image2, cv2.COLOR_RGB2BGR)) <pre>altura: 720 largura: 1280\n</pre> In\u00a0[13]: Copied! <pre>#implemente sua solu\u00e7\u00e3o \n</pre> #implemente sua solu\u00e7\u00e3o       In\u00a0[14]: Copied! <pre># Entenda o codigo e fa\u00e7a as altera\u00e7\u00f5es que achar necess\u00e1rias\nimport cv2\nimagem = cv2.imread(\"drone.jpg\")\nimage = cv2.cvtColor(imagem, cv2.COLOR_BGR2RGB)\nprint(image.shape)\n\nfor y in range(0, image.shape[0]):\n  for x in range(0, image.shape[1]):\n    if image[y,x,1] &gt; 170 :\n      image[y,x]= (255,255,255)\n    \n\nplt.imshow(image, interpolation=\"none\")\nplt.show()\n</pre> # Entenda o codigo e fa\u00e7a as altera\u00e7\u00f5es que achar necess\u00e1rias import cv2 imagem = cv2.imread(\"drone.jpg\") image = cv2.cvtColor(imagem, cv2.COLOR_BGR2RGB) print(image.shape)  for y in range(0, image.shape[0]):   for x in range(0, image.shape[1]):     if image[y,x,1] &gt; 170 :       image[y,x]= (255,255,255)       plt.imshow(image, interpolation=\"none\") plt.show() <pre>(420, 1120, 3)\n</pre> In\u00a0[15]: Copied! <pre># Implemente seu c\u00f3digo aqui\n</pre> # Implemente seu c\u00f3digo aqui"},{"location":"aulas/PDI/lab02/atividade2.html#filtro-negativo-inverte-imagem","title":"Filtro negativo (Inverte imagem)\u00b6","text":"<p>Para aplicar um filtro negativo precisamos inverter os seus valores, ou seja, em uma imagem bin\u00e1ria realizamos a troca de 0 pra 1 e de 1 para 0 para cada pixel da imagem.</p>"},{"location":"aulas/PDI/lab02/atividade2.html#desafio-1","title":"Desafio 1\u00b6","text":"<p>Fa\u00e7a uma implementa\u00e7\u00e3o que inverte as cores de uma imagem em escala de cinza, com valores que v\u00e3o de 0 ate 255. dica: a forma explicita de fazer uma invers\u00e3\u00e3o \u00e9: a = 255 - a</p>"},{"location":"aulas/PDI/lab02/atividade2.html#desafio-2","title":"Desafio 2\u00b6","text":"<p>Fa\u00e7a o mesmo par uma imagem colorida, realize a invers\u00e3o de cores dos canais R, G e B.</p> <p>o resultado deve ser parecido com a imagem abaixo: </p>"},{"location":"aulas/PDI/lab02/atividade2.html#recorte-da-imagem-crop","title":"Recorte da imagem (crop)\u00b6","text":"<p>O recorte de uma parte da imagem, ou crop, consiste em extrair da imagem uma regi\u00e3o de interresse (ROI).</p>"},{"location":"aulas/PDI/lab02/atividade2.html#desafio3","title":"Desafio3\u00b6","text":"<p>Ajude o nosso sayajin!!</p> <p></p> <p>A imagem foi dividida em 4 quadrantes aleatorios e precisamos organizar essa bagun\u00e7a. Fa\u00e7a a reconstru\u00e7\u00e3o da imagem nas posi\u00e7\u00f5es corretas.</p> <p>Dica: Crie uma copia da imagem original (img2 = img.copy()), fa\u00e7a um crop da imagem 4 partes (crop1, crop2, crop3, crop4), junte as partes cortadas na ordem correta na img2. no final Salve a imagem (cv2.imwrite())</p>"},{"location":"aulas/PDI/lab02/atividade2.html#seguimentacao-de-imagens","title":"Seguimenta\u00e7\u00e3o de imagens\u00b6","text":"<p>Agora que sabemos como manipular pixel e como alterar seu valor e sua posi\u00e7\u00e3o. Podemos fazer atividades mais complexas como conseguir reaalizar a seguimenta\u00e7\u00e3o de algum objeto ou item da imagem (video), Como na imagem abaixo.</p>"},{"location":"aulas/PDI/lab02/atividade2.html#desafio-4","title":"Desafio 4\u00b6","text":"<p>De forma intuitiva realize algumas mudan\u00e7as no c\u00f3digo e veja o efeito que causa na imagem. Este exercio \u00e9 apenas um aperitivo de algumas tecnicas que vamos estudar na proxima aula.</p>"},{"location":"aulas/PDI/lab02/atividade2.html#desafio-5","title":"Desafio 5\u00b6","text":"<p>Vamos tentar fazer o contrario, vamos tentar filtar o fundo da imagem sem o drone</p>"},{"location":"aulas/PDI/lab02/sol_atividade2.html","title":"Sol atividade2","text":"<p>Objetivos da aula:</p> <ul> <li>Filtro negativo de imagem</li> <li>Recorte da imagem</li> <li>Seguimenta\u00e7\u00e3o por pixel</li> </ul> In\u00a0[1]: Copied! <pre>%matplotlib inline\n# Importando a biblioteca OpenCV\nimport cv2 \n\n#import a biblioteca Numpy\nimport numpy as np\n\nfrom matplotlib import pyplot as plt\n\n\nprint (\"OpenCV Vers\u00e3o : %s \" % cv2.__version__)\n</pre> %matplotlib inline # Importando a biblioteca OpenCV import cv2   #import a biblioteca Numpy import numpy as np  from matplotlib import pyplot as plt   print (\"OpenCV Vers\u00e3o : %s \" % cv2.__version__) <pre>OpenCV Vers\u00e3o : 4.9.0 \n</pre> In\u00a0[\u00a0]: Copied! <pre>!wget \"https://raw.githubusercontent.com/arnaldojr/cognitivecomputing/master/material/aulas/PDI/lab02/cogumelo.png\" /content\n!wget \"https://raw.githubusercontent.com/arnaldojr/cognitivecomputing/master/material/aulas/PDI/lab02/droneinvertido.jpg\" /content\n!wget \"https://raw.githubusercontent.com/arnaldojr/cognitivecomputing/master/material/aulas/PDI/lab02/drone.jpg\" /content\n!wget \"https://raw.githubusercontent.com/arnaldojr/cognitivecomputing/master/material/aulas/PDI/lab02/droneinvertido.jpg\" /content\n!wget \"https://raw.githubusercontent.com/arnaldojr/cognitivecomputing/master/material/aulas/PDI/lab02/goku.jpg\" /content\n!wget \"https://raw.githubusercontent.com/arnaldojr/cognitivecomputing/master/material/aulas/PDI/lab02/gokuinvertido.jpg\" /content\n!wget \"https://raw.githubusercontent.com/arnaldojr/cognitivecomputing/master/material/aulas/PDI/lab02/cogumelo.png\" /content\n</pre> !wget \"https://raw.githubusercontent.com/arnaldojr/cognitivecomputing/master/material/aulas/PDI/lab02/cogumelo.png\" /content !wget \"https://raw.githubusercontent.com/arnaldojr/cognitivecomputing/master/material/aulas/PDI/lab02/droneinvertido.jpg\" /content !wget \"https://raw.githubusercontent.com/arnaldojr/cognitivecomputing/master/material/aulas/PDI/lab02/drone.jpg\" /content !wget \"https://raw.githubusercontent.com/arnaldojr/cognitivecomputing/master/material/aulas/PDI/lab02/droneinvertido.jpg\" /content !wget \"https://raw.githubusercontent.com/arnaldojr/cognitivecomputing/master/material/aulas/PDI/lab02/goku.jpg\" /content !wget \"https://raw.githubusercontent.com/arnaldojr/cognitivecomputing/master/material/aulas/PDI/lab02/gokuinvertido.jpg\" /content !wget \"https://raw.githubusercontent.com/arnaldojr/cognitivecomputing/master/material/aulas/PDI/lab02/cogumelo.png\" /content In\u00a0[2]: Copied! <pre>import cv2\nimagem = cv2.imread(\"cogumelo.png\")\nimage = cv2.cvtColor(imagem, cv2.COLOR_BGR2GRAY)\n\nplt.imshow(image, interpolation=\"none\", cmap=\"gray\")\nplt.show()\n</pre> import cv2 imagem = cv2.imread(\"cogumelo.png\") image = cv2.cvtColor(imagem, cv2.COLOR_BGR2GRAY)  plt.imshow(image, interpolation=\"none\", cmap=\"gray\") plt.show() In\u00a0[4]: Copied! <pre>import cv2\nimagem = cv2.imread(\"cogumelo.png\")\nimage = cv2.cvtColor(imagem, cv2.COLOR_BGR2GRAY)\n\nfor y in range(0, image.shape[0]):\n  for x in range(0, image.shape[1]):\n    ##### aqui eu inverto o valor do pixel\n    if image[y, x] == 255:\n      image[y,x] = 0\n    else:\n      image[y,x] = 255\n\nplt.imshow(image, interpolation=\"none\", cmap=\"gray\")\nplt.show()\n</pre> import cv2 imagem = cv2.imread(\"cogumelo.png\") image = cv2.cvtColor(imagem, cv2.COLOR_BGR2GRAY)  for y in range(0, image.shape[0]):   for x in range(0, image.shape[1]):     ##### aqui eu inverto o valor do pixel     if image[y, x] == 255:       image[y,x] = 0     else:       image[y,x] = 255  plt.imshow(image, interpolation=\"none\", cmap=\"gray\") plt.show() In\u00a0[5]: Copied! <pre># implemente aqui sua solu\u00e7\u00e3o\n\n\nimport cv2\nimagem = cv2.imread(\"cogumelo.png\")\nimage = cv2.cvtColor(imagem, cv2.COLOR_BGR2GRAY)\n\nfor y in range(0, image.shape[0]):\n  for x in range(0, image.shape[1]):\n    ##### aqui eu inverto o valor do pixel\n    image[y, x] = 255 -image[y, x]\n\n\nplt.imshow(image, interpolation=\"none\", cmap=\"gray\")\nplt.show()\n</pre> # implemente aqui sua solu\u00e7\u00e3o   import cv2 imagem = cv2.imread(\"cogumelo.png\") image = cv2.cvtColor(imagem, cv2.COLOR_BGR2GRAY)  for y in range(0, image.shape[0]):   for x in range(0, image.shape[1]):     ##### aqui eu inverto o valor do pixel     image[y, x] = 255 -image[y, x]   plt.imshow(image, interpolation=\"none\", cmap=\"gray\") plt.show()   In\u00a0[9]: Copied! <pre># Implemente aqui sua solu\u00e7\u00e3o\n\nimport cv2\nimagem = cv2.imread(\"drone.jpg\")\nimage = cv2.cvtColor(imagem, cv2.COLOR_BGR2RGB)\n\nfor y in range(0, image.shape[0]):\n  for x in range(0, image.shape[1]):\n    ##### aqui eu inverto o valor do pixel\n    image[y, x] = 255 -image[y, x]\n\n\nplt.imshow(image, interpolation=\"none\", cmap=\"gray\")\nplt.show()\n</pre> # Implemente aqui sua solu\u00e7\u00e3o  import cv2 imagem = cv2.imread(\"drone.jpg\") image = cv2.cvtColor(imagem, cv2.COLOR_BGR2RGB)  for y in range(0, image.shape[0]):   for x in range(0, image.shape[1]):     ##### aqui eu inverto o valor do pixel     image[y, x] = 255 -image[y, x]   plt.imshow(image, interpolation=\"none\", cmap=\"gray\") plt.show() In\u00a0[10]: Copied! <pre>import cv2\nimagem = cv2.imread(\"drone.jpg\")\nimage = cv2.cvtColor(imagem, cv2.COLOR_BGR2RGB)\n\nplt.imshow(image, interpolation=\"none\")\n\nplt.show()\n</pre> import cv2 imagem = cv2.imread(\"drone.jpg\") image = cv2.cvtColor(imagem, cv2.COLOR_BGR2RGB)  plt.imshow(image, interpolation=\"none\")  plt.show()  In\u00a0[11]: Copied! <pre>image2 = image.copy()\n\n#crop_img = img[y:y+h, x:x+w]\nimage2 = image[50:250,580:950]\n\nplt.imshow(image2, interpolation=\"none\", cmap=\"gray\")\nplt.show()\n</pre> image2 = image.copy()  #crop_img = img[y:y+h, x:x+w] image2 = image[50:250,580:950]  plt.imshow(image2, interpolation=\"none\", cmap=\"gray\") plt.show() In\u00a0[12]: Copied! <pre>import cv2\nimagem = cv2.imread(\"gokuinvertido.jpg\")\nimage = cv2.cvtColor(imagem, cv2.COLOR_BGR2RGB)\n\naltura = image.shape[0]\nlargura = image.shape[1]\n\nprint(\"altura: {} largura: {}\".format(altura, largura))\n\nplt.imshow(image, interpolation=\"none\")\n\nplt.show()\n\n# para salvar imagem\n#cv2.imwrite(\"gokunormal.jpg\", cv2.cvtColor(image2, cv2.COLOR_RGB2BGR))\n</pre> import cv2 imagem = cv2.imread(\"gokuinvertido.jpg\") image = cv2.cvtColor(imagem, cv2.COLOR_BGR2RGB)  altura = image.shape[0] largura = image.shape[1]  print(\"altura: {} largura: {}\".format(altura, largura))  plt.imshow(image, interpolation=\"none\")  plt.show()  # para salvar imagem #cv2.imwrite(\"gokunormal.jpg\", cv2.cvtColor(image2, cv2.COLOR_RGB2BGR)) <pre>altura: 720 largura: 1280\n</pre> In\u00a0[12]: Copied! <pre>#implemente sua solu\u00e7\u00e3o \n\nimport cv2\nimagem = cv2.imread(\"gokuinvertido.jpg\")\nimage = cv2.cvtColor(imagem, cv2.COLOR_BGR2RGB)\n\naltura_metade = image.shape[0]//2\nlargura_metade = image.shape[1]//2\n\n#crop_img = img[y:y+h, x:x+w] em 4 partes\ncrop1 = image[0:altura_metade,0:largura_metade]\ncrop2 = image[0:altura_metade,largura_metade:largura_metade*2]\ncrop3 = image[altura_metade:altura_metade*2,0:largura_metade]\ncrop4 = image[altura_metade:altura_metade*2,largura_metade:largura_metade*2]\n\n# copia da imagem original\nimage2 = image.copy()\n\n# coloca os crops da imagem nas posi\u00e7\u00f5es corretas, por exemplo: crop1 na parte inferior direita\nimage2[0:altura_metade,0:largura_metade] = crop4\nimage2[0:altura_metade,largura_metade:largura_metade*2] = crop3\nimage2[altura_metade:altura_metade*2,0:largura_metade] = crop2\nimage2[altura_metade:altura_metade*2,largura_metade:largura_metade*2] = crop1\n\n\nplt.imshow(image2, interpolation=\"none\")\nplt.show()\n</pre> #implemente sua solu\u00e7\u00e3o   import cv2 imagem = cv2.imread(\"gokuinvertido.jpg\") image = cv2.cvtColor(imagem, cv2.COLOR_BGR2RGB)  altura_metade = image.shape[0]//2 largura_metade = image.shape[1]//2  #crop_img = img[y:y+h, x:x+w] em 4 partes crop1 = image[0:altura_metade,0:largura_metade] crop2 = image[0:altura_metade,largura_metade:largura_metade*2] crop3 = image[altura_metade:altura_metade*2,0:largura_metade] crop4 = image[altura_metade:altura_metade*2,largura_metade:largura_metade*2]  # copia da imagem original image2 = image.copy()  # coloca os crops da imagem nas posi\u00e7\u00f5es corretas, por exemplo: crop1 na parte inferior direita image2[0:altura_metade,0:largura_metade] = crop4 image2[0:altura_metade,largura_metade:largura_metade*2] = crop3 image2[altura_metade:altura_metade*2,0:largura_metade] = crop2 image2[altura_metade:altura_metade*2,largura_metade:largura_metade*2] = crop1   plt.imshow(image2, interpolation=\"none\") plt.show()     In\u00a0[14]: Copied! <pre># Entenda o codigo e fa\u00e7a as altera\u00e7\u00f5es que achar necess\u00e1rias\nimport cv2\nimagem = cv2.imread(\"drone.jpg\")\nimage = cv2.cvtColor(imagem, cv2.COLOR_BGR2RGB)\nprint(image.shape)\n\nfor y in range(0, image.shape[0]):\n  for x in range(0, image.shape[1]):\n    if image[y,x,1] &gt; 170 :\n      image[y,x]= (255,255,255)\n    \n\nplt.imshow(image, interpolation=\"none\")\nplt.show()\n</pre> # Entenda o codigo e fa\u00e7a as altera\u00e7\u00f5es que achar necess\u00e1rias import cv2 imagem = cv2.imread(\"drone.jpg\") image = cv2.cvtColor(imagem, cv2.COLOR_BGR2RGB) print(image.shape)  for y in range(0, image.shape[0]):   for x in range(0, image.shape[1]):     if image[y,x,1] &gt; 170 :       image[y,x]= (255,255,255)       plt.imshow(image, interpolation=\"none\") plt.show() <pre>(420, 1120, 3)\n</pre> In\u00a0[18]: Copied! <pre># Implemente seu c\u00f3digo aqui\n\nimport cv2\nimagem = cv2.imread(\"drone.jpg\")\nimage = cv2.cvtColor(imagem, cv2.COLOR_BGR2RGB)\nprint(image.shape)\n\nfor y in range(0, image.shape[0]):\n  for x in range(0, image.shape[1]):\n    if image[y,x,0] &lt; 70 :\n      image[y,x]= (255,255,255)\n    \n\nplt.imshow(image, interpolation=\"none\")\nplt.show()\n</pre> # Implemente seu c\u00f3digo aqui  import cv2 imagem = cv2.imread(\"drone.jpg\") image = cv2.cvtColor(imagem, cv2.COLOR_BGR2RGB) print(image.shape)  for y in range(0, image.shape[0]):   for x in range(0, image.shape[1]):     if image[y,x,0] &lt; 70 :       image[y,x]= (255,255,255)       plt.imshow(image, interpolation=\"none\") plt.show()   <pre>(420, 1120, 3)\n</pre>"},{"location":"aulas/PDI/lab02/sol_atividade2.html#filtro-negativo-inverte-imagem","title":"Filtro negativo (Inverte imagem)\u00b6","text":"<p>Para aplicar um filtro negativo precisamos inverter os seus valores, ou seja, em uma imagem bin\u00e1ria realizamos a troca de 0 pra 1 e de 1 para 0 para cada pixel da imagem.</p>"},{"location":"aulas/PDI/lab02/sol_atividade2.html#desafio-1","title":"Desafio 1\u00b6","text":"<p>Fa\u00e7a uma implementa\u00e7\u00e3o que inverte as cores de uma imagem em escala de cinza, com valores que v\u00e3o de 0 ate 255. dica: a forma explicita de fazer uma invers\u00e3\u00e3o \u00e9: a = 255 - a</p>"},{"location":"aulas/PDI/lab02/sol_atividade2.html#desafio-2","title":"Desafio 2\u00b6","text":"<p>Fa\u00e7a o mesmo par uma imagem colorida, realize a invers\u00e3o de cores dos canais R, G e B.</p> <p>o resultado deve ser parecido com a imagem abaixo: </p>"},{"location":"aulas/PDI/lab02/sol_atividade2.html#recorte-da-imagem-crop","title":"Recorte da imagem (crop)\u00b6","text":"<p>O recorte de uma parte da imagem, ou crop, consiste em extrair da imagem uma regi\u00e3o de interresse (ROI).</p>"},{"location":"aulas/PDI/lab02/sol_atividade2.html#desafio3","title":"Desafio3\u00b6","text":"<p>Ajude o nosso sayajin!!</p> <p></p> <p>A imagem foi dividida em 4 quadrantes aleatorios e precisamos organizar essa bagun\u00e7a. Fa\u00e7a a reconstru\u00e7\u00e3o da imagem nas posi\u00e7\u00f5es corretas.</p> <p>Dica: Crie uma copia da imagem original (img2 = img.copy()), fa\u00e7a um crop da imagem 4 partes (crop1, crop2, crop3, crop4), junte as partes cortadas na ordem correta na img2. no final Salve a imagem (cv2.imwrite())</p>"},{"location":"aulas/PDI/lab02/sol_atividade2.html#seguimentacao-de-imagens","title":"Seguimenta\u00e7\u00e3o de imagens\u00b6","text":"<p>Agora que sabemos como manipular pixel e como alterar seu valor e sua posi\u00e7\u00e3o. Podemos fazer atividades mais complexas como conseguir reaalizar a seguimenta\u00e7\u00e3o de algum objeto ou item da imagem (video), Como na imagem abaixo.</p>"},{"location":"aulas/PDI/lab02/sol_atividade2.html#desafio-4","title":"Desafio 4\u00b6","text":"<p>De forma intuitiva realize algumas mudan\u00e7as no c\u00f3digo e veja o efeito que causa na imagem. Este exercio \u00e9 apenas um aperitivo de algumas tecnicas que vamos estudar na proxima aula.</p>"},{"location":"aulas/PDI/lab02/sol_atividade2.html#desafio-5","title":"Desafio 5\u00b6","text":"<p>Vamos tentar fazer o contrario, vamos tentar filtar o fundo da imagem sem o drone</p>"},{"location":"aulas/PDI/lab03/atividade3.html","title":"Lab03 - Histograma e equaliza\u00e7\u00e3o","text":"<p>Objetivos da aula:</p> <ul> <li>Histograma e equaliza\u00e7\u00e3o de histograma</li> <li>Seguimenta\u00e7\u00e3o com auxilio do histograma</li> <li>Webcam opencv</li> </ul> In\u00a0[37]: Copied! <pre>## Vou fazer o download das imagens do laborat\u00f3rio diretamente do reposit\u00f3rio para ficar mais facil....\n\nimport requests\nimport os\n\n# Define o laborat\u00f3rio\nlaboratorio = 'lab03'  ### altere para o laborat\u00f3rio desejado\ndiretorio = 'lab_images'  ### altere para o diret\u00f3rio que deseja salvar as imagens\n\n# Download de um arquivo\ndef download_file(url, destination):\n    response = requests.get(url, stream=True)\n    if response.status_code == 200:\n        with open(destination, 'wb') as file:\n            for chunk in response.iter_content(chunk_size=8192):\n                file.write(chunk)\n        print(f\"Baixado: {destination}\")\n    else:\n        print(f\"Erro ao baixar {url}\")\n\n# Monta a URL completa\napi_url = \"https://api.github.com/repos/arnaldojr/cognitivecomputing/contents/material/aulas/PDI/\"\nurl_completa = api_url + laboratorio\nprint(f\"Fazendo o download de: {url_completa}\")\n\n# checa se a URL est\u00e1 acess\u00edvel\nresponse = requests.get(url_completa)\nif response.status_code != 200:\n    raise Exception(f\"Erro ao acessar o reposit\u00f3rio: {response.status_code}\")\nfiles = response.json()\n\n\n# Faz o download de cada arquivo\nos.makedirs(diretorio, exist_ok=True) # Cria a pasta downloads\nfor file in files:\n    file_name = file['name']\n    if file_name.endswith(('.png', '.jpg', '.jpeg', '.mp4')):  # Adicione mais extens\u00f5es se necess\u00e1rio\n        file_url = file['download_url']\n        destination = os.path.join(diretorio, file_name)\n        download_file(file_url, destination)\n\nprint(f\"Download conclu\u00eddo. Arquivos salvos na pasta {diretorio}.\")\n</pre> ## Vou fazer o download das imagens do laborat\u00f3rio diretamente do reposit\u00f3rio para ficar mais facil....  import requests import os  # Define o laborat\u00f3rio laboratorio = 'lab03'  ### altere para o laborat\u00f3rio desejado diretorio = 'lab_images'  ### altere para o diret\u00f3rio que deseja salvar as imagens  # Download de um arquivo def download_file(url, destination):     response = requests.get(url, stream=True)     if response.status_code == 200:         with open(destination, 'wb') as file:             for chunk in response.iter_content(chunk_size=8192):                 file.write(chunk)         print(f\"Baixado: {destination}\")     else:         print(f\"Erro ao baixar {url}\")  # Monta a URL completa api_url = \"https://api.github.com/repos/arnaldojr/cognitivecomputing/contents/material/aulas/PDI/\" url_completa = api_url + laboratorio print(f\"Fazendo o download de: {url_completa}\")  # checa se a URL est\u00e1 acess\u00edvel response = requests.get(url_completa) if response.status_code != 200:     raise Exception(f\"Erro ao acessar o reposit\u00f3rio: {response.status_code}\") files = response.json()   # Faz o download de cada arquivo os.makedirs(diretorio, exist_ok=True) # Cria a pasta downloads for file in files:     file_name = file['name']     if file_name.endswith(('.png', '.jpg', '.jpeg', '.mp4')):  # Adicione mais extens\u00f5es se necess\u00e1rio         file_url = file['download_url']         destination = os.path.join(diretorio, file_name)         download_file(file_url, destination)  print(f\"Download conclu\u00eddo. Arquivos salvos na pasta {diretorio}.\") <pre>Fazendo o download de: https://api.github.com/repos/arnaldojr/cognitivecomputing/contents/material/aulas/PDI/lab03\nBaixado: lab_images/bola.png\nBaixado: lab_images/bolinha.png\nBaixado: lab_images/fuca.png\nDownload conclu\u00eddo. Arquivos salvos na pasta lab_images.\n</pre> In\u00a0[1]: Copied! <pre>%matplotlib inline\nimport cv2\nfrom matplotlib import pyplot as plt\nimport numpy as np\n\nprint (\"OpenCV Version : %s \" % cv2.__version__)\n</pre> %matplotlib inline import cv2 from matplotlib import pyplot as plt import numpy as np  print (\"OpenCV Version : %s \" % cv2.__version__) <pre>OpenCV Version : 4.6.0 \n</pre> In\u00a0[2]: Copied! <pre>img = cv2.imread(\"fuca.png\", cv2.IMREAD_GRAYSCALE)\nplt.imshow(img, cmap=\"Greys_r\", vmin=0, vmax=255)\n</pre> img = cv2.imread(\"fuca.png\", cv2.IMREAD_GRAYSCALE) plt.imshow(img, cmap=\"Greys_r\", vmin=0, vmax=255)  Out[2]: <pre>&lt;matplotlib.image.AxesImage at 0x131d46d60&gt;</pre> In\u00a0[3]: Copied! <pre>img_gray = img\n\n# Calculando histograma com NumPy para imagem em escala de cinza\nhist_np, bins = np.histogram(img_gray.ravel(), bins=256, range=[0,256])\nplt.figure(figsize=(10,4))\nplt.title('Histograma com NumPy - Escala de Cinza')\nplt.xlabel('Intensidade')\nplt.ylabel('Frequ\u00eancia')\nplt.plot(hist_np)\nplt.xlim([0,256])\nplt.show()\n\n# Calculando histograma com OpenCV para imagem em escala de cinza\nhist_cv = cv2.calcHist([img_gray], [0], None, [256], [0,256])\nplt.figure(figsize=(10,4))\nplt.title('Histograma com OpenCV - Escala de Cinza')\nplt.xlabel('Intensidade')\nplt.ylabel('Frequ\u00eancia')\nplt.plot(hist_cv)\nplt.xlim([0,256])\nplt.show()\n\n# Exibindo o histograma com a fun\u00e7\u00e3o plt.hist\nplt.figure(figsize=(10,4))\nplt.hist(img_gray.ravel(),256,[0,256])\nplt.title('Histograma com Matplotlib - Escala de Cinza')\nplt.xlabel('Intensidade')\nplt.ylabel('Frequ\u00eancia')\nplt.xlim([0,256])\nplt.show()\n</pre>  img_gray = img  # Calculando histograma com NumPy para imagem em escala de cinza hist_np, bins = np.histogram(img_gray.ravel(), bins=256, range=[0,256]) plt.figure(figsize=(10,4)) plt.title('Histograma com NumPy - Escala de Cinza') plt.xlabel('Intensidade') plt.ylabel('Frequ\u00eancia') plt.plot(hist_np) plt.xlim([0,256]) plt.show()  # Calculando histograma com OpenCV para imagem em escala de cinza hist_cv = cv2.calcHist([img_gray], [0], None, [256], [0,256]) plt.figure(figsize=(10,4)) plt.title('Histograma com OpenCV - Escala de Cinza') plt.xlabel('Intensidade') plt.ylabel('Frequ\u00eancia') plt.plot(hist_cv) plt.xlim([0,256]) plt.show()  # Exibindo o histograma com a fun\u00e7\u00e3o plt.hist plt.figure(figsize=(10,4)) plt.hist(img_gray.ravel(),256,[0,256]) plt.title('Histograma com Matplotlib - Escala de Cinza') plt.xlabel('Intensidade') plt.ylabel('Frequ\u00eancia') plt.xlim([0,256]) plt.show()  In\u00a0[4]: Copied! <pre># Equaliza\u00e7\u00e3o do histograma utilizando OpenCV\nimg_eq = cv2.equalizeHist(img_gray)\n\n# Plotando as imagens original e equalizada\nplt.figure(figsize=(12,6))\nplt.subplot(1,2,1)\nplt.title('Imagem Original')\nplt.imshow(img_gray, cmap='gray')\nplt.axis('off')\n\nplt.subplot(1,2,2)\nplt.title('Imagem Equalizada')\nplt.imshow(img_eq, cmap='gray')\nplt.axis('off')\nplt.show()\n\n# Comparando os histogramas antes e depois da equaliza\u00e7\u00e3o\nhist_original = cv2.calcHist([img_gray], [0], None, [256], [0,256])\nhist_equalizado = cv2.calcHist([img_eq], [0], None, [256], [0,256])\n\nplt.figure(figsize=(10,4))\nplt.plot(hist_original, label='Original')\nplt.plot(hist_equalizado, label='Equalizado')\nplt.title('Compara\u00e7\u00e3o dos Histogramas')\nplt.xlabel('Intensidade')\nplt.ylabel('Frequ\u00eancia')\nplt.legend()\nplt.xlim([0,256])\nplt.show()\n</pre> # Equaliza\u00e7\u00e3o do histograma utilizando OpenCV img_eq = cv2.equalizeHist(img_gray)  # Plotando as imagens original e equalizada plt.figure(figsize=(12,6)) plt.subplot(1,2,1) plt.title('Imagem Original') plt.imshow(img_gray, cmap='gray') plt.axis('off')  plt.subplot(1,2,2) plt.title('Imagem Equalizada') plt.imshow(img_eq, cmap='gray') plt.axis('off') plt.show()  # Comparando os histogramas antes e depois da equaliza\u00e7\u00e3o hist_original = cv2.calcHist([img_gray], [0], None, [256], [0,256]) hist_equalizado = cv2.calcHist([img_eq], [0], None, [256], [0,256])  plt.figure(figsize=(10,4)) plt.plot(hist_original, label='Original') plt.plot(hist_equalizado, label='Equalizado') plt.title('Compara\u00e7\u00e3o dos Histogramas') plt.xlabel('Intensidade') plt.ylabel('Frequ\u00eancia') plt.legend() plt.xlim([0,256]) plt.show() <p>Podemos fazer o mesmo para uma imgem colorida</p> In\u00a0[5]: Copied! <pre>imagem = cv2.imread(\"bola.png\")\nimage = cv2.cvtColor(imagem, cv2.COLOR_BGR2RGB)\nplt.imshow(image, vmin=0, vmax=255); plt.show()\nplt.hist(image.ravel(),256,[0,256]); plt.show()\n</pre> imagem = cv2.imread(\"bola.png\") image = cv2.cvtColor(imagem, cv2.COLOR_BGR2RGB) plt.imshow(image, vmin=0, vmax=255); plt.show() plt.hist(image.ravel(),256,[0,256]); plt.show() In\u00a0[6]: Copied! <pre>#histograma Vermelho\nplt.imshow(image[:,:,0], cmap=\"gray\", vmin=0, vmax=255); plt.show()\nplt.hist(image[:,:,0].ravel(),256,[0,256]); plt.show()\n</pre> #histograma Vermelho plt.imshow(image[:,:,0], cmap=\"gray\", vmin=0, vmax=255); plt.show() plt.hist(image[:,:,0].ravel(),256,[0,256]); plt.show() In\u00a0[7]: Copied! <pre># Histogrma Verde\nplt.imshow(image[:,:,1], cmap=\"Greys_r\", vmin=0, vmax=255); plt.show()\nplt.hist(image[:,:,1].ravel(),256,[0,256]); plt.show()\n</pre> # Histogrma Verde plt.imshow(image[:,:,1], cmap=\"Greys_r\", vmin=0, vmax=255); plt.show() plt.hist(image[:,:,1].ravel(),256,[0,256]); plt.show() In\u00a0[8]: Copied! <pre># Histograma Azul\nplt.imshow(image[:,:,2], cmap=\"Greys_r\", vmin=0, vmax=255); plt.show()\nplt.hist(image[:,:,2].ravel(),256,[0,256]); plt.show()\n</pre> # Histograma Azul plt.imshow(image[:,:,2], cmap=\"Greys_r\", vmin=0, vmax=255); plt.show() plt.hist(image[:,:,2].ravel(),256,[0,256]); plt.show() In\u00a0[11]: Copied! <pre># Cria uma c\u00f3pia para a segmenta\u00e7\u00e3o\nimg_bola = image.copy()\n\n# Varredura pixel a pixel utilizando la\u00e7os for\nfor y in range(img_bola.shape[0]):\n    for x in range(img_bola.shape[1]):\n        # Condi\u00e7\u00f5es aplicadas para o pixel (no formato RGB)\n        # Aqui, se o canal verde &lt;= 230 ou o canal vermelho &gt;= 240, zera o pixel\n        if img_bola[y, x, 1] &lt;= 230 or img_bola[y, x, 0] &gt;= 240:\n            img_bola[y, x] = [0, 0, 0]\n\nplt.figure(figsize=(6,4))\nplt.title('Segmenta\u00e7\u00e3o (Loop For)')\n# Convertendo de BGR para RGB para exibi\u00e7\u00e3o correta\nplt.imshow(img_bola)\nplt.axis('off')\nplt.show()\n</pre> # Cria uma c\u00f3pia para a segmenta\u00e7\u00e3o img_bola = image.copy()  # Varredura pixel a pixel utilizando la\u00e7os for for y in range(img_bola.shape[0]):     for x in range(img_bola.shape[1]):         # Condi\u00e7\u00f5es aplicadas para o pixel (no formato RGB)         # Aqui, se o canal verde &lt;= 230 ou o canal vermelho &gt;= 240, zera o pixel         if img_bola[y, x, 1] &lt;= 230 or img_bola[y, x, 0] &gt;= 240:             img_bola[y, x] = [0, 0, 0]  plt.figure(figsize=(6,4)) plt.title('Segmenta\u00e7\u00e3o (Loop For)') # Convertendo de BGR para RGB para exibi\u00e7\u00e3o correta plt.imshow(img_bola) plt.axis('off') plt.show() In\u00a0[13]: Copied! <pre>img_bola_vet = image.copy()\n\n# Separando os canais (lembrando: B, G, R)\ncanal_vermelho = img_bola_vet[:, :, 0]\ncanal_verde = img_bola_vet[:, :, 1]\n\n# Criar m\u00e1scaras para as condi\u00e7\u00f5es:\n# - pixels com canal verde &lt;= 230\n# - pixels com canal vermelho &gt;= 240\nmask_verde = canal_verde &lt;= 230\nmask_vermelho  = canal_vermelho &gt;= 240\n\n# Combina as m\u00e1scaras com operador l\u00f3gico OR\nmask = mask_verde | mask_vermelho\n\n# Aplica a m\u00e1scara: onde a condi\u00e7\u00e3o \u00e9 True, zera o pixel\nimg_bola_vet[mask] = [0, 0, 0]\n\nplt.figure(figsize=(6,4))\nplt.title('Segmenta\u00e7\u00e3o (Vetorizada)')\nplt.imshow(img_bola_vet)\nplt.axis('off')\nplt.show()\n</pre> img_bola_vet = image.copy()  # Separando os canais (lembrando: B, G, R) canal_vermelho = img_bola_vet[:, :, 0] canal_verde = img_bola_vet[:, :, 1]  # Criar m\u00e1scaras para as condi\u00e7\u00f5es: # - pixels com canal verde &lt;= 230 # - pixels com canal vermelho &gt;= 240 mask_verde = canal_verde &lt;= 230 mask_vermelho  = canal_vermelho &gt;= 240  # Combina as m\u00e1scaras com operador l\u00f3gico OR mask = mask_verde | mask_vermelho  # Aplica a m\u00e1scara: onde a condi\u00e7\u00e3o \u00e9 True, zera o pixel img_bola_vet[mask] = [0, 0, 0]  plt.figure(figsize=(6,4)) plt.title('Segmenta\u00e7\u00e3o (Vetorizada)') plt.imshow(img_bola_vet) plt.axis('off') plt.show()  In\u00a0[\u00a0]: Copied! <pre># Implemente seu c\u00f3digo\n</pre> # Implemente seu c\u00f3digo       In\u00a0[14]: Copied! <pre>imagem = cv2.imread(\"bolinha.png\")\nimage = cv2.cvtColor(imagem, cv2.COLOR_BGR2RGB)\nplt.imshow(image, vmin=0, vmax=255); plt.show()\n</pre> imagem = cv2.imread(\"bolinha.png\") image = cv2.cvtColor(imagem, cv2.COLOR_BGR2RGB) plt.imshow(image, vmin=0, vmax=255); plt.show() In\u00a0[13]: Copied! <pre># Implemente seu c\u00f3digo\n</pre> # Implemente seu c\u00f3digo         In\u00a0[\u00a0]: Copied! <pre>import cv2\n\n# Iniciando a captura de v\u00eddeo\ncap = cv2.VideoCapture(0)\n\nwhile True:\n    # Tenta fazer a Captura do frame\n    ret, frame = cap.read()\n\n    # verifica se o frame foi capturado corretamente\n    if not ret:\n        print(\"Erro: N\u00e3o foi poss\u00edvel capturar o frame.\")\n        break\n    \n    # processa o frame capturado\n    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n    \n    # Exibe o frame processado\n    cv2.imshow('frame', gray)\n    \n    # Aguarda 1 ms e verifica se a tecla 'q' foi pressionada para sair\n    if cv2.waitKey(1) &amp; 0xFF == ord('q'):\n        break\n\n# Libera a captura e fecha todas as janelas\ncap.release()\ncv2.destroyAllWindows()\n</pre> import cv2  # Iniciando a captura de v\u00eddeo cap = cv2.VideoCapture(0)  while True:     # Tenta fazer a Captura do frame     ret, frame = cap.read()      # verifica se o frame foi capturado corretamente     if not ret:         print(\"Erro: N\u00e3o foi poss\u00edvel capturar o frame.\")         break          # processa o frame capturado     gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)          # Exibe o frame processado     cv2.imshow('frame', gray)          # Aguarda 1 ms e verifica se a tecla 'q' foi pressionada para sair     if cv2.waitKey(1) &amp; 0xFF == ord('q'):         break  # Libera a captura e fecha todas as janelas cap.release() cv2.destroyAllWindows() <pre>Erro: N\u00e3o foi poss\u00edvel capturar o frame.\n</pre> <pre>OpenCV: out device of bound (0-1): 2\nOpenCV: camera failed to properly initialize!\n</pre> In\u00a0[\u00a0]: Copied! <pre># implemente seu c\u00f3digo em um novo script python, n\u00e3o se esque\u00e7a de salvar o script no formato .py \n</pre> # implemente seu c\u00f3digo em um novo script python, n\u00e3o se esque\u00e7a de salvar o script no formato .py"},{"location":"aulas/PDI/lab03/atividade3.html#introducao-aos-histogramas","title":"Introdu\u00e7\u00e3o aos Histogramas\u00b6","text":"<p>Um histograma \u00e9 uma representa\u00e7\u00e3o gr\u00e1fica da distribui\u00e7\u00e3o dos n\u00edveis de intensidade em uma imagem. Em imagens em escala de cinza, ele mostra a frequ\u00eancia de ocorr\u00eancia de cada n\u00edvel de cinza (0 a 255). Em imagens coloridas, o histograma pode ser calculado separadamente para cada canal (R, G e B).</p> <p>Por que utilizar histogramas?</p> <ul> <li>An\u00e1lise de contraste e brilho.</li> <li>Detec\u00e7\u00e3o de problemas de exposi\u00e7\u00e3o.</li> <li>Base para t\u00e9cnicas de equaliza\u00e7\u00e3o e normaliza\u00e7\u00e3o.</li> </ul>"},{"location":"aulas/PDI/lab03/atividade3.html#desafio1","title":"Desafio1\u00b6","text":"<ul> <li><p>Quais s\u00e3o as diferen\u00e7as e similaridades entre as abordagens?</p> </li> <li><p>Import\u00e2ncia do par\u00e2metro range e do n\u00famero de bins.</p> </li> </ul>"},{"location":"aulas/PDI/lab03/atividade3.html#equalizacao-do-histograma","title":"Equaliza\u00e7\u00e3o do Histograma\u00b6","text":"<p>A equaliza\u00e7\u00e3o de histograma \u00e9 uma t\u00e9cnica utilizada para melhorar o contraste de uma imagem. Ela redistribui os n\u00edveis de intensidade de modo que o histograma da imagem equalizada se aproxime de uma distribui\u00e7\u00e3o uniforme. Isso \u00e9 especialmente \u00fatil em imagens com contraste baixo ou m\u00e1 distribui\u00e7\u00e3o dos tons de cinza.</p>"},{"location":"aulas/PDI/lab03/atividade3.html#objetivos-da-equalizacao","title":"Objetivos da Equaliza\u00e7\u00e3o:\u00b6","text":"<ul> <li>Melhorar o contraste: Ao expandir as \u00e1reas de baixa intensidade e comprimir as de alta intensidade, a imagem passa a apresentar mais detalhes.</li> <li>Real\u00e7ar detalhes ocultos: Em imagens com fundo e objeto de intensidades muito pr\u00f3ximas, a equaliza\u00e7\u00e3o pode ajudar a evidenciar detalhes que passariam despercebidos.</li> </ul>"},{"location":"aulas/PDI/lab03/atividade3.html#versao-2-abordagem-vetorizada-com-numpy","title":"Vers\u00e3o 2: Abordagem Vetorizada com NumPy\u00b6","text":"<p>Nesta vers\u00e3o, criamos m\u00e1scaras booleanas para cada condi\u00e7\u00e3o e combinamos as m\u00e1scaras para aplicar a segmenta\u00e7\u00e3o de forma vetorizada.</p> <p>Essa abordagem \u00e9 muito mais eficiente e concisa.</p>"},{"location":"aulas/PDI/lab03/atividade3.html#desafio-2","title":"Desafio 2\u00b6","text":"<p>Fa\u00e7a a seguimenta\u00e7\u00e3o da bolinha de cor laranja.</p> <p>Dica use 2 canais de cores para conseguir seguimentar.</p>"},{"location":"aulas/PDI/lab03/atividade3.html#desafio-3","title":"Desafio 3\u00b6","text":"<p>Fa\u00e7a a seguimenta\u00e7\u00e3o da bolinha para a imagem \"bolinha.png\".</p>"},{"location":"aulas/PDI/lab03/atividade3.html#webcam-e-opencv","title":"Webcam e OpenCV\u00b6","text":""},{"location":"aulas/PDI/lab03/atividade3.html#este-recurso-nao-vai-funcionar-no-google-colab","title":"Este recurso n\u00e3o vai funcionar no Google Colab\u00b6","text":"<p>Podemos usar a nossa webcam para registrar imagens e v\u00eddeos. Para isso, usamos a fun\u00e7\u00e3o <code>cv2.VideoCapture</code>.</p>"},{"location":"aulas/PDI/lab03/atividade3.html#em-sua-maquina-local","title":"Em sua m\u00e1quina local\u00b6","text":"<ol> <li><p>Crie um novo arquivo Python ou use este notebook para executar o c\u00f3digo abaixo.</p> </li> <li><p>Escolha a fonte do video se voc\u00ea quiser usar um v\u00eddeo MP4 em vez da webcam, basta passar o caminho do arquivo para cv2.VideoCapture:</p> <ul> <li>cv2.VideoCapture(0) # Inicializa a captura de v\u00eddeo da webcam (0 \u00e9 o \u00edndice da c\u00e2mera padr\u00e3o)</li> <li>cv2.VideoCapture(\"video.mp4\") # Carrega o arquivo de video</li> </ul> </li> </ol>"},{"location":"aulas/PDI/lab03/atividade3.html#desafio-4","title":"Desafio 4\u00b6","text":"<p>Crie um script Python que execute o processameento de um video (webcam ou arquivo mp4) em sua maquina local. Crie uma fun\u00e7\u00e3o que processa a imagem e realizada uma opera\u00e7\u00e3o de processamento de imagem que vimos at\u00e9 o momento em nosso curso.</p>"},{"location":"aulas/PDI/lab03/sol_atividade3.html","title":"Sol atividade3","text":"<p>Objetivos da aula:</p> <ul> <li>Histograma e equaliza\u00e7\u00e3o de histograma</li> <li>Seguimenta\u00e7\u00e3o com auxilio do histograma</li> <li>Webcam opencv</li> </ul> In\u00a0[1]: Copied! <pre>%matplotlib inline\nimport cv2\nfrom matplotlib import pyplot as plt\nimport numpy as np\n\nprint (\"OpenCV Version : %s \" % cv2.__version__)\n</pre> %matplotlib inline import cv2 from matplotlib import pyplot as plt import numpy as np  print (\"OpenCV Version : %s \" % cv2.__version__) <pre>OpenCV Version : 4.9.0 \n</pre> In\u00a0[\u00a0]: Copied! <pre>!wget \"https://raw.githubusercontent.com/arnaldojr/cognitivecomputing/master/material/aulas/PDI/lab03/bola.png\" /content\n!wget \"https://raw.githubusercontent.com/arnaldojr/cognitivecomputing/master/material/aulas/PDI/lab03/bolinha.png\" /content\n!wget \"https://raw.githubusercontent.com/arnaldojr/cognitivecomputing/master/material/aulas/PDI/lab03/fuca.png\" /content\n</pre> !wget \"https://raw.githubusercontent.com/arnaldojr/cognitivecomputing/master/material/aulas/PDI/lab03/bola.png\" /content !wget \"https://raw.githubusercontent.com/arnaldojr/cognitivecomputing/master/material/aulas/PDI/lab03/bolinha.png\" /content !wget \"https://raw.githubusercontent.com/arnaldojr/cognitivecomputing/master/material/aulas/PDI/lab03/fuca.png\" /content   In\u00a0[2]: Copied! <pre>img = cv2.imread(\"fuca.png\", cv2.IMREAD_GRAYSCALE)\nplt.imshow(img, cmap=\"Greys_r\", vmin=0, vmax=255)\n</pre> img = cv2.imread(\"fuca.png\", cv2.IMREAD_GRAYSCALE) plt.imshow(img, cmap=\"Greys_r\", vmin=0, vmax=255)  Out[2]: <pre>&lt;matplotlib.image.AxesImage at 0x15eff6460&gt;</pre> In\u00a0[3]: Copied! <pre>plt.hist(img.ravel(),256,[0,256]); plt.show()\n</pre> plt.hist(img.ravel(),256,[0,256]); plt.show() In\u00a0[4]: Copied! <pre># normaliza\u00e7\u00e3o de histograma\n\nimg_eq = cv2.equalizeHist(img)\nplt.imshow(3*img_eq, cmap=\"Greys_r\", vmin=0, vmax=255)\n</pre> # normaliza\u00e7\u00e3o de histograma  img_eq = cv2.equalizeHist(img) plt.imshow(3*img_eq, cmap=\"Greys_r\", vmin=0, vmax=255) Out[4]: <pre>&lt;matplotlib.image.AxesImage at 0x15f9cf370&gt;</pre> In\u00a0[5]: Copied! <pre>plt.hist(3*img_eq.ravel(),256,[0,256]); plt.show()\n</pre> plt.hist(3*img_eq.ravel(),256,[0,256]); plt.show() <p>Podemos fazer o mesmo para uma imgem colorida</p> In\u00a0[6]: Copied! <pre>imagem = cv2.imread(\"bola.png\")\nimage = cv2.cvtColor(imagem, cv2.COLOR_BGR2RGB)\nplt.imshow(image, vmin=0, vmax=255); plt.show()\nplt.hist(image.ravel(),256,[0,256]); plt.show()\n</pre> imagem = cv2.imread(\"bola.png\") image = cv2.cvtColor(imagem, cv2.COLOR_BGR2RGB) plt.imshow(image, vmin=0, vmax=255); plt.show() plt.hist(image.ravel(),256,[0,256]); plt.show() In\u00a0[7]: Copied! <pre>#histograma Vermelho\nplt.imshow(image[:,:,0], cmap=\"gray\", vmin=0, vmax=255); plt.show()\nplt.hist(image[:,:,0].ravel(),256,[0,256]); plt.show()\n</pre> #histograma Vermelho plt.imshow(image[:,:,0], cmap=\"gray\", vmin=0, vmax=255); plt.show() plt.hist(image[:,:,0].ravel(),256,[0,256]); plt.show() In\u00a0[8]: Copied! <pre># Histogrma Verde\nplt.imshow(image[:,:,1], cmap=\"Greys_r\", vmin=0, vmax=255); plt.show()\nplt.hist(image[:,:,1].ravel(),256,[0,256]); plt.show()\n</pre> # Histogrma Verde plt.imshow(image[:,:,1], cmap=\"Greys_r\", vmin=0, vmax=255); plt.show() plt.hist(image[:,:,1].ravel(),256,[0,256]); plt.show() In\u00a0[9]: Copied! <pre># Histograma Azul\nplt.imshow(image[:,:,2], cmap=\"Greys_r\", vmin=0, vmax=255); plt.show()\nplt.hist(image[:,:,2].ravel(),256,[0,256]); plt.show()\n</pre> # Histograma Azul plt.imshow(image[:,:,2], cmap=\"Greys_r\", vmin=0, vmax=255); plt.show() plt.hist(image[:,:,2].ravel(),256,[0,256]); plt.show() In\u00a0[10]: Copied! <pre>image2 = image.copy()\ngray_r = image2[:,:,0]\ngray_g = image2[:,:,1]\ngray_b = image2[:,:,2]\n\nimg_bola = image2.copy()\n\nfor y in range(0, image2.shape[0]):\n    for x in range(0, image2.shape[1]):\n        \n        if gray_g[y][x] &lt;= 230:\n            img_bola[y][x]= 0\n        if gray_b[y][x] &gt;= 240:\n            img_bola[y][x]= 0    \n\n    \n\nplt.imshow(img_bola, interpolation=\"none\")\nplt.show()\n</pre> image2 = image.copy() gray_r = image2[:,:,0] gray_g = image2[:,:,1] gray_b = image2[:,:,2]  img_bola = image2.copy()  for y in range(0, image2.shape[0]):     for x in range(0, image2.shape[1]):                  if gray_g[y][x] &lt;= 230:             img_bola[y][x]= 0         if gray_b[y][x] &gt;= 240:             img_bola[y][x]= 0            plt.imshow(img_bola, interpolation=\"none\") plt.show() In\u00a0[13]: Copied! <pre># Implemente seu c\u00f3digo\n\n# para encontrar a bolinha laranja na imagem, \u00e9 necess\u00e1rio encontrar a cor laranja, que \u00e9 uma mistura de vermelho e verde\n# para isso, \u00e9 necess\u00e1rio encontrar os valores de vermelho e verde que comp\u00f5em a cor laranja\n\n# n\u00e3o existe um valor exato para a cor laranja, ent\u00e3o \u00e9 necess\u00e1rio testar valores para encontrar a cor laranja\n# no caso, o vermelho \u00e9 menor que 240 e o verde \u00e9 maior que 240 para a cor laranja da bolinha na imagem\n\n\nimg_bola_laranja = image.copy()\n\ngray_r = image[:,:,0]\ngray_g = image[:,:,1]\n\n\nfor y in range(0, image.shape[0]):\n    for x in range(0, image.shape[1]):\n        \n        if gray_r[y][x] &lt;= 240:\n            img_bola_laranja[y][x]= 0\n        if gray_g[y][x] &gt;= 240:\n            img_bola_laranja[y][x]= 0    \n\n\nplt.imshow(img_bola_laranja)\nplt.show()\n</pre> # Implemente seu c\u00f3digo  # para encontrar a bolinha laranja na imagem, \u00e9 necess\u00e1rio encontrar a cor laranja, que \u00e9 uma mistura de vermelho e verde # para isso, \u00e9 necess\u00e1rio encontrar os valores de vermelho e verde que comp\u00f5em a cor laranja  # n\u00e3o existe um valor exato para a cor laranja, ent\u00e3o \u00e9 necess\u00e1rio testar valores para encontrar a cor laranja # no caso, o vermelho \u00e9 menor que 240 e o verde \u00e9 maior que 240 para a cor laranja da bolinha na imagem   img_bola_laranja = image.copy()  gray_r = image[:,:,0] gray_g = image[:,:,1]   for y in range(0, image.shape[0]):     for x in range(0, image.shape[1]):                  if gray_r[y][x] &lt;= 240:             img_bola_laranja[y][x]= 0         if gray_g[y][x] &gt;= 240:             img_bola_laranja[y][x]= 0       plt.imshow(img_bola_laranja) plt.show() In\u00a0[14]: Copied! <pre>imagem = cv2.imread(\"bolinha.png\")\nimage = cv2.cvtColor(imagem, cv2.COLOR_BGR2RGB)\nplt.imshow(image, vmin=0, vmax=255); plt.show()\n</pre> imagem = cv2.imread(\"bolinha.png\") image = cv2.cvtColor(imagem, cv2.COLOR_BGR2RGB) plt.imshow(image, vmin=0, vmax=255); plt.show() In\u00a0[30]: Copied! <pre># Implemente seu c\u00f3digo\n\n# para encontrar a bolinha magenta na imagem, \u00e9 necess\u00e1rio encontrar a cor magenta, \n# que \u00e9 uma mistura de vermelho e azul\n\nimg_entrada = cv2.imread(\"bolinha.png\")\nimg_entrada = cv2.cvtColor(img_entrada, cv2.COLOR_BGR2RGB)\n\n# Criando uma figura com subplots para exibir a imagem e o histograma\nfig, axs = plt.subplots(2, 3, figsize=(10, 8))\nnomes_canais = [\"Vermelho\", \"Verde\", \"Azul\"]\n\n# Iterando sobre os canais de cores\nfor i, (canal, nome) in enumerate(zip([0, 1, 2], nomes_canais)):\n    # Exibindo o canal de cor\n    axs[0, i].imshow(img_entrada[:, :, canal], cmap=\"Greys_r\", vmin=0, vmax=255)\n    axs[0, i].set_title(f\"Canal {nome}\")\n    # Exibindo o histograma do canal de cor\n    axs[1, i].hist(img_entrada[:, :, canal].ravel(), 256, [0, 256])\n    axs[1, i].set_title(f\"Histograma {nome}\")\n\n#  Exibindo a figura\nplt.tight_layout()\nplt.show()\n\n# agora \u00e9 analisar os valores de vermelho e azul para encontrar a cor magenta da bolinha na imagem \n\nbolinha_magenta = image.copy()\ngray_r = img_entrada[:,:,0]\ngray_b = img_entrada[:,:,2]\n\nfor y in range(0, img_entrada.shape[0]):\n    for x in range(0, img_entrada.shape[1]):\n        \n        if gray_r[y][x] &lt;= 251:\n            bolinha_magenta[y][x]= 0\n        if gray_b[y][x] &gt;= 252:\n            bolinha_magenta[y][x]= 0    \n\nplt.subplot(1,2,1), plt.imshow(img_entrada)\nplt.subplot(1,2,2), plt.imshow(bolinha_magenta)\nplt.show()\n\n# Dificilmente encontraremos um valor exato para a cor magenta, mas com um pouco de paci\u00eancia,\n# \u00e9 poss\u00edvel encontrar a cor magenta da bolinha na imagem\n</pre> # Implemente seu c\u00f3digo  # para encontrar a bolinha magenta na imagem, \u00e9 necess\u00e1rio encontrar a cor magenta,  # que \u00e9 uma mistura de vermelho e azul  img_entrada = cv2.imread(\"bolinha.png\") img_entrada = cv2.cvtColor(img_entrada, cv2.COLOR_BGR2RGB)  # Criando uma figura com subplots para exibir a imagem e o histograma fig, axs = plt.subplots(2, 3, figsize=(10, 8)) nomes_canais = [\"Vermelho\", \"Verde\", \"Azul\"]  # Iterando sobre os canais de cores for i, (canal, nome) in enumerate(zip([0, 1, 2], nomes_canais)):     # Exibindo o canal de cor     axs[0, i].imshow(img_entrada[:, :, canal], cmap=\"Greys_r\", vmin=0, vmax=255)     axs[0, i].set_title(f\"Canal {nome}\")     # Exibindo o histograma do canal de cor     axs[1, i].hist(img_entrada[:, :, canal].ravel(), 256, [0, 256])     axs[1, i].set_title(f\"Histograma {nome}\")  #  Exibindo a figura plt.tight_layout() plt.show()  # agora \u00e9 analisar os valores de vermelho e azul para encontrar a cor magenta da bolinha na imagem   bolinha_magenta = image.copy() gray_r = img_entrada[:,:,0] gray_b = img_entrada[:,:,2]  for y in range(0, img_entrada.shape[0]):     for x in range(0, img_entrada.shape[1]):                  if gray_r[y][x] &lt;= 251:             bolinha_magenta[y][x]= 0         if gray_b[y][x] &gt;= 252:             bolinha_magenta[y][x]= 0      plt.subplot(1,2,1), plt.imshow(img_entrada) plt.subplot(1,2,2), plt.imshow(bolinha_magenta) plt.show()  # Dificilmente encontraremos um valor exato para a cor magenta, mas com um pouco de paci\u00eancia, # \u00e9 poss\u00edvel encontrar a cor magenta da bolinha na imagem  In\u00a0[\u00a0]: Copied! <pre>%matplotlib inline\nimport cv2\nfrom matplotlib import pyplot as plt\nimport numpy as np\nimport time as t\nprint (\"OpenCV Version : %s \" % cv2.__version__)\n</pre> %matplotlib inline import cv2 from matplotlib import pyplot as plt import numpy as np import time as t print (\"OpenCV Version : %s \" % cv2.__version__) <pre>OpenCV Version : 4.5.5 \n</pre> In\u00a0[\u00a0]: Copied! <pre>webcam = cv2.VideoCapture(0) # pode acontecer do ID da camera n\u00e3o ser 0, ai precisa testar com outros numeros \n</pre>  webcam = cv2.VideoCapture(0) # pode acontecer do ID da camera n\u00e3o ser 0, ai precisa testar com outros numeros  In\u00a0[\u00a0]: Copied! <pre>t.sleep(3) # Espera a webcam ficar pronta\n</pre> t.sleep(3) # Espera a webcam ficar pronta In\u00a0[\u00a0]: Copied! <pre>val, image = webcam.read()\n</pre> val, image = webcam.read() In\u00a0[\u00a0]: Copied! <pre>val  # Checa se um frame chegou\n</pre> val  # Checa se um frame chegou Out[\u00a0]: <pre>True</pre> In\u00a0[\u00a0]: Copied! <pre>webcam.release() # fecha a webcam\n</pre> webcam.release() # fecha a webcam In\u00a0[\u00a0]: Copied! <pre>plt.imshow(image)\n</pre> plt.imshow(image) Out[\u00a0]: <pre>&lt;matplotlib.image.AxesImage at 0x252ed548df0&gt;</pre> In\u00a0[\u00a0]: Copied! <pre>%matplotlib inline\nimport cv2\nfrom matplotlib import pyplot as plt\nimport time as t\n\n## aqui n\u00e3o tem segredo, \u00e9 copiar, colar e rodar o c\u00f3digo dado no enunciado.\n\n# Iniciando a captura de v\u00eddeo\nwebcam = cv2.VideoCapture(0)\n\n# Aguardando 3 segundos para a c\u00e2mera se ajustar\nt.sleep(3)\n\n# Capturando uma imagem\nval, image = webcam.read()\n\n# Liberando a c\u00e2mera\nwebcam.release()\n\n# Convertendo a imagem de BGR para RGB\nimage_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n\n# Exibindo a imagem\nplt.imshow(image_rgb)\nplt.axis('off')  # Ocultando os eixos\nplt.show()\n</pre> %matplotlib inline import cv2 from matplotlib import pyplot as plt import time as t  ## aqui n\u00e3o tem segredo, \u00e9 copiar, colar e rodar o c\u00f3digo dado no enunciado.  # Iniciando a captura de v\u00eddeo webcam = cv2.VideoCapture(0)  # Aguardando 3 segundos para a c\u00e2mera se ajustar t.sleep(3)  # Capturando uma imagem val, image = webcam.read()  # Liberando a c\u00e2mera webcam.release()  # Convertendo a imagem de BGR para RGB image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)  # Exibindo a imagem plt.imshow(image_rgb) plt.axis('off')  # Ocultando os eixos plt.show()  In\u00a0[\u00a0]: Copied! <pre>## para captura um video, \u00e9 necess\u00e1rio usar um loop para capturar os frames da c\u00e2mera e exibir os frames capturados \n## em tempo real na tela do computador \n\n## fa\u00e7a o teste em seu computador, copie e cole o c\u00f3digo abaixo e veja o que acontece \n\nimport cv2\n\n# Iniciando a captura de v\u00eddeo\nwebcam = cv2.VideoCapture(0)\n\n# Definindo o tamanho da janela\nwebcam.set(cv2.CAP_PROP_FRAME_WIDTH, 640)\nwebcam.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)\n\n# Loop para capturar e exibir os frames\nwhile True:\n    # Capturando um frame\n    ret, frame = webcam.read()\n\n    # Verificando se o frame foi capturado corretamente\n    if not ret:\n        print(\"Falha ao capturar o frame. Saindo...\")\n        break\n\n    # Exibindo o frame\n    cv2.imshow(\"Video da Webcam\", frame)\n\n    # Aguardando por 1 milissegundo e verificando se a tecla 'q' foi pressionada\n    if cv2.waitKey(1) &amp; 0xFF == ord('q'):\n        break\n\n# Liberando a c\u00e2mera e fechando todas as janelas\nwebcam.release()\ncv2.destroyAllWindows()\n</pre> ## para captura um video, \u00e9 necess\u00e1rio usar um loop para capturar os frames da c\u00e2mera e exibir os frames capturados  ## em tempo real na tela do computador   ## fa\u00e7a o teste em seu computador, copie e cole o c\u00f3digo abaixo e veja o que acontece   import cv2  # Iniciando a captura de v\u00eddeo webcam = cv2.VideoCapture(0)  # Definindo o tamanho da janela webcam.set(cv2.CAP_PROP_FRAME_WIDTH, 640) webcam.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)  # Loop para capturar e exibir os frames while True:     # Capturando um frame     ret, frame = webcam.read()      # Verificando se o frame foi capturado corretamente     if not ret:         print(\"Falha ao capturar o frame. Saindo...\")         break      # Exibindo o frame     cv2.imshow(\"Video da Webcam\", frame)      # Aguardando por 1 milissegundo e verificando se a tecla 'q' foi pressionada     if cv2.waitKey(1) &amp; 0xFF == ord('q'):         break  # Liberando a c\u00e2mera e fechando todas as janelas webcam.release() cv2.destroyAllWindows()"},{"location":"aulas/PDI/lab03/sol_atividade3.html#histograma","title":"Histograma\u00b6","text":"<p>Na ultima aula, tentamos fazer a segmenta\u00e7\u00e3o de um objeto da imagem pelo metodo for\u00e7a bruta #GoHorse, pode ser que funcione mas n\u00e3o \u00e9 a forma mais intessnte de ser feita. Um histograma pode nos ajudar, ele plota em um gr\u00e1fico de frequ\u00eancia as componentes de cores (r,g,b ou gray) da imagem.</p>"},{"location":"aulas/PDI/lab03/sol_atividade3.html#desafio-1","title":"Desafio 1\u00b6","text":"<p>Fa\u00e7a a seguimenta\u00e7\u00e3o da bolinha de cor laranja. Dica use 2 canais de cores para conseguir seguimentar.</p>"},{"location":"aulas/PDI/lab03/sol_atividade3.html#desafio-2","title":"Desafio 2\u00b6","text":"<p>Fa\u00e7a a seguimenta\u00e7\u00e3o da bolinha para a imagem \"bolinha.png\".</p>"},{"location":"aulas/PDI/lab03/sol_atividade3.html#webcam-e-opencv","title":"Webcam e opencv\u00b6","text":""},{"location":"aulas/PDI/lab03/sol_atividade3.html#este-recurso-nao-vai-funcionar-no-google-colab","title":"Este recurso n\u00e3o vai funcionar no google colab\u00b6","text":"<p>Podemos usar a nossa webcam para registrar imagens e videos, para isso usamos a fun\u00e7\u00e3o cv2.VideoCapture.</p>"},{"location":"aulas/PDI/lab03/sol_atividade3.html#desafio-3","title":"Desafio 3\u00b6","text":"<p>Fa\u00e7a uma foto sua.</p>"},{"location":"aulas/PDI/lab03/webcam.html","title":"Webcam","text":"In\u00a0[\u00a0]: Copied! <p>Programa simples com camera webcam e opencv</p> In\u00a0[\u00a0]: Copied! <pre>import cv2\nimport os,sys, os.path\nimport numpy as np\n</pre> import cv2 import os,sys, os.path import numpy as np In\u00a0[\u00a0]: Copied! <pre>def image_da_webcam(img):\n    \"\"\"\n    -&gt;&gt;&gt; !!!! FECHE A JANELA COM A TECLA ESC !!!! &lt;&lt;&lt;&lt;-\n        deve receber a imagem da camera e retornar uma imagems filtrada.\n    \"\"\"\n    img = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n     # Detect edges in the image and threshold it\n    edges = cv2.Laplacian(img, cv2.CV_8U, ksize=5)\n    ret, mask = cv2.threshold(edges, 100, 255, cv2.THRESH_BINARY_INV)\n\n    return mask\n</pre> def image_da_webcam(img):     \"\"\"     -&gt;&gt;&gt; !!!! FECHE A JANELA COM A TECLA ESC !!!! &lt;&lt;&lt;&lt;-         deve receber a imagem da camera e retornar uma imagems filtrada.     \"\"\"     img = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)      # Detect edges in the image and threshold it     edges = cv2.Laplacian(img, cv2.CV_8U, ksize=5)     ret, mask = cv2.threshold(edges, 100, 255, cv2.THRESH_BINARY_INV)      return mask In\u00a0[\u00a0]: Copied! <pre>cv2.namedWindow(\"preview\")\nvc = cv2.VideoCapture(0)\n</pre> cv2.namedWindow(\"preview\") vc = cv2.VideoCapture(0) In\u00a0[\u00a0]: Copied! <pre>if vc.isOpened(): # try to get the first frame\n    rval, frame = vc.read()\nelse:\n    rval = False\n</pre> if vc.isOpened(): # try to get the first frame     rval, frame = vc.read() else:     rval = False In\u00a0[\u00a0]: Copied! <pre>while rval:\n    \n    img = image_da_webcam(frame)\n\n    cv2.imshow(\"preview\", img)\n    rval, frame = vc.read()\n    key = cv2.waitKey(20)\n    if key == 27: # exit on ESC\n        break\n</pre> while rval:          img = image_da_webcam(frame)      cv2.imshow(\"preview\", img)     rval, frame = vc.read()     key = cv2.waitKey(20)     if key == 27: # exit on ESC         break In\u00a0[\u00a0]: Copied! <pre>cv2.destroyWindow(\"preview\")\nvc.release()\n</pre> cv2.destroyWindow(\"preview\") vc.release()"},{"location":"aulas/PDI/lab04/Filtros_de_Convolu%C3%A7%C3%A3o.html","title":"Lab04 - Filtros de Convolu\u00e7\u00e3o","text":"<p>Objetivos da aula:</p> <ul> <li>Conhecer processo generico de filtro de convolu\u00e7\u00e3o</li> <li>conhecer os filtros de blurring (suaviza\u00e7\u00e3o)</li> <li>conhecer o filtro de sharpening (realce)</li> <li>conhecer o filtro de limiar e suas varia\u00e7\u00f5es</li> <li>conhecer o detetor linhas de canny</li> </ul> In\u00a0[1]: Copied! <pre>## Vou fazer o download das imagens do laborat\u00f3rio diretamente do reposit\u00f3rio para ficar mais facil....\n\nimport requests\nimport os\n\n# Define o laborat\u00f3rio\nlaboratorio = 'lab04'  ### altere para o laborat\u00f3rio desejado\ndiretorio = 'lab_images'  ### altere para o diret\u00f3rio que deseja salvar as imagens\n\n# Download de um arquivo\ndef download_file(url, destination):\n    response = requests.get(url, stream=True)\n    if response.status_code == 200:\n        with open(destination, 'wb') as file:\n            for chunk in response.iter_content(chunk_size=8192):\n                file.write(chunk)\n        print(f\"Baixado: {destination}\")\n    else:\n        print(f\"Erro ao baixar {url}\")\n\n# Monta a URL completa\napi_url = \"https://api.github.com/repos/arnaldojr/cognitivecomputing/contents/material/aulas/PDI/\"\nurl_completa = api_url + laboratorio\nprint(f\"Fazendo o download de: {url_completa}\")\n\n# checa se a URL est\u00e1 acess\u00edvel\nresponse = requests.get(url_completa)\nif response.status_code != 200:\n    raise Exception(f\"Erro ao acessar o reposit\u00f3rio: {response.status_code}\")\nfiles = response.json()\n\n\n# Faz o download de cada arquivo\nos.makedirs(diretorio, exist_ok=True) # Cria a pasta downloads\nfor file in files:\n    file_name = file['name']\n    if file_name.endswith(('.png', '.jpg', '.jpeg', '.mp4')):  # Adicione mais extens\u00f5es se necess\u00e1rio\n        file_url = file['download_url']\n        destination = os.path.join(diretorio, file_name)\n        download_file(file_url, destination)\n\nprint(f\"Download conclu\u00eddo. Arquivos salvos na pasta {diretorio}.\")\n</pre> ## Vou fazer o download das imagens do laborat\u00f3rio diretamente do reposit\u00f3rio para ficar mais facil....  import requests import os  # Define o laborat\u00f3rio laboratorio = 'lab04'  ### altere para o laborat\u00f3rio desejado diretorio = 'lab_images'  ### altere para o diret\u00f3rio que deseja salvar as imagens  # Download de um arquivo def download_file(url, destination):     response = requests.get(url, stream=True)     if response.status_code == 200:         with open(destination, 'wb') as file:             for chunk in response.iter_content(chunk_size=8192):                 file.write(chunk)         print(f\"Baixado: {destination}\")     else:         print(f\"Erro ao baixar {url}\")  # Monta a URL completa api_url = \"https://api.github.com/repos/arnaldojr/cognitivecomputing/contents/material/aulas/PDI/\" url_completa = api_url + laboratorio print(f\"Fazendo o download de: {url_completa}\")  # checa se a URL est\u00e1 acess\u00edvel response = requests.get(url_completa) if response.status_code != 200:     raise Exception(f\"Erro ao acessar o reposit\u00f3rio: {response.status_code}\") files = response.json()   # Faz o download de cada arquivo os.makedirs(diretorio, exist_ok=True) # Cria a pasta downloads for file in files:     file_name = file['name']     if file_name.endswith(('.png', '.jpg', '.jpeg', '.mp4')):  # Adicione mais extens\u00f5es se necess\u00e1rio         file_url = file['download_url']         destination = os.path.join(diretorio, file_name)         download_file(file_url, destination)  print(f\"Download conclu\u00eddo. Arquivos salvos na pasta {diretorio}.\") <pre>Fazendo o download de: https://api.github.com/repos/arnaldojr/cognitivecomputing/contents/material/aulas/PDI/lab04\nBaixado: lab_images/convolution.png\nBaixado: lab_images/lena.png\nBaixado: lab_images/people-walking.mp4\nBaixado: lab_images/saida.png\nBaixado: lab_images/sudoku.png\nBaixado: lab_images/tux.png\nDownload conclu\u00eddo. Arquivos salvos na pasta lab_images.\n</pre> In\u00a0[\u00a0]: Copied! <pre>%matplotlib inline\nimport cv2\nfrom matplotlib import pyplot as plt\nimport numpy as np\n\nimg = cv2.imread('convolution.png')\nplt.imshow(img); plt.show()\n</pre> %matplotlib inline import cv2 from matplotlib import pyplot as plt import numpy as np  img = cv2.imread('convolution.png') plt.imshow(img); plt.show() In\u00a0[\u00a0]: Copied! <pre>from IPython.display import Image\nImage(open('same_padding_no_strides.gif','rb').read())\n</pre> from IPython.display import Image Image(open('same_padding_no_strides.gif','rb').read()) Out[\u00a0]: <p>Observa\u00e7\u00e3o</p> <p>Embora o nome convolu\u00e7\u00e3o seja muito usado, na pr\u00e1tica realizamos o processo de correla\u00e7\u00e3o, para realizar a convolu\u00e7\u00e3o \u00e9 necess\u00e1rio realizar a invers\u00e3o da mascara (matriz), o que n\u00e3o \u00e9 um problema pois em processamento de imagem, tipicamente os kernels s\u00e3o sim\u00e9tricos, logo os resultados de convolu\u00e7\u00e3o e correla\u00e7\u00e3o n\u00e3o mudam.</p> In\u00a0[\u00a0]: Copied! <pre>import numpy as np\nimport cv2\n\n\n#carrega imagem\nimg = cv2.imread('lena.png')\nplt.imshow(img, cmap=\"Greys_r\", vmin=0, vmax=255); plt.show()\n\n# Define o kernel\nkernel = np.array([[1, 1, 1, 1, 1], \n                   [1, 1, 1, 1, 1],\n                   [1, 1, 1, 1, 1],\n                   [1, 1, 1, 1, 1],\n                   [1, 1, 1, 1 ,1]])\nkernel = kernel/(np.sum(kernel) if np.sum(kernel)!=0 else 1)\n\n# Realiza o produto de convolu\u00e7\u00e3o\nimgf = cv2.filter2D(img,-1,kernel)\n\n#exibe resultado filtrado\nplt.imshow(imgf, cmap=\"Greys_r\", vmin=0, vmax=255); plt.show()\n</pre> import numpy as np import cv2   #carrega imagem img = cv2.imread('lena.png') plt.imshow(img, cmap=\"Greys_r\", vmin=0, vmax=255); plt.show()  # Define o kernel kernel = np.array([[1, 1, 1, 1, 1],                     [1, 1, 1, 1, 1],                    [1, 1, 1, 1, 1],                    [1, 1, 1, 1, 1],                    [1, 1, 1, 1 ,1]]) kernel = kernel/(np.sum(kernel) if np.sum(kernel)!=0 else 1)  # Realiza o produto de convolu\u00e7\u00e3o imgf = cv2.filter2D(img,-1,kernel)  #exibe resultado filtrado plt.imshow(imgf, cmap=\"Greys_r\", vmin=0, vmax=255); plt.show() <p>FILTROS PARA BLURRING</p> <p>O filtro de blurring (borramento) consiste na  perda gradual de foco da imagem, produzindo a sensa\u00e7\u00e3o que ela est\u00e1 borrada. Em outras palavras s\u00e3o filtros passa-baixa.</p> <p>Existem diversos m\u00e9todos para constru\u00e7\u00f5es de kernels para blurring:</p> <ul> <li>filtro da m\u00e9dia (box filter): blur = cv.blur(img,(5,5))</li> <li>filtro gaussiano: blur = cv.GaussianBlur(img,(5,5),0)</li> <li>filtro da mediana: blur = cv.medianBlur(img,5)</li> <li>filtro bilateral: blur = cv.bilateralFilter(img,9,75,75)</li> </ul> In\u00a0[4]: Copied! <pre>import numpy as np\nimport cv2 \n\n#carrega imagem\nimg = cv2.imread('lena.png')\n\n# Realiza o blur\nimgf = cv2.blur(img,(51,51),0)\n\n# Exibir as imagens\nplt.figure(figsize=(15, 5))\nplt.subplot(1, 3, 1)\nplt.title('Imagem Original')\nplt.imshow(img, cmap='gray')\n\nplt.subplot(1, 3, 2)\nplt.title('Suavizada (Blurring)')\nplt.imshow(imgf, cmap='gray')\n</pre> import numpy as np import cv2   #carrega imagem img = cv2.imread('lena.png')  # Realiza o blur imgf = cv2.blur(img,(51,51),0)  # Exibir as imagens plt.figure(figsize=(15, 5)) plt.subplot(1, 3, 1) plt.title('Imagem Original') plt.imshow(img, cmap='gray')  plt.subplot(1, 3, 2) plt.title('Suavizada (Blurring)') plt.imshow(imgf, cmap='gray') Out[4]: <pre>&lt;matplotlib.image.AxesImage at 0x1511ee310&gt;</pre> In\u00a0[\u00a0]: Copied! <pre>#Implemente seu c\u00f3digo aqui.\n</pre> #Implemente seu c\u00f3digo aqui. <p>FILTRO DE SHARPENING</p> <p>O filtro de sharpening consiste no ganho gradual de foco de uma imagem, produzindo a sensa\u00e7\u00e3o que ela est\u00e1 cada vez mais bem definida. \u00c9 uma aproxima\u00e7\u00e3o da inversa do filtro de blurring.</p> <p>Existem diversos m\u00e9todos para constru\u00e7\u00f5es de kernels para blurring:</p> <ul> <li>filtro Sobel X: imgf = cv.Sobel(img,cv.CV_64F,1,0,ksize=5)</li> <li>filtro Sobel Y: imgf = cv.Sobel(img,cv.CV_64F,0,1,ksize=5)</li> <li>filtro Laplaciano: imgf = cv.Laplacian(img,cv.CV_64F)</li> </ul> <p>Abaixo, temos as formas matriciais do filtro de sharpening.</p> In\u00a0[\u00a0]: Copied! <pre>#Filtro Laplaciano\nkernel = np.array([[0, -1, 0], \n                   [-1, 4, -1], \n                   [0, -1, 0]])\n\nkernel = np.array([[-1, -1, -1], \n                   [-1, 8, -1], \n                   [-1, -1, -1]])\n#filtro de Sobel X\nkernel = np.array([[-1, 0, 1], \n                   [-2, 0, 2], \n                   [-1, 0, 1]])\nkernel = np.array([[-1, -2, -1], \n                   [ 0, 0, 0], \n                   [-1, 0, 1]])\n</pre> #Filtro Laplaciano kernel = np.array([[0, -1, 0],                     [-1, 4, -1],                     [0, -1, 0]])  kernel = np.array([[-1, -1, -1],                     [-1, 8, -1],                     [-1, -1, -1]]) #filtro de Sobel X kernel = np.array([[-1, 0, 1],                     [-2, 0, 2],                     [-1, 0, 1]]) kernel = np.array([[-1, -2, -1],                     [ 0, 0, 0],                     [-1, 0, 1]]) In\u00a0[\u00a0]: Copied! <pre>import numpy as np\nimport cv2\n\n\n#carrega imagem\nimg = cv2.imread('lena.png')\nplt.imshow(img, cmap=\"Greys_r\", vmin=0, vmax=255); plt.show()\n\n\n\nimgf = cv2.Sobel(img,cv2.CV_64F,1,0,ksize=3)\nimgf2 = cv2.Sobel(img,cv2.CV_64F,0,1,ksize=3)\n\n# Monta o kernel filtro \n#kernel = np.array([[-1, -1, -1], \n#                   [-1, 8, -1], \n#                   [-1, -1, -1]])\n# Realiza o produto de convolu\u00e7\u00e3o\n#imgf = cv2.filter2D(img,-1,kernel)\n\n#exibe resultado filtrado\nplt.imshow(imgf, cmap=\"Greys_r\", vmin=0, vmax=255);plt.show()\nplt.imshow(imgf2, cmap=\"Greys_r\", vmin=0, vmax=255); plt.show()\n</pre> import numpy as np import cv2   #carrega imagem img = cv2.imread('lena.png') plt.imshow(img, cmap=\"Greys_r\", vmin=0, vmax=255); plt.show()    imgf = cv2.Sobel(img,cv2.CV_64F,1,0,ksize=3) imgf2 = cv2.Sobel(img,cv2.CV_64F,0,1,ksize=3)  # Monta o kernel filtro  #kernel = np.array([[-1, -1, -1],  #                   [-1, 8, -1],  #                   [-1, -1, -1]]) # Realiza o produto de convolu\u00e7\u00e3o #imgf = cv2.filter2D(img,-1,kernel)  #exibe resultado filtrado plt.imshow(imgf, cmap=\"Greys_r\", vmin=0, vmax=255);plt.show() plt.imshow(imgf2, cmap=\"Greys_r\", vmin=0, vmax=255); plt.show() <pre>WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n</pre> <pre>WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n</pre> In\u00a0[\u00a0]: Copied! <pre>#implemente seu c\u00f3digo aqui.\n</pre> #implemente seu c\u00f3digo aqui. <p>FILTRO DE BORDAS DE CANNY</p> <p>O filtro de canny \u00e9 um detector de linhas e bordas que combina de forma mais sofisticada opera\u00e7\u00f5es lineares.</p> In\u00a0[2]: Copied! <pre>import cv2\nimport matplotlib.pyplot as plt\n\n# Carregar a imagem\nimage = cv2.imread('lab_images/lena.png', cv2.IMREAD_GRAYSCALE)\n\n\nthreshold_min = 100\nthreshold_max = 200\n# Aplicar o detector de bordas de Canny\nedges = cv2.Canny(image, threshold1=threshold_min, threshold2=threshold_max)\n\n# Exibir a imagem original e a imagem com bordas detectadas\nplt.figure(figsize=(10, 5))\nplt.subplot(1, 2, 1)\nplt.title('Imagem Original')\nplt.imshow(image, cmap='gray')\n\nplt.subplot(1, 2, 2)\nplt.title('Bordas Detectadas (Canny)')\nplt.imshow(edges, cmap='gray')\nplt.show()\n</pre> import cv2 import matplotlib.pyplot as plt  # Carregar a imagem image = cv2.imread('lab_images/lena.png', cv2.IMREAD_GRAYSCALE)   threshold_min = 100 threshold_max = 200 # Aplicar o detector de bordas de Canny edges = cv2.Canny(image, threshold1=threshold_min, threshold2=threshold_max)  # Exibir a imagem original e a imagem com bordas detectadas plt.figure(figsize=(10, 5)) plt.subplot(1, 2, 1) plt.title('Imagem Original') plt.imshow(image, cmap='gray')  plt.subplot(1, 2, 2) plt.title('Bordas Detectadas (Canny)') plt.imshow(edges, cmap='gray') plt.show() In\u00a0[\u00a0]: Copied! <pre>#Seu c\u00f3digo\n</pre> #Seu c\u00f3digo In\u00a0[\u00a0]: Copied! <pre>import cv2\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# Carregar imagem em escala de cinza\nimg_original = cv2.imread('lena.png')\nimg = cv2.cvtColor(img_original, cv2.COLOR_BGR2GRAY)\n\n\n# Definir um valor de limiar\nthreshold_value = 127\n\n# Aplicando Filtro de Limiariza\u00e7\u00e3o\n_, thresh_binary = cv2.threshold(img, threshold_value, 255, cv2.THRESH_BINARY)\n_, thresh_binary_inv = cv2.threshold(img, threshold_value, 255, cv2.THRESH_BINARY_INV)\n_, thresh_trunc = cv2.threshold(img, threshold_value, 255, cv2.THRESH_TRUNC)\n_, thresh_tozero = cv2.threshold(img, threshold_value, 255, cv2.THRESH_TOZERO)\n_, thresh_tozero_inv = cv2.threshold(img, threshold_value, 255, cv2.THRESH_TOZERO_INV)\n_, thresh_otsu = cv2.threshold(img, 0, 255, cv2.THRESH_OTSU)\n\ntitles = ['Original','Gray', 'THRESH_BINARY', 'THRESH_BINARY_INV', 'THRESH_TRUNC', 'THRESH_TOZERO', 'THRESH_TOZERO_INV', 'THRESH_OTSU']\nimages = [img_original, img, thresh_binary, thresh_binary_inv, thresh_trunc, thresh_tozero, thresh_tozero_inv, thresh_otsu]\n\nfig, axes = plt.subplots(2, 4, figsize=(12, 6))\nfor ax, title, image in zip(axes.flat, titles, images):\n    ax.imshow(image, cmap='gray')\n    ax.set_title(title)\n    ax.axis('off')\n\nplt.tight_layout()\nplt.show()\n</pre> import cv2 import numpy as np import matplotlib.pyplot as plt  # Carregar imagem em escala de cinza img_original = cv2.imread('lena.png') img = cv2.cvtColor(img_original, cv2.COLOR_BGR2GRAY)   # Definir um valor de limiar threshold_value = 127  # Aplicando Filtro de Limiariza\u00e7\u00e3o _, thresh_binary = cv2.threshold(img, threshold_value, 255, cv2.THRESH_BINARY) _, thresh_binary_inv = cv2.threshold(img, threshold_value, 255, cv2.THRESH_BINARY_INV) _, thresh_trunc = cv2.threshold(img, threshold_value, 255, cv2.THRESH_TRUNC) _, thresh_tozero = cv2.threshold(img, threshold_value, 255, cv2.THRESH_TOZERO) _, thresh_tozero_inv = cv2.threshold(img, threshold_value, 255, cv2.THRESH_TOZERO_INV) _, thresh_otsu = cv2.threshold(img, 0, 255, cv2.THRESH_OTSU)  titles = ['Original','Gray', 'THRESH_BINARY', 'THRESH_BINARY_INV', 'THRESH_TRUNC', 'THRESH_TOZERO', 'THRESH_TOZERO_INV', 'THRESH_OTSU'] images = [img_original, img, thresh_binary, thresh_binary_inv, thresh_trunc, thresh_tozero, thresh_tozero_inv, thresh_otsu]  fig, axes = plt.subplots(2, 4, figsize=(12, 6)) for ax, title, image in zip(axes.flat, titles, images):     ax.imshow(image, cmap='gray')     ax.set_title(title)     ax.axis('off')  plt.tight_layout() plt.show() In\u00a0[18]: Copied! <pre>import cv2\nimport matplotlib.pyplot as plt\n\n# Carregar duas imagens\nimage1 = cv2.imread('lab_images/lena.png')\nimage2 = cv2.imread('lab_images/tux.png')\n\n# Redimensionar as imagens para o mesmo tamanho (se necess\u00e1rio)\nimage2 = cv2.resize(image2, (image1.shape[1], image1.shape[0]))\n\n# Definir o valor de alpha (transpar\u00eancia)\nalpha = 0.5  # 50% de cada imagem\n\n# Aplicar a sobreposi\u00e7\u00e3o\nblended_image = cv2.addWeighted(image1, 1 - alpha, image2, alpha, 0)\n\n# Exibir as imagens\nplt.figure(figsize=(15, 5))\nplt.subplot(1, 3, 1)\nplt.title('Imagem 1 (Lena)')\nplt.imshow(cv2.cvtColor(image1, cv2.COLOR_BGR2RGB))\n\nplt.subplot(1, 3, 2)\nplt.title('Imagem 2 (Tux)')\nplt.imshow(cv2.cvtColor(image2, cv2.COLOR_BGR2RGB))\n\nplt.subplot(1, 3, 3)\nplt.title(f'Sobreposi\u00e7\u00e3o (\u03b1 = {alpha})')\nplt.imshow(cv2.cvtColor(blended_image, cv2.COLOR_BGR2RGB))\nplt.show()\n</pre> import cv2 import matplotlib.pyplot as plt  # Carregar duas imagens image1 = cv2.imread('lab_images/lena.png') image2 = cv2.imread('lab_images/tux.png')  # Redimensionar as imagens para o mesmo tamanho (se necess\u00e1rio) image2 = cv2.resize(image2, (image1.shape[1], image1.shape[0]))  # Definir o valor de alpha (transpar\u00eancia) alpha = 0.5  # 50% de cada imagem  # Aplicar a sobreposi\u00e7\u00e3o blended_image = cv2.addWeighted(image1, 1 - alpha, image2, alpha, 0)  # Exibir as imagens plt.figure(figsize=(15, 5)) plt.subplot(1, 3, 1) plt.title('Imagem 1 (Lena)') plt.imshow(cv2.cvtColor(image1, cv2.COLOR_BGR2RGB))  plt.subplot(1, 3, 2) plt.title('Imagem 2 (Tux)') plt.imshow(cv2.cvtColor(image2, cv2.COLOR_BGR2RGB))  plt.subplot(1, 3, 3) plt.title(f'Sobreposi\u00e7\u00e3o (\u03b1 = {alpha})') plt.imshow(cv2.cvtColor(blended_image, cv2.COLOR_BGR2RGB)) plt.show() In\u00a0[\u00a0]: Copied! <pre>#Seu c\u00f3digo aqui.\n</pre> #Seu c\u00f3digo aqui."},{"location":"aulas/PDI/lab04/Filtros_de_Convolu%C3%A7%C3%A3o.html#introducao-aos-filtros-de-convolucao","title":"Introdu\u00e7\u00e3o aos Filtros de Convolu\u00e7\u00e3o\u00b6","text":"<p>O filtro de convolu\u00e7\u00e3o \u00e9 um nomes dados para filtragem no dom\u00ednio espacial. Esse processo ocorre com a aplica\u00e7\u00e3o de filtros (pequenas matrizes), posicionados sob cada pixel da imagem. Estes filtros, normalmente, s\u00e3o chamados de kernels (ou n\u00facleos). O resultado final do valor do pixel \u00e9 calculado atrav\u00e9s de um produto de convolu\u00e7\u00e3o.</p> <p>Normalmente os kernels s\u00e3o matrizes 3x3, 5x5 ou 7x7.</p>"},{"location":"aulas/PDI/lab04/Filtros_de_Convolu%C3%A7%C3%A3o.html#desafio-0","title":"Desafio 0\u00b6","text":"<p>Abra o link https://setosa.io/ev/image-kernels/ e de forma intuitiva altere o valor do filtro/kernel e descubra efeitos resultantes.</p>"},{"location":"aulas/PDI/lab04/Filtros_de_Convolu%C3%A7%C3%A3o.html#implementacao-na-opencv","title":"Implementa\u00e7\u00e3o na OpenCV\u00b6","text":"<p>Podemos implementar o produto de convolu\u00e7\u00e3o montando uma estrutura com dois for para varrer a imagem toda, pixel-a-pixel.N\u00e3o \u00e9 a forma mais eficiente, pois Na OpenCV tem uma fun\u00e7\u00e3o built-in para implementa\u00e7\u00e3o de filtro de convolu\u00e7\u00e3o a cv2.filter2D()</p>"},{"location":"aulas/PDI/lab04/Filtros_de_Convolu%C3%A7%C3%A3o.html#desafio-1","title":"Desafio 1\u00b6","text":"<p>Escolha uma imagem da sua prefer\u00eancia e fa\u00e7a um estudo sobre os diferentes tipos de filtros de borramento, analise tamb\u00e9m o que acontece quando \u00e9 alterado o tamanho do kernel.</p>"},{"location":"aulas/PDI/lab04/Filtros_de_Convolu%C3%A7%C3%A3o.html#desafio-2","title":"Desafio 2\u00b6","text":"<p>Escolha uma imagem da sua prefer\u00eancia e fa\u00e7a um estudo sobre os diferentes tipos de filtros de contraste, analise tamb\u00e9m o que acontece quando \u00e9 alterado o tamanho do kernel.</p>"},{"location":"aulas/PDI/lab04/Filtros_de_Convolu%C3%A7%C3%A3o.html#desafio-3","title":"Desafio 3\u00b6","text":"<p>O Filtro de Canny \u00e9 um dos mais utilizados at\u00e9 hoje, por ser robusto e apresentar bons resultados.</p> <p>Ajuste os valores de threshold1 e threshold2 no detector de Canny e observe como os limiares afetam a detec\u00e7\u00e3o de bordas. Tente encontrar os valores ideais para diferentes imagens.</p>"},{"location":"aulas/PDI/lab04/Filtros_de_Convolu%C3%A7%C3%A3o.html#filtro-de-limiarizacao","title":"FILTRO DE LIMIARIZA\u00c7\u00c3O\u00b6","text":"<p>O filtro de limiariza\u00e7\u00e3o \u00e9 uma t\u00e9cnica que converte uma imagem em tons de cinza em uma imagem bin\u00e1ria, onde os pixels s\u00e3o classificados como preto ou branco com base em um valor de limiar. Essa t\u00e9cnica \u00e9 utilizada em tarefas como segmenta\u00e7\u00e3o de objetos, detec\u00e7\u00e3o de bordas e pr\u00e9-processamento de imagens.</p> <p>O OpenCV oferece v\u00e1rias t\u00e9cnicas de limiariza\u00e7\u00e3o, cada uma com suas particularidades. Abaixo est\u00e3o as principais:</p> <ul> <li>cv2.THRESH_BINARY: Pixels acima do limiar s\u00e3o definidos como branco (255), e os abaixo, como preto (0).</li> <li>cv2.THRESH_BINARY_INV: Inverso do THRESH_BINARY. Pixels acima do limiar s\u00e3o definidos como preto, e os abaixo, como branco.</li> <li>cv2.THRESH_TRUNC: Pixels acima do limiar s\u00e3o truncados ao valor do limiar, enquanto os abaixo permanecem inalterados.</li> <li>cv2.THRESH_TOZERO: Pixels abaixo do limiar s\u00e3o definidos como preto, e os acima permanecem inalterados.</li> <li>cv2.THRESH_TOZERO_INV: Inverso do THRESH_TOZERO. Pixels acima do limiar s\u00e3o definidos como preto, e os abaixo permanecem inalterados.</li> <li>cv2.THRESH_OTSU: M\u00e9todo autom\u00e1tico para determinar o limiar ideal, especialmente \u00fatil para imagens com histogramas bimodais</li> </ul> <p>DICA</p> <ul> <li>cv2.threshold(): Fun\u00e7\u00e3o usada para aplicar a limiariza\u00e7\u00e3o. Recebe a imagem, o valor do limiar, o valor m\u00e1ximo (geralmente 255) e o tipo de limiariza\u00e7\u00e3o.</li> <li>cv2.THRESH_OTSU: M\u00e9todo autom\u00e1tico que calcula o limiar ideal com base no histograma da imagem. N\u00e3o \u00e9 necess\u00e1rio fornecer um valor de limiar manualmente.</li> </ul>"},{"location":"aulas/PDI/lab04/Filtros_de_Convolu%C3%A7%C3%A3o.html#filtro-de-sobreposicao-de-imagens","title":"FILTRO DE SOBREPOSI\u00c7\u00c3O DE IMAGENS\u00b6","text":"<p>O filtro de sobreposi\u00e7\u00e3o (ou blending) mescla duas imagens, gerando um efeito de transpar\u00eancia ou combina\u00e7\u00e3o. A opera\u00e7\u00e3o matem\u00e1tica para a imagem de sa\u00edda \u00e9 dada por:</p> <p>A opera\u00e7\u00e3o da imagem de saida \u00e9 a seguinte: g(x)=(1\u2212\u03b1)\u2217f0(x)+\u03b1\u2217f1(x)</p>"},{"location":"aulas/PDI/lab04/Filtros_de_Convolu%C3%A7%C3%A3o.html#desafio-4","title":"Desafio 4\u00b6","text":"<p>Combine a sobreposi\u00e7\u00e3o com outros filtros, como suaviza\u00e7\u00e3o ou realce, e observe os efeitos.</p>"},{"location":"aulas/PDI/lab04/Filtros_de_Convolu%C3%A7%C3%A3o.html#desafio-5","title":"Desafio 5\u00b6","text":"<p>Fa\u00e7a um script python (.py) que processa um video (webcam ou .mp4) e processe cada frame aplicando uma opera\u00e7\u00e3o de convolu\u00e7\u00e3o (por exemplo, para detec\u00e7\u00e3o de bordas ou desfoque) e exiba o resultado em tempo real.</p> <p>Defini\u00e7\u00e3o da M\u00e1scara de Convolu\u00e7\u00e3o:</p> <ul> <li>Escolha e implemente pelo menos uma m\u00e1scara de convolu\u00e7\u00e3o.</li> <li>Exemplos:<ul> <li>Detec\u00e7\u00e3o de Bordas: M\u00e1scara de Sobel ou Laplaciano.</li> <li>Desfoque: M\u00e1scara m\u00e9dia ou gaussiana.</li> </ul> </li> <li>Explique brevemente no c\u00f3digo o efeito de cada m\u00e1scara.</li> </ul> <p>Organiza\u00e7\u00e3o de c\u00f3digo</p> <ul> <li>C\u00f3digo bem comentado, com fun\u00e7\u00f5es (separando as responsabilidades) e estrutura clara.</li> </ul>"},{"location":"aulas/PDI/lab04/sol_Filtros_de_Convolu%C3%A7%C3%A3o.html","title":"sol Filtros de Convolu\u00e7\u00e3o","text":"<p>Objetivos da aula:</p> <ul> <li>Conhecer processo generico de filtro de convolu\u00e7\u00e3o</li> <li>conhecer os filtros de blurring (suaviza\u00e7\u00e3o)</li> <li>conhecer o filtro de sharpening (realce)</li> <li>conhecer o detetor linhas de canny</li> </ul> <p>Filtro de convolu\u00e7\u00e3o</p> <p>O filtro de convolu\u00e7\u00e3o \u00e9 um nomes dados para filtragem no dom\u00ednio espacial. Esse processo ocorre com a aplica\u00e7\u00e3o de filtros (pequenas matrizes), posicionados sob cada pixel da imagem. Estes filtros, normalmente, s\u00e3o chamados de kernels (ou n\u00facleos). O resultado final do valor do pixel \u00e9 calculado atrav\u00e9s de um produto de convolu\u00e7\u00e3o.</p> <p>Normalmente os kernels s\u00e3o matrizes 3x3, 5x5 ou 7x7.</p> In\u00a0[\u00a0]: Copied! <pre># fazendo o download das imagens necess\u00e1rias para o lab\n\n!wget https://raw.githubusercontent.com/arnaldojr/cognitivecomputing/master/material/aulas/PDI/lab04/convolution.png /content\n!wget https://raw.githubusercontent.com/arnaldojr/cognitivecomputing/master/material/aulas/PDI/lab04/lena.png /content\n!wget https://raw.githubusercontent.com/arnaldojr/cognitivecomputing/master/material/aulas/PDI/lab04/saida.png /content\n!wget https://raw.githubusercontent.com/arnaldojr/cognitivecomputing/master/material/aulas/PDI/lab04/same_padding_no_strides.gif /content\n!wget https://raw.githubusercontent.com/arnaldojr/cognitivecomputing/master/material/aulas/PDI/lab04/tux.png /content\n</pre> # fazendo o download das imagens necess\u00e1rias para o lab  !wget https://raw.githubusercontent.com/arnaldojr/cognitivecomputing/master/material/aulas/PDI/lab04/convolution.png /content !wget https://raw.githubusercontent.com/arnaldojr/cognitivecomputing/master/material/aulas/PDI/lab04/lena.png /content !wget https://raw.githubusercontent.com/arnaldojr/cognitivecomputing/master/material/aulas/PDI/lab04/saida.png /content !wget https://raw.githubusercontent.com/arnaldojr/cognitivecomputing/master/material/aulas/PDI/lab04/same_padding_no_strides.gif /content !wget https://raw.githubusercontent.com/arnaldojr/cognitivecomputing/master/material/aulas/PDI/lab04/tux.png /content In\u00a0[1]: Copied! <pre>%matplotlib inline\nimport cv2\nfrom matplotlib import pyplot as plt\nimport numpy as np\n\nimg = cv2.imread('convolution.png')\nplt.imshow(img); plt.show()\n</pre> %matplotlib inline import cv2 from matplotlib import pyplot as plt import numpy as np  img = cv2.imread('convolution.png') plt.imshow(img); plt.show() In\u00a0[2]: Copied! <pre>from IPython.display import Image\nImage(open('same_padding_no_strides.gif','rb').read())\n</pre> from IPython.display import Image Image(open('same_padding_no_strides.gif','rb').read()) Out[2]: <p>Observa\u00e7\u00e3o</p> <p>Embora o nome convolu\u00e7\u00e3o seja muito usado, na pr\u00e1tica realizamos o processo de correla\u00e7\u00e3o, para realizar a convolu\u00e7\u00e3o \u00e9 necess\u00e1rio realizar a invers\u00e3o da mascara (matriz), o que n\u00e3o \u00e9 um problema pois em processamento de imagem, tipicamente os kernels s\u00e3o sim\u00e9tricos, logo os resultados de convolu\u00e7\u00e3o e correla\u00e7\u00e3o n\u00e3o mudam.</p> In\u00a0[3]: Copied! <pre>import numpy as np\nimport cv2\n\n\n#carrega imagem\nimg = cv2.imread('lena.png')\nplt.imshow(img, cmap=\"Greys_r\", vmin=0, vmax=255); plt.show()\n\n# Define o kernel\nkernel = np.array([[1, 1, 1, 1, 1], \n                   [1, 1, 1, 1, 1],\n                   [1, 1, 1, 1, 1],\n                   [1, 1, 1, 1, 1],\n                   [1, 1, 1, 1 ,1]])\nkernel = kernel/(np.sum(kernel) if np.sum(kernel)!=0 else 1)\n\n# Realiza o produto de convolu\u00e7\u00e3o\nimgf = cv2.filter2D(img,-1,kernel)\n\n#exibe resultado filtrado\nplt.imshow(imgf, cmap=\"Greys_r\", vmin=0, vmax=255); plt.show()\n</pre> import numpy as np import cv2   #carrega imagem img = cv2.imread('lena.png') plt.imshow(img, cmap=\"Greys_r\", vmin=0, vmax=255); plt.show()  # Define o kernel kernel = np.array([[1, 1, 1, 1, 1],                     [1, 1, 1, 1, 1],                    [1, 1, 1, 1, 1],                    [1, 1, 1, 1, 1],                    [1, 1, 1, 1 ,1]]) kernel = kernel/(np.sum(kernel) if np.sum(kernel)!=0 else 1)  # Realiza o produto de convolu\u00e7\u00e3o imgf = cv2.filter2D(img,-1,kernel)  #exibe resultado filtrado plt.imshow(imgf, cmap=\"Greys_r\", vmin=0, vmax=255); plt.show() <p>FILTROS PARA BLURRING</p> <p>O filtro de blurring (borramento) consiste na  perda gradual de foco da imagem, produzindo a sensa\u00e7\u00e3o que ela est\u00e1 borrada. Em outras palavras s\u00e3o filtros passa-baixa.</p> <p>Existem diversos m\u00e9todos para constru\u00e7\u00f5es de kernels para blurring:</p> <ul> <li>filtro da m\u00e9dia (box filter): blur = cv.blur(img,(5,5))</li> <li>filtro gaussiano: blur = cv.GaussianBlur(img,(5,5),0)</li> <li>filtro da mediana: blur = cv.medianBlur(img,5)</li> <li>filtro bilateral: blur = cv.bilateralFilter(img,9,75,75)</li> </ul> In\u00a0[4]: Copied! <pre>import numpy as np\nimport cv2 \n\n#carrega imagem\nimg = cv2.imread('lena.png')\nplt.imshow(img, cmap=\"Greys_r\", vmin=0, vmax=255); plt.show()\n\n# Realiza o blur\nimgf = cv2.blur(img,(51,51),0)\n\n#exibe resultado filtrado\nplt.imshow(imgf, cmap=\"Greys_r\", vmin=0, vmax=255); plt.show()\n</pre> import numpy as np import cv2   #carrega imagem img = cv2.imread('lena.png') plt.imshow(img, cmap=\"Greys_r\", vmin=0, vmax=255); plt.show()  # Realiza o blur imgf = cv2.blur(img,(51,51),0)  #exibe resultado filtrado plt.imshow(imgf, cmap=\"Greys_r\", vmin=0, vmax=255); plt.show() In\u00a0[5]: Copied! <pre>#Implemente seu c\u00f3digo aqui.\n\n# Como a ideia \u00e9 realizar um estudo para entender o efeito de diferentes filtros, vou realizar a mesma opera\u00e7\u00e3o para diferentes tamanhos de kernel.\n# Vou utilizar um filtro de m\u00e9dia, um filtro gaussiano, um filtro de mediana e um filtro bilateral. \n# Vou exibir os resultados para cada tamanho de kernel. \n# Por essa raz\u00e3o, vou criar uma figura com subplots para exibir os resultados e varrer os diferentes tamanhos de kernel utilizando um loop for.\n\n# \u00c9 apenas uma sugest\u00e3o de abordagem, voc\u00ea pode implementar de outra forma se preferir.\n\n\nimport cv2\nfrom matplotlib import pyplot as plt\n\n# Carrega a imagem\nimg = cv2.imread('lena.png')\nimg = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n\n# Define os tamanhos de kernel para experimenta\u00e7\u00e3o\nkernels = [(5, 5), (15, 15), (51, 51)]\n\n# Cria uma figura com subplots\nfig, axs = plt.subplots(len(kernels) + 1, 4, figsize=(20, 15))\n\n# Exibe a imagem original\naxs[0, 0].imshow(img)\naxs[0, 0].set_title('Imagem Original')\nfor i in range(1, 4):\n    axs[0, i].axis('off')\n\n# Aplica e exibe os diferentes filtros para cada tamanho de kernel\nfor i, kernel in enumerate(kernels, 1):\n    # Filtro de M\u00e9dia\n    img_blur = cv2.blur(img, kernel)\n    axs[i, 0].imshow(img_blur)\n    axs[i, 0].set_title(f'Filtro de M\u00e9dia - Kernel {kernel}')\n\n    # Filtro Gaussiano\n    img_gaussian = cv2.GaussianBlur(img, kernel, 0)\n    axs[i, 1].imshow(img_gaussian)\n    axs[i, 1].set_title(f'Filtro Gaussiano - Kernel {kernel}')\n\n    # Filtro de Mediana\n    img_median = cv2.medianBlur(img, kernel[0])  # O kernel \u00e9 um \u00fanico valor para o filtro de mediana\n    axs[i, 2].imshow(img_median)\n    axs[i, 2].set_title(f'Filtro de Mediana - Kernel {kernel[0]}')\n\n    # Filtro Bilateral\n    img_bilateral = cv2.bilateralFilter(img, 9, 75, 75)\n    axs[i, 3].imshow(img_bilateral)\n    axs[i, 3].set_title(f'Filtro Bilateral - D=9, SigmaColor=75, SigmaSpace=75')\n\n# Ajusta o layout e exibe a figura\nplt.tight_layout()\nplt.show()\n</pre> #Implemente seu c\u00f3digo aqui.  # Como a ideia \u00e9 realizar um estudo para entender o efeito de diferentes filtros, vou realizar a mesma opera\u00e7\u00e3o para diferentes tamanhos de kernel. # Vou utilizar um filtro de m\u00e9dia, um filtro gaussiano, um filtro de mediana e um filtro bilateral.  # Vou exibir os resultados para cada tamanho de kernel.  # Por essa raz\u00e3o, vou criar uma figura com subplots para exibir os resultados e varrer os diferentes tamanhos de kernel utilizando um loop for.  # \u00c9 apenas uma sugest\u00e3o de abordagem, voc\u00ea pode implementar de outra forma se preferir.   import cv2 from matplotlib import pyplot as plt  # Carrega a imagem img = cv2.imread('lena.png') img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)  # Define os tamanhos de kernel para experimenta\u00e7\u00e3o kernels = [(5, 5), (15, 15), (51, 51)]  # Cria uma figura com subplots fig, axs = plt.subplots(len(kernels) + 1, 4, figsize=(20, 15))  # Exibe a imagem original axs[0, 0].imshow(img) axs[0, 0].set_title('Imagem Original') for i in range(1, 4):     axs[0, i].axis('off')  # Aplica e exibe os diferentes filtros para cada tamanho de kernel for i, kernel in enumerate(kernels, 1):     # Filtro de M\u00e9dia     img_blur = cv2.blur(img, kernel)     axs[i, 0].imshow(img_blur)     axs[i, 0].set_title(f'Filtro de M\u00e9dia - Kernel {kernel}')      # Filtro Gaussiano     img_gaussian = cv2.GaussianBlur(img, kernel, 0)     axs[i, 1].imshow(img_gaussian)     axs[i, 1].set_title(f'Filtro Gaussiano - Kernel {kernel}')      # Filtro de Mediana     img_median = cv2.medianBlur(img, kernel[0])  # O kernel \u00e9 um \u00fanico valor para o filtro de mediana     axs[i, 2].imshow(img_median)     axs[i, 2].set_title(f'Filtro de Mediana - Kernel {kernel[0]}')      # Filtro Bilateral     img_bilateral = cv2.bilateralFilter(img, 9, 75, 75)     axs[i, 3].imshow(img_bilateral)     axs[i, 3].set_title(f'Filtro Bilateral - D=9, SigmaColor=75, SigmaSpace=75')  # Ajusta o layout e exibe a figura plt.tight_layout() plt.show()  <p>FILTRO DE SHARPENING</p> <p>O filtro de sharpening consiste no ganho gradual de foco de uma imagem, produzindo a sensa\u00e7\u00e3o que ela est\u00e1 cada vez mais bem definida. \u00c9 uma aproxima\u00e7\u00e3o da inversa do filtro de blurring.</p> <p>Existem diversos m\u00e9todos para constru\u00e7\u00f5es de kernels para blurring:</p> <ul> <li>filtro Sobel X: imgf = cv.Sobel(img,cv.CV_64F,1,0,ksize=5)</li> <li>filtro Sobel Y: imgf = cv.Sobel(img,cv.CV_64F,0,1,ksize=5)</li> <li>filtro Laplaciano: imgf = cv.Laplacian(img,cv.CV_64F)</li> </ul> <p>Abaixo, temos as formas matriciais do filtro de sharpening.</p> In\u00a0[6]: Copied! <pre>#Filtro Laplaciano\nkernel = np.array([[0, -1, 0], \n                   [-1, 4, -1], \n                   [0, -1, 0]])\n\nkernel = np.array([[-1, -1, -1], \n                   [-1, 8, -1], \n                   [-1, -1, -1]])\n#filtro de Sobel X\nkernel = np.array([[-1, 0, 1], \n                   [-2, 0, 2], \n                   [-1, 0, 1]])\nkernel = np.array([[-1, -2, -1], \n                   [ 0, 0, 0], \n                   [-1, 0, 1]])\n</pre> #Filtro Laplaciano kernel = np.array([[0, -1, 0],                     [-1, 4, -1],                     [0, -1, 0]])  kernel = np.array([[-1, -1, -1],                     [-1, 8, -1],                     [-1, -1, -1]]) #filtro de Sobel X kernel = np.array([[-1, 0, 1],                     [-2, 0, 2],                     [-1, 0, 1]]) kernel = np.array([[-1, -2, -1],                     [ 0, 0, 0],                     [-1, 0, 1]]) In\u00a0[7]: Copied! <pre>import numpy as np\nimport cv2\n\n\n#carrega imagem\nimg = cv2.imread('lena.png')\nplt.imshow(img, cmap=\"Greys_r\", vmin=0, vmax=255); plt.show()\n\n\n\nimgf = cv2.Sobel(img,cv2.CV_64F,1,0,ksize=3)\nimgf2 = cv2.Sobel(img,cv2.CV_64F,0,1,ksize=3)\n\n# Monta o kernel filtro \n#kernel = np.array([[-1, -1, -1], \n#                   [-1, 8, -1], \n#                   [-1, -1, -1]])\n# Realiza o produto de convolu\u00e7\u00e3o\n#imgf = cv2.filter2D(img,-1,kernel)\n\n#exibe resultado filtrado\nplt.imshow(imgf, cmap=\"Greys_r\", vmin=0, vmax=255);plt.show()\nplt.imshow(imgf2, cmap=\"Greys_r\", vmin=0, vmax=255); plt.show()\n</pre> import numpy as np import cv2   #carrega imagem img = cv2.imread('lena.png') plt.imshow(img, cmap=\"Greys_r\", vmin=0, vmax=255); plt.show()    imgf = cv2.Sobel(img,cv2.CV_64F,1,0,ksize=3) imgf2 = cv2.Sobel(img,cv2.CV_64F,0,1,ksize=3)  # Monta o kernel filtro  #kernel = np.array([[-1, -1, -1],  #                   [-1, 8, -1],  #                   [-1, -1, -1]]) # Realiza o produto de convolu\u00e7\u00e3o #imgf = cv2.filter2D(img,-1,kernel)  #exibe resultado filtrado plt.imshow(imgf, cmap=\"Greys_r\", vmin=0, vmax=255);plt.show() plt.imshow(imgf2, cmap=\"Greys_r\", vmin=0, vmax=255); plt.show() <pre>Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n</pre> <pre>Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n</pre> In\u00a0[10]: Copied! <pre>#implemente seu c\u00f3digo aqui.\n\n# Aqui, a ideia \u00e9 realizar um estudo para entender o efeito de diferentes filtros.\n# Vou aplicar o filtro Sobel e o filtro Laplaciano para diferentes tamanhos de kernel.\n# Vou exibir os resultados para cada tamanho de kernel.\n# Por essa raz\u00e3o, vou criar uma figura com subplots para exibir os resultados e varrer os diferentes tamanhos de kernel utilizando um loop for.\n\n# \u00c9 apenas uma sugest\u00e3o de abordagem, voc\u00ea pode implementar de outra forma se preferir.\n\n\nimport cv2\nimport numpy as np\nfrom matplotlib import pyplot as plt\n\n# Carrega a imagem\nimg = cv2.imread('lena.png', cv2.IMREAD_GRAYSCALE)\n\n# Define os tamanhos de kernel para experimenta\u00e7\u00e3o\nkernels = [3, 13, 21]\n\n# Cria uma figura com subplots\nfig, axs = plt.subplots(len(kernels), 2, figsize=(10, len(kernels) * 5))\n\n# Aplica e exibe os diferentes filtros para cada tamanho de kernel\nfor i, kernel_size in enumerate(kernels):\n    # Filtro Sobel\n    sobel_x = cv2.Sobel(img, cv2.CV_64F, 1, 0, ksize=kernel_size)\n    sobel_y = cv2.Sobel(img, cv2.CV_64F, 0, 1, ksize=kernel_size)\n    sobel = np.sqrt(sobel_x**2 + sobel_y**2) # Sugest\u00e3o, combinar as respostas dos filtros em x e y para obter o m\u00f3dulo do gradiente da imagem, que \u00e9 mais informativo que as respostas individuais dos filtros em x e y \n    axs[i, 0].imshow(sobel, cmap='gray')\n    axs[i, 0].set_title(f'Filtro Sobel - Kernel {kernel_size}x{kernel_size}')\n\n    # Filtro Laplaciano\n    laplacian = cv2.Laplacian(img, cv2.CV_64F, ksize=kernel_size)\n    axs[i, 1].imshow(laplacian, cmap='gray')\n    axs[i, 1].set_title(f'Filtro Laplaciano - Kernel {kernel_size}x{kernel_size}')\n\n# Ajusta o layout e exibe a figura\nplt.tight_layout()\nplt.show()\n</pre> #implemente seu c\u00f3digo aqui.  # Aqui, a ideia \u00e9 realizar um estudo para entender o efeito de diferentes filtros. # Vou aplicar o filtro Sobel e o filtro Laplaciano para diferentes tamanhos de kernel. # Vou exibir os resultados para cada tamanho de kernel. # Por essa raz\u00e3o, vou criar uma figura com subplots para exibir os resultados e varrer os diferentes tamanhos de kernel utilizando um loop for.  # \u00c9 apenas uma sugest\u00e3o de abordagem, voc\u00ea pode implementar de outra forma se preferir.   import cv2 import numpy as np from matplotlib import pyplot as plt  # Carrega a imagem img = cv2.imread('lena.png', cv2.IMREAD_GRAYSCALE)  # Define os tamanhos de kernel para experimenta\u00e7\u00e3o kernels = [3, 13, 21]  # Cria uma figura com subplots fig, axs = plt.subplots(len(kernels), 2, figsize=(10, len(kernels) * 5))  # Aplica e exibe os diferentes filtros para cada tamanho de kernel for i, kernel_size in enumerate(kernels):     # Filtro Sobel     sobel_x = cv2.Sobel(img, cv2.CV_64F, 1, 0, ksize=kernel_size)     sobel_y = cv2.Sobel(img, cv2.CV_64F, 0, 1, ksize=kernel_size)     sobel = np.sqrt(sobel_x**2 + sobel_y**2) # Sugest\u00e3o, combinar as respostas dos filtros em x e y para obter o m\u00f3dulo do gradiente da imagem, que \u00e9 mais informativo que as respostas individuais dos filtros em x e y      axs[i, 0].imshow(sobel, cmap='gray')     axs[i, 0].set_title(f'Filtro Sobel - Kernel {kernel_size}x{kernel_size}')      # Filtro Laplaciano     laplacian = cv2.Laplacian(img, cv2.CV_64F, ksize=kernel_size)     axs[i, 1].imshow(laplacian, cmap='gray')     axs[i, 1].set_title(f'Filtro Laplaciano - Kernel {kernel_size}x{kernel_size}')  # Ajusta o layout e exibe a figura plt.tight_layout() plt.show()  <p>FILTRO DE BORDAS DE CANNY</p> <p>O filtro de canny \u00e9 um detector de linhas e bordas que combina de forma mais sofisticada opera\u00e7\u00f5es lineares.</p> In\u00a0[\u00a0]: Copied! <pre>import numpy as np\nimport cv2\n\n\n#carrega imagem\nimg = cv2.imread('lena.png')\nplt.imshow(img, cmap=\"Greys_r\", vmin=0, vmax=255); plt.show()\n\nmin_contrast = 50\nmax_contrast = 200\n\nimgfb = cv2.GaussianBlur(img,(5,5),0)\nimgf = cv2.Canny(imgfb, min_contrast, max_contrast )\n\nplt.imshow(imgf,cmap=\"Greys_r\", vmin=0, vmax=255); plt.show()\n</pre> import numpy as np import cv2   #carrega imagem img = cv2.imread('lena.png') plt.imshow(img, cmap=\"Greys_r\", vmin=0, vmax=255); plt.show()  min_contrast = 50 max_contrast = 200  imgfb = cv2.GaussianBlur(img,(5,5),0) imgf = cv2.Canny(imgfb, min_contrast, max_contrast )  plt.imshow(imgf,cmap=\"Greys_r\", vmin=0, vmax=255); plt.show() In\u00a0[11]: Copied! <pre>#Seu c\u00f3digo\n\nimport cv2\nimport numpy as np\nfrom matplotlib import pyplot as plt\n\n# Carrega a imagem\nimg = cv2.imread('lena.png', cv2.IMREAD_GRAYSCALE)\n\n# Define os pares de valores de threshold para experimenta\u00e7\u00e3o no detector de bordas de Canny, \n# onde cada par \u00e9 um conjunto de valores para os thresholds m\u00ednimo e m\u00e1ximo\n# A ideia \u00e9 experimentar diferentes valores para os thresholds e observar o efeito no resultado\nthresholds = [(50, 100), (100, 150), (150, 200)]\n\n# Cria uma figura com subplots\nfig, axs = plt.subplots(1, len(thresholds), figsize=(15, 5))\n\n# Aplica e exibe o detector de bordas de Canny para cada par de thresholds\nfor i, (low_threshold, high_threshold) in enumerate(thresholds):\n    # Detector de bordas de Canny\n    edges = cv2.Canny(img, low_threshold, high_threshold)\n    axs[i].imshow(edges, cmap='gray')\n    axs[i].set_title(f'Canny - Thresholds: ({low_threshold}, {high_threshold})')\n\n# Ajusta o layout e exibe a figura\nplt.tight_layout()\nplt.show()\n</pre> #Seu c\u00f3digo  import cv2 import numpy as np from matplotlib import pyplot as plt  # Carrega a imagem img = cv2.imread('lena.png', cv2.IMREAD_GRAYSCALE)  # Define os pares de valores de threshold para experimenta\u00e7\u00e3o no detector de bordas de Canny,  # onde cada par \u00e9 um conjunto de valores para os thresholds m\u00ednimo e m\u00e1ximo # A ideia \u00e9 experimentar diferentes valores para os thresholds e observar o efeito no resultado thresholds = [(50, 100), (100, 150), (150, 200)]  # Cria uma figura com subplots fig, axs = plt.subplots(1, len(thresholds), figsize=(15, 5))  # Aplica e exibe o detector de bordas de Canny para cada par de thresholds for i, (low_threshold, high_threshold) in enumerate(thresholds):     # Detector de bordas de Canny     edges = cv2.Canny(img, low_threshold, high_threshold)     axs[i].imshow(edges, cmap='gray')     axs[i].set_title(f'Canny - Thresholds: ({low_threshold}, {high_threshold})')  # Ajusta o layout e exibe a figura plt.tight_layout() plt.show()  <p>FILTRO DE LIMIARIZA\u00c7\u00c3O</p> <p>O filtro de limiariaza\u00e7\u00e3o \u00e9 converte uma imagem em tons de ciza para uma imagem binaria.</p> <p>Podemos utilizar diversas tecnicas de limiariza\u00e7\u00e3o, cada um com sua particularidade, leia a documenta\u00e7\u00e3o para mais detalhes:</p> <p>cv2.THRESH_BINARY cv2.THRESH_BINARY_INV cv2.THRESH_TRUNC cv2.THRESH_TOZERO cv2.THRESH_TOZERO_INV cv2.THRESH_OTSU</p> In\u00a0[12]: Copied! <pre>import numpy as np\nimport cv2\n\n\n#carrega imagem\nimage = cv2.imread('lena.png')\nimg = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\nplt.imshow(img,cmap=\"Greys_r\", vmin=0, vmax=255); plt.show()\n\n\nret3,th3 = cv2.threshold(img,0,255,cv2.THRESH_OTSU)\n\nplt.imshow(th3,cmap=\"Greys_r\", vmin=0, vmax=255); plt.show()\n</pre> import numpy as np import cv2   #carrega imagem image = cv2.imread('lena.png') img = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY) plt.imshow(img,cmap=\"Greys_r\", vmin=0, vmax=255); plt.show()   ret3,th3 = cv2.threshold(img,0,255,cv2.THRESH_OTSU)  plt.imshow(th3,cmap=\"Greys_r\", vmin=0, vmax=255); plt.show()   <p>FILTRO DE SOBREPOSI\u00c7\u00c3O DE IMAGENS</p> <p>O filtro de sobreposi\u00e7\u00e3o mescla duas imagens gerando efeito de sobreposi\u00e7\u00e3o, ou Blending.</p> <p>A opera\u00e7\u00e3o da imagem de saida \u00e9 a seguinte: g(x)=(1\u2212\u03b1)\u2217f0(x)+\u03b1\u2217f1(x)</p> In\u00a0[\u00a0]: Copied! <pre>import numpy as np\nimport cv2\n\nalpha = 0.8\nbeta = (1.0 - alpha)\n\nsrc1 = cv2.imread(\"lena.png\")\nsrc2 = cv2.imread(\"tux.png\")\nsrc2= cv2.cvtColor(src2, cv2.COLOR_BGR2RGB )\n\nsrc2 = cv2.resize(src2, src1.shape[1::-1])\nprint(src1.shape, src2.shape)\n\n\ndst = cv2.addWeighted(src1, alpha, src2, beta, 0.0)\n\n\nplt.imshow(src1); plt.show()\nplt.imshow(src2); plt.show()\nplt.imshow(dst); plt.show()\n</pre> import numpy as np import cv2  alpha = 0.8 beta = (1.0 - alpha)  src1 = cv2.imread(\"lena.png\") src2 = cv2.imread(\"tux.png\") src2= cv2.cvtColor(src2, cv2.COLOR_BGR2RGB )  src2 = cv2.resize(src2, src1.shape[1::-1]) print(src1.shape, src2.shape)   dst = cv2.addWeighted(src1, alpha, src2, beta, 0.0)   plt.imshow(src1); plt.show() plt.imshow(src2); plt.show() plt.imshow(dst); plt.show() <pre>(512, 512, 3) (512, 512, 3)\n</pre> In\u00a0[13]: Copied! <pre>#Seu c\u00f3digo aqui.\n\n# No desafio 2 do lab, eu sugeri a aplica\u00e7\u00e3o do filtro de sobel com essa jun\u00e7\u00e3o de respostas para obter o m\u00f3dulo do gradiente da imagem.\n# Vou aplicar o filtro de sobel e exibir o resultado para a imagem lena.png.\n\nimport cv2\nimport numpy as np\nfrom matplotlib import pyplot as plt\n\n# Carrega a imagem\nimg = cv2.imread('lena.png', cv2.IMREAD_GRAYSCALE)\n\n# Filtro Sobel\nsobel_x = cv2.Sobel(img, cv2.CV_64F, 1, 0, ksize=3)\nsobel_y = cv2.Sobel(img, cv2.CV_64F, 0, 1, ksize=3)\nsobel = np.sqrt(sobel_x**2 + sobel_y**2)\n\n# Exibe o resultado\nplt.imshow(sobel, cmap='gray')\nplt.title('Filtro Sobel - M\u00f3dulo do Gradiente')\nplt.show()\n</pre> #Seu c\u00f3digo aqui.  # No desafio 2 do lab, eu sugeri a aplica\u00e7\u00e3o do filtro de sobel com essa jun\u00e7\u00e3o de respostas para obter o m\u00f3dulo do gradiente da imagem. # Vou aplicar o filtro de sobel e exibir o resultado para a imagem lena.png.  import cv2 import numpy as np from matplotlib import pyplot as plt  # Carrega a imagem img = cv2.imread('lena.png', cv2.IMREAD_GRAYSCALE)  # Filtro Sobel sobel_x = cv2.Sobel(img, cv2.CV_64F, 1, 0, ksize=3) sobel_y = cv2.Sobel(img, cv2.CV_64F, 0, 1, ksize=3) sobel = np.sqrt(sobel_x**2 + sobel_y**2)  # Exibe o resultado plt.imshow(sobel, cmap='gray') plt.title('Filtro Sobel - M\u00f3dulo do Gradiente') plt.show()"},{"location":"aulas/PDI/lab04/sol_Filtros_de_Convolu%C3%A7%C3%A3o.html#desafio-0","title":"Desafio 0\u00b6","text":"<p>Abra o link https://setosa.io/ev/image-kernels/ e de forma intuitiva altere o valor do filtro/kernel e descubra efeitos resultantes.</p>"},{"location":"aulas/PDI/lab04/sol_Filtros_de_Convolu%C3%A7%C3%A3o.html#implementacao-na-opencv","title":"Implementa\u00e7\u00e3o na OpenCV\u00b6","text":"<p>Podemos implementar o produto de convolu\u00e7\u00e3o montando uma estrutura com dois for para varrer a imagem toda, pixel-a-pixel.N\u00e3o \u00e9 a forma mais eficiente, pois Na OpenCV tem uma fun\u00e7\u00e3o built-in para implementa\u00e7\u00e3o de filtro de convolu\u00e7\u00e3o a cv2.filter2D()</p>"},{"location":"aulas/PDI/lab04/sol_Filtros_de_Convolu%C3%A7%C3%A3o.html#desafio-1","title":"Desafio 1\u00b6","text":"<p>Escolha uma imagem da sua prefer\u00eancia e fa\u00e7a um estudo sobre os diferentes tipos de filtros de borramento, analise tamb\u00e9m o que acontece quando \u00e9 alterado o tamanho do kernel.</p>"},{"location":"aulas/PDI/lab04/sol_Filtros_de_Convolu%C3%A7%C3%A3o.html#desafio-2","title":"Desafio 2\u00b6","text":"<p>Escolha uma imagem da sua prefer\u00eancia e fa\u00e7a um estudo sobre os diferentes tipos de filtros de contraste, analise tamb\u00e9m o que acontece quando \u00e9 alterado o tamanho do kernel.</p>"},{"location":"aulas/PDI/lab04/sol_Filtros_de_Convolu%C3%A7%C3%A3o.html#desafio-3","title":"Desafio 3\u00b6","text":"<p>O Filtro de Canny \u00e9 um dos mais utilizados at\u00e9 hoje, por ser robusto e apresentar bons resultados. Implemente o detector de bordas de canny e analise os efeitos alterandos os valores de threshold.</p>"},{"location":"aulas/PDI/lab04/sol_Filtros_de_Convolu%C3%A7%C3%A3o.html#desafio-4","title":"Desafio 4\u00b6","text":"<p>O filtro de sobel calcula a primeira derivada, isso pode ser feito na dire\u00e7\u00e3o de X ou em Y. Fa\u00e7a uma implementa\u00e7\u00e3o que junta os efeitos das duas derivadas de sobel</p>"},{"location":"aulas/PDI/lab04/webcam.html","title":"Webcam","text":"In\u00a0[\u00a0]: Copied! <p>Programa simples com camera webcam e opencv</p> In\u00a0[\u00a0]: Copied! <pre>import cv2\nimport os,sys, os.path\nimport numpy as np\n</pre> import cv2 import os,sys, os.path import numpy as np In\u00a0[\u00a0]: Copied! <pre>def image_da_webcam(img):\n    \"\"\"\n    -&gt;&gt;&gt; !!!! FECHE A JANELA COM A TECLA ESC !!!! &lt;&lt;&lt;&lt;-\n        deve receber a imagem da camera e retornar uma imagems filtrada.\n    \"\"\"\n    img = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n     # Detect edges in the image and threshold it\n    edges = cv2.Laplacian(img, cv2.CV_8U, ksize=5)\n    \n    ret, mask = cv2.threshold(edges, 100, 255, cv2.THRESH_BINARY_INV)\n\n    return mask\n</pre> def image_da_webcam(img):     \"\"\"     -&gt;&gt;&gt; !!!! FECHE A JANELA COM A TECLA ESC !!!! &lt;&lt;&lt;&lt;-         deve receber a imagem da camera e retornar uma imagems filtrada.     \"\"\"     img = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)      # Detect edges in the image and threshold it     edges = cv2.Laplacian(img, cv2.CV_8U, ksize=5)          ret, mask = cv2.threshold(edges, 100, 255, cv2.THRESH_BINARY_INV)      return mask In\u00a0[\u00a0]: Copied! <pre>vc = cv2.VideoCapture(0) ### significa que vou usar a minha webcam, 1,2,3\n</pre> vc = cv2.VideoCapture(0) ### significa que vou usar a minha webcam, 1,2,3 <p>vc = cv2.VideoCapture(\"people-walking.mp4\") ### suport video mp4. .avi  .mkv</p> <p>vc = cv2.VideoCapture(\"rtsp://192.168.52.25:800\") ### significa que vou usar a minha webcam, 1,2,3</p> In\u00a0[\u00a0]: Copied! <pre>if vc.isOpened(): # try to get the first frame\n    rval, frame = vc.read()\nelse:\n    rval = False\n</pre> if vc.isOpened(): # try to get the first frame     rval, frame = vc.read() else:     rval = False In\u00a0[\u00a0]: Copied! <pre>while rval:\n    \n    img = image_da_webcam(frame)\n\n    cv2.imshow(\"preview\", img)\n    cv2.imshow(\"original\", frame)\n\n    rval, frame = vc.read()\n    key = cv2.waitKey(20)\n    if key == 27: # exit on ESC\n        break\n</pre> while rval:          img = image_da_webcam(frame)      cv2.imshow(\"preview\", img)     cv2.imshow(\"original\", frame)      rval, frame = vc.read()     key = cv2.waitKey(20)     if key == 27: # exit on ESC         break In\u00a0[\u00a0]: Copied! <pre>cv2.destroyWindow(\"preview\")\nvc.release()\n</pre> cv2.destroyWindow(\"preview\") vc.release()"},{"location":"aulas/PDI/lab05/Espa%C3%A7o-cor-contorno.html","title":"Lab05 - Espa\u00e7o de cor e contorno","text":"<p>Objetivos da aula:</p> <ul> <li>Conhecer o espa\u00e7o de cor HSV</li> <li>Conhecer o processo de mascara</li> <li>conhecer o processo de detec\u00e7\u00e3o de contornos</li> <li>conhecer o processo de calculo do centro de massa</li> <li>conhecer o processo para desenar e escrever na imagem</li> </ul> In\u00a0[1]: Copied! <pre>## Vou fazer o download das imagens do laborat\u00f3rio diretamente do reposit\u00f3rio para ficar mais facil....\n\nimport requests\nimport os\n\n# Define o laborat\u00f3rio\nlaboratorio = 'lab05'  ### altere para o laborat\u00f3rio desejado\ndiretorio = 'lab_images'  ### altere para o diret\u00f3rio que deseja salvar as imagens\n\n# Download de um arquivo\ndef download_file(url, destination):\n    response = requests.get(url, stream=True)\n    if response.status_code == 200:\n        with open(destination, 'wb') as file:\n            for chunk in response.iter_content(chunk_size=8192):\n                file.write(chunk)\n        print(f\"Baixado: {destination}\")\n    else:\n        print(f\"Erro ao baixar {url}\")\n\n# Monta a URL completa\napi_url = \"https://api.github.com/repos/arnaldojr/cognitivecomputing/contents/material/aulas/PDI/\"\nurl_completa = api_url + laboratorio\nprint(f\"Fazendo o download de: {url_completa}\")\n\n# checa se a URL est\u00e1 acess\u00edvel\nresponse = requests.get(url_completa)\nif response.status_code != 200:\n    raise Exception(f\"Erro ao acessar o reposit\u00f3rio: {response.status_code}\")\nfiles = response.json()\n\n\n# Faz o download de cada arquivo\nos.makedirs(diretorio, exist_ok=True) # Cria a pasta downloads\nfor file in files:\n    file_name = file['name']\n    if file_name.endswith(('.png', '.jpg', '.jpeg', '.mp4')):  # Adicione mais extens\u00f5es se necess\u00e1rio\n        file_url = file['download_url']\n        destination = os.path.join(diretorio, file_name)\n        download_file(file_url, destination)\n\nprint(f\"Download conclu\u00eddo. Arquivos salvos na pasta {diretorio}.\")\n</pre> ## Vou fazer o download das imagens do laborat\u00f3rio diretamente do reposit\u00f3rio para ficar mais facil....  import requests import os  # Define o laborat\u00f3rio laboratorio = 'lab05'  ### altere para o laborat\u00f3rio desejado diretorio = 'lab_images'  ### altere para o diret\u00f3rio que deseja salvar as imagens  # Download de um arquivo def download_file(url, destination):     response = requests.get(url, stream=True)     if response.status_code == 200:         with open(destination, 'wb') as file:             for chunk in response.iter_content(chunk_size=8192):                 file.write(chunk)         print(f\"Baixado: {destination}\")     else:         print(f\"Erro ao baixar {url}\")  # Monta a URL completa api_url = \"https://api.github.com/repos/arnaldojr/cognitivecomputing/contents/material/aulas/PDI/\" url_completa = api_url + laboratorio print(f\"Fazendo o download de: {url_completa}\")  # checa se a URL est\u00e1 acess\u00edvel response = requests.get(url_completa) if response.status_code != 200:     raise Exception(f\"Erro ao acessar o reposit\u00f3rio: {response.status_code}\") files = response.json()   # Faz o download de cada arquivo os.makedirs(diretorio, exist_ok=True) # Cria a pasta downloads for file in files:     file_name = file['name']     if file_name.endswith(('.png', '.jpg', '.jpeg', '.mp4')):  # Adicione mais extens\u00f5es se necess\u00e1rio         file_url = file['download_url']         destination = os.path.join(diretorio, file_name)         download_file(file_url, destination)  print(f\"Download conclu\u00eddo. Arquivos salvos na pasta {diretorio}.\") <pre>Fazendo o download de: https://api.github.com/repos/arnaldojr/cognitivecomputing/contents/material/aulas/PDI/lab05\nBaixado: lab_images/HSV_colorspace.jpg\nBaixado: lab_images/bolinha.png\nBaixado: lab_images/convolution.png\nBaixado: lab_images/formas.png\nBaixado: lab_images/formas_contorno.png\nBaixado: lab_images/formas_contornor.png\nBaixado: lab_images/hsv_colorspace.png\nBaixado: lab_images/lena.png\nBaixado: lab_images/melancia.png\nBaixado: lab_images/melancia_filtrada.png\nBaixado: lab_images/melancia_filtrada_rgb.png\nBaixado: lab_images/saida.png\nBaixado: lab_images/segmenta_melancia.mp4\nBaixado: lab_images/sudoku.png\nBaixado: lab_images/tux.png\nDownload conclu\u00eddo. Arquivos salvos na pasta lab_images.\n</pre> In\u00a0[\u00a0]: Copied! <pre>%matplotlib inline\nimport cv2\nfrom matplotlib import pyplot as plt\nimport numpy as np\n\nimg = cv2.imread('hsv_colorspace.png')\nimg = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n\nplt.figure(figsize = (20,20))\nplt.imshow(img); plt.show()\n</pre> %matplotlib inline import cv2 from matplotlib import pyplot as plt import numpy as np  img = cv2.imread('hsv_colorspace.png') img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)  plt.figure(figsize = (20,20)) plt.imshow(img); plt.show() <p>A matiz descreve o pigmento de uma cor e \u00e9 medido em graus de 0 a 359 graus.</p> <p>A satura\u00e7\u00e3o descreve a vivacidade ou o esmaecimento de uma cor e \u00e9 medida em porcentagem de 0 a 100 (0 = cor \"diluida\" 100 = cor pura).</p> <p>O brilho determina a intensidade percebida (0 = preto 100 = brilho maximo);</p> <p>Dica: Pra entender bem o que \u00e9 cada componente, da uma olhada neste link ou digita no google \"colorpicker\"</p> <p>lembrete super importante!! a OpenCV trabalha com valores de 8bits (0-255), ou seja o valor da matriz tem que ser divido por 2</p> <p>Convers\u00e3o para HSV</p> <p>Na OpenCV a convers\u00e3o de BGR para RGB \u00e9 muito simples, podemos converter diretamete da imagem em BGR usando o cv2.COLOR_BGR2HSV.</p> In\u00a0[\u00a0]: Copied! <pre>img = cv2.imread('bolinha.png')\n\nimg_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\nimg_hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n\nplt.subplot(1, 2, 1)\nplt.imshow(img_rgb)\nplt.subplot(1, 2, 2)\nplt.imshow(img_hsv)\nplt.show()\n</pre> img = cv2.imread('bolinha.png')  img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB) img_hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)  plt.subplot(1, 2, 1) plt.imshow(img_rgb) plt.subplot(1, 2, 2) plt.imshow(img_hsv) plt.show() <p>mascara de cor</p> <p>Para realizar uma marcara de cor, nos usamos a fun\u00e7\u00e3o cv2.inrange para escolher o intervalo de cor ( o valor minimo e o valor maximo).</p> In\u00a0[\u00a0]: Copied! <pre>%matplotlib inline\nimport cv2\nfrom matplotlib import pyplot as plt\nimport numpy as np\n\nimg = cv2.imread('bolinha.png')\n\nimg_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\nimg_hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n\n\n# Defini\u00e7\u00e3o dos valores minimo e max da mascara\n# o magenta tem h=300 mais ou menos ou 150 para a OpenCV\nimage_lower_hsv = np.array([140, 100, 40])  \nimage_upper_hsv = np.array([175, 255, 255])\n\n\nmask_hsv = cv2.inRange(img_hsv, image_lower_hsv, image_upper_hsv)\n\n\n\nplt.subplot(1, 2, 1)\nplt.imshow(img_rgb)\nplt.subplot(1, 2, 2)\nplt.imshow(mask_hsv, cmap=\"Greys_r\", vmin=0, vmax=255)\nplt.show()\n</pre> %matplotlib inline import cv2 from matplotlib import pyplot as plt import numpy as np  img = cv2.imread('bolinha.png')  img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB) img_hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)   # Defini\u00e7\u00e3o dos valores minimo e max da mascara # o magenta tem h=300 mais ou menos ou 150 para a OpenCV image_lower_hsv = np.array([140, 100, 40])   image_upper_hsv = np.array([175, 255, 255])   mask_hsv = cv2.inRange(img_hsv, image_lower_hsv, image_upper_hsv)    plt.subplot(1, 2, 1) plt.imshow(img_rgb) plt.subplot(1, 2, 2) plt.imshow(mask_hsv, cmap=\"Greys_r\", vmin=0, vmax=255) plt.show()   In\u00a0[\u00a0]: Copied! <pre>%matplotlib inline\nimport cv2\nfrom matplotlib import pyplot as plt\nimport numpy as np\n\nimg = cv2.imread('melancia.png')\nimg_res = cv2.imread('melancia_filtrada.png')\n\nimg_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\nimg_res_rgb = cv2.cvtColor(img_res, cv2.COLOR_BGR2RGB)\n\nfig = plt.figure(figsize=(20,20))\nplt.subplot(1, 2, 1)\nplt.imshow(img_rgb)\nplt.subplot(1, 2, 2)\nplt.imshow(img_res_rgb)\nplt.show()\n</pre> %matplotlib inline import cv2 from matplotlib import pyplot as plt import numpy as np  img = cv2.imread('melancia.png') img_res = cv2.imread('melancia_filtrada.png')  img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB) img_res_rgb = cv2.cvtColor(img_res, cv2.COLOR_BGR2RGB)  fig = plt.figure(figsize=(20,20)) plt.subplot(1, 2, 1) plt.imshow(img_rgb) plt.subplot(1, 2, 2) plt.imshow(img_res_rgb) plt.show()  In\u00a0[\u00a0]: Copied! <pre>#Implemente seu c\u00f3digo\n</pre> #Implemente seu c\u00f3digo      In\u00a0[\u00a0]: Copied! <pre>%matplotlib inline\nimport cv2\nfrom matplotlib import pyplot as plt\nimport numpy as np\n\nimg = cv2.imread('melancia_filtrada.png')\nimg_res = cv2.imread('melancia_filtrada_rgb.png')\n\nimg_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\nimg_res_rgb = cv2.cvtColor(img_res, cv2.COLOR_BGR2RGB)\n\nfig = plt.figure(figsize=(20,20))\nplt.subplot(1, 2, 1)\nplt.imshow(img_rgb)\nplt.subplot(1, 2, 2)\nplt.imshow(img_res_rgb)\nplt.show()\n</pre> %matplotlib inline import cv2 from matplotlib import pyplot as plt import numpy as np  img = cv2.imread('melancia_filtrada.png') img_res = cv2.imread('melancia_filtrada_rgb.png')  img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB) img_res_rgb = cv2.cvtColor(img_res, cv2.COLOR_BGR2RGB)  fig = plt.figure(figsize=(20,20)) plt.subplot(1, 2, 1) plt.imshow(img_rgb) plt.subplot(1, 2, 2) plt.imshow(img_res_rgb) plt.show() In\u00a0[\u00a0]: Copied! <pre>#Implemente seu c\u00f3digo\n</pre> #Implemente seu c\u00f3digo      In\u00a0[\u00a0]: Copied! <pre>#recarregando o nosso exemplo...\n\n%matplotlib inline\nimport cv2\nfrom matplotlib import pyplot as plt\nimport numpy as np\n\nimg = cv2.imread('bolinha.png')\n\nimg_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\nimg_hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n\n\n# Defini\u00e7\u00e3o dos valores minimo e max da mascara\n# o magenta tem h=300 mais ou menos ou 150 para a OpenCV\nimage_lower_hsv = np.array([140, 50, 100])  \nimage_upper_hsv = np.array([170, 255, 255])\n\n\nmask_hsv = cv2.inRange(img_hsv, image_lower_hsv, image_upper_hsv)\n\n\n\nplt.subplot(1, 2, 1)\nplt.imshow(img_rgb)\nplt.subplot(1, 2, 2)\nplt.imshow(mask_hsv, cmap=\"Greys_r\", vmin=0, vmax=255)\nplt.show()\n</pre> #recarregando o nosso exemplo...  %matplotlib inline import cv2 from matplotlib import pyplot as plt import numpy as np  img = cv2.imread('bolinha.png')  img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB) img_hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)   # Defini\u00e7\u00e3o dos valores minimo e max da mascara # o magenta tem h=300 mais ou menos ou 150 para a OpenCV image_lower_hsv = np.array([140, 50, 100])   image_upper_hsv = np.array([170, 255, 255])   mask_hsv = cv2.inRange(img_hsv, image_lower_hsv, image_upper_hsv)    plt.subplot(1, 2, 1) plt.imshow(img_rgb) plt.subplot(1, 2, 2) plt.imshow(mask_hsv, cmap=\"Greys_r\", vmin=0, vmax=255) plt.show()  In\u00a0[\u00a0]: Copied! <pre># realizando o contorno da imagem\n\ncontornos, _ = cv2.findContours(mask_hsv, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE) \n</pre> # realizando o contorno da imagem  contornos, _ = cv2.findContours(mask_hsv, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)   In\u00a0[\u00a0]: Copied! <pre># para desenhar o contorno primeiro faz uma copia da imagem \n\nmask_rgb = cv2.cvtColor(mask_hsv, cv2.COLOR_GRAY2RGB) \ncontornos_img = mask_rgb.copy() # C\u00f3pia da m\u00e1scara para ser desenhada \"por cima\"\n\ncv2.drawContours(contornos_img, contornos, -1, [255, 0, 0], 5);\n\nplt.figure(figsize=(8,6))\nplt.imshow(contornos_img);\n</pre> # para desenhar o contorno primeiro faz uma copia da imagem   mask_rgb = cv2.cvtColor(mask_hsv, cv2.COLOR_GRAY2RGB)  contornos_img = mask_rgb.copy() # C\u00f3pia da m\u00e1scara para ser desenhada \"por cima\"  cv2.drawContours(contornos_img, contornos, -1, [255, 0, 0], 5);  plt.figure(figsize=(8,6)) plt.imshow(contornos_img); In\u00a0[\u00a0]: Copied! <pre># para desenhar o contorno primeiro faz uma copia da imagem \n\nmask_rgb = cv2.cvtColor(mask_hsv, cv2.COLOR_GRAY2RGB) \ncontornos_img = mask_rgb.copy() # C\u00f3pia da m\u00e1scara para ser desenhada \"por cima\"\n\ncv2.drawContours(img_rgb, contornos, -1, [0, 0, 255], 10);\n\nplt.figure(figsize=(8,6))\nplt.imshow(img_rgb);\n</pre> # para desenhar o contorno primeiro faz uma copia da imagem   mask_rgb = cv2.cvtColor(mask_hsv, cv2.COLOR_GRAY2RGB)  contornos_img = mask_rgb.copy() # C\u00f3pia da m\u00e1scara para ser desenhada \"por cima\"  cv2.drawContours(img_rgb, contornos, -1, [0, 0, 255], 10);  plt.figure(figsize=(8,6)) plt.imshow(img_rgb); <p>Note que a fun\u00e7\u00e3o findContours devolve uma lista com os contornos detectados.</p> In\u00a0[\u00a0]: Copied! <pre>print(\"Quantidade de contornos encontrado: \", len(contornos))\n</pre> print(\"Quantidade de contornos encontrado: \", len(contornos)) <pre>Quantidade de contornos encontrado:  1\n</pre> In\u00a0[\u00a0]: Copied! <pre>%matplotlib inline\nimport cv2\nfrom matplotlib import pyplot as plt\nimport numpy as np\n\nimg = cv2.imread('formas.png')\nimg_res = cv2.imread('formas_contorno.png')\n\nimg_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\nimg_res_rgb = cv2.cvtColor(img_res, cv2.COLOR_BGR2RGB)\n\n\n# Defini\u00e7\u00e3o dos valores minimo e max da mascara\n\nimage_lower_hsv = np.array([0, 1, 0])  \nimage_upper_hsv = np.array([180, 255, 255])\n\nfig = plt.figure(figsize=(20,20))\nplt.subplot(1, 2, 1)\nplt.imshow(img_rgb)\nplt.subplot(1, 2, 2)\nplt.imshow(img_res_rgb)\nplt.show()\n</pre>  %matplotlib inline import cv2 from matplotlib import pyplot as plt import numpy as np  img = cv2.imread('formas.png') img_res = cv2.imread('formas_contorno.png')  img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB) img_res_rgb = cv2.cvtColor(img_res, cv2.COLOR_BGR2RGB)   # Defini\u00e7\u00e3o dos valores minimo e max da mascara  image_lower_hsv = np.array([0, 1, 0])   image_upper_hsv = np.array([180, 255, 255])  fig = plt.figure(figsize=(20,20)) plt.subplot(1, 2, 1) plt.imshow(img_rgb) plt.subplot(1, 2, 2) plt.imshow(img_res_rgb) plt.show() In\u00a0[\u00a0]: Copied! <pre>#Implemente seu c\u00f3digo\n</pre> #Implemente seu c\u00f3digo     In\u00a0[\u00a0]: Copied! <pre>## Implemente seu c\u00f3digo\n</pre> ## Implemente seu c\u00f3digo     In\u00a0[\u00a0]: Copied! <pre>cv2.__version__\n</pre> cv2.__version__ Out[\u00a0]: <pre>'4.5.5'</pre> In\u00a0[\u00a0]: Copied! <pre>#recarregando o nosso exemplo...\n\n%matplotlib inline\nimport cv2\nfrom matplotlib import pyplot as plt\nimport numpy as np\n\nimg = cv2.imread('bolinha.png')\n\nimg_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\nimg_hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n\n\n# Defini\u00e7\u00e3o dos valores minimo e max da mascara\n# o magenta tem h=300 mais ou menos ou 150 para a OpenCV\nimage_lower_hsv = np.array([140, 50, 100])  \nimage_upper_hsv = np.array([170, 255, 255])\n\n\nmask_hsv = cv2.inRange(img_hsv, image_lower_hsv, image_upper_hsv)\n\ncontornos, _ = cv2.findContours(mask_hsv, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE) \n\nmask_rgb = cv2.cvtColor(mask_hsv, cv2.COLOR_GRAY2RGB) \ncontornos_img = mask_rgb.copy() # C\u00f3pia da m\u00e1scara para ser desenhada \"por cima\"\n\ncv2.drawContours(contornos_img, contornos, -1, [255, 0, 0], 5);\n\nplt.figure(figsize=(8,6))\nplt.imshow(contornos_img);\n</pre> #recarregando o nosso exemplo...  %matplotlib inline import cv2 from matplotlib import pyplot as plt import numpy as np  img = cv2.imread('bolinha.png')  img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB) img_hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)   # Defini\u00e7\u00e3o dos valores minimo e max da mascara # o magenta tem h=300 mais ou menos ou 150 para a OpenCV image_lower_hsv = np.array([140, 50, 100])   image_upper_hsv = np.array([170, 255, 255])   mask_hsv = cv2.inRange(img_hsv, image_lower_hsv, image_upper_hsv)  contornos, _ = cv2.findContours(mask_hsv, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)   mask_rgb = cv2.cvtColor(mask_hsv, cv2.COLOR_GRAY2RGB)  contornos_img = mask_rgb.copy() # C\u00f3pia da m\u00e1scara para ser desenhada \"por cima\"  cv2.drawContours(contornos_img, contornos, -1, [255, 0, 0], 5);  plt.figure(figsize=(8,6)) plt.imshow(contornos_img); In\u00a0[\u00a0]: Copied! <pre># usando o exemplo da documenta\u00e7\u00e3o https://docs.opencv.org/master/dd/d49/tutorial_py_contour_features.html\n# notamos que a fun\u00e7\u00e3o devolve um dicionario. \n\ncnt = contornos[0]\n\nM = cv2.moments(cnt)\nprint( M )\n</pre> # usando o exemplo da documenta\u00e7\u00e3o https://docs.opencv.org/master/dd/d49/tutorial_py_contour_features.html # notamos que a fun\u00e7\u00e3o devolve um dicionario.   cnt = contornos[0]  M = cv2.moments(cnt) print( M ) <pre>{'m00': 20954.5, 'm10': 8414785.5, 'm01': 4813317.5, 'm20': 3414210172.083333, 'm11': 1932427931.625, 'm02': 1140509199.0833333, 'm30': 1399201096317.6501, 'm21': 783868070420.7833, 'm12': 457787216119.7167, 'm03': 278003040454.85004, 'mu20': 35049847.99971104, 'mu11': -475946.1051416397, 'mu02': 34874354.26211333, 'mu30': -7672941.9208984375, 'mu21': -4968840.380795479, 'mu12': 6858123.621509552, 'mu03': 2822544.575317383, 'nu20': 0.07982364109512664, 'nu11': -0.0010839348312655414, 'nu02': 0.07942396606302501, 'nu30': -0.00012071706132489804, 'nu21': -7.817390189392743e-05, 'nu12': 0.00010789766667418762, 'nu03': 4.4406603113053444e-05}\n</pre> In\u00a0[\u00a0]: Copied! <pre># Calculo das coordenadas do centro de massa\n\ncx = int(M['m10']/M['m00'])\ncy = int(M['m01']/M['m00'])\n\nprint(\"centro de massa na possi\u00e7\u00e3o: \",cx, cy)\n</pre> # Calculo das coordenadas do centro de massa  cx = int(M['m10']/M['m00']) cy = int(M['m01']/M['m00'])  print(\"centro de massa na possi\u00e7\u00e3o: \",cx, cy) <pre>centro de massa na possi\u00e7\u00e3o:  401 229\n</pre> <p>Vamos plotar isso na imagem para saber se esta correto. A fun\u00e7\u00e3o \"cv2.line\" vai nos ajudar a desenhar uma cruz. e fun\u00e7\u00e3o \"cv2.putText\" a escrever na imagem as coordenadas.</p> In\u00a0[\u00a0]: Copied! <pre>## para desenhar a cruz vamos passar a cor e o tamanho em pixel\nsize = 20\ncolor = (128,128,0)\n\n\ncv2.line(contornos_img,(cx - size,cy),(cx + size,cy),color,5)\ncv2.line(contornos_img,(cx,cy - size),(cx, cy + size),color,5)\n\n# Para escrever vamos definir uma fonte \n\nfont = cv2.FONT_HERSHEY_SIMPLEX\ntext = cy , cx\norigem = (0,50)\n\ncv2.putText(contornos_img, str(text), origem, font,1,(200,50,0),2,cv2.LINE_AA)\n\n\nplt.imshow(contornos_img);\n</pre> ## para desenhar a cruz vamos passar a cor e o tamanho em pixel size = 20 color = (128,128,0)   cv2.line(contornos_img,(cx - size,cy),(cx + size,cy),color,5) cv2.line(contornos_img,(cx,cy - size),(cx, cy + size),color,5)  # Para escrever vamos definir uma fonte   font = cv2.FONT_HERSHEY_SIMPLEX text = cy , cx origem = (0,50)  cv2.putText(contornos_img, str(text), origem, font,1,(200,50,0),2,cv2.LINE_AA)   plt.imshow(contornos_img); In\u00a0[\u00a0]: Copied! <pre>#### seu c\u00f3digo aqui...\n</pre> #### seu c\u00f3digo aqui... In\u00a0[\u00a0]: Copied! <pre>\n</pre>"},{"location":"aulas/PDI/lab05/Espa%C3%A7o-cor-contorno.html#espaco-de-cor-hsv","title":"Espa\u00e7o de cor HSV\u00b6","text":"<p>At\u00e9 o momento trabalhamos com imagens em escala de cinza, BGR, RGB e binaria. Agora vamos conhecer e trabalhar com HSV ou HSB.</p> <pre><code>H - hue (matriz)\nS - saturation (satura\u00e7\u00e3o)\nV - value (Value) ou B - brightness (brilho)</code></pre> <p>Utilizar esse espa\u00e7o possui algumas vantagens vamos ver no exemplo abaixo.</p>"},{"location":"aulas/PDI/lab05/Espa%C3%A7o-cor-contorno.html#desafio-1","title":"DESAFIO 1\u00b6","text":"<p>Fa\u00e7a a segmenta\u00e7\u00e3o da meia lua da imagem \"melancia.png\". O seu resultado deve ser proximo/parecido com a imagem \"melancia_filtrada.png\".</p> <p>Dica: talvez voc\u00ea precise usar mais que uma faixa de valores, se necess\u00e1rio use a fun\u00e7\u00e3o \"cv2.bitwise_or\" para juntar as partes.</p>"},{"location":"aulas/PDI/lab05/Espa%C3%A7o-cor-contorno.html#desafio-2","title":"DESAFIO 2\u00b6","text":"<p>Usando a imagem \"melancia_filtrada.png\", devolva a cor original que era antes da filtragem.</p> <p>Dica: Use as fun\u00e7\u00f5es de \"cv2.bitwise_and\" para juntar.</p>"},{"location":"aulas/PDI/lab05/Espa%C3%A7o-cor-contorno.html#deteccao-de-contornos","title":"DETEC\u00c7\u00c3O DE CONTORNOS\u00b6","text":"<p>Para realizar a detec\u00e7\u00e3o dos contornos, ou bordas de um objeto, usamos a fun\u00e7\u00e3o cv2.findontours</p>"},{"location":"aulas/PDI/lab05/Espa%C3%A7o-cor-contorno.html#desafio-3","title":"DESAFIO 3\u00b6","text":"<p>Usando a imagem \"formas.png\", fa\u00e7a um c\u00f3digo que detecta todos os contornos da imagem. O resultado deve ser parecido com \"formas_contorno.png\"</p> <p>Dica: Neste desafio, basicamente tem que ajustar a a mascara, o resto n\u00e3o muda.</p>"},{"location":"aulas/PDI/lab05/Espa%C3%A7o-cor-contorno.html#desafio-4","title":"DESAFIO 4\u00b6","text":"<p>Altere o seu codigo para desenhar o contorno de maior area da imagem. Use a fun\u00e7\u00e3o \"cv2.contourArea()\".</p> <p>Refer\u00eancia da documenta\u00e7\u00e3o: https://docs.opencv.org/master/dd/d49/tutorial_py_contour_features.html</p> <p>Dica: Use um for para varrer a lista e armazene o indice do maior valor e passe esse valor para desenhar o contorno.</p>"},{"location":"aulas/PDI/lab05/Espa%C3%A7o-cor-contorno.html#centro-de-massa-de-um-objeto","title":"CENTRO DE MASSA DE UM OBJETO\u00b6","text":"<p>O calculo para o centro de massa \u00e9 feito atr\u00e1ves da fun\u00e7\u00e3o cv2.findontours</p>"},{"location":"aulas/PDI/lab05/Espa%C3%A7o-cor-contorno.html#desafio-5","title":"DESAFIO 5\u00b6","text":"<p>O desafio \u00e9 juntar o que aprendemos em um video, use como base \"webcam.py\". Voc\u00ea deve seguimentar a cor de um objeto, encontrar seu contorno e montar a imagem segmentada com o centro de massa e suas coordenadas. Video de refer\u00eancia \"segmenta_melancia.mp4\"</p>"},{"location":"aulas/PDI/lab05/sol_Espa%C3%A7o-cor-contorno.html","title":"sol Espa\u00e7o cor contorno","text":"<p>Objetivos da aula:</p> <ul> <li>Conhecer o espa\u00e7o de cor HSV</li> <li>Conhecer o processo de mascara</li> <li>conhecer o processo de detec\u00e7\u00e3o de contornos</li> <li>conhecer o processo de calculo do centro de massa</li> <li>conhecer o processo para desenar e escrever na imagem</li> </ul> In\u00a0[\u00a0]: Copied! <pre>!wget https://raw.githubusercontent.com/arnaldojr/cognitivecomputing/master/material/aulas/PDI/lab05/HSV_colorspace.jpg /content \n!wget https://raw.githubusercontent.com/arnaldojr/cognitivecomputing/master/material/aulas/PDI/lab05/bolinha.png /content\n!wget https://raw.githubusercontent.com/arnaldojr/cognitivecomputing/master/material/aulas/PDI/lab05/convolution.png /content\n!wget https://raw.githubusercontent.com/arnaldojr/cognitivecomputing/master/material/aulas/PDI/lab05/formas.png /content\n!wget https://raw.githubusercontent.com/arnaldojr/cognitivecomputing/master/material/aulas/PDI/lab05/formas_contorno.png /content\n!wget https://raw.githubusercontent.com/arnaldojr/cognitivecomputing/master/material/aulas/PDI/lab05/formas_contornor.png /content\n!wget https://raw.githubusercontent.com/arnaldojr/cognitivecomputing/master/material/aulas/PDI/lab05/lena.png /content\n!wget https://raw.githubusercontent.com/arnaldojr/cognitivecomputing/master/material/aulas/PDI/lab05/melancia.png /content\n!wget https://raw.githubusercontent.com/arnaldojr/cognitivecomputing/master/material/aulas/PDI/lab05/melancia_filtrada.png /content\n!wget https://raw.githubusercontent.com/arnaldojr/cognitivecomputing/master/material/aulas/PDI/lab05/HSV_colorspace.jpg /content\n!wget https://raw.githubusercontent.com/arnaldojr/cognitivecomputing/master/material/aulas/PDI/lab05/melancia_filtrada_rgb.png /content\n!wget https://raw.githubusercontent.com/arnaldojr/cognitivecomputing/master/material/aulas/PDI/lab05/same_padding_no_strides.gif /content\n!wget https://raw.githubusercontent.com/arnaldojr/cognitivecomputing/master/material/aulas/PDI/lab05/sudoku.png /content\n!wget https://raw.githubusercontent.com/arnaldojr/cognitivecomputing/master/material/aulas/PDI/lab05/tux.png /content\n</pre> !wget https://raw.githubusercontent.com/arnaldojr/cognitivecomputing/master/material/aulas/PDI/lab05/HSV_colorspace.jpg /content  !wget https://raw.githubusercontent.com/arnaldojr/cognitivecomputing/master/material/aulas/PDI/lab05/bolinha.png /content !wget https://raw.githubusercontent.com/arnaldojr/cognitivecomputing/master/material/aulas/PDI/lab05/convolution.png /content !wget https://raw.githubusercontent.com/arnaldojr/cognitivecomputing/master/material/aulas/PDI/lab05/formas.png /content !wget https://raw.githubusercontent.com/arnaldojr/cognitivecomputing/master/material/aulas/PDI/lab05/formas_contorno.png /content !wget https://raw.githubusercontent.com/arnaldojr/cognitivecomputing/master/material/aulas/PDI/lab05/formas_contornor.png /content !wget https://raw.githubusercontent.com/arnaldojr/cognitivecomputing/master/material/aulas/PDI/lab05/lena.png /content !wget https://raw.githubusercontent.com/arnaldojr/cognitivecomputing/master/material/aulas/PDI/lab05/melancia.png /content !wget https://raw.githubusercontent.com/arnaldojr/cognitivecomputing/master/material/aulas/PDI/lab05/melancia_filtrada.png /content !wget https://raw.githubusercontent.com/arnaldojr/cognitivecomputing/master/material/aulas/PDI/lab05/HSV_colorspace.jpg /content !wget https://raw.githubusercontent.com/arnaldojr/cognitivecomputing/master/material/aulas/PDI/lab05/melancia_filtrada_rgb.png /content !wget https://raw.githubusercontent.com/arnaldojr/cognitivecomputing/master/material/aulas/PDI/lab05/same_padding_no_strides.gif /content !wget https://raw.githubusercontent.com/arnaldojr/cognitivecomputing/master/material/aulas/PDI/lab05/sudoku.png /content !wget https://raw.githubusercontent.com/arnaldojr/cognitivecomputing/master/material/aulas/PDI/lab05/tux.png /content In\u00a0[1]: Copied! <pre>%matplotlib inline\nimport cv2\nfrom matplotlib import pyplot as plt\nimport numpy as np\n\nimg = cv2.imread('hsv_colorspace.png')\nimg = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n\nplt.figure(figsize = (20,20))\nplt.imshow(img); plt.show()\n</pre> %matplotlib inline import cv2 from matplotlib import pyplot as plt import numpy as np  img = cv2.imread('hsv_colorspace.png') img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)  plt.figure(figsize = (20,20)) plt.imshow(img); plt.show() <p>A matiz descreve o pigmento de uma cor e \u00e9 medido em graus de 0 a 359 graus.</p> <p>A satura\u00e7\u00e3o descreve a vivacidade ou o esmaecimento de uma cor e \u00e9 medida em porcentagem de 0 a 100 (0 = cor \"diluida\" 100 = cor pura).</p> <p>O brilho determina a intensidade percebida (0 = preto 100 = brilho maximo);</p> <p>Dica: Pra entender bem o que \u00e9 cada componente, da uma olhada neste link ou digita no google \"colorpicker\"</p> <p>lembrete super importante!! a OpenCV trabalha com valores de 8bits (0-255), ou seja o valor da matriz tem que ser divido por 2</p> <p>Convers\u00e3o para HSV</p> <p>Na OpenCV a convers\u00e3o de BGR para RGB \u00e9 muito simples, podemos converter diretamete da imagem em BGR usando o cv2.COLOR_BGR2HSV.</p> In\u00a0[\u00a0]: Copied! <pre>img = cv2.imread('bolinha.png')\n\nimg_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\nimg_hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n\nplt.subplot(1, 2, 1)\nplt.imshow(img_rgb)\nplt.subplot(1, 2, 2)\nplt.imshow(img_hsv)\nplt.show()\n</pre> img = cv2.imread('bolinha.png')  img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB) img_hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)  plt.subplot(1, 2, 1) plt.imshow(img_rgb) plt.subplot(1, 2, 2) plt.imshow(img_hsv) plt.show() <p>mascara de cor</p> <p>Para realizar uma marcara de cor, nos usamos a fun\u00e7\u00e3o cv2.inrange para escolher o intervalo de cor ( o valor minimo e o valor maximo).</p> In\u00a0[\u00a0]: Copied! <pre>%matplotlib inline\nimport cv2\nfrom matplotlib import pyplot as plt\nimport numpy as np\n\nimg = cv2.imread('bolinha.png')\n\nimg_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\nimg_hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n\n\n# Defini\u00e7\u00e3o dos valores minimo e max da mascara\n# o magenta tem h=300 mais ou menos ou 150 para a OpenCV\nimage_lower_hsv = np.array([140, 100, 40])  \nimage_upper_hsv = np.array([175, 255, 255])\n\n\nmask_hsv = cv2.inRange(img_hsv, image_lower_hsv, image_upper_hsv)\n\n\n\nplt.subplot(1, 2, 1)\nplt.imshow(img_rgb)\nplt.subplot(1, 2, 2)\nplt.imshow(mask_hsv, cmap=\"Greys_r\", vmin=0, vmax=255)\nplt.show()\n</pre> %matplotlib inline import cv2 from matplotlib import pyplot as plt import numpy as np  img = cv2.imread('bolinha.png')  img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB) img_hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)   # Defini\u00e7\u00e3o dos valores minimo e max da mascara # o magenta tem h=300 mais ou menos ou 150 para a OpenCV image_lower_hsv = np.array([140, 100, 40])   image_upper_hsv = np.array([175, 255, 255])   mask_hsv = cv2.inRange(img_hsv, image_lower_hsv, image_upper_hsv)    plt.subplot(1, 2, 1) plt.imshow(img_rgb) plt.subplot(1, 2, 2) plt.imshow(mask_hsv, cmap=\"Greys_r\", vmin=0, vmax=255) plt.show()   In\u00a0[\u00a0]: Copied! <pre>%matplotlib inline\nimport cv2\nfrom matplotlib import pyplot as plt\nimport numpy as np\n\nimg = cv2.imread('melancia.png')\nimg_res = cv2.imread('melancia_filtrada.png')\n\nimg_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\nimg_res_rgb = cv2.cvtColor(img_res, cv2.COLOR_BGR2RGB)\n\nfig = plt.figure(figsize=(20,20))\nplt.subplot(1, 2, 1)\nplt.imshow(img_rgb)\nplt.subplot(1, 2, 2)\nplt.imshow(img_res_rgb)\nplt.show()\n</pre> %matplotlib inline import cv2 from matplotlib import pyplot as plt import numpy as np  img = cv2.imread('melancia.png') img_res = cv2.imread('melancia_filtrada.png')  img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB) img_res_rgb = cv2.cvtColor(img_res, cv2.COLOR_BGR2RGB)  fig = plt.figure(figsize=(20,20)) plt.subplot(1, 2, 1) plt.imshow(img_rgb) plt.subplot(1, 2, 2) plt.imshow(img_res_rgb) plt.show()  In\u00a0[32]: Copied! <pre>#Implemente seu c\u00f3digo\n\n%matplotlib inline\nimport cv2\nfrom matplotlib import pyplot as plt\nimport numpy as np\n\nimg = cv2.imread('melancia.png')\n\nimg_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\nimg_hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n\nprint(img_hsv.shape)\nprint(img_hsv[220,700])\n\n# Defini\u00e7\u00e3o dos valores minimo e max da mascara para a melancia\n# use o color picker para pegar os valores aproximados de h, s e v para a melancia \nmelancia_lower1 = np.array([175, 120, 150])  \nmelancia_upper1 = np.array([180, 255, 255])\nmelancia_lower2 = np.array([0, 140, 160])  \nmelancia_upper2 = np.array([15, 255, 255])\n\n# Cria as m\u00e1scaras para as faixas de vermelho\nmask_1 = cv2.inRange(img_hsv, melancia_lower1, melancia_upper1)\nmask_2 = cv2.inRange(img_hsv, melancia_lower2, melancia_upper2)\n\n# Combina as duas m\u00e1scaras com uma opera\u00e7\u00e3o bitwise_or\nmask_melancia = cv2.bitwise_or(mask_1, mask_2)\n\n\nplt.subplot(2, 2, 1)\nplt.imshow(img_rgb)\nplt.subplot(2, 2, 2)\nplt.imshow(mask_melancia, cmap=\"Greys_r\")\nplt.subplot(2, 2, 3)\nplt.imshow(mask_1, cmap=\"Greys_r\")\nplt.subplot(2, 2, 4)\nplt.imshow(mask_2, cmap=\"Greys_r\")\nplt.show()\n\n# Com um pouco mais de trabalho, podemos melhorar um pouco mais a m\u00e1scara\n# mas ja est\u00e1 bom para o que precisamos, e \u00e9 um bom exemplo de como podemos\n# manipular as m\u00e1scaras para obter o resultado desejado\n</pre> #Implemente seu c\u00f3digo  %matplotlib inline import cv2 from matplotlib import pyplot as plt import numpy as np  img = cv2.imread('melancia.png')  img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB) img_hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)  print(img_hsv.shape) print(img_hsv[220,700])  # Defini\u00e7\u00e3o dos valores minimo e max da mascara para a melancia # use o color picker para pegar os valores aproximados de h, s e v para a melancia  melancia_lower1 = np.array([175, 120, 150])   melancia_upper1 = np.array([180, 255, 255]) melancia_lower2 = np.array([0, 140, 160])   melancia_upper2 = np.array([15, 255, 255])  # Cria as m\u00e1scaras para as faixas de vermelho mask_1 = cv2.inRange(img_hsv, melancia_lower1, melancia_upper1) mask_2 = cv2.inRange(img_hsv, melancia_lower2, melancia_upper2)  # Combina as duas m\u00e1scaras com uma opera\u00e7\u00e3o bitwise_or mask_melancia = cv2.bitwise_or(mask_1, mask_2)   plt.subplot(2, 2, 1) plt.imshow(img_rgb) plt.subplot(2, 2, 2) plt.imshow(mask_melancia, cmap=\"Greys_r\") plt.subplot(2, 2, 3) plt.imshow(mask_1, cmap=\"Greys_r\") plt.subplot(2, 2, 4) plt.imshow(mask_2, cmap=\"Greys_r\") plt.show()  # Com um pouco mais de trabalho, podemos melhorar um pouco mais a m\u00e1scara # mas ja est\u00e1 bom para o que precisamos, e \u00e9 um bom exemplo de como podemos # manipular as m\u00e1scaras para obter o resultado desejado  <pre>(723, 1280, 3)\n[179 172 231]\n</pre> In\u00a0[\u00a0]: Copied! <pre>%matplotlib inline\nimport cv2\nfrom matplotlib import pyplot as plt\nimport numpy as np\n\nimg = cv2.imread('melancia_filtrada.png')\nimg_res = cv2.imread('melancia_filtrada_rgb.png')\n\nimg_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\nimg_res_rgb = cv2.cvtColor(img_res, cv2.COLOR_BGR2RGB)\n\nfig = plt.figure(figsize=(20,20))\nplt.subplot(1, 2, 1)\nplt.imshow(img_rgb)\nplt.subplot(1, 2, 2)\nplt.imshow(img_res_rgb)\nplt.show()\n</pre> %matplotlib inline import cv2 from matplotlib import pyplot as plt import numpy as np  img = cv2.imread('melancia_filtrada.png') img_res = cv2.imread('melancia_filtrada_rgb.png')  img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB) img_res_rgb = cv2.cvtColor(img_res, cv2.COLOR_BGR2RGB)  fig = plt.figure(figsize=(20,20)) plt.subplot(1, 2, 1) plt.imshow(img_rgb) plt.subplot(1, 2, 2) plt.imshow(img_res_rgb) plt.show() In\u00a0[33]: Copied! <pre>#Implemente seu c\u00f3digo\n\n\n# Aplica a m\u00e1scara combinada \u00e0 imagem original\nimg_red = cv2.bitwise_and(img_rgb, img_rgb, mask=mask_melancia)\n\n# Mostra a imagem\nplt.imshow(img_red)\nplt.show()\n</pre> #Implemente seu c\u00f3digo   # Aplica a m\u00e1scara combinada \u00e0 imagem original img_red = cv2.bitwise_and(img_rgb, img_rgb, mask=mask_melancia)  # Mostra a imagem plt.imshow(img_red) plt.show()    In\u00a0[\u00a0]: Copied! <pre>#recarregando o nosso exemplo...\n\n%matplotlib inline\nimport cv2\nfrom matplotlib import pyplot as plt\nimport numpy as np\n\nimg = cv2.imread('bolinha.png')\n\nimg_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\nimg_hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n\n\n# Defini\u00e7\u00e3o dos valores minimo e max da mascara\n# o magenta tem h=300 mais ou menos ou 150 para a OpenCV\nimage_lower_hsv = np.array([140, 50, 100])  \nimage_upper_hsv = np.array([170, 255, 255])\n\n\nmask_hsv = cv2.inRange(img_hsv, image_lower_hsv, image_upper_hsv)\n\n\n\nplt.subplot(1, 2, 1)\nplt.imshow(img_rgb)\nplt.subplot(1, 2, 2)\nplt.imshow(mask_hsv, cmap=\"Greys_r\", vmin=0, vmax=255)\nplt.show()\n</pre> #recarregando o nosso exemplo...  %matplotlib inline import cv2 from matplotlib import pyplot as plt import numpy as np  img = cv2.imread('bolinha.png')  img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB) img_hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)   # Defini\u00e7\u00e3o dos valores minimo e max da mascara # o magenta tem h=300 mais ou menos ou 150 para a OpenCV image_lower_hsv = np.array([140, 50, 100])   image_upper_hsv = np.array([170, 255, 255])   mask_hsv = cv2.inRange(img_hsv, image_lower_hsv, image_upper_hsv)    plt.subplot(1, 2, 1) plt.imshow(img_rgb) plt.subplot(1, 2, 2) plt.imshow(mask_hsv, cmap=\"Greys_r\", vmin=0, vmax=255) plt.show()  In\u00a0[\u00a0]: Copied! <pre># realizando o contorno da imagem\n\ncontornos, _ = cv2.findContours(mask_hsv, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE) \n</pre> # realizando o contorno da imagem  contornos, _ = cv2.findContours(mask_hsv, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)   In\u00a0[\u00a0]: Copied! <pre># para desenhar o contorno primeiro faz uma copia da imagem \n\nmask_rgb = cv2.cvtColor(mask_hsv, cv2.COLOR_GRAY2RGB) \ncontornos_img = mask_rgb.copy() # C\u00f3pia da m\u00e1scara para ser desenhada \"por cima\"\n\ncv2.drawContours(contornos_img, contornos, -1, [255, 0, 0], 5);\n\nplt.figure(figsize=(8,6))\nplt.imshow(contornos_img);\n</pre> # para desenhar o contorno primeiro faz uma copia da imagem   mask_rgb = cv2.cvtColor(mask_hsv, cv2.COLOR_GRAY2RGB)  contornos_img = mask_rgb.copy() # C\u00f3pia da m\u00e1scara para ser desenhada \"por cima\"  cv2.drawContours(contornos_img, contornos, -1, [255, 0, 0], 5);  plt.figure(figsize=(8,6)) plt.imshow(contornos_img); In\u00a0[\u00a0]: Copied! <pre># para desenhar o contorno primeiro faz uma copia da imagem \n\nmask_rgb = cv2.cvtColor(mask_hsv, cv2.COLOR_GRAY2RGB) \ncontornos_img = mask_rgb.copy() # C\u00f3pia da m\u00e1scara para ser desenhada \"por cima\"\n\ncv2.drawContours(img_rgb, contornos, -1, [0, 0, 255], 10);\n\nplt.figure(figsize=(8,6))\nplt.imshow(img_rgb);\n</pre> # para desenhar o contorno primeiro faz uma copia da imagem   mask_rgb = cv2.cvtColor(mask_hsv, cv2.COLOR_GRAY2RGB)  contornos_img = mask_rgb.copy() # C\u00f3pia da m\u00e1scara para ser desenhada \"por cima\"  cv2.drawContours(img_rgb, contornos, -1, [0, 0, 255], 10);  plt.figure(figsize=(8,6)) plt.imshow(img_rgb); <p>Note que a fun\u00e7\u00e3o findContours devolve uma lista com os contornos detectados.</p> In\u00a0[\u00a0]: Copied! <pre>print(\"Quantidade de contornos encontrado: \", len(contornos))\n</pre> print(\"Quantidade de contornos encontrado: \", len(contornos)) <pre>Quantidade de contornos encontrado:  1\n</pre> In\u00a0[\u00a0]: Copied! <pre>%matplotlib inline\nimport cv2\nfrom matplotlib import pyplot as plt\nimport numpy as np\n\nimg = cv2.imread('formas.png')\nimg_res = cv2.imread('formas_contorno.png')\n\nimg_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\nimg_res_rgb = cv2.cvtColor(img_res, cv2.COLOR_BGR2RGB)\n\n\n# Defini\u00e7\u00e3o dos valores minimo e max da mascara\n\nimage_lower_hsv = np.array([0, 1, 0])  \nimage_upper_hsv = np.array([180, 255, 255])\n\nfig = plt.figure(figsize=(20,20))\nplt.subplot(1, 2, 1)\nplt.imshow(img_rgb)\nplt.subplot(1, 2, 2)\nplt.imshow(img_res_rgb)\nplt.show()\n</pre>  %matplotlib inline import cv2 from matplotlib import pyplot as plt import numpy as np  img = cv2.imread('formas.png') img_res = cv2.imread('formas_contorno.png')  img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB) img_res_rgb = cv2.cvtColor(img_res, cv2.COLOR_BGR2RGB)   # Defini\u00e7\u00e3o dos valores minimo e max da mascara  image_lower_hsv = np.array([0, 1, 0])   image_upper_hsv = np.array([180, 255, 255])  fig = plt.figure(figsize=(20,20)) plt.subplot(1, 2, 1) plt.imshow(img_rgb) plt.subplot(1, 2, 2) plt.imshow(img_res_rgb) plt.show() In\u00a0[50]: Copied! <pre>#Implemente seu c\u00f3digo\n\n# para desenhar o contorno podemos fazer uma imagem em escala de cinza e depois desenhar o contorno\n# ou podemos usar a imagem original e desenhar o contorno por cima\n\n\nimport cv2\nfrom matplotlib import pyplot as plt\n\nimg = cv2.imread('formas.png')\nimg_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\nimg_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\nimg_hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n\n# Define as faixas de cor para o vermelho no espa\u00e7o HSV\nlower_hsv = np.array([0, 1, 1])\nupper_hsv = np.array([180, 255, 255])\n\n# Cria as m\u00e1scaras\nedges = cv2.inRange(img_hsv, lower_hsv, upper_hsv)\n\n# Encontra os contornos na imagem\ncontours, _ = cv2.findContours(edges, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n\n# Desenha os contornos na imagem em escala de cinza\nedges_copy = edges.copy()\nimg_gray_contours = cv2.cvtColor(edges_copy, cv2.COLOR_GRAY2RGB)\ncv2.drawContours(img_gray_contours, contours, -1, (255, 0, 0), 5)\n\n# Desenha os contornos na imagem original\nimg_contours = img_rgb.copy()\ncv2.drawContours(img_contours, contours, -1, (255, 0, 0), 2)\n\n# Exibe a imagem original e a imagem com os contornos\nplt.figure(figsize=(10, 5))\nplt.subplot(1, 3, 1)\nplt.imshow(img_rgb)\nplt.title('Imagem Original')\nplt.axis('off')\n\nplt.subplot(1, 3, 2)\nplt.imshow(img_gray_contours)\nplt.title('Contornos gray')\nplt.axis('off')\n\nplt.subplot(1, 3, 3)\nplt.imshow(img_contours)\nplt.title('Contornos RGB')\nplt.axis('off')\n\nplt.show()\n</pre> #Implemente seu c\u00f3digo  # para desenhar o contorno podemos fazer uma imagem em escala de cinza e depois desenhar o contorno # ou podemos usar a imagem original e desenhar o contorno por cima   import cv2 from matplotlib import pyplot as plt  img = cv2.imread('formas.png') img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB) img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY) img_hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)  # Define as faixas de cor para o vermelho no espa\u00e7o HSV lower_hsv = np.array([0, 1, 1]) upper_hsv = np.array([180, 255, 255])  # Cria as m\u00e1scaras edges = cv2.inRange(img_hsv, lower_hsv, upper_hsv)  # Encontra os contornos na imagem contours, _ = cv2.findContours(edges, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)  # Desenha os contornos na imagem em escala de cinza edges_copy = edges.copy() img_gray_contours = cv2.cvtColor(edges_copy, cv2.COLOR_GRAY2RGB) cv2.drawContours(img_gray_contours, contours, -1, (255, 0, 0), 5)  # Desenha os contornos na imagem original img_contours = img_rgb.copy() cv2.drawContours(img_contours, contours, -1, (255, 0, 0), 2)  # Exibe a imagem original e a imagem com os contornos plt.figure(figsize=(10, 5)) plt.subplot(1, 3, 1) plt.imshow(img_rgb) plt.title('Imagem Original') plt.axis('off')  plt.subplot(1, 3, 2) plt.imshow(img_gray_contours) plt.title('Contornos gray') plt.axis('off')  plt.subplot(1, 3, 3) plt.imshow(img_contours) plt.title('Contornos RGB') plt.axis('off')  plt.show()   In\u00a0[65]: Copied! <pre>## Implemente seu c\u00f3digo\nimport cv2\nfrom matplotlib import pyplot as plt\n\nimg = cv2.imread('formas.png')\nimg_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\nimg_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\nimg_hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n\n# Define as faixas de cor para o vermelho no espa\u00e7o HSV\nlower_hsv = np.array([0, 1, 1])\nupper_hsv = np.array([180, 255, 255])\n\n# Cria as m\u00e1scaras\nedges = cv2.inRange(img_hsv, lower_hsv, upper_hsv)\n\n# Encontra os contornos na imagem\ncontours, _ = cv2.findContours(edges, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n\n### o findContours devolve uma lista de contornos, a ideia \u00e9 varrer esses contornos e encontrar a maior area e maior index\n \nmax_area = 0\nmax_index = -1\nfor i, contour in enumerate(contours):\n    area = cv2.contourArea(contour)\n    if area &gt; max_area:\n        max_area = area\n        max_index = i\n\nprint(f'Foram detectados {len(contours)} contornos.\\nO maior contorno \u00e9 o de indice {max_index} com a \u00e1rea de {max_area}')\n\n# Desenha o contorno de maior \u00e1rea na imagem original\nimg_contour_max = img_rgb.copy()\nif max_index != -1:\n    cv2.drawContours(img_contour_max, [contours[max_index]], -1, (0, 0, 0), 10)\n\n# Exibe a imagem original e a imagem com o contorno de maior \u00e1rea\nplt.figure(figsize=(10, 5))\nplt.subplot(1, 2, 1)\nplt.imshow(img_contour_max)\nplt.title('Maior Contorno')\nplt.axis('off')\n\n\nplt.show()\n</pre> ## Implemente seu c\u00f3digo import cv2 from matplotlib import pyplot as plt  img = cv2.imread('formas.png') img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB) img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY) img_hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)  # Define as faixas de cor para o vermelho no espa\u00e7o HSV lower_hsv = np.array([0, 1, 1]) upper_hsv = np.array([180, 255, 255])  # Cria as m\u00e1scaras edges = cv2.inRange(img_hsv, lower_hsv, upper_hsv)  # Encontra os contornos na imagem contours, _ = cv2.findContours(edges, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)  ### o findContours devolve uma lista de contornos, a ideia \u00e9 varrer esses contornos e encontrar a maior area e maior index   max_area = 0 max_index = -1 for i, contour in enumerate(contours):     area = cv2.contourArea(contour)     if area &gt; max_area:         max_area = area         max_index = i  print(f'Foram detectados {len(contours)} contornos.\\nO maior contorno \u00e9 o de indice {max_index} com a \u00e1rea de {max_area}')  # Desenha o contorno de maior \u00e1rea na imagem original img_contour_max = img_rgb.copy() if max_index != -1:     cv2.drawContours(img_contour_max, [contours[max_index]], -1, (0, 0, 0), 10)  # Exibe a imagem original e a imagem com o contorno de maior \u00e1rea plt.figure(figsize=(10, 5)) plt.subplot(1, 2, 1) plt.imshow(img_contour_max) plt.title('Maior Contorno') plt.axis('off')   plt.show()  <pre>Foram detectados 11 contornos.\nO maior contorno \u00e9 o de indice 1 com a \u00e1rea de 42784.0\n</pre> In\u00a0[\u00a0]: Copied! <pre>cv2.__version__\n</pre> cv2.__version__ Out[\u00a0]: <pre>'4.5.5'</pre> In\u00a0[\u00a0]: Copied! <pre>#recarregando o nosso exemplo...\n\n%matplotlib inline\nimport cv2\nfrom matplotlib import pyplot as plt\nimport numpy as np\n\nimg = cv2.imread('bolinha.png')\n\nimg_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\nimg_hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n\n\n# Defini\u00e7\u00e3o dos valores minimo e max da mascara\n# o magenta tem h=300 mais ou menos ou 150 para a OpenCV\nimage_lower_hsv = np.array([140, 50, 100])  \nimage_upper_hsv = np.array([170, 255, 255])\n\n\nmask_hsv = cv2.inRange(img_hsv, image_lower_hsv, image_upper_hsv)\n\ncontornos, _ = cv2.findContours(mask_hsv, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE) \n\nmask_rgb = cv2.cvtColor(mask_hsv, cv2.COLOR_GRAY2RGB) \ncontornos_img = mask_rgb.copy() # C\u00f3pia da m\u00e1scara para ser desenhada \"por cima\"\n\ncv2.drawContours(contornos_img, contornos, -1, [255, 0, 0], 5);\n\nplt.figure(figsize=(8,6))\nplt.imshow(contornos_img);\n</pre> #recarregando o nosso exemplo...  %matplotlib inline import cv2 from matplotlib import pyplot as plt import numpy as np  img = cv2.imread('bolinha.png')  img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB) img_hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)   # Defini\u00e7\u00e3o dos valores minimo e max da mascara # o magenta tem h=300 mais ou menos ou 150 para a OpenCV image_lower_hsv = np.array([140, 50, 100])   image_upper_hsv = np.array([170, 255, 255])   mask_hsv = cv2.inRange(img_hsv, image_lower_hsv, image_upper_hsv)  contornos, _ = cv2.findContours(mask_hsv, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)   mask_rgb = cv2.cvtColor(mask_hsv, cv2.COLOR_GRAY2RGB)  contornos_img = mask_rgb.copy() # C\u00f3pia da m\u00e1scara para ser desenhada \"por cima\"  cv2.drawContours(contornos_img, contornos, -1, [255, 0, 0], 5);  plt.figure(figsize=(8,6)) plt.imshow(contornos_img); In\u00a0[\u00a0]: Copied! <pre># usando o exemplo da documenta\u00e7\u00e3o https://docs.opencv.org/master/dd/d49/tutorial_py_contour_features.html\n# notamos que a fun\u00e7\u00e3o devolve um dicionario. \n\ncnt = contornos[0]\n\nM = cv2.moments(cnt)\nprint( M )\n</pre> # usando o exemplo da documenta\u00e7\u00e3o https://docs.opencv.org/master/dd/d49/tutorial_py_contour_features.html # notamos que a fun\u00e7\u00e3o devolve um dicionario.   cnt = contornos[0]  M = cv2.moments(cnt) print( M ) <pre>{'m00': 20954.5, 'm10': 8414785.5, 'm01': 4813317.5, 'm20': 3414210172.083333, 'm11': 1932427931.625, 'm02': 1140509199.0833333, 'm30': 1399201096317.6501, 'm21': 783868070420.7833, 'm12': 457787216119.7167, 'm03': 278003040454.85004, 'mu20': 35049847.99971104, 'mu11': -475946.1051416397, 'mu02': 34874354.26211333, 'mu30': -7672941.9208984375, 'mu21': -4968840.380795479, 'mu12': 6858123.621509552, 'mu03': 2822544.575317383, 'nu20': 0.07982364109512664, 'nu11': -0.0010839348312655414, 'nu02': 0.07942396606302501, 'nu30': -0.00012071706132489804, 'nu21': -7.817390189392743e-05, 'nu12': 0.00010789766667418762, 'nu03': 4.4406603113053444e-05}\n</pre> In\u00a0[\u00a0]: Copied! <pre># Calculo das coordenadas do centro de massa\n\ncx = int(M['m10']/M['m00'])\ncy = int(M['m01']/M['m00'])\n\nprint(\"centro de massa na possi\u00e7\u00e3o: \",cx, cy)\n</pre> # Calculo das coordenadas do centro de massa  cx = int(M['m10']/M['m00']) cy = int(M['m01']/M['m00'])  print(\"centro de massa na possi\u00e7\u00e3o: \",cx, cy) <pre>centro de massa na possi\u00e7\u00e3o:  401 229\n</pre> <p>Vamos plotar isso na imagem para saber se esta correto. A fun\u00e7\u00e3o \"cv2.line\" vai nos ajudar a desenhar uma cruz. e fun\u00e7\u00e3o \"cv2.putText\" a escrever na imagem as coordenadas.</p> In\u00a0[\u00a0]: Copied! <pre>## para desenhar a cruz vamos passar a cor e o tamanho em pixel\nsize = 20\ncolor = (128,128,0)\n\n\ncv2.line(contornos_img,(cx - size,cy),(cx + size,cy),color,5)\ncv2.line(contornos_img,(cx,cy - size),(cx, cy + size),color,5)\n\n# Para escrever vamos definir uma fonte \n\nfont = cv2.FONT_HERSHEY_SIMPLEX\ntext = cy , cx\norigem = (0,50)\n\ncv2.putText(contornos_img, str(text), origem, font,1,(200,50,0),2,cv2.LINE_AA)\n\n\nplt.imshow(contornos_img);\n</pre> ## para desenhar a cruz vamos passar a cor e o tamanho em pixel size = 20 color = (128,128,0)   cv2.line(contornos_img,(cx - size,cy),(cx + size,cy),color,5) cv2.line(contornos_img,(cx,cy - size),(cx, cy + size),color,5)  # Para escrever vamos definir uma fonte   font = cv2.FONT_HERSHEY_SIMPLEX text = cy , cx origem = (0,50)  cv2.putText(contornos_img, str(text), origem, font,1,(200,50,0),2,cv2.LINE_AA)   plt.imshow(contornos_img); In\u00a0[70]: Copied! <pre>#### seu c\u00f3digo aqui...\n\n## Vamos fazer por partes, primeiro vamos achar o centro de massa para a imagem que estamos utilizando da melancia\n%matplotlib inline\nimport cv2\nfrom matplotlib import pyplot as plt\nimport numpy as np\n\nimg = cv2.imread('melancia.png')\n\nimg_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\nimg_hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n\nprint(img_hsv.shape)\nprint(img_hsv[220,700])\n\n# Defini\u00e7\u00e3o dos valores minimo e max da mascara para a melancia\n# use o color picker para pegar os valores aproximados de h, s e v para a melancia \nmelancia_lower1 = np.array([175, 120, 150])  \nmelancia_upper1 = np.array([180, 255, 255])\nmelancia_lower2 = np.array([0, 140, 160])  \nmelancia_upper2 = np.array([15, 255, 255])\n\n# Cria as m\u00e1scaras para as faixas de vermelho\nmask_1 = cv2.inRange(img_hsv, melancia_lower1, melancia_upper1)\nmask_2 = cv2.inRange(img_hsv, melancia_lower2, melancia_upper2)\n\n# Combina as duas m\u00e1scaras com uma opera\u00e7\u00e3o bitwise_or\nmask_melancia = cv2.bitwise_or(mask_1, mask_2)\n\n# Encontra os contornos na imagem\ncontours, _ = cv2.findContours(mask_melancia, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n\n### o findContours devolve uma lista de contornos, a ideia \u00e9 varrer esses contornos e encontrar a maior area e maior index\n \nmax_area = 0\nmax_index = -1\nfor i, contour in enumerate(contours):\n    area = cv2.contourArea(contour)\n    if area &gt; max_area:\n        max_area = area\n        max_index = i\n\nprint(f'Foram detectados {len(contours)} contornos.\\nO maior contorno \u00e9 o de indice {max_index} com a \u00e1rea de {max_area}')\n## para desenhar a cruz vamos passar a cor e o tamanho em pixel\nsize = 20\ncolor = (128,128,0)\n# Desenha o contorno de maior \u00e1rea na imagem original\nimg_contour_max = img_rgb.copy()\nif max_index != -1:\n    cv2.drawContours(img_contour_max, [contours[max_index]], -1, (0, 255, 0), 10)\n\n    # Calcula o centro de massa\n    M = cv2.moments(contours[max_index])\n    if M[\"m00\"] != 0:\n        cx = int(M[\"m10\"] / M[\"m00\"])\n        cy = int(M[\"m01\"] / M[\"m00\"])\n        # Desenha o centro de massa\n        cv2.line(img_contour_max,(cx - size,cy),(cx + size,cy),color,5)\n        cv2.line(img_contour_max,(cx,cy - size),(cx, cy + size),color,5)\n        cv2.putText(img, f'({cy}, {cx})', (0, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (200, 50, 0), 2, cv2.LINE_AA)\n\n# Exibe a imagem original e a imagem com o contorno de maior \u00e1rea\nplt.figure(figsize=(10, 5))\nplt.subplot(1, 2, 1)\nplt.imshow(img_contour_max)\nplt.title('Achei voc\u00ea!')\nplt.axis('off')\n\n\nplt.show()\n</pre> #### seu c\u00f3digo aqui...  ## Vamos fazer por partes, primeiro vamos achar o centro de massa para a imagem que estamos utilizando da melancia %matplotlib inline import cv2 from matplotlib import pyplot as plt import numpy as np  img = cv2.imread('melancia.png')  img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB) img_hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)  print(img_hsv.shape) print(img_hsv[220,700])  # Defini\u00e7\u00e3o dos valores minimo e max da mascara para a melancia # use o color picker para pegar os valores aproximados de h, s e v para a melancia  melancia_lower1 = np.array([175, 120, 150])   melancia_upper1 = np.array([180, 255, 255]) melancia_lower2 = np.array([0, 140, 160])   melancia_upper2 = np.array([15, 255, 255])  # Cria as m\u00e1scaras para as faixas de vermelho mask_1 = cv2.inRange(img_hsv, melancia_lower1, melancia_upper1) mask_2 = cv2.inRange(img_hsv, melancia_lower2, melancia_upper2)  # Combina as duas m\u00e1scaras com uma opera\u00e7\u00e3o bitwise_or mask_melancia = cv2.bitwise_or(mask_1, mask_2)  # Encontra os contornos na imagem contours, _ = cv2.findContours(mask_melancia, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)  ### o findContours devolve uma lista de contornos, a ideia \u00e9 varrer esses contornos e encontrar a maior area e maior index   max_area = 0 max_index = -1 for i, contour in enumerate(contours):     area = cv2.contourArea(contour)     if area &gt; max_area:         max_area = area         max_index = i  print(f'Foram detectados {len(contours)} contornos.\\nO maior contorno \u00e9 o de indice {max_index} com a \u00e1rea de {max_area}') ## para desenhar a cruz vamos passar a cor e o tamanho em pixel size = 20 color = (128,128,0) # Desenha o contorno de maior \u00e1rea na imagem original img_contour_max = img_rgb.copy() if max_index != -1:     cv2.drawContours(img_contour_max, [contours[max_index]], -1, (0, 255, 0), 10)      # Calcula o centro de massa     M = cv2.moments(contours[max_index])     if M[\"m00\"] != 0:         cx = int(M[\"m10\"] / M[\"m00\"])         cy = int(M[\"m01\"] / M[\"m00\"])         # Desenha o centro de massa         cv2.line(img_contour_max,(cx - size,cy),(cx + size,cy),color,5)         cv2.line(img_contour_max,(cx,cy - size),(cx, cy + size),color,5)         cv2.putText(img, f'({cy}, {cx})', (0, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (200, 50, 0), 2, cv2.LINE_AA)  # Exibe a imagem original e a imagem com o contorno de maior \u00e1rea plt.figure(figsize=(10, 5)) plt.subplot(1, 2, 1) plt.imshow(img_contour_max) plt.title('Achei voc\u00ea!') plt.axis('off')   plt.show()  <pre>(723, 1280, 3)\n[179 172 231]\nForam detectados 116 contornos.\nO maior contorno \u00e9 o de indice 98 com a \u00e1rea de 53061.0\n</pre> In\u00a0[\u00a0]: Copied! <pre>import cv2\nimport numpy as np\n\n# Inicializa a captura de v\u00eddeo da webcam\ncap = cv2.VideoCapture(0)\n\n# Defini\u00e7\u00e3o dos valores m\u00ednimo e m\u00e1ximo da m\u00e1scara para a melancia\nmelancia_lower1 = np.array([175, 120, 150])\nmelancia_upper1 = np.array([180, 255, 255])\nmelancia_lower2 = np.array([0, 140, 160])\nmelancia_upper2 = np.array([15, 255, 255])\n\n# Loop para ler os frames da webcam\nwhile True:\n    ret, img = cap.read()\n    if not ret:\n        break\n\n    img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n    img_hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n\n    # Cria as m\u00e1scaras para as faixas de vermelho\n    mask_1 = cv2.inRange(img_hsv, melancia_lower1, melancia_upper1)\n    mask_2 = cv2.inRange(img_hsv, melancia_lower2, melancia_upper2)\n\n    # Combina as duas m\u00e1scaras com uma opera\u00e7\u00e3o bitwise_or\n    mask_melancia = cv2.bitwise_or(mask_1, mask_2)\n\n    # Encontra os contornos na imagem\n    contours, _ = cv2.findContours(mask_melancia, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n\n    # Encontra o contorno de maior \u00e1rea\n    max_area = 0\n    max_index = -1\n    for i, contour in enumerate(contours):\n        area = cv2.contourArea(contour)\n        if area &gt; max_area:\n            max_area = area\n            max_index = i\n\n    # Desenha o contorno de maior \u00e1rea na imagem original\n    if max_index != -1:\n        cv2.drawContours(img, [contours[max_index]], -1, (0, 255, 0), 10)\n\n        # Calcula o centro de massa\n        M = cv2.moments(contours[max_index])\n        if M[\"m00\"] != 0:\n            cx = int(M[\"m10\"] / M[\"m00\"])\n            cy = int(M[\"m01\"] / M[\"m00\"])\n            # Desenha o centro de massa\n            cv2.line(img, (cx - 20, cy), (cx + 20, cy), (128, 128, 0), 5)\n            cv2.line(img, (cx, cy - 20), (cx, cy + 20), (128, 128, 0), 5)\n            cv2.putText(img, f'({cy}, {cx})', (0, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (200, 50, 0), 2, cv2.LINE_AA)\n\n    # Exibe a imagem com o contorno de maior \u00e1rea\n    cv2.imshow('Achei voc\u00ea!', img)\n\n    # Sai do loop se a tecla 'q' for pressionada\n    if cv2.waitKey(1) &amp; 0xFF == ord('q'):\n        break\n\n# Libera a captura e fecha todas as janelas\ncap.release()\ncv2.destroyAllWindows()\n</pre> import cv2 import numpy as np  # Inicializa a captura de v\u00eddeo da webcam cap = cv2.VideoCapture(0)  # Defini\u00e7\u00e3o dos valores m\u00ednimo e m\u00e1ximo da m\u00e1scara para a melancia melancia_lower1 = np.array([175, 120, 150]) melancia_upper1 = np.array([180, 255, 255]) melancia_lower2 = np.array([0, 140, 160]) melancia_upper2 = np.array([15, 255, 255])  # Loop para ler os frames da webcam while True:     ret, img = cap.read()     if not ret:         break      img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)     img_hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)      # Cria as m\u00e1scaras para as faixas de vermelho     mask_1 = cv2.inRange(img_hsv, melancia_lower1, melancia_upper1)     mask_2 = cv2.inRange(img_hsv, melancia_lower2, melancia_upper2)      # Combina as duas m\u00e1scaras com uma opera\u00e7\u00e3o bitwise_or     mask_melancia = cv2.bitwise_or(mask_1, mask_2)      # Encontra os contornos na imagem     contours, _ = cv2.findContours(mask_melancia, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)      # Encontra o contorno de maior \u00e1rea     max_area = 0     max_index = -1     for i, contour in enumerate(contours):         area = cv2.contourArea(contour)         if area &gt; max_area:             max_area = area             max_index = i      # Desenha o contorno de maior \u00e1rea na imagem original     if max_index != -1:         cv2.drawContours(img, [contours[max_index]], -1, (0, 255, 0), 10)          # Calcula o centro de massa         M = cv2.moments(contours[max_index])         if M[\"m00\"] != 0:             cx = int(M[\"m10\"] / M[\"m00\"])             cy = int(M[\"m01\"] / M[\"m00\"])             # Desenha o centro de massa             cv2.line(img, (cx - 20, cy), (cx + 20, cy), (128, 128, 0), 5)             cv2.line(img, (cx, cy - 20), (cx, cy + 20), (128, 128, 0), 5)             cv2.putText(img, f'({cy}, {cx})', (0, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (200, 50, 0), 2, cv2.LINE_AA)      # Exibe a imagem com o contorno de maior \u00e1rea     cv2.imshow('Achei voc\u00ea!', img)      # Sai do loop se a tecla 'q' for pressionada     if cv2.waitKey(1) &amp; 0xFF == ord('q'):         break  # Libera a captura e fecha todas as janelas cap.release() cv2.destroyAllWindows()"},{"location":"aulas/PDI/lab05/sol_Espa%C3%A7o-cor-contorno.html#espaco-de-cor-hsv","title":"Espa\u00e7o de cor HSV\u00b6","text":"<p>At\u00e9 o momento trabalhamos com imagens em escala de cinza, BGR, RGB e binaria. Agora vamos conhecer e trabalhar com HSV ou HSB.</p> <pre><code>H - hue (matriz)\nS - saturation (satura\u00e7\u00e3o)\nV - value (Value) ou B - brightness (brilho)</code></pre> <p>Utilizar esse espa\u00e7o possui algumas vantagens vamos ver no exemplo abaixo.</p>"},{"location":"aulas/PDI/lab05/sol_Espa%C3%A7o-cor-contorno.html#desafio-1","title":"DESAFIO 1\u00b6","text":"<p>Fa\u00e7a a segmenta\u00e7\u00e3o da meia lua da imagem \"melancia.png\". O seu resultado deve ser proximo/parecido com a imagem \"melancia_filtrada.png\".</p> <p>Dica: talvez voc\u00ea precise usar mais que uma faixa de valores, se necess\u00e1rio use a fun\u00e7\u00e3o \"cv2.bitwise_or\" para juntar as partes.</p>"},{"location":"aulas/PDI/lab05/sol_Espa%C3%A7o-cor-contorno.html#desafio-2","title":"DESAFIO 2\u00b6","text":"<p>Usando a imagem \"melancia_filtrada.png\", devolva a cor original que era antes da filtragem.</p> <p>Dica: Use as fun\u00e7\u00f5es de \"cv2.bitwise_and\" para juntar.</p>"},{"location":"aulas/PDI/lab05/sol_Espa%C3%A7o-cor-contorno.html#deteccao-de-contornos","title":"DETEC\u00c7\u00c3O DE CONTORNOS\u00b6","text":"<p>Para realizar a detec\u00e7\u00e3o dos contornos, ou bordas de um objeto, usamos a fun\u00e7\u00e3o cv2.findontours</p>"},{"location":"aulas/PDI/lab05/sol_Espa%C3%A7o-cor-contorno.html#desafio-3","title":"DESAFIO 3\u00b6","text":"<p>Usando a imagem \"formas.png\", fa\u00e7a um c\u00f3digo que detecta todos os contornos da imagem. O resultado deve ser parecido com \"formas_contorno.png\"</p> <p>Dica: Neste desafio, basicamente tem que ajustar a a mascara, o resto n\u00e3o muda.</p>"},{"location":"aulas/PDI/lab05/sol_Espa%C3%A7o-cor-contorno.html#desafio-4","title":"DESAFIO 4\u00b6","text":"<p>Altere o seu codigo para desenhar o contorno de maior area da imagem. Use a fun\u00e7\u00e3o \"cv2.contourArea()\".</p> <p>Refer\u00eancia da documenta\u00e7\u00e3o: https://docs.opencv.org/master/dd/d49/tutorial_py_contour_features.html</p> <p>Dica: Use um for para varrer a lista e armazene o indice do maior valor e passe esse valor para desenhar o contorno.</p>"},{"location":"aulas/PDI/lab05/sol_Espa%C3%A7o-cor-contorno.html#centro-de-massa-de-um-objeto","title":"CENTRO DE MASSA DE UM OBJETO\u00b6","text":"<p>O calculo para o centro de massa \u00e9 feito atr\u00e1ves da fun\u00e7\u00e3o cv2.findontours</p>"},{"location":"aulas/PDI/lab05/sol_Espa%C3%A7o-cor-contorno.html#desafio-5","title":"DESAFIO 5\u00b6","text":"<p>O desafio \u00e9 juntar o que aprendemos em um video, use como base \"webcam.py\". Voc\u00ea deve seguimentar a cor de um objeto, encontrar seu contorno e montar a imagem segmentada com o centro de massa e suas coordenadas. Video de refer\u00eancia \"segmenta_melancia.mp4\"</p>"},{"location":"aulas/PDI/lab05/webcam.html","title":"Webcam","text":"In\u00a0[\u00a0]: Copied! <p>Programa simples com camera webcam e opencv</p> In\u00a0[\u00a0]: Copied! <pre>import cv2\nimport os,sys, os.path\nimport numpy as np\n</pre> import cv2 import os,sys, os.path import numpy as np In\u00a0[\u00a0]: Copied! <pre>def image_da_webcam(img):\n    \"\"\"\n    -&gt;&gt;&gt; !!!! FECHE A JANELA COM A TECLA ESC !!!! &lt;&lt;&lt;&lt;-\n        deve receber a imagem da camera e retornar uma imagems filtrada.\n    \"\"\"\n    img = cv2.cvtColor(img,cv2.COLOR_BGR2RGB)\n\n    return img\n</pre> def image_da_webcam(img):     \"\"\"     -&gt;&gt;&gt; !!!! FECHE A JANELA COM A TECLA ESC !!!! &lt;&lt;&lt;&lt;-         deve receber a imagem da camera e retornar uma imagems filtrada.     \"\"\"     img = cv2.cvtColor(img,cv2.COLOR_BGR2RGB)      return img In\u00a0[\u00a0]: Copied! <pre>cv2.namedWindow(\"preview\")\nvc = cv2.VideoCapture(0)\n</pre> cv2.namedWindow(\"preview\") vc = cv2.VideoCapture(0) In\u00a0[\u00a0]: Copied! <pre>if vc.isOpened(): # try to get the first frame\n    rval, frame = vc.read()\nelse:\n    rval = False\n</pre> if vc.isOpened(): # try to get the first frame     rval, frame = vc.read() else:     rval = False In\u00a0[\u00a0]: Copied! <pre>while rval:\n    \n    img = image_da_webcam(frame)\n\n\n    cv2.imshow(\"preview\", img)\n\n    rval, frame = vc.read()\n    key = cv2.waitKey(20)\n    if key == 27: # exit on ESC\n        break\n</pre> while rval:          img = image_da_webcam(frame)       cv2.imshow(\"preview\", img)      rval, frame = vc.read()     key = cv2.waitKey(20)     if key == 27: # exit on ESC         break In\u00a0[\u00a0]: Copied! <pre>cv2.destroyWindow(\"preview\")\nvc.release()\n</pre> cv2.destroyWindow(\"preview\") vc.release()"},{"location":"aulas/PDI/lab06/Transformada-Hough-morfologia.html","title":"Elementos Estruturantes","text":"<p>Objetivos da aula:</p> <ul> <li>Conhecer e praticar a Transformada de Hough para linhas e circulos</li> <li>conhecer e praticar com os operadores de dilata\u00e7\u00e3o e eros\u00e3o</li> <li>conhecer e praticar com os operadores de abertura e fechamento</li> </ul> In\u00a0[\u00a0]: Copied! <pre>## Vou fazer o download das imagens do laborat\u00f3rio diretamente do reposit\u00f3rio para ficar mais facil....\n\nimport requests\nimport os\n\n# Define o laborat\u00f3rio\nlaboratorio = 'lab06'  ### altere para o laborat\u00f3rio desejado\ndiretorio = 'lab_images'  ### altere para o diret\u00f3rio que deseja salvar as imagens\n\n# Download de um arquivo\ndef download_file(url, destination):\n    response = requests.get(url, stream=True)\n    if response.status_code == 200:\n        with open(destination, 'wb') as file:\n            for chunk in response.iter_content(chunk_size=8192):\n                file.write(chunk)\n        print(f\"Baixado: {destination}\")\n    else:\n        print(f\"Erro ao baixar {url}\")\n\n# Monta a URL completa\napi_url = \"https://api.github.com/repos/arnaldojr/cognitivecomputing/contents/material/aulas/PDI/\"\nurl_completa = api_url + laboratorio\nprint(f\"Fazendo o download de: {url_completa}\")\n\n# checa se a URL est\u00e1 acess\u00edvel\nresponse = requests.get(url_completa)\nif response.status_code != 200:\n    raise Exception(f\"Erro ao acessar o reposit\u00f3rio: {response.status_code}\")\nfiles = response.json()\n\n\n# Faz o download de cada arquivo\nos.makedirs(diretorio, exist_ok=True) # Cria a pasta downloads\nfor file in files:\n    file_name = file['name']\n    if file_name.endswith(('.png', '.jpg', '.jpeg', '.mp4')):  # Adicione mais extens\u00f5es se necess\u00e1rio\n        file_url = file['download_url']\n        destination = os.path.join(diretorio, file_name)\n        download_file(file_url, destination)\n\nprint(f\"Download conclu\u00eddo. Arquivos salvos na pasta {diretorio}.\")\n</pre> ## Vou fazer o download das imagens do laborat\u00f3rio diretamente do reposit\u00f3rio para ficar mais facil....  import requests import os  # Define o laborat\u00f3rio laboratorio = 'lab06'  ### altere para o laborat\u00f3rio desejado diretorio = 'lab_images'  ### altere para o diret\u00f3rio que deseja salvar as imagens  # Download de um arquivo def download_file(url, destination):     response = requests.get(url, stream=True)     if response.status_code == 200:         with open(destination, 'wb') as file:             for chunk in response.iter_content(chunk_size=8192):                 file.write(chunk)         print(f\"Baixado: {destination}\")     else:         print(f\"Erro ao baixar {url}\")  # Monta a URL completa api_url = \"https://api.github.com/repos/arnaldojr/cognitivecomputing/contents/material/aulas/PDI/\" url_completa = api_url + laboratorio print(f\"Fazendo o download de: {url_completa}\")  # checa se a URL est\u00e1 acess\u00edvel response = requests.get(url_completa) if response.status_code != 200:     raise Exception(f\"Erro ao acessar o reposit\u00f3rio: {response.status_code}\") files = response.json()   # Faz o download de cada arquivo os.makedirs(diretorio, exist_ok=True) # Cria a pasta downloads for file in files:     file_name = file['name']     if file_name.endswith(('.png', '.jpg', '.jpeg', '.mp4')):  # Adicione mais extens\u00f5es se necess\u00e1rio         file_url = file['download_url']         destination = os.path.join(diretorio, file_name)         download_file(file_url, destination)  print(f\"Download conclu\u00eddo. Arquivos salvos na pasta {diretorio}.\") In\u00a0[15]: Copied! <pre>%matplotlib inline\nimport cv2\nfrom matplotlib import pyplot as plt\nimport numpy as np\n\nimg = cv2.imread('formas.png')\nimg = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n\nplt.figure(figsize = (10,10))\nplt.imshow(img); plt.show()\n</pre> %matplotlib inline import cv2 from matplotlib import pyplot as plt import numpy as np  img = cv2.imread('formas.png') img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)  plt.figure(figsize = (10,10)) plt.imshow(img); plt.show() In\u00a0[21]: Copied! <pre>img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n\nedges = cv2.Canny(img_gray,50,150)\n\n\"\"\"\nDetecta c\u00edrculos em uma imagem usando a Transformada de Hough\n\nPar\u00e2metros:\nimagem (ndarray): Imagem de entrada\ndp (float): Resolu\u00e7\u00e3o do acumulador\nminDist (int): Dist\u00e2ncia m\u00ednima entre os centros dos c\u00edrculos detectados\nparam1 (int): Limiar superior para o detector de bordas Canny\nparam2 (int): Limiar do acumulador para centros de c\u00edrculos\nminRadius (int): Raio m\u00ednimo dos c\u00edrculos\nmaxRadius (int): Raio m\u00e1ximo dos c\u00edrculos\n\nRetorno:\nndarray: Imagem com c\u00edrculos detectados\n\"\"\"\ncircles=cv2.HoughCircles(edges,cv2.HOUGH_GRADIENT,dp=2,minDist=10,param1=200,param2=100,minRadius=5,maxRadius=150)\n\nbordas_rgb = cv2.cvtColor(edges, cv2.COLOR_GRAY2RGB)\noutput = bordas_rgb\n\n\nif circles is not None:        \n    circles = np.uint16(np.around(circles))\n    for i in circles[0,:]:\n        # desenha o contorno do circulo\n        cv2.circle(output,(i[0],i[1]),i[2],(0,255,0),2)\n        # desenha no centro do circulo\n        cv2.circle(output,(i[0],i[1]),2,(0,0,255),3)\n        \nplt.figure(figsize = (10,10))\nplt.imshow(output, cmap=\"Greys_r\", vmin=0, vmax=255); plt.show()\n</pre> img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)  edges = cv2.Canny(img_gray,50,150)  \"\"\" Detecta c\u00edrculos em uma imagem usando a Transformada de Hough  Par\u00e2metros: imagem (ndarray): Imagem de entrada dp (float): Resolu\u00e7\u00e3o do acumulador minDist (int): Dist\u00e2ncia m\u00ednima entre os centros dos c\u00edrculos detectados param1 (int): Limiar superior para o detector de bordas Canny param2 (int): Limiar do acumulador para centros de c\u00edrculos minRadius (int): Raio m\u00ednimo dos c\u00edrculos maxRadius (int): Raio m\u00e1ximo dos c\u00edrculos  Retorno: ndarray: Imagem com c\u00edrculos detectados \"\"\" circles=cv2.HoughCircles(edges,cv2.HOUGH_GRADIENT,dp=2,minDist=10,param1=200,param2=100,minRadius=5,maxRadius=150)  bordas_rgb = cv2.cvtColor(edges, cv2.COLOR_GRAY2RGB) output = bordas_rgb   if circles is not None:             circles = np.uint16(np.around(circles))     for i in circles[0,:]:         # desenha o contorno do circulo         cv2.circle(output,(i[0],i[1]),i[2],(0,255,0),2)         # desenha no centro do circulo         cv2.circle(output,(i[0],i[1]),2,(0,0,255),3)          plt.figure(figsize = (10,10)) plt.imshow(output, cmap=\"Greys_r\", vmin=0, vmax=255); plt.show() In\u00a0[6]: Copied! <pre># Implemente sua solu\u00e7\u00e3o aqui...\n</pre> # Implemente sua solu\u00e7\u00e3o aqui...   In\u00a0[8]: Copied! <pre>#Implemente seu c\u00f3digo\n</pre> #Implemente seu c\u00f3digo      In\u00a0[22]: Copied! <pre>%matplotlib inline\nimport cv2\nfrom matplotlib import pyplot as plt\nimport numpy as np\nimport math\n\nimg = cv2.imread('formas.png')\nimg = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n\nplt.figure(figsize = (10,10))\nplt.imshow(img); plt.show()\n</pre> %matplotlib inline import cv2 from matplotlib import pyplot as plt import numpy as np import math  img = cv2.imread('formas.png') img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)  plt.figure(figsize = (10,10)) plt.imshow(img); plt.show() In\u00a0[28]: Copied! <pre>img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n\nedges = cv2.Canny(img_gray,50,150)\n\n\nlines = cv2.HoughLinesP(edges, 1, np.pi/180, 200, minLineLength=100, maxLineGap=10)\n\nhough_img_rgb = cv2.cvtColor(edges, cv2.COLOR_GRAY2BGR)\n\nfor line in lines:\n    x1, y1, x2, y2 = line[0]\n    cv2.line(hough_img_rgb, (x1, y1), (x2, y2), (255, 0, 255), 5)\n\n\nplt.figure(figsize = (10,10))\nplt.imshow(hough_img_rgb); plt.show()\n</pre> img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)  edges = cv2.Canny(img_gray,50,150)   lines = cv2.HoughLinesP(edges, 1, np.pi/180, 200, minLineLength=100, maxLineGap=10)  hough_img_rgb = cv2.cvtColor(edges, cv2.COLOR_GRAY2BGR)  for line in lines:     x1, y1, x2, y2 = line[0]     cv2.line(hough_img_rgb, (x1, y1), (x2, y2), (255, 0, 255), 5)   plt.figure(figsize = (10,10)) plt.imshow(hough_img_rgb); plt.show() In\u00a0[11]: Copied! <pre>#Implemente seu c\u00f3digo\n</pre> #Implemente seu c\u00f3digo      In\u00a0[34]: Copied! <pre>#Implemente seu c\u00f3digo\n</pre> #Implemente seu c\u00f3digo      In\u00a0[14]: Copied! <pre>from IPython.display import Image\nImage(open('dilata\u00e7\u00e3o.gif','rb').read())\n</pre> from IPython.display import Image Image(open('dilata\u00e7\u00e3o.gif','rb').read()) Out[14]: In\u00a0[58]: Copied! <pre>img = cv2.imread('j.png',0)\n\n\nkernel = np.ones((5,5),np.uint8)\n\ndilation = cv2.dilate(img,kernel,iterations = 1)\n\n\n\nplt.subplot(121),plt.imshow(img, cmap=\"gray\", vmin=0, vmax=255)\nplt.subplot(122),plt.imshow(dilation, cmap=\"gray\", vmin=0, vmax=255)\nplt.show()\n</pre>  img = cv2.imread('j.png',0)   kernel = np.ones((5,5),np.uint8)  dilation = cv2.dilate(img,kernel,iterations = 1)    plt.subplot(121),plt.imshow(img, cmap=\"gray\", vmin=0, vmax=255) plt.subplot(122),plt.imshow(dilation, cmap=\"gray\", vmin=0, vmax=255) plt.show() In\u00a0[59]: Copied! <pre>img = cv2.imread('j.png',0)\n\ndst = img.copy()\nkernel = np.ones((5,5),np.uint8)\n\ndilation = cv2.dilate(img,kernel,iterations = 1)\n\ndst = dilation - img\n\nplt.subplot(121),plt.imshow(img, cmap=\"gray\", vmin=0, vmax=255)\nplt.subplot(122),plt.imshow(dst, cmap=\"gray\", vmin=0, vmax=255)\nplt.show()\n</pre>  img = cv2.imread('j.png',0)  dst = img.copy() kernel = np.ones((5,5),np.uint8)  dilation = cv2.dilate(img,kernel,iterations = 1)  dst = dilation - img  plt.subplot(121),plt.imshow(img, cmap=\"gray\", vmin=0, vmax=255) plt.subplot(122),plt.imshow(dst, cmap=\"gray\", vmin=0, vmax=255) plt.show() In\u00a0[60]: Copied! <pre>img = cv2.imread('j.png',0)\n\n# Criar e visualizar elementos estruturantes de tamanho 5x5\ntamanho = (5, 5)\n\n# 1. Elemento estruturante retangular\nkernel_retangular = cv2.getStructuringElement(cv2.MORPH_RECT, tamanho)\n\n# 2. Elemento estruturante el\u00edptico\nkernel_eliptico = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, tamanho)\n\n# 3. Elemento estruturante em forma de cruz\nkernel_cruz = cv2.getStructuringElement(cv2.MORPH_CROSS, tamanho)\n\n\n# Aplicar opera\u00e7\u00f5es morfol\u00f3gicas\nimg_dilated_rect = cv2.dilate(img, kernel_retangular, iterations=1)\nimg_dilated_ellipse = cv2.dilate(img, kernel_eliptico, iterations=1)\nimg_dilated_cross = cv2.dilate(img, kernel_cruz, iterations=1)\n# contorno da imagem\nborder_diff_rect = img_dilated_rect - img\nborder_diff_ellipse = img_dilated_ellipse - img\nborder_diff_cross = img_dilated_cross - img\n\n\n\nplt.subplot(131), plt.imshow(border_diff_rect, cmap=\"gray\", vmin=0, vmax=255)\nplt.subplot(132), plt.imshow(border_diff_ellipse, cmap=\"gray\", vmin=0, vmax=255)\nplt.subplot(133), plt.imshow(border_diff_cross, cmap=\"gray\", vmin=0, vmax=255)\nplt.show()\n</pre>  img = cv2.imread('j.png',0)  # Criar e visualizar elementos estruturantes de tamanho 5x5 tamanho = (5, 5)  # 1. Elemento estruturante retangular kernel_retangular = cv2.getStructuringElement(cv2.MORPH_RECT, tamanho)  # 2. Elemento estruturante el\u00edptico kernel_eliptico = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, tamanho)  # 3. Elemento estruturante em forma de cruz kernel_cruz = cv2.getStructuringElement(cv2.MORPH_CROSS, tamanho)   # Aplicar opera\u00e7\u00f5es morfol\u00f3gicas img_dilated_rect = cv2.dilate(img, kernel_retangular, iterations=1) img_dilated_ellipse = cv2.dilate(img, kernel_eliptico, iterations=1) img_dilated_cross = cv2.dilate(img, kernel_cruz, iterations=1) # contorno da imagem border_diff_rect = img_dilated_rect - img border_diff_ellipse = img_dilated_ellipse - img border_diff_cross = img_dilated_cross - img    plt.subplot(131), plt.imshow(border_diff_rect, cmap=\"gray\", vmin=0, vmax=255) plt.subplot(132), plt.imshow(border_diff_ellipse, cmap=\"gray\", vmin=0, vmax=255) plt.subplot(133), plt.imshow(border_diff_cross, cmap=\"gray\", vmin=0, vmax=255) plt.show()  In\u00a0[17]: Copied! <pre>from IPython.display import Image\nImage(open('erosao.gif','rb').read())\n</pre> from IPython.display import Image Image(open('erosao.gif','rb').read()) Out[17]: In\u00a0[61]: Copied! <pre>img = cv2.imread('j.png',0)\n\n\ndst = img.copy()\nkernel = cv2.getStructuringElement(cv2.MORPH_RECT, (5,5))\n\nerode = cv2.erode(img,kernel,iterations = 1)\n\nplt.subplot(121),plt.imshow(img, cmap=\"gray\", vmin=0, vmax=255)\nplt.subplot(122),plt.imshow(erode, cmap=\"gray\", vmin=0, vmax=255)\nplt.show()\n</pre>  img = cv2.imread('j.png',0)   dst = img.copy() kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (5,5))  erode = cv2.erode(img,kernel,iterations = 1)  plt.subplot(121),plt.imshow(img, cmap=\"gray\", vmin=0, vmax=255) plt.subplot(122),plt.imshow(erode, cmap=\"gray\", vmin=0, vmax=255) plt.show() In\u00a0[62]: Copied! <pre>img = cv.imread('j-noise.png',0)\n\nkernel = cv2.getStructuringElement(cv2.MORPH_RECT, (5,5))\n\nopening = cv2.morphologyEx(img, cv2.MORPH_OPEN, kernel)\n\n\n\nplt.subplot(121),plt.imshow(img, cmap=\"gray\", vmin=0, vmax=255)\nplt.subplot(122),plt.imshow(opening, cmap=\"gray\", vmin=0, vmax=255)\nplt.show()\n</pre>  img = cv.imread('j-noise.png',0)  kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (5,5))  opening = cv2.morphologyEx(img, cv2.MORPH_OPEN, kernel)    plt.subplot(121),plt.imshow(img, cmap=\"gray\", vmin=0, vmax=255) plt.subplot(122),plt.imshow(opening, cmap=\"gray\", vmin=0, vmax=255) plt.show()  In\u00a0[63]: Copied! <pre>img = cv2.imread('holes.png',0)\n\n\nkernel = cv2.getStructuringElement(cv2.MORPH_RECT, (5,5))\n\nclosing = cv2.morphologyEx(img, cv2.MORPH_CLOSE, kernel)\n\n\nplt.subplot(121),plt.imshow(img, cmap=\"gray\", vmin=0, vmax=255)\nplt.subplot(122),plt.imshow(closing, cmap=\"gray\", vmin=0, vmax=255)\nplt.show()\n</pre>  img = cv2.imread('holes.png',0)   kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (5,5))  closing = cv2.morphologyEx(img, cv2.MORPH_CLOSE, kernel)   plt.subplot(121),plt.imshow(img, cmap=\"gray\", vmin=0, vmax=255) plt.subplot(122),plt.imshow(closing, cmap=\"gray\", vmin=0, vmax=255) plt.show() In\u00a0[\u00a0]: Copied! <pre>### seu c\u00f3digo ###\n</pre> ### seu c\u00f3digo ###"},{"location":"aulas/PDI/lab06/Transformada-Hough-morfologia.html#transformada-de-hough","title":"Transformada de Hough\u00b6","text":"<p>A Transformada de Hough \u00e9 uma t\u00e9cnica poderosa para detec\u00e7\u00e3o de padr\u00f5es geom\u00e9tricos em imagens, como linhas e c\u00edrculos. Esta t\u00e9cnica \u00e9 particularmente \u00fatil quando:</p> <ul> <li>Os padr\u00f5es est\u00e3o parcialmente oclusos ou fragmentados</li> <li>H\u00e1 ru\u00eddo significativo na imagem</li> <li>Existem outros objetos ou caracter\u00edsticas na imagem</li> </ul> <p>A transformada funciona mapeando pontos da imagem para um espa\u00e7o de par\u00e2metros, onde os padr\u00f5es podem ser identificados como picos em um acumulador.</p>"},{"location":"aulas/PDI/lab06/Transformada-Hough-morfologia.html#deteccao-de-circulos","title":"DETEC\u00c7\u00c3O DE CIRCULOS\u00b6","text":"<p>Vamos fazer a dete\u00e7\u00e3o de circulos da imagem forma.</p>"},{"location":"aulas/PDI/lab06/Transformada-Hough-morfologia.html#parametros-da-transformada-de-hough-para-circulos","title":"Par\u00e2metros da Transformada de Hough para C\u00edrculos\u00b6","text":"<p>O resultado n\u00e3o ficou bom, pois h\u00e1 muitos falsos positivos detectados, neste caso precisamos alterar os parametros da transformada de hough.</p> <p>Vamos ver o que \u00e9 cada um deles.</p>"},{"location":"aulas/PDI/lab06/Transformada-Hough-morfologia.html#sintaxe","title":"Sintaxe:\u00b6","text":"<p><code>circles=cv2.HoughCircles(image,method=cv2.HOUGH_GRADIENT,dp,minDist,param1,param2,minRadius,maxRadius)</code></p>"},{"location":"aulas/PDI/lab06/Transformada-Hough-morfologia.html#parametros","title":"Par\u00e2metros:\u00b6","text":"<ul> <li>dp: Rela\u00e7\u00e3o entre o tamanho da imagem e o tamanho do acumulador. Um valor maior de dp detecta bordas mais t\u00eanues.</li> <li>minDist: Dist\u00e2ncia m\u00ednima entre os centros dos c\u00edrculos detectados.</li> <li>param1: Valor do gradiente usado para detec\u00e7\u00e3o de bordas (limiar superior para o detector Canny).</li> <li>param2: Limiar do acumulador. Valores mais baixos detectam mais c\u00edrculos (incluindo falsos positivos).</li> <li>minRadius: Raio m\u00ednimo dos c\u00edrculos a serem detectados (em pixels).</li> <li>maxRadius: Raio m\u00e1ximo dos c\u00edrculos a serem detectados (em pixels).</li> </ul>"},{"location":"aulas/PDI/lab06/Transformada-Hough-morfologia.html#desafio-1","title":"DESAFIO 1\u00b6","text":"<p>Fa\u00e7a a altera\u00e7\u00e3o dos parametros para a transformada de Hough afim de detectar apenas os circulos da imagem.</p> <p>Dica: Altere um parametro por vez e analise o resultado.</p>"},{"location":"aulas/PDI/lab06/Transformada-Hough-morfologia.html#desafio-2","title":"DESAFIO 2\u00b6","text":"<p>Desenvolva um pipeline de processamento digital de imagens incluindo Transformada de Hough Circles para detectar moedas espalhadas sobre mesa. Note que o seu sistema deve ser capaz de diferenciar o valor da moeda por sua dimens\u00e3o e contar quantas imagens de cada valor est\u00e3o expostas.</p> <p></p>"},{"location":"aulas/PDI/lab06/Transformada-Hough-morfologia.html#deteccao-de-retas","title":"DETEC\u00c7\u00c3O DE RETAS\u00b6","text":"<p>A detec\u00e7\u00e3o de retas pode ser realizada utilizando a Transformada de Hough para Linhas, implementada nas fun\u00e7\u00f5es cv2.HoughLines() e cv2.HoughLinesP(). A vers\u00e3o probabil\u00edstica (HoughLinesP) melhora a estimativa das linhas detectadas ao considerar apenas pontos significativos.</p>"},{"location":"aulas/PDI/lab06/Transformada-Hough-morfologia.html#sintaxe","title":"Sintaxe:\u00b6","text":"<pre>cv2.HoughLinesP(image, rho, theta, threshold, minLineLength=None, maxLineGap=None)\n</pre>"},{"location":"aulas/PDI/lab06/Transformada-Hough-morfologia.html#parametros","title":"Par\u00e2metros:\u00b6","text":"<ul> <li>image: Imagem de entrada em escala de cinza.</li> <li>rho: Resolu\u00e7\u00e3o da dist\u00e2ncia no acumulador, em pixels.</li> <li>theta: Resolu\u00e7\u00e3o angular no acumulador, em radianos (normalmente 1 grau = \u03c0/180).</li> <li>threshold: Limiar m\u00ednimo de votos no acumulador para validar uma linha.</li> <li>minLineLength: Comprimento m\u00ednimo para considerar um segmento como linha.</li> <li>maxLineGap: Dist\u00e2ncia m\u00e1xima entre pontos para serem considerados na mesma linha.</li> </ul>"},{"location":"aulas/PDI/lab06/Transformada-Hough-morfologia.html#desafio-3","title":"DESAFIO 3\u00b6","text":"<p>Fa\u00e7a a altera\u00e7\u00e3o dos parametros para a transformada de Hough afim de detectar todas as linhas da imagem.</p> <p>Dica: Altere um parametro por vez e analise o resultado.</p>"},{"location":"aulas/PDI/lab06/Transformada-Hough-morfologia.html#transformada-de-hough-e-filtragem-por-angulo","title":"Transformada de Hough e Filtragem por \u00c2ngulo\u00b6","text":"<p>Para aplica\u00e7\u00f5es avan\u00e7adas, podemos filtrar os resultados com base no \u00e2ngulo das linhas detectadas.</p>"},{"location":"aulas/PDI/lab06/Transformada-Hough-morfologia.html#calculo-do-angulo-de-uma-reta","title":"C\u00e1lculo do \u00c2ngulo de uma Reta\u00b6","text":"<p>A Transformada de Hough detecta linhas retas identificando pontos alinhados em uma imagem de bordas. Cada linha detectada \u00e9 representada por dois pontos:</p> <ul> <li>$ (x_1, y_1) $ - Primeiro ponto da linha</li> <li>$ (x_2, y_2) $ - Segundo ponto da linha</li> </ul> <p>A partir desses pontos, podemos calcular o \u00e2ngulo da linha usando a seguinte f\u00f3rmula:</p> <p>Cada linha detectada em <code>HoughLinesP</code> \u00e9 representada por dois pontos $(x_1, y_1)$ e $(x_2, y_2)$. O \u00e2ngulo $\\theta$  da reta pode ser calculado com:</p> <p>$$ \\theta = \\arctan \\left( \\frac{y_2 - y_1}{x_2 - x_1} \\right) $$</p> <p>Para converter para graus:</p> <p>$$ \\theta_{graus} = \\theta \\times \\frac{180}{\\pi} $$</p>"},{"location":"aulas/PDI/lab06/Transformada-Hough-morfologia.html#filtro-de-linhas-por-angulo","title":"Filtro de Linhas por \u00c2ngulo\u00b6","text":"<p>Podemos definir um intervalo de \u00e2ngulos desejado para filtrar as linhas:</p> <ul> <li>Linhas verticais: $\\theta \\approx 90^\\circ$</li> <li>Linhas horizontais: $\\theta \\approx 0^\\circ$ ou $180^\\circ$</li> <li>Linhas inclinadas: qualquer outro intervalo necess\u00e1rio.</li> </ul>"},{"location":"aulas/PDI/lab06/Transformada-Hough-morfologia.html#pseudocodigo","title":"pseudoc\u00f3digo\u00b6","text":"<pre>    for line in lines:\n        x1, y1, x2, y2 = line[0]\n        \n        # Calcular o \u00e2ngulo da linha\n        angle_radianos = np.arctan2(y2 - y1, x2 - x1)\n        angle_graus = np.degrees(angle_radianos)\n\n    \n</pre>"},{"location":"aulas/PDI/lab06/Transformada-Hough-morfologia.html#desafio-4","title":"DESAFIO 4\u00b6","text":"<p>Voc\u00ea recebeu a imagem de uma rodovia e precisa detectar as linhas das faixas de tr\u00e2nsito usando t\u00e9cnicas de processamento de imagem com a Transformada de Hough.</p> <p>Note que o seu sistema deve ser inteligente o suficiente para detectar apenas as faixas de tr\u00e2nsito, ignorando outros segmentos de reta que possam aparecer na imagem. Para isso, ser\u00e1 necess\u00e1rio um pipeline de processamento de imagem adequado. Crie e aplique uma m\u00e1scara para isolar a estrada.</p>"},{"location":"aulas/PDI/lab06/Transformada-Hough-morfologia.html#morfologia-matematica","title":"MORFOLOGIA MATEM\u00c1TICA\u00b6","text":"<p>A morfologia matem\u00e1tica \u00e9 um conjunto de t\u00e9cnicas de processamento de imagens baseadas na teoria dos conjuntos. Estas opera\u00e7\u00f5es s\u00e3o fundamentais para:</p> <ul> <li>Extra\u00e7\u00e3o de componentes de imagens \u00fateis para representa\u00e7\u00e3o e descri\u00e7\u00e3o de formas</li> <li>Pr\u00e9-processamento e p\u00f3s-processamento em tarefas de vis\u00e3o computacional</li> <li>Filtragem, afinamento e poda de regi\u00f5es</li> </ul> <p>As opera\u00e7\u00f5es morfol\u00f3gicas trabalham com dois elementos principais:</p> <ol> <li>Imagem: Geralmente bin\u00e1ria (0s e 1s) ou em escala de cinza</li> <li>Elemento Estruturante: Uma pequena matriz que define como a opera\u00e7\u00e3o afetar\u00e1 a imagem</li> </ol>"},{"location":"aulas/PDI/lab06/Transformada-Hough-morfologia.html#operacoes-basicas","title":"Opera\u00e7\u00f5es B\u00e1sicas\u00b6","text":"<p>As duas opera\u00e7\u00f5es fundamentais da morfologia matem\u00e1tica s\u00e3o:</p> <ul> <li>Dilata\u00e7\u00e3o: Expande as regi\u00f5es claras (1s) da imagem</li> <li>Eros\u00e3o: Reduz as regi\u00f5es claras da imagem</li> </ul> <p>A partir destas opera\u00e7\u00f5es b\u00e1sicas, podemos criar opera\u00e7\u00f5es compostas como:</p> <ul> <li>Abertura: Eros\u00e3o seguida de dilata\u00e7\u00e3o (remove pequenos objetos)</li> <li>Fechamento: Dilata\u00e7\u00e3o seguida de eros\u00e3o (preenche pequenos buracos)</li> </ul>"},{"location":"aulas/PDI/lab06/Transformada-Hough-morfologia.html#dilatacao-binaria","title":"DILATA\u00c7\u00c3O BIN\u00c1RIA\u00b6","text":"<p>\u00c9 uma transforma\u00e7\u00e3o morfol\u00f3gica que combina dois conjuntos usando adi\u00e7\u00e3o vetorial. Como o nome diz, o resultado ser\u00e1 uma imagem \u201cengordada\u201d.</p>"},{"location":"aulas/PDI/lab06/Transformada-Hough-morfologia.html#detectando-contorno-com-dilatacao","title":"Detectando contorno com dilata\u00e7\u00e3o\u00b6","text":""},{"location":"aulas/PDI/lab06/Transformada-Hough-morfologia.html#elementos-estruturantes","title":"Elementos Estruturantes\u00b6","text":""},{"location":"aulas/PDI/lab06/Transformada-Hough-morfologia.html#o-que-e-um-elemento-estruturante","title":"O que \u00e9 um Elemento Estruturante?\u00b6","text":"<p>O elemento estruturante (tamb\u00e9m chamado de kernel ou m\u00e1scara) \u00e9 uma matriz pequena que define como as opera\u00e7\u00f5es morfol\u00f3gicas afetar\u00e3o a imagem. Ele funciona como uma \"sonda\" que examina cada pixel da imagem e sua vizinhan\u00e7a para determinar o valor do pixel na imagem de sa\u00edda.</p> <p>Caracter\u00edsticas importantes:</p> <ul> <li>Possui uma origem (ponto central)</li> <li>Tem uma forma espec\u00edfica (ret\u00e2ngulo, c\u00edrculo, cruz, etc.)</li> <li>Possui um tamanho que determina sua \u00e1rea de influ\u00eancia</li> </ul>"},{"location":"aulas/PDI/lab06/Transformada-Hough-morfologia.html#importancia-do-elemento-estruturante","title":"Import\u00e2ncia do Elemento Estruturante\u00b6","text":"<p>A escolha do elemento estruturante \u00e9 impacta o resultado da opera\u00e7\u00e3o morfol\u00f3gica:</p> <ul> <li>Forma: Influencia a dire\u00e7\u00e3o e o padr\u00e3o da transforma\u00e7\u00e3o</li> <li>Tamanho: Determina a escala da transforma\u00e7\u00e3o (objetos menores que o elemento estruturante podem ser removidos)</li> <li>Orienta\u00e7\u00e3o: Pode ser usado para detectar caracter\u00edsticas direcionais</li> </ul>"},{"location":"aulas/PDI/lab06/Transformada-Hough-morfologia.html#dicas-para-escolher-o-elemento-estruturante","title":"Dicas para escolher o Elemento Estruturante\u00b6","text":"<p>OpenCV oferece tr\u00eas formas b\u00e1sicas:</p> <ul> <li><p>Retangular: <code>cv2.MORPH_RECT</code></p> </li> <li><p>El\u00edptico: <code>cv2.MORPH_ELLIPSE</code></p> </li> <li><p>Cruz: <code>cv2.MORPH_CROSS</code></p> </li> <li><p>Retangular: Bom para opera\u00e7\u00f5es gerais, preserva bordas horizontais e verticais</p> </li> <li><p>El\u00edptico: Produz resultados mais suaves, sem cantos acentuados</p> </li> <li><p>Cruz: Preserva linhas finas horizontais e verticais</p> </li> </ul> <p>Experimenta\u00e7\u00e3o \u00e9 fundamental para encontrar o elemento estruturante ideal para cada aplica\u00e7\u00e3o</p>"},{"location":"aulas/PDI/lab06/Transformada-Hough-morfologia.html#erosao-binaria","title":"EROS\u00c3O BIN\u00c1RIA\u00b6","text":"<p>A eros\u00e3o basicamente encolhe uma imagem e pode ser vista como uma transforma\u00e7\u00e3o morfol\u00f3gica que combina dois conjuntos usando vetores de subtra\u00e7\u00e3o. Ela \u00e9 expressa como a interse\u00e7\u00e3o de A e B.</p>"},{"location":"aulas/PDI/lab06/Transformada-Hough-morfologia.html#abertura-binaria","title":"ABERTURA BIN\u00c1RIA\u00b6","text":"<p>A abertura em geral suaviza o contorno de uma imagem, quebra estreitos e elimina proemin\u00eancias delgadas, a opera\u00e7\u00e3o de abertura e usada tamb\u00e9m para remover ru\u00eddos da imagem.</p>"},{"location":"aulas/PDI/lab06/Transformada-Hough-morfologia.html#fechamento-binario","title":"FECHAMENTO BIN\u00c1RIO\u00b6","text":"<p>O fechamento funde pequenos quebras e alargas golfos estreitos elimina pequenos orif\u00edcios. Se uma abertura cria pequenos vazios na imagem, um fechamento ir\u00e1 preencher ou fechar os vazios, estas opera\u00e7\u00f5es podem remover muitos dos pixels brancos com ru\u00eddos, ou seja basicamente ele e igual a abertura s\u00f3 que primeiramente e feita a dilata\u00e7\u00e3o e ap\u00f3s e feita a eros\u00e3o.</p>"},{"location":"aulas/PDI/lab06/Transformada-Hough-morfologia.html#desafio-5","title":"DESAFIO 5\u00b6","text":"<p>Utilizando a opera\u00e7\u00e3o abertura e depois a opera\u00e7\u00e3o de fechamento bin\u00e1rio, \u00e9 esperado que a imagem volte ao original? Por que?</p>"},{"location":"aulas/PDI/lab06/emulatecla%20-%20Copia.html","title":"emulatecla   Copia","text":"In\u00a0[\u00a0]: Copied! <pre># Programa simples com camera webcam e opencv\\n\nimport math\nimport cv2\nimport os.path\nimport numpy as np\n</pre> # Programa simples com camera webcam e opencv\\n import math import cv2 import os.path import numpy as np In\u00a0[\u00a0]: Copied! <pre>def image_da_webcam(img):\n    #-&gt;&gt;&gt; !!!! FECHE A JANELA COM A TECLA ESC !!!! &lt;&lt;&lt;&lt;-\n    #deve receber a imagem da camera e retornar uma imagems filtrada.\n\n    gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n    gray = cv2.medianBlur(gray,5)\n    saida = cv2.cvtColor(img,cv2.COLOR_BGR2RGB)\n    img_hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n    \n    #detecta os circulos maiores e circula eles\n    circles = cv2.HoughCircles(gray,cv2.HOUGH_GRADIENT,1,20,param1=30,param2=80,minRadius=100,maxRadius=0)\n    circulosDetectados = np.uint16(np.around(circles))\n    for (x, y, r) in circulosDetectados[0,:]:\n        cv2.circle(saida,(x, y), r,(0,0,0),3)\n    \n    # Defini\u00e7\u00e3o dos valores minimo e max da mascara azul\n    blue_lower_hsv = np.array([70, 150, 210])\n    blue_upper_hsv = np.array([100, 255, 240])\n    \n    # Defini\u00e7\u00e3o dos valores minimo e max da mascara vermelha\n    red_lower_hsv = np.array([0, 220, 160])\n    red_upper_hsv = np.array([20, 255, 255])\n\n    # Aplicando a m\u00e1scara azul e vermelha na imagem\n    blue_mask_hsv = cv2.inRange(img_hsv, blue_lower_hsv, blue_upper_hsv)\n    red_mask_hsv = cv2.inRange(img_hsv, red_lower_hsv, red_upper_hsv)\n    both_mask_hsv = cv2.bitwise_or(blue_mask_hsv, red_mask_hsv)\n    \n    # Identificando os contornos para uso posterior de calculo da \u00e1rea\n    contornos, _ = cv2.findContours(both_mask_hsv, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n    mascara_rgb = cv2.cvtColor(both_mask_hsv, cv2.COLOR_GRAY2RGB)\n    \n    # For para calcular a \u00e1rea e o CM, e imprimir na imagem de acordo com a posi\u00e7\u00e3o do eixo X do CM,\\n\",\n    # para que cada informa\u00e7\u00e3o fique do lado do circulo correspondente\\n\",\n    cxV = []\n    cyV = []\n    for i in contornos:\n        area = cv2.contourArea(i)\n        M = cv2.moments(i)\n        cx = int(M['m10']/M['m00'])\n        cy = int(M['m01']/M['m00'])\n        cxV.append(cx)\n        cyV.append(cy)\n\n        tamnho = 20\n        cor = (0,0,0)\n        cv2.line(saida,(cx - tamnho,cy),(cx + tamnho,cy),cor,5)\n        cv2.line(saida,(cx,cy - tamnho),(cx, cy + tamnho),cor,5)\n        fonte = cv2.FONT_HERSHEY_SIMPLEX\n        texto = cx, cy, area\n        if cx &lt;200:\n              origem = (cx+150,cy)\n        else:\n              origem = (cx-470,cy)\n    \n        cv2.putText(saida, str(texto), origem, fonte,1,(0,0,0),2,cv2.LINE_AA)\n   \n        # Tra\u00e7a a reta\n        cor = (0, 0, 0)\n        vetorTamanho = len(cxV)\n        cv2.line(saida,(cxV[0],cyV[0]), (cxV[vetorTamanho-1], cyV[vetorTamanho-1]),cor,5)\n    \n        # Calcula e imprime o \u00e2ngulo da reta\\n\",\n        fonte = cv2.FONT_HERSHEY_SIMPLEX\n        cxT = cxV[0]-cxV[vetorTamanho-1]\n        cyT = cyV[0]-cyV[vetorTamanho-1]\n\n        angulo = math.atan2(cyV[0], cyV[vetorTamanho-1]) - math.atan2(cxV[0], cxV[vetorTamanho-1])\n        texto = str(round(math.degrees(angulo), 2))\n        origem = (cxT-100,cyT-80)\n        cv2.putText(saida, texto, origem, fonte,1,(0,0,0),2,cv2.LINE_AA)\n    \n        return saida\n</pre> def image_da_webcam(img):     #-&gt;&gt;&gt; !!!! FECHE A JANELA COM A TECLA ESC !!!! &lt;&lt;&lt;&lt;-     #deve receber a imagem da camera e retornar uma imagems filtrada.      gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)     gray = cv2.medianBlur(gray,5)     saida = cv2.cvtColor(img,cv2.COLOR_BGR2RGB)     img_hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)          #detecta os circulos maiores e circula eles     circles = cv2.HoughCircles(gray,cv2.HOUGH_GRADIENT,1,20,param1=30,param2=80,minRadius=100,maxRadius=0)     circulosDetectados = np.uint16(np.around(circles))     for (x, y, r) in circulosDetectados[0,:]:         cv2.circle(saida,(x, y), r,(0,0,0),3)          # Defini\u00e7\u00e3o dos valores minimo e max da mascara azul     blue_lower_hsv = np.array([70, 150, 210])     blue_upper_hsv = np.array([100, 255, 240])          # Defini\u00e7\u00e3o dos valores minimo e max da mascara vermelha     red_lower_hsv = np.array([0, 220, 160])     red_upper_hsv = np.array([20, 255, 255])      # Aplicando a m\u00e1scara azul e vermelha na imagem     blue_mask_hsv = cv2.inRange(img_hsv, blue_lower_hsv, blue_upper_hsv)     red_mask_hsv = cv2.inRange(img_hsv, red_lower_hsv, red_upper_hsv)     both_mask_hsv = cv2.bitwise_or(blue_mask_hsv, red_mask_hsv)          # Identificando os contornos para uso posterior de calculo da \u00e1rea     contornos, _ = cv2.findContours(both_mask_hsv, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)     mascara_rgb = cv2.cvtColor(both_mask_hsv, cv2.COLOR_GRAY2RGB)          # For para calcular a \u00e1rea e o CM, e imprimir na imagem de acordo com a posi\u00e7\u00e3o do eixo X do CM,\\n\",     # para que cada informa\u00e7\u00e3o fique do lado do circulo correspondente\\n\",     cxV = []     cyV = []     for i in contornos:         area = cv2.contourArea(i)         M = cv2.moments(i)         cx = int(M['m10']/M['m00'])         cy = int(M['m01']/M['m00'])         cxV.append(cx)         cyV.append(cy)          tamnho = 20         cor = (0,0,0)         cv2.line(saida,(cx - tamnho,cy),(cx + tamnho,cy),cor,5)         cv2.line(saida,(cx,cy - tamnho),(cx, cy + tamnho),cor,5)         fonte = cv2.FONT_HERSHEY_SIMPLEX         texto = cx, cy, area         if cx &lt;200:               origem = (cx+150,cy)         else:               origem = (cx-470,cy)              cv2.putText(saida, str(texto), origem, fonte,1,(0,0,0),2,cv2.LINE_AA)             # Tra\u00e7a a reta         cor = (0, 0, 0)         vetorTamanho = len(cxV)         cv2.line(saida,(cxV[0],cyV[0]), (cxV[vetorTamanho-1], cyV[vetorTamanho-1]),cor,5)              # Calcula e imprime o \u00e2ngulo da reta\\n\",         fonte = cv2.FONT_HERSHEY_SIMPLEX         cxT = cxV[0]-cxV[vetorTamanho-1]         cyT = cyV[0]-cyV[vetorTamanho-1]          angulo = math.atan2(cyV[0], cyV[vetorTamanho-1]) - math.atan2(cxV[0], cxV[vetorTamanho-1])         texto = str(round(math.degrees(angulo), 2))         origem = (cxT-100,cyT-80)         cv2.putText(saida, texto, origem, fonte,1,(0,0,0),2,cv2.LINE_AA)              return saida In\u00a0[\u00a0]: Copied! <pre>cv2.namedWindow(\"\\preview\")\nvc = cv2.VideoCapture(0)\n</pre> cv2.namedWindow(\"\\preview\") vc = cv2.VideoCapture(0) In\u00a0[\u00a0]: Copied! <pre>if vc.isOpened(): # try to get the first frame\n    rval, frame = vc.read()\nelse:\n    rval = False\n</pre> if vc.isOpened(): # try to get the first frame     rval, frame = vc.read() else:     rval = False In\u00a0[\u00a0]: Copied! <pre>while rval:\n    img = image_da_webcam(frame)\n    \n    cv2.imshow(\"\\preview\", img)\n    rval, frame = vc.read()\n    key = cv2.waitKey(20)\n    if key == 27: # exit on ESC\n        break\n</pre> while rval:     img = image_da_webcam(frame)          cv2.imshow(\"\\preview\", img)     rval, frame = vc.read()     key = cv2.waitKey(20)     if key == 27: # exit on ESC         break In\u00a0[\u00a0]: Copied! <pre>cv2.destroyWindow(\"\\preview\")\nvc.release()\n</pre> cv2.destroyWindow(\"\\preview\") vc.release()"},{"location":"aulas/PDI/lab06/emulatecla.html","title":"Emulatecla","text":"In\u00a0[\u00a0]: Copied! <p>Programa simples com camera webcam e opencv que emula precionamento de teclas</p> In\u00a0[\u00a0]: Copied! <pre>import cv2\nimport os,sys, os.path\nimport numpy as np\n</pre> import cv2 import os,sys, os.path import numpy as np In\u00a0[\u00a0]: Copied! <pre>#importes para emular precionamento de teclas\nfrom pynput.keyboard import Key, Controller\nimport pynput\nimport time\nimport random\n</pre> #importes para emular precionamento de teclas from pynput.keyboard import Key, Controller import pynput import time import random In\u00a0[\u00a0]: Copied! <pre>keys = [\n    #Key.up,                                 # UP\n    #Key.down,                               # DOWN\n    #Key.left,                               # LEFT\n    #Key.right,                              # RIGHT\n    pynput.keyboard.KeyCode.from_char('S'),  # A\n    pynput.keyboard.KeyCode.from_char('W'),  # B\n    pynput.keyboard.KeyCode.from_char('a'),  # X\n    #Key.enter,                              # START\n    #Key.shift_r,                            # SELECT\n]\n</pre> keys = [     #Key.up,                                 # UP     #Key.down,                               # DOWN     #Key.left,                               # LEFT     #Key.right,                              # RIGHT     pynput.keyboard.KeyCode.from_char('S'),  # A     pynput.keyboard.KeyCode.from_char('W'),  # B     pynput.keyboard.KeyCode.from_char('a'),  # X     #Key.enter,                              # START     #Key.shift_r,                            # SELECT ] In\u00a0[\u00a0]: Copied! <pre>\n</pre> In\u00a0[\u00a0]: Copied! <pre>#Inicializa o controle \nkeyboard = Controller()\n</pre> #Inicializa o controle  keyboard = Controller() In\u00a0[\u00a0]: Copied! <pre>\n</pre> In\u00a0[\u00a0]: Copied! <pre>#filtro baixo\nimage_lower_hsv1 = np.array([120,130,10])\nimage_upper_hsv1 = np.array([180,255,255])\n#filtro alto\nimage_lower_hsv2 = np.array([0,130,100])\nimage_upper_hsv2 = np.array([30,255,255])\n</pre> #filtro baixo image_lower_hsv1 = np.array([120,130,10]) image_upper_hsv1 = np.array([180,255,255]) #filtro alto image_lower_hsv2 = np.array([0,130,100]) image_upper_hsv2 = np.array([30,255,255]) In\u00a0[\u00a0]: Copied! <pre>\n</pre> In\u00a0[\u00a0]: Copied! <pre>def filtro_de_cor(img_bgr, low_hsv, high_hsv):\n    \"\"\" retorna a imagem filtrada\"\"\"\n    img = cv2.cvtColor(img_bgr,cv2.COLOR_BGR2HSV)\n    mask = cv2.inRange(img, low_hsv, high_hsv)\n    return mask \n</pre> def filtro_de_cor(img_bgr, low_hsv, high_hsv):     \"\"\" retorna a imagem filtrada\"\"\"     img = cv2.cvtColor(img_bgr,cv2.COLOR_BGR2HSV)     mask = cv2.inRange(img, low_hsv, high_hsv)     return mask  In\u00a0[\u00a0]: Copied! <pre>def mascara_or(mask1, mask2):\n\n    \"\"\" retorna a mascara or\"\"\"\n    mask = cv2.bitwise_or(mask1, mask2)\n    return mask\n</pre> def mascara_or(mask1, mask2):      \"\"\" retorna a mascara or\"\"\"     mask = cv2.bitwise_or(mask1, mask2)     return mask In\u00a0[\u00a0]: Copied! <pre>def mascara_and(mask1, mask2):\n     \"\"\" retorna a mascara and\"\"\"\n     mask = cv2.bitwise_and(mask1, mask2)\n     \n     return mask\n</pre> def mascara_and(mask1, mask2):      \"\"\" retorna a mascara and\"\"\"      mask = cv2.bitwise_and(mask1, mask2)            return mask In\u00a0[\u00a0]: Copied! <pre>def desenha_cruz(img, cX,cY, size, color):\n     \"\"\" faz a cruz no ponto cx cy\"\"\"\n     cv2.line(img,(cX - size,cY),(cX + size,cY),color,5)\n     cv2.line(img,(cX,cY - size),(cX, cY + size),color,5)    \n</pre> def desenha_cruz(img, cX,cY, size, color):      \"\"\" faz a cruz no ponto cx cy\"\"\"      cv2.line(img,(cX - size,cY),(cX + size,cY),color,5)      cv2.line(img,(cX,cY - size),(cX, cY + size),color,5)     In\u00a0[\u00a0]: Copied! <pre>def escreve_texto(img, text, origem, color):\n     \"\"\" faz a cruz no ponto cx cy\"\"\"\n \n     font = cv2.FONT_HERSHEY_SIMPLEX\n     \n     cv2.putText(img, str(text), origem, font,1,color,2,cv2.LINE_AA)\n</pre> def escreve_texto(img, text, origem, color):      \"\"\" faz a cruz no ponto cx cy\"\"\"        font = cv2.FONT_HERSHEY_SIMPLEX            cv2.putText(img, str(text), origem, font,1,color,2,cv2.LINE_AA) In\u00a0[\u00a0]: Copied! <pre>\n</pre> In\u00a0[\u00a0]: Copied! <pre>def image_da_webcam(img):\n    \"\"\"\n    -&gt;&gt;&gt; !!!! FECHE A JANELA COM A TECLA ESC !!!! &lt;&lt;&lt;&lt;-\n        deve receber a imagem da camera e retornar uma imagems filtrada.\n    \"\"\"  \n    mask_hsv1 = filtro_de_cor(img, image_lower_hsv1, image_upper_hsv1)\n    mask_hsv2 = filtro_de_cor(img, image_lower_hsv2, image_upper_hsv2)\n    \n    mask_hsv = mascara_or(mask_hsv1, mask_hsv2)\n    \n    contornos, _ = cv2.findContours(mask_hsv, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE) \n\n    mask_rgb = cv2.cvtColor(mask_hsv, cv2.COLOR_GRAY2RGB) \n    contornos_img = mask_rgb.copy()\n    \n    maior = None\n    maior_area = 0\n    for c in contornos:\n        area = cv2.contourArea(c)\n        \n        if area &gt; maior_area:\n            maior_area = area\n            maior = c\n            \n    escreve_texto(contornos_img, maior_area, (250,250), (255,255,0))\n    if maior_area &gt;=20000:\n        #escreve no teclado\n        texto = 'Perto W'\n        origem = (200,50)\n        escreve_texto(contornos_img, texto, origem, (0,0,255))\n        print('Tecla: ', keys[1])\n        keyboard.press(keys[1])\n        time.sleep(0.1)\n        keyboard.release(keys[1])\n    elif maior_area &lt;= 2000:\n        texto = 'Muito longe nao escreve'\n        origem = (200,50)\n        escreve_texto(contornos_img, texto, origem, (0,0,255))\n    else:\n        texto = 'Longe S'\n        origem = (200,50)\n        escreve_texto(contornos_img, texto, origem, (0,0,255))\n        print('Tecla: ', keys[0])\n        keyboard.press(keys[0])\n        time.sleep(0.1)\n        keyboard.release(keys[0])\n    \n    M = cv2.moments(maior)\n\n    # Verifica se existe alguma para calcular, se sim calcula e exibe no display\n    if M[\"m00\"] != 0:\n        cX = int(M[\"m10\"] / M[\"m00\"])\n        cY = int(M[\"m01\"] / M[\"m00\"])\n        \n        cv2.drawContours(contornos_img, [maior], -1, [255, 0, 0], 5)\n       \n        #faz a cruz no centro de massa\n        desenha_cruz(contornos_img, cX,cY, 20, (0,0,255))\n\n        \n        # Para escrever vamos definir uma fonte \n        texto = cY , cX\n        origem = (0,50)\n        escreve_texto(contornos_img, texto, origem, (0,255,0))\n            \n    else:\n    # se n\u00e3o existe nada para segmentar\n        cX, cY = 0, 0\n        # Para escrever vamos definir uma fonte \n        texto = ' '\n        origem = (0,50)\n        escreve_texto(contornos_img, texto, origem, (0,0,255))\n    \n\n\n    return contornos_img\n</pre> def image_da_webcam(img):     \"\"\"     -&gt;&gt;&gt; !!!! FECHE A JANELA COM A TECLA ESC !!!! &lt;&lt;&lt;&lt;-         deve receber a imagem da camera e retornar uma imagems filtrada.     \"\"\"       mask_hsv1 = filtro_de_cor(img, image_lower_hsv1, image_upper_hsv1)     mask_hsv2 = filtro_de_cor(img, image_lower_hsv2, image_upper_hsv2)          mask_hsv = mascara_or(mask_hsv1, mask_hsv2)          contornos, _ = cv2.findContours(mask_hsv, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)       mask_rgb = cv2.cvtColor(mask_hsv, cv2.COLOR_GRAY2RGB)      contornos_img = mask_rgb.copy()          maior = None     maior_area = 0     for c in contornos:         area = cv2.contourArea(c)                  if area &gt; maior_area:             maior_area = area             maior = c                  escreve_texto(contornos_img, maior_area, (250,250), (255,255,0))     if maior_area &gt;=20000:         #escreve no teclado         texto = 'Perto W'         origem = (200,50)         escreve_texto(contornos_img, texto, origem, (0,0,255))         print('Tecla: ', keys[1])         keyboard.press(keys[1])         time.sleep(0.1)         keyboard.release(keys[1])     elif maior_area &lt;= 2000:         texto = 'Muito longe nao escreve'         origem = (200,50)         escreve_texto(contornos_img, texto, origem, (0,0,255))     else:         texto = 'Longe S'         origem = (200,50)         escreve_texto(contornos_img, texto, origem, (0,0,255))         print('Tecla: ', keys[0])         keyboard.press(keys[0])         time.sleep(0.1)         keyboard.release(keys[0])          M = cv2.moments(maior)      # Verifica se existe alguma para calcular, se sim calcula e exibe no display     if M[\"m00\"] != 0:         cX = int(M[\"m10\"] / M[\"m00\"])         cY = int(M[\"m01\"] / M[\"m00\"])                  cv2.drawContours(contornos_img, [maior], -1, [255, 0, 0], 5)                 #faz a cruz no centro de massa         desenha_cruz(contornos_img, cX,cY, 20, (0,0,255))                   # Para escrever vamos definir uma fonte          texto = cY , cX         origem = (0,50)         escreve_texto(contornos_img, texto, origem, (0,255,0))                  else:     # se n\u00e3o existe nada para segmentar         cX, cY = 0, 0         # Para escrever vamos definir uma fonte          texto = ' '         origem = (0,50)         escreve_texto(contornos_img, texto, origem, (0,0,255))            return contornos_img In\u00a0[\u00a0]: Copied! <pre>cv2.namedWindow(\"preview\")\n# define a entrada de video para webcam\nvc = cv2.VideoCapture(0)\n</pre> cv2.namedWindow(\"preview\") # define a entrada de video para webcam vc = cv2.VideoCapture(0) <p>vc = cv2.VideoCapture(\"video.mp4\") # para ler um video mp4</p> In\u00a0[\u00a0]: Copied! <pre>#configura o tamanho da janela \nvc.set(cv2.CAP_PROP_FRAME_WIDTH, 640)\nvc.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)\n</pre> #configura o tamanho da janela  vc.set(cv2.CAP_PROP_FRAME_WIDTH, 640) vc.set(cv2.CAP_PROP_FRAME_HEIGHT, 480) In\u00a0[\u00a0]: Copied! <pre>if vc.isOpened(): # try to get the first frame\n    rval, frame = vc.read()\nelse:\n    rval = False\n</pre> if vc.isOpened(): # try to get the first frame     rval, frame = vc.read() else:     rval = False In\u00a0[\u00a0]: Copied! <pre>while rval:\n    \n    img = image_da_webcam(frame) # passa o frame para a fun\u00e7\u00e3o imagem_da_webcam e recebe em img imagem tratada\n\n\n\n    cv2.imshow(\"preview\", img)\n    cv2.imshow(\"original\", frame)\n    rval, frame = vc.read()\n    key = cv2.waitKey(20)\n    if key == 27: # exit on ESC\n        break\n</pre> while rval:          img = image_da_webcam(frame) # passa o frame para a fun\u00e7\u00e3o imagem_da_webcam e recebe em img imagem tratada        cv2.imshow(\"preview\", img)     cv2.imshow(\"original\", frame)     rval, frame = vc.read()     key = cv2.waitKey(20)     if key == 27: # exit on ESC         break In\u00a0[\u00a0]: Copied! <pre>cv2.destroyWindow(\"preview\")\nvc.release()\n</pre> cv2.destroyWindow(\"preview\") vc.release()"},{"location":"aulas/PDI/lab06/motion.html","title":"Motion","text":"In\u00a0[\u00a0]: Copied! In\u00a0[\u00a0]: Copied! <pre>import cv2\nfrom datetime import datetime\n</pre> import cv2 from datetime import datetime In\u00a0[\u00a0]: Copied! <pre>BLUR_KERNEL_P0 = (21, 21)\nBLUR_KERNEL_P1 = (11, 11)\nLEARNING_RATE = 0.001\nMIN_CONTOUR_AREA = 625\n</pre> BLUR_KERNEL_P0 = (21, 21) BLUR_KERNEL_P1 = (11, 11) LEARNING_RATE = 0.001 MIN_CONTOUR_AREA = 625 In\u00a0[\u00a0]: Copied! <pre>feed = cv2.VideoCapture(\"people-walking.mp4\")\n</pre> feed = cv2.VideoCapture(\"people-walking.mp4\") In\u00a0[\u00a0]: Copied! <pre>backSub = cv2.createBackgroundSubtractorKNN()\n#backSub = cv.createBackgroundSubtractorMOG2()\n</pre> backSub = cv2.createBackgroundSubtractorKNN() #backSub = cv.createBackgroundSubtractorMOG2() In\u00a0[\u00a0]: Copied! <pre>while True:\n    (grabbed, frame) = feed.read()\n\n    if not grabbed:\n        break\n\n    frame_blured = cv2.GaussianBlur(frame, BLUR_KERNEL_P0, 0)\n#    backSubmask = backSub.apply(frame_blured, learningRate=LEARNING_RATE)\n    backSubmask = backSub.apply(frame_blured)\n\n    thresh = cv2.GaussianBlur(backSubmask, BLUR_KERNEL_P1, 0)\n    thresh = cv2.dilate(thresh, None, iterations=2)\n\n    (cnts, _) = cv2.findContours(\n        thresh.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE\n    )\n\n    area_in_motion = 0\n    for cnt in cnts:\n        area = cv2.contourArea(cnt)\n        if  area &lt; MIN_CONTOUR_AREA:\n            continue\n\n        area_in_motion += area\n        (x, y, w, h) = cv2.boundingRect(cnt)\n        cv2.rectangle(frame, (x, y), (x+w, y+h), (128, 255, 255), 2)\n\n    cv2.putText(\n        frame, datetime.now().strftime(\"%A %d %B %Y %I:%M:%S%p\"),\n        (10, frame.shape[0] - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.35, (0, 0, 255), 1\n    )\n    # Show results\n    cv2.imshow(\"Feed\", frame)\n    cv2.imshow(\"Thresh\", thresh)\n\n    # Wait for key 'ESC' to quit\n    key = cv2.waitKey(1) &amp; 0xFF\n    if key == 27:\n        break\n</pre> while True:     (grabbed, frame) = feed.read()      if not grabbed:         break      frame_blured = cv2.GaussianBlur(frame, BLUR_KERNEL_P0, 0) #    backSubmask = backSub.apply(frame_blured, learningRate=LEARNING_RATE)     backSubmask = backSub.apply(frame_blured)      thresh = cv2.GaussianBlur(backSubmask, BLUR_KERNEL_P1, 0)     thresh = cv2.dilate(thresh, None, iterations=2)      (cnts, _) = cv2.findContours(         thresh.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE     )      area_in_motion = 0     for cnt in cnts:         area = cv2.contourArea(cnt)         if  area &lt; MIN_CONTOUR_AREA:             continue          area_in_motion += area         (x, y, w, h) = cv2.boundingRect(cnt)         cv2.rectangle(frame, (x, y), (x+w, y+h), (128, 255, 255), 2)      cv2.putText(         frame, datetime.now().strftime(\"%A %d %B %Y %I:%M:%S%p\"),         (10, frame.shape[0] - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.35, (0, 0, 255), 1     )     # Show results     cv2.imshow(\"Feed\", frame)     cv2.imshow(\"Thresh\", thresh)      # Wait for key 'ESC' to quit     key = cv2.waitKey(1) &amp; 0xFF     if key == 27:         break In\u00a0[\u00a0]: Copied! <pre># That's how you exit\nfeed.release()\ncv2.destroyAllWindows()\n</pre> # That's how you exit feed.release() cv2.destroyAllWindows()"},{"location":"aulas/PDI/lab06/sol_Transformada-Hough-morfologia.html","title":"sol Transformada Hough morfologia","text":"<p>Objetivos da aula:</p> <ul> <li>Conhecer e praticar a Transformada de Hough para linhas e circulos</li> <li>conhecer e praticar com os operadores de dilata\u00e7\u00e3o e eros\u00e3o</li> <li>conhecer e praticar com os operadores de abertura e fechamento</li> </ul> In\u00a0[\u00a0]: Copied! <pre>####----- FAZENDO O DOWNLOAD DAS IMAGENS DO RESPOSIT\u00d3RIO, APENAS PARA FACILITAR -----#####\n## SE ESTIVER RODANDO EM SUA M\u00c1QUINA LOCAL N\u00c3O PRECISA RODAR ESSA CELULA ##\n\n\n!wget https://raw.githubusercontent.com/arnaldojr/cognitivecomputing/master/material/aulas/PDI/lab06/coins.png /content\n!wget https://raw.githubusercontent.com/arnaldojr/cognitivecomputing/master/material/aulas/PDI/lab06/corredor.png /content\n!wget https://raw.githubusercontent.com/arnaldojr/cognitivecomputing/master/material/aulas/PDI/lab06/dilata\u00e7\u00e3o.gif /content\n!wget https://raw.githubusercontent.com/arnaldojr/cognitivecomputing/master/material/aulas/PDI/lab06/erosao.gif /content\n!wget https://raw.githubusercontent.com/arnaldojr/cognitivecomputing/master/material/aulas/PDI/lab06/formas.png /content\n!wget https://raw.githubusercontent.com/arnaldojr/cognitivecomputing/master/material/aulas/PDI/lab06/formas_contorno.png /content\n!wget https://raw.githubusercontent.com/arnaldojr/cognitivecomputing/master/material/aulas/PDI/lab06/formas_contornor.png /content\n!wget https://raw.githubusercontent.com/arnaldojr/cognitivecomputing/master/material/aulas/PDI/lab06/j-noise.png /content\n!wget https://raw.githubusercontent.com/arnaldojr/cognitivecomputing/master/material/aulas/PDI/lab06/j.png /content\n!wget https://raw.githubusercontent.com/arnaldojr/cognitivecomputing/master/material/aulas/PDI/lab06/holes.png /content\n!wget https://raw.githubusercontent.com/arnaldojr/cognitivecomputing/master/material/aulas/PDI/lab06/melancia_filtrada.png /content\n!wget https://raw.githubusercontent.com/arnaldojr/cognitivecomputing/master/material/aulas/PDI/lab06/melancia_filtrada_rgb.png /content\n!wget https://raw.githubusercontent.com/arnaldojr/cognitivecomputing/master/material/aulas/PDI/lab06/moeda1.jpg /content\n!wget https://raw.githubusercontent.com/arnaldojr/cognitivecomputing/master/material/aulas/PDI/lab06/pessoas-gif.gif /content\n!wget https://raw.githubusercontent.com/arnaldojr/cognitivecomputing/master/material/aulas/PDI/lab06/rua.png /content\n!wget https://raw.githubusercontent.com/arnaldojr/cognitivecomputing/master/material/aulas/PDI/lab06/sala.jpg /content\n!wget https://raw.githubusercontent.com/arnaldojr/cognitivecomputing/master/material/aulas/PDI/lab06/sala1.jpg /content\n!wget https://raw.githubusercontent.com/arnaldojr/cognitivecomputing/master/material/aulas/PDI/lab06/sala2.jpg /content\n!wget https://raw.githubusercontent.com/arnaldojr/cognitivecomputing/master/material/aulas/PDI/lab06/sala3.jpg /content\n!wget https://raw.githubusercontent.com/arnaldojr/cognitivecomputing/master/material/aulas/PDI/lab06/sala_res.png /content\n!wget https://raw.githubusercontent.com/arnaldojr/cognitivecomputing/master/material/aulas/PDI/lab06/people-walking.mp4 /content\n</pre>   ####----- FAZENDO O DOWNLOAD DAS IMAGENS DO RESPOSIT\u00d3RIO, APENAS PARA FACILITAR -----##### ## SE ESTIVER RODANDO EM SUA M\u00c1QUINA LOCAL N\u00c3O PRECISA RODAR ESSA CELULA ##   !wget https://raw.githubusercontent.com/arnaldojr/cognitivecomputing/master/material/aulas/PDI/lab06/coins.png /content !wget https://raw.githubusercontent.com/arnaldojr/cognitivecomputing/master/material/aulas/PDI/lab06/corredor.png /content !wget https://raw.githubusercontent.com/arnaldojr/cognitivecomputing/master/material/aulas/PDI/lab06/dilata\u00e7\u00e3o.gif /content !wget https://raw.githubusercontent.com/arnaldojr/cognitivecomputing/master/material/aulas/PDI/lab06/erosao.gif /content !wget https://raw.githubusercontent.com/arnaldojr/cognitivecomputing/master/material/aulas/PDI/lab06/formas.png /content !wget https://raw.githubusercontent.com/arnaldojr/cognitivecomputing/master/material/aulas/PDI/lab06/formas_contorno.png /content !wget https://raw.githubusercontent.com/arnaldojr/cognitivecomputing/master/material/aulas/PDI/lab06/formas_contornor.png /content !wget https://raw.githubusercontent.com/arnaldojr/cognitivecomputing/master/material/aulas/PDI/lab06/j-noise.png /content !wget https://raw.githubusercontent.com/arnaldojr/cognitivecomputing/master/material/aulas/PDI/lab06/j.png /content !wget https://raw.githubusercontent.com/arnaldojr/cognitivecomputing/master/material/aulas/PDI/lab06/holes.png /content !wget https://raw.githubusercontent.com/arnaldojr/cognitivecomputing/master/material/aulas/PDI/lab06/melancia_filtrada.png /content !wget https://raw.githubusercontent.com/arnaldojr/cognitivecomputing/master/material/aulas/PDI/lab06/melancia_filtrada_rgb.png /content !wget https://raw.githubusercontent.com/arnaldojr/cognitivecomputing/master/material/aulas/PDI/lab06/moeda1.jpg /content !wget https://raw.githubusercontent.com/arnaldojr/cognitivecomputing/master/material/aulas/PDI/lab06/pessoas-gif.gif /content !wget https://raw.githubusercontent.com/arnaldojr/cognitivecomputing/master/material/aulas/PDI/lab06/rua.png /content !wget https://raw.githubusercontent.com/arnaldojr/cognitivecomputing/master/material/aulas/PDI/lab06/sala.jpg /content !wget https://raw.githubusercontent.com/arnaldojr/cognitivecomputing/master/material/aulas/PDI/lab06/sala1.jpg /content !wget https://raw.githubusercontent.com/arnaldojr/cognitivecomputing/master/material/aulas/PDI/lab06/sala2.jpg /content !wget https://raw.githubusercontent.com/arnaldojr/cognitivecomputing/master/material/aulas/PDI/lab06/sala3.jpg /content !wget https://raw.githubusercontent.com/arnaldojr/cognitivecomputing/master/material/aulas/PDI/lab06/sala_res.png /content !wget https://raw.githubusercontent.com/arnaldojr/cognitivecomputing/master/material/aulas/PDI/lab06/people-walking.mp4 /content  In\u00a0[1]: Copied! <pre>%matplotlib inline\nimport cv2\nfrom matplotlib import pyplot as plt\nimport numpy as np\n\nimg = cv2.imread('formas.png')\nimg = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n\nplt.figure(figsize = (10,10))\nplt.imshow(img); plt.show()\n</pre> %matplotlib inline import cv2 from matplotlib import pyplot as plt import numpy as np  img = cv2.imread('formas.png') img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)  plt.figure(figsize = (10,10)) plt.imshow(img); plt.show() In\u00a0[2]: Copied! <pre>img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\nedges = cv2.Canny(img_gray,50,150)\ncircles=cv2.HoughCircles(edges,cv2.HOUGH_GRADIENT,dp=160,minDist=100,param1=200,param2=100,minRadius=50,maxRadius=150)\n\nbordas_rgb = cv2.cvtColor(edges, cv2.COLOR_GRAY2RGB)\noutput = bordas_rgb\n\n\nif circles is not None:        \n    circles = np.uint16(np.around(circles))\n    for i in circles[0,:]:\n        # desenha o contorno do circulo\n        cv2.circle(output,(i[0],i[1]),i[2],(0,255,0),2)\n        # desenha no centro do circulo\n        cv2.circle(output,(i[0],i[1]),2,(0,0,255),3)\n        \nplt.figure(figsize = (10,10))\nplt.imshow(output, cmap=\"Greys_r\", vmin=0, vmax=255); plt.show()\n</pre> img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY) edges = cv2.Canny(img_gray,50,150) circles=cv2.HoughCircles(edges,cv2.HOUGH_GRADIENT,dp=160,minDist=100,param1=200,param2=100,minRadius=50,maxRadius=150)  bordas_rgb = cv2.cvtColor(edges, cv2.COLOR_GRAY2RGB) output = bordas_rgb   if circles is not None:             circles = np.uint16(np.around(circles))     for i in circles[0,:]:         # desenha o contorno do circulo         cv2.circle(output,(i[0],i[1]),i[2],(0,255,0),2)         # desenha no centro do circulo         cv2.circle(output,(i[0],i[1]),2,(0,0,255),3)          plt.figure(figsize = (10,10)) plt.imshow(output, cmap=\"Greys_r\", vmin=0, vmax=255); plt.show() <p>O resultado n\u00e3o ficou bom, pois h\u00e1 muitos falsos positivos detectados, neste caso precisamos alterar os parametros da transformada de hough. Vamos ver o que \u00e9 cada um deles.</p> <p><code>circles=cv2.HoughCircles(image,method=cv2.HOUGH_GRADIENT,dp,minDist,param1,param2,minRadius,maxRadius)</code></p> <ul> <li>image: imagem de entrada na escala de ciza.</li> <li>method: Define o met\u00f3do de detec\u00e7\u00e3o de circulos.</li> <li>dp: rela\u00e7\u00e3o entre o tamanho da imagem e o tamanho do acumulador. Um dp grande \"pega\" bordas mais t\u00eanues.</li> <li>minDist: Dist\u00e2ncia minima entre centros (x,y) dos circulos detectados</li> <li>param1: Valor do gradiente usado para lidar com a detec\u00e7\u00e3o de bordas</li> <li>param2: Limiar do Acumulador usado pelo met\u00f3do. Se muito baixo, retorna mais circulos (incluindo c\u00edrculos falsos). Se mais alto, mais c\u00edrculos ser\u00e3o potencialmente retornados.</li> <li>minRadius: Raio minimo (em pixels).</li> <li>maxRadius: Raio m\u00e1ximo (em pixels).</li> </ul> In\u00a0[22]: Copied! <pre># Implemente sua solu\u00e7\u00e3o aqui...\nimport cv2\nfrom matplotlib import pyplot as plt\nimport numpy as np\n\nimg = cv2.imread('formas.png')\nimg = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\nimg_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n\nedges = cv2.Canny(img_gray,50,150) # O detector de bordas de Canny na imagem em escala de cinza para encontrar as bordas\n\n# A transformada de Hough para encontrar os c\u00edrculos na imagem com valores de dp=2 esse valor tem que testar, nao existe um valor padr\u00e3o\ncircles=cv2.HoughCircles(edges,cv2.HOUGH_GRADIENT,dp=2,minDist=100,param1=200,param2=100,minRadius=50,maxRadius=150)\n\nbordas_rgb = cv2.cvtColor(edges, cv2.COLOR_GRAY2RGB)\noutput = bordas_rgb\n\n\nif circles is not None:        \n    circles = np.uint16(np.around(circles))\n    for i in circles[0,:]:\n        # desenha o contorno do circulo\n        cv2.circle(output,(i[0],i[1]),i[2],(0,255,0),2)\n        # desenha no centro do circulo\n        cv2.circle(output,(i[0],i[1]),2,(0,0,255),3)\n        \nplt.figure(figsize = (10,10))\nplt.imshow(output, cmap=\"Greys_r\", vmin=0, vmax=255); plt.show()\n\n\n#### vamos aproveitar para entender melhor o que o HoughCircles est\u00e1 retornando ####\n\nprint(circles) # retorno do HoughCircles\nprint(f'O shape de cicles \u00e9: {circles.shape}')\nprint(f'Acessando o primeiro indice, conseguimos acessar os valores da submatriz {circles[0]}, repare que nao tem como acessar o circles[1]')\nprint(f'Essa matriz tem shape igual a {circles[0].shape}') \nprint(f'O primeiro circulo detectado \u00e9 {circles[0][0]}') # o raio, x e y do circulo\nprint(f'Raio: {circles[0][0][0]}') # raio\nprint(f'Centro x: {circles[0][0][1]}') # x\nprint(f'Centro y: {circles[0][0][2]}') # y\n\n\n \n</pre> # Implemente sua solu\u00e7\u00e3o aqui... import cv2 from matplotlib import pyplot as plt import numpy as np  img = cv2.imread('formas.png') img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB) img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)  edges = cv2.Canny(img_gray,50,150) # O detector de bordas de Canny na imagem em escala de cinza para encontrar as bordas  # A transformada de Hough para encontrar os c\u00edrculos na imagem com valores de dp=2 esse valor tem que testar, nao existe um valor padr\u00e3o circles=cv2.HoughCircles(edges,cv2.HOUGH_GRADIENT,dp=2,minDist=100,param1=200,param2=100,minRadius=50,maxRadius=150)  bordas_rgb = cv2.cvtColor(edges, cv2.COLOR_GRAY2RGB) output = bordas_rgb   if circles is not None:             circles = np.uint16(np.around(circles))     for i in circles[0,:]:         # desenha o contorno do circulo         cv2.circle(output,(i[0],i[1]),i[2],(0,255,0),2)         # desenha no centro do circulo         cv2.circle(output,(i[0],i[1]),2,(0,0,255),3)          plt.figure(figsize = (10,10)) plt.imshow(output, cmap=\"Greys_r\", vmin=0, vmax=255); plt.show()   #### vamos aproveitar para entender melhor o que o HoughCircles est\u00e1 retornando ####  print(circles) # retorno do HoughCircles print(f'O shape de cicles \u00e9: {circles.shape}') print(f'Acessando o primeiro indice, conseguimos acessar os valores da submatriz {circles[0]}, repare que nao tem como acessar o circles[1]') print(f'Essa matriz tem shape igual a {circles[0].shape}')  print(f'O primeiro circulo detectado \u00e9 {circles[0][0]}') # o raio, x e y do circulo print(f'Raio: {circles[0][0][0]}') # raio print(f'Centro x: {circles[0][0][1]}') # x print(f'Centro y: {circles[0][0][2]}') # y        <pre>[[[1281  493  112]\n  [ 609  601   56]\n  [ 733  189   85]\n  [ 187  459   87]]]\nO shape de cicles \u00e9: (1, 4, 3)\nAcessando o primeiro indice, conseguimos acessar os valores da submatriz [[1281  493  112]\n [ 609  601   56]\n [ 733  189   85]\n [ 187  459   87]], repare que nao tem como acessar o circles[1]\nEssa matriz tem shape igual a (4, 3)\nO primeiro circulo detectado \u00e9 [1281  493  112]\nRaio: 1281\nCentro x: 493\nCentro y: 112\n</pre> In\u00a0[7]: Copied! <pre>import cv2 as cv\nimport numpy as np\n\nimg = cv.imread('coins.png',0)\nimg = cv.medianBlur(img,5)\ncimg = cv.cvtColor(img,cv.COLOR_GRAY2BGR)\n\ncircles = cv.HoughCircles(img,cv.HOUGH_GRADIENT,1,20,param1=50,param2=40,minRadius=45,maxRadius=60)\n\ncircles = np.uint16(np.around(circles))\nfor i in circles[0,:]:\n    cv.circle(cimg,(i[0],i[1]),i[2],(0,255,0),2)\n    \nplt.figure(figsize = (10,10))   \nplt.imshow(cimg)\n</pre> import cv2 as cv import numpy as np  img = cv.imread('coins.png',0) img = cv.medianBlur(img,5) cimg = cv.cvtColor(img,cv.COLOR_GRAY2BGR)  circles = cv.HoughCircles(img,cv.HOUGH_GRADIENT,1,20,param1=50,param2=40,minRadius=45,maxRadius=60)  circles = np.uint16(np.around(circles)) for i in circles[0,:]:     cv.circle(cimg,(i[0],i[1]),i[2],(0,255,0),2)      plt.figure(figsize = (10,10))    plt.imshow(cimg) Out[7]: <pre>&lt;matplotlib.image.AxesImage at 0x7f6c31b2ea60&gt;</pre> In\u00a0[11]: Copied! <pre>#Implemente seu c\u00f3digo\n\nimport cv2 as cv\nimport numpy as np\n\nimg = cv.imread('coins.png',0)\nimg = cv.medianBlur(img,5)\ncimg = cv.cvtColor(img,cv.COLOR_GRAY2BGR)\n\n# fica facil de alterar os parametros de minRadius e maxRadius para encontrar os circulos maiores que no caso sao as moedas de 1 Dolar\ncircles = cv.HoughCircles(img,cv.HOUGH_GRADIENT,1,20,param1=50,param2=40,minRadius=75,maxRadius=100)\n\n\n# aqui eu desenho os circulos encontrados\ncircles = np.uint16(np.around(circles))\nfor i in circles[0,:]:\n    cv.circle(cimg,(i[0],i[1]),i[2],(0,255,0),2)\n\n\nplt.figure(figsize = (10,10))   \nplt.imshow(cimg)\n\nprint(f'foram encontrados {len(circles[0])} moedas de 1 Dolar')\n</pre> #Implemente seu c\u00f3digo  import cv2 as cv import numpy as np  img = cv.imread('coins.png',0) img = cv.medianBlur(img,5) cimg = cv.cvtColor(img,cv.COLOR_GRAY2BGR)  # fica facil de alterar os parametros de minRadius e maxRadius para encontrar os circulos maiores que no caso sao as moedas de 1 Dolar circles = cv.HoughCircles(img,cv.HOUGH_GRADIENT,1,20,param1=50,param2=40,minRadius=75,maxRadius=100)   # aqui eu desenho os circulos encontrados circles = np.uint16(np.around(circles)) for i in circles[0,:]:     cv.circle(cimg,(i[0],i[1]),i[2],(0,255,0),2)   plt.figure(figsize = (10,10))    plt.imshow(cimg)  print(f'foram encontrados {len(circles[0])} moedas de 1 Dolar')  <pre>foram encontrados 4 moedas de 1 Dolar\n</pre> In\u00a0[9]: Copied! <pre>%matplotlib inline\nimport cv2\nfrom matplotlib import pyplot as plt\nimport numpy as np\nimport math\n\nimg = cv2.imread('formas.png')\nimg = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n\nplt.figure(figsize = (10,10))\nplt.imshow(img); plt.show()\n</pre> %matplotlib inline import cv2 from matplotlib import pyplot as plt import numpy as np import math  img = cv2.imread('formas.png') img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)  plt.figure(figsize = (10,10)) plt.imshow(img); plt.show() In\u00a0[25]: Copied! <pre>img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\nedges = cv2.Canny(img_gray,50,150)\n\nlines = cv2.HoughLinesP(edges, 1, math.pi/180.0, 100, np.array([]), 180, 5)\n\nhough_img_rgb = cv2.cvtColor(edges, cv2.COLOR_GRAY2BGR)\n\nfor line in lines:\n    x1, y1, x2, y2 = line[0]\n    cv2.line(hough_img_rgb, (x1, y1), (x2, y2), (255, 0, 255), 5)\n\n\nplt.figure(figsize = (10,10))\nplt.imshow(hough_img_rgb); plt.show()\n</pre> img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY) edges = cv2.Canny(img_gray,50,150)  lines = cv2.HoughLinesP(edges, 1, math.pi/180.0, 100, np.array([]), 180, 5)  hough_img_rgb = cv2.cvtColor(edges, cv2.COLOR_GRAY2BGR)  for line in lines:     x1, y1, x2, y2 = line[0]     cv2.line(hough_img_rgb, (x1, y1), (x2, y2), (255, 0, 255), 5)   plt.figure(figsize = (10,10)) plt.imshow(hough_img_rgb); plt.show() In\u00a0[64]: Copied! <pre>#Implemente seu c\u00f3digo\n\nimport cv2\nfrom matplotlib import pyplot as plt\nimport numpy as np\nimport math\n\nimg = cv2.imread('formas.png')\nimg = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n\nimg_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\nimg_gray = cv2.Canny(img_gray,100,200)\n\n# O detector de linhas de Hough na imagem em escala de cinza para encontrar as linhas, os valores devem ser testados\nlines = cv2.HoughLinesP(img_gray, 1.5, math.pi/180.0, 100, np.array([]), 10, 5)\n\n\nhough_img_rgb = cv2.cvtColor(img_gray, cv2.COLOR_GRAY2BGR)\n\nfor line in lines:\n    x1, y1, x2, y2 = line[0]\n    cv2.line(hough_img_rgb, (x1, y1), (x2, y2), (255, 0, 255), 10)\n\n\nplt.figure(figsize = (10,10))\nplt.imshow(hough_img_rgb); plt.show()\n</pre> #Implemente seu c\u00f3digo  import cv2 from matplotlib import pyplot as plt import numpy as np import math  img = cv2.imread('formas.png') img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)  img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY) img_gray = cv2.Canny(img_gray,100,200)  # O detector de linhas de Hough na imagem em escala de cinza para encontrar as linhas, os valores devem ser testados lines = cv2.HoughLinesP(img_gray, 1.5, math.pi/180.0, 100, np.array([]), 10, 5)   hough_img_rgb = cv2.cvtColor(img_gray, cv2.COLOR_GRAY2BGR)  for line in lines:     x1, y1, x2, y2 = line[0]     cv2.line(hough_img_rgb, (x1, y1), (x2, y2), (255, 0, 255), 10)   plt.figure(figsize = (10,10)) plt.imshow(hough_img_rgb); plt.show()   <p>Exemplo mais pr\u00e1tico, detec\u00e7\u00e3o de faixa por veiculos auton\u00f4mos.</p> In\u00a0[65]: Copied! <pre>%matplotlib inline\nimport cv2\nfrom matplotlib import pyplot as plt\nimport numpy as np\nimport math\n\nimg = cv2.imread('rua.png')\nimg = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n\nplt.figure(figsize = (10,10))\nplt.imshow(img); plt.show()\n</pre> %matplotlib inline import cv2 from matplotlib import pyplot as plt import numpy as np import math  img = cv2.imread('rua.png') img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)  plt.figure(figsize = (10,10)) plt.imshow(img); plt.show() In\u00a0[66]: Copied! <pre>img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\nedges = cv2.Canny(img_gray,50,200)\n\nlines = cv2.HoughLinesP(edges, 1, math.pi/180.0, 120, np.array([]), 10, 100)\n\n\nhough_img_rgb = cv2.cvtColor(edges, cv2.COLOR_GRAY2BGR)\n\nfor line in lines:\n    x1, y1, x2, y2 = line[0]\n    cv2.line(hough_img_rgb, (x1, y1), (x2, y2), (255, 0, 255), 5)\n\n\nplt.figure(figsize = (10,10))\nplt.imshow(hough_img_rgb); plt.show()\n</pre> img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY) edges = cv2.Canny(img_gray,50,200)  lines = cv2.HoughLinesP(edges, 1, math.pi/180.0, 120, np.array([]), 10, 100)   hough_img_rgb = cv2.cvtColor(edges, cv2.COLOR_GRAY2BGR)  for line in lines:     x1, y1, x2, y2 = line[0]     cv2.line(hough_img_rgb, (x1, y1), (x2, y2), (255, 0, 255), 5)   plt.figure(figsize = (10,10)) plt.imshow(hough_img_rgb); plt.show() In\u00a0[14]: Copied! <pre>from IPython.display import Image\nImage(open('dilata\u00e7\u00e3o.gif','rb').read())\n</pre> from IPython.display import Image Image(open('dilata\u00e7\u00e3o.gif','rb').read()) Out[14]: In\u00a0[15]: Copied! <pre>import cv2 as cv\nimport numpy as np\nimg = cv.imread('j.png',0)\nplt.imshow(img, cmap=\"Greys_r\", vmin=0, vmax=255); plt.show()\n\nkernel = np.ones((5,5),np.uint8)\n\ndilation = cv.dilate(img,kernel,iterations = 1)\n\n\nplt.imshow(dilation, cmap=\"Greys_r\", vmin=0, vmax=255); plt.show()\n</pre> import cv2 as cv import numpy as np img = cv.imread('j.png',0) plt.imshow(img, cmap=\"Greys_r\", vmin=0, vmax=255); plt.show()  kernel = np.ones((5,5),np.uint8)  dilation = cv.dilate(img,kernel,iterations = 1)   plt.imshow(dilation, cmap=\"Greys_r\", vmin=0, vmax=255); plt.show() In\u00a0[16]: Copied! <pre>import cv2 as cv\nimport numpy as np\n\nimg = cv.imread('j.png',0)\n\nplt.imshow(img, cmap=\"Greys_r\", vmin=0, vmax=255); plt.show()\n\ndst = img.copy()\nkernel = np.ones((5,5),np.uint8)\n\ndilation = cv.dilate(img,kernel,iterations = 1)\n\ndst = dilation - img\n\n\nplt.imshow(dst, cmap=\"Greys_r\", vmin=0, vmax=255); plt.show()\n</pre> import cv2 as cv import numpy as np  img = cv.imread('j.png',0)  plt.imshow(img, cmap=\"Greys_r\", vmin=0, vmax=255); plt.show()  dst = img.copy() kernel = np.ones((5,5),np.uint8)  dilation = cv.dilate(img,kernel,iterations = 1)  dst = dilation - img   plt.imshow(dst, cmap=\"Greys_r\", vmin=0, vmax=255); plt.show() In\u00a0[17]: Copied! <pre>from IPython.display import Image\nImage(open('erosao.gif','rb').read())\n</pre> from IPython.display import Image Image(open('erosao.gif','rb').read()) Out[17]: In\u00a0[18]: Copied! <pre>import cv2 as cv\nimport numpy as np\nimg = cv.imread('j.png',0)\nplt.imshow(img, cmap=\"Greys_r\", vmin=0, vmax=255); plt.show()\n\ndst = img.copy()\nkernel = np.ones((5,5),np.uint8)\n\nerode = cv.erode(img,kernel,iterations = 1)\n\nplt.imshow(erode, cmap=\"Greys_r\", vmin=0, vmax=255); plt.show()\n</pre> import cv2 as cv import numpy as np img = cv.imread('j.png',0) plt.imshow(img, cmap=\"Greys_r\", vmin=0, vmax=255); plt.show()  dst = img.copy() kernel = np.ones((5,5),np.uint8)  erode = cv.erode(img,kernel,iterations = 1)  plt.imshow(erode, cmap=\"Greys_r\", vmin=0, vmax=255); plt.show() In\u00a0[72]: Copied! <pre>#implemente seu c\u00f3digo...\n\n\nimport cv2 as cv\nimport numpy as np\nimg = cv.imread('j.png',0)\n\ndst = img.copy()\nkernel = np.ones((5,5),np.uint8)\n\nerode = cv.erode(img,kernel,iterations = 1)\n\ncontorno = img - erode\n\nplt.subplot(131), plt.imshow(img, cmap=\"Greys_r\", vmin=0, vmax=255)\nplt.subplot(132), plt.imshow(erode, cmap=\"Greys_r\", vmin=0, vmax=255)\nplt.subplot(133), plt.imshow(contorno, cmap=\"Greys_r\", vmin=0, vmax=255); plt.show()\n</pre> #implemente seu c\u00f3digo...   import cv2 as cv import numpy as np img = cv.imread('j.png',0)  dst = img.copy() kernel = np.ones((5,5),np.uint8)  erode = cv.erode(img,kernel,iterations = 1)  contorno = img - erode  plt.subplot(131), plt.imshow(img, cmap=\"Greys_r\", vmin=0, vmax=255) plt.subplot(132), plt.imshow(erode, cmap=\"Greys_r\", vmin=0, vmax=255) plt.subplot(133), plt.imshow(contorno, cmap=\"Greys_r\", vmin=0, vmax=255); plt.show()    In\u00a0[19]: Copied! <pre>import cv2 as cv\nimport numpy as np\nimg = cv.imread('j-noise.png',0)\nplt.imshow(img, cmap=\"Greys_r\", vmin=0, vmax=255); plt.show()\n\ndst = img.copy()\nkernel = np.ones((5,5),np.uint8)\n\nopening = cv.morphologyEx(img, cv.MORPH_OPEN, kernel)\n\nplt.imshow(opening, cmap=\"Greys_r\", vmin=0, vmax=255); plt.show()\n</pre> import cv2 as cv import numpy as np img = cv.imread('j-noise.png',0) plt.imshow(img, cmap=\"Greys_r\", vmin=0, vmax=255); plt.show()  dst = img.copy() kernel = np.ones((5,5),np.uint8)  opening = cv.morphologyEx(img, cv.MORPH_OPEN, kernel)  plt.imshow(opening, cmap=\"Greys_r\", vmin=0, vmax=255); plt.show() In\u00a0[22]: Copied! <pre>import cv2 as cv\nimport numpy as np\nimg = cv.imread('holes.png',0)\nplt.imshow(img, cmap=\"Greys_r\", vmin=0, vmax=255); plt.show()\n\ndst = img.copy()\nkernel = np.ones((5,5),np.uint8)\n\nclosing = cv.morphologyEx(img, cv.MORPH_CLOSE, kernel)\n\nplt.imshow(closing, cmap=\"Greys_r\", vmin=0, vmax=255); plt.show()\n</pre> import cv2 as cv import numpy as np img = cv.imread('holes.png',0) plt.imshow(img, cmap=\"Greys_r\", vmin=0, vmax=255); plt.show()  dst = img.copy() kernel = np.ones((5,5),np.uint8)  closing = cv.morphologyEx(img, cv.MORPH_CLOSE, kernel)  plt.imshow(closing, cmap=\"Greys_r\", vmin=0, vmax=255); plt.show() In\u00a0[75]: Copied! <pre>### seu c\u00f3digo ###\n\n# a resposta \u00e9 n\u00e3o, pois a morfologia modifica a estrutura da imagem, e a opera\u00e7ao de fechamento pode preencher os buracos, mas nao vai conseguir recuperar a informa\u00e7\u00e3o perdida\n\n\nimport cv2 as cv\nimport numpy as np\n\nimg = cv.imread('holes.png',0)\n\nkernel = np.ones((5,5),np.uint8)\n\nopening = cv.morphologyEx(img, cv.MORPH_OPEN, kernel)\nclosing = cv.morphologyEx(opening, cv.MORPH_CLOSE, kernel)\n\ndiferenca = closing - img\n\nplt.subplot(141), plt.imshow(img, cmap=\"Greys_r\", vmin=0, vmax=255)\nplt.subplot(142), plt.imshow(opening, cmap=\"Greys_r\", vmin=0, vmax=255)\nplt.subplot(143), plt.imshow(closing, cmap=\"Greys_r\", vmin=0, vmax=255)\nplt.subplot(144), plt.imshow(diferenca, cmap=\"Greys_r\", vmin=0, vmax=255); plt.show()\n</pre> ### seu c\u00f3digo ###  # a resposta \u00e9 n\u00e3o, pois a morfologia modifica a estrutura da imagem, e a opera\u00e7ao de fechamento pode preencher os buracos, mas nao vai conseguir recuperar a informa\u00e7\u00e3o perdida   import cv2 as cv import numpy as np  img = cv.imread('holes.png',0)  kernel = np.ones((5,5),np.uint8)  opening = cv.morphologyEx(img, cv.MORPH_OPEN, kernel) closing = cv.morphologyEx(opening, cv.MORPH_CLOSE, kernel)  diferenca = closing - img  plt.subplot(141), plt.imshow(img, cmap=\"Greys_r\", vmin=0, vmax=255) plt.subplot(142), plt.imshow(opening, cmap=\"Greys_r\", vmin=0, vmax=255) plt.subplot(143), plt.imshow(closing, cmap=\"Greys_r\", vmin=0, vmax=255) plt.subplot(144), plt.imshow(diferenca, cmap=\"Greys_r\", vmin=0, vmax=255); plt.show()"},{"location":"aulas/PDI/lab06/sol_Transformada-Hough-morfologia.html#transformada-de-hough","title":"Transformada de Hough\u00b6","text":"<p>A transformada de Hough \u00e9 um metodo utilizado para reconhecimento de padr\u00f5es simples como retas e circulos. a aplica\u00e7\u00e3o da t\u00e9cnica \u00e9 feita em contornos de imagem. \u00c9 uma t\u00e9cnica muito popular e muito poderosa, pois possibilita detectar linhas e circulos em imagens com pouco vis\u00edvel ou muito ruidosa.</p>"},{"location":"aulas/PDI/lab06/sol_Transformada-Hough-morfologia.html#deteccao-de-circulos","title":"DETEC\u00c7\u00c3O DE CIRCULOS\u00b6","text":"<p>Vamos fazer a dete\u00e7\u00e3o de circulos da imagem forma.</p>"},{"location":"aulas/PDI/lab06/sol_Transformada-Hough-morfologia.html#desafio-1","title":"DESAFIO 1\u00b6","text":"<p>Fa\u00e7a a altera\u00e7\u00e3o dos parametros para a transformada de Hough afim de detectar apenas os circulos da imagem.</p> <p>Dica: Altere um parametro por vez e analise o resultado.</p>"},{"location":"aulas/PDI/lab06/sol_Transformada-Hough-morfologia.html#desafio-2","title":"DESAFIO 2\u00b6","text":"<p>Modifique este c\u00f3digo para detectar, segmentar e exibir a quantidade de moedas de 1 d\u00f3lar. Neste imagem, temos quatro moedas de 1 d\u00f3lar.</p>"},{"location":"aulas/PDI/lab06/sol_Transformada-Hough-morfologia.html#deteccao-de-retas","title":"DETEC\u00c7\u00c3O DE RETAS\u00b6","text":"<p>De forma semelhante ao CV2.HOUGHCIRCLE(), para detec\u00e7\u00e3o de retas usamos o cv2.HoughLines() ou cv2.HoughLinesP() o segundo faz uma estimativa probabilistica.</p> <p><code>cv.HoughLinesP( image, rho, theta, threshold[, lines[, minLineLength[, maxLineGap]]])</code></p> <ul> <li>imagem: Imagem de entrada em escala de cinza.</li> <li>rho: Resolu\u00e7\u00e3o da dist\u00e2ncia do acumulador em pixeis.</li> <li>teta: Resolu\u00e7\u00e3o do \u00e2ngulo de rota\u00e7\u00e3o do acumulador em radianos, normalmente 1 Grau.</li> <li>threshold: Limiar do acumulador. S\u00f3 s\u00e3o devolvidas as linhas que obt\u00eam votos suficientes ( &gt;threshold ).</li> <li>minLineLineLength: Comprimento m\u00ednimo da linha. Segmentos de linha mais curtos do que isso s\u00e3o rejeitados.</li> <li>maxLineGap: Dist\u00e2ncia m\u00e1xima permitida entre pontos considerados na mesma linha.</li> </ul>"},{"location":"aulas/PDI/lab06/sol_Transformada-Hough-morfologia.html#desafio-3","title":"DESAFIO 3\u00b6","text":"<p>Fa\u00e7a a altera\u00e7\u00e3o dos parametros para a transformada de Hough afim de detectar apenas todas as linhas da imagem.</p> <p>Dica: Altere um parametro por vez e analise o resultado.</p>"},{"location":"aulas/PDI/lab06/sol_Transformada-Hough-morfologia.html#morfologia-matematica","title":"MORFOLOGIA MATEM\u00c1TICA\u00b6","text":"<p>A Morfologia Matem\u00e1tica (MM) \u00e9 um modelo te\u00f3rico para as imagens digitais constru\u00eddas em cima da teoria dos reticulados e da topologia . \u00c9 o fundamento do processamento de imagem morfol\u00f3gico, que \u00e9 baseado nos operadores de deslocamento-invariante (transla\u00e7\u00e3o invariante) baseados principalmente na adi\u00e7\u00e3o de Minkowski.</p>"},{"location":"aulas/PDI/lab06/sol_Transformada-Hough-morfologia.html#dilatacao-binaria","title":"DILATA\u00c7\u00c3O BIN\u00c1RIA\u00b6","text":"<p>\u00c9 uma transforma\u00e7\u00e3o morfol\u00f3gica que combina dois conjuntos usando adi\u00e7\u00e3o vetorial. Como o nome diz, o resultado ser\u00e1 uma imagem \u201cengordada\u201d.</p>"},{"location":"aulas/PDI/lab06/sol_Transformada-Hough-morfologia.html#detectando-contorno-com-dilatacao","title":"Detectando contorno com dilata\u00e7\u00e3o\u00b6","text":""},{"location":"aulas/PDI/lab06/sol_Transformada-Hough-morfologia.html#erosao-binaria","title":"EROS\u00c3O BIN\u00c1RIA\u00b6","text":"<p>A eros\u00e3o basicamente encolhe uma imagem e pode ser vista como uma transforma\u00e7\u00e3o morfol\u00f3gica que combina dois conjuntos usando vetores de subtra\u00e7\u00e3o. Ela \u00e9 expressa como a interse\u00e7\u00e3o de A e B.</p>"},{"location":"aulas/PDI/lab06/sol_Transformada-Hough-morfologia.html#desafio-4","title":"DESAFIO 4\u00b6","text":"<p>Utilizando a opera\u00e7\u00e3o de eros\u00e3o, calcule o contorno da imagem \"j.png\":</p>"},{"location":"aulas/PDI/lab06/sol_Transformada-Hough-morfologia.html#abertura-binaria","title":"ABERTURA BIN\u00c1RIA\u00b6","text":"<p>A abertura em geral suaviza o contorno de uma imagem, quebra estreitos e elimina proemin\u00eancias delgadas, a opera\u00e7\u00e3o de abertura e usada tamb\u00e9m para remover ru\u00eddos da imagem.</p>"},{"location":"aulas/PDI/lab06/sol_Transformada-Hough-morfologia.html#fechamento-binario","title":"FECHAMENTO BIN\u00c1RIO\u00b6","text":"<p>O fechamento funde pequenos quebras e alargas golfos estreitos elimina pequenos orif\u00edcios. Se uma abertura cria pequenos vazios na imagem, um fechamento ir\u00e1 preencher ou fechar os vazios, estas opera\u00e7\u00f5es podem remover muitos dos pixels brancos com ru\u00eddos, ou seja basicamente ele e igual a abertura s\u00f3 que primeiramente e feita a dilata\u00e7\u00e3o e ap\u00f3s e feita a eros\u00e3o.</p>"},{"location":"aulas/PDI/lab06/sol_Transformada-Hough-morfologia.html#desafio-5","title":"DESAFIO 5\u00b6","text":"<p>Utilizando a opera\u00e7\u00e3o abertura e depois a opera\u00e7\u00e3o de fechamento bin\u00e1rio, \u00e9 esperado que a imagem volte ao original? Por que?</p>"},{"location":"aulas/PDI/lab07/motion.html","title":"Motion","text":"In\u00a0[\u00a0]: Copied! In\u00a0[\u00a0]: Copied! <pre>import cv2\nfrom datetime import datetime\n</pre> import cv2 from datetime import datetime In\u00a0[\u00a0]: Copied! <pre>BLUR_KERNEL_P0 = (21, 21)\nBLUR_KERNEL_P1 = (11, 11)\nLEARNING_RATE = 0.001\nMIN_CONTOUR_AREA = 625\n</pre> BLUR_KERNEL_P0 = (21, 21) BLUR_KERNEL_P1 = (11, 11) LEARNING_RATE = 0.001 MIN_CONTOUR_AREA = 625 In\u00a0[\u00a0]: Copied! <pre>cap = cv2.VideoCapture(\"people-walking.mp4\")\n</pre> cap = cv2.VideoCapture(\"people-walking.mp4\") In\u00a0[\u00a0]: Copied! <pre>#backSub = cv2.createBackgroundSubtractorKNN()\nbackSub = cv2.createBackgroundSubtractorMOG2()\n</pre> #backSub = cv2.createBackgroundSubtractorKNN() backSub = cv2.createBackgroundSubtractorMOG2() In\u00a0[\u00a0]: Copied! <pre>while True:\n    ret, frame = cap.read()\n\n    if not ret:\n        break\n\n    frame_blured = cv2.GaussianBlur(frame, BLUR_KERNEL_P0, 0)\n    #backSubmask = backSub.apply(frame_blured, learningRate=LEARNING_RATE)\n    backSubmask = backSub.apply(frame_blured)\n\n    thresh = cv2.GaussianBlur(backSubmask, BLUR_KERNEL_P1, 0)\n    thresh = cv2.dilate(thresh, None, iterations=2)\n\n    cnts, _ = cv2.findContours(thresh.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n\n    area_movimento = 0\n    for cnt in cnts:\n        area = cv2.contourArea(cnt)\n        if  area &lt; MIN_CONTOUR_AREA:\n            continue\n\n        area_movimento += area\n        (x, y, w, h) = cv2.boundingRect(cnt)\n        cv2.rectangle(frame, (x, y), (x+w, y+h), (128, 255, 255), 2)\n\n    cv2.putText(\n        frame, datetime.now().strftime(\"%A %d %B %Y %I:%M:%S%p\"),\n        (10, frame.shape[0] - 10), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)\n    # Show results\n    cv2.imshow(\"Feed\", frame)\n    cv2.imshow(\"Thresh\", thresh)\n\n    # Wait for key 'ESC' to quit\n    key = cv2.waitKey(1) &amp; 0xFF\n    if key == 27:\n        break\n</pre> while True:     ret, frame = cap.read()      if not ret:         break      frame_blured = cv2.GaussianBlur(frame, BLUR_KERNEL_P0, 0)     #backSubmask = backSub.apply(frame_blured, learningRate=LEARNING_RATE)     backSubmask = backSub.apply(frame_blured)      thresh = cv2.GaussianBlur(backSubmask, BLUR_KERNEL_P1, 0)     thresh = cv2.dilate(thresh, None, iterations=2)      cnts, _ = cv2.findContours(thresh.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)      area_movimento = 0     for cnt in cnts:         area = cv2.contourArea(cnt)         if  area &lt; MIN_CONTOUR_AREA:             continue          area_movimento += area         (x, y, w, h) = cv2.boundingRect(cnt)         cv2.rectangle(frame, (x, y), (x+w, y+h), (128, 255, 255), 2)      cv2.putText(         frame, datetime.now().strftime(\"%A %d %B %Y %I:%M:%S%p\"),         (10, frame.shape[0] - 10), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)     # Show results     cv2.imshow(\"Feed\", frame)     cv2.imshow(\"Thresh\", thresh)      # Wait for key 'ESC' to quit     key = cv2.waitKey(1) &amp; 0xFF     if key == 27:         break In\u00a0[\u00a0]: Copied! <pre># That's how you exit\ncap.release()\ncv2.destroyAllWindows()\n</pre> # That's how you exit cap.release() cv2.destroyAllWindows()"},{"location":"aulas/PDI/lab07/Aula09/mot.html","title":"Mot","text":"In\u00a0[\u00a0]: Copied! <pre>import numpy as np\nimport cv2\n</pre> import numpy as np import cv2 In\u00a0[\u00a0]: Copied! <pre>#carrega o video \ncap = cv2.VideoCapture(0)\n</pre> #carrega o video  cap = cv2.VideoCapture(0) In\u00a0[\u00a0]: Copied! <pre># Cria a subtra\u00e7\u00e3o do fundo\nfgbg = cv2.createBackgroundSubtractorMOG2()\n#fgbg = cv2.createBackgroundSubtractorKNN()\n</pre> # Cria a subtra\u00e7\u00e3o do fundo fgbg = cv2.createBackgroundSubtractorMOG2() #fgbg = cv2.createBackgroundSubtractorKNN() In\u00a0[\u00a0]: Copied! <pre>kernel = np.ones((5,5),np.uint8)\n</pre> kernel = np.ones((5,5),np.uint8) In\u00a0[\u00a0]: Copied! <pre>while(1):\n    ret, frame = cap.read()\n    \n    if not ret:\n        break\n    \n    # Aplica a mascara no frame recebido\n    fgmask = fgbg.apply(frame)\n\n\n    ## vou testar a eros\u00e3o, forma 1\n   # kernel = np.ones((3,3),np.uint8)\n\n    #erode = cv2.erode(fgmask,kernel,iterations = 2)\n\n    #dilation = cv2.dilate(erode,kernel,iterations = 7)\n \n    ## vou testar a forma 2\n   \n    opening = cv2.morphologyEx(fgmask, cv2.MORPH_OPEN, kernel)\n    dilation = cv2.dilate(opening,kernel,iterations = 7) \n #   closing = cv2.morphologyEx(opening, cv2.MORPH_CLOSE, kernel)\n    #opening = cv2.morphologyEx(opening, cv2.MORPH_OPEN, kernel)\n\n\n    ## acha contornos\n    contours,hierarchy = cv2.findContours(dilation, 1, 2)\n    if len(contours)&gt;0:\n        cnt = contours[0]\n    \n        ## desenha retangulo \n        x,y,w,h = cv2.boundingRect(cnt)\n        frame = cv2.rectangle(frame,(x,y),(x+w,y+h),(0,255,0),2)\n\n\n    ### exibo o resultado\n    cv2.imshow('frame',frame)\n\n    cv2.imshow('processado',dilation)\n\n    \n    k = cv2.waitKey(30) &amp; 0xff\n    if k == 27:\n        break\n</pre> while(1):     ret, frame = cap.read()          if not ret:         break          # Aplica a mascara no frame recebido     fgmask = fgbg.apply(frame)       ## vou testar a eros\u00e3o, forma 1    # kernel = np.ones((3,3),np.uint8)      #erode = cv2.erode(fgmask,kernel,iterations = 2)      #dilation = cv2.dilate(erode,kernel,iterations = 7)       ## vou testar a forma 2         opening = cv2.morphologyEx(fgmask, cv2.MORPH_OPEN, kernel)     dilation = cv2.dilate(opening,kernel,iterations = 7)   #   closing = cv2.morphologyEx(opening, cv2.MORPH_CLOSE, kernel)     #opening = cv2.morphologyEx(opening, cv2.MORPH_OPEN, kernel)       ## acha contornos     contours,hierarchy = cv2.findContours(dilation, 1, 2)     if len(contours)&gt;0:         cnt = contours[0]              ## desenha retangulo          x,y,w,h = cv2.boundingRect(cnt)         frame = cv2.rectangle(frame,(x,y),(x+w,y+h),(0,255,0),2)       ### exibo o resultado     cv2.imshow('frame',frame)      cv2.imshow('processado',dilation)           k = cv2.waitKey(30) &amp; 0xff     if k == 27:         break In\u00a0[\u00a0]: Copied! <pre>cap.release()\ncv2.destroyAllWindows()\n</pre> cap.release() cv2.destroyAllWindows()"},{"location":"aulas/PDI/lab07/Aula09/motion.html","title":"Lab07 - Traking de objetos e movimento","text":"<p>Objetivos da aula:</p> <ul> <li>Conhecer e praticar tracking de objetos em movimento</li> </ul> In\u00a0[\u00a0]: Copied! <pre>####----- FAZENDO O DOWNLOAD DAS IMAGENS DO RESPOSIT\u00d3RIO, APENAS PARA FACILITAR -----#####\n## SE ESTIVER RODANDO EM SUA M\u00c1QUINA LOCAL N\u00c3O PRECISA RODAR ESSA CELULA ##\n\n\n!wget https://raw.githubusercontent.com/arnaldojr/cognitivecomputing/master/material/aulas/lab07/Aula09/pessoas-gif.gif /content\n!wget https://raw.githubusercontent.com/arnaldojr/cognitivecomputing/master/material/aulas/lab07/Aula09/sala.jpg /content\n!wget https://raw.githubusercontent.com/arnaldojr/cognitivecomputing/master/material/aulas/lab07/Aula09/sala1.jpg /content\n!wget https://raw.githubusercontent.com/arnaldojr/cognitivecomputing/master/material/aulas/lab07/Aula09/sala2.jpg /content\n!wget https://raw.githubusercontent.com/arnaldojr/cognitivecomputing/master/material/aulas/lab07/Aula09/sala3.jpg /content\n!wget https://raw.githubusercontent.com/arnaldojr/cognitivecomputing/master/material/aulas/lab07/Aula09/sala_res.png /content\n!wget https://raw.githubusercontent.com/arnaldojr/cognitivecomputing/master/material/aulas/lab07/Aula09/people-walking.mp4 /content\n</pre> ####----- FAZENDO O DOWNLOAD DAS IMAGENS DO RESPOSIT\u00d3RIO, APENAS PARA FACILITAR -----##### ## SE ESTIVER RODANDO EM SUA M\u00c1QUINA LOCAL N\u00c3O PRECISA RODAR ESSA CELULA ##   !wget https://raw.githubusercontent.com/arnaldojr/cognitivecomputing/master/material/aulas/lab07/Aula09/pessoas-gif.gif /content !wget https://raw.githubusercontent.com/arnaldojr/cognitivecomputing/master/material/aulas/lab07/Aula09/sala.jpg /content !wget https://raw.githubusercontent.com/arnaldojr/cognitivecomputing/master/material/aulas/lab07/Aula09/sala1.jpg /content !wget https://raw.githubusercontent.com/arnaldojr/cognitivecomputing/master/material/aulas/lab07/Aula09/sala2.jpg /content !wget https://raw.githubusercontent.com/arnaldojr/cognitivecomputing/master/material/aulas/lab07/Aula09/sala3.jpg /content !wget https://raw.githubusercontent.com/arnaldojr/cognitivecomputing/master/material/aulas/lab07/Aula09/sala_res.png /content !wget https://raw.githubusercontent.com/arnaldojr/cognitivecomputing/master/material/aulas/lab07/Aula09/people-walking.mp4 /content  In\u00a0[2]: Copied! <pre>%matplotlib inline\nimport cv2\nfrom matplotlib import pyplot as plt\nimport numpy as np\n\nimg = cv2.imread('sala_res.png')\n\nplt.figure(figsize = (10,10))\nplt.imshow(img); plt.show();\n</pre> %matplotlib inline import cv2 from matplotlib import pyplot as plt import numpy as np  img = cv2.imread('sala_res.png')  plt.figure(figsize = (10,10)) plt.imshow(img); plt.show();  In\u00a0[\u00a0]: Copied! <pre># Implemente seu c\u00f3digo.....\n</pre> # Implemente seu c\u00f3digo.....       In\u00a0[\u00a0]: Copied! <pre>###### leia com aten\u00e7\u00e3o!!! este c\u00f3digo roda em sua m\u00e1quina local.\n\nimport numpy as np\nimport cv2\n\n#carrega o video \ncap = cv2.VideoCapture('people-walking.mp4')\n\n# Cria a subtra\u00e7\u00e3o do fundo\n#fgbg = cv2.createBackgroundSubtractorMOG2()\nfgbg = cv2.createBackgroundSubtractorKNN()\n\nwhile(1):\n    ret, frame = cap.read()\n    \n    if not ret:\n        break\n    \n    # Aplica a mascara no frame recebido\n    fgmask = fgbg.apply(frame)\n   \n   cv2.imshow('fgmask',frame)\n    cv2.imshow('frame',fgmask)\n\n    \n    k = cv2.waitKey(30) &amp; 0xff\n    if k == 27:\n        break\n    \n\ncap.release()\ncv2.destroyAllWindows()\n</pre>  ###### leia com aten\u00e7\u00e3o!!! este c\u00f3digo roda em sua m\u00e1quina local.  import numpy as np import cv2  #carrega o video  cap = cv2.VideoCapture('people-walking.mp4')  # Cria a subtra\u00e7\u00e3o do fundo #fgbg = cv2.createBackgroundSubtractorMOG2() fgbg = cv2.createBackgroundSubtractorKNN()  while(1):     ret, frame = cap.read()          if not ret:         break          # Aplica a mascara no frame recebido     fgmask = fgbg.apply(frame)        cv2.imshow('fgmask',frame)     cv2.imshow('frame',fgmask)           k = cv2.waitKey(30) &amp; 0xff     if k == 27:         break       cap.release() cv2.destroyAllWindows() In\u00a0[\u00a0]: Copied! <pre>\n</pre> In\u00a0[6]: Copied! <pre>from IPython.display import Image\nImage(open('pessoas-gif.gif','rb').read())\n</pre> from IPython.display import Image Image(open('pessoas-gif.gif','rb').read()) Out[6]: In\u00a0[1]: Copied! <pre>##### Implemente seu c\u00f3digo aqui......\n</pre> ##### Implemente seu c\u00f3digo aqui......   In\u00a0[\u00a0]: Copied! <pre>\n</pre>"},{"location":"aulas/PDI/lab07/Aula09/motion.html#background-subtraction","title":"Background Subtraction\u00b6","text":"<p>A intui\u00e7\u00e3o de como realizar essa tarefa n\u00f3s j\u00e1 sabemso, basicamente iremos comparar duas imagem: a de refer\u00eancia do fundo com uma segunda imagem de teste. O resultado ir\u00e1 ressaltar a diferen\u00e7a da imagem.</p>"},{"location":"aulas/PDI/lab07/Aula09/motion.html#desafio-1","title":"DESAFIO 1\u00b6","text":"<p>Implemente um c\u00f3digo (simples) que seja capaz de realizar a subtra\u00e7\u00e3o das imagens e detectar movimento.</p> <p>Dica: voc\u00ea pode usar opera\u00e7\u00f5es <code>cv2.absdiff(img1, img2)</code> e se necess\u00e1rio realizar uma opera\u00e7\u00e3o morfologia (abertura/ fechamento, dilata\u00e7\u00e3o/eros\u00e3o) para reduzir o ruido. O resultado deve ser parecido com a imagem \"sala_res.png\".</p>"},{"location":"aulas/PDI/lab07/Aula09/motion.html#use-como-imagens-de-entrada-as-opcoes","title":"USE COMO IMAGENS DE ENTRADA AS OP\u00c7\u00d5ES:\u00b6","text":"<ul> <li>SALA, SALA1, SALA2, SALA3</li> </ul>"},{"location":"aulas/PDI/lab07/Aula09/motion.html#background-subtraction-em-videos","title":"Background Subtraction em videos\u00b6","text":"<p>O desafio acima foi f\u00e1cil! pois existe uma imagem de fundo sozinha, como uma imagem da sala sem vazia. Basta subtrair a nova imagem do plano de fundo. Voc\u00ea obt\u00e9m os objetos de primeiro plano sozinhos.</p> <p>Mas, na maioria dos casos, voc\u00ea pode n\u00e3o ter essa imagem, ent\u00e3o precisamos extrair o plano de fundo de qualquer imagem que tenhamos. Aiiiiii complica as coisas.</p> <p>Na OpenCV podemos implementar isso por meio de dois algoritmos. O primeiro \u00e9 createBackgroundSubtractorKNN() ou createBackgroundSubtractorMOG2(). Isso cria um objeto subtrator de fundo por K-Nearest Neighbor (KNN) ou Mixture of Gaussians (MOG2) . Ent\u00e3o, podemos chamar a fun\u00e7\u00e3o <code>apply()</code> com o objeto para obter a m\u00e1scara do primeiro plano. Podemos exibir diretamente a m\u00e1scara de primeiro plano em tempo real (com video :)).</p> <p>Refer\u00eancia da documenta\u00e7\u00e3o: https://docs.opencv.org/master/de/de1/group__video__motion.html#gac9be925771f805b6fdb614ec2292006d</p>"},{"location":"aulas/PDI/lab07/Aula09/motion.html#executar-video-no-jupyter-notebook-normalmente-da-problema","title":"Executar video no jupyter notebook normalmente da problema.\u00b6","text":"<p>Existem algumas formas de rodar, mas pode ficar delay.</p> <p>Sugest\u00e3o: Escreva um script e execute direto pelo terminal.</p>"},{"location":"aulas/PDI/lab07/Aula09/motion.html#desafio-2","title":"DESAFIO 2\u00b6","text":"<p>Crie um programa python e execute o c\u00f3digo acima. O objetivo, nesse primeiro momento, \u00e9 se familiarizar com a estrutura do c\u00f3digo, para isso, explore os metodos <code>MOG2</code> e <code>KNN</code> e observe os resultados.</p> <p>Explore os parametros da fun\u00e7\u00e3o:</p> <pre><code>history: O numero de frames usado para construir o modelo estatisco da fundo. Quando menor mais rapido.\n\ndist2Threshold: \u00e9 o limiar definido para saber se o pixel pertence ao fundo ou n\u00e3o da imagem. Quando menor mais sensivel.\n\ndetectShadows : Se True, a sombra (shadows) vai aparecer em cinza na imagem.</code></pre>"},{"location":"aulas/PDI/lab07/Aula09/motion.html#desafio-3","title":"DESAFIO 3\u00b6","text":"<p>Fa\u00e7a um programa que detecta o movimento das pessoas andando na rua e marca com um boundBox (retangulo) o que foi detectado.</p> <p>Instru\u00e7\u00f5es/Dicas:</p> <ul> <li><p>Use 'people-walking.mp4' como video para os testes.</p> </li> <li><p>Lembre-se do que j\u00e1 estudamos para remover ruido, real\u00e7ar contorno, detectar bordas....</p> </li> <li><p>Sempre <code>Leia a documenta\u00e7\u00e3o</code>: https://opencv-python-tutroals.readthedocs.io/en/latest/py_tutorials/py_imgproc/py_contours/py_contour_features/py_contour_features.html</p> </li> <li><p>Use a fun\u00e7\u00e3o cv2.boundingRect() para desenhar o retangulo.</p> </li> </ul> <p>O resultado dever ser semelhante ao do video.</p>"},{"location":"aulas/PDI/lab07/Aula09/motion.html#desafio-4-extra-top-das-galaxias","title":"Desafio 4 - Extra top das galaxias!\u00b6","text":"<p>A \u00e1rea de seguran\u00e7a tornou-se um grande mercado, onde empresas desenvolvem e vendem seus produtos. A vigilancia por c\u00e2meras \u00e9 um grande alindo nesse mercado, por v\u00e1rios motivos. Nesse sentido, voc\u00ea foi contratado para desenvolver um sistema de seguran\u00e7a remoto que ir\u00e1 capturar um video remotamente (c\u00e2mera IP) realizar o processamento para detec\u00e7\u00e3o de movimento.</p> <p>Dicas/Instru\u00e7\u00f5es:</p> <ul> <li>Fa\u00e7a uma aplica\u00e7\u00e3o web em <code>Flask</code></li> <li>https://www.youtube.com/watch?v=EkqhIeSZGN8 esse video pode ajudar um pouco</li> <li>https://github.com/arnaldojr/videostream</li> </ul> <p>Se topar o desafio, vamos fazer um projeto IC?</p>"},{"location":"aulas/PDI/lab07/Aula09/sol_motion.html","title":"Sol motion","text":"<p>Objetivos da aula:</p> <ul> <li>Conhecer e praticar tracking de objetos em movimento</li> </ul> In\u00a0[\u00a0]: Copied! <pre>####----- FAZENDO O DOWNLOAD DAS IMAGENS DO RESPOSIT\u00d3RIO, APENAS PARA FACILITAR -----#####\n## SE ESTIVER RODANDO EM SUA M\u00c1QUINA LOCAL N\u00c3O PRECISA RODAR ESSA CELULA ##\n\n\n!wget https://raw.githubusercontent.com/arnaldojr/cognitivecomputing/master/material/aulas/lab07/Aula09/pessoas-gif.gif /content\n!wget https://raw.githubusercontent.com/arnaldojr/cognitivecomputing/master/material/aulas/lab07/Aula09/sala.jpg /content\n!wget https://raw.githubusercontent.com/arnaldojr/cognitivecomputing/master/material/aulas/lab07/Aula09/sala1.jpg /content\n!wget https://raw.githubusercontent.com/arnaldojr/cognitivecomputing/master/material/aulas/lab07/Aula09/sala2.jpg /content\n!wget https://raw.githubusercontent.com/arnaldojr/cognitivecomputing/master/material/aulas/lab07/Aula09/sala3.jpg /content\n!wget https://raw.githubusercontent.com/arnaldojr/cognitivecomputing/master/material/aulas/lab07/Aula09/sala_res.png /content\n!wget https://raw.githubusercontent.com/arnaldojr/cognitivecomputing/master/material/aulas/lab07/Aula09/people-walking.mp4 /content\n</pre> ####----- FAZENDO O DOWNLOAD DAS IMAGENS DO RESPOSIT\u00d3RIO, APENAS PARA FACILITAR -----##### ## SE ESTIVER RODANDO EM SUA M\u00c1QUINA LOCAL N\u00c3O PRECISA RODAR ESSA CELULA ##   !wget https://raw.githubusercontent.com/arnaldojr/cognitivecomputing/master/material/aulas/lab07/Aula09/pessoas-gif.gif /content !wget https://raw.githubusercontent.com/arnaldojr/cognitivecomputing/master/material/aulas/lab07/Aula09/sala.jpg /content !wget https://raw.githubusercontent.com/arnaldojr/cognitivecomputing/master/material/aulas/lab07/Aula09/sala1.jpg /content !wget https://raw.githubusercontent.com/arnaldojr/cognitivecomputing/master/material/aulas/lab07/Aula09/sala2.jpg /content !wget https://raw.githubusercontent.com/arnaldojr/cognitivecomputing/master/material/aulas/lab07/Aula09/sala3.jpg /content !wget https://raw.githubusercontent.com/arnaldojr/cognitivecomputing/master/material/aulas/lab07/Aula09/sala_res.png /content !wget https://raw.githubusercontent.com/arnaldojr/cognitivecomputing/master/material/aulas/lab07/Aula09/people-walking.mp4 /content  In\u00a0[1]: Copied! <pre>%matplotlib inline\nimport cv2\nfrom matplotlib import pyplot as plt\nimport numpy as np\n\nimg = cv2.imread('sala_res.png')\n\nplt.figure(figsize = (10,10))\nplt.imshow(img); plt.show();\n</pre> %matplotlib inline import cv2 from matplotlib import pyplot as plt import numpy as np  img = cv2.imread('sala_res.png')  plt.figure(figsize = (10,10)) plt.imshow(img); plt.show();  In\u00a0[6]: Copied! <pre># Implemente seu c\u00f3digo.....\n\n%matplotlib inline\nimport cv2\nfrom matplotlib import pyplot as plt\nimport numpy as np\n\nimg = cv2.imread('sala.jpg',0)\nimg2 = cv2.imread('sala1.jpg',0)\n\n\nres1 = cv2.absdiff(img, img2)\n\nplt.subplot(1,3,1)\nplt.imshow(img, cmap='gray')\nplt.title('sala')\nplt.subplot(1,3,2)\nplt.imshow(img2, cmap='gray')\nplt.title('sala 1')\nplt.subplot(1,3,3)\nplt.imshow(res1, cmap='gray')\nplt.title('resultado')\nplt.show()\n\n# vamos tentar melhorar o resultado aplicando morfologia matem\u00e1tica\n\nopening = cv2.morphologyEx(res1, cv2.MORPH_OPEN, np.ones((3,3),np.uint8))\n\nclossing = cv2.morphologyEx(res1, cv2.MORPH_CLOSE, np.ones((3,3),np.uint8))\n\nerode = cv2.erode(res1, np.ones((3,3),np.uint8), iterations=1)\n\ndilate = cv2.dilate(res1, np.ones((3,3),np.uint8), iterations=1)\n\nplt.figure(figsize=(10,10))\nplt.subplot(2,2,1)\nplt.imshow(opening, cmap='gray')\nplt.title('opening')\nplt.subplot(2,2,2)\nplt.imshow(clossing, cmap='gray')\nplt.title('clossing')\nplt.subplot(2,2,3)\nplt.imshow(erode, cmap='gray')\nplt.title('erode')\nplt.subplot(2,2,4)\nplt.imshow(dilate, cmap='gray')\nplt.title('dilate')\nplt.show()\n\n# o erode ficou bacana, podemos tentar melhorar o resultado aplicando novamente o erode\n\nerode2 = cv2.erode(erode, np.ones((3,3),np.uint8), iterations=1) # como sugest\u00e3o pode alterar o valor de iterations para tentar melhorar o resultado\n\nplt.figure(figsize=(10,10))\nplt.subplot(1,2,1)\nplt.imshow(erode, cmap='gray')\nplt.title('erode')\nplt.subplot(1,2,2)\nplt.imshow(erode2, cmap='gray')\nplt.title('erode2')\nplt.show()\n</pre> # Implemente seu c\u00f3digo.....  %matplotlib inline import cv2 from matplotlib import pyplot as plt import numpy as np  img = cv2.imread('sala.jpg',0) img2 = cv2.imread('sala1.jpg',0)   res1 = cv2.absdiff(img, img2)  plt.subplot(1,3,1) plt.imshow(img, cmap='gray') plt.title('sala') plt.subplot(1,3,2) plt.imshow(img2, cmap='gray') plt.title('sala 1') plt.subplot(1,3,3) plt.imshow(res1, cmap='gray') plt.title('resultado') plt.show()  # vamos tentar melhorar o resultado aplicando morfologia matem\u00e1tica  opening = cv2.morphologyEx(res1, cv2.MORPH_OPEN, np.ones((3,3),np.uint8))  clossing = cv2.morphologyEx(res1, cv2.MORPH_CLOSE, np.ones((3,3),np.uint8))  erode = cv2.erode(res1, np.ones((3,3),np.uint8), iterations=1)  dilate = cv2.dilate(res1, np.ones((3,3),np.uint8), iterations=1)  plt.figure(figsize=(10,10)) plt.subplot(2,2,1) plt.imshow(opening, cmap='gray') plt.title('opening') plt.subplot(2,2,2) plt.imshow(clossing, cmap='gray') plt.title('clossing') plt.subplot(2,2,3) plt.imshow(erode, cmap='gray') plt.title('erode') plt.subplot(2,2,4) plt.imshow(dilate, cmap='gray') plt.title('dilate') plt.show()  # o erode ficou bacana, podemos tentar melhorar o resultado aplicando novamente o erode  erode2 = cv2.erode(erode, np.ones((3,3),np.uint8), iterations=1) # como sugest\u00e3o pode alterar o valor de iterations para tentar melhorar o resultado  plt.figure(figsize=(10,10)) plt.subplot(1,2,1) plt.imshow(erode, cmap='gray') plt.title('erode') plt.subplot(1,2,2) plt.imshow(erode2, cmap='gray') plt.title('erode2') plt.show()    In\u00a0[\u00a0]: Copied! <pre>###### leia com aten\u00e7\u00e3o!!! este c\u00f3digo roda em sua m\u00e1quina local.\n\nimport numpy as np\nimport cv2\n\n#carrega o video \ncap = cv2.VideoCapture('people-walking.mp4')\n\n# Cria a subtra\u00e7\u00e3o do fundo\n#fgbg = cv2.createBackgroundSubtractorMOG2()\nfgbg = cv2.createBackgroundSubtractorKNN()\n\nwhile(1):\n    ret, frame = cap.read()\n    \n    if not ret:\n        break\n    \n    # Aplica a mascara no frame recebido\n    fgmask = fgbg.apply(frame)\n   \n    cv2.imshow('fgmask',frame)\n    cv2.imshow('frame',fgmask)\n\n    \n    k = cv2.waitKey(30) &amp; 0xff\n    if k == 27:\n        break\n    \n\ncap.release()\ncv2.destroyAllWindows()\n</pre>  ###### leia com aten\u00e7\u00e3o!!! este c\u00f3digo roda em sua m\u00e1quina local.  import numpy as np import cv2  #carrega o video  cap = cv2.VideoCapture('people-walking.mp4')  # Cria a subtra\u00e7\u00e3o do fundo #fgbg = cv2.createBackgroundSubtractorMOG2() fgbg = cv2.createBackgroundSubtractorKNN()  while(1):     ret, frame = cap.read()          if not ret:         break          # Aplica a mascara no frame recebido     fgmask = fgbg.apply(frame)         cv2.imshow('fgmask',frame)     cv2.imshow('frame',fgmask)           k = cv2.waitKey(30) &amp; 0xff     if k == 27:         break       cap.release() cv2.destroyAllWindows() In\u00a0[\u00a0]: Copied! <pre>## insira seu c\u00f3digo aqui\n\n# como vou abrir algums telas para observar a diferen\u00e7a entre os metodos, vou diminuir o tamanho da tela para n\u00e3o ficar muito grande e atrapalhar a visualiza\u00e7\u00e3o\n\n\nimport numpy as np\nimport cv2\n\n#carrega o video \ncap = cv2.VideoCapture('people-walking.mp4')\n\n# Reduzindo a resolu\u00e7\u00e3o do v\u00eddeo (opcional)\nscale_factor = 0.5\n\n# Cria\u00e7\u00e3o do objeto de subtra\u00e7\u00e3o de fundo MOG2\nmog2 = cv2.createBackgroundSubtractorMOG2(history=500, varThreshold=16, detectShadows=True)\n\n# Cria\u00e7\u00e3o do objeto de subtra\u00e7\u00e3o de fundo KNN\nknn = cv2.createBackgroundSubtractorKNN(history=350, dist2Threshold=400, detectShadows=True)\n\n\nwhile(1):\n    ret, frame = cap.read()\n    \n    if not ret:\n        break\n     # Redimensionamento do frame (opcional)\n    frame = cv2.resize(frame, None, fx=scale_factor, fy=scale_factor, interpolation=cv2.INTER_AREA)\n\n    # Aplica\u00e7\u00e3o dos m\u00e9todos de subtra\u00e7\u00e3o de fundo\n    fgmask_mog2 = mog2.apply(frame)\n    fgmask_knn = knn.apply(frame)\n\n    # Exibi\u00e7\u00e3o dos resultados\n    cv2.imshow('Original', frame)\n    cv2.imshow('MOG2', fgmask_mog2)\n    cv2.imshow('KNN', fgmask_knn)\n\n    if cv2.waitKey(0) &amp; 0xFF == ord('q'):\n        print(\"Encerrando a execu\u00e7\u00e3o.\")\n        break\n    \n\ncap.release()\ncv2.destroyAllWindows()\n</pre> ## insira seu c\u00f3digo aqui  # como vou abrir algums telas para observar a diferen\u00e7a entre os metodos, vou diminuir o tamanho da tela para n\u00e3o ficar muito grande e atrapalhar a visualiza\u00e7\u00e3o   import numpy as np import cv2  #carrega o video  cap = cv2.VideoCapture('people-walking.mp4')  # Reduzindo a resolu\u00e7\u00e3o do v\u00eddeo (opcional) scale_factor = 0.5  # Cria\u00e7\u00e3o do objeto de subtra\u00e7\u00e3o de fundo MOG2 mog2 = cv2.createBackgroundSubtractorMOG2(history=500, varThreshold=16, detectShadows=True)  # Cria\u00e7\u00e3o do objeto de subtra\u00e7\u00e3o de fundo KNN knn = cv2.createBackgroundSubtractorKNN(history=350, dist2Threshold=400, detectShadows=True)   while(1):     ret, frame = cap.read()          if not ret:         break      # Redimensionamento do frame (opcional)     frame = cv2.resize(frame, None, fx=scale_factor, fy=scale_factor, interpolation=cv2.INTER_AREA)      # Aplica\u00e7\u00e3o dos m\u00e9todos de subtra\u00e7\u00e3o de fundo     fgmask_mog2 = mog2.apply(frame)     fgmask_knn = knn.apply(frame)      # Exibi\u00e7\u00e3o dos resultados     cv2.imshow('Original', frame)     cv2.imshow('MOG2', fgmask_mog2)     cv2.imshow('KNN', fgmask_knn)      if cv2.waitKey(0) &amp; 0xFF == ord('q'):         print(\"Encerrando a execu\u00e7\u00e3o.\")         break       cap.release() cv2.destroyAllWindows()  In\u00a0[6]: Copied! <pre>from IPython.display import Image\nImage(open('pessoas-gif.gif','rb').read())\n</pre> from IPython.display import Image Image(open('pessoas-gif.gif','rb').read()) Out[6]: In\u00a0[1]: Copied! <pre>##### Implemente seu c\u00f3digo aqui......\n\n\n#!/usr/bin/env python3\n# -*- coding: utf-8 -*-\n\nimport cv2\nfrom datetime import datetime\n\n\nBLUR_KERNEL_P0 = (21, 21)\nBLUR_KERNEL_P1 = (11, 11)\nLEARNING_RATE = 0.001\nMIN_CONTOUR_AREA = 625\n\ncap = cv2.VideoCapture(\"people-walking.mp4\")\n\n#backSub = cv2.createBackgroundSubtractorKNN()\nbackSub = cv2.createBackgroundSubtractorMOG2()\n\nwhile True:\n    ret, frame = cap.read()\n\n    if not ret:\n        break\n\n    frame_blured = cv2.GaussianBlur(frame, BLUR_KERNEL_P0, 0)\n    #backSubmask = backSub.apply(frame_blured, learningRate=LEARNING_RATE)\n    backSubmask = backSub.apply(frame_blured)\n\n    thresh = cv2.GaussianBlur(backSubmask, BLUR_KERNEL_P1, 0)\n    thresh = cv2.dilate(thresh, None, iterations=2)\n\n    cnts, _ = cv2.findContours(thresh.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n\n    area_movimento = 0\n    for cnt in cnts:\n        area = cv2.contourArea(cnt)\n        if  area &lt; MIN_CONTOUR_AREA:\n            continue\n\n        area_movimento += area\n        (x, y, w, h) = cv2.boundingRect(cnt)\n        cv2.rectangle(frame, (x, y), (x+w, y+h), (128, 255, 255), 2)\n\n    cv2.putText(\n        frame, datetime.now().strftime(\"%A %d %B %Y %I:%M:%S%p\"),\n        (10, frame.shape[0] - 10), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)\n    # Show results\n    cv2.imshow(\"Feed\", frame)\n    cv2.imshow(\"Thresh\", thresh)\n\n    # Wait for key 'ESC' to quit\n    key = cv2.waitKey(1) &amp; 0xFF\n    if key == 27:\n        break\n\n# That's how you exit\ncap.release()\ncv2.destroyAllWindows()\n</pre> ##### Implemente seu c\u00f3digo aqui......   #!/usr/bin/env python3 # -*- coding: utf-8 -*-  import cv2 from datetime import datetime   BLUR_KERNEL_P0 = (21, 21) BLUR_KERNEL_P1 = (11, 11) LEARNING_RATE = 0.001 MIN_CONTOUR_AREA = 625  cap = cv2.VideoCapture(\"people-walking.mp4\")  #backSub = cv2.createBackgroundSubtractorKNN() backSub = cv2.createBackgroundSubtractorMOG2()  while True:     ret, frame = cap.read()      if not ret:         break      frame_blured = cv2.GaussianBlur(frame, BLUR_KERNEL_P0, 0)     #backSubmask = backSub.apply(frame_blured, learningRate=LEARNING_RATE)     backSubmask = backSub.apply(frame_blured)      thresh = cv2.GaussianBlur(backSubmask, BLUR_KERNEL_P1, 0)     thresh = cv2.dilate(thresh, None, iterations=2)      cnts, _ = cv2.findContours(thresh.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)      area_movimento = 0     for cnt in cnts:         area = cv2.contourArea(cnt)         if  area &lt; MIN_CONTOUR_AREA:             continue          area_movimento += area         (x, y, w, h) = cv2.boundingRect(cnt)         cv2.rectangle(frame, (x, y), (x+w, y+h), (128, 255, 255), 2)      cv2.putText(         frame, datetime.now().strftime(\"%A %d %B %Y %I:%M:%S%p\"),         (10, frame.shape[0] - 10), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)     # Show results     cv2.imshow(\"Feed\", frame)     cv2.imshow(\"Thresh\", thresh)      # Wait for key 'ESC' to quit     key = cv2.waitKey(1) &amp; 0xFF     if key == 27:         break  # That's how you exit cap.release() cv2.destroyAllWindows()    <pre>2024-03-13 18:19:45.703 Python[38035:1992601] WARNING: Secure coding is automatically enabled for restorable state! However, not on all supported macOS versions of this application. Opt-in to secure coding explicitly by implementing NSApplicationDelegate.applicationSupportsSecureRestorableState:.\n</pre> In\u00a0[\u00a0]: Copied! <pre># esse \u00e9 bonus, para quem quiser tentar fazer \n</pre> # esse \u00e9 bonus, para quem quiser tentar fazer"},{"location":"aulas/PDI/lab07/Aula09/sol_motion.html#background-subtraction","title":"Background Subtraction\u00b6","text":"<p>A intui\u00e7\u00e3o de como realizar essa tarefa n\u00f3s j\u00e1 sabemso, basicamente iremos comparar duas imagem: a de refer\u00eancia do fundo com uma segunda imagem de teste. O resultado ir\u00e1 ressaltar a diferen\u00e7a da imagem.</p>"},{"location":"aulas/PDI/lab07/Aula09/sol_motion.html#desafio-1","title":"DESAFIO 1\u00b6","text":"<p>Implemente um c\u00f3digo (simples) que seja capaz de realizar a subtra\u00e7\u00e3o das imagens e detectar movimento.</p> <p>Dica: voc\u00ea pode usar opera\u00e7\u00f5es <code>cv2.absdiff(img1, img2)</code> e se necess\u00e1rio realizar uma opera\u00e7\u00e3o morfologia (abertura/ fechamento, dilata\u00e7\u00e3o/eros\u00e3o) para reduzir o ruido. O resultado deve ser parecido com a imagem \"sala_res.png\".</p>"},{"location":"aulas/PDI/lab07/Aula09/sol_motion.html#use-como-imagens-de-entrada-as-opcoes","title":"USE COMO IMAGENS DE ENTRADA AS OP\u00c7\u00d5ES:\u00b6","text":"<ul> <li>SALA, SALA1, SALA2, SALA3</li> </ul>"},{"location":"aulas/PDI/lab07/Aula09/sol_motion.html#background-subtraction-em-videos","title":"Background Subtraction em videos\u00b6","text":"<p>O desafio acima foi f\u00e1cil! pois existe uma imagem de fundo sozinha, como uma imagem da sala sem vazia. Basta subtrair a nova imagem do plano de fundo. Voc\u00ea obt\u00e9m os objetos de primeiro plano sozinhos.</p> <p>Mas, na maioria dos casos, voc\u00ea pode n\u00e3o ter essa imagem, ent\u00e3o precisamos extrair o plano de fundo de qualquer imagem que tenhamos. Aiiiiii complica as coisas.</p> <p>Na OpenCV podemos implementar isso por meio de dois algoritmos. O primeiro \u00e9 createBackgroundSubtractorKNN() ou createBackgroundSubtractorMOG2(). Isso cria um objeto subtrator de fundo por K-Nearest Neighbor (KNN) ou Mixture of Gaussians (MOG2) . Ent\u00e3o, podemos chamar a fun\u00e7\u00e3o <code>apply()</code> com o objeto para obter a m\u00e1scara do primeiro plano. Podemos exibir diretamente a m\u00e1scara de primeiro plano em tempo real (com video :)).</p> <p>Refer\u00eancia da documenta\u00e7\u00e3o: https://docs.opencv.org/master/de/de1/group__video__motion.html#gac9be925771f805b6fdb614ec2292006d</p>"},{"location":"aulas/PDI/lab07/Aula09/sol_motion.html#executar-video-no-jupyter-notebook-normalmente-da-problema","title":"Executar video no jupyter notebook normalmente da problema.\u00b6","text":"<p>Existem algumas formas de rodar, mas pode ficar delay.</p> <p>Sugest\u00e3o: Escreva um script e execute direto pelo terminal.</p>"},{"location":"aulas/PDI/lab07/Aula09/sol_motion.html#desafio-2","title":"DESAFIO 2\u00b6","text":"<p>Crie um programa python e execute o c\u00f3digo acima. O objetivo, nesse primeiro momento, \u00e9 se familiarizar com a estrutura do c\u00f3digo, para isso, explore os metodos <code>MOG2</code> e <code>KNN</code> e observe os resultados.</p> <p>Explore os parametros da fun\u00e7\u00e3o:</p> <pre><code>history: O numero de frames usado para construir o modelo estatisco da fundo. Quando menor mais rapido.\n\ndist2Threshold: \u00e9 o limiar definido para saber se o pixel pertence ao fundo ou n\u00e3o da imagem. Quando menor mais sensivel.\n\ndetectShadows : Se True, a sombra (shadows) vai aparecer em cinza na imagem.</code></pre>"},{"location":"aulas/PDI/lab07/Aula09/sol_motion.html#desafio-3","title":"DESAFIO 3\u00b6","text":"<p>Fa\u00e7a um programa que detecta o movimento das pessoas andando na rua e marca com um boundBox (retangulo) o que foi detectado.</p> <p>Instru\u00e7\u00f5es/Dicas:</p> <ul> <li><p>Use 'people-walking.mp4' como video para os testes.</p> </li> <li><p>Lembre-se do que j\u00e1 estudamos para remover ruido, real\u00e7ar contorno, detectar bordas....</p> </li> <li><p>Sempre <code>Leia a documenta\u00e7\u00e3o</code>: https://opencv-python-tutroals.readthedocs.io/en/latest/py_tutorials/py_imgproc/py_contours/py_contour_features/py_contour_features.html</p> </li> <li><p>Use a fun\u00e7\u00e3o cv2.boundingRect() para desenhar o retangulo.</p> </li> </ul> <p>O resultado dever ser semelhante ao do video.</p>"},{"location":"aulas/PDI/lab07/Aula09/sol_motion.html#desafio-4-extra-top-das-galaxias","title":"Desafio 4 - Extra top das galaxias!\u00b6","text":"<p>A \u00e1rea de seguran\u00e7a tornou-se um grande mercado, onde empresas desenvolvem e vendem seus produtos. A vigilancia por c\u00e2meras \u00e9 um grande alindo nesse mercado, por v\u00e1rios motivos. Nesse sentido, voc\u00ea foi contratado para desenvolver um sistema de seguran\u00e7a remoto que ir\u00e1 capturar um video remotamente (c\u00e2mera IP) realizar o processamento para detec\u00e7\u00e3o de movimento.</p> <p>Dicas/Instru\u00e7\u00f5es:</p> <ul> <li>Fa\u00e7a uma aplica\u00e7\u00e3o web em <code>Flask</code></li> <li>https://www.youtube.com/watch?v=EkqhIeSZGN8 esse video pode ajudar um pouco</li> <li>https://github.com/arnaldojr/videostream</li> </ul> <p>Se topar o desafio, vamos fazer um projeto IC?</p>"},{"location":"aulas/PDI/lab08/Aula4.html","title":"Lab08 - Relacionamento e opera\u00e7\u00f5es entre imagens","text":"In\u00a0[1]: Copied! <pre>%matplotlib inline\nimport cv2\nfrom matplotlib import pyplot as plt\nimport numpy as np\n\n\nimg = cv2.imread(\"goku.jpg\")\nimg = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n\n# cria uma matriz com o mesmo dimensional da imagem original, mas com valores 100\nmatriz = np.ones(img.shape, dtype=\"uint8\") * 150\n\n\n\nimg2 = cv2.add(img, matriz)\n\n\nplt.imshow(img);\nplt.show()\nplt.imshow(img2);\n</pre> %matplotlib inline import cv2 from matplotlib import pyplot as plt import numpy as np   img = cv2.imread(\"goku.jpg\") img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)  # cria uma matriz com o mesmo dimensional da imagem original, mas com valores 100 matriz = np.ones(img.shape, dtype=\"uint8\") * 150    img2 = cv2.add(img, matriz)   plt.imshow(img); plt.show() plt.imshow(img2); In\u00a0[2]: Copied! <pre>%matplotlib inline\nimport cv2\nfrom matplotlib import pyplot as plt\nimport numpy as np\n\n\nimg = cv2.imread(\"goku.jpg\")\nimg = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n\n# cria uma matriz com o mesmo dimensional da imagem original, mas com valores 100\nmatriz = np.ones(img.shape, dtype=\"uint8\") * 150\n\n\n\nimg2 = cv2.subtract(img, matriz)\n\n\nplt.imshow(img);\nplt.show()\nplt.imshow(img2);\n</pre> %matplotlib inline import cv2 from matplotlib import pyplot as plt import numpy as np   img = cv2.imread(\"goku.jpg\") img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)  # cria uma matriz com o mesmo dimensional da imagem original, mas com valores 100 matriz = np.ones(img.shape, dtype=\"uint8\") * 150    img2 = cv2.subtract(img, matriz)   plt.imshow(img); plt.show() plt.imshow(img2); In\u00a0[3]: Copied! <pre>%matplotlib inline\nimport cv2\nfrom matplotlib import pyplot as plt\nimport numpy as np\n\n\nimg = cv2.imread(\"jornada.png\")\nimg = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n\n# cria uma matriz com o mesmo dimensional da imagem original, mas com valores 100\nmatriz = np.ones(img.shape, dtype=\"uint8\") * 100\n\n\n\nimg2 = cv2.add(img, matriz)\n\n\nplt.imshow(img);\nplt.show()\nplt.imshow(img2);\n</pre> %matplotlib inline import cv2 from matplotlib import pyplot as plt import numpy as np   img = cv2.imread(\"jornada.png\") img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)  # cria uma matriz com o mesmo dimensional da imagem original, mas com valores 100 matriz = np.ones(img.shape, dtype=\"uint8\") * 100    img2 = cv2.add(img, matriz)   plt.imshow(img); plt.show() plt.imshow(img2); In\u00a0[4]: Copied! <pre>%matplotlib inline\nimport cv2\nfrom matplotlib import pyplot as plt\nimport numpy as np\n\n\n\nsrc1 = cv2.imread('lena.jpg')\nsrc1_rgb = cv2.cvtColor(src1, cv2.COLOR_BGR2RGB)\n\nsrc2 = cv2.imread('rocket.jpg')\nsrc2_rgb = cv2.cvtColor(src2, cv2.COLOR_BGR2RGB)\n\n# 50% de transparencia para cada imagem\ndst = cv2.addWeighted(src1_rgb, 0.5, src2_rgb, 0.5, 0)\n\nplt.imshow(dst);\nplt.show()\n</pre> %matplotlib inline import cv2 from matplotlib import pyplot as plt import numpy as np    src1 = cv2.imread('lena.jpg') src1_rgb = cv2.cvtColor(src1, cv2.COLOR_BGR2RGB)  src2 = cv2.imread('rocket.jpg') src2_rgb = cv2.cvtColor(src2, cv2.COLOR_BGR2RGB)  # 50% de transparencia para cada imagem dst = cv2.addWeighted(src1_rgb, 0.5, src2_rgb, 0.5, 0)  plt.imshow(dst); plt.show() In\u00a0[5]: Copied! <pre>import cv2\nimport numpy as np\n\nimg = cv2.imread('lena.jpg',0)\n\n\nplt.imshow(img, cmap=\"gray\")\nplt.show()\n</pre> import cv2 import numpy as np  img = cv2.imread('lena.jpg',0)   plt.imshow(img, cmap=\"gray\") plt.show()  In\u00a0[6]: Copied! <pre># Aplicando NOT\nm_not = cv2.bitwise_not(img)\n\nplt.imshow(m_not, cmap=\"gray\")\nplt.show()\n</pre> # Aplicando NOT m_not = cv2.bitwise_not(img)  plt.imshow(m_not, cmap=\"gray\") plt.show()  In\u00a0[7]: Copied! <pre># Criando uma imagen inicial preta\nmask = np.zeros((img.shape[0], img.shape[1]), dtype=\"uint8\")\n\n# Coordenada central\ncenter = (int(img.shape[1]/2), int(img.shape[0]/2))\n\n# Tamanho do raio\nradius = int((img.shape[0]/2)*0.8)\n\n# Desenhando circulo braco\ncv2.circle(mask, center, radius, 255, -1)\n\nplt.imshow(mask, cmap=\"gray\")\nplt.show()\n</pre> # Criando uma imagen inicial preta mask = np.zeros((img.shape[0], img.shape[1]), dtype=\"uint8\")  # Coordenada central center = (int(img.shape[1]/2), int(img.shape[0]/2))  # Tamanho do raio radius = int((img.shape[0]/2)*0.8)  # Desenhando circulo braco cv2.circle(mask, center, radius, 255, -1)  plt.imshow(mask, cmap=\"gray\") plt.show()   In\u00a0[8]: Copied! <pre># Aplicando AND\nm_and = cv2.bitwise_and(img,mask)\nplt.imshow(m_and, cmap=\"gray\")\nplt.show()\n</pre> # Aplicando AND m_and = cv2.bitwise_and(img,mask) plt.imshow(m_and, cmap=\"gray\") plt.show()  In\u00a0[9]: Copied! <pre># Aplicando OR\nm_or = cv2.bitwise_or(img,mask)\nplt.imshow(m_or, cmap=\"gray\")\nplt.show()\n</pre> # Aplicando OR m_or = cv2.bitwise_or(img,mask) plt.imshow(m_or, cmap=\"gray\") plt.show() In\u00a0[10]: Copied! <pre># Aplicando XOR\nm_xor = cv2.bitwise_xor(img,mask)\nplt.imshow(m_xor, cmap=\"gray\")\nplt.show()\n</pre> # Aplicando XOR m_xor = cv2.bitwise_xor(img,mask) plt.imshow(m_xor, cmap=\"gray\") plt.show() In\u00a0[\u00a0]: Copied! <pre>\n</pre>"},{"location":"aulas/PDI/lab08/Aula4.html#operacoes-aritmeticas","title":"Opera\u00e7\u00f5es aritm\u00e9ticas\u00b6","text":"<p>Objetivos: Compreender e praticar relacionamento e opera\u00e7\u00f5es entre imagens</p> <p>Sim, por que n\u00e3o?? lembre que uma imagem nada mais \u00e9 que uma matriz. Logo podemos aplicar as mais diversas opera\u00e7\u00f5es matem\u00e1ticas.</p>"},{"location":"aulas/PDI/lab08/Aula4.html#soma-e-subtracao","title":"Soma e Subtra\u00e7\u00e3o\u00b6","text":"<p>Podemos aplicar opera\u00e7\u00f5es matem\u00e1ticas para alterar o brilho e contraste de uma imagem. Na OpenCV usamos as fun\u00e7\u00f5es cv2.add() e cv2.subtract()</p>"},{"location":"aulas/PDI/lab08/Aula4.html#sobreposicao-de-imagens","title":"Sobreposi\u00e7\u00e3o de imagens\u00b6","text":"<p>Para realizar a sobreposi\u00e7\u00e3o de imagens, ou blending, a OpenCV possui a fun\u00e7\u00e3o cv2.addWeighted(). Neste caso precisamos ponderar a porcentagem de cada imagem na imagem final.</p>"},{"location":"aulas/PDI/lab08/Aula4.html#operacoes-logicas","title":"Opera\u00e7\u00f5es L\u00f3gicas\u00b6","text":"<p>Podemos executar nas imagens opera\u00e7\u00f5es l\u00f3gicas, como as mais usuais: NOT, AND, OR e XOR</p>"},{"location":"aulas/PDI/lab09/aula.html","title":"Lab09 - FFT","text":"<p>Objetivo: - Conhecer e praticar filtragem no dom\u00ednio da frequ\u00eancia.</p> In\u00a0[1]: Copied! <pre>import cv2\nfrom matplotlib import pyplot as plt\nimport numpy as np\n\n\n#carrega imagem\nimg = cv2.imread('face.png',0)\n\n# Transforma\u00e7\u00e3o discreta de Fourier\ndft = cv2.dft(np.float32(img),flags = cv2.DFT_COMPLEX_OUTPUT)\ndft = np.fft.fftshift(dft)\n\n\n# Aplicado uma fun\u00e7\u00e3o log para visualiza\u00e7\u00e3o da magnitude do espectro\nmagnitude_spectrum = np.log(cv2.magnitude(dft[:,:,0],dft[:,:,1]))\n\n\n# Visualiza\u00e7\u00e3o das imagens\nfig = plt.figure(figsize=(20,20))\nplt.subplot(1, 2, 1),plt.title('Original')\nplt.imshow(img, cmap=\"gray\")\nplt.subplot(1, 2, 2),plt.title('magnitude_spectrum')\nplt.imshow(magnitude_spectrum, cmap=\"gray\")\nplt.show()\n</pre> import cv2 from matplotlib import pyplot as plt import numpy as np   #carrega imagem img = cv2.imread('face.png',0)  # Transforma\u00e7\u00e3o discreta de Fourier dft = cv2.dft(np.float32(img),flags = cv2.DFT_COMPLEX_OUTPUT) dft = np.fft.fftshift(dft)   # Aplicado uma fun\u00e7\u00e3o log para visualiza\u00e7\u00e3o da magnitude do espectro magnitude_spectrum = np.log(cv2.magnitude(dft[:,:,0],dft[:,:,1]))   # Visualiza\u00e7\u00e3o das imagens fig = plt.figure(figsize=(20,20)) plt.subplot(1, 2, 1),plt.title('Original') plt.imshow(img, cmap=\"gray\") plt.subplot(1, 2, 2),plt.title('magnitude_spectrum') plt.imshow(magnitude_spectrum, cmap=\"gray\") plt.show()  In\u00a0[9]: Copied! <pre>import cv2\nfrom matplotlib import pyplot as plt\nimport numpy as np\n\n\n#carrega imagem\nimg = cv2.imread('face.png',0)\n\n\n# extraindo shape da imagem\nrows, cols = img.shape\nhalf_row, half_col = rows/2 , cols/2\nlimiar = 40\n\n\n# Criando a m\u00e1scara quadrada\nmask = np.zeros((rows,cols,2),np.uint8)\nmask[int(half_row-limiar):int(half_row+limiar), int(half_col-limiar):int(half_col+limiar)] = 1\n\n\n# Transformada discreta de Fourier\ndft = cv2.dft(np.float32(img),flags = cv2.DFT_COMPLEX_OUTPUT)\ndft = np.fft.fftshift(dft)\n\n# Aplicar filtro na imagem\ndft_mask = dft*mask\n\n\n# Transformada inversa de Fourier\ndft_mask = np.fft.ifftshift(dft_mask)\nimg_restored = cv2.idft(dft_mask)\nimg_restored = cv2.magnitude(img_restored[:,:,0],img_restored[:,:,1])\n\n\n# Visualiza\u00e7\u00e3o das imagens\nfig = plt.figure(figsize=(20,20))\nplt.subplot(1, 2, 1),plt.title('Original')\nplt.imshow(img, cmap=\"gray\")\nplt.subplot(1, 2, 2),plt.title('img_restored')\nplt.imshow(img_restored, cmap=\"gray\")\nplt.show()\n</pre> import cv2 from matplotlib import pyplot as plt import numpy as np   #carrega imagem img = cv2.imread('face.png',0)   # extraindo shape da imagem rows, cols = img.shape half_row, half_col = rows/2 , cols/2 limiar = 40   # Criando a m\u00e1scara quadrada mask = np.zeros((rows,cols,2),np.uint8) mask[int(half_row-limiar):int(half_row+limiar), int(half_col-limiar):int(half_col+limiar)] = 1   # Transformada discreta de Fourier dft = cv2.dft(np.float32(img),flags = cv2.DFT_COMPLEX_OUTPUT) dft = np.fft.fftshift(dft)  # Aplicar filtro na imagem dft_mask = dft*mask   # Transformada inversa de Fourier dft_mask = np.fft.ifftshift(dft_mask) img_restored = cv2.idft(dft_mask) img_restored = cv2.magnitude(img_restored[:,:,0],img_restored[:,:,1])   # Visualiza\u00e7\u00e3o das imagens fig = plt.figure(figsize=(20,20)) plt.subplot(1, 2, 1),plt.title('Original') plt.imshow(img, cmap=\"gray\") plt.subplot(1, 2, 2),plt.title('img_restored') plt.imshow(img_restored, cmap=\"gray\") plt.show() In\u00a0[3]: Copied! <pre>import cv2\nfrom matplotlib import pyplot as plt\nimport numpy as np\n\n\n#carrega imagem\nimg = cv2.imread('face.png',0)\n\n\n# extraindo shape da imagem\nrows, cols = img.shape\nhalf_row, half_col = rows/2 , cols/2\nlimiar = 10\n\n\n# Criando a m\u00e1scara quadrada\nmask = np.ones((rows,cols,2),np.uint8)\nmask[int(half_row-limiar):int(half_row+limiar), int(half_col-limiar):int(half_col+limiar)] = 0\n\n\n# Transformada discreta de Fourier\ndft = cv2.dft(np.float32(img),flags = cv2.DFT_COMPLEX_OUTPUT)\ndft = np.fft.fftshift(dft)\n\n# Aplicar filtro na imagem\ndft_mask = dft*mask\n\n\n# Transformada inversa de Fourier\ndft_mask = np.fft.ifftshift(dft_mask)\nimg_restored = cv2.idft(dft_mask)\nimg_restored = cv2.magnitude(img_restored[:,:,0],img_restored[:,:,1])\n\n\n# Visualiza\u00e7\u00e3o das imagens\nfig = plt.figure(figsize=(20,20))\nplt.subplot(1, 2, 1),plt.title('Original')\nplt.imshow(img, cmap=\"gray\")\nplt.subplot(1, 2, 2),plt.title('img_restored')\nplt.imshow(img_restored, cmap=\"gray\")\nplt.show()\n</pre> import cv2 from matplotlib import pyplot as plt import numpy as np   #carrega imagem img = cv2.imread('face.png',0)   # extraindo shape da imagem rows, cols = img.shape half_row, half_col = rows/2 , cols/2 limiar = 10   # Criando a m\u00e1scara quadrada mask = np.ones((rows,cols,2),np.uint8) mask[int(half_row-limiar):int(half_row+limiar), int(half_col-limiar):int(half_col+limiar)] = 0   # Transformada discreta de Fourier dft = cv2.dft(np.float32(img),flags = cv2.DFT_COMPLEX_OUTPUT) dft = np.fft.fftshift(dft)  # Aplicar filtro na imagem dft_mask = dft*mask   # Transformada inversa de Fourier dft_mask = np.fft.ifftshift(dft_mask) img_restored = cv2.idft(dft_mask) img_restored = cv2.magnitude(img_restored[:,:,0],img_restored[:,:,1])   # Visualiza\u00e7\u00e3o das imagens fig = plt.figure(figsize=(20,20)) plt.subplot(1, 2, 1),plt.title('Original') plt.imshow(img, cmap=\"gray\") plt.subplot(1, 2, 2),plt.title('img_restored') plt.imshow(img_restored, cmap=\"gray\") plt.show() In\u00a0[\u00a0]: Copied! <pre>\n</pre>"},{"location":"aulas/PDI/lab09/aula.html#filtros-espectrais","title":"Filtros espectrais\u00b6","text":"<p>Filtragem espectral \u00e9 uma opera\u00e7\u00e3o que tem a finalidade de refor\u00e7ar ou atenuar certas frequ\u00eancias na imagem, mudando suas caracter\u00edsticas de suaviza\u00e7\u00e3o ou refor\u00e7o das bordas dos objetos.</p>"},{"location":"aulas/PDI/lab09/aula.html#transformada-de-fourier","title":"Transformada de Fourier\u00b6","text":"<p>Da mesma forma que existe audio com grave e agudo, existe imagens com frequencias baixa e alta. A Transformada de Fourier \u00e9 usada para analisar as caracter\u00edsticas de frequ\u00eancia de v\u00e1rios filtros. Para imagens, a Transformada Discreta de Fourier 2D (DFT) \u00e9 usada para encontrar a imagem no dom\u00ednio da frequ\u00eancia. Um algoritmo r\u00e1pido chamado Fast Fourier Transform (FFT) \u00e9 usado para o c\u00e1lculo da DFT.</p>"},{"location":"aulas/PDI/lab09/aula.html#exibindo-uma-imagem-no-dominio-da-frequencia","title":"Exibindo uma imagem no dominio da frequ\u00eancia\u00b6","text":"<p>Na OpenCV usamos a fun\u00e7\u00e3o cv2.dft()</p>"},{"location":"aulas/PDI/lab09/aula.html#filtro-espectral","title":"Filtro espectral\u00b6","text":"<p>O filtro espectral (ou no dom\u00ednio das frequ\u00eancias) usa o espectro da imagem para ressaltar ou atenuar determinadas carecter\u00edsticas de frequ\u00eancias da imagem. O mais comum \u00e9 empregar filtros que manipulam diretamente a magnitude das frequ\u00eancias, que podem ser do tipo:</p> <ul> <li>Filtro passa-baixas (PB): real\u00e7a baixas frequ\u00eancias e atenua as altas, multiplicando por valores baixos a magnitude das frequ\u00eancias maiores</li> <li>Filtro passa-altas (PA): real\u00e7a altas frequ\u00eancias e atenua as baixas, multiplicando por valores baixos a magnitude das frequ\u00eancias menores</li> <li>Filtro passa-faixa (PF): real\u00e7a uma regi\u00e3o do espectro em torno de determinada frequ\u00eancia</li> </ul>"},{"location":"aulas/PDI/lab09/aula.html#filtro-passa-baixas","title":"Filtro passa-baixas\u00b6","text":""},{"location":"aulas/PDI/lab09/aula.html#filtro-passa-altas","title":"Filtro passa-altas\u00b6","text":""},{"location":"aulas/PDI/lab10/medidas.html","title":"Lab10 - Medidas aproximadas","text":"<p>O PROBLEMA</p> <p>Como obter os tamanhos dos objetos?</p> In\u00a0[5]: Copied! <pre>%matplotlib inline\nimport cv2\nfrom matplotlib import pyplot as plt\nimport numpy as np\n\nimg = cv2.imread('objects.png')\nimg = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n\nplt.figure(figsize = (10,10))\nplt.imshow(img); plt.show();\n</pre> %matplotlib inline import cv2 from matplotlib import pyplot as plt import numpy as np  img = cv2.imread('objects.png') img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)  plt.figure(figsize = (10,10)) plt.imshow(img); plt.show(); <p>EXERC\u00cdCIO</p> <p>Calcular as arestas dos objetos da imagem acima.</p> In\u00a0[2]: Copied! <pre>#carregamos a imagem, convertemos para n\u00edveis de cinza e a borramos levemente\nimage = cv2.imread('objects.png')\nimage = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\ngray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n\n# aplico um filtro gaussiano para suaviazar a imagem...\ngray = cv2.GaussianBlur(gray, (9,9), 0)\n\n#calculamos as arestas e realizamos uma dilata\u00e7\u00e3o + eros\u00e3o para fechar\n#eventuais gaps entre as arestas dos objetos\nedged = cv2.Canny(gray, 50, 250)\ndilate = cv2.dilate(edged, None, iterations=2)\nerode = cv2.erode(dilate, None, iterations=2)\n\nplt.figure(figsize = (20,15))\nplt.subplot(2, 2, 1), plt.imshow(image)\nplt.subplot(2, 2, 2), plt.imshow(gray, 'gray'), plt.title('gray')\nplt.subplot(2, 2, 3), plt.imshow(dilate, 'gray'), plt.title('dilate')\nplt.subplot(2, 2, 4), plt.imshow(erode, 'gray'), plt.title('erode')\n\nplt.show();\n</pre> #carregamos a imagem, convertemos para n\u00edveis de cinza e a borramos levemente image = cv2.imread('objects.png') image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB) gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)  # aplico um filtro gaussiano para suaviazar a imagem... gray = cv2.GaussianBlur(gray, (9,9), 0)  #calculamos as arestas e realizamos uma dilata\u00e7\u00e3o + eros\u00e3o para fechar #eventuais gaps entre as arestas dos objetos edged = cv2.Canny(gray, 50, 250) dilate = cv2.dilate(edged, None, iterations=2) erode = cv2.erode(dilate, None, iterations=2)  plt.figure(figsize = (20,15)) plt.subplot(2, 2, 1), plt.imshow(image) plt.subplot(2, 2, 2), plt.imshow(gray, 'gray'), plt.title('gray') plt.subplot(2, 2, 3), plt.imshow(dilate, 'gray'), plt.title('dilate') plt.subplot(2, 2, 4), plt.imshow(erode, 'gray'), plt.title('erode')  plt.show(); In\u00a0[3]: Copied! <pre>#uma solu\u00e7\u00e3o possivel...\n\n#carregamos a imagem, convertemos para n\u00edveis de cinza e a borramos levemente\nimage = cv2.imread('objects.png')\nimage = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\ngray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n\n# aplico um filtro gaussiano para suaviazar a imagem...\ngray = cv2.GaussianBlur(gray, (7,7), 0)\n\n#calculamos as arestas e realizamos uma dilata\u00e7\u00e3o + eros\u00e3o para fechar\n#eventuais gaps entre as arestas dos objetos\nedged = cv2.Canny(gray, 50, 150)\ndilate = cv2.dilate(edged, None, iterations=2)\nerode = cv2.erode(dilate, None, iterations=1)\n\nplt.figure(figsize = (20,15))\nplt.subplot(2, 2, 1), plt.imshow(gray, 'gray'), plt.title('gray')\nplt.subplot(2, 2, 2), plt.imshow(edged, 'gray'), plt.title('edged')\nplt.subplot(2, 2, 3), plt.imshow(dilate, 'gray'), plt.title('dilate')\nplt.subplot(2, 2, 4), plt.imshow(erode, 'gray'), plt.title('erode')\nplt.show();\n</pre> #uma solu\u00e7\u00e3o possivel...  #carregamos a imagem, convertemos para n\u00edveis de cinza e a borramos levemente image = cv2.imread('objects.png') image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB) gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)  # aplico um filtro gaussiano para suaviazar a imagem... gray = cv2.GaussianBlur(gray, (7,7), 0)  #calculamos as arestas e realizamos uma dilata\u00e7\u00e3o + eros\u00e3o para fechar #eventuais gaps entre as arestas dos objetos edged = cv2.Canny(gray, 50, 150) dilate = cv2.dilate(edged, None, iterations=2) erode = cv2.erode(dilate, None, iterations=1)  plt.figure(figsize = (20,15)) plt.subplot(2, 2, 1), plt.imshow(gray, 'gray'), plt.title('gray') plt.subplot(2, 2, 2), plt.imshow(edged, 'gray'), plt.title('edged') plt.subplot(2, 2, 3), plt.imshow(dilate, 'gray'), plt.title('dilate') plt.subplot(2, 2, 4), plt.imshow(erode, 'gray'), plt.title('erode') plt.show();  In\u00a0[4]: Copied! <pre>## pratique um pouco, rode os exemplos dos links para te ajudar a compreender o que est\u00e1 acontecendo...\n</pre> ## pratique um pouco, rode os exemplos dos links para te ajudar a compreender o que est\u00e1 acontecendo...    In\u00a0[5]: Copied! <pre>## pratique um pouco, rode os exemplos dos links para te ajudar a compreender o que est\u00e1 acontecendo...\n</pre> ## pratique um pouco, rode os exemplos dos links para te ajudar a compreender o que est\u00e1 acontecendo...   In\u00a0[6]: Copied! <pre>## pratique um pouco, rode os exemplos dos links para te ajudar a compreender o que est\u00e1 acontecendo...\n</pre> ## pratique um pouco, rode os exemplos dos links para te ajudar a compreender o que est\u00e1 acontecendo...   In\u00a0[7]: Copied! <pre>cnts, _ = cv2.findContours(erode.copy(),cv2.RETR_EXTERNAL,cv2.CHAIN_APPROX_SIMPLE)\n\n# Ordena a lista de contornos para ficar da esquerda para direita. \n# Vamos precisar disso mais tarde.  \n# https://github.com/jrosebr1/imutils/blob/master/imutils/contours.py\n\n(cnts, boundingBoxes) = zip(*sorted(zip(cnts, [cv2.boundingRect(c) for c in cnts]), key=lambda b: b[1][0], reverse=False))\n</pre> cnts, _ = cv2.findContours(erode.copy(),cv2.RETR_EXTERNAL,cv2.CHAIN_APPROX_SIMPLE)  # Ordena a lista de contornos para ficar da esquerda para direita.  # Vamos precisar disso mais tarde.   # https://github.com/jrosebr1/imutils/blob/master/imutils/contours.py  (cnts, boundingBoxes) = zip(*sorted(zip(cnts, [cv2.boundingRect(c) for c in cnts]), key=lambda b: b[1][0], reverse=False)) In\u00a0[8]: Copied! <pre># https://github.com/jrosebr1/imutils/blob/master/imutils/perspective.py\n# ordena os pontos do contorno de tal modo que eles\n# apare\u00e7am na seguinte ordem: topo-esquerda, topo-direita,\n# base-direita e base-esquerda\nimport numpy as np\nfrom scipy.spatial import distance as dist\n\n\ndef order_points(pts):\n     xSorted = pts[np.argsort(pts[:, 0]), :]\n\n    # grab the left-most and right-most points from the sorted\n    # x-roodinate points\n     leftMost = xSorted[:2, :]\n     rightMost = xSorted[2:, :]\n\n    # now, sort the left-most coordinates according to their\n    # y-coordinates so we can grab the top-left and bottom-left\n    # points, respectively\n     leftMost = leftMost[np.argsort(leftMost[:, 1]), :]\n     (tl, bl) = leftMost\n\n    # now that we have the top-left coordinate, use it as an\n    # anchor to calculate the Euclidean distance between the\n    # top-left and right-most points; by the Pythagorean\n    # theorem, the point with the largest distance will be\n    # our bottom-right point\n     D = dist.cdist(tl[np.newaxis], rightMost, \"euclidean\")[0]\n     (br, tr) = rightMost[np.argsort(D)[::-1], :]\n\n    # return the coordinates in top-left, top-right,\n    # bottom-right, and bottom-left order\n     return np.array([tl, tr, br, bl], dtype=\"float32\")   \n</pre> # https://github.com/jrosebr1/imutils/blob/master/imutils/perspective.py # ordena os pontos do contorno de tal modo que eles # apare\u00e7am na seguinte ordem: topo-esquerda, topo-direita, # base-direita e base-esquerda import numpy as np from scipy.spatial import distance as dist   def order_points(pts):      xSorted = pts[np.argsort(pts[:, 0]), :]      # grab the left-most and right-most points from the sorted     # x-roodinate points      leftMost = xSorted[:2, :]      rightMost = xSorted[2:, :]      # now, sort the left-most coordinates according to their     # y-coordinates so we can grab the top-left and bottom-left     # points, respectively      leftMost = leftMost[np.argsort(leftMost[:, 1]), :]      (tl, bl) = leftMost      # now that we have the top-left coordinate, use it as an     # anchor to calculate the Euclidean distance between the     # top-left and right-most points; by the Pythagorean     # theorem, the point with the largest distance will be     # our bottom-right point      D = dist.cdist(tl[np.newaxis], rightMost, \"euclidean\")[0]      (br, tr) = rightMost[np.argsort(D)[::-1], :]      # return the coordinates in top-left, top-right,     # bottom-right, and bottom-left order      return np.array([tl, tr, br, bl], dtype=\"float32\")    In\u00a0[9]: Copied! <pre>orig = image.copy()\n\n#Percorre todos os contornos\nfor c in cnts:\n  # se o contorno n\u00e3o \u00e9 suficientemente grande, ignor\u00e1-lo\n  if cv2.contourArea(c) &lt; 100:\n    continue\n  \n  # calcula a bounding box rotacionada do contorno\n  box = cv2.minAreaRect(c)\n  box = cv2.boxPoints(box) \n  box = np.array(box, dtype=\"int\")\n\n  #ordena os pontos do contorno de tal modo que eles\n  #apare\u00e7am na seguinte ordem: topo-esquerda, topo-direita,\n  #base-direita e base-esquerda\n  \n  box = order_points(box)\n  #print(box)\n  cv2.drawContours(orig, [box.astype(\"int\")], -1, (0, 255, 0), 2)\n  for (x, y) in box:\n    cv2.circle(orig, (int(x), int(y)), 5, (255, 0, 0), -1)\n\nplt.figure(figsize = (10,10))\nplt.imshow(orig); plt.show();\n</pre>  orig = image.copy()  #Percorre todos os contornos for c in cnts:   # se o contorno n\u00e3o \u00e9 suficientemente grande, ignor\u00e1-lo   if cv2.contourArea(c) &lt; 100:     continue      # calcula a bounding box rotacionada do contorno   box = cv2.minAreaRect(c)   box = cv2.boxPoints(box)    box = np.array(box, dtype=\"int\")    #ordena os pontos do contorno de tal modo que eles   #apare\u00e7am na seguinte ordem: topo-esquerda, topo-direita,   #base-direita e base-esquerda      box = order_points(box)   #print(box)   cv2.drawContours(orig, [box.astype(\"int\")], -1, (0, 255, 0), 2)   for (x, y) in box:     cv2.circle(orig, (int(x), int(y)), 5, (255, 0, 0), -1)  plt.figure(figsize = (10,10)) plt.imshow(orig); plt.show();  <p>OBTEN\u00c7\u00c3O DOS PONTOS M\u00c9DIOS</p> <p>Vamos, agora, obter os pontos-m\u00e9dios de cada regi\u00e3o identificada e desenh\u00e1-los:</p> In\u00a0[10]: Copied! <pre>import numpy as np\n\ndef midpoint(ptA, ptB):\n  return ((ptA[0] + ptB[0]) * 0.5, (ptA[1] + ptB[1]) * 0.5)\n\norig = image.copy()\n#Percorre todos os contornos\nfor c in cnts:\n  # ignora contornos muito pequenos\n  if cv2.contourArea(c) &lt; 100:\n    continue\n  # calcula a bounding box rotacionada do contorno\n  box = cv2.minAreaRect(c)\n  box = cv2.boxPoints(box) \n  box = np.array(box, dtype=\"int\")\n  \n  #ordena os pontos do contorno de tal modo que eles\n  #apare\u00e7am na seguinte ordem: top-left, top-right,\n  #bottom-right e bottom-left\n  box = order_points(box)\n  cv2.drawContours(orig, [box.astype(\"int\")], -1, (0, 255, 0), 2)\n  for (x, y) in box:\n    cv2.circle(orig, (int(x), int(y)), 5, (255, 0, 0), -1)\n\n    \n #-----------------------------------isso \u00e9 novidade ----------------   \n    \n  #obt\u00e9m os pontos m\u00e9dios de top-left/top-right e bottom-left e bottom-right\n  (tl, tr, br, bl) = box\n  (tltrX, tltrY) = midpoint(tl, tr)\n  (blbrX, blbrY) = midpoint(bl, br)\n  \n  #obt\u00e9m os pontos m\u00e9dios de top-left/bottom-left e top-right e bottom-right\n  (tlblX, tlblY) = midpoint(tl, bl)\n  (trbrX, trbrY) = midpoint(tr, br)\n\n  #desenha c\u00edculos nos pontos-m\u00e9dios\n  cv2.circle(orig, (int(tltrX), int(tltrY)), 5, (255, 0, 0), -1)\n  cv2.circle(orig, (int(blbrX), int(blbrY)), 5, (255, 0, 0), -1)\n  cv2.circle(orig, (int(tlblX), int(tlblY)), 5, (255, 0, 0), -1)\n  cv2.circle(orig, (int(trbrX), int(trbrY)), 5, (255, 0, 0), -1)\n  \n  #une os pontos-m\u00e9dios com segmentos de reta\n  cv2.line(orig, (int(tltrX), int(tltrY)), (int(blbrX), int(blbrY)),(255, 0, 255), 2)\n  cv2.line(orig, (int(tlblX), int(tlblY)), (int(trbrX), int(trbrY)),(255, 0, 255), 2)\n\nplt.figure(figsize = (10,10))\nplt.imshow(orig); plt.show();\n</pre> import numpy as np  def midpoint(ptA, ptB):   return ((ptA[0] + ptB[0]) * 0.5, (ptA[1] + ptB[1]) * 0.5)  orig = image.copy() #Percorre todos os contornos for c in cnts:   # ignora contornos muito pequenos   if cv2.contourArea(c) &lt; 100:     continue   # calcula a bounding box rotacionada do contorno   box = cv2.minAreaRect(c)   box = cv2.boxPoints(box)    box = np.array(box, dtype=\"int\")      #ordena os pontos do contorno de tal modo que eles   #apare\u00e7am na seguinte ordem: top-left, top-right,   #bottom-right e bottom-left   box = order_points(box)   cv2.drawContours(orig, [box.astype(\"int\")], -1, (0, 255, 0), 2)   for (x, y) in box:     cv2.circle(orig, (int(x), int(y)), 5, (255, 0, 0), -1)        #-----------------------------------isso \u00e9 novidade ----------------           #obt\u00e9m os pontos m\u00e9dios de top-left/top-right e bottom-left e bottom-right   (tl, tr, br, bl) = box   (tltrX, tltrY) = midpoint(tl, tr)   (blbrX, blbrY) = midpoint(bl, br)      #obt\u00e9m os pontos m\u00e9dios de top-left/bottom-left e top-right e bottom-right   (tlblX, tlblY) = midpoint(tl, bl)   (trbrX, trbrY) = midpoint(tr, br)    #desenha c\u00edculos nos pontos-m\u00e9dios   cv2.circle(orig, (int(tltrX), int(tltrY)), 5, (255, 0, 0), -1)   cv2.circle(orig, (int(blbrX), int(blbrY)), 5, (255, 0, 0), -1)   cv2.circle(orig, (int(tlblX), int(tlblY)), 5, (255, 0, 0), -1)   cv2.circle(orig, (int(trbrX), int(trbrY)), 5, (255, 0, 0), -1)      #une os pontos-m\u00e9dios com segmentos de reta   cv2.line(orig, (int(tltrX), int(tltrY)), (int(blbrX), int(blbrY)),(255, 0, 255), 2)   cv2.line(orig, (int(tlblX), int(tlblY)), (int(trbrX), int(trbrY)),(255, 0, 255), 2)  plt.figure(figsize = (10,10)) plt.imshow(orig); plt.show(); <p>OBTEN\u00c7\u00c3O DAS MEDIDAS</p> <p>Para obter as medidas dos objetos, precisamos tomar um objeto de refer\u00eancia (ponto de calibra\u00e7\u00e3o) de tamanho conhecido. Na imagem anterior, vamos tomar como medida de refer\u00eancia a moeda de d\u00f3lar norte-americano, cujo comprimento \u00e9 2.43 cm. A partir dela, definimos todas as outras medidas.</p> <p>\u00c9 neste ponto que vai servir ter feito a ordena\u00e7\u00e3o do <code>cnts</code> da esquerda para a direita, a nossa moeda de d\u00f3lar esta bem destacada no lado esquerdo da imagem, desta forma fica facil fazer a calibra\u00e7\u00e3o pois ser\u00e1 o primeiro item da lista.</p> In\u00a0[11]: Copied! <pre>width=2.43\npixelsPerMetric=None\n</pre> width=2.43 pixelsPerMetric=None In\u00a0[12]: Copied! <pre>def midpoint(ptA, ptB):\n  return ((ptA[0] + ptB[0]) * 0.5, (ptA[1] + ptB[1]) * 0.5)\n\norig = image.copy()\n#Percorre todos os contornos\nfor c in cnts:\n  # se o contorno n\u00e3o \u00e9 suficientemente grande, ignor\u00e1-lo\n  if cv2.contourArea(c) &lt; 100:\n    continue\n  # calcula a bounding box rotacionada do contorno\n  box = cv2.minAreaRect(c)\n  box = cv2.boxPoints(box) \n  box = np.array(box, dtype=\"int\")\n  #ordena os pontos do contorno de tal modo que eles\n  #apare\u00e7am na seguinte ordem: top-left, top-right,\n  #bottom-right e bottom-left\n  box = order_points(box)\n  cv2.drawContours(orig, [box.astype(\"int\")], -1, (0, 255, 0), 2)\n  for (x, y) in box:\n    cv2.circle(orig, (int(x), int(y)), 5, (25, 0, 0), -1)\n\n  #obt\u00e9m os pontos m\u00e9dios de top-left/top-right e bottom-left e bottom-right\n  (tl, tr, br, bl) = box\n  (tltrX, tltrY) = midpoint(tl, tr)\n  (blbrX, blbrY) = midpoint(bl, br)\n  \n  #obt\u00e9m os pontos m\u00e9dios de top-left/bottom-left e top-right e bottom-right\n  (tlblX, tlblY) = midpoint(tl, bl)\n  (trbrX, trbrY) = midpoint(tr, br)\n\n  #desenha c\u00edculos nos pontos-m\u00e9dios\n  cv2.circle(orig, (int(tltrX), int(tltrY)), 5, (255, 0, 0), -1)\n  cv2.circle(orig, (int(blbrX), int(blbrY)), 5, (255, 0, 0), -1)\n  cv2.circle(orig, (int(tlblX), int(tlblY)), 5, (255, 0, 0), -1)\n  cv2.circle(orig, (int(trbrX), int(trbrY)), 5, (255, 0, 0), -1)\n  \n  #une os pontos-m\u00e9dios com segmentos de reta\n  cv2.line(orig, (int(tltrX), int(tltrY)), (int(blbrX), int(blbrY)),(255, 0, 255), 2)\n  cv2.line(orig, (int(tlblX), int(tlblY)), (int(trbrX), int(trbrY)),(255, 0, 255), 2)\n ###-------------n\u00e3o te mnovidade  \n    \n  # C\u00e1lculo da dist\u00e2ncia entre dois pontos, dist\u00e2ncia euclidiana\n  dA = dist.euclidean((tltrX, tltrY), (blbrX, blbrY))\n  dB = dist.euclidean((tlblX, tlblY), (trbrX, trbrY))\n\n##########---------------isso \u00e9 novidade--------------------------------------------------------------------\n\n  # define a escala para relacionar pixel por centrimetro\n  if pixelsPerMetric is None:\n    pixelsPerMetric = dB / width\n  \n  dimA = dA / pixelsPerMetric\n  dimB = dB / pixelsPerMetric\n  \n  cv2.putText(orig, \"{:.2f}cm\".format(dimB),(int(tltrX - 15), int(tltrY - 10)), cv2.FONT_HERSHEY_SIMPLEX,0.50, (255, 255, 255), 1)\n  cv2.putText(orig, \"{:.2f}cm\".format(dimA),(int(trbrX + 10), int(trbrY)), cv2.FONT_HERSHEY_SIMPLEX,0.50, (255, 255, 255), 1) \n  \nplt.figure(figsize = (10,10))\nplt.imshow(orig); plt.show();\n</pre> def midpoint(ptA, ptB):   return ((ptA[0] + ptB[0]) * 0.5, (ptA[1] + ptB[1]) * 0.5)  orig = image.copy() #Percorre todos os contornos for c in cnts:   # se o contorno n\u00e3o \u00e9 suficientemente grande, ignor\u00e1-lo   if cv2.contourArea(c) &lt; 100:     continue   # calcula a bounding box rotacionada do contorno   box = cv2.minAreaRect(c)   box = cv2.boxPoints(box)    box = np.array(box, dtype=\"int\")   #ordena os pontos do contorno de tal modo que eles   #apare\u00e7am na seguinte ordem: top-left, top-right,   #bottom-right e bottom-left   box = order_points(box)   cv2.drawContours(orig, [box.astype(\"int\")], -1, (0, 255, 0), 2)   for (x, y) in box:     cv2.circle(orig, (int(x), int(y)), 5, (25, 0, 0), -1)    #obt\u00e9m os pontos m\u00e9dios de top-left/top-right e bottom-left e bottom-right   (tl, tr, br, bl) = box   (tltrX, tltrY) = midpoint(tl, tr)   (blbrX, blbrY) = midpoint(bl, br)      #obt\u00e9m os pontos m\u00e9dios de top-left/bottom-left e top-right e bottom-right   (tlblX, tlblY) = midpoint(tl, bl)   (trbrX, trbrY) = midpoint(tr, br)    #desenha c\u00edculos nos pontos-m\u00e9dios   cv2.circle(orig, (int(tltrX), int(tltrY)), 5, (255, 0, 0), -1)   cv2.circle(orig, (int(blbrX), int(blbrY)), 5, (255, 0, 0), -1)   cv2.circle(orig, (int(tlblX), int(tlblY)), 5, (255, 0, 0), -1)   cv2.circle(orig, (int(trbrX), int(trbrY)), 5, (255, 0, 0), -1)      #une os pontos-m\u00e9dios com segmentos de reta   cv2.line(orig, (int(tltrX), int(tltrY)), (int(blbrX), int(blbrY)),(255, 0, 255), 2)   cv2.line(orig, (int(tlblX), int(tlblY)), (int(trbrX), int(trbrY)),(255, 0, 255), 2)  ###-------------n\u00e3o te mnovidade          # C\u00e1lculo da dist\u00e2ncia entre dois pontos, dist\u00e2ncia euclidiana   dA = dist.euclidean((tltrX, tltrY), (blbrX, blbrY))   dB = dist.euclidean((tlblX, tlblY), (trbrX, trbrY))  ##########---------------isso \u00e9 novidade--------------------------------------------------------------------    # define a escala para relacionar pixel por centrimetro   if pixelsPerMetric is None:     pixelsPerMetric = dB / width      dimA = dA / pixelsPerMetric   dimB = dB / pixelsPerMetric      cv2.putText(orig, \"{:.2f}cm\".format(dimB),(int(tltrX - 15), int(tltrY - 10)), cv2.FONT_HERSHEY_SIMPLEX,0.50, (255, 255, 255), 1)   cv2.putText(orig, \"{:.2f}cm\".format(dimA),(int(trbrX + 10), int(trbrY)), cv2.FONT_HERSHEY_SIMPLEX,0.50, (255, 255, 255), 1)     plt.figure(figsize = (10,10)) plt.imshow(orig); plt.show(); <p>Refer\u00eancia:</p> <ul> <li>https://pyimagesearch.com/2016/03/28/measuring-size-of-objects-in-an-image-with-opencv/</li> </ul> In\u00a0[13]: Copied! <pre>%matplotlib inline\nimport cv2\nfrom matplotlib import pyplot as plt\nimport numpy as np\n\nimg = cv2.imread('objects2.png')\nimg = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n\nplt.figure(figsize = (10,10))\nplt.imshow(img); plt.show();\n</pre> %matplotlib inline import cv2 from matplotlib import pyplot as plt import numpy as np  img = cv2.imread('objects2.png') img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)  plt.figure(figsize = (10,10)) plt.imshow(img); plt.show(); In\u00a0[14]: Copied! <pre>### Seu c\u00f3digo aqui....\n</pre> ### Seu c\u00f3digo aqui....      In\u00a0[\u00a0]: Copied! <pre>\n</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre>"},{"location":"aulas/PDI/lab10/medidas.html#processamento-de-imagens","title":"PROCESSAMENTO DE IMAGENS\u00b6","text":"<p>Objetivos da aula:</p> <ul> <li>reconhecer e fazer medidas b\u00e1sicas e aproximadas de objetos</li> </ul>"},{"location":"aulas/PDI/lab10/medidas.html#desafio1","title":"desafio1\u00b6","text":"<p>Dica r\u00e1pida de python. Vamos utilizar a fun\u00e7\u00e3o <code>zip</code> do python que retorna uma sequ\u00eancia de tuplas. Pratique um pouco essa fun\u00e7\u00e3o.</p> <ul> <li>http://devfuria.com.br/python/built-in-zip/</li> <li>https://pythonhelp.wordpress.com/2013/04/16/funcao-zip-em-python/</li> <li>https://www.programiz.com/python-programming/methods/built-in/zip</li> </ul> <p>obs. O operador <code>*</code> pode ser utilizado com o zip() para descompactar (unzip) uma lista.</p>"},{"location":"aulas/PDI/lab10/medidas.html#desafio2","title":"desafio2\u00b6","text":"<p>Dica r\u00e1pida de python. Vamos utilizar <code>list comprehensions</code> que basicamente realiza de forma compacta uma manipula\u00e7\u00e3o de listas. Pratique um pouco essa fun\u00e7\u00e3o.</p> <ul> <li>https://pythonhelp.wordpress.com/2011/03/01/list-comprehension/</li> <li>https://www.w3schools.com/python/python_lists_comprehension.asp</li> <li>https://pythonacademy.com.br/blog/list-comprehensions-no-python</li> </ul>"},{"location":"aulas/PDI/lab10/medidas.html#desafio3","title":"desafio3\u00b6","text":"<p>Dica r\u00e1pida de python. Vamos utilizar a fun\u00e7\u00e3o <code>lambda</code> que basicamente realiza de forma pratica uma fun\u00e7\u00e3o an\u00f4nima. Pratique um pouco essa fun\u00e7\u00e3o.</p> <ul> <li>https://www.hashtagtreinamentos.com/funcoes-lambda-python?gclid=CjwKCAjwiuuRBhBvEiwAFXKaNF77HmSrHlWg1Tx5Okpt6x9QFZemjbINiX9sX43R-fCNnXkuy8fiTxoCkiEQAvD_BwE</li> <li>https://www.w3schools.com/python/python_lambda.asp</li> <li>https://www.codingame.com/playgrounds/52499/programacao-python-intermediario---prof--marco-vaz/funcao-lambda</li> </ul>"},{"location":"aulas/PDI/lab10/medidas.html#obtencao-dos-contornos","title":"OBTEN\u00c7\u00c3O DOS CONTORNOS\u00b6","text":"<p>A partir das arestas, podemos obter os contornos dos objetos.</p>"},{"location":"aulas/PDI/lab10/medidas.html#desafio","title":"Desafio\u00b6","text":"<p>Realize o processamento da imagem abaixo a fim de obter os dimensionais de todos os cart\u00f5es. Fa\u00e7a a escolha de um dos cart\u00f5es para ser a refer\u00eancia e servir de calibra\u00e7\u00e3o.</p> <p>O cart\u00e3o da esquerda possui 8.89 x 5.08 cm.</p>"},{"location":"aulas/PDI/lab10/medidas.html#desafio-extra-top","title":"Desafio extra top!\u00b6","text":"<p>Um grande problemada industria de manufatura est\u00e1 na determin\u00e7\u00e3o do dimensional de alguns objetos para controle de qualidade. Nesse sentido, voc\u00ea foi contratado para desenvolver um sistema que ir\u00e1 capturar um frame de um v\u00eddeo, processar e definir o seu dimenssional.</p> <p>Se topar o desafio, vamos fazer um projeto IC?</p>"},{"location":"aulas/PDI/lab10/sol_medidas.html","title":"Sol medidas","text":"<p>O PROBLEMA</p> <p>Como obter os tamanhos dos objetos?</p> In\u00a0[\u00a0]: Copied! <pre>%matplotlib inline\nimport cv2\nfrom matplotlib import pyplot as plt\nimport numpy as np\n\nimg = cv2.imread('objects.png')\nimg = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n\nplt.figure(figsize = (10,10))\nplt.imshow(img); plt.show();\n</pre> %matplotlib inline import cv2 from matplotlib import pyplot as plt import numpy as np  img = cv2.imread('objects.png') img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)  plt.figure(figsize = (10,10)) plt.imshow(img); plt.show(); <p>EXERC\u00cdCIO</p> <p>Calcular as arestas dos objetos da imagem acima.</p> In\u00a0[\u00a0]: Copied! <pre>#carregamos a imagem, convertemos para n\u00edveis de cinza e a borramos levemente\nimage = cv2.imread('objects.png')\nimage = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\ngray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n\n# aplico um filtro gaussiano para suaviazar a imagem...\ngray = cv2.GaussianBlur(gray, (9,9), 0)\n\n#calculamos as arestas e realizamos uma dilata\u00e7\u00e3o + eros\u00e3o para fechar\n#eventuais gaps entre as arestas dos objetos\nedged = cv2.Canny(gray, 50, 250)\ndilate = cv2.dilate(edged, None, iterations=2)\nerode = cv2.erode(dilate, None, iterations=2)\n\nplt.figure(figsize = (20,15))\nplt.subplot(2, 2, 1), plt.imshow(image)\nplt.subplot(2, 2, 2), plt.imshow(gray, 'gray'), plt.title('gray')\nplt.subplot(2, 2, 3), plt.imshow(dilate, 'gray'), plt.title('dilate')\nplt.subplot(2, 2, 4), plt.imshow(erode, 'gray'), plt.title('erode')\n\nplt.show();\n</pre> #carregamos a imagem, convertemos para n\u00edveis de cinza e a borramos levemente image = cv2.imread('objects.png') image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB) gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)  # aplico um filtro gaussiano para suaviazar a imagem... gray = cv2.GaussianBlur(gray, (9,9), 0)  #calculamos as arestas e realizamos uma dilata\u00e7\u00e3o + eros\u00e3o para fechar #eventuais gaps entre as arestas dos objetos edged = cv2.Canny(gray, 50, 250) dilate = cv2.dilate(edged, None, iterations=2) erode = cv2.erode(dilate, None, iterations=2)  plt.figure(figsize = (20,15)) plt.subplot(2, 2, 1), plt.imshow(image) plt.subplot(2, 2, 2), plt.imshow(gray, 'gray'), plt.title('gray') plt.subplot(2, 2, 3), plt.imshow(dilate, 'gray'), plt.title('dilate') plt.subplot(2, 2, 4), plt.imshow(erode, 'gray'), plt.title('erode')  plt.show(); In\u00a0[\u00a0]: Copied! <pre>#uma solu\u00e7\u00e3o possivel...\n\n#carregamos a imagem, convertemos para n\u00edveis de cinza e a borramos levemente\nimage = cv2.imread('objects.png')\nimage = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\ngray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n\n# aplico um filtro gaussiano para suaviazar a imagem...\ngray = cv2.GaussianBlur(gray, (7,7), 0)\n\n#calculamos as arestas e realizamos uma dilata\u00e7\u00e3o + eros\u00e3o para fechar\n#eventuais gaps entre as arestas dos objetos\nedged = cv2.Canny(gray, 50, 150)\ndilate = cv2.dilate(edged, None, iterations=2)\nerode = cv2.erode(dilate, None, iterations=1)\n\nplt.figure(figsize = (20,15))\nplt.subplot(2, 2, 1), plt.imshow(gray, 'gray'), plt.title('gray')\nplt.subplot(2, 2, 2), plt.imshow(edged, 'gray'), plt.title('edged')\nplt.subplot(2, 2, 3), plt.imshow(dilate, 'gray'), plt.title('dilate')\nplt.subplot(2, 2, 4), plt.imshow(erode, 'gray'), plt.title('erode')\nplt.show();\n</pre> #uma solu\u00e7\u00e3o possivel...  #carregamos a imagem, convertemos para n\u00edveis de cinza e a borramos levemente image = cv2.imread('objects.png') image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB) gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)  # aplico um filtro gaussiano para suaviazar a imagem... gray = cv2.GaussianBlur(gray, (7,7), 0)  #calculamos as arestas e realizamos uma dilata\u00e7\u00e3o + eros\u00e3o para fechar #eventuais gaps entre as arestas dos objetos edged = cv2.Canny(gray, 50, 150) dilate = cv2.dilate(edged, None, iterations=2) erode = cv2.erode(dilate, None, iterations=1)  plt.figure(figsize = (20,15)) plt.subplot(2, 2, 1), plt.imshow(gray, 'gray'), plt.title('gray') plt.subplot(2, 2, 2), plt.imshow(edged, 'gray'), plt.title('edged') plt.subplot(2, 2, 3), plt.imshow(dilate, 'gray'), plt.title('dilate') plt.subplot(2, 2, 4), plt.imshow(erode, 'gray'), plt.title('erode') plt.show();  In\u00a0[\u00a0]: Copied! <pre>## pratique um pouco, rode os exemplos dos links para te ajudar a compreender o que est\u00e1 acontecendo...\n\n# A fun\u00e7ao zip() \u00e9 utilizada para unir duas listas. \n\nlista_a = [6, 7, 8, 9, 1, 2, 3, 4, 5]\nlista_b = ['R', 'A', 'I', 'M', 'U', 'N', 'D', 'O','S']\n\nprint('Unindo as listas...')\nzipado = zip(lista_a, lista_b)\n# print(zipado[0]) ### essa linha vai dar erro, pois zipado \u00e9 um objeto do tipo zip, e n\u00e3o uma lista.\nprint(list(zipado)) ### para visualizar o conte\u00fado de zipado, precisamos converter para lista.\n\nfor x in zip(lista_a, lista_b):\n    print(x)\n\n\n\n# Aproveitando para mostrar a fun\u00e7ao enumerate()...\n# A fun\u00e7ao enumerate() \u00e9 utilizada para retornar o \u00edndice e o valor de um item em uma lista.\nprint('listas com enumerate...')    \nfor x,y in enumerate(zip(lista_a, lista_b)):\n    print(x,y)\n</pre> ## pratique um pouco, rode os exemplos dos links para te ajudar a compreender o que est\u00e1 acontecendo...  # A fun\u00e7ao zip() \u00e9 utilizada para unir duas listas.   lista_a = [6, 7, 8, 9, 1, 2, 3, 4, 5] lista_b = ['R', 'A', 'I', 'M', 'U', 'N', 'D', 'O','S']  print('Unindo as listas...') zipado = zip(lista_a, lista_b) # print(zipado[0]) ### essa linha vai dar erro, pois zipado \u00e9 um objeto do tipo zip, e n\u00e3o uma lista. print(list(zipado)) ### para visualizar o conte\u00fado de zipado, precisamos converter para lista.  for x in zip(lista_a, lista_b):     print(x)    # Aproveitando para mostrar a fun\u00e7ao enumerate()... # A fun\u00e7ao enumerate() \u00e9 utilizada para retornar o \u00edndice e o valor de um item em uma lista. print('listas com enumerate...')     for x,y in enumerate(zip(lista_a, lista_b)):     print(x,y)  In\u00a0[\u00a0]: Copied! <pre>## pratique um pouco, rode os exemplos dos links para te ajudar a compreender o que est\u00e1 acontecendo...\n\n# A funcao list comprehension \u00e9 uma forma de criar listas de forma mais compacta e elegante. 'Pythonica'.\n\n# A sintaxe \u00e9: [expressao for item in lista]\n\n# Exemplo 1:\n\n# da forma tradicional, teriamos que fazer algo assim:\nfruits = [\"apple\", \"banana\", \"cherry\", \"kiwi\", \"mango\"]\nnewlist = []\n\nfor x in fruits:\n  if \"a\" in x:\n    newlist.append(x)\n\nprint(newlist)\n\n# usando list comprehension, podemos fazer assim:\nfruits = [\"apple\", \"banana\", \"cherry\", \"kiwi\", \"mango\"]\nnewlist = [x for x in fruits if \"a\" in x]\nprint(newlist)\n\n# Exemplo 2:\n\n# da forma tradicional, teriamos que fazer algo assim:\nlista = [1, 2, 3, 4, 5]\nnova_lista = []\n\nfor x in lista:\n    nova_lista.append(x + 10)\n\nprint(nova_lista)\n\n# usando list comprehension, podemos fazer assim:\nlista = [1, 2, 3, 4, 5]\nnova_lista = [x + 10 for x in lista]\nprint(nova_lista)\n\n# Exemplo 3:\n# podemos usar list comprehension para somar os elementos de duas listas...\nlista1 = [1, 2, 3, 4, 5]\nlista2 = [6, 7, 8, 9, 10]\n\nsoma = [x + y for x, y in zip(lista1, lista2)]\n\nprint(soma)\n</pre> ## pratique um pouco, rode os exemplos dos links para te ajudar a compreender o que est\u00e1 acontecendo...  # A funcao list comprehension \u00e9 uma forma de criar listas de forma mais compacta e elegante. 'Pythonica'.  # A sintaxe \u00e9: [expressao for item in lista]  # Exemplo 1:  # da forma tradicional, teriamos que fazer algo assim: fruits = [\"apple\", \"banana\", \"cherry\", \"kiwi\", \"mango\"] newlist = []  for x in fruits:   if \"a\" in x:     newlist.append(x)  print(newlist)  # usando list comprehension, podemos fazer assim: fruits = [\"apple\", \"banana\", \"cherry\", \"kiwi\", \"mango\"] newlist = [x for x in fruits if \"a\" in x] print(newlist)  # Exemplo 2:  # da forma tradicional, teriamos que fazer algo assim: lista = [1, 2, 3, 4, 5] nova_lista = []  for x in lista:     nova_lista.append(x + 10)  print(nova_lista)  # usando list comprehension, podemos fazer assim: lista = [1, 2, 3, 4, 5] nova_lista = [x + 10 for x in lista] print(nova_lista)  # Exemplo 3: # podemos usar list comprehension para somar os elementos de duas listas... lista1 = [1, 2, 3, 4, 5] lista2 = [6, 7, 8, 9, 10]  soma = [x + y for x, y in zip(lista1, lista2)]  print(soma) In\u00a0[\u00a0]: Copied! <pre>## pratique um pouco, rode os exemplos dos links para te ajudar a compreender o que est\u00e1 acontecendo...\n\n# a fun\u00e7\u00e3o lambda \u00e9 uma forma de criar fun\u00e7\u00f5es an\u00f4nimas, ou seja, fun\u00e7\u00f5es que n\u00e3o tem um nome associado. \n# Elas s\u00e3o \u00fateis quando voc\u00ea precisa de uma fun\u00e7\u00e3o simples por um curto per\u00edodo de tempo e n\u00e3o quer defini-la usando a sintaxe padr\u00e3o def.\n\n# A sintaxe \u00e9: lambda arguments : expression \n\n# Exemplo 1:\nx = lambda a : a + 10\nprint(x(5))\n\n# Exemplo 2:\nx = lambda a, b : a * b\nprint(x(5, 6))\n\n# Exemplo 3:\nx = lambda a, b, c : a + b + c\nprint(x(5, 6, 2))\n\n# Exemplo 4:\n# podemos usar lambda para ordenar uma lista de tuplas...\nlista = [(1, 2), (4, 1), (9, 10), (13, -3)]\nlista.sort(key=lambda x: x[1])\nprint(lista)\n\n\n# Para avan\u00e7ar na programa\u00e7\u00e3o em linguagem python, sugiro praticar e conhecer essas fun\u00e7\u00f5es e outras tais como: 'map', 'filter' e 'sorted'.\n# A pr\u00e1tica leva a perfei\u00e7\u00e3o.\n</pre> ## pratique um pouco, rode os exemplos dos links para te ajudar a compreender o que est\u00e1 acontecendo...  # a fun\u00e7\u00e3o lambda \u00e9 uma forma de criar fun\u00e7\u00f5es an\u00f4nimas, ou seja, fun\u00e7\u00f5es que n\u00e3o tem um nome associado.  # Elas s\u00e3o \u00fateis quando voc\u00ea precisa de uma fun\u00e7\u00e3o simples por um curto per\u00edodo de tempo e n\u00e3o quer defini-la usando a sintaxe padr\u00e3o def.  # A sintaxe \u00e9: lambda arguments : expression   # Exemplo 1: x = lambda a : a + 10 print(x(5))  # Exemplo 2: x = lambda a, b : a * b print(x(5, 6))  # Exemplo 3: x = lambda a, b, c : a + b + c print(x(5, 6, 2))  # Exemplo 4: # podemos usar lambda para ordenar uma lista de tuplas... lista = [(1, 2), (4, 1), (9, 10), (13, -3)] lista.sort(key=lambda x: x[1]) print(lista)   # Para avan\u00e7ar na programa\u00e7\u00e3o em linguagem python, sugiro praticar e conhecer essas fun\u00e7\u00f5es e outras tais como: 'map', 'filter' e 'sorted'. # A pr\u00e1tica leva a perfei\u00e7\u00e3o.   In\u00a0[\u00a0]: Copied! <pre>cnts, _ = cv2.findContours(erode.copy(),cv2.RETR_EXTERNAL,cv2.CHAIN_APPROX_SIMPLE)\n\n# Ordena a lista de contornos para ficar da esquerda para direita. \n# Vamos precisar disso mais tarde.  \n# https://github.com/jrosebr1/imutils/blob/master/imutils/contours.py\n\n(cnts, boundingBoxes) = zip(*sorted(zip(cnts, [cv2.boundingRect(c) for c in cnts]), key=lambda b: b[1][0], reverse=False))\n</pre> cnts, _ = cv2.findContours(erode.copy(),cv2.RETR_EXTERNAL,cv2.CHAIN_APPROX_SIMPLE)  # Ordena a lista de contornos para ficar da esquerda para direita.  # Vamos precisar disso mais tarde.   # https://github.com/jrosebr1/imutils/blob/master/imutils/contours.py  (cnts, boundingBoxes) = zip(*sorted(zip(cnts, [cv2.boundingRect(c) for c in cnts]), key=lambda b: b[1][0], reverse=False)) In\u00a0[\u00a0]: Copied! <pre># https://github.com/jrosebr1/imutils/blob/master/imutils/perspective.py\n# ordena os pontos do contorno de tal modo que eles\n# apare\u00e7am na seguinte ordem: topo-esquerda, topo-direita,\n# base-direita e base-esquerda\nimport numpy as np\nfrom scipy.spatial import distance as dist\n\n\ndef order_points(pts):\n     xSorted = pts[np.argsort(pts[:, 0]), :]\n\n    # grab the left-most and right-most points from the sorted\n    # x-roodinate points\n     leftMost = xSorted[:2, :]\n     rightMost = xSorted[2:, :]\n\n    # now, sort the left-most coordinates according to their\n    # y-coordinates so we can grab the top-left and bottom-left\n    # points, respectively\n     leftMost = leftMost[np.argsort(leftMost[:, 1]), :]\n     (tl, bl) = leftMost\n\n    # now that we have the top-left coordinate, use it as an\n    # anchor to calculate the Euclidean distance between the\n    # top-left and right-most points; by the Pythagorean\n    # theorem, the point with the largest distance will be\n    # our bottom-right point\n     D = dist.cdist(tl[np.newaxis], rightMost, \"euclidean\")[0]\n     (br, tr) = rightMost[np.argsort(D)[::-1], :]\n\n    # return the coordinates in top-left, top-right,\n    # bottom-right, and bottom-left order\n     return np.array([tl, tr, br, bl], dtype=\"float32\")   \n</pre> # https://github.com/jrosebr1/imutils/blob/master/imutils/perspective.py # ordena os pontos do contorno de tal modo que eles # apare\u00e7am na seguinte ordem: topo-esquerda, topo-direita, # base-direita e base-esquerda import numpy as np from scipy.spatial import distance as dist   def order_points(pts):      xSorted = pts[np.argsort(pts[:, 0]), :]      # grab the left-most and right-most points from the sorted     # x-roodinate points      leftMost = xSorted[:2, :]      rightMost = xSorted[2:, :]      # now, sort the left-most coordinates according to their     # y-coordinates so we can grab the top-left and bottom-left     # points, respectively      leftMost = leftMost[np.argsort(leftMost[:, 1]), :]      (tl, bl) = leftMost      # now that we have the top-left coordinate, use it as an     # anchor to calculate the Euclidean distance between the     # top-left and right-most points; by the Pythagorean     # theorem, the point with the largest distance will be     # our bottom-right point      D = dist.cdist(tl[np.newaxis], rightMost, \"euclidean\")[0]      (br, tr) = rightMost[np.argsort(D)[::-1], :]      # return the coordinates in top-left, top-right,     # bottom-right, and bottom-left order      return np.array([tl, tr, br, bl], dtype=\"float32\")    In\u00a0[\u00a0]: Copied! <pre>orig = image.copy()\n\n#Percorre todos os contornos\nfor c in cnts:\n  # se o contorno n\u00e3o \u00e9 suficientemente grande, ignor\u00e1-lo\n  if cv2.contourArea(c) &lt; 100:\n    continue\n  \n  # calcula a bounding box rotacionada do contorno\n  box = cv2.minAreaRect(c)\n  box = cv2.boxPoints(box) \n  box = np.array(box, dtype=\"int\")\n\n  #ordena os pontos do contorno de tal modo que eles\n  #apare\u00e7am na seguinte ordem: topo-esquerda, topo-direita,\n  #base-direita e base-esquerda\n  \n  box = order_points(box)\n  #print(box)\n  cv2.drawContours(orig, [box.astype(\"int\")], -1, (0, 255, 0), 2)\n  for (x, y) in box:\n    cv2.circle(orig, (int(x), int(y)), 5, (255, 0, 0), -1)\n\nplt.figure(figsize = (10,10))\nplt.imshow(orig); plt.show();\n</pre>  orig = image.copy()  #Percorre todos os contornos for c in cnts:   # se o contorno n\u00e3o \u00e9 suficientemente grande, ignor\u00e1-lo   if cv2.contourArea(c) &lt; 100:     continue      # calcula a bounding box rotacionada do contorno   box = cv2.minAreaRect(c)   box = cv2.boxPoints(box)    box = np.array(box, dtype=\"int\")    #ordena os pontos do contorno de tal modo que eles   #apare\u00e7am na seguinte ordem: topo-esquerda, topo-direita,   #base-direita e base-esquerda      box = order_points(box)   #print(box)   cv2.drawContours(orig, [box.astype(\"int\")], -1, (0, 255, 0), 2)   for (x, y) in box:     cv2.circle(orig, (int(x), int(y)), 5, (255, 0, 0), -1)  plt.figure(figsize = (10,10)) plt.imshow(orig); plt.show();  <p>OBTEN\u00c7\u00c3O DOS PONTOS M\u00c9DIOS</p> <p>Vamos, agora, obter os pontos-m\u00e9dios de cada regi\u00e3o identificada e desenh\u00e1-los:</p> In\u00a0[\u00a0]: Copied! <pre>import numpy as np\n\ndef midpoint(ptA, ptB):\n  return ((ptA[0] + ptB[0]) * 0.5, (ptA[1] + ptB[1]) * 0.5)\n\norig = image.copy()\n#Percorre todos os contornos\nfor c in cnts:\n  # ignora contornos muito pequenos\n  if cv2.contourArea(c) &lt; 100:\n    continue\n  # calcula a bounding box rotacionada do contorno\n  box = cv2.minAreaRect(c)\n  box = cv2.boxPoints(box) \n  box = np.array(box, dtype=\"int\")\n  \n  #ordena os pontos do contorno de tal modo que eles\n  #apare\u00e7am na seguinte ordem: top-left, top-right,\n  #bottom-right e bottom-left\n  box = order_points(box)\n  cv2.drawContours(orig, [box.astype(\"int\")], -1, (0, 255, 0), 2)\n  for (x, y) in box:\n    cv2.circle(orig, (int(x), int(y)), 5, (255, 0, 0), -1)\n\n    \n #-----------------------------------isso \u00e9 novidade ----------------   \n    \n  #obt\u00e9m os pontos m\u00e9dios de top-left/top-right e bottom-left e bottom-right\n  (tl, tr, br, bl) = box\n  (tltrX, tltrY) = midpoint(tl, tr)\n  (blbrX, blbrY) = midpoint(bl, br)\n  \n  #obt\u00e9m os pontos m\u00e9dios de top-left/bottom-left e top-right e bottom-right\n  (tlblX, tlblY) = midpoint(tl, bl)\n  (trbrX, trbrY) = midpoint(tr, br)\n\n  #desenha c\u00edculos nos pontos-m\u00e9dios\n  cv2.circle(orig, (int(tltrX), int(tltrY)), 5, (255, 0, 0), -1)\n  cv2.circle(orig, (int(blbrX), int(blbrY)), 5, (255, 0, 0), -1)\n  cv2.circle(orig, (int(tlblX), int(tlblY)), 5, (255, 0, 0), -1)\n  cv2.circle(orig, (int(trbrX), int(trbrY)), 5, (255, 0, 0), -1)\n  \n  #une os pontos-m\u00e9dios com segmentos de reta\n  cv2.line(orig, (int(tltrX), int(tltrY)), (int(blbrX), int(blbrY)),(255, 0, 255), 2)\n  cv2.line(orig, (int(tlblX), int(tlblY)), (int(trbrX), int(trbrY)),(255, 0, 255), 2)\n\nplt.figure(figsize = (10,10))\nplt.imshow(orig); plt.show();\n</pre> import numpy as np  def midpoint(ptA, ptB):   return ((ptA[0] + ptB[0]) * 0.5, (ptA[1] + ptB[1]) * 0.5)  orig = image.copy() #Percorre todos os contornos for c in cnts:   # ignora contornos muito pequenos   if cv2.contourArea(c) &lt; 100:     continue   # calcula a bounding box rotacionada do contorno   box = cv2.minAreaRect(c)   box = cv2.boxPoints(box)    box = np.array(box, dtype=\"int\")      #ordena os pontos do contorno de tal modo que eles   #apare\u00e7am na seguinte ordem: top-left, top-right,   #bottom-right e bottom-left   box = order_points(box)   cv2.drawContours(orig, [box.astype(\"int\")], -1, (0, 255, 0), 2)   for (x, y) in box:     cv2.circle(orig, (int(x), int(y)), 5, (255, 0, 0), -1)        #-----------------------------------isso \u00e9 novidade ----------------           #obt\u00e9m os pontos m\u00e9dios de top-left/top-right e bottom-left e bottom-right   (tl, tr, br, bl) = box   (tltrX, tltrY) = midpoint(tl, tr)   (blbrX, blbrY) = midpoint(bl, br)      #obt\u00e9m os pontos m\u00e9dios de top-left/bottom-left e top-right e bottom-right   (tlblX, tlblY) = midpoint(tl, bl)   (trbrX, trbrY) = midpoint(tr, br)    #desenha c\u00edculos nos pontos-m\u00e9dios   cv2.circle(orig, (int(tltrX), int(tltrY)), 5, (255, 0, 0), -1)   cv2.circle(orig, (int(blbrX), int(blbrY)), 5, (255, 0, 0), -1)   cv2.circle(orig, (int(tlblX), int(tlblY)), 5, (255, 0, 0), -1)   cv2.circle(orig, (int(trbrX), int(trbrY)), 5, (255, 0, 0), -1)      #une os pontos-m\u00e9dios com segmentos de reta   cv2.line(orig, (int(tltrX), int(tltrY)), (int(blbrX), int(blbrY)),(255, 0, 255), 2)   cv2.line(orig, (int(tlblX), int(tlblY)), (int(trbrX), int(trbrY)),(255, 0, 255), 2)  plt.figure(figsize = (10,10)) plt.imshow(orig); plt.show(); <p>OBTEN\u00c7\u00c3O DAS MEDIDAS</p> <p>Para obter as medidas dos objetos, precisamos tomar um objeto de refer\u00eancia (ponto de calibra\u00e7\u00e3o) de tamanho conhecido. Na imagem anterior, vamos tomar como medida de refer\u00eancia a moeda de d\u00f3lar norte-americano, cujo comprimento \u00e9 2.43 cm. A partir dela, definimos todas as outras medidas.</p> <p>\u00c9 neste ponto que vai servir ter feito a ordena\u00e7\u00e3o do <code>cnts</code> da esquerda para a direita, a nossa moeda de d\u00f3lar esta bem destacada no lado esquerdo da imagem, desta forma fica facil fazer a calibra\u00e7\u00e3o pois ser\u00e1 o primeiro item da lista.</p> In\u00a0[\u00a0]: Copied! <pre>width=2.43\npixelsPerMetric=None\n</pre> width=2.43 pixelsPerMetric=None In\u00a0[\u00a0]: Copied! <pre>def midpoint(ptA, ptB):\n  return ((ptA[0] + ptB[0]) * 0.5, (ptA[1] + ptB[1]) * 0.5)\n\norig = image.copy()\n#Percorre todos os contornos\nfor c in cnts:\n  # se o contorno n\u00e3o \u00e9 suficientemente grande, ignor\u00e1-lo\n  if cv2.contourArea(c) &lt; 100:\n    continue\n  # calcula a bounding box rotacionada do contorno\n  box = cv2.minAreaRect(c)\n  box = cv2.boxPoints(box) \n  box = np.array(box, dtype=\"int\")\n  #ordena os pontos do contorno de tal modo que eles\n  #apare\u00e7am na seguinte ordem: top-left, top-right,\n  #bottom-right e bottom-left\n  box = order_points(box)\n  cv2.drawContours(orig, [box.astype(\"int\")], -1, (0, 255, 0), 2)\n  for (x, y) in box:\n    cv2.circle(orig, (int(x), int(y)), 5, (25, 0, 0), -1)\n\n  #obt\u00e9m os pontos m\u00e9dios de top-left/top-right e bottom-left e bottom-right\n  (tl, tr, br, bl) = box\n  (tltrX, tltrY) = midpoint(tl, tr)\n  (blbrX, blbrY) = midpoint(bl, br)\n  \n  #obt\u00e9m os pontos m\u00e9dios de top-left/bottom-left e top-right e bottom-right\n  (tlblX, tlblY) = midpoint(tl, bl)\n  (trbrX, trbrY) = midpoint(tr, br)\n\n  #desenha c\u00edculos nos pontos-m\u00e9dios\n  cv2.circle(orig, (int(tltrX), int(tltrY)), 5, (255, 0, 0), -1)\n  cv2.circle(orig, (int(blbrX), int(blbrY)), 5, (255, 0, 0), -1)\n  cv2.circle(orig, (int(tlblX), int(tlblY)), 5, (255, 0, 0), -1)\n  cv2.circle(orig, (int(trbrX), int(trbrY)), 5, (255, 0, 0), -1)\n  \n  #une os pontos-m\u00e9dios com segmentos de reta\n  cv2.line(orig, (int(tltrX), int(tltrY)), (int(blbrX), int(blbrY)),(255, 0, 255), 2)\n  cv2.line(orig, (int(tlblX), int(tlblY)), (int(trbrX), int(trbrY)),(255, 0, 255), 2)\n ###-------------n\u00e3o te mnovidade  \n    \n  # C\u00e1lculo da dist\u00e2ncia entre dois pontos, dist\u00e2ncia euclidiana\n  dA = dist.euclidean((tltrX, tltrY), (blbrX, blbrY))\n  dB = dist.euclidean((tlblX, tlblY), (trbrX, trbrY))\n\n##########---------------isso \u00e9 novidade--------------------------------------------------------------------\n\n  # define a escala para relacionar pixel por centrimetro\n  if pixelsPerMetric is None:\n    pixelsPerMetric = dB / width\n  \n  dimA = dA / pixelsPerMetric\n  dimB = dB / pixelsPerMetric\n  \n  cv2.putText(orig, \"{:.2f}cm\".format(dimB),(int(tltrX - 15), int(tltrY - 10)), cv2.FONT_HERSHEY_SIMPLEX,0.50, (255, 255, 255), 1)\n  cv2.putText(orig, \"{:.2f}cm\".format(dimA),(int(trbrX + 10), int(trbrY)), cv2.FONT_HERSHEY_SIMPLEX,0.50, (255, 255, 255), 1) \n  \nplt.figure(figsize = (10,10))\nplt.imshow(orig); plt.show();\n</pre> def midpoint(ptA, ptB):   return ((ptA[0] + ptB[0]) * 0.5, (ptA[1] + ptB[1]) * 0.5)  orig = image.copy() #Percorre todos os contornos for c in cnts:   # se o contorno n\u00e3o \u00e9 suficientemente grande, ignor\u00e1-lo   if cv2.contourArea(c) &lt; 100:     continue   # calcula a bounding box rotacionada do contorno   box = cv2.minAreaRect(c)   box = cv2.boxPoints(box)    box = np.array(box, dtype=\"int\")   #ordena os pontos do contorno de tal modo que eles   #apare\u00e7am na seguinte ordem: top-left, top-right,   #bottom-right e bottom-left   box = order_points(box)   cv2.drawContours(orig, [box.astype(\"int\")], -1, (0, 255, 0), 2)   for (x, y) in box:     cv2.circle(orig, (int(x), int(y)), 5, (25, 0, 0), -1)    #obt\u00e9m os pontos m\u00e9dios de top-left/top-right e bottom-left e bottom-right   (tl, tr, br, bl) = box   (tltrX, tltrY) = midpoint(tl, tr)   (blbrX, blbrY) = midpoint(bl, br)      #obt\u00e9m os pontos m\u00e9dios de top-left/bottom-left e top-right e bottom-right   (tlblX, tlblY) = midpoint(tl, bl)   (trbrX, trbrY) = midpoint(tr, br)    #desenha c\u00edculos nos pontos-m\u00e9dios   cv2.circle(orig, (int(tltrX), int(tltrY)), 5, (255, 0, 0), -1)   cv2.circle(orig, (int(blbrX), int(blbrY)), 5, (255, 0, 0), -1)   cv2.circle(orig, (int(tlblX), int(tlblY)), 5, (255, 0, 0), -1)   cv2.circle(orig, (int(trbrX), int(trbrY)), 5, (255, 0, 0), -1)      #une os pontos-m\u00e9dios com segmentos de reta   cv2.line(orig, (int(tltrX), int(tltrY)), (int(blbrX), int(blbrY)),(255, 0, 255), 2)   cv2.line(orig, (int(tlblX), int(tlblY)), (int(trbrX), int(trbrY)),(255, 0, 255), 2)  ###-------------n\u00e3o te mnovidade          # C\u00e1lculo da dist\u00e2ncia entre dois pontos, dist\u00e2ncia euclidiana   dA = dist.euclidean((tltrX, tltrY), (blbrX, blbrY))   dB = dist.euclidean((tlblX, tlblY), (trbrX, trbrY))  ##########---------------isso \u00e9 novidade--------------------------------------------------------------------    # define a escala para relacionar pixel por centrimetro   if pixelsPerMetric is None:     pixelsPerMetric = dB / width      dimA = dA / pixelsPerMetric   dimB = dB / pixelsPerMetric      cv2.putText(orig, \"{:.2f}cm\".format(dimB),(int(tltrX - 15), int(tltrY - 10)), cv2.FONT_HERSHEY_SIMPLEX,0.50, (255, 255, 255), 1)   cv2.putText(orig, \"{:.2f}cm\".format(dimA),(int(trbrX + 10), int(trbrY)), cv2.FONT_HERSHEY_SIMPLEX,0.50, (255, 255, 255), 1)     plt.figure(figsize = (10,10)) plt.imshow(orig); plt.show(); <p>Refer\u00eancia:</p> <ul> <li>https://pyimagesearch.com/2016/03/28/measuring-size-of-objects-in-an-image-with-opencv/</li> </ul> In\u00a0[\u00a0]: Copied! <pre>%matplotlib inline\nimport cv2\nfrom matplotlib import pyplot as plt\nimport numpy as np\n\nimg = cv2.imread('objects2.png')\nimg = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n\nplt.figure(figsize = (10,10))\nplt.imshow(img); plt.show();\n</pre> %matplotlib inline import cv2 from matplotlib import pyplot as plt import numpy as np  img = cv2.imread('objects2.png') img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)  plt.figure(figsize = (10,10)) plt.imshow(img); plt.show(); In\u00a0[8]: Copied! <pre>### Seu c\u00f3digo aqui....\n\n## uma solu\u00e7ao simples \u00e9 basicamente copiar e colar o c\u00f3digo acima e adaptar para a nova imagem.\n# funciona? sim, mas n\u00e3o \u00e9 a melhor forma de fazer. \n\n# Sugiro utilizar essa exercicio para praticar python e programa\u00e7\u00e3o, tente criar novas fun\u00e7\u00f5es para refatorar o c\u00f3digo.\n\n%matplotlib inline\nimport cv2\nfrom matplotlib import pyplot as plt\nimport numpy as np\nfrom scipy.spatial import distance as dist\n\nwidth=8.89\npixelsPerMetric=None\n\ndef order_points(pts):\n     xSorted = pts[np.argsort(pts[:, 0]), :]\n\n    # grab the left-most and right-most points from the sorted\n    # x-roodinate points\n     leftMost = xSorted[:2, :]\n     rightMost = xSorted[2:, :]\n\n    # now, sort the left-most coordinates according to their\n    # y-coordinates so we can grab the top-left and bottom-left\n    # points, respectively\n     leftMost = leftMost[np.argsort(leftMost[:, 1]), :]\n     (tl, bl) = leftMost\n\n    # now that we have the top-left coordinate, use it as an\n    # anchor to calculate the Euclidean distance between the\n    # top-left and right-most points; by the Pythagorean\n    # theorem, the point with the largest distance will be\n    # our bottom-right point\n     D = dist.cdist(tl[np.newaxis], rightMost, \"euclidean\")[0]\n     (br, tr) = rightMost[np.argsort(D)[::-1], :]\n\n    # return the coordinates in top-left, top-right,\n    # bottom-right, and bottom-left order\n     return np.array([tl, tr, br, bl], dtype=\"float32\")   \n\n\ndef midpoint(ptA, ptB):\n  return ((ptA[0] + ptB[0]) * 0.5, (ptA[1] + ptB[1]) * 0.5)\n\n#carregamos a imagem, convertemos para n\u00edveis de cinza e a borramos levemente\nimage = cv2.imread('objects2.png')\nimage = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\ngray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n\n# aplico um filtro gaussiano para suaviazar a imagem...\ngray = cv2.GaussianBlur(gray, (9,9), 0)\n\n#calculamos as arestas e realizamos uma dilata\u00e7\u00e3o + eros\u00e3o para fechar\n#eventuais gaps entre as arestas dos objetos\nedged = cv2.Canny(gray, 50, 250)\ndilate = cv2.dilate(edged, None, iterations=2)\nerode = cv2.erode(dilate, None, iterations=2)\n\n\ncnts, _ = cv2.findContours(erode.copy(),cv2.RETR_EXTERNAL,cv2.CHAIN_APPROX_SIMPLE)\n\n(cnts, boundingBoxes) = zip(*sorted(zip(cnts, [cv2.boundingRect(c) for c in cnts]), key=lambda b: b[1][0], reverse=False))\n\norig = image.copy()\n#Percorre todos os contornos\nfor c in cnts:\n  # se o contorno n\u00e3o \u00e9 suficientemente grande, ignor\u00e1-lo\n  if cv2.contourArea(c) &lt; 100:\n    continue\n  # calcula a bounding box rotacionada do contorno\n  box = cv2.minAreaRect(c)\n  box = cv2.boxPoints(box) \n  box = np.array(box, dtype=\"int\")\n  #ordena os pontos do contorno de tal modo que eles\n  #apare\u00e7am na seguinte ordem: top-left, top-right,\n  #bottom-right e bottom-left\n  box = order_points(box)\n  cv2.drawContours(orig, [box.astype(\"int\")], -1, (0, 255, 0), 2)\n  for (x, y) in box:\n    cv2.circle(orig, (int(x), int(y)), 5, (25, 0, 0), -1)\n\n  #obt\u00e9m os pontos m\u00e9dios de top-left/top-right e bottom-left e bottom-right\n  (tl, tr, br, bl) = box\n  (tltrX, tltrY) = midpoint(tl, tr)\n  (blbrX, blbrY) = midpoint(bl, br)\n  \n  #obt\u00e9m os pontos m\u00e9dios de top-left/bottom-left e top-right e bottom-right\n  (tlblX, tlblY) = midpoint(tl, bl)\n  (trbrX, trbrY) = midpoint(tr, br)\n\n  #desenha c\u00edculos nos pontos-m\u00e9dios\n  cv2.circle(orig, (int(tltrX), int(tltrY)), 5, (255, 0, 0), -1)\n  cv2.circle(orig, (int(blbrX), int(blbrY)), 5, (255, 0, 0), -1)\n  cv2.circle(orig, (int(tlblX), int(tlblY)), 5, (255, 0, 0), -1)\n  cv2.circle(orig, (int(trbrX), int(trbrY)), 5, (255, 0, 0), -1)\n  \n  #une os pontos-m\u00e9dios com segmentos de reta\n  cv2.line(orig, (int(tltrX), int(tltrY)), (int(blbrX), int(blbrY)),(255, 0, 255), 2)\n  cv2.line(orig, (int(tlblX), int(tlblY)), (int(trbrX), int(trbrY)),(255, 0, 255), 2)\n ###-------------n\u00e3o te mnovidade  \n    \n  # C\u00e1lculo da dist\u00e2ncia entre dois pontos, dist\u00e2ncia euclidiana\n  dA = dist.euclidean((tltrX, tltrY), (blbrX, blbrY))\n  dB = dist.euclidean((tlblX, tlblY), (trbrX, trbrY))\n\n##########---------------isso \u00e9 novidade--------------------------------------------------------------------\n\n  # define a escala para relacionar pixel por centrimetro\n  if pixelsPerMetric is None:\n    pixelsPerMetric = dB / width\n  \n  dimA = dA / pixelsPerMetric\n  dimB = dB / pixelsPerMetric\n  \n  cv2.putText(orig, \"{:.2f}cm\".format(dimB),(int(tltrX - 15), int(tltrY - 10)), cv2.FONT_HERSHEY_SIMPLEX,0.50, (255, 255, 255), 1)\n  cv2.putText(orig, \"{:.2f}cm\".format(dimA),(int(trbrX + 10), int(trbrY)), cv2.FONT_HERSHEY_SIMPLEX,0.50, (255, 255, 255), 1) \n  \nplt.figure(figsize = (10,10))\nplt.imshow(orig); plt.show();\n</pre> ### Seu c\u00f3digo aqui....  ## uma solu\u00e7ao simples \u00e9 basicamente copiar e colar o c\u00f3digo acima e adaptar para a nova imagem. # funciona? sim, mas n\u00e3o \u00e9 a melhor forma de fazer.   # Sugiro utilizar essa exercicio para praticar python e programa\u00e7\u00e3o, tente criar novas fun\u00e7\u00f5es para refatorar o c\u00f3digo.  %matplotlib inline import cv2 from matplotlib import pyplot as plt import numpy as np from scipy.spatial import distance as dist  width=8.89 pixelsPerMetric=None  def order_points(pts):      xSorted = pts[np.argsort(pts[:, 0]), :]      # grab the left-most and right-most points from the sorted     # x-roodinate points      leftMost = xSorted[:2, :]      rightMost = xSorted[2:, :]      # now, sort the left-most coordinates according to their     # y-coordinates so we can grab the top-left and bottom-left     # points, respectively      leftMost = leftMost[np.argsort(leftMost[:, 1]), :]      (tl, bl) = leftMost      # now that we have the top-left coordinate, use it as an     # anchor to calculate the Euclidean distance between the     # top-left and right-most points; by the Pythagorean     # theorem, the point with the largest distance will be     # our bottom-right point      D = dist.cdist(tl[np.newaxis], rightMost, \"euclidean\")[0]      (br, tr) = rightMost[np.argsort(D)[::-1], :]      # return the coordinates in top-left, top-right,     # bottom-right, and bottom-left order      return np.array([tl, tr, br, bl], dtype=\"float32\")      def midpoint(ptA, ptB):   return ((ptA[0] + ptB[0]) * 0.5, (ptA[1] + ptB[1]) * 0.5)  #carregamos a imagem, convertemos para n\u00edveis de cinza e a borramos levemente image = cv2.imread('objects2.png') image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB) gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)  # aplico um filtro gaussiano para suaviazar a imagem... gray = cv2.GaussianBlur(gray, (9,9), 0)  #calculamos as arestas e realizamos uma dilata\u00e7\u00e3o + eros\u00e3o para fechar #eventuais gaps entre as arestas dos objetos edged = cv2.Canny(gray, 50, 250) dilate = cv2.dilate(edged, None, iterations=2) erode = cv2.erode(dilate, None, iterations=2)   cnts, _ = cv2.findContours(erode.copy(),cv2.RETR_EXTERNAL,cv2.CHAIN_APPROX_SIMPLE)  (cnts, boundingBoxes) = zip(*sorted(zip(cnts, [cv2.boundingRect(c) for c in cnts]), key=lambda b: b[1][0], reverse=False))  orig = image.copy() #Percorre todos os contornos for c in cnts:   # se o contorno n\u00e3o \u00e9 suficientemente grande, ignor\u00e1-lo   if cv2.contourArea(c) &lt; 100:     continue   # calcula a bounding box rotacionada do contorno   box = cv2.minAreaRect(c)   box = cv2.boxPoints(box)    box = np.array(box, dtype=\"int\")   #ordena os pontos do contorno de tal modo que eles   #apare\u00e7am na seguinte ordem: top-left, top-right,   #bottom-right e bottom-left   box = order_points(box)   cv2.drawContours(orig, [box.astype(\"int\")], -1, (0, 255, 0), 2)   for (x, y) in box:     cv2.circle(orig, (int(x), int(y)), 5, (25, 0, 0), -1)    #obt\u00e9m os pontos m\u00e9dios de top-left/top-right e bottom-left e bottom-right   (tl, tr, br, bl) = box   (tltrX, tltrY) = midpoint(tl, tr)   (blbrX, blbrY) = midpoint(bl, br)      #obt\u00e9m os pontos m\u00e9dios de top-left/bottom-left e top-right e bottom-right   (tlblX, tlblY) = midpoint(tl, bl)   (trbrX, trbrY) = midpoint(tr, br)    #desenha c\u00edculos nos pontos-m\u00e9dios   cv2.circle(orig, (int(tltrX), int(tltrY)), 5, (255, 0, 0), -1)   cv2.circle(orig, (int(blbrX), int(blbrY)), 5, (255, 0, 0), -1)   cv2.circle(orig, (int(tlblX), int(tlblY)), 5, (255, 0, 0), -1)   cv2.circle(orig, (int(trbrX), int(trbrY)), 5, (255, 0, 0), -1)      #une os pontos-m\u00e9dios com segmentos de reta   cv2.line(orig, (int(tltrX), int(tltrY)), (int(blbrX), int(blbrY)),(255, 0, 255), 2)   cv2.line(orig, (int(tlblX), int(tlblY)), (int(trbrX), int(trbrY)),(255, 0, 255), 2)  ###-------------n\u00e3o te mnovidade          # C\u00e1lculo da dist\u00e2ncia entre dois pontos, dist\u00e2ncia euclidiana   dA = dist.euclidean((tltrX, tltrY), (blbrX, blbrY))   dB = dist.euclidean((tlblX, tlblY), (trbrX, trbrY))  ##########---------------isso \u00e9 novidade--------------------------------------------------------------------    # define a escala para relacionar pixel por centrimetro   if pixelsPerMetric is None:     pixelsPerMetric = dB / width      dimA = dA / pixelsPerMetric   dimB = dB / pixelsPerMetric      cv2.putText(orig, \"{:.2f}cm\".format(dimB),(int(tltrX - 15), int(tltrY - 10)), cv2.FONT_HERSHEY_SIMPLEX,0.50, (255, 255, 255), 1)   cv2.putText(orig, \"{:.2f}cm\".format(dimA),(int(trbrX + 10), int(trbrY)), cv2.FONT_HERSHEY_SIMPLEX,0.50, (255, 255, 255), 1)     plt.figure(figsize = (10,10)) plt.imshow(orig); plt.show();  In\u00a0[18]: Copied! <pre>### vou criar algumas fun\u00e7\u00f5es para refatorar o c\u00f3digo acima...\n\n\n%matplotlib inline\nimport cv2\nfrom matplotlib import pyplot as plt\nimport numpy as np\nfrom scipy.spatial import distance as dist\n\ndef order_points(pts):\n    x_sorted = pts[np.argsort(pts[:, 0]), :]\n    left_most = x_sorted[:2, :]\n    right_most = x_sorted[2:, :]\n    left_most = left_most[np.argsort(left_most[:, 1]), :]\n    tl, bl = left_most\n    d = dist.cdist(tl[np.newaxis], right_most, \"euclidean\")[0]\n    br, tr = right_most[np.argsort(d)[::-1], :]\n    return np.array([tl, tr, br, bl], dtype=\"float32\")\n\ndef midpoint(pt_a, pt_b):\n    return ((pt_a[0] + pt_b[0]) * 0.5, (pt_a[1] + pt_b[1]) * 0.5)\n\ndef process_image(image_path):\n    image = cv2.imread(image_path)\n    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n    gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n    gray = cv2.GaussianBlur(gray, (9, 9), 0)\n    edged = cv2.Canny(gray, 50, 250)\n    dilate = cv2.dilate(edged, None, iterations=2)\n    erode = cv2.erode(dilate, None, iterations=2)\n    return erode\n\n\ndef find_and_sort_contours(eroded_image):\n    cnts, _ = cv2.findContours(eroded_image.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n    (cnts, bounding_boxes) = zip(*sorted(zip(cnts, [cv2.boundingRect(c) for c in cnts]), key=lambda b: b[1][0]))\n    return cnts, bounding_boxes\n\ndef draw_contours(image, cnts):\n    orig = image.copy()\n    for c in cnts:\n        if cv2.contourArea(c) &lt; 100:\n            continue\n        box = cv2.minAreaRect(c)\n        box = cv2.boxPoints(box)\n        box = np.array(box, dtype=\"int\")\n        box = order_points(box)\n        cv2.drawContours(orig, [box.astype(\"int\")], -1, (0, 255, 0), 2)\n        for (x, y) in box:\n            cv2.circle(orig, (int(x), int(y)), 5, (25, 0, 0), -1)\n    return orig\n\ndef draw_midpoints(image, cnts):\n    orig = image.copy()\n    for c in cnts:\n        if cv2.contourArea(c) &lt; 100:\n            continue\n        box = cv2.minAreaRect(c)\n        box = cv2.boxPoints(box)\n        box = np.array(box, dtype=\"int\")\n        box = order_points(box)\n\n        tl, tr, br, bl = box\n        tltr_x, tltr_y = midpoint(tl, tr)\n        blbr_x, blbr_y = midpoint(bl, br)\n        tlbl_x, tlbl_y = midpoint(tl, bl)\n        trbr_x, trbr_y = midpoint(tr, br)\n\n        cv2.circle(orig, (int(tltr_x), int(tltr_y)), 5, (255, 0, 0), -1)\n        cv2.circle(orig, (int(blbr_x), int(blbr_y)), 5, (255, 0, 0), -1)\n        cv2.circle(orig, (int(tlbl_x), int(tlbl_y)), 5, (255, 0, 0), -1)\n        cv2.circle(orig, (int(trbr_x), int(trbr_y)), 5, (255, 0, 0), -1)\n\n        cv2.line(orig, (int(tltr_x), int(tltr_y)), (int(blbr_x), int(blbr_y)), (255, 0, 255), 2)\n        cv2.line(orig, (int(tlbl_x), int(tlbl_y)), (int(trbr_x), int(trbr_y)), (255, 0, 255), 2)\n    return orig\n\ndef draw_dimensions(image, cnts, pixels_per_metric):\n    orig = image.copy()\n    for c in cnts:\n        if cv2.contourArea(c) &lt; 100:\n            continue\n        box = cv2.minAreaRect(c)\n        box = cv2.boxPoints(box)\n        box = np.array(box, dtype=\"int\")\n        box = order_points(box)\n\n        tl, tr, br, bl = box\n        tltr_x, tltr_y = midpoint(tl, tr)\n        blbr_x, blbr_y = midpoint(bl, br)\n        tlbl_x, tlbl_y = midpoint(tl, bl)\n        trbr_x, trbr_y = midpoint(tr, br)\n\n        da = dist.euclidean((tltr_x, tltr_y), (blbr_x, blbr_y))\n        db = dist.euclidean((tlbl_x, tlbl_y), (trbr_x, trbr_y))\n\n        if pixels_per_metric is None:\n            pixels_per_metric = db / width\n\n        dim_a = da / pixels_per_metric\n        dim_b = db / pixels_per_metric\n\n        cv2.putText(orig, \"{:.2f}cm\".format(dim_b), (int(tltr_x - 15), int(tltr_y - 10)), cv2.FONT_HERSHEY_SIMPLEX, 0.50, (255, 255, 255), 1)\n        cv2.putText(orig, \"{:.2f}cm\".format(dim_a), (int(trbr_x + 10), int(trbr_y)), cv2.FONT_HERSHEY_SIMPLEX, 0.50, (255, 255, 255), 1)\n    \n    return orig\n\ndef display_image(image, title=\"Image\", figsize=(10, 10)):\n    plt.figure(figsize=figsize)\n    plt.imshow(image)\n    plt.title(title)\n    plt.axis('off')  # Oculta os eixos\n    plt.show()\n\n### o c\u00f3digo principal fica mais limpo e f\u00e1cil de entender...\n\nwidth = 8.89\npixels_per_metric = None\n\nerode = process_image('objects2.png')\ncnts, bounding_boxes = find_and_sort_contours(erode)\ncontours_image = draw_contours(image, cnts)\nmidpoints_image = draw_midpoints(contours_image, cnts)\ndimensions_image = draw_dimensions(midpoints_image, cnts, pixels_per_metric)\ndisplay_image(dimensions_image, title=\"Imagem final\")\n\n## da pra melhorar ainda mais o c\u00f3digo, mas acredito que j\u00e1 deu pra ter uma ideia de como refatorar o c\u00f3digo.\n</pre> ### vou criar algumas fun\u00e7\u00f5es para refatorar o c\u00f3digo acima...   %matplotlib inline import cv2 from matplotlib import pyplot as plt import numpy as np from scipy.spatial import distance as dist  def order_points(pts):     x_sorted = pts[np.argsort(pts[:, 0]), :]     left_most = x_sorted[:2, :]     right_most = x_sorted[2:, :]     left_most = left_most[np.argsort(left_most[:, 1]), :]     tl, bl = left_most     d = dist.cdist(tl[np.newaxis], right_most, \"euclidean\")[0]     br, tr = right_most[np.argsort(d)[::-1], :]     return np.array([tl, tr, br, bl], dtype=\"float32\")  def midpoint(pt_a, pt_b):     return ((pt_a[0] + pt_b[0]) * 0.5, (pt_a[1] + pt_b[1]) * 0.5)  def process_image(image_path):     image = cv2.imread(image_path)     image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)     gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)     gray = cv2.GaussianBlur(gray, (9, 9), 0)     edged = cv2.Canny(gray, 50, 250)     dilate = cv2.dilate(edged, None, iterations=2)     erode = cv2.erode(dilate, None, iterations=2)     return erode   def find_and_sort_contours(eroded_image):     cnts, _ = cv2.findContours(eroded_image.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)     (cnts, bounding_boxes) = zip(*sorted(zip(cnts, [cv2.boundingRect(c) for c in cnts]), key=lambda b: b[1][0]))     return cnts, bounding_boxes  def draw_contours(image, cnts):     orig = image.copy()     for c in cnts:         if cv2.contourArea(c) &lt; 100:             continue         box = cv2.minAreaRect(c)         box = cv2.boxPoints(box)         box = np.array(box, dtype=\"int\")         box = order_points(box)         cv2.drawContours(orig, [box.astype(\"int\")], -1, (0, 255, 0), 2)         for (x, y) in box:             cv2.circle(orig, (int(x), int(y)), 5, (25, 0, 0), -1)     return orig  def draw_midpoints(image, cnts):     orig = image.copy()     for c in cnts:         if cv2.contourArea(c) &lt; 100:             continue         box = cv2.minAreaRect(c)         box = cv2.boxPoints(box)         box = np.array(box, dtype=\"int\")         box = order_points(box)          tl, tr, br, bl = box         tltr_x, tltr_y = midpoint(tl, tr)         blbr_x, blbr_y = midpoint(bl, br)         tlbl_x, tlbl_y = midpoint(tl, bl)         trbr_x, trbr_y = midpoint(tr, br)          cv2.circle(orig, (int(tltr_x), int(tltr_y)), 5, (255, 0, 0), -1)         cv2.circle(orig, (int(blbr_x), int(blbr_y)), 5, (255, 0, 0), -1)         cv2.circle(orig, (int(tlbl_x), int(tlbl_y)), 5, (255, 0, 0), -1)         cv2.circle(orig, (int(trbr_x), int(trbr_y)), 5, (255, 0, 0), -1)          cv2.line(orig, (int(tltr_x), int(tltr_y)), (int(blbr_x), int(blbr_y)), (255, 0, 255), 2)         cv2.line(orig, (int(tlbl_x), int(tlbl_y)), (int(trbr_x), int(trbr_y)), (255, 0, 255), 2)     return orig  def draw_dimensions(image, cnts, pixels_per_metric):     orig = image.copy()     for c in cnts:         if cv2.contourArea(c) &lt; 100:             continue         box = cv2.minAreaRect(c)         box = cv2.boxPoints(box)         box = np.array(box, dtype=\"int\")         box = order_points(box)          tl, tr, br, bl = box         tltr_x, tltr_y = midpoint(tl, tr)         blbr_x, blbr_y = midpoint(bl, br)         tlbl_x, tlbl_y = midpoint(tl, bl)         trbr_x, trbr_y = midpoint(tr, br)          da = dist.euclidean((tltr_x, tltr_y), (blbr_x, blbr_y))         db = dist.euclidean((tlbl_x, tlbl_y), (trbr_x, trbr_y))          if pixels_per_metric is None:             pixels_per_metric = db / width          dim_a = da / pixels_per_metric         dim_b = db / pixels_per_metric          cv2.putText(orig, \"{:.2f}cm\".format(dim_b), (int(tltr_x - 15), int(tltr_y - 10)), cv2.FONT_HERSHEY_SIMPLEX, 0.50, (255, 255, 255), 1)         cv2.putText(orig, \"{:.2f}cm\".format(dim_a), (int(trbr_x + 10), int(trbr_y)), cv2.FONT_HERSHEY_SIMPLEX, 0.50, (255, 255, 255), 1)          return orig  def display_image(image, title=\"Image\", figsize=(10, 10)):     plt.figure(figsize=figsize)     plt.imshow(image)     plt.title(title)     plt.axis('off')  # Oculta os eixos     plt.show()  ### o c\u00f3digo principal fica mais limpo e f\u00e1cil de entender...  width = 8.89 pixels_per_metric = None  erode = process_image('objects2.png') cnts, bounding_boxes = find_and_sort_contours(erode) contours_image = draw_contours(image, cnts) midpoints_image = draw_midpoints(contours_image, cnts) dimensions_image = draw_dimensions(midpoints_image, cnts, pixels_per_metric) display_image(dimensions_image, title=\"Imagem final\")  ## da pra melhorar ainda mais o c\u00f3digo, mas acredito que j\u00e1 deu pra ter uma ideia de como refatorar o c\u00f3digo.  In\u00a0[\u00a0]: Copied! <pre>### Bora fazer uma IC??\n</pre> ### Bora fazer uma IC??"},{"location":"aulas/PDI/lab10/sol_medidas.html#processamento-de-imagens","title":"PROCESSAMENTO DE IMAGENS\u00b6","text":"<p>Objetivos da aula:</p> <ul> <li>reconhecer e fazer medidas b\u00e1sicas e aproximadas de objetos</li> </ul>"},{"location":"aulas/PDI/lab10/sol_medidas.html#desafio1","title":"desafio1\u00b6","text":"<p>Dica r\u00e1pida de python. Vamos utilizar a fun\u00e7\u00e3o <code>zip</code> do python que retorna uma sequ\u00eancia de tuplas. Pratique um pouco essa fun\u00e7\u00e3o.</p> <ul> <li>http://devfuria.com.br/python/built-in-zip/</li> <li>https://pythonhelp.wordpress.com/2013/04/16/funcao-zip-em-python/</li> <li>https://www.programiz.com/python-programming/methods/built-in/zip</li> </ul> <p>obs. O operador <code>*</code> pode ser utilizado com o zip() para descompactar (unzip) uma lista.</p>"},{"location":"aulas/PDI/lab10/sol_medidas.html#desafio2","title":"desafio2\u00b6","text":"<p>Dica r\u00e1pida de python. Vamos utilizar <code>list comprehensions</code> que basicamente realiza de forma compacta uma manipula\u00e7\u00e3o de listas. Pratique um pouco essa fun\u00e7\u00e3o.</p> <ul> <li>https://pythonhelp.wordpress.com/2011/03/01/list-comprehension/</li> <li>https://www.w3schools.com/python/python_lists_comprehension.asp</li> <li>https://pythonacademy.com.br/blog/list-comprehensions-no-python</li> </ul>"},{"location":"aulas/PDI/lab10/sol_medidas.html#desafio3","title":"desafio3\u00b6","text":"<p>Dica r\u00e1pida de python. Vamos utilizar a fun\u00e7\u00e3o <code>lambda</code> que basicamente realiza de forma pratica uma fun\u00e7\u00e3o an\u00f4nima. Pratique um pouco essa fun\u00e7\u00e3o.</p> <ul> <li>https://www.hashtagtreinamentos.com/funcoes-lambda-python?gclid=CjwKCAjwiuuRBhBvEiwAFXKaNF77HmSrHlWg1Tx5Okpt6x9QFZemjbINiX9sX43R-fCNnXkuy8fiTxoCkiEQAvD_BwE</li> <li>https://www.w3schools.com/python/python_lambda.asp</li> <li>https://www.codingame.com/playgrounds/52499/programacao-python-intermediario---prof--marco-vaz/funcao-lambda</li> </ul>"},{"location":"aulas/PDI/lab10/sol_medidas.html#obtencao-dos-contornos","title":"OBTEN\u00c7\u00c3O DOS CONTORNOS\u00b6","text":"<p>A partir das arestas, podemos obter os contornos dos objetos.</p>"},{"location":"aulas/PDI/lab10/sol_medidas.html#desafio","title":"Desafio\u00b6","text":"<p>Realize o processamento da imagem abaixo a fim de obter os dimensionais de todos os cart\u00f5es. Fa\u00e7a a escolha de um dos cart\u00f5es para ser a refer\u00eancia e servir de calibra\u00e7\u00e3o.</p> <p>O cart\u00e3o da esquerda possui 8.89 x 5.08 cm.</p>"},{"location":"aulas/PDI/lab10/sol_medidas.html#desafio-extra-top","title":"Desafio extra top!\u00b6","text":"<p>Um grande problemada industria de manufatura est\u00e1 na determin\u00e7\u00e3o do dimensional de alguns objetos para controle de qualidade. Nesse sentido, voc\u00ea foi contratado para desenvolver um sistema que ir\u00e1 capturar um frame de um v\u00eddeo, processar e definir o seu dimenssional.</p> <p>Se topar o desafio, vamos fazer um projeto IC?</p>"},{"location":"aulas/PDI/lab11/watershed.html","title":"Lab11 - Transformada de watershed","text":"<p>O NOSSO PROBLEMA</p> <p>Como segmentar objetos semelhantes que est\u00e3o se tocando?</p> <p>At\u00e9 o momento, os objetos est\u00e3o bem separados uns dos outros, neste caso o metodo de segmenta\u00e7\u00e3o de contorno funciona muito bem. E para o caso abaixo?</p> In\u00a0[1]: Copied! <pre>%matplotlib inline\nimport cv2\nfrom matplotlib import pyplot as plt\nimport numpy as np\n\nimg = cv2.imread('water_coins.jpg')\nimg_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n\nplt.figure(figsize = (10,10))\nplt.imshow(img_rgb); plt.show();\n\ngray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\nret, thresh = cv2.threshold(gray,0,255,cv2.THRESH_BINARY_INV+cv2.THRESH_OTSU)\n\nplt.figure(figsize = (10,10))\nplt.imshow(thresh,cmap=\"gray\"); plt.show();\n</pre> %matplotlib inline import cv2 from matplotlib import pyplot as plt import numpy as np  img = cv2.imread('water_coins.jpg') img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)  plt.figure(figsize = (10,10)) plt.imshow(img_rgb); plt.show();  gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY) ret, thresh = cv2.threshold(gray,0,255,cv2.THRESH_BINARY_INV+cv2.THRESH_OTSU)  plt.figure(figsize = (10,10)) plt.imshow(thresh,cmap=\"gray\"); plt.show(); <p>Algoritmo de Watershed</p> <p>Em casos como esse, podemos usar o algoritmo de watershed, uma intui\u00e7\u00e3o de como funciona este algotimo \u00e9 a seguinte.</p> <p>Queremos isolar regi\u00f5es da imagem, para isso vamos imaginar uma imagem como um relevo (imagem topografica), que tem altos e baixos, a intensidade do pixel determina sua altura, o top ou vale. A teoria e a matem\u00e1tica por tr\u00e1s s\u00e3o complexas, mas por temos uma receita de bolo que costuma dar certo.</p> <p></p> <p>Pr\u00f3s e contras</p> <p>Vantagem, conseguimos seguimentar uma imagem em escala de cinza em mais do que duas regi\u00f5es. Mesmo sendo objetos sobrepostos, conseguimos determinar sua fronteira.</p> <p>Como desvantagem temos um problema de inicializa\u00e7\u00e3o, se for aleat\u00f3rio ou mal inicializada, pode gerar resultado ruim.</p> <p>Na OpenCV, temos uma fun\u00e7\u00e3o built-in que implementa o algoritimo de watershed:</p> <pre><code>cv2.watershed(image, markers)\n\nimage: imagem de entrada\n\nmarkers: s\u00e3o sementes \"seeds\", ou seja, onde nasce um objeto. \u00c9 uma imagem do mesmo tamanho da imagem original, mas com regio\u1ebds de interesse delineadas, cada regi\u00e3o \u00e9 equivalente a um centro objeto da imagem, nas bordas das regio\u1ebds o valor da semente \u00e9 -1.</code></pre> <p>Como determinar os markers</p> <pre><code>1 - Determine a \u00e1rea da imagem que \u00e9 o fundo certo (sure background area)\n2 - Encontre uma area em primeiro plano (find sure foreground area)\n3 - A diferen\u00e7a entre as duas areas (sure_bg -sure_fg) \u00e9 uma regi\u00e3o desconhecida pois \u00e9 onde est\u00e1 a borda.\n4 - Rotule as regi\u00f5es, o fundo da imagem com 0 e outros objetos s\u00e3o rotulados com n\u00fameros inteiros a partir de 1.</code></pre> <p>Simples assim...:)</p> In\u00a0[2]: Copied! <pre>%matplotlib inline\nimport cv2\nfrom matplotlib import pyplot as plt\nimport numpy as np\n\nimg = cv2.imread('Osteosarcoma_01.tif')\nimg_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\ncells=img_rgb[:,:,2]  #usando a cor azul, pega melhor o contorno (para esse exemplo de imagem)\n_, thresh = cv2.threshold(cells, 0, 255, cv2.THRESH_OTSU) ## limiariza\u00e7\u00e3o\n\n\nplt.figure(figsize=(20,20))\nplt.subplot(1, 2, 1); plt.imshow(img,cmap=\"gray\")\nplt.subplot(1, 2, 2);plt.imshow(thresh,cmap=\"gray\"); plt.show();\n</pre> %matplotlib inline import cv2 from matplotlib import pyplot as plt import numpy as np  img = cv2.imread('Osteosarcoma_01.tif') img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB) cells=img_rgb[:,:,2]  #usando a cor azul, pega melhor o contorno (para esse exemplo de imagem) _, thresh = cv2.threshold(cells, 0, 255, cv2.THRESH_OTSU) ## limiariza\u00e7\u00e3o   plt.figure(figsize=(20,20)) plt.subplot(1, 2, 1); plt.imshow(img,cmap=\"gray\") plt.subplot(1, 2, 2);plt.imshow(thresh,cmap=\"gray\"); plt.show(); In\u00a0[3]: Copied! <pre># vamos realizar o pre-processamento da imagem, limpando os ruidos e tapando buracos da imagem\n# podemos usar morfologia ou qualquer outro processo.\n\nkernel = np.ones((3,3),np.uint8) # matriz de convolu\u00e7\u00e3o 3x3\n\nopening = cv2.morphologyEx(thresh,cv2.MORPH_OPEN,kernel, iterations = 2) ##morfologia para remover ruidos\n\nplt.figure(figsize=(20,20))\nplt.subplot(1, 2, 1); plt.imshow(thresh,cmap=\"gray\")\nplt.subplot(1, 2, 2);plt.imshow(opening,cmap=\"gray\"); plt.show();\n</pre> # vamos realizar o pre-processamento da imagem, limpando os ruidos e tapando buracos da imagem # podemos usar morfologia ou qualquer outro processo.  kernel = np.ones((3,3),np.uint8) # matriz de convolu\u00e7\u00e3o 3x3  opening = cv2.morphologyEx(thresh,cv2.MORPH_OPEN,kernel, iterations = 2) ##morfologia para remover ruidos  plt.figure(figsize=(20,20)) plt.subplot(1, 2, 1); plt.imshow(thresh,cmap=\"gray\") plt.subplot(1, 2, 2);plt.imshow(opening,cmap=\"gray\"); plt.show(); <p>Vamos fazer um teste usando o que j\u00e1 conhecemos para contar usando o findcontours(), note que a contagem n\u00e3o est\u00e1 correta, pois existe sobreposi\u00e7\u00e3o na imagem.</p> In\u00a0[4]: Copied! <pre>contornos, _ = cv2.findContours(opening, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE) \n\nopening_rgb = cv2.cvtColor(opening, cv2.COLOR_GRAY2RGB) \ncontornos_img = opening_rgb.copy() # C\u00f3pia da m\u00e1scara para ser desenhada \"por cima\"\n\n\n\nfor (i, c) in enumerate(contornos):\n    # draw the contour\n    ((x, y), _) = cv2.minEnclosingCircle(c)  ## truque para pegar as coordenadas de centro x,y de cada contorno\n    cv2.putText(contornos_img, \"#{}\".format(i + 1), (int(x) - 10, int(y)), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)\n    cv2.drawContours(contornos_img, [c], -1, [255, 0, 0], 5);\n\nprint(\"Foram identificados\",len(contornos),\"contornos\")\n\n\nplt.figure(figsize=(20,20))\nplt.subplot(1, 2, 1); plt.imshow(opening,cmap=\"gray\")\nplt.subplot(1, 2, 2);plt.imshow(contornos_img); plt.show();\n</pre>  contornos, _ = cv2.findContours(opening, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)   opening_rgb = cv2.cvtColor(opening, cv2.COLOR_GRAY2RGB)  contornos_img = opening_rgb.copy() # C\u00f3pia da m\u00e1scara para ser desenhada \"por cima\"    for (i, c) in enumerate(contornos):     # draw the contour     ((x, y), _) = cv2.minEnclosingCircle(c)  ## truque para pegar as coordenadas de centro x,y de cada contorno     cv2.putText(contornos_img, \"#{}\".format(i + 1), (int(x) - 10, int(y)), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)     cv2.drawContours(contornos_img, [c], -1, [255, 0, 0], 5);  print(\"Foram identificados\",len(contornos),\"contornos\")   plt.figure(figsize=(20,20)) plt.subplot(1, 2, 1); plt.imshow(opening,cmap=\"gray\") plt.subplot(1, 2, 2);plt.imshow(contornos_img); plt.show(); <pre>Foram identificados 109 contornos\n</pre> <p>Vamos aplicar a transformada de Watershed. Para isso vamos seguir o proprio exemplo de aplica\u00e7\u00e3o da t\u00e9cnica e adaptar para a nosso exemplo.</p> <p>REF: https://opencv24-python-tutorials.readthedocs.io/en/latest/py_tutorials/py_imgproc/py_watershed/py_watershed.html</p> In\u00a0[5]: Copied! <pre># agora que j\u00e1 sabemos onde est\u00e3o os centros das celulas, determinamos uma \u00e1rea de fundo certo (sure background area)\n\nsure_bg = cv2.dilate(opening,kernel,iterations=10)\n\n# Determinamos uma \u00e1rea segura em primeiro plano (Finding sure foreground area)\ndist_transform = cv2.distanceTransform(opening,cv2.DIST_L2,5)\nret, sure_fg = cv2.threshold(dist_transform,0.5*dist_transform.max(),255,0)\n\n\n# Buscamos regi\u00f5es desconhecidas (Finding unknown region)\nsure_fg = np.uint8(sure_fg)\nunknown = cv2.subtract(sure_bg,sure_fg) \n\n\n# Rotulando o marcador\nret, markers = cv2.connectedComponents(sure_fg)\n\n\n# Adicione 1 a todos os marcadores para garantir que o plano de fundo n\u00e3o seja 0, mas 1\nmarkers = markers+10\n\n# Agora, marque a regi\u00e3o desconhecida com zero\nmarkers[unknown==255] = 0 \n\n\nplt.figure(figsize=(15,15))\nplt.subplot(2, 2, 1);plt.imshow(sure_bg,cmap=\"gray\")\nplt.subplot(2, 2, 2);plt.imshow(sure_fg,cmap=\"gray\")\nplt.subplot(2, 2, 3);plt.imshow(unknown,cmap=\"gray\")\nplt.subplot(2, 2, 4); plt.imshow(markers,cmap=\"gray\"); plt.show();\n</pre> # agora que j\u00e1 sabemos onde est\u00e3o os centros das celulas, determinamos uma \u00e1rea de fundo certo (sure background area)  sure_bg = cv2.dilate(opening,kernel,iterations=10)  # Determinamos uma \u00e1rea segura em primeiro plano (Finding sure foreground area) dist_transform = cv2.distanceTransform(opening,cv2.DIST_L2,5) ret, sure_fg = cv2.threshold(dist_transform,0.5*dist_transform.max(),255,0)   # Buscamos regi\u00f5es desconhecidas (Finding unknown region) sure_fg = np.uint8(sure_fg) unknown = cv2.subtract(sure_bg,sure_fg)    # Rotulando o marcador ret, markers = cv2.connectedComponents(sure_fg)   # Adicione 1 a todos os marcadores para garantir que o plano de fundo n\u00e3o seja 0, mas 1 markers = markers+10  # Agora, marque a regi\u00e3o desconhecida com zero markers[unknown==255] = 0    plt.figure(figsize=(15,15)) plt.subplot(2, 2, 1);plt.imshow(sure_bg,cmap=\"gray\") plt.subplot(2, 2, 2);plt.imshow(sure_fg,cmap=\"gray\") plt.subplot(2, 2, 3);plt.imshow(unknown,cmap=\"gray\") plt.subplot(2, 2, 4); plt.imshow(markers,cmap=\"gray\"); plt.show(); In\u00a0[6]: Copied! <pre>#Agora podemos aplicar watershed. \nmarkers = cv2.watershed(img,markers)\n\n# cada contorno fica vermelho\nimg[markers == -1] = [255,0,0]  \n\nprint(markers.shape)\n\nplt.figure(figsize=(20,20))\nplt.subplot(1, 2, 2); plt.imshow(markers,cmap=\"gray\")\nplt.subplot(1, 2, 1);plt.imshow(img); plt.show();\n</pre> #Agora podemos aplicar watershed.  markers = cv2.watershed(img,markers)  # cada contorno fica vermelho img[markers == -1] = [255,0,0]    print(markers.shape)  plt.figure(figsize=(20,20)) plt.subplot(1, 2, 2); plt.imshow(markers,cmap=\"gray\") plt.subplot(1, 2, 1);plt.imshow(img); plt.show();   <pre>(1104, 1376)\n</pre> In\u00a0[7]: Copied! <pre>contornos, _ = cv2.findContours(sure_fg, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE) \n\nopening_rgb = cv2.cvtColor(opening, cv2.COLOR_GRAY2RGB) \ncontornos_img = opening_rgb.copy() # C\u00f3pia da m\u00e1scara para ser desenhada \"por cima\"\n\nfor (i, c) in enumerate(contornos):\n    # desenha o contorno\n    ((x, y), _) = cv2.minEnclosingCircle(c)  ## truque para pegar as coordenadas de centro x,y de cada contorno\n    cv2.putText(contornos_img, \"#{}\".format(i + 1), (int(x) - 10, int(y)), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)\n    cv2.drawContours(contornos_img, [c], -1, [255, 0, 0], 5);\n\nprint(\"Foram identificados\",len(contornos),\"contornos\")\n\n\nplt.figure(figsize=(20,20))\nplt.subplot(1, 2, 1); plt.imshow(opening,cmap=\"gray\")\nplt.subplot(1, 2, 2);plt.imshow(contornos_img); plt.show();\n</pre> contornos, _ = cv2.findContours(sure_fg, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)   opening_rgb = cv2.cvtColor(opening, cv2.COLOR_GRAY2RGB)  contornos_img = opening_rgb.copy() # C\u00f3pia da m\u00e1scara para ser desenhada \"por cima\"  for (i, c) in enumerate(contornos):     # desenha o contorno     ((x, y), _) = cv2.minEnclosingCircle(c)  ## truque para pegar as coordenadas de centro x,y de cada contorno     cv2.putText(contornos_img, \"#{}\".format(i + 1), (int(x) - 10, int(y)), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)     cv2.drawContours(contornos_img, [c], -1, [255, 0, 0], 5);  print(\"Foram identificados\",len(contornos),\"contornos\")   plt.figure(figsize=(20,20)) plt.subplot(1, 2, 1); plt.imshow(opening,cmap=\"gray\") plt.subplot(1, 2, 2);plt.imshow(contornos_img); plt.show(); <pre>Foram identificados 99 contornos\n</pre> In\u00a0[8]: Copied! <pre>%matplotlib inline\nimport cv2\nfrom matplotlib import pyplot as plt\nimport numpy as np\n\nimg = cv2.imread('water_coins.jpg')\nimg_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n\n\nplt.figure(figsize = (10,10))\nplt.imshow(img_rgb); plt.show();\n</pre> %matplotlib inline import cv2 from matplotlib import pyplot as plt import numpy as np  img = cv2.imread('water_coins.jpg') img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)   plt.figure(figsize = (10,10)) plt.imshow(img_rgb); plt.show(); In\u00a0[10]: Copied! <pre>#implemente sua solu\u00e7\u00e3o aqui..\n</pre> #implemente sua solu\u00e7\u00e3o aqui.."},{"location":"aulas/PDI/lab11/watershed.html#processamento-de-imagens","title":"PROCESSAMENTO DE IMAGENS\u00b6","text":"<p>Objetivos da aula:</p> <ul> <li>apresentar e aplicar ao algoritimo de Watershed</li> </ul> <p>ref: https://github.com/bnsreenu/python_for_microscopists/blob/master/033-grain_size_analysis_using_wateshed_segmentation.py</p>"},{"location":"aulas/PDI/lab11/watershed.html#desafio","title":"Desafio\u00b6","text":"<p>Fa\u00e7a a segmenta\u00e7\u00e3o das moedas utilizando o algoritmo de watershed</p>"},{"location":"aulas/PDI/lab12/Template_matching.html","title":"Lab12 - Template matching","text":"<p>Objetivos da aula:</p> <ul> <li>apresentar e aplicar template matching</li> </ul> <p>Template matching</p> <p>At\u00e9 o momenos estudamos t\u00e9cnicas para realizar a segmenta\u00e7\u00e3o e detec\u00e7\u00e3o de objetos e formas simples como circulos e retas e cores.</p> <p>Agora vamos estudar uma t\u00e9cnica chamada template matching, essa t\u00e9cnica realiza o casamento (matching) entre uma imagem de refer\u00eancia (template) com uma imagem de an\u00e1lise.</p> <p>Uma intui\u00e7\u00e3o de como essa t\u00e9cnica funciona \u00e9 lembrar dos filtros lineares, com a fun\u00e7\u00e3o cv2.filter2d(), onde um kernel convolui uma imagem. Em outras palavras a nossa template realiza um processo iterativo varrendo pixel a pixel a imagem de an\u00e1lise buscando a maior correla\u00e7\u00e3o possivel. Na OpenCV podemos utilizar a fun\u00e7\u00e3o built-in cv2.matchTemplate().</p> <p>Queremos encontrar o GOOMBA na imagem. </p> In\u00a0[10]: Copied! <pre>## Vou fazer o download das imagens do laborat\u00f3rio diretamente do reposit\u00f3rio para usar no colab mais facil....\nimport requests\n\n# Definie o modulo e o laborat\u00f3rio\nmodulo ='PDI/'\nlaboratorio = 'lab12'\n\n# URL da API do GitHub para a pasta do reposit\u00f3rio\napi_url = \"https://api.github.com/repos/arnaldojr/cognitivecomputing/contents/material/aulas/\"\n\n# Monta a URL completa\nurl_completa = api_url + modulo + laboratorio\n\nprint(f\"Fazendo o download de: {url_completa}\")\n\n# Requisi\u00e7\u00e3o para obter a lista de arquivos na pasta\nresponse = requests.get(url_completa)\nfiles = response.json()\n\n# Fazer o download de cada arquivo de imagem\nfor file in files:\n    file_name = file['name']\n    if file_name.endswith(('.png', '.jpg', '.jpeg', '.mp4')):  # Adicione mais extens\u00f5es se necess\u00e1rio\n        file_url = file['download_url']\n        print(f\"Baixando {file_name}...\")\n        !wget -q {file_url} -P /content\n\nprint(\"Download conclu\u00eddo.\")\n</pre> ## Vou fazer o download das imagens do laborat\u00f3rio diretamente do reposit\u00f3rio para usar no colab mais facil.... import requests  # Definie o modulo e o laborat\u00f3rio modulo ='PDI/' laboratorio = 'lab12'  # URL da API do GitHub para a pasta do reposit\u00f3rio api_url = \"https://api.github.com/repos/arnaldojr/cognitivecomputing/contents/material/aulas/\"  # Monta a URL completa url_completa = api_url + modulo + laboratorio  print(f\"Fazendo o download de: {url_completa}\")  # Requisi\u00e7\u00e3o para obter a lista de arquivos na pasta response = requests.get(url_completa) files = response.json()  # Fazer o download de cada arquivo de imagem for file in files:     file_name = file['name']     if file_name.endswith(('.png', '.jpg', '.jpeg', '.mp4')):  # Adicione mais extens\u00f5es se necess\u00e1rio         file_url = file['download_url']         print(f\"Baixando {file_name}...\")         !wget -q {file_url} -P /content  print(\"Download conclu\u00eddo.\")  <pre>Fazendo o download de: https://api.github.com/repos/arnaldojr/cognitivecomputing/contents/material/aulas/PDI/lab12\nBaixando mario-template.png...\nBaixando mario-template2.png...\nBaixando mario.png...\nBaixando res.png...\nBaixando res2.png...\nDownload conclu\u00eddo.\n</pre> In\u00a0[11]: Copied! <pre>%matplotlib inline\nimport cv2\nfrom matplotlib import pyplot as plt\nimport numpy as np\n\n# carrega a imagem analisada.\nimg = cv2.imread('mario.png')\nimg_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n\nplt.imshow(img_rgb); plt.show();\n</pre> %matplotlib inline import cv2 from matplotlib import pyplot as plt import numpy as np  # carrega a imagem analisada. img = cv2.imread('mario.png') img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)  plt.imshow(img_rgb); plt.show(); In\u00a0[12]: Copied! <pre>%matplotlib inline\nimport cv2\nfrom matplotlib import pyplot as plt\nimport numpy as np\n\n# carrega as imagens.\ntemplate = cv2.imread('mario-template.png', 0)  ##template\n\nimg = cv2.imread('mario.png')  ### cena\nimg_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n\n# Aplica template Matching\nres = cv2.matchTemplate(img_gray,template,cv2.TM_SQDIFF)\n\n# res \u00e9 uma imagem e podemos plotar seu shape e imagem\n\nprint(res.shape, res.dtype)\n\n\nplt.figure(figsize = (10,10))\nplt.imshow(res,cmap=\"gray\");\n</pre> %matplotlib inline import cv2 from matplotlib import pyplot as plt import numpy as np  # carrega as imagens. template = cv2.imread('mario-template.png', 0)  ##template  img = cv2.imread('mario.png')  ### cena img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)  # Aplica template Matching res = cv2.matchTemplate(img_gray,template,cv2.TM_SQDIFF)  # res \u00e9 uma imagem e podemos plotar seu shape e imagem  print(res.shape, res.dtype)   plt.figure(figsize = (10,10)) plt.imshow(res,cmap=\"gray\"); <pre>(624, 965) float32\n</pre> <p>Visualmente podemos notar que o nosso GOOMBA est\u00e1 destacado na imagem como pixel mais escuro da imagem.</p> <p>Para capturar a posi\u00e7\u00e3o deste pixel vamos usar a fun\u00e7\u00e3o da OpenCV <code>cv2.minMaxLoc()</code> que devolde o valor minimo e maximo al\u00e9m de suas posi\u00e7\u00f5es</p> In\u00a0[13]: Copied! <pre>#Vamos aproveitar para entender melhor o que a fun\u00e7\u00e3o devolve.\n\nprint(cv2.minMaxLoc(res))\n#resultado\n# (1824.0, 58356096.0, (709, 511), (927, 11))\n\n# res \u00e9 umTemos 4 valores;\n# os 2 primeiros s\u00e3o float32, indicamos valores dos pixels com menor e maior valor\n# os 2 ultimos s\u00e3o tuplas que indicam a posi\u00e7\u00e3o (x,y) dos pixels com menor e maior valor\n# vamos separar cada um em uma variavel\n\nmin_val, max_val, min_loc, max_loc = cv2.minMaxLoc(res)\n</pre> #Vamos aproveitar para entender melhor o que a fun\u00e7\u00e3o devolve.  print(cv2.minMaxLoc(res)) #resultado # (1824.0, 58356096.0, (709, 511), (927, 11))  # res \u00e9 umTemos 4 valores; # os 2 primeiros s\u00e3o float32, indicamos valores dos pixels com menor e maior valor # os 2 ultimos s\u00e3o tuplas que indicam a posi\u00e7\u00e3o (x,y) dos pixels com menor e maior valor # vamos separar cada um em uma variavel  min_val, max_val, min_loc, max_loc = cv2.minMaxLoc(res)  <pre>(1824.0, 58356096.0, (709, 511), (927, 11))\n</pre> In\u00a0[\u00a0]: Copied! <pre>## Implemente sua solu\u00e7\u00e3o aqui....\n</pre> ## Implemente sua solu\u00e7\u00e3o aqui....       In\u00a0[15]: Copied! <pre># Resolu\u00e7\u00e3o do desafio1, j\u00e1 fiz pq preciso dela pra resolver o resto do notebook\n\n#Extrai o shape (dimens\u00e3o da imagem)\nlargura, altura = template.shape[::-1]\n\n# ajusta o bounbox da imagem lembra que \u00e9 uma tupla ()\nbottom_right = (min_loc[0] + largura, min_loc[1] + altura)\n\n# desenha o retangulo na imagem original\ncv2.rectangle(img,min_loc, bottom_right, (127,255,255), 4)\n\n#v2.imwrite(\"res.png\",img)\n\nplt.figure(figsize = (10,10))\nplt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB)); plt.show();\n</pre> # Resolu\u00e7\u00e3o do desafio1, j\u00e1 fiz pq preciso dela pra resolver o resto do notebook  #Extrai o shape (dimens\u00e3o da imagem) largura, altura = template.shape[::-1]  # ajusta o bounbox da imagem lembra que \u00e9 uma tupla () bottom_right = (min_loc[0] + largura, min_loc[1] + altura)  # desenha o retangulo na imagem original cv2.rectangle(img,min_loc, bottom_right, (127,255,255), 4)  #v2.imwrite(\"res.png\",img)  plt.figure(figsize = (10,10)) plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB)); plt.show(); In\u00a0[\u00a0]: Copied! <pre>## Implemente sua solu\u00e7\u00e3o aqui....\n</pre> ## Implemente sua solu\u00e7\u00e3o aqui....       <p>Vamos la....</p> In\u00a0[16]: Copied! <pre>%matplotlib inline\nimport cv2\nfrom matplotlib import pyplot as plt\nimport numpy as np\n\n# carrega as imagens.\ntemplate = cv2.imread('mario-template2.png', 0)\n\nimg = cv2.imread('mario.png')\nimg_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n\n# Aplica template Matching\nres = cv2.matchTemplate(img_gray,template,cv2.TM_SQDIFF_NORMED)\n\nplt.figure(figsize = (10,10))\nplt.imshow(res, cmap=\"gray\"); plt.show();\n</pre> %matplotlib inline import cv2 from matplotlib import pyplot as plt import numpy as np  # carrega as imagens. template = cv2.imread('mario-template2.png', 0)  img = cv2.imread('mario.png') img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)  # Aplica template Matching res = cv2.matchTemplate(img_gray,template,cv2.TM_SQDIFF_NORMED)  plt.figure(figsize = (10,10)) plt.imshow(res, cmap=\"gray\"); plt.show(); <p>Visualmente podemos notar que as <code>Caixas ?</code> est\u00e3o destacadas na imagem como os pixels mais escuros da imagem.</p> <p>Neste caso, onde queremos detectar mais que uma ocorrencia, a fun\u00e7\u00e3o cv2.minMaxLoc() n\u00e3o resolve nosso problema, pois devolve apenas uma ocorencia, n\u00e3o uma lista de valores.</p> <p>Vamos utilizar outro metodo para capiturar esses pontos.</p> In\u00a0[19]: Copied! <pre># Vamos entender como funciona a fun\u00e7\u00e3o np.where\n# essa fun\u00e7\u00e3o faz uma busca na matriz e devolve a posi\u00e7\u00e3o que satisfaz a condi\u00e7\u00e3o (x,y)\n\n# S\u00f3 para entender como funciona, vamos criar uma matriz (3,3)\na = np.array([[0, 1, 5],\n              [2, 2, 3],\n              [0, 3, 1]])\nprint(a.shape)\n\n# agora vamos busca nesta matriz os valores que s\u00e3o maiores ou igual a 4\nb = np.where(a &gt;= 1)\n\n# a variavel b \u00e9 uma tupla (x,y) com as posi\u00e7\u00f5es onde a matriz a \u00e9 maior ou igual a 4\nprint(b,type(b))\n\nprint(b[0])  ##vetor linha\nprint(b[1])  ###vetor coluna\nprint(b[::-1])\n</pre> # Vamos entender como funciona a fun\u00e7\u00e3o np.where # essa fun\u00e7\u00e3o faz uma busca na matriz e devolve a posi\u00e7\u00e3o que satisfaz a condi\u00e7\u00e3o (x,y)  # S\u00f3 para entender como funciona, vamos criar uma matriz (3,3) a = np.array([[0, 1, 5],               [2, 2, 3],               [0, 3, 1]]) print(a.shape)  # agora vamos busca nesta matriz os valores que s\u00e3o maiores ou igual a 4 b = np.where(a &gt;= 1)  # a variavel b \u00e9 uma tupla (x,y) com as posi\u00e7\u00f5es onde a matriz a \u00e9 maior ou igual a 4 print(b,type(b))  print(b[0])  ##vetor linha print(b[1])  ###vetor coluna print(b[::-1]) <pre>(3, 3)\n(array([0, 0, 1, 1, 1, 2, 2]), array([1, 2, 0, 1, 2, 1, 2])) &lt;class 'tuple'&gt;\n[0 0 1 1 1 2 2]\n[1 2 0 1 2 1 2]\n(array([1, 2, 0, 1, 2, 1, 2]), array([0, 0, 1, 1, 1, 2, 2]))\n</pre> In\u00a0[20]: Copied! <pre># Vamos aproveitar e entender como funciona o objeto zip\n# O zip recebe 2 ou mais sequencias e cria uma tupla juntando um elemento de cada\n\nc = 'FIAP'\nd = [0,1,2,4]\nzip(c,d)  # objeto zip\n\nfor pares in zip(c, d):\n    print(pares)\n\nprint(\"...\")#pular linha\n\n#no exemplo acima b \u00e9 uma tupla (x,y), para iterar precisamos descompactar a tupla, para isso usamos *.\n\nfor pt in zip(*b[::-1]):\n    print(pt,pt[0],pt[1])\n\n\n# Agora que entendemos, vamos voltar para o nosso problema original.\n</pre> # Vamos aproveitar e entender como funciona o objeto zip # O zip recebe 2 ou mais sequencias e cria uma tupla juntando um elemento de cada  c = 'FIAP' d = [0,1,2,4] zip(c,d)  # objeto zip  for pares in zip(c, d):     print(pares)  print(\"...\")#pular linha  #no exemplo acima b \u00e9 uma tupla (x,y), para iterar precisamos descompactar a tupla, para isso usamos *.  for pt in zip(*b[::-1]):     print(pt,pt[0],pt[1])   # Agora que entendemos, vamos voltar para o nosso problema original. <pre>('F', 0)\n('I', 1)\n('A', 2)\n('P', 4)\n...\n(1, 0) 1 0\n(2, 0) 2 0\n(0, 1) 0 1\n(1, 1) 1 1\n(2, 1) 2 1\n(1, 2) 1 2\n(2, 2) 2 2\n</pre> In\u00a0[17]: Copied! <pre>#Extrai o shape (dimens\u00e3o da imagem)\nw, h = template.shape[::-1]\n\n\n#print(res) #### ajuda a definir o valor de threshold\nthreshold = 0.1\nloc = np.where( res &lt;= threshold)\n\nfor pt in zip(*loc[::-1]):\n    cv2.rectangle(img, pt, (pt[0] + w, pt[1] + h), (0,255,0), 5)\n\n\n\n\n#cv2.imwrite(\"res2.png\",img)\nplt.figure(figsize = (10,10))\n#plt.imshow(img_rgb)\nplt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB)); plt.show();\n</pre> #Extrai o shape (dimens\u00e3o da imagem) w, h = template.shape[::-1]   #print(res) #### ajuda a definir o valor de threshold threshold = 0.1 loc = np.where( res &lt;= threshold)  for pt in zip(*loc[::-1]):     cv2.rectangle(img, pt, (pt[0] + w, pt[1] + h), (0,255,0), 5)     #cv2.imwrite(\"res2.png\",img) plt.figure(figsize = (10,10)) #plt.imshow(img_rgb) plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB)); plt.show();   In\u00a0[\u00a0]: Copied! <pre>#implemente sua solu\u00e7\u00e3o aqui....\n</pre> #implemente sua solu\u00e7\u00e3o aqui...."},{"location":"aulas/PDI/lab12/Template_matching.html#desafio-1","title":"DESAFIO 1\u00b6","text":"<p>Desenhe um retangulo como contorno sobre o GOOMBA</p> <p>Dica: A fun\u00e7\u00e3o cv2.rectangle(img, pos_inicial, posi\u00e7\u00e3o_final, color, espessura)</p> <p>Temos de definir pos_inicial e pos_final </p>"},{"location":"aulas/PDI/lab12/Template_matching.html#desafio-2","title":"DESAFIO 2\u00b6","text":"<p>Na fun\u00e7\u00e3o cv2.matchTemplate(Image, template, Metodo) temos 3 parametros:</p> <p>Utilizamos o m\u00e9todo cv2.TM_SQDIFF no exerc\u00edcio acima, explore a refer\u00eancia da OpenCV alterando os m\u00e9todos de correla\u00e7\u00e3o.</p> <p>Ref: https://docs.opencv.org/3.4/de/da9/tutorial_template_matching.html</p>"},{"location":"aulas/PDI/lab12/Template_matching.html#queremos-encontrar-o-na-imagem","title":"Queremos encontrar o <code>?</code> na imagem.\u00b6","text":"<p>Note que neste caso temos mais de uma ocorrencia na image.A imagem final deve detectar 4 caixas.</p>"},{"location":"aulas/PDI/lab12/Template_matching.html#pausa-na-aula-para-dica-rapida-de-python","title":"Pausa na aula para dica r\u00e1pida de python :)\u00b6","text":""},{"location":"aulas/PDI/lab12/Template_matching.html#npwhere","title":"np.where()\u00b6","text":"<p>Leia a documenta\u00e7\u00e3o oficial para conhecer a fun\u00e7\u00e3o np.where()</p> <p>link: https://numpy.org/doc/stable/reference/generated/numpy.where.html</p>"},{"location":"aulas/PDI/lab12/Template_matching.html#zip","title":"zip()\u00b6","text":"<p>j\u00e1 vimos na aula passada, apenas relembrando....</p>"},{"location":"aulas/PDI/lab12/Template_matching.html#voltando","title":"Voltando.....\u00b6","text":""},{"location":"aulas/PDI/lab12/Template_matching.html#desafio-3","title":"Desafio 3\u00b6","text":"<p>Refa\u00e7a o exercico acima substituindo o m\u00e9todo TM_SQDIFF_NORMED por outro qualquer. Verifique se \u00e9 necess\u00e1rio alterar a condi\u00e7\u00e3o do threshold ou outro ponto qualquer do c\u00f3digo.</p>"},{"location":"aulas/PDI/lab12/Template_matching.html#desafio-4","title":"Desafio 4\u00b6","text":"<p>Para pensar um pouco...</p> <pre><code>O que acontece se a template n\u00e3o estiver na escala do objeto que queremos detectar?\n\nO que acontece que a imagem estiver com um nivel de brilho ou contraste diferente da template?\n\nO que acontece se a imagem estiver rotacionada em rela\u00e7\u00e3o a template?</code></pre>"},{"location":"aulas/PDI/lab13/Features.html","title":"Lab13 - Features","text":"<p>Objetivos da aula:</p> <ul> <li>apresentar e aplicar o conceito de FEATURE</li> <li>apresentar e aplicar o conceito de DESCRITORES</li> </ul> <p>QUAL O PROBLEMA?</p> <p>Estamos tentando ao longo do curso computar imagens de forma eficiente. Na \u00faltima aula aprendemos e usamos a t\u00e9cnica template matching, vimos que \u00e9 uma t\u00e9cnica simples e poderosa que basicamente convolui uma template em um espa\u00e7o de busca (Imagem). Contudo, possui algumas fragilidades tais como, escala, rota\u00e7\u00e3o e intensidade luminosa.</p> <p>Queremos encontrar essa caixa. </p> <p></p> <p>Neste espa\u00e7o de busca, imagem. </p> <p>Vamos pensar um pouco...</p> <p>Com as t\u00e9cnicas que conhecemos, como podemos fazer essa detec\u00e7\u00e3o da caixa??</p> <p>...</p> <p>FEATURES</p> <p>Features em vis\u00e3o computacional s\u00e3o detalhes de uma imagem, que fornecem informa\u00e7\u00f5es sobre o que ela significa. J\u00e1 conhecemos e aplicamos t\u00e9cnicas para detec\u00e7\u00e3o por cor e contorno, por exemplo.</p> <p>Hoje, vamos conhecer uma t\u00e9cnica que extrai da imagem uma descri\u00e7\u00e3o local com pontos de interesse (key points), desta forma criamos uma assinatura para cada ponto da imagem, a ideia \u00e9 maximizar pontos que apresentam que apresentam invari\u00e2ncia a rota\u00e7\u00e3o, escala e transla\u00e7\u00e3o. Assim conseguimos buscar e encontrar esses pontos em outras imagens.</p> <p>Os principais algoritmos s\u00e3o:</p> <p>SIFT,ORB, SURF, FAST, BRISK</p> <p>Onde usamos esses algoritmos?</p> <pre><code>Reconhecimento de objetos\nalinhamento de imagens (imagens panor\u00e2micas)\nreconstru\u00e7\u00e3o 3d\ntracking de imagem\nindexa\u00e7\u00e3o de imagem (banco de imagem)</code></pre> In\u00a0[\u00a0]: Copied! <pre>## vou fazer o download das imagens do reposit\u00f3rio para usar no colab mais facil....\n\n!wget https://raw.githubusercontent.com/arnaldojr/cognitivecomputing/master/material/aulas/PDI/lab13/box_4features.png /content\n!wget https://raw.githubusercontent.com/arnaldojr/cognitivecomputing/master/material/aulas/PDI/lab13/box_in_scene.png /content\n!wget https://raw.githubusercontent.com/arnaldojr/cognitivecomputing/master/material/aulas/PDI/lab13/box.png /content\n!wget https://raw.githubusercontent.com/arnaldojr/cognitivecomputing/master/material/aulas/PDI/lab13/admiravelmundonovo.jpg /content\n!wget https://raw.githubusercontent.com/arnaldojr/cognitivecomputing/master/material/aulas/PDI/lab13/admiravelmundonovo.mp4 /content\n!wget https://raw.githubusercontent.com/arnaldojr/cognitivecomputing/master/material/aulas/PDI/lab13/q22.jpg /content\n!wget https://raw.githubusercontent.com/arnaldojr/cognitivecomputing/master/material/aulas/PDI/lab13/q11.jpg /content\n</pre> ## vou fazer o download das imagens do reposit\u00f3rio para usar no colab mais facil....  !wget https://raw.githubusercontent.com/arnaldojr/cognitivecomputing/master/material/aulas/PDI/lab13/box_4features.png /content !wget https://raw.githubusercontent.com/arnaldojr/cognitivecomputing/master/material/aulas/PDI/lab13/box_in_scene.png /content !wget https://raw.githubusercontent.com/arnaldojr/cognitivecomputing/master/material/aulas/PDI/lab13/box.png /content !wget https://raw.githubusercontent.com/arnaldojr/cognitivecomputing/master/material/aulas/PDI/lab13/admiravelmundonovo.jpg /content !wget https://raw.githubusercontent.com/arnaldojr/cognitivecomputing/master/material/aulas/PDI/lab13/admiravelmundonovo.mp4 /content !wget https://raw.githubusercontent.com/arnaldojr/cognitivecomputing/master/material/aulas/PDI/lab13/q22.jpg /content !wget https://raw.githubusercontent.com/arnaldojr/cognitivecomputing/master/material/aulas/PDI/lab13/q11.jpg /content  In\u00a0[1]: Copied! <pre>%matplotlib inline\nimport cv2\nfrom matplotlib import pyplot as plt\nimport numpy as np\n\n# carrega as imagens\nimg1 = cv2.imread('box.png',0)\nimg2 = cv2.imread('box_in_scene.png',0)\n\n#template\nplt.figure(figsize = (10,10))\nplt.imshow(img1, cmap=\"gray\"); plt.show();\n\n# Imagem espa\u00e7o de busca\nplt.figure(figsize = (10,10))\nplt.imshow(img2, cmap=\"gray\"); plt.show();\n</pre> %matplotlib inline import cv2 from matplotlib import pyplot as plt import numpy as np  # carrega as imagens img1 = cv2.imread('box.png',0) img2 = cv2.imread('box_in_scene.png',0)  #template plt.figure(figsize = (10,10)) plt.imshow(img1, cmap=\"gray\"); plt.show();  # Imagem espa\u00e7o de busca plt.figure(figsize = (10,10)) plt.imshow(img2, cmap=\"gray\"); plt.show();  In\u00a0[2]: Copied! <pre># inicializa com o construtor ORB\norb = cv2.ORB_create()\n</pre> # inicializa com o construtor ORB orb = cv2.ORB_create()  In\u00a0[3]: Copied! <pre># Detecta os keypoints\n#kp = orb.detect(img1,None)\n# Computa os Descritores\n#orb_tuple = orb.compute(img1, kp)\n\n#Podemos usar uma fun\u00e7\u00e3o que calcula os keypoints e Descritores\nkp1, des1 = orb.detectAndCompute(img1,None)\n</pre> # Detecta os keypoints #kp = orb.detect(img1,None) # Computa os Descritores #orb_tuple = orb.compute(img1, kp)  #Podemos usar uma fun\u00e7\u00e3o que calcula os keypoints e Descritores kp1, des1 = orb.detectAndCompute(img1,None)  In\u00a0[4]: Copied! <pre># Desenha os keypoints na imagem \ngray2 = cv2.drawKeypoints(img1, kp1, outImage=np.array([]), flags=0)\n\nplt.figure(figsize=(10, 10))\nplt.imshow(cv2.cvtColor(gray2, cv2.COLOR_BGR2RGB));\n</pre> # Desenha os keypoints na imagem  gray2 = cv2.drawKeypoints(img1, kp1, outImage=np.array([]), flags=0)  plt.figure(figsize=(10, 10)) plt.imshow(cv2.cvtColor(gray2, cv2.COLOR_BGR2RGB));  In\u00a0[5]: Copied! <pre># Os keypoints s\u00e3o formados dos gradientes da imagem naquele ponto, por essa raz\u00e3o possuem amplitude e dire\u00e7\u00e3o\ngray3 = cv2.drawKeypoints(img1, kp1, outImage=np.array([]), flags=cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)\n\n\nplt.figure(figsize=(10, 10))\nplt.imshow(cv2.cvtColor(gray3, cv2.COLOR_BGR2RGB))\n</pre> # Os keypoints s\u00e3o formados dos gradientes da imagem naquele ponto, por essa raz\u00e3o possuem amplitude e dire\u00e7\u00e3o gray3 = cv2.drawKeypoints(img1, kp1, outImage=np.array([]), flags=cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)   plt.figure(figsize=(10, 10)) plt.imshow(cv2.cvtColor(gray3, cv2.COLOR_BGR2RGB)) Out[5]: <pre>&lt;matplotlib.image.AxesImage at 0x14429c730&gt;</pre> In\u00a0[\u00a0]: Copied! <pre>### Implemente sua solu\u00e7\u00e3o aqui.....\n</pre> ### Implemente sua solu\u00e7\u00e3o aqui.....          <p>O resultado para 4 features, nessa imagem conseguimos visualizar os keypoints e sua dire\u00e7\u00e3o e amplitude do vetor gradiente resultante. </p> In\u00a0[\u00a0]: Copied! <pre>## Implemente sua solu\u00e7\u00e3o aqui......\n</pre> ## Implemente sua solu\u00e7\u00e3o aqui......       In\u00a0[6]: Copied! <pre>%matplotlib inline\nimport cv2\nfrom matplotlib import pyplot as plt\nimport numpy as np\n\n# carrega as imagens\nimg1 = cv2.imread('box.png',0)\nimg2 = cv2.imread('box_in_scene.png',0)\n\n# inicializa com o construtor ORB\norb = cv2.ORB_create()\n\n#Podemos usar uma fun\u00e7\u00e3o que calcula os keypoints e Descritores\nkp1, des1 = orb.detectAndCompute(img1,None)\nkp2, des2 = orb.detectAndCompute(img2,None)\n\n\ngray1 = cv2.drawKeypoints(img1, kp1, outImage=np.array([]), flags=0)\ngray2 = cv2.drawKeypoints(img2, kp2, outImage=np.array([]), flags=0)\n\n\n#template\nplt.figure(figsize = (10,10))\nplt.imshow(gray1); plt.show();\n\n# Imagem espa\u00e7o de busca\nplt.figure(figsize = (10,10))\nplt.imshow(gray2); plt.show();\n</pre> %matplotlib inline import cv2 from matplotlib import pyplot as plt import numpy as np  # carrega as imagens img1 = cv2.imread('box.png',0) img2 = cv2.imread('box_in_scene.png',0)  # inicializa com o construtor ORB orb = cv2.ORB_create()  #Podemos usar uma fun\u00e7\u00e3o que calcula os keypoints e Descritores kp1, des1 = orb.detectAndCompute(img1,None) kp2, des2 = orb.detectAndCompute(img2,None)   gray1 = cv2.drawKeypoints(img1, kp1, outImage=np.array([]), flags=0) gray2 = cv2.drawKeypoints(img2, kp2, outImage=np.array([]), flags=0)   #template plt.figure(figsize = (10,10)) plt.imshow(gray1); plt.show();  # Imagem espa\u00e7o de busca plt.figure(figsize = (10,10)) plt.imshow(gray2); plt.show();  In\u00a0[7]: Copied! <pre># cria o objeto bf (Brute-force descriptor matcher)\nbf = cv2.BFMatcher(cv2.NORM_HAMMING, crossCheck=True)\n\n# a fun\u00e7\u00e3o match devolve os matches encontrados\nmatches = bf.match(des1,des2)\n\nprint(\"Foram encontrados: {} matches\".format(len(matches)))\n\nimg3 = cv2.drawMatches(img1,kp1,img2,kp2,matches,None, flags=2)\n\nplt.figure(figsize = (20,10))\nplt.imshow(img3); plt.show();\n</pre> # cria o objeto bf (Brute-force descriptor matcher) bf = cv2.BFMatcher(cv2.NORM_HAMMING, crossCheck=True)  # a fun\u00e7\u00e3o match devolve os matches encontrados matches = bf.match(des1,des2)  print(\"Foram encontrados: {} matches\".format(len(matches)))  img3 = cv2.drawMatches(img1,kp1,img2,kp2,matches,None, flags=2)  plt.figure(figsize = (20,10)) plt.imshow(img3); plt.show();  <pre>Foram encontrados: 148 matches\n</pre> <p>Parece que o resultado n\u00e3o foi o que est\u00e1vamos esperando... mas nem tudo est\u00e1 perdido ainda. vamos fazer alguns ajustes nas fun\u00e7\u00f5es matches e na quantidade keypoints printados. Muitos keypoints s\u00e3o falsos positivos.</p> <p>Primeiro, vamos ordenar o vetor matches para ficar de acordo com a dist\u00e2ncia entre os descritores. Quanto mais baixo, melhor.</p> In\u00a0[8]: Copied! <pre>## Vamos dar uma olhada em duas fun\u00e7\u00f5es novas do python. sorted() e lambda\n\n# essa a lista de compra da feira, item e pre\u00e7o.\n\nlista = [\n    ('Banana', 18),\n    ('Ma\u00e7a', 1),\n    ('Goiaba', 20),\n    ('Uva', 22),\n    ('Pera', 12)\n]\n\nprint(\"lista n\u00e3o ordenada: \",lista) # lista n\u00e3o ordenada\n\nlista_ord = sorted(lista)\n\nprint(\"lista ordenada ordem alfabetica: \",lista_ord) # lista ordenada por indice a..z\n\nlista_ord_pre = sorted(lista, key= lambda x:x[1])\n\nprint(\"lista ordenada por pre\u00e7o: \",lista_ord_pre) # lista ordenada pelo pre\u00e7o\n</pre> ## Vamos dar uma olhada em duas fun\u00e7\u00f5es novas do python. sorted() e lambda  # essa a lista de compra da feira, item e pre\u00e7o.  lista = [     ('Banana', 18),     ('Ma\u00e7a', 1),     ('Goiaba', 20),     ('Uva', 22),     ('Pera', 12) ]  print(\"lista n\u00e3o ordenada: \",lista) # lista n\u00e3o ordenada  lista_ord = sorted(lista)  print(\"lista ordenada ordem alfabetica: \",lista_ord) # lista ordenada por indice a..z  lista_ord_pre = sorted(lista, key= lambda x:x[1])  print(\"lista ordenada por pre\u00e7o: \",lista_ord_pre) # lista ordenada pelo pre\u00e7o <pre>lista n\u00e3o ordenada:  [('Banana', 18), ('Ma\u00e7a', 1), ('Goiaba', 20), ('Uva', 22), ('Pera', 12)]\nlista ordenada ordem alfabetica:  [('Banana', 18), ('Goiaba', 20), ('Ma\u00e7a', 1), ('Pera', 12), ('Uva', 22)]\nlista ordenada por pre\u00e7o:  [('Ma\u00e7a', 1), ('Pera', 12), ('Banana', 18), ('Goiaba', 20), ('Uva', 22)]\n</pre> In\u00a0[9]: Copied! <pre># ordenamos o vetor matches para ficar os melhores (menor distancia) no inicio da lista\n\nmatches = sorted(matches, key = lambda x:x.distance)\n</pre> # ordenamos o vetor matches para ficar os melhores (menor distancia) no inicio da lista  matches = sorted(matches, key = lambda x:x.distance)  In\u00a0[10]: Copied! <pre>img3 = cv2.drawMatches(img1,kp1,img2,kp2,matches[:15],None, flags=2)\n\n\nplt.figure(figsize = (20,10))\nplt.imshow(img3); plt.show();\n</pre> img3 = cv2.drawMatches(img1,kp1,img2,kp2,matches[:15],None, flags=2)   plt.figure(figsize = (20,10)) plt.imshow(img3); plt.show(); In\u00a0[\u00a0]: Copied! <pre>## implemente sua solu\u00e7\u00e3o aqui......\n</pre> ## implemente sua solu\u00e7\u00e3o aqui......       In\u00a0[\u00a0]: Copied! <pre>######## N\u00e3o fa\u00e7a esse desafio no google colab, fa\u00e7a em sua m\u00e1quina. \n######## N\u00e3o fa\u00e7a esse desafio no google colab, fa\u00e7a em sua m\u00e1quina. \n######## N\u00e3o fa\u00e7a esse desafio no google colab, fa\u00e7a em sua m\u00e1quina. \n######## N\u00e3o fa\u00e7a esse desafio no google colab, fa\u00e7a em sua m\u00e1quina. \n######## N\u00e3o fa\u00e7a esse desafio no google colab, fa\u00e7a em sua m\u00e1quina. \n######## N\u00e3o fa\u00e7a esse desafio no google colab, fa\u00e7a em sua m\u00e1quina. \n######## N\u00e3o fa\u00e7a esse desafio no google colab, fa\u00e7a em sua m\u00e1quina. \n######## N\u00e3o fa\u00e7a esse desafio no google colab, fa\u00e7a em sua m\u00e1quina. \n######## N\u00e3o fa\u00e7a esse desafio no google colab, fa\u00e7a em sua m\u00e1quina. \n######## N\u00e3o fa\u00e7a esse desafio no google colab, fa\u00e7a em sua m\u00e1quina. \n######## N\u00e3o fa\u00e7a esse desafio no google colab, fa\u00e7a em sua m\u00e1quina. \n######## N\u00e3o fa\u00e7a esse desafio no google colab, fa\u00e7a em sua m\u00e1quina. \n######## N\u00e3o fa\u00e7a esse desafio no google colab, fa\u00e7a em sua m\u00e1quina. \n######## N\u00e3o fa\u00e7a esse desafio no google colab, fa\u00e7a em sua m\u00e1quina.\n</pre> ######## N\u00e3o fa\u00e7a esse desafio no google colab, fa\u00e7a em sua m\u00e1quina.  ######## N\u00e3o fa\u00e7a esse desafio no google colab, fa\u00e7a em sua m\u00e1quina.  ######## N\u00e3o fa\u00e7a esse desafio no google colab, fa\u00e7a em sua m\u00e1quina.  ######## N\u00e3o fa\u00e7a esse desafio no google colab, fa\u00e7a em sua m\u00e1quina.  ######## N\u00e3o fa\u00e7a esse desafio no google colab, fa\u00e7a em sua m\u00e1quina.  ######## N\u00e3o fa\u00e7a esse desafio no google colab, fa\u00e7a em sua m\u00e1quina.  ######## N\u00e3o fa\u00e7a esse desafio no google colab, fa\u00e7a em sua m\u00e1quina.  ######## N\u00e3o fa\u00e7a esse desafio no google colab, fa\u00e7a em sua m\u00e1quina.  ######## N\u00e3o fa\u00e7a esse desafio no google colab, fa\u00e7a em sua m\u00e1quina.  ######## N\u00e3o fa\u00e7a esse desafio no google colab, fa\u00e7a em sua m\u00e1quina.  ######## N\u00e3o fa\u00e7a esse desafio no google colab, fa\u00e7a em sua m\u00e1quina.  ######## N\u00e3o fa\u00e7a esse desafio no google colab, fa\u00e7a em sua m\u00e1quina.  ######## N\u00e3o fa\u00e7a esse desafio no google colab, fa\u00e7a em sua m\u00e1quina.  ######## N\u00e3o fa\u00e7a esse desafio no google colab, fa\u00e7a em sua m\u00e1quina. In\u00a0[11]: Copied! <pre>%matplotlib inline\nimport cv2\nfrom matplotlib import pyplot as plt\nimport numpy as np\n\n# carrega as imagens\nimg = cv2.imread(\"q11.jpg\")\nimg2 = cv2.imread(\"q22.jpg\")\n\n\n# Exibe as imagens que ser\u00e3o usadas\nplt.figure(figsize = (10,10))\nplt.subplot(1, 2, 1), plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\nplt.subplot(1, 2, 2), plt.imshow(cv2.cvtColor(img2, cv2.COLOR_BGR2RGB))\nplt.show();\n</pre> %matplotlib inline import cv2 from matplotlib import pyplot as plt import numpy as np  # carrega as imagens img = cv2.imread(\"q11.jpg\") img2 = cv2.imread(\"q22.jpg\")   # Exibe as imagens que ser\u00e3o usadas plt.figure(figsize = (10,10)) plt.subplot(1, 2, 1), plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB)) plt.subplot(1, 2, 2), plt.imshow(cv2.cvtColor(img2, cv2.COLOR_BGR2RGB)) plt.show(); In\u00a0[14]: Copied! <pre># Cria o objeto Stitcher\nstitcher = cv2.Stitcher.create()\n\n# Essa \u00e9 a parte mais complicada do c\u00f3digo, \u00e9 aqui que o hard work \u00e9 feito. \n# o m\u00e9todo devolve em status se foi possivel realizar overlap (sopreposi\u00e7\u00e3o) das imagens na variavel status,\n# se sim, a imagem esta panoramica est\u00e1 em result.\n(status, result) = stitcher.stitch((img,img2))\n\nif (status == cv2.STITCHER_OK):\n    print(\"Sucesso, imagem gerada, exiba o result\")\nelse:\n    print(\"falha, n\u00e3o consegui gerar a imagem\")\n</pre> # Cria o objeto Stitcher stitcher = cv2.Stitcher.create()  # Essa \u00e9 a parte mais complicada do c\u00f3digo, \u00e9 aqui que o hard work \u00e9 feito.  # o m\u00e9todo devolve em status se foi possivel realizar overlap (sopreposi\u00e7\u00e3o) das imagens na variavel status, # se sim, a imagem esta panoramica est\u00e1 em result. (status, result) = stitcher.stitch((img,img2))  if (status == cv2.STITCHER_OK):     print(\"Sucesso, imagem gerada, exiba o result\") else:     print(\"falha, n\u00e3o consegui gerar a imagem\") <pre>Sucesso, imagem gerada, exiba o result\n</pre> In\u00a0[15]: Copied! <pre>plt.figure(figsize = (10,10))\nplt.imshow(cv2.cvtColor(result, cv2.COLOR_BGR2RGB)); plt.show();\n</pre> plt.figure(figsize = (10,10)) plt.imshow(cv2.cvtColor(result, cv2.COLOR_BGR2RGB)); plt.show(); <p>Temos um bom resultado, mas as bordas n\u00e3o ficaram boas. Podemos aplicar um crop na imagem. Podemos fazer um crop chutando alguns valores ou podemos tentar fazer esse processo de forma automatica.</p> In\u00a0[16]: Copied! <pre># n\u00e3o \u00e9 a melhor tecnica, mas resolve...\nprint(result.shape)\nh = result.shape[0]\nw = result.shape[1]\nprint(h,w)\ncrop = result[150:2700, 50:3350]\nplt.figure(figsize = (10,10))\nplt.imshow(cv2.cvtColor(crop, cv2.COLOR_BGR2RGB)); plt.show();  \n</pre> # n\u00e3o \u00e9 a melhor tecnica, mas resolve... print(result.shape) h = result.shape[0] w = result.shape[1] print(h,w) crop = result[150:2700, 50:3350] plt.figure(figsize = (10,10)) plt.imshow(cv2.cvtColor(crop, cv2.COLOR_BGR2RGB)); plt.show();   <pre>(2889, 3402, 3)\n2889 3402\n</pre>"},{"location":"aulas/PDI/lab13/Features.html#reconhecimento-de-imagem-no-espaco-de-busca","title":"Reconhecimento de imagem no espa\u00e7o de busca\u00b6","text":"<p>Vamos usar a imagem acima para aplicar esse m\u00e9todo.</p> <p>Vamos usar o m\u00e9todo ORB, \u00e9 semelhante ao SIFT, mas n\u00e3o \u00e9 patenteado.</p> <p>https://docs.opencv.org/3.4/db/d95/classcv_1_1ORB.html</p>"},{"location":"aulas/PDI/lab13/Features.html#desafio-1","title":"Desafio 1\u00b6","text":"<p>Por default os m\u00e9todos descritores quando s\u00e3o criados est\u00e3o configurados para encontrar 500 features na imagem.</p> <p>Busque na documenta\u00e7\u00e3o da OpenCV como alterar esse par\u00e2metro e descubra quais outros par\u00e2metros podem ser configurados no m\u00e9todo cv2.orb_create()</p> <p>https://docs.opencv.org/3.4/db/d95/classcv_1_1ORB.html</p>"},{"location":"aulas/PDI/lab13/Features.html#continuando","title":"Continuando...\u00b6","text":"<p>Agora j\u00e1 possu\u00edmos a \"assinatura\" da nossa caixa de cereais.</p> <p>Vamos realizar a detec\u00e7\u00e3o e descri\u00e7\u00f5es dos keypoints da imagem do espa\u00e7o de busca.</p>"},{"location":"aulas/PDI/lab13/Features.html#desafio-2","title":"Desafio 2\u00b6","text":"<p>Fa\u00e7a um c\u00f3digo que calcula os keypoints para a imagem no espa\u00e7o de busca. Compare a caixa de cereal das duas imagens (box e box_in_scene), existe correla\u00e7\u00e3o entre todos os keypoints?</p>"},{"location":"aulas/PDI/lab13/Features.html#fazendo-o-match","title":"Fazendo o match...\u00b6","text":"<p>Visualmente podemos ter uma intui\u00e7\u00e3o se existe matching entre os keypoints, mas na vamos usar a fun\u00e7\u00e3o cv2.BFMatcher()</p>"},{"location":"aulas/PDI/lab13/Features.html#pausa-para-uma-dica-python","title":"Pausa para uma dica Python\u00b6","text":"<p>ordena\u00e7\u00e3o de vetor e fun\u00e7\u00e3o lambda, veja como \u00e9 simples :)</p>"},{"location":"aulas/PDI/lab13/Features.html#voltando-ao-nosso-problema","title":"Voltando ao nosso problema\u00b6","text":""},{"location":"aulas/PDI/lab13/Features.html#resultado-de-match","title":"Resultado de match\u00b6","text":"<p>O resultado de matches = bf.match(des1,des2) devolve uma lista de objetos do tipo DMatch. Os atributos s\u00e3o:</p> <ul> <li>DMatch.distance - Distancia entre os descritores da menor para maior dist\u00e2ncia. (Quanto menor melhor)</li> <li>DMatch.trainIdx - Index of the descriptor in train descriptors</li> <li>DMatch.queryIdx - Index of the descriptor in query descriptors</li> <li>DMatch.imgIdx - Index of the train image.</li> </ul>"},{"location":"aulas/PDI/lab13/Features.html#desafio-3","title":"Desafio 3\u00b6","text":"<p>Refa\u00e7a este notebook utilizando o m\u00e9todo SIFT.</p> <p>Dicas: No in\u00edcio do c\u00f3digo, basta trocar o orb por sift.</p> <p>Para a fun\u00e7\u00e3o cv2.BFMatcher() use o m\u00e9todo baseado em KNN knnMatch()</p> <p>Encontre por material de ref\u00eancia em projetos de outras pessoas no github.</p>"},{"location":"aulas/PDI/lab13/Features.html#desafio-4-para-entregar","title":"Desafio 4 - Para entregar\u00b6","text":"<p>Implemente um c\u00f3digo em python .py que realiza a detec\u00e7\u00e3o em tempo real da webcam. Sugest\u00e3o: como template, escolha um livro, ou algo semelhante.</p> <p>no reposit\u00f3rio deixei como sugest\u00e3o uma imagem e um video que pode ser utilizado como refer\u00eancia se chama <code>admiravelmundonovo</code> jpg e mp4 respectivamente.</p> <p>Para desenhar o contorno quando \u00e9 encontrado match use a fun\u00e7\u00e3o abaixo:</p> <pre>def desenhaContorno(qp,tp,refImg,frame):\n        \"\"\"\n        essa fun\u00e7\u00e3o do tipo void que desenha o contorno quando existe matches das duas imagens\n        \n        recebe:\n         - qp,tp que representa a convers\u00e3o de keypoints em argumentos para o findhomography ref:https://answers.opencv.org/question/122802/how-to-convert-keypoints-to-an-argument-for-findhomography/\n         - refImg = imagem de refer\u00eancia\n         - frame = imagem de destino onde ser\u00e1 desenhado o contorno\n\n    \"\"\"\n        # o findHomography mapeia os pontos de um plano em outro.\n        # ou seja, mapeia os keypoints da imagem ref em frame\n        H,status=cv2.findHomography(qp,tp,cv2.RANSAC,3.0)\n        \n        # extrai o shape da imagem de referencia\n        h,w=refImg.shape\n        # Mapeia os pontos das bordas com base no shape refImg (imagem de referncia), s\u00e3o 4 pontos\n        #  [0,0]        [w-1,0]\n        #\n        # \n        #  [0,h-1]      [w-1,h-1]\n        #\n        refBorda=np.float32([[[0,0],[0,h-1],[w-1,h-1],[w-1,0]]])\n        # Usa refBorda e a matrix de homografia H para calcular a matrix transforma\u00e7\u00e3o de pespectiva\n        frameBorda=cv2.perspectiveTransform(refBorda,H)\n        # polylines desenha poligonos ou qualquer imagem, na cor verde e largura do tra\u00e7o igual a 5.\n        cv2.polylines(frame,[np.int32(frameBorda)],True,(0,255,0),5)\n</pre> <p>Busque por refer\u00eancias externas para resolver o desafio. Bom trabalho.</p>"},{"location":"aulas/PDI/lab13/Features.html#imagem-panoramica","title":"Imagem panor\u00e2mica\u00b6","text":"<p>Imagem panor\u00e2mica, para criar a nossa imagem panor\u00e2mica vamos utilizar todos os conceitos que vimos de extra\u00e7\u00e3o e descri\u00e7\u00e3o de features.</p> <p>Vou demonstrar duas t\u00e9cnicas para realizar esse processo.</p> <p>O primeiro utilizando os passos do m\u00e9todo que aprendemos, realizando a extra\u00e7\u00e3o de features com SIFT, destacando as melhores correla\u00e7\u00f5es e realizando a sobreposi\u00e7\u00e3o das imagens. Uma sugest\u00e3o de como realizar este processo est\u00e1 implementado no link do github, os c\u00f3digos est\u00e3o abertos e pode ser explorado.</p> <p>ref. https://github.com/linrl3/Image-Stitching-OpenCV.git</p> <p>O segundo \u00e9 utilizando uma fun\u00e7\u00e3o built-in da openCV para isso, cv2.Stitcher() por debaixo dos panos essa fun\u00e7\u00e3o realiza as mesmas t\u00e9cnicas que estudamos, com a diferen\u00e7a de estar otimizada para uso.</p> <p>ref. https://docs.opencv.org/master/d2/d8d/classcv_1_1Stitcher.html</p>"},{"location":"aulas/PDI/lab13/webcam_sift.html","title":"Webcam sift","text":"In\u00a0[\u00a0]: Copied! In\u00a0[\u00a0]: Copied! <pre># este c\u00f3digo implementa o descritor SIFT e realiza um processo homografia para desenhar o contorno da imagem detectada\nimport cv2\nimport numpy as np\n</pre> # este c\u00f3digo implementa o descritor SIFT e realiza um processo homografia para desenhar o contorno da imagem detectada import cv2 import numpy as np In\u00a0[\u00a0]: Copied! <pre># Numero m\u00ednimo de matches para considerar que encontrou o objeto\nminKPMatch=30\n</pre> # Numero m\u00ednimo de matches para considerar que encontrou o objeto minKPMatch=30 In\u00a0[\u00a0]: Copied! <pre># Inicializa o SIFT\nsift=cv2.SIFT_create(nfeatures=500)\n</pre> # Inicializa o SIFT sift=cv2.SIFT_create(nfeatures=500) In\u00a0[\u00a0]: Copied! <pre># Carrega a imagem de referencia na escala de cinza.\n# Em outras palavras, quero encontrar essa imagem no video. \nrefImg=cv2.imread(\"admiravelmundonovo.jpg\",0)\n</pre> # Carrega a imagem de referencia na escala de cinza. # Em outras palavras, quero encontrar essa imagem no video.  refImg=cv2.imread(\"admiravelmundonovo.jpg\",0) In\u00a0[\u00a0]: Copied! <pre># Calcula os keypoints e Descritores da imagem de referencia\nrefKP,refDesc = sift.detectAndCompute(refImg,None)\n</pre> # Calcula os keypoints e Descritores da imagem de referencia refKP,refDesc = sift.detectAndCompute(refImg,None) In\u00a0[\u00a0]: Copied! <pre># configura a captura de imagem da webcam\nvc=cv2.VideoCapture('admiravelmundonovo.mp4')\n# vc=cv2.VideoCapture(0)\n</pre> # configura a captura de imagem da webcam vc=cv2.VideoCapture('admiravelmundonovo.mp4') # vc=cv2.VideoCapture(0) In\u00a0[\u00a0]: Copied! <pre># Cria um objeto BFMatcher\nbf = cv2.BFMatcher()\n</pre> # Cria um objeto BFMatcher bf = cv2.BFMatcher() In\u00a0[\u00a0]: Copied! <pre># \u00e1rea m\u00ednima para desenhar o pol\u00edgono\nmin_area = 1000\n</pre> # \u00e1rea m\u00ednima para desenhar o pol\u00edgono min_area = 1000 In\u00a0[\u00a0]: Copied! <pre># configs para exibir o texto na tela\nfonte = cv2.FONT_HERSHEY_SIMPLEX\nposicao = (10, 30)  # Posi\u00e7\u00e3o do texto no canto superior esquerdo\nfonte_escala = 1  # Tamanho da fonte\ncor = (255, 0, 0)  # Cor do texto (branco)\nespessura = 2  # Espessura do texto\n</pre> # configs para exibir o texto na tela fonte = cv2.FONT_HERSHEY_SIMPLEX posicao = (10, 30)  # Posi\u00e7\u00e3o do texto no canto superior esquerdo fonte_escala = 1  # Tamanho da fonte cor = (255, 0, 0)  # Cor do texto (branco) espessura = 2  # Espessura do texto In\u00a0[\u00a0]: Copied! <pre>while True:\n    rval, frame = vc.read()\n\n    if not rval:\n        break   \n\n\n    # Converte o frame da web para escala de cinza\n    frameImg=cv2.cvtColor(frame,cv2.COLOR_BGR2GRAY)\n\n    # Calcula os keypoints e Descritores do frame recebido pela webcam\n    frameKP, frameDesc = sift.detectAndCompute(frameImg,None)\n\n    # a fun\u00e7\u00e3o matches devolve os pontos encontrados\n    # para k=2, dois objetos s\u00e3o retornados\n    matches = bf.knnMatch(refDesc,frameDesc, k=2) \n\n    # Filtra os matches encontrados em matches (m,n), para obter um resultado mais limpo\n    # Implementado conforme o paper publicado por D.Lowe\n    goodMatch=[]\n    for m,n in matches:\n        if(m.distance &lt; 0.75*n.distance):\n            goodMatch.append(m)\n       \n    # Testa se foram encontrados matches acima do minimo definido\n    if(len(goodMatch)&gt; minKPMatch):\n        # Se sim, extrai os matches das duas imagens.\n        # isso \u00e9 importante pq sabendo onde os pontos se encontram nas duas imagens\n        # posso correlacionar as coordenadas de uma imagem na outra\n        # ref:https://answers.opencv.org/question/122802/how-to-convert-keypoints-to-an-argument-for-findhomography/\n\n        tp=[]\n        qp=[]\n        for m in goodMatch:\n            qp.append(refKP[m.queryIdx].pt) # fornece os indices de um ID e .pt as coordenadas\n            tp.append(frameKP[m.trainIdx].pt)\n        tp,qp=np.float32((tp,qp))\n        \n        # o findHomography mapeia os pontos de um plano em outro.\n        # ou seja, mapeia os keypoints da imagem ref em frame\n        H,status=cv2.findHomography(qp,tp,cv2.RANSAC,3.0)\n        \n        # extrai o shape da imagem de referencia\n        h,w=refImg.shape\n        # Mapeia os pontos das bordas com base no shape refImg, s\u00e3o 4 pontos\n        #  [0,0]        [w-1,0]\n        #\n        # \n        #  [0,h-1]      [w-1,h-1]\n        #\n        refBorda = np.float32([[[0,0],[0,h-1],[w-1,h-1],[w-1,0]]])\n        # Usa refBorda e a matrix de homografia H para calcular a matrix transforma\u00e7\u00e3o de pespectiva\n        frameBorda = cv2.perspectiveTransform(refBorda,H)\n\n        # Para nao desenhar contornos falsos positivos, vou calcula a area do poligono encontrado e comparar com a area minima\n        area = cv2.contourArea(frameBorda)\n\n        # Desenha o pol\u00edgono se a \u00e1rea for maior que a \u00e1rea m\u00ednima\n        if area &gt; min_area:\n            cv2.polylines(frame, [np.int32(frameBorda)], True, (0, 255, 0), 5)\n            texto = f\"Encontrado match - {len(goodMatch)}/{minKPMatch} - area: {int(area)} - BOM\"\n        else:\n            texto = f\"Encontrado match - {len(goodMatch)}/{minKPMatch} - area: {int(area)} - INSUFICIENTE\"\n    else:\n        texto = f\"Encontrado match - {len(goodMatch)}/{minKPMatch} - RUIM\"\n\n    # Escreva o texto e exibe a imagem\n    cv2.putText(frame, texto, posicao, fonte, fonte_escala, cor, espessura)\n    cv2.imshow(\"resultado\", frame)\n\n    rval, frame = vc.read()\n    if cv2.waitKey(10) &amp; 0xFF == ord('q'):# tecla 'q' para sair do programa\n        break\n</pre> while True:     rval, frame = vc.read()      if not rval:         break          # Converte o frame da web para escala de cinza     frameImg=cv2.cvtColor(frame,cv2.COLOR_BGR2GRAY)      # Calcula os keypoints e Descritores do frame recebido pela webcam     frameKP, frameDesc = sift.detectAndCompute(frameImg,None)      # a fun\u00e7\u00e3o matches devolve os pontos encontrados     # para k=2, dois objetos s\u00e3o retornados     matches = bf.knnMatch(refDesc,frameDesc, k=2)       # Filtra os matches encontrados em matches (m,n), para obter um resultado mais limpo     # Implementado conforme o paper publicado por D.Lowe     goodMatch=[]     for m,n in matches:         if(m.distance &lt; 0.75*n.distance):             goodMatch.append(m)             # Testa se foram encontrados matches acima do minimo definido     if(len(goodMatch)&gt; minKPMatch):         # Se sim, extrai os matches das duas imagens.         # isso \u00e9 importante pq sabendo onde os pontos se encontram nas duas imagens         # posso correlacionar as coordenadas de uma imagem na outra         # ref:https://answers.opencv.org/question/122802/how-to-convert-keypoints-to-an-argument-for-findhomography/          tp=[]         qp=[]         for m in goodMatch:             qp.append(refKP[m.queryIdx].pt) # fornece os indices de um ID e .pt as coordenadas             tp.append(frameKP[m.trainIdx].pt)         tp,qp=np.float32((tp,qp))                  # o findHomography mapeia os pontos de um plano em outro.         # ou seja, mapeia os keypoints da imagem ref em frame         H,status=cv2.findHomography(qp,tp,cv2.RANSAC,3.0)                  # extrai o shape da imagem de referencia         h,w=refImg.shape         # Mapeia os pontos das bordas com base no shape refImg, s\u00e3o 4 pontos         #  [0,0]        [w-1,0]         #         #          #  [0,h-1]      [w-1,h-1]         #         refBorda = np.float32([[[0,0],[0,h-1],[w-1,h-1],[w-1,0]]])         # Usa refBorda e a matrix de homografia H para calcular a matrix transforma\u00e7\u00e3o de pespectiva         frameBorda = cv2.perspectiveTransform(refBorda,H)          # Para nao desenhar contornos falsos positivos, vou calcula a area do poligono encontrado e comparar com a area minima         area = cv2.contourArea(frameBorda)          # Desenha o pol\u00edgono se a \u00e1rea for maior que a \u00e1rea m\u00ednima         if area &gt; min_area:             cv2.polylines(frame, [np.int32(frameBorda)], True, (0, 255, 0), 5)             texto = f\"Encontrado match - {len(goodMatch)}/{minKPMatch} - area: {int(area)} - BOM\"         else:             texto = f\"Encontrado match - {len(goodMatch)}/{minKPMatch} - area: {int(area)} - INSUFICIENTE\"     else:         texto = f\"Encontrado match - {len(goodMatch)}/{minKPMatch} - RUIM\"      # Escreva o texto e exibe a imagem     cv2.putText(frame, texto, posicao, fonte, fonte_escala, cor, espessura)     cv2.imshow(\"resultado\", frame)      rval, frame = vc.read()     if cv2.waitKey(10) &amp; 0xFF == ord('q'):# tecla 'q' para sair do programa         break In\u00a0[\u00a0]: Copied! <pre>vc.release()\ncv2.destroyAllWindows()\n</pre> vc.release() cv2.destroyAllWindows()"},{"location":"aulas/PDI/lab14/haarCascade.html","title":"Lab14 - Detector haar Cascade","text":"<p>Objetivos da aula:</p> <ul> <li>apresentar uma introdu\u00e7\u00e3o sobre aprendizado de m\u00e1quina</li> <li>apresentar e aplicar o haar cascade para detec\u00e7\u00e3o de face</li> <li>apresentar uma intui\u00e7\u00e3o do algoritimo de Viola Jones</li> </ul> <p>Como fazer a dete\u00e7\u00e3o de faces?</p> <p>O nosso objetivo hoje \u00e9 compreender a essencia de algoritimos para detec\u00e7\u00e3o facial, apenas refor\u00e7ando que j\u00e1 sabemos, esses algoritmos s\u00e3o utilizados para diversas aplica\u00e7\u00f5es, desde a lendaria camera tekpix, passando por smartphones e o google fotos para classificador na organiza\u00e7\u00e3o de pastas por pessoas, por exemplo.</p> <p>Aprendizado de m\u00e1quina</p> <p>Antes de entrar em tecnicas mais avan\u00e7adas de Deep Learning em vis\u00e3o computacional, vamos introduzir este tema estudando e aplicando o m\u00e9todo muito cl\u00e1ssico de classifica\u00e7\u00e3o em cascata de faces desenvolvido por Viola e Jones, na OpenCV temos exemplares pr\u00e9-treinados para detec\u00e7\u00e3o de faces e de olhos.</p> <p>**Classificador Haar-Cascade **</p> <p>Voc\u00ea vai ver em todo e qualquer curso ou livro de vis\u00e3o computacional o detector de face de Viola-Jones sendo mencionado. Inventado em 2001, foi disruptivo no campo da vis\u00e3o computacional, por que finalmente permitiu a detec\u00e7\u00e3o e o reconhecimento de rostos em tempo real.</p> <p>Muito obrigado Viola e Jones :)</p> <p>ref: https://www.cs.cmu.edu/~efros/courses/LBMV07/Papers/viola-cvpr-01.pdf https://docs.opencv.org/master/db/d28/tutorial_cascade_classifier.html</p> <p>Para apresentar uma intui\u00e7\u00e3o de como funciona, vamos imaginar o seguinte:</p> <p>Algumas caracteristicas do rosto s\u00e3o bem definidas e conseguimos correlacionar tais como bochecha com olhos, testa com nariz.... Para encontrar essas correla\u00e7\u00f5es usamos a ideia de feature e convolu\u00e7\u00e3o que ja estudamos. Podemos visualizar essa t\u00e9cnica no gif da Lena.</p> <p>ref. https://vimeo.com/12774628</p> In\u00a0[1]: Copied! <pre>## Vou fazer o download das imagens do laborat\u00f3rio diretamente do reposit\u00f3rio para usar no colab mais facil....\nimport requests\n\n# Definie o modulo e o laborat\u00f3rio\nmodulo ='PDI/'\nlaboratorio = 'lab14'\n\n# URL da API do GitHub para a pasta do reposit\u00f3rio\napi_url = \"https://api.github.com/repos/arnaldojr/cognitivecomputing/contents/material/aulas/\"\n\n# Monta a URL completa\nurl_completa = api_url + modulo + laboratorio\n\nprint(f\"Fazendo o download de: {url_completa}\")\n\n# Requisi\u00e7\u00e3o para obter a lista de arquivos na pasta\nresponse = requests.get(url_completa)\nfiles = response.json()\n\n# Fazer o download de cada arquivo de imagem\nfor file in files:\n    file_name = file['name']\n    if file_name.endswith(('.png', '.jpg', '.jpeg', '.mp4')):  # Adicione mais extens\u00f5es se necess\u00e1rio\n        file_url = file['download_url']\n        print(f\"Baixando {file_name}...\")\n        !wget -q {file_url} -P /content\n\nprint(\"Download conclu\u00eddo.\")\n</pre> ## Vou fazer o download das imagens do laborat\u00f3rio diretamente do reposit\u00f3rio para usar no colab mais facil.... import requests  # Definie o modulo e o laborat\u00f3rio modulo ='PDI/' laboratorio = 'lab14'  # URL da API do GitHub para a pasta do reposit\u00f3rio api_url = \"https://api.github.com/repos/arnaldojr/cognitivecomputing/contents/material/aulas/\"  # Monta a URL completa url_completa = api_url + modulo + laboratorio  print(f\"Fazendo o download de: {url_completa}\")  # Requisi\u00e7\u00e3o para obter a lista de arquivos na pasta response = requests.get(url_completa) files = response.json()  # Fazer o download de cada arquivo de imagem for file in files:     file_name = file['name']     if file_name.endswith(('.png', '.jpg', '.jpeg', '.mp4')):  # Adicione mais extens\u00f5es se necess\u00e1rio         file_url = file['download_url']         print(f\"Baixando {file_name}...\")         !wget -q {file_url} -P /content  print(\"Download conclu\u00eddo.\")   <pre>Fazendo o download de: https://api.github.com/repos/arnaldojr/cognitivecomputing/contents/material/aulas/PDI/lab14\nBaixando acumulador.jpg...\nBaixando lena-eye-face.png...\nBaixando lena.png...\nDownload conclu\u00eddo.\n</pre> In\u00a0[2]: Copied! <pre>%matplotlib inline\nimport cv2\nfrom matplotlib import pyplot as plt\nimport numpy as np\n\n#caminho onde est\u00e3o os pesos\npath = cv2.data.haarcascades + \"haarcascade_frontalface_default.xml\"\n\n# Inicializa o classificador cascade\nface = cv2.CascadeClassifier(path)\n\nprint(\"Os pesos est\u00e3o no diretorio: \", path)\n</pre> %matplotlib inline import cv2 from matplotlib import pyplot as plt import numpy as np  #caminho onde est\u00e3o os pesos path = cv2.data.haarcascades + \"haarcascade_frontalface_default.xml\"  # Inicializa o classificador cascade face = cv2.CascadeClassifier(path)  print(\"Os pesos est\u00e3o no diretorio: \", path)  <pre>Os pesos est\u00e3o no diretorio:  /usr/local/lib/python3.10/dist-packages/cv2/data/haarcascade_frontalface_default.xml\n</pre> In\u00a0[\u00a0]: Copied! <pre># Fa\u00e7a aqui os ajustes que forem necess\u00e1rios.....\n</pre> # Fa\u00e7a aqui os ajustes que forem necess\u00e1rios.....           <p>O m\u00e9todo detectMultiScale() realiza o processo de varredura que vimos no gif acima e retorna uma lista com as faces encontrardas.</p> <p>Este possui 3 parametros principais;</p> <pre><code>gray image \u2013 Imagem de entrada na escala de cinza.\nscaleFactor \u2013 Parametro para ajustar a escala, em uma imagem pode conter rostos maiores e menores. Esse parametro tenta corrigir isso.\nminNeighbors \u2013 Este par\u00e2metro especifica o n\u00famero de vizinhos que uma janela deve ter para ser chamado de face.</code></pre> <p>Voc\u00ea pode ler mais sobre isso aqui. https://docs.opencv.org/2.4.13.2/modules/objdetect/doc/cascade_classification.html#cv2.CascadeClassifier.detectMultiScale</p> In\u00a0[3]: Copied! <pre>img = cv2.imread('lena.png')\nimg_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n\n# O m\u00e9todo detectMultiScale() realiza o processo de varredura que vimos no gif acima e retorna uma lista com as faces encontrardas.\n\nfaces_return = face.detectMultiScale(img_gray, scaleFactor = 1.2, minNeighbors = 5)\n\n\nprint('Faces encontradas: ', len(faces_return),type(faces_return), faces_return)\nprint(\"\")\nprint(\"x:\", faces_return[0][0])\nprint(\"y:\", faces_return[0][0])\nprint(\"x e y, representam a coodenada top esquerda da face detectada\")\nprint(\"\")\nprint(\"Largura :\", faces_return[0][0])\nprint(\"Altura:\", faces_return[0][0])\n</pre> img = cv2.imread('lena.png') img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)  # O m\u00e9todo detectMultiScale() realiza o processo de varredura que vimos no gif acima e retorna uma lista com as faces encontrardas.  faces_return = face.detectMultiScale(img_gray, scaleFactor = 1.2, minNeighbors = 5)   print('Faces encontradas: ', len(faces_return),type(faces_return), faces_return) print(\"\") print(\"x:\", faces_return[0][0]) print(\"y:\", faces_return[0][0]) print(\"x e y, representam a coodenada top esquerda da face detectada\") print(\"\") print(\"Largura :\", faces_return[0][0]) print(\"Altura:\", faces_return[0][0]) <pre>Faces encontradas:  1 &lt;class 'numpy.ndarray'&gt; [[224 210 156 156]]\n\nx: 224\ny: 224\nx e y, representam a coodenada top esquerda da face detectada\n\nLargura : 224\nAltura: 224\n</pre> In\u00a0[4]: Copied! <pre>## Dica r\u00e1pida de python\n\n#Podemos iterar varias listas ao mesmo tempo dentro de um unico *for* de forma simultanea usando o python\n\n# Exemplo, vamos criar uma lista qualquer\n\na = np.array([[\"x\", \"y\", \"largura\", \"altura\"]])\n\nprint (a)\nfor (x,y,w,h) in a:\n    print(\"posi\u00e7\u00e3o (x,y): \", x,y, \"largura: \", w, \"altura\",h)\n</pre> ## Dica r\u00e1pida de python  #Podemos iterar varias listas ao mesmo tempo dentro de um unico *for* de forma simultanea usando o python  # Exemplo, vamos criar uma lista qualquer  a = np.array([[\"x\", \"y\", \"largura\", \"altura\"]])  print (a) for (x,y,w,h) in a:     print(\"posi\u00e7\u00e3o (x,y): \", x,y, \"largura: \", w, \"altura\",h)  <pre>[['x' 'y' 'largura' 'altura']]\nposi\u00e7\u00e3o (x,y):  x y largura:  largura altura altura\n</pre> In\u00a0[5]: Copied! <pre>    # Implemente sua solu\u00e7\u00e3o aqui.....\n</pre>     # Implemente sua solu\u00e7\u00e3o aqui.....           In\u00a0[\u00a0]: Copied! <pre>    # Implemente sua solu\u00e7\u00e3o aqui.....\n</pre>     # Implemente sua solu\u00e7\u00e3o aqui.....     In\u00a0[\u00a0]: Copied! <pre># implemente aqui sua sulu\u00e7\u00e3o.............\n</pre> # implemente aqui sua sulu\u00e7\u00e3o............."},{"location":"aulas/PDI/lab14/haarCascade.html#implementacao-na-opencv","title":"Implementa\u00e7\u00e3o na OpenCV\u00b6","text":"<p>Vamos implementar um detector de face baseado em haar cascade, como essa t\u00e9cnica \u00e9 baseada em machine learning, vamos utilizar uma rede com os pesos do classificador treinado e dispoiniblizado pela OpenCV.</p> <p>J\u00e1 temos esses arquivos com os pesos das redes quando instalamos a OpenCV, o que temos que fazer \u00e9 carregar esses pesos.</p>"},{"location":"aulas/PDI/lab14/haarCascade.html#desafio-1","title":"Desafio 1\u00b6","text":""},{"location":"aulas/PDI/lab14/haarCascade.html#se-nao-estiver-usando-o-google-coclab","title":"<code>Se n\u00e3o estiver usando o google coclab</code>\u00b6","text":"<p>Pode acontecer de n\u00e3o encontrar o caminho do diretorio com os pesos. Como suget\u00e3o, verifique se ja possui os arquivos de pesos. Caso n\u00e3o encontre, ser\u00e1 necess\u00e1rio fazer o download desses pesos. Para facilitar a vida, na pasta cascade j\u00e1 est\u00e3o os pesos note que s\u00e3o varios arquivos. Fa\u00e7a os ajustes necess\u00e1rios para carregar os pesos da rede.</p> <p>vamos usar o \"haarcascade_frontalface_default.xml\".</p>"},{"location":"aulas/PDI/lab14/haarCascade.html#desafio-2","title":"Desafio 2\u00b6","text":"<p>Usando as posi\u00e7\u00f5es da lista <code>face_return</code>. Implemente uma fun\u00e7\u00e3o que desenha um um retangulo sobre a face detectada.</p>"},{"location":"aulas/PDI/lab14/haarCascade.html#desafio-3","title":"Desafio 3\u00b6","text":"<p>Vamos aproveitar que temos as coodenadas da face e vamos lembrar como faz um crop (recorte ) desta imagem.</p>"},{"location":"aulas/PDI/lab14/haarCascade.html#desafio-4","title":"Desafio 4\u00b6","text":"<p><code>Fa\u00e7a a dete\u00e7\u00e3o dos olhos</code> da Lena, carrege os pesos que correspodem a detec\u00e7\u00e3o de olhos e implemente sua solu\u00e7\u00e3o.</p> <p>Escolha um modelo haarcascade coerente para realizar essa tarefa.</p> <p>Dica: Os olhos fazem parte da face, nesse sentido, n\u00e3o \u00e9 necess\u00e1rio fazer a varredura em toda a imagem, basta fazer a varredura dentro dos limites onde est\u00e1 contida a face, concorda???</p>"},{"location":"aulas/PDI/lab14/haarCascade.html#desafio-5","title":"Desafio 5\u00b6","text":"<p>No inicio da aula falamos que o m\u00e9todo de Viola-Jones foi desruptivo por que tornou capaz a detec\u00e7\u00e3o de faces em tempo real. Implemente um c\u00f3digo .py que realiza a dete\u00e7\u00e3o em tempo real, capturando a imagem da sua webcam.</p>"},{"location":"aulas/PDI/lab15/EventMouse.html","title":"Lab15 - Event Mouse","text":"<p>Objetivos da aula:</p> <ul> <li>apresentar e aplicar o Event click do mouse</li> </ul> <p>QUAL O PROBLEMA?</p> <p>N\u00e3o \u00e9 bem um problema mas pode ser util em alguns casos saber interagir na imagem com o mouse para fazer um recorte da imaem, saber o RGB de um pixel ou encontrar um angulo entre retas. Sabemos fazer isso sem mouser, mas gastamos um tempinho para fazer todos os ajustes...</p> <p>Visualmente \u00e9 simples essa tarefa, basta clicar com o mouse na regi\u00e3o escolhida e pronto!.</p> In\u00a0[\u00a0]: Copied! <pre>## vou fazer o download das imagens do reposit\u00f3rio para usar no colab mais facil....\n\n!wget https://raw.githubusercontent.com/arnaldojr/cognitivecomputing/master/material/aulas/PDI/lab15/admiravelmundonovo.jpg /content\n!wget https://raw.githubusercontent.com/arnaldojr/cognitivecomputing/master/material/aulas/PDI/lab15/transferidor.jpg /content\n</pre> ## vou fazer o download das imagens do reposit\u00f3rio para usar no colab mais facil....  !wget https://raw.githubusercontent.com/arnaldojr/cognitivecomputing/master/material/aulas/PDI/lab15/admiravelmundonovo.jpg /content !wget https://raw.githubusercontent.com/arnaldojr/cognitivecomputing/master/material/aulas/PDI/lab15/transferidor.jpg /content In\u00a0[1]: Copied! <pre>import cv2\nimport numpy as np\n \n# \n# cria uma matriz (imagem) de 480x640 com 3 canais (r,g,b), img toda preta com maximos de 0-255\nimg = np.zeros((480, 640, 3), dtype=\"uint8\")\n  \n# exibe a img\ncv2.imshow('image', img)\n\n# \u00e9 uma fun\u00e7\u00e3o de callback para tratativa de eventos do mouse\ndef mouse_click(event, x, y, flags, param):\n    \n    # se foi click do botao direito \n    if event == cv2.EVENT_RBUTTONDOWN:\n        # fa\u00e7a a fun\u00e7\u00e3o.... \n        pass\n    if event == cv2.EVENT_LBUTTONDOWN:\n        # fa\u00e7a a fun\u00e7\u00e3o.... \n        pass\n\n\n\n\n\n#  configura o evento do mouse e chama a fun\u00e7\u00e3o mouse_click\ncv2.setMouseCallback('image', mouse_click)\n   \ncv2.waitKey(0)\n  \n# \ncv2.destroyAllWindows()\n</pre> import cv2 import numpy as np   #  # cria uma matriz (imagem) de 480x640 com 3 canais (r,g,b), img toda preta com maximos de 0-255 img = np.zeros((480, 640, 3), dtype=\"uint8\")    # exibe a img cv2.imshow('image', img)  # \u00e9 uma fun\u00e7\u00e3o de callback para tratativa de eventos do mouse def mouse_click(event, x, y, flags, param):          # se foi click do botao direito      if event == cv2.EVENT_RBUTTONDOWN:         # fa\u00e7a a fun\u00e7\u00e3o....          pass     if event == cv2.EVENT_LBUTTONDOWN:         # fa\u00e7a a fun\u00e7\u00e3o....          pass      #  configura o evento do mouse e chama a fun\u00e7\u00e3o mouse_click cv2.setMouseCallback('image', mouse_click)     cv2.waitKey(0)    #  cv2.destroyAllWindows() <pre>2024-04-01 11:53:22.997 Python[30860:5062868] WARNING: Secure coding is automatically enabled for restorable state! However, not on all supported macOS versions of this application. Opt-in to secure coding explicitly by implementing NSApplicationDelegate.applicationSupportsSecureRestorableState:.\n</pre> <p>O c\u00f3digo acima cria uma imagem preta e fica aguardando um evento do mouse. O mouse pode gerar alguns tipos de eventos, mas quais s\u00e3o eles???</p> In\u00a0[2]: Copied! <pre># Dica python como usar um list comprehensions no python e a fun\u00e7\u00e3o built-in dir()\n\nimport cv2\nimport numpy as np\n\n# A fun\u00e7\u00e3o dir() devolte todas propriedades e m\u00e9todos de um objeto especifico\n#print(len(dir(cv2)))\n#print (dir(cv2))\n\n\n# Vamos varrer o objeto cv2 e filtrar apenas os m\u00e9todos que tem rela\u00e7\u00e3o com EVENT\neventos = []\nfor i in dir(cv2):\n    if 'EVENT' in i:\n        eventos.append(i)\nprint(eventos)\nprint(len(eventos))\n\n# Usando List comprehension\n# Devolve uma lista na variavel events filtando os dados de outra lista\n\n#events = [i for i in dir(cv2) if 'EVENT' in i]\n#print( events )\n</pre> # Dica python como usar um list comprehensions no python e a fun\u00e7\u00e3o built-in dir()  import cv2 import numpy as np  # A fun\u00e7\u00e3o dir() devolte todas propriedades e m\u00e9todos de um objeto especifico #print(len(dir(cv2))) #print (dir(cv2))   # Vamos varrer o objeto cv2 e filtrar apenas os m\u00e9todos que tem rela\u00e7\u00e3o com EVENT eventos = [] for i in dir(cv2):     if 'EVENT' in i:         eventos.append(i) print(eventos) print(len(eventos))  # Usando List comprehension # Devolve uma lista na variavel events filtando os dados de outra lista  #events = [i for i in dir(cv2) if 'EVENT' in i] #print( events )    <pre>['EVENT_FLAG_ALTKEY', 'EVENT_FLAG_CTRLKEY', 'EVENT_FLAG_LBUTTON', 'EVENT_FLAG_MBUTTON', 'EVENT_FLAG_RBUTTON', 'EVENT_FLAG_SHIFTKEY', 'EVENT_LBUTTONDBLCLK', 'EVENT_LBUTTONDOWN', 'EVENT_LBUTTONUP', 'EVENT_MBUTTONDBLCLK', 'EVENT_MBUTTONDOWN', 'EVENT_MBUTTONUP', 'EVENT_MOUSEHWHEEL', 'EVENT_MOUSEMOVE', 'EVENT_MOUSEWHEEL', 'EVENT_RBUTTONDBLCLK', 'EVENT_RBUTTONDOWN', 'EVENT_RBUTTONUP']\n18\n</pre> <p>Basicamente s\u00e3o esses:</p> <p>Eventos:</p> <pre><code>    CV_EVENT_MOUSEMOVE: movimento do mouse\n\n    CV_EVENT_LBUTTONDOWN: Pressione o bot\u00e3o esquerdo do mouse\n    CV_EVENT_RBUTTONDOWN: Pressione o bot\u00e3o direito do mouse\n    CV_EVENT_MBUTTONDOWN: Pressione o bot\u00e3o do meio do mouse\n\n    CV_EVENT_LBUTTONUP: solte o bot\u00e3o esquerdo\n    CV_EVENT_RBUTTONUP: solte o bot\u00e3o direito \n    CV_EVENT_MBUTTONUP: Solte o bot\u00e3o do meio\n\n    CV_EVENT_LBUTTONDBLCLK: clique duplo esquerdo\n    CV_EVENT_RBUTTONDBLCLK: Clique duplo direito \n    CV_EVENT_MBUTTONDBLCLK: clique duplo do bot\u00e3o do meio\n    \n    CV_EVENT_MOUSEWHEEL: Mova o mouse para frente (+) ou para tr\u00e1s (-)\n    CV_EVENT_MOUSEHWHEEL: Mova o mouse para a direita (+) ou esquerda (-)\n    </code></pre> <p>Flags:</p> <pre><code>    CV_EVENT_FLAG_LBUTTON: Clique com o bot\u00e3o esquerdo e arraste\n    CV_EVENT_FLAG_RBUTTON: Clique com o bot\u00e3o direito e arraste\n    CV_EVENT_FLAG_MBUTTON: bot\u00e3o do meio arrastar\n    \n    CV_EVENT_FLAG_CTRLKEY: Pressione e segure Ctrl\n    CV_EVENT_FLAG_SHIFTKEY: shift pressione e segure\n    CV_EVENT_FLAG_ALTKEY: pressione e segure alt</code></pre> In\u00a0[4]: Copied! <pre>import cv2\nimport numpy as np\n \n# Carrega uma imagem\n# Neste caso estamos criando uma imagem RGB preta de tamanho 480x640\nimg = np.zeros((480, 640, 3), dtype=\"uint8\")\n  \n# Exibe a imagem\ncv2.imshow('image', img)\n\n# Fun\u00e7\u00e3o de callback, quando ocorre um evento do mouse, essa fun\u00e7\u00e3o \u00e9 chamada\ndef mouse_click(event, x, y, flags, param):\n    global img\n    # Se foi o bot\u00e3o esquerdo do mouse  \n\n\n    # Se foi o bot\u00e3o direito do mouse  \n    if event == cv2.EVENT_RBUTTONDOWN:\n        \n        # ---------- implemente a solu\u00e7\u00e3o... \n        img[:,:] = [255,0,0]\n\n        cv2.imshow('image', img)\n    # Se foi o bot\u00e3o direito do mouse  \n\n    if event == cv2.EVENT_LBUTTONDBLCLK:\n        \n        # ---------- implemente a solu\u00e7\u00e3o... \n        img[:,:] = [0,0,255]\n\n        cv2.imshow('image', img)\n\n\n\n# Seta a fun\u00e7\u00e3o de callback que ser\u00e1 chamada \n# Evento 'image', fun\u00e7\u00e3o callback mouse_click  \ncv2.setMouseCallback('image', mouse_click)\n   \ncv2.waitKey(0)\n  \n# fecha a janela.\ncv2.destroyAllWindows()\n</pre> import cv2 import numpy as np   # Carrega uma imagem # Neste caso estamos criando uma imagem RGB preta de tamanho 480x640 img = np.zeros((480, 640, 3), dtype=\"uint8\")    # Exibe a imagem cv2.imshow('image', img)  # Fun\u00e7\u00e3o de callback, quando ocorre um evento do mouse, essa fun\u00e7\u00e3o \u00e9 chamada def mouse_click(event, x, y, flags, param):     global img     # Se foi o bot\u00e3o esquerdo do mouse         # Se foi o bot\u00e3o direito do mouse       if event == cv2.EVENT_RBUTTONDOWN:                  # ---------- implemente a solu\u00e7\u00e3o...          img[:,:] = [255,0,0]          cv2.imshow('image', img)     # Se foi o bot\u00e3o direito do mouse        if event == cv2.EVENT_LBUTTONDBLCLK:                  # ---------- implemente a solu\u00e7\u00e3o...          img[:,:] = [0,0,255]          cv2.imshow('image', img)    # Seta a fun\u00e7\u00e3o de callback que ser\u00e1 chamada  # Evento 'image', fun\u00e7\u00e3o callback mouse_click   cv2.setMouseCallback('image', mouse_click)     cv2.waitKey(0)    # fecha a janela. cv2.destroyAllWindows() In\u00a0[5]: Copied! <pre>import cv2\nimport numpy as np\n \n# Carrega uma imagem\nimg = cv2.imread('admiravelmundonovo.jpg')\n  \n# Exibe a imagem\ncv2.imshow('image', img)\n\n# Fun\u00e7\u00e3o de callback, quando ocorre um evento do mouse, essa fun\u00e7\u00e3o \u00e9 chamada\ndef mouse_click(event, x, y, flags, param):\n    \n    # Se foi o bot\u00e3o esquerdo do mouse  \n    if event == cv2.EVENT_LBUTTONDOWN:\n        \n        # Realiza fun\u00e7\u00e3o... \n        #blue = img[y,x,0]\n        #green = img[y,x,1]\n        #red = img[y,x,2]\n        blue, green, red = img[y,x]\n        #print (red, green, blue)\n        msg = \"R:\" + str(red) + \", G:\" + str(green) + \", B:\" +str(blue)\n        cv2.putText(img,msg,(x,y),cv2.FONT_HERSHEY_COMPLEX,1.5,(255,255,255),2)\n\n        cv2.imshow('image', img)\n\n# Seta a fun\u00e7\u00e3o de callback que ser\u00e1 chamada \n# Evento 'image', fun\u00e7\u00e3o callback mouse_click  \ncv2.setMouseCallback('image', mouse_click)\n   \ncv2.waitKey(0)\n  \n# fecha a janela.\ncv2.destroyAllWindows()\n</pre> import cv2 import numpy as np   # Carrega uma imagem img = cv2.imread('admiravelmundonovo.jpg')    # Exibe a imagem cv2.imshow('image', img)  # Fun\u00e7\u00e3o de callback, quando ocorre um evento do mouse, essa fun\u00e7\u00e3o \u00e9 chamada def mouse_click(event, x, y, flags, param):          # Se foi o bot\u00e3o esquerdo do mouse       if event == cv2.EVENT_LBUTTONDOWN:                  # Realiza fun\u00e7\u00e3o...          #blue = img[y,x,0]         #green = img[y,x,1]         #red = img[y,x,2]         blue, green, red = img[y,x]         #print (red, green, blue)         msg = \"R:\" + str(red) + \", G:\" + str(green) + \", B:\" +str(blue)         cv2.putText(img,msg,(x,y),cv2.FONT_HERSHEY_COMPLEX,1.5,(255,255,255),2)          cv2.imshow('image', img)  # Seta a fun\u00e7\u00e3o de callback que ser\u00e1 chamada  # Evento 'image', fun\u00e7\u00e3o callback mouse_click   cv2.setMouseCallback('image', mouse_click)     cv2.waitKey(0)    # fecha a janela. cv2.destroyAllWindows() In\u00a0[1]: Copied! <pre># Implemente a solu\u00e7\u00e3o aqui.....\n</pre> # Implemente a solu\u00e7\u00e3o aqui.....     In\u00a0[6]: Copied! <pre>import cv2\nimport numpy as np\n \n# Carrega uma imagem\n# Neste caso estamos criando uma imagem RGB preta de tamanho 480x640\nimg = np.zeros((480, 640, 3), dtype=\"uint8\")\n  \n# Exibe a imagem\ncv2.imshow('image', img)\n\n# Fun\u00e7\u00e3o de callback, quando ocorre um evento do mouse, essa fun\u00e7\u00e3o \u00e9 chamada\ndef mouse_click(event, x, y, flags, param):\n    \n    # Se foi movimento do mouse   \n    if event == cv2.EVENT_MOUSEMOVE:\n        \n        # Realiza fun\u00e7\u00e3o... \n        \n        cv2.circle(img, (x,y), 20,(0,255,0), -1)\n        cv2.imshow('image', img)\n\n\n# Seta a fun\u00e7\u00e3o de callback que ser\u00e1 chamada \n# Evento 'image', fun\u00e7\u00e3o callback mouse_click  \ncv2.setMouseCallback('image', mouse_click)\n   \ncv2.waitKey(0)\n  \n# fecha a janela.\ncv2.destroyAllWindows()\n</pre> import cv2 import numpy as np   # Carrega uma imagem # Neste caso estamos criando uma imagem RGB preta de tamanho 480x640 img = np.zeros((480, 640, 3), dtype=\"uint8\")    # Exibe a imagem cv2.imshow('image', img)  # Fun\u00e7\u00e3o de callback, quando ocorre um evento do mouse, essa fun\u00e7\u00e3o \u00e9 chamada def mouse_click(event, x, y, flags, param):          # Se foi movimento do mouse        if event == cv2.EVENT_MOUSEMOVE:                  # Realiza fun\u00e7\u00e3o...                   cv2.circle(img, (x,y), 20,(0,255,0), -1)         cv2.imshow('image', img)   # Seta a fun\u00e7\u00e3o de callback que ser\u00e1 chamada  # Evento 'image', fun\u00e7\u00e3o callback mouse_click   cv2.setMouseCallback('image', mouse_click)     cv2.waitKey(0)    # fecha a janela. cv2.destroyAllWindows() In\u00a0[\u00a0]: Copied! <pre># Implemente a solu\u00e7\u00e3o aqui.....\n</pre> # Implemente a solu\u00e7\u00e3o aqui.....        <p>Muito legal mas... pouco util at\u00e9 o momento. Vamos desenvolver aplica\u00e7\u00f5es mais interessantes.</p> In\u00a0[7]: Copied! <pre>import cv2\nimport numpy as np\n \n# Carrega uma imagem\n# Neste caso estamos criando uma imagem RGB preta de tamanho 480x640\nimg = np.zeros((480, 640, 3), dtype=\"uint8\")\n  \n# Exibe a imagem\ncv2.imshow('image', img)\n\n# Cria duas variaveis globais\nclicks = 0      # conta a quantidade de clicks dada\ncoordinates = [] # salva as coordenadas de cada click\n\n\n# Fun\u00e7\u00e3o de callback, quando ocorre um evento do mouse, essa fun\u00e7\u00e3o \u00e9 chamada\ndef mouse_click(event, x, y, flags, param):\n    global clicks, coordinates, image\n    # Se foi movimento do mouse  \n\n    if clicks &lt; 2:\n        if event == cv2.EVENT_LBUTTONDBLCLK:\n            clicks += 1        \n            coordinates.append([x, y])\n            cv2.circle(img, (x,y), 2,(0,255,0), -1)\n            cv2.imshow('image', img)\n            print(clicks, coordinates)\n\n    # Se foi o bot\u00e3o esquerdo do mouse  \n    else:\n        if event == cv2.EVENT_RBUTTONDOWN:\n            img[:,:,] = 0\n            img[:,:,1] = 0\n            img[:,:,2] = 0\n            clicks = 0\n            coordinates = []\n            cv2.imshow('image', img)\n        else:\n            start_point = tuple(coordinates[0]) \n            end_point = tuple(coordinates[1])\n            print(start_point,end_point)\n            cv2.line(img, start_point, end_point, (0,255,0), 2)\n            cv2.imshow('image', img)\n\n\n# Seta a fun\u00e7\u00e3o de callback que ser\u00e1 chamada \n# Evento 'image', fun\u00e7\u00e3o callback mouse_click  \ncv2.setMouseCallback('image', mouse_click)\n   \ncv2.waitKey(0)\n  \n# fecha a janela.\ncv2.destroyAllWindows()\n</pre> import cv2 import numpy as np   # Carrega uma imagem # Neste caso estamos criando uma imagem RGB preta de tamanho 480x640 img = np.zeros((480, 640, 3), dtype=\"uint8\")    # Exibe a imagem cv2.imshow('image', img)  # Cria duas variaveis globais clicks = 0      # conta a quantidade de clicks dada coordinates = [] # salva as coordenadas de cada click   # Fun\u00e7\u00e3o de callback, quando ocorre um evento do mouse, essa fun\u00e7\u00e3o \u00e9 chamada def mouse_click(event, x, y, flags, param):     global clicks, coordinates, image     # Se foi movimento do mouse        if clicks &lt; 2:         if event == cv2.EVENT_LBUTTONDBLCLK:             clicks += 1                     coordinates.append([x, y])             cv2.circle(img, (x,y), 2,(0,255,0), -1)             cv2.imshow('image', img)             print(clicks, coordinates)      # Se foi o bot\u00e3o esquerdo do mouse       else:         if event == cv2.EVENT_RBUTTONDOWN:             img[:,:,] = 0             img[:,:,1] = 0             img[:,:,2] = 0             clicks = 0             coordinates = []             cv2.imshow('image', img)         else:             start_point = tuple(coordinates[0])              end_point = tuple(coordinates[1])             print(start_point,end_point)             cv2.line(img, start_point, end_point, (0,255,0), 2)             cv2.imshow('image', img)   # Seta a fun\u00e7\u00e3o de callback que ser\u00e1 chamada  # Evento 'image', fun\u00e7\u00e3o callback mouse_click   cv2.setMouseCallback('image', mouse_click)     cv2.waitKey(0)    # fecha a janela. cv2.destroyAllWindows() In\u00a0[\u00a0]: Copied! <pre># implemente sua solu\u00e7\u00e3o aqui...........\n</pre> # implemente sua solu\u00e7\u00e3o aqui...........                In\u00a0[8]: Copied! <pre>import cv2\nimport numpy as np\n \n# Carrega uma imagem\n# Neste caso estamos criando uma imagem RGB preta de tamanho 480x640\nimg = np.zeros((480, 640, 3), dtype=\"uint8\")\n  \n# Exibe a imagem\ncv2.imshow('image', img)\n\npoints = []\n\n# Fun\u00e7\u00e3o de callback, quando ocorre um evento do mouse, essa fun\u00e7\u00e3o \u00e9 chamada\ndef mouse_click(event, x, y, flags, param): \n    global points\n\n    if event == cv2.EVENT_LBUTTONDOWN:\n        points = [(x, y)]\n\n    elif event == cv2.EVENT_LBUTTONUP:\n        points.append((x, y))\n        p1 = tuple(points[0]) \n        p2 = tuple(points[1])\n\n        cv2.rectangle(img, p1 , p2, (0, 255, 0), 3)\n        cv2.imshow('image', img)\n\n# Seta a fun\u00e7\u00e3o de callback que ser\u00e1 chamada \n# Evento 'image', fun\u00e7\u00e3o callback mouse_click  \ncv2.setMouseCallback('image', mouse_click)\n   \ncv2.waitKey(0)\n  \n# fecha a janela.\ncv2.destroyAllWindows()\n</pre> import cv2 import numpy as np   # Carrega uma imagem # Neste caso estamos criando uma imagem RGB preta de tamanho 480x640 img = np.zeros((480, 640, 3), dtype=\"uint8\")    # Exibe a imagem cv2.imshow('image', img)  points = []  # Fun\u00e7\u00e3o de callback, quando ocorre um evento do mouse, essa fun\u00e7\u00e3o \u00e9 chamada def mouse_click(event, x, y, flags, param):      global points      if event == cv2.EVENT_LBUTTONDOWN:         points = [(x, y)]      elif event == cv2.EVENT_LBUTTONUP:         points.append((x, y))         p1 = tuple(points[0])          p2 = tuple(points[1])          cv2.rectangle(img, p1 , p2, (0, 255, 0), 3)         cv2.imshow('image', img)  # Seta a fun\u00e7\u00e3o de callback que ser\u00e1 chamada  # Evento 'image', fun\u00e7\u00e3o callback mouse_click   cv2.setMouseCallback('image', mouse_click)     cv2.waitKey(0)    # fecha a janela. cv2.destroyAllWindows() <pre>2024-04-01 11:56:24.318 Python[30860:5062868] Warning: Window move completed without beginning\n</pre> In\u00a0[6]: Copied! <pre># Implemente sua resposta.......\n</pre> # Implemente sua resposta......."},{"location":"aulas/PDI/lab15/EventMouse.html#event-mouse","title":"Event Mouse\u00b6","text":"<p>Podemos criar uma interface gr\u00e1fica e interatividade com o mouse, nesse caso, baseado em eventos.</p> <p>Toda a vez que ocorre um evento do mouse, uma fun\u00e7\u00e3o de callback \u00e9 executada no c\u00f3digo.</p> <p>Vamos ver isso funcionado no c\u00f3digo.</p> <p>Lembrete: No notebook pode travar, \u00e9 melhor rodar em um arquivo .py</p>"},{"location":"aulas/PDI/lab15/EventMouse.html#desafio-1","title":"Desafio 1\u00b6","text":"<p>O nosso c\u00f3digo est\u00e1 funcionando mas, note que n\u00e3o mandamos realizar nenhum a\u00e7\u00e3o na chamada do callback.</p> <p>Implemente um c\u00f3digo que troca a cor da imagem a cada click.</p>"},{"location":"aulas/PDI/lab15/EventMouse.html#projeto-1","title":"Projeto 1\u00b6","text":"<p>Vamos criar o nosso proprio color picker.</p> <p>Ao clicar sobre a imagem, aparece a intensidade do pixel em RGB.</p>"},{"location":"aulas/PDI/lab15/EventMouse.html#desafio-2","title":"Desafio 2\u00b6","text":"<p>Vamos melhorar um pouco esse color picker...</p> <p>Fa\u00e7a um script que ao clicar sobre a imagem, aparece a intensidade do pixel em RGB e abre uma nova janela (100x100) com essa cor.</p>"},{"location":"aulas/PDI/lab15/EventMouse.html#projeto-2","title":"Projeto 2\u00b6","text":"<p>Vamos implementar um c\u00f3digo que desenha um circulo na imagem conforme o mouse anda pela tela. (tipo Paint-Brush)</p>"},{"location":"aulas/PDI/lab15/EventMouse.html#desafio-3","title":"Desafio 3\u00b6","text":"<p>Ficou legal, mas ainda esta bem \"zoado\"...</p> <p>Melhore este c\u00f3digo, altere o c\u00f3digo para desenhar um circulo na imagem se o bot\u00e3o esquerdo estiver pressionado, quando solta o bot\u00e3o para de desenhar.</p> <p>Implemente tambem a fun\u00e7\u00e3o que limpa a tela quando o bot\u00e3o direto \u00e9 pressionado.</p>"},{"location":"aulas/PDI/lab15/EventMouse.html#projeto-3","title":"Projeto 3\u00b6","text":"<p>Vamos fazer um c\u00f3digo que marca dois pontos na tela com o bot\u00e3o esquerdo e tra\u00e7a uma reta. Quando clica com o direito zera.</p>"},{"location":"aulas/PDI/lab15/EventMouse.html#desafio-4","title":"Desafio 4\u00b6","text":"<p>A logica implementada acima n\u00e3o foi a mais otimizada... mas com base nele (ou n\u00e3o), fa\u00e7a um programa que calcula o angulo entre quais 3 pontos. O resultado deve ser exibido no tela.</p> <p>Dicas:</p> <pre><code>cv2.putText() para escrever na tela. \n\ncalculo do angulo: Se n\u00e3o lembra de trigonometria, n\u00e3o tem problema! Da um google de como calcular o angulo entre 2 linhas ou entre 3 pontos. por exemplo: https://manivannan-ai.medium.com/find-the-angle-between-three-points-from-2d-using-python-348c513e2cd</code></pre>"},{"location":"aulas/PDI/lab15/EventMouse.html#projeto-4","title":"Projeto 4\u00b6","text":"<p>A sele\u00e7\u00e3o de um regi\u00e3o de interesse nada mais \u00e9 que a determina\u00e7\u00e3o de das coordenadas iniciais e finais do boundbox.</p>"},{"location":"aulas/PDI/lab15/EventMouse.html#desafio-5","title":"Desafio 5\u00b6","text":"<p>Fa\u00e7a um script que o usuario define uma area de sele\u00e7\u00e3o. essa imagem \u00e9 aberta em uma nova janela e se for pressionado a tecla \"s\" salva a imagem no diretorio.</p> <p>Dicas:</p> <pre><code>cv2.imwrite() para salvar.\n\nif key == ord('s') : dar uma lida na fun\u00e7\u00e3o cv2.waiKey() e ord().  </code></pre>"},{"location":"aulas/PDI/lab16/dlib2.html","title":"Lab16 - Detector dlib","text":"<p>Objetivos da aula:</p> <ul> <li>apresentar e aplicar o dlib para detec\u00e7\u00e3o de face</li> </ul> <p>N\u00e3o se vive vive apenas de HAAR CASCADE</p> <p>Muito obrigado Viola e Jones! Se n\u00e3o fosse por voc\u00eas n\u00e3o teriamos hoje outras bibliotecas t\u00e3o incriveis para detec\u00e7\u00e3o de face quanto Haar Cascade.</p> <p>Atualmente temos dispon\u00edveis para uso outras diversas redes j\u00e1 treinadas para detec\u00e7\u00e3o n\u00e3o apenas de face mas tambem de m\u00e3os, corpo, objetos.....</p> <p>Vou destacar algumas redes:</p> <p>Dlib C++</p> <p>MTCNN</p> <p>Media Pipe</p> <p>Cada uma das redes acima aplica usam t\u00e9cnicas de machine learning na etapa de treinamento para realizar a detec\u00e7\u00e3o essas redes dentre outras coisas conseguem realizar a dete\u00e7\u00e3o de face. Hoje vamos da destaque especial para a rede Dlid. Como sugest\u00e3o leia a documeta\u00e7\u00e3o e aprenda a usar as rede MTCNN e Media Pipe para descobrir qual \u00e9 mais r\u00e1pida, mais leve ou mais acurada.</p> In\u00a0[2]: Copied! <pre>## Vou fazer o download das imagens do laborat\u00f3rio diretamente do reposit\u00f3rio para usar no colab mais facil....\nimport requests\n\n# Definie o modulo e o laborat\u00f3rio\nmodulo ='PDI/'\nlaboratorio = 'lab16'\n\n# URL da API do GitHub para a pasta do reposit\u00f3rio\napi_url = \"https://api.github.com/repos/arnaldojr/cognitivecomputing/contents/material/aulas/\"\n\n# Monta a URL completa\nurl_completa = api_url + modulo + laboratorio\n\nprint(f\"Fazendo o download de: {url_completa}\")\n\n# Requisi\u00e7\u00e3o para obter a lista de arquivos na pasta\nresponse = requests.get(url_completa)\nfiles = response.json()\n\n# Fazer o download de cada arquivo de imagem\nfor file in files:\n    file_name = file['name']\n    if file_name.endswith(('.png', '.jpg', '.jpeg', '.mp4')):  # Adicione mais extens\u00f5es se necess\u00e1rio\n        file_url = file['download_url']\n        print(f\"Baixando {file_name}...\")\n        !wget -q {file_url} -P /content\n\nprint(\"Download conclu\u00eddo.\")\n\n!wget -q https://raw.githubusercontent.com/arnaldojr/cognitivecomputing/master/material/aulas/PDI/lab13/admiravelmundonovo.mp4 /content\n</pre> ## Vou fazer o download das imagens do laborat\u00f3rio diretamente do reposit\u00f3rio para usar no colab mais facil.... import requests  # Definie o modulo e o laborat\u00f3rio modulo ='PDI/' laboratorio = 'lab16'  # URL da API do GitHub para a pasta do reposit\u00f3rio api_url = \"https://api.github.com/repos/arnaldojr/cognitivecomputing/contents/material/aulas/\"  # Monta a URL completa url_completa = api_url + modulo + laboratorio  print(f\"Fazendo o download de: {url_completa}\")  # Requisi\u00e7\u00e3o para obter a lista de arquivos na pasta response = requests.get(url_completa) files = response.json()  # Fazer o download de cada arquivo de imagem for file in files:     file_name = file['name']     if file_name.endswith(('.png', '.jpg', '.jpeg', '.mp4')):  # Adicione mais extens\u00f5es se necess\u00e1rio         file_url = file['download_url']         print(f\"Baixando {file_name}...\")         !wget -q {file_url} -P /content  print(\"Download conclu\u00eddo.\")  !wget -q https://raw.githubusercontent.com/arnaldojr/cognitivecomputing/master/material/aulas/PDI/lab13/admiravelmundonovo.mp4 /content  <pre>Fazendo o download de: https://api.github.com/repos/arnaldojr/cognitivecomputing/contents/material/aulas/PDI/lab16\nBaixando boca.png...\nBaixando installdlib.png...\nBaixando landmark.png...\nBaixando lena.png...\nDownload conclu\u00eddo.\n</pre> In\u00a0[3]: Copied! <pre>%matplotlib inline\nimport cv2\nfrom matplotlib import pyplot as plt\n\nimport dlib\n\n# carrega uma imagem para detectar o rosto\nimg1 = cv2.imread('lena.png')\nimg1_gray = cv2.cvtColor(img1, cv2.COLOR_BGR2GRAY)\n\n# Inicializa o detector dlib\ndetector = dlib.get_frontal_face_detector()\n\n# Faz dete\u00e7\u00e3o das faces\nfaces = detector(img1_gray)\n\nprint(faces)\n\n\nfor face in faces:\n        x,y = face.left(), face.top()  # topo esquerda\n        x1,y1 = face.right(), face.bottom() #baixo direita\n\n        cv2.rectangle(img1, (x, y), (x1, y1), (0, 255, 0), 1)\n\n\n# Exibe imagem\nplt.figure(figsize = (10,10))\nplt.imshow(cv2.cvtColor(img1,cv2.COLOR_BGR2RGB)); plt.show();\n</pre> %matplotlib inline import cv2 from matplotlib import pyplot as plt  import dlib  # carrega uma imagem para detectar o rosto img1 = cv2.imread('lena.png') img1_gray = cv2.cvtColor(img1, cv2.COLOR_BGR2GRAY)  # Inicializa o detector dlib detector = dlib.get_frontal_face_detector()  # Faz dete\u00e7\u00e3o das faces faces = detector(img1_gray)  print(faces)   for face in faces:         x,y = face.left(), face.top()  # topo esquerda         x1,y1 = face.right(), face.bottom() #baixo direita          cv2.rectangle(img1, (x, y), (x1, y1), (0, 255, 0), 1)   # Exibe imagem plt.figure(figsize = (10,10)) plt.imshow(cv2.cvtColor(img1,cv2.COLOR_BGR2RGB)); plt.show();  <pre>rectangles[[(228, 228) (377, 377)]]\n</pre> In\u00a0[7]: Copied! <pre># usando o linux fica facil fazer o download...\nprint(f\"Baixando pesos da rede...\")\n\n!wget -q http://dlib.net/files/shape_predictor_68_face_landmarks.dat.bz2 /content\n!bzip2 -d shape_predictor_68_face_landmarks.dat.bz2\n\nprint(f\"Download completo.\")\n</pre> # usando o linux fica facil fazer o download... print(f\"Baixando pesos da rede...\")  !wget -q http://dlib.net/files/shape_predictor_68_face_landmarks.dat.bz2 /content !bzip2 -d shape_predictor_68_face_landmarks.dat.bz2  print(f\"Download completo.\") <pre>Baixando pesos da rede...\nbzip2: Output file shape_predictor_68_face_landmarks.dat already exists.\nDownload completo.\n</pre> In\u00a0[8]: Copied! <pre>%matplotlib inline\nimport cv2\nfrom matplotlib import pyplot as plt\n\nimport dlib\n\n# carrega uma imagem para detectar o rosto\nimg1 = cv2.imread('lena.png')\n\nimg1_gray = cv2.cvtColor(img1, cv2.COLOR_BGR2GRAY)\n\n# Inicializa o detector dlib\ndetector = dlib.get_frontal_face_detector()\n\n# Inicializa o identificador de Landmark identifier. Voc\u00ea ter esse arquiva na pasta do projeto\npredictor = dlib.shape_predictor(\"shape_predictor_68_face_landmarks.dat\")\n\n# Faz dete\u00e7\u00e3o das faces\nfaces = detector(img1_gray)\n\nprint(\"Numeros de faces detectadas: {}\".format(len(faces)))\n\n# para todas faces detectadas\nfor face in faces:\n  print(\"Left: {} Top: {} Right: {} Bottom: {}\".format(\n            face.left(), face.top(), face.right(), face.bottom()))\n  # Faz a predi\u00e7\u00e3o dos landmarks\n  shape = predictor(img1_gray, face)\n\n  # shape \u00e9 uma lista de tupla com as posi\u00e7\u00f5es (x, y) dos landmarks\n  print(\"\\nAo todo s\u00e3o: {} landmarks \\n\\nEsses s\u00e3o landmarks: {} \".format(len(shape.parts()) , shape.parts()))\n</pre> %matplotlib inline import cv2 from matplotlib import pyplot as plt  import dlib  # carrega uma imagem para detectar o rosto img1 = cv2.imread('lena.png')  img1_gray = cv2.cvtColor(img1, cv2.COLOR_BGR2GRAY)  # Inicializa o detector dlib detector = dlib.get_frontal_face_detector()  # Inicializa o identificador de Landmark identifier. Voc\u00ea ter esse arquiva na pasta do projeto predictor = dlib.shape_predictor(\"shape_predictor_68_face_landmarks.dat\")  # Faz dete\u00e7\u00e3o das faces faces = detector(img1_gray)  print(\"Numeros de faces detectadas: {}\".format(len(faces)))  # para todas faces detectadas for face in faces:   print(\"Left: {} Top: {} Right: {} Bottom: {}\".format(             face.left(), face.top(), face.right(), face.bottom()))   # Faz a predi\u00e7\u00e3o dos landmarks   shape = predictor(img1_gray, face)    # shape \u00e9 uma lista de tupla com as posi\u00e7\u00f5es (x, y) dos landmarks   print(\"\\nAo todo s\u00e3o: {} landmarks \\n\\nEsses s\u00e3o landmarks: {} \".format(len(shape.parts()) , shape.parts()))  <pre>Numeros de faces detectadas: 1\nLeft: 228 Top: 228 Right: 377 Bottom: 377\n\nAo todo s\u00e3o: 68 landmarks \n\nEsses s\u00e3o landmarks: points[(209, 268), (207, 291), (207, 315), (211, 337), (221, 357), (238, 373), (255, 385), (275, 394), (293, 395), (306, 388), (315, 373), (322, 358), (330, 343), (338, 326), (345, 311), (349, 294), (349, 279), (242, 250), (256, 244), (271, 243), (285, 247), (298, 254), (327, 257), (334, 251), (342, 248), (349, 246), (355, 250), (312, 271), (313, 287), (315, 303), (317, 319), (295, 326), (302, 328), (309, 330), (315, 329), (320, 326), (255, 267), (265, 261), (278, 262), (285, 272), (275, 275), (263, 274), (318, 273), (327, 263), (337, 262), (342, 268), (338, 275), (328, 276), (267, 350), (285, 348), (299, 345), (305, 347), (310, 345), (315, 347), (319, 349), (313, 357), (308, 362), (302, 364), (295, 364), (282, 360), (273, 352), (297, 352), (304, 353), (309, 352), (315, 351), (309, 351), (304, 352), (297, 352)] \n</pre> In\u00a0[9]: Copied! <pre>%matplotlib inline\nimport cv2\nfrom matplotlib import pyplot as plt\n\nimport dlib\n\n# carrega uma imagem para detectar o rosto\nimg1 = cv2.imread('lena.png')\n\nimg1_gray = cv2.cvtColor(img1, cv2.COLOR_BGR2GRAY)\n\n# Inicializa o detector dlib\ndetector = dlib.get_frontal_face_detector()\n\n# Inicializa o identificador de Landmark identifier. Voc\u00ea ter esse arquiva na pasta do projeto\npredictor = dlib.shape_predictor(\"shape_predictor_68_face_landmarks.dat\")\n\n# Faz dete\u00e7\u00e3o das faces\nfaces = detector(img1_gray)\n\n#print(\"Numeros de faces detectadas: {}\".format(len(faces)))\n\n# para todas faces detectadas\nfor face in faces:\n  # print(\"Left: {} Top: {} Right: {} Bottom: {}\".format(\n  #           face.left(), face.top(), face.right(), face.bottom()))\n  # Faz a predi\u00e7\u00e3o dos landmarks\n  shape = predictor(img1_gray, face)\n\n  # shape \u00e9 uma lista de tupla com as posi\u00e7\u00f5es (x, y) dos landmarks\n  # da uma olhada na quantidade total e nos 3 primeiros\n  # print(len(shape.parts()) , shape.parts()[0:3])\n\n###---- varendo os landmarks e fazendo a marca\u00e7\u00e3o na imagem----###\n\n  for i in range(len(shape.parts())): #S\u00e3o 68 landmark detectados por face\n      # Desenha um circulo e exibe o indice do landmark\n      # shape.part(i).x devolve o valor x da coordenada\n#      print(\"mark: {} coordenada x: {}, coordenada y: {}\".format(i+1, shape.part(i).x, shape.part(i).y))\n\n      # desenha um circulo na coordenada do laandmark\n      cv2.circle(img1, (shape.part(i).x, shape.part(i).y), 1, (0,255,0), thickness=-1)\n\n      # Escreve o indice de cada landmark na imagem\n      cv2.putText(img1, str(i+1), (shape.part(i).x,shape.part(i).y), fontFace=cv2.FONT_HERSHEY_SCRIPT_SIMPLEX, fontScale=0.3, color=(0, 0, 255))\n\n\n# Exibe imagem\nplt.figure(figsize = (10,10))\nplt.imshow(cv2.cvtColor(img1,cv2.COLOR_BGR2RGB)); plt.show();\n</pre> %matplotlib inline import cv2 from matplotlib import pyplot as plt  import dlib  # carrega uma imagem para detectar o rosto img1 = cv2.imread('lena.png')  img1_gray = cv2.cvtColor(img1, cv2.COLOR_BGR2GRAY)  # Inicializa o detector dlib detector = dlib.get_frontal_face_detector()  # Inicializa o identificador de Landmark identifier. Voc\u00ea ter esse arquiva na pasta do projeto predictor = dlib.shape_predictor(\"shape_predictor_68_face_landmarks.dat\")  # Faz dete\u00e7\u00e3o das faces faces = detector(img1_gray)  #print(\"Numeros de faces detectadas: {}\".format(len(faces)))  # para todas faces detectadas for face in faces:   # print(\"Left: {} Top: {} Right: {} Bottom: {}\".format(   #           face.left(), face.top(), face.right(), face.bottom()))   # Faz a predi\u00e7\u00e3o dos landmarks   shape = predictor(img1_gray, face)    # shape \u00e9 uma lista de tupla com as posi\u00e7\u00f5es (x, y) dos landmarks   # da uma olhada na quantidade total e nos 3 primeiros   # print(len(shape.parts()) , shape.parts()[0:3])  ###---- varendo os landmarks e fazendo a marca\u00e7\u00e3o na imagem----###    for i in range(len(shape.parts())): #S\u00e3o 68 landmark detectados por face       # Desenha um circulo e exibe o indice do landmark       # shape.part(i).x devolve o valor x da coordenada #      print(\"mark: {} coordenada x: {}, coordenada y: {}\".format(i+1, shape.part(i).x, shape.part(i).y))        # desenha um circulo na coordenada do laandmark       cv2.circle(img1, (shape.part(i).x, shape.part(i).y), 1, (0,255,0), thickness=-1)        # Escreve o indice de cada landmark na imagem       cv2.putText(img1, str(i+1), (shape.part(i).x,shape.part(i).y), fontFace=cv2.FONT_HERSHEY_SCRIPT_SIMPLEX, fontScale=0.3, color=(0, 0, 255))   # Exibe imagem plt.figure(figsize = (10,10)) plt.imshow(cv2.cvtColor(img1,cv2.COLOR_BGR2RGB)); plt.show();  In\u00a0[\u00a0]: Copied! <pre>### Implemente sua solu\u00e7\u00e3o aqui...\n</pre> ### Implemente sua solu\u00e7\u00e3o aqui...      In\u00a0[\u00a0]: Copied! <pre>### Implemente sua solu\u00e7\u00e3o em um arquivo .py\n\n## n\u00e3o fa\u00e7a no colab\n## n\u00e3o fa\u00e7a no colab\n## n\u00e3o fa\u00e7a no colab\n## n\u00e3o fa\u00e7a no colab\n## n\u00e3o fa\u00e7a no colab\n</pre> ### Implemente sua solu\u00e7\u00e3o em um arquivo .py  ## n\u00e3o fa\u00e7a no colab ## n\u00e3o fa\u00e7a no colab ## n\u00e3o fa\u00e7a no colab ## n\u00e3o fa\u00e7a no colab ## n\u00e3o fa\u00e7a no colab  In\u00a0[\u00a0]: Copied! <pre>### Implemente sua solu\u00e7\u00e3o em um arquivo .py\n</pre> ### Implemente sua solu\u00e7\u00e3o em um arquivo .py   In\u00a0[\u00a0]: Copied! <pre>import cv2\nimport dlib\n\n\ndef draw_text_info():\n    \"\"\"Fun\u00e7\u00e3o para escrever na tela as instru\u00e7\u00f5es de uso\"\"\"\n\n    menu_pos = (10, 20)\n    menu_pos_2 = (10, 40)\n    menu_pos_3 = (10, 60)\n    info_1 = \"Selecione com o mouse o objeto para rastreamento\"\n    info_2 = \"Use '1' para start, '2' para reset\"\n\n    cv2.putText(frame, info_1, menu_pos, cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255))\n    cv2.putText(frame, info_2, menu_pos_2, cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255))\n    if tracking_state:\n        cv2.putText(frame, \"Rastreando...\", menu_pos_3, cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0))\n    else:\n        cv2.putText(frame, \"N\u00e3o rastreando\", menu_pos_3, cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255))\n\n\n\npoints = []\n\n\n# Fun\u00e7\u00e3o de callback do mouse\ndef mouse_click(event, x, y, flags, param):\n    global points\n\n    if event == cv2.EVENT_LBUTTONDOWN:\n        points = [(x, y)]\n\n    elif event == cv2.EVENT_LBUTTONUP:\n        points.append((x, y))\n\n\n\ncapture = cv2.VideoCapture(0)\n\n\nwindow_name = \"tracking\"\ncv2.namedWindow(window_name)\ncv2.setMouseCallback(window_name, mouse_click)\n\n# Inicializa metodo de correla\u00e7\u00e3o de rastreamento\ntracker = dlib.correlation_tracker()\n\n# Variavel de estado\ntracking_state = False\n\nwhile True:\n    ret, frame = capture.read()\n\n    draw_text_info()\n\n    # Se objeto esta selecionado\n    if len(points) == 2:\n        cv2.rectangle(frame, points[0], points[1], (0, 0, 255), 3)\n        dlib_rectangle = dlib.rectangle(points[0][0], points[0][1], points[1][0], points[1][1])\n\n    # Se \u00e9 pra rastrear\n    if tracking_state == True:\n        tracker.update(frame)\n        pos = tracker.get_position()\n        cv2.rectangle(frame, (int(pos.left()), int(pos.top())), (int(pos.right()), int(pos.bottom())), (0, 255, 0), 3)\n\n    # l\u00ea teclado\n    key = 0xFF &amp; cv2.waitKey(1)\n\n    # '1' start\n    if key == ord(\"1\"):\n        if len(points) == 2:\n            # Start tracking:\n            tracker.start_track(frame, dlib_rectangle)\n            tracking_state = True\n            points = []\n\n    # '2' reset\n    if key == ord(\"2\"):\n        points = []\n        tracking_state = False\n\n    if key == ord('q'):\n        break\n\n    cv2.imshow(window_name, frame)\n\n# Release everything:\ncapture.release()\ncv2.destroyAllWindows()\n</pre> import cv2 import dlib   def draw_text_info():     \"\"\"Fun\u00e7\u00e3o para escrever na tela as instru\u00e7\u00f5es de uso\"\"\"      menu_pos = (10, 20)     menu_pos_2 = (10, 40)     menu_pos_3 = (10, 60)     info_1 = \"Selecione com o mouse o objeto para rastreamento\"     info_2 = \"Use '1' para start, '2' para reset\"      cv2.putText(frame, info_1, menu_pos, cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255))     cv2.putText(frame, info_2, menu_pos_2, cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255))     if tracking_state:         cv2.putText(frame, \"Rastreando...\", menu_pos_3, cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0))     else:         cv2.putText(frame, \"N\u00e3o rastreando\", menu_pos_3, cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255))    points = []   # Fun\u00e7\u00e3o de callback do mouse def mouse_click(event, x, y, flags, param):     global points      if event == cv2.EVENT_LBUTTONDOWN:         points = [(x, y)]      elif event == cv2.EVENT_LBUTTONUP:         points.append((x, y))    capture = cv2.VideoCapture(0)   window_name = \"tracking\" cv2.namedWindow(window_name) cv2.setMouseCallback(window_name, mouse_click)  # Inicializa metodo de correla\u00e7\u00e3o de rastreamento tracker = dlib.correlation_tracker()  # Variavel de estado tracking_state = False  while True:     ret, frame = capture.read()      draw_text_info()      # Se objeto esta selecionado     if len(points) == 2:         cv2.rectangle(frame, points[0], points[1], (0, 0, 255), 3)         dlib_rectangle = dlib.rectangle(points[0][0], points[0][1], points[1][0], points[1][1])      # Se \u00e9 pra rastrear     if tracking_state == True:         tracker.update(frame)         pos = tracker.get_position()         cv2.rectangle(frame, (int(pos.left()), int(pos.top())), (int(pos.right()), int(pos.bottom())), (0, 255, 0), 3)      # l\u00ea teclado     key = 0xFF &amp; cv2.waitKey(1)      # '1' start     if key == ord(\"1\"):         if len(points) == 2:             # Start tracking:             tracker.start_track(frame, dlib_rectangle)             tracking_state = True             points = []      # '2' reset     if key == ord(\"2\"):         points = []         tracking_state = False      if key == ord('q'):         break      cv2.imshow(window_name, frame)  # Release everything: capture.release() cv2.destroyAllWindows() In\u00a0[\u00a0]: Copied! <pre># Implemente sua solu\u00e7\u00e3o aqui......\n</pre> # Implemente sua solu\u00e7\u00e3o aqui......    In\u00a0[\u00a0]: Copied! <pre>from math import dist\nimport time\nimport numpy as np\nimport dlib\nimport cv2\n\n# definir constantes\nEYE_AR_THRESH = 0.3\nEYE_AR_CONSEC_FRAMES = 40\nCOUNTER = 0\n\ndef eye_aspect_ratio(eye):\n    # calcula a distancia euclidiana vertical os olhos\n    # vertical eye landmarks (x, y)-coordinates\n    A = dist(eye[1], eye[5])\n    B = dist(eye[2], eye[4])\n\n    # # calcula a distancia euclidiana horizontal os olhos\n    # eye landmark (x, y)-coordinates\n    C = dist(eye[0], eye[3])\n\n    # calcula uma taxa de abertura dos olhos\n    ear = (A + B) / (2.0 * C)\n\n    # return the eye aspect ratio\n    return ear\n\n\n# inicializa o detector e preditor do dlib\ndetector = dlib.get_frontal_face_detector()\npredictor = dlib.shape_predictor(\"shape_predictor_68_face_landmarks.dat\")\n\n# pega os \u00edndices do previsor, para olhos esquerdo e direito\n(lStart, lEnd) = (42, 48)\n(rStart, rEnd) = (36, 42)\n\n# inicializar v\u00eddeo\nvs = cv2.VideoCapture(0)\n#vs = cv2.VideoCapture(\"admiravelmundonovo.mp4\")\n\n\n# loop sobre os frames do v\u00eddeo\nwhile True:\n    ret, frame = vs.read()\n    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n\n    # detectar faces (grayscale)\n    rects = detector(gray, 0)\n\n    # loop nas detec\u00e7\u00f5es de faces\n    for rect in rects:\n\n        shape = predictor(gray, rect)\n        #devolve shape em uma lista coords\n        coords = np.zeros((shape.num_parts, 2), dtype=int)\n        for i in range(0,68): #S\u00e3o 68 landmark em cada face\n            coords[i] = (shape.part(i).x, shape.part(i).y)\n\n        # extrair coordenadas dos olhos e calcular a propor\u00e7\u00e3o de abertura\n        leftEye = coords[lStart:lEnd]\n        rightEye = coords[rStart:rEnd]\n\n        leftEAR = eye_aspect_ratio(leftEye)\n        rightEAR = eye_aspect_ratio(rightEye)\n\n        # ratio m\u00e9dia para os dois olhos\n        ear = (leftEAR + rightEAR) / 2.0\n\n        # convex hull cria um contorno com base nos pontos\n        leftEyeHull = cv2.convexHull(leftEye)\n        rightEyeHull = cv2.convexHull(rightEye)\n        cv2.drawContours(frame, [leftEyeHull], -1, (0, 255, 0), 1)\n        cv2.drawContours(frame, [rightEyeHull], -1, (0, 255, 0), 1)\n\n        # checar ratio x threshold\n        if ear &lt; EYE_AR_THRESH:\n            COUNTER += 1\n\n            # dentro dos crit\u00e9rios\n            if COUNTER &gt;= EYE_AR_CONSEC_FRAMES:\n                cv2.putText(frame, \"[ALERTA] FADIGA!\", (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)\n\n        # caso acima do threshold, resetar o contador e desligar o alarme\n        else:\n            COUNTER = 0\n            # desenhar a propor\u00e7\u00e3o de abertura dos olhos\n        cv2.putText(frame, \"EAR: {:.2f}\".format(ear), (300, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)\n\n    # Exibe resultado\n    cv2.imshow(\"Frame\", frame) # se estiver rodando local\n    key = cv2.waitKey(1) &amp; 0xFF\n    # tecla para sair do script \"q\"\n    if key == ord(\"q\"):\n        break\n\n# clean\ncv2.destroyAllWindows()\nvs.release()\n</pre> from math import dist import time import numpy as np import dlib import cv2  # definir constantes EYE_AR_THRESH = 0.3 EYE_AR_CONSEC_FRAMES = 40 COUNTER = 0  def eye_aspect_ratio(eye):     # calcula a distancia euclidiana vertical os olhos     # vertical eye landmarks (x, y)-coordinates     A = dist(eye[1], eye[5])     B = dist(eye[2], eye[4])      # # calcula a distancia euclidiana horizontal os olhos     # eye landmark (x, y)-coordinates     C = dist(eye[0], eye[3])      # calcula uma taxa de abertura dos olhos     ear = (A + B) / (2.0 * C)      # return the eye aspect ratio     return ear   # inicializa o detector e preditor do dlib detector = dlib.get_frontal_face_detector() predictor = dlib.shape_predictor(\"shape_predictor_68_face_landmarks.dat\")  # pega os \u00edndices do previsor, para olhos esquerdo e direito (lStart, lEnd) = (42, 48) (rStart, rEnd) = (36, 42)  # inicializar v\u00eddeo vs = cv2.VideoCapture(0) #vs = cv2.VideoCapture(\"admiravelmundonovo.mp4\")   # loop sobre os frames do v\u00eddeo while True:     ret, frame = vs.read()     gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)      # detectar faces (grayscale)     rects = detector(gray, 0)      # loop nas detec\u00e7\u00f5es de faces     for rect in rects:          shape = predictor(gray, rect)         #devolve shape em uma lista coords         coords = np.zeros((shape.num_parts, 2), dtype=int)         for i in range(0,68): #S\u00e3o 68 landmark em cada face             coords[i] = (shape.part(i).x, shape.part(i).y)          # extrair coordenadas dos olhos e calcular a propor\u00e7\u00e3o de abertura         leftEye = coords[lStart:lEnd]         rightEye = coords[rStart:rEnd]          leftEAR = eye_aspect_ratio(leftEye)         rightEAR = eye_aspect_ratio(rightEye)          # ratio m\u00e9dia para os dois olhos         ear = (leftEAR + rightEAR) / 2.0          # convex hull cria um contorno com base nos pontos         leftEyeHull = cv2.convexHull(leftEye)         rightEyeHull = cv2.convexHull(rightEye)         cv2.drawContours(frame, [leftEyeHull], -1, (0, 255, 0), 1)         cv2.drawContours(frame, [rightEyeHull], -1, (0, 255, 0), 1)          # checar ratio x threshold         if ear &lt; EYE_AR_THRESH:             COUNTER += 1              # dentro dos crit\u00e9rios             if COUNTER &gt;= EYE_AR_CONSEC_FRAMES:                 cv2.putText(frame, \"[ALERTA] FADIGA!\", (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)          # caso acima do threshold, resetar o contador e desligar o alarme         else:             COUNTER = 0             # desenhar a propor\u00e7\u00e3o de abertura dos olhos         cv2.putText(frame, \"EAR: {:.2f}\".format(ear), (300, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)      # Exibe resultado     cv2.imshow(\"Frame\", frame) # se estiver rodando local     key = cv2.waitKey(1) &amp; 0xFF     # tecla para sair do script \"q\"     if key == ord(\"q\"):         break  # clean cv2.destroyAllWindows() vs.release() In\u00a0[\u00a0]: Copied! <pre># Implemente sua solu\u00e7\u00e3o aqui......\n</pre> # Implemente sua solu\u00e7\u00e3o aqui......"},{"location":"aulas/PDI/lab16/dlib2.html#dlib","title":"Dlib\u00b6","text":"<p>A Dlib, al\u00e9m de realizar a predi\u00e7\u00e3o para detectar uma face, ela consegue ressaltar alguns pontos da face. Esses pontos de destaque s\u00e3o chamados de landmarks, a Dlib consegue encontrar 68 pontos da face como cantos dos olhos, sobrancelhas, boca e ponta do nariz.</p> <p>Cada landmark devolve uma coordenada da posi\u00e7\u00e3o (x,y) da imagem.</p>"},{"location":"aulas/PDI/lab16/dlib2.html#instalacao-dlib","title":"Instala\u00e7\u00e3o Dlib\u00b6","text":"<p>no linux, a instala\u00e7\u00e3o \u00e9 feita com o comando:</p> <pre>pip install dlib\n    \n</pre>"},{"location":"aulas/PDI/lab16/dlib2.html#verificacao-da-instalacao","title":"Verifica\u00e7\u00e3o da instala\u00e7\u00e3o\u00b6","text":"<p>pode ser necess\u00e1rio instalar alguns pacotes extras:</p> <pre>!sudo apt-get update\n!sudo apt-get install -y build-essential cmake\n!sudo apt-get install -y libopenblas-dev liblapack-dev\n!sudo apt-get install -y libx11-dev libgtk-3-dev\n!pip install dlib\n</pre>"},{"location":"aulas/PDI/lab16/dlib2.html#para-instalar-a-biblioteca-dlib-no-windows-localmente-voce-pode-seguir-estes-passos","title":"Para instalar a biblioteca dlib no <code>Windows localmente</code>, voc\u00ea pode seguir estes passos:\u00b6","text":"<ol> <li><p>Instale o CMake: dlib requer CMake para ser compilado. Voc\u00ea pode baixar e instalar o CMake a partir do site oficial: https://cmake.org/download/. Certifique-se de adicionar o CMake ao seu <code>PATH</code> durante a instala\u00e7\u00e3o.</p> </li> <li><p>Instale o Visual Studio: dlib precisa de um compilador C++ para ser compilado no Windows. Voc\u00ea pode usar o Visual Studio Community Edition, que \u00e9 gratuito para uso pessoal. Certifique-se de incluir o desenvolvimento em C++ durante a instala\u00e7\u00e3o. Voc\u00ea pode baix\u00e1-lo aqui: https://visualstudio.microsoft.com/vs/community/.</p> </li> <li><p>Instale a dlib: Abra um prompt de comando (CMD) ou PowerShell e execute o seguinte comando para instalar a dlib:</p> </li> </ol> <pre>pip install dlib\n</pre> <p>Esse comando deve compilar e instalar a dlib. Dependendo do seu sistema, esse processo pode levar algum tempo.</p> <ol> <li>Verifique a instala\u00e7\u00e3o: Ap\u00f3s a instala\u00e7\u00e3o, voc\u00ea pode verificar se a dlib foi instalada corretamente abrindo um terminal ou prompt de comando e executando o seguinte comando Python:</li> </ol> <pre>python -c \"import dlib; print(dlib.__version__)\"\n</pre> <p>Se tudo estiver correto, esse comando deve imprimir a vers\u00e3o da dlib instalada sem gerar erros.</p>"},{"location":"aulas/PDI/lab16/dlib2.html#detecao-de-faces-com-o-dlib","title":"Dete\u00e7\u00e3o de faces com o dlib\u00b6","text":"<p>Vamos fazer o nosso \"Hello World\" usando a Dlib, neste caso, vamos implementar um detector de face simples.</p> <p>Note que o m\u00e9todo \u00e9 bem similar ao que j\u00e1 conhecemos, a lista de faces detectadas \u00e9 um pouco diferente.</p>"},{"location":"aulas/PDI/lab16/dlib2.html#deteccao-dos-landmarks-da-face","title":"Detec\u00e7\u00e3o dos landmarks da face\u00b6","text":"<p>Para predi\u00e7\u00e3o dos landmarks uma rede neural j\u00e1 treinada \u00e9 utilizada, ser\u00e3o preditos 68 pontos da face.</p> <p>Para carregar os pesos da rede \u00e9 necess\u00e1rio fazer o download em:</p> <p>hape_predictor_68_face_landmarks.dat</p>"},{"location":"aulas/PDI/lab16/dlib2.html#dlib-positions","title":"Dlib positions\u00b6","text":"<ul> <li>(\"mouth\", (48, 68)),</li> <li>(\"right_eyebrow\", (17, 22)),</li> <li>(\"left_eyebrow\", (22, 27)),</li> <li>(\"right_eye\", (36, 42)),</li> <li>(\"left_eye\", (42, 48)),</li> <li>(\"nose\", (27, 35)),</li> <li>(\"jaw\", (0, 17))</li> </ul>"},{"location":"aulas/PDI/lab16/dlib2.html#desafio-1","title":"Desafio 1\u00b6","text":"<p>Implemente um c\u00f3digo que faz o crop de uma das regi\u00f5es preditas.</p> <p>Exemplo: crop da boca, sobrancelha, olho, nariz ou boca.</p>"},{"location":"aulas/PDI/lab16/dlib2.html#desafio-2","title":"Desafio 2\u00b6","text":"<p>Fa\u00e7a um c\u00f3digo capaz de detectar em tempo real as landmarks face pela webcam.</p>"},{"location":"aulas/PDI/lab16/dlib2.html#nao-faca-no-colab","title":"N\u00e3o fa\u00e7a no colab\u00b6","text":""},{"location":"aulas/PDI/lab16/dlib2.html#desafio-extra","title":"Desafio extra\u00b6","text":"<p>Altere o aquivo de pesos da rede para rede shape_predictor_5_face_landmarks e an\u00e1lise o tempo de resposta da rede. Ficou mais r\u00e1pida a detec\u00e7\u00e3o, a mesma coisa ou mais lenta?</p>"},{"location":"aulas/PDI/lab16/dlib2.html#tracking","title":"Tracking\u00b6","text":"<p>O tracking de objetos ou de faces possui diversas aplica\u00e7\u00f5es.O rastreamento de objetos tenta estimar a trajet\u00f3ria do alvo ao longo da sequ\u00eancia de v\u00eddeo onde apenas a localiza\u00e7\u00e3o inicial de um alvo \u00e9 conhecida. Basicamente o custo computacional para realiza\u00e7\u00e3o de rastreamento de um objeto \u00e9 muito menor, o que \u00e9 cr\u00edtico em aplicativos em tempo real, comparado ao custo computacional para a detec\u00e7\u00e3o de um objeto, onde a cada frame \u00e9 realizado a detec\u00e7\u00e3o do zero.</p> <p>Uma t\u00e9cnica muito poderosa para a realiza\u00e7\u00e3o de rastreamento \u00e9 DCF (discriminative correlation filter).A biblioteca dlib implementa um rastreador baseado em DCF, que \u00e9 f\u00e1cil de usar para rastreamento de faces ou objetos.</p> <p>Artigo bacana para se aprofundar na teoria: https://arxiv.org/pdf/1611.08461.pdf</p>"},{"location":"aulas/PDI/lab16/dlib2.html#rastreamento-de-objetos","title":"Rastreamento de objetos\u00b6","text":""},{"location":"aulas/PDI/lab16/dlib2.html#desafio-4","title":"Desafio 4\u00b6","text":"<p>Com base no c\u00f3digo acima, implemente um c\u00f3digo que faz o tracking de face</p>"},{"location":"aulas/PDI/lab16/dlib2.html#detector-de-fadiga","title":"Detector de fadiga\u00b6","text":"<p>O detector de fadiga pode ser elaborado a partir a abertura dos olhos, o c\u00f3digo a baixo foi inspirado no link: Artigo de ref\u00eancia</p> <p>Al\u00e9m deste artigo, vamos utilizar algumas outras fun\u00e7\u00f5es da OpenCV que ainda n\u00e3o conhecemos.</p> <p>cv2.convexHull = Cria um contorno com base nos pontos. https://learnopencv.com/convex-hull-using-opencv-in-python-and-c/</p>"},{"location":"aulas/PDI/lab16/dlib2.html#dlib-positions","title":"Dlib positions\u00b6","text":"<ul> <li>(\"mouth\", (48, 68)),</li> <li>(\"right_eyebrow\", (17, 22)),</li> <li>(\"left_eyebrow\", (22, 27)),</li> <li>(\"right_eye\", (36, 42)),</li> <li>(\"left_eye\", (42, 48)),</li> <li>(\"nose\", (27, 35)),</li> <li>(\"jaw\", (0, 17))</li> </ul>"},{"location":"aulas/PDI/lab16/dlib2.html#desafio-5","title":"Desafio 5\u00b6","text":"<p>Inspirado na solu\u00e7\u00e3o do detector de fadiga, implemente um c\u00f3digo que faz a dete\u00e7\u00e3o de emo\u00e7\u00e3o. Ou seja, detecta se a pessoa esta sorrindo ou n\u00e3o.</p>"},{"location":"aulas/PDI/lab17/mediapipe.html","title":"Lab17 - Mediapipe","text":"In\u00a0[\u00a0]: Copied! <pre>## instala\u00e7\u00e3o via pip\n\n#!pip install mediapipe==0.10.9\n</pre> ## instala\u00e7\u00e3o via pip  #!pip install mediapipe==0.10.9 In\u00a0[11]: Copied! <pre>import mediapipe as mp\nimport cv2\nimport numpy as np\nimport matplotlib.pyplot as plt\n</pre> import mediapipe as mp import cv2 import numpy as np import matplotlib.pyplot as plt In\u00a0[17]: Copied! <pre># Configura\u00e7\u00f5es de desenho\nmp_drawing = mp.solutions.drawing_utils\nmp_drawing_styles = mp.solutions.drawing_styles\nmp_face_mesh = mp.solutions.face_mesh\n\n# Crie uma inst\u00e2ncia do objeto FaceMesh\nface_mesh = mp_face_mesh.FaceMesh(\n    static_image_mode=True,\n    max_num_faces=1,\n    refine_landmarks=True,\n    min_detection_confidence=0.5)\n\nfile = 'lena.png'\n\n# Leia o arquivo de imagem com cv2 e converta de BGR para RGB\nimage = cv2.imread(file)\nresults = face_mesh.process(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n\nface_found = results.multi_face_landmarks\nprint(f'foram encontradas: {len(face_found)} faces na imagem')\n\nif face_found:\n    # Crie uma c\u00f3pia da imagem\n    annotated_image = image.copy()\n\n    # Desenha as landmarks e conex\u00f5es\n    mp_drawing.draw_landmarks(\n        image=annotated_image,\n        landmark_list=results.multi_face_landmarks[0],\n        connections=mp_face_mesh.FACEMESH_TESSELATION,\n        landmark_drawing_spec=None,\n        connection_drawing_spec=mp_drawing_styles.get_default_face_mesh_tesselation_style())\n\n    # Plota a imagem\n    plt.figure(figsize=(10, 10))\n    plt.imshow(cv2.cvtColor(annotated_image, cv2.COLOR_BGR2RGB))\n    plt.axis('off')\n    plt.show()\n\n# N\u00e3o se esque\u00e7a de liberar os recursos do objeto face_mesh quando terminar\n# face_mesh.close()\n</pre>  # Configura\u00e7\u00f5es de desenho mp_drawing = mp.solutions.drawing_utils mp_drawing_styles = mp.solutions.drawing_styles mp_face_mesh = mp.solutions.face_mesh  # Crie uma inst\u00e2ncia do objeto FaceMesh face_mesh = mp_face_mesh.FaceMesh(     static_image_mode=True,     max_num_faces=1,     refine_landmarks=True,     min_detection_confidence=0.5)  file = 'lena.png'  # Leia o arquivo de imagem com cv2 e converta de BGR para RGB image = cv2.imread(file) results = face_mesh.process(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))  face_found = results.multi_face_landmarks print(f'foram encontradas: {len(face_found)} faces na imagem')  if face_found:     # Crie uma c\u00f3pia da imagem     annotated_image = image.copy()      # Desenha as landmarks e conex\u00f5es     mp_drawing.draw_landmarks(         image=annotated_image,         landmark_list=results.multi_face_landmarks[0],         connections=mp_face_mesh.FACEMESH_TESSELATION,         landmark_drawing_spec=None,         connection_drawing_spec=mp_drawing_styles.get_default_face_mesh_tesselation_style())      # Plota a imagem     plt.figure(figsize=(10, 10))     plt.imshow(cv2.cvtColor(annotated_image, cv2.COLOR_BGR2RGB))     plt.axis('off')     plt.show()  # N\u00e3o se esque\u00e7a de liberar os recursos do objeto face_mesh quando terminar # face_mesh.close()  <pre>I0000 00:00:1712871282.566201       1 gl_context.cc:344] GL version: 2.1 (2.1 Metal - 88), renderer: Apple M2\n</pre> <pre>foram encontradas: 1 faces na imagem\n</pre> In\u00a0[\u00a0]: Copied! <pre># seu c\u00f3digo aqui...\n</pre> # seu c\u00f3digo aqui... In\u00a0[\u00a0]: Copied! <pre># seu c\u00f3digo aqui...\n</pre> # seu c\u00f3digo aqui... In\u00a0[20]: Copied! <pre>mp_drawing = mp.solutions.drawing_utils\nmp_hands = mp.solutions.hands\n</pre> mp_drawing = mp.solutions.drawing_utils mp_hands = mp.solutions.hands In\u00a0[21]: outputPrepend Copied! <pre>cap = cv2.VideoCapture(0)\n\nwith mp_hands.Hands(min_detection_confidence=0.8, min_tracking_confidence=0.5) as hands: \n    while cap.isOpened():\n        ret, frame = cap.read()\n        \n        # BGR 2 RGB\n        image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n        \n        # Flip on horizontal\n        image = cv2.flip(image, 1)\n        \n        # Set flag\n        image.flags.writeable = False\n        \n        # Detections\n        results = hands.process(image)\n        \n        # Set flag to true\n        image.flags.writeable = True\n        \n        # RGB 2 BGR\n        image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n        \n        # Rendering results\n        if results.multi_hand_landmarks:\n            for num, hand in enumerate(results.multi_hand_landmarks):\n                mp_drawing.draw_landmarks(image, hand, mp_hands.HAND_CONNECTIONS, \n                                        mp_drawing.DrawingSpec(color=(121, 22, 76), thickness=2, circle_radius=4),\n                                        mp_drawing.DrawingSpec(color=(250, 44, 250), thickness=2, circle_radius=2),\n                                         )\n            \n        \n        cv2.imshow('Hand Tracking', image)\n\n        if cv2.waitKey(10) &amp; 0xFF == ord('q'):\n            break\n\ncap.release()\ncv2.destroyAllWindows()\n</pre> cap = cv2.VideoCapture(0)  with mp_hands.Hands(min_detection_confidence=0.8, min_tracking_confidence=0.5) as hands:      while cap.isOpened():         ret, frame = cap.read()                  # BGR 2 RGB         image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)                  # Flip on horizontal         image = cv2.flip(image, 1)                  # Set flag         image.flags.writeable = False                  # Detections         results = hands.process(image)                  # Set flag to true         image.flags.writeable = True                  # RGB 2 BGR         image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)                  # Rendering results         if results.multi_hand_landmarks:             for num, hand in enumerate(results.multi_hand_landmarks):                 mp_drawing.draw_landmarks(image, hand, mp_hands.HAND_CONNECTIONS,                                          mp_drawing.DrawingSpec(color=(121, 22, 76), thickness=2, circle_radius=4),                                         mp_drawing.DrawingSpec(color=(250, 44, 250), thickness=2, circle_radius=2),                                          )                               cv2.imshow('Hand Tracking', image)          if cv2.waitKey(10) &amp; 0xFF == ord('q'):             break  cap.release() cv2.destroyAllWindows() <pre>I0000 00:00:1712871632.333893       1 gl_context.cc:344] GL version: 2.1 (2.1 Metal - 88), renderer: Apple M2\n2024-04-11 18:40:32.487 Python[40047:7578102] WARNING: Secure coding is automatically enabled for restorable state! However, not on all supported macOS versions of this application. Opt-in to secure coding explicitly by implementing NSApplicationDelegate.applicationSupportsSecureRestorableState:.\n</pre> In\u00a0[22]: Copied! <pre>import cv2\nimport mediapipe\nimport time\n\nctime=0\nptime=0\n\ncap=cv2.VideoCapture(0)\n\nmedhands=mediapipe.solutions.hands\nhands=medhands.Hands(max_num_hands=1,min_detection_confidence=0.7)\ndraw=mediapipe.solutions.drawing_utils\n\nwhile True:\n    success, img=cap.read() #pega um frame da imagem\n    \n    img = cv2.flip(img,1) # inverte a imagem\n    \n    imgrgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)  \n    \n    \n    #realiza a detec\u00e7\u00e3o da m\u00e3o na imagem\n    res = hands.process(imgrgb)\n    \n    lmlist=[]\n    tipids=[4,8,12,16,20] # lista com as pontas dos dedos\n    \n    #desenha no canto da tela um retangulo, os numeros v\u00e3o aparecer aqui\n    cv2.rectangle(img,(20,350),(90,440),(0,255,204),cv2.FILLED)\n    cv2.rectangle(img,(20,350),(90,440),(0,0,0),5)\n    \n    ## se detectar alguma m\u00e3o entra no if \n    if res.multi_hand_landmarks:\n        for handlms in res.multi_hand_landmarks:\n            for id,lm in enumerate(handlms.landmark):\n                \n                h,w,c= img.shape\n                cx,cy=int(lm.x * w) , int(lm.y * h)\n                lmlist.append([id,cx,cy])\n                if len(lmlist) != 0 and len(lmlist)==21:\n                    fingerlist=[]\n                    \n                    #thumb and dealing with flipping of hands\n                    if lmlist[12][1] &gt; lmlist[20][1]:\n                        if lmlist[tipids[0]][1] &gt; lmlist[tipids[0]-1][1]:\n                            fingerlist.append(1)\n                        else:\n                            fingerlist.append(0)\n                    else:\n                        if lmlist[tipids[0]][1] &lt; lmlist[tipids[0]-1][1]:\n                            fingerlist.append(1)\n                        else:\n                            fingerlist.append(0)\n                    \n                    #others\n                    for id in range (1,5):\n                        if lmlist[tipids[id]][2] &lt; lmlist[tipids[id]-2][2]:\n                            fingerlist.append(1)\n                        else:\n                            fingerlist.append(0)\n                    \n                    \n                    if len(fingerlist)!=0:  # se a lista for diferente de zero ent\u00e3o \n                        fingercount=fingerlist.count(1) # conta quantidade de dedos\n                    \n                    # escreve na tela a quantidade detectada\n                    cv2.putText(img,str(fingercount),(25,430),cv2.FONT_HERSHEY_PLAIN,6,(0,0,0),5)\n                    \n                #change color of points and lines\n                draw.draw_landmarks(img,handlms,medhands.HAND_CONNECTIONS,draw.DrawingSpec(color=(0,255,204),thickness=2,circle_radius=2),draw.DrawingSpec(color=(0,0,0),thickness=2,circle_radius=3))\n          \n    cv2.imshow(\"hand gestures\",img)\n    \n    #press q to quit\n    if cv2.waitKey(1) == ord('q'):\n        break\ncap.release()   \ncv2.destroyAllWindows()\n</pre> import cv2 import mediapipe import time  ctime=0 ptime=0  cap=cv2.VideoCapture(0)  medhands=mediapipe.solutions.hands hands=medhands.Hands(max_num_hands=1,min_detection_confidence=0.7) draw=mediapipe.solutions.drawing_utils  while True:     success, img=cap.read() #pega um frame da imagem          img = cv2.flip(img,1) # inverte a imagem          imgrgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)                 #realiza a detec\u00e7\u00e3o da m\u00e3o na imagem     res = hands.process(imgrgb)          lmlist=[]     tipids=[4,8,12,16,20] # lista com as pontas dos dedos          #desenha no canto da tela um retangulo, os numeros v\u00e3o aparecer aqui     cv2.rectangle(img,(20,350),(90,440),(0,255,204),cv2.FILLED)     cv2.rectangle(img,(20,350),(90,440),(0,0,0),5)          ## se detectar alguma m\u00e3o entra no if      if res.multi_hand_landmarks:         for handlms in res.multi_hand_landmarks:             for id,lm in enumerate(handlms.landmark):                                  h,w,c= img.shape                 cx,cy=int(lm.x * w) , int(lm.y * h)                 lmlist.append([id,cx,cy])                 if len(lmlist) != 0 and len(lmlist)==21:                     fingerlist=[]                                          #thumb and dealing with flipping of hands                     if lmlist[12][1] &gt; lmlist[20][1]:                         if lmlist[tipids[0]][1] &gt; lmlist[tipids[0]-1][1]:                             fingerlist.append(1)                         else:                             fingerlist.append(0)                     else:                         if lmlist[tipids[0]][1] &lt; lmlist[tipids[0]-1][1]:                             fingerlist.append(1)                         else:                             fingerlist.append(0)                                          #others                     for id in range (1,5):                         if lmlist[tipids[id]][2] &lt; lmlist[tipids[id]-2][2]:                             fingerlist.append(1)                         else:                             fingerlist.append(0)                                                               if len(fingerlist)!=0:  # se a lista for diferente de zero ent\u00e3o                          fingercount=fingerlist.count(1) # conta quantidade de dedos                                          # escreve na tela a quantidade detectada                     cv2.putText(img,str(fingercount),(25,430),cv2.FONT_HERSHEY_PLAIN,6,(0,0,0),5)                                      #change color of points and lines                 draw.draw_landmarks(img,handlms,medhands.HAND_CONNECTIONS,draw.DrawingSpec(color=(0,255,204),thickness=2,circle_radius=2),draw.DrawingSpec(color=(0,0,0),thickness=2,circle_radius=3))                cv2.imshow(\"hand gestures\",img)          #press q to quit     if cv2.waitKey(1) == ord('q'):         break cap.release()    cv2.destroyAllWindows() <pre>I0000 00:00:1712871645.820581       1 gl_context.cc:344] GL version: 2.1 (2.1 Metal - 88), renderer: Apple M2\n</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre>"},{"location":"aulas/PDI/lab17/mediapipe.html#mediapipe","title":"Mediapipe\u00b6","text":"<p>Objetivos da aula:</p> <ul> <li>Apresentar e aplicar a biblioteca <code>mediapipe</code></li> </ul> <p>Mediapipe \u00e9 uma biblioteca de processamento de m\u00eddia de c\u00f3digo aberto desenvolvida pelo Google, que fornece uma ampla variedade de algoritmos e ferramentas de vis\u00e3o computacional para an\u00e1lise de dados em tempo real.</p> <p>A biblioteca \u00e9 implementada em C++ e Python, com suporte para processamento em CPU e GPU.</p> <p>Entre as funcionalidades oferecidas pela biblioteca Mediapipe, destacam-se a detec\u00e7\u00e3o de <code>keypoints</code>, <code>tracking</code>, <code>classifica\u00e7\u00e3o de gestos</code>, <code>reconhecimento facial</code>, <code>pose estimation</code>, <code>detec\u00e7\u00e3o de objetos</code> e <code>segmenta\u00e7\u00e3o de imagem</code>.</p> <p>A implementa\u00e7\u00e3o desses algoritmos \u00e9 feita utilizando t\u00e9cnicas de aprendizado de m\u00e1quina e redes neurais profundas, incluindo redes neurais convolucionais e redes de grafos.</p>"},{"location":"aulas/PDI/lab17/mediapipe.html#instalacao","title":"Instala\u00e7\u00e3o\u00b6","text":"<p>A instala\u00e7\u00e3o \u00e9 simples. Mas pode acontecer incompatibilidade de vers\u00f5es entre o python e algumas dependencias. Caso n\u00e3o consiga instalar via <code>pip</code> ser\u00e1 necess\u00e1rio investigar o erro para entender o que precisa ser ajustado na instala\u00e7\u00e3o.</p> <p>No meu caso, usando Mac M2, estou usando:</p> <ul> <li>python 3.9.6</li> <li>mediapipe==0.10.9</li> </ul>"},{"location":"aulas/PDI/lab17/mediapipe.html#primeiros-passos","title":"Primeiros passos\u00b6","text":"<p>O site oficial da documenta\u00e7\u00e3o do Mediapipe \u00e9 o https://mediapipe.dev/.</p> <p>J\u00e1 existe bastante conte\u00fado contendo informa\u00e7\u00f5es detalhadas sobre como utilizar cada uma das funcionalidades da biblioteca, incluindo tutoriais em v\u00eddeo e em texto, exemplos de c\u00f3digo, e muito mais.</p> <p>Al\u00e9m disso, a p\u00e1gina oferece uma ampla variedade de recursos adicionais, como f\u00f3runs de discuss\u00e3o, bibliotecas de modelos pr\u00e9-treinados, e outros materiais \u00fateis para desenvolvedores de vis\u00e3o computacional.</p>"},{"location":"aulas/PDI/lab17/mediapipe.html#face","title":"Face\u00b6","text":"<p>O <code>Mediapipe face mesh</code> \u00e9 um recurso da biblioteca Mediapipe que permite a detec\u00e7\u00e3o e rastreamento de faces.</p>"},{"location":"aulas/PDI/lab17/mediapipe.html#desafio1","title":"desafio1\u00b6","text":"<p>Fa\u00e7a os ajustes para o c\u00f3digo rodar com webcam.</p>"},{"location":"aulas/PDI/lab17/mediapipe.html#desafio-2","title":"Desafio 2\u00b6","text":"<p>Implemente uma solu\u00e7\u00e3o que detecta se a pessoa est\u00e1 de olhos abertos ou fechados.</p>"},{"location":"aulas/PDI/lab17/mediapipe.html#tracking-de-mao","title":"Tracking de m\u00e3o\u00b6","text":"<p>O <code>Mediapipe Hand Tracking</code> \u00e9 um recurso da biblioteca Mediapipe que permite a detec\u00e7\u00e3o e rastreamento das m\u00e3os em tempo real, a partir de uma entrada de v\u00eddeo ou imagem.</p> <p>Esse recurso utiliza uma <code>rede neural</code> que \u00e9 <code>treinada</code> para reconhecer pontos de refer\u00eancia nas m\u00e3os, como a base dos dedos, pontas dos dedos e pulso.</p>"},{"location":"aulas/PDI/lab17/mediapipe.html#contagem-dos-dedos","title":"contagem dos dedos\u00b6","text":"<p>adaptado de: https://github.com/ANANTH-SWAMY/NUMBER-DETECTION-WITH-MEDIAPIPE</p>"},{"location":"aulas/PDI/lab17/mediapipe.html#desafio-3","title":"Desafio 3\u00b6","text":"<p>O mediapipe possui um modo para detec\u00e7\u00e3o de pose, o dense pose. Implemente uma solu\u00e7\u00e3o que realiza</p>"},{"location":"aulas/PDI/lab17/mediapipe_face.html","title":"Mediapipe face","text":"In\u00a0[\u00a0]: Copied! <pre>import cv2\nimport mediapipe as mp\n</pre> import cv2 import mediapipe as mp In\u00a0[\u00a0]: Copied! <pre>\n</pre> In\u00a0[\u00a0]: Copied! <pre>mp_face_mesh = mp.solutions.face_mesh\nface_mesh = mp_face_mesh.FaceMesh()\n</pre> mp_face_mesh = mp.solutions.face_mesh face_mesh = mp_face_mesh.FaceMesh() In\u00a0[\u00a0]: Copied! <pre>cap = cv2.VideoCapture(0)\n</pre> cap = cv2.VideoCapture(0) In\u00a0[\u00a0]: Copied! <pre>\n</pre> In\u00a0[\u00a0]: Copied! <pre>while True:\n\n    ret,frame = cap.read()\n\n    if ret is not True:\n        break\n\n    h,w,_ = frame.shape\n    rgb_image = cv2.cvtColor(frame,cv2.COLOR_BGR2RGB)\n\n\n    ressult = face_mesh.process(rgb_image)\n\n    for facial_landmarks in ressult.multi_face_landmarks:\n        for i in range(0,468):\n            pt1 = facial_landmarks.landmark[i]\n            x = int(pt1.x*w)\n            y = int(pt1.y*h)\n            cv2.circle(frame, (x,y), 1,(0,255,0),-1)\n    \n    cv2.imshow(\"Img\", frame)\n\n    key = cv2.waitKey(1)\n    if key == 27:           \n        break               \n</pre> while True:      ret,frame = cap.read()      if ret is not True:         break      h,w,_ = frame.shape     rgb_image = cv2.cvtColor(frame,cv2.COLOR_BGR2RGB)       ressult = face_mesh.process(rgb_image)      for facial_landmarks in ressult.multi_face_landmarks:         for i in range(0,468):             pt1 = facial_landmarks.landmark[i]             x = int(pt1.x*w)             y = int(pt1.y*h)             cv2.circle(frame, (x,y), 1,(0,255,0),-1)          cv2.imshow(\"Img\", frame)      key = cv2.waitKey(1)     if key == 27:                    break                In\u00a0[\u00a0]: Copied! <pre>cv2.destroyAllWindows()\ncap.release()\n</pre> cv2.destroyAllWindows() cap.release()"},{"location":"aulas/PDI/lab18/index.html","title":"Lab18 - Yolo","text":""},{"location":"aulas/PDI/lab18/index.html#modulo-dnn-opencv","title":"Modulo DNN OpenCV","text":"<p>Acesso os c\u00f3digos python para testar:</p> <ul> <li>Yolo - imagem</li> <li>Yolo - video</li> </ul>"},{"location":"aulas/PDI/lab18/index.html#deteccao-de-objetos-com-yolov5-e-opencv-em-python","title":"Detec\u00e7\u00e3o de Objetos com YOLOv5 e OpenCV em Python","text":"<p>Vamos compreender o uso do modelo YOLOv5 para detec\u00e7\u00e3o de objetos em imagens usando a OpenCV. </p> <p>O <code>m\u00f3dulo DNN (Deep Neural Network) do OpenCV</code> \u00e9 uma biblioteca que oferece uma interface para <code>executar infer\u00eancias a partir de redes neurais</code>. Ele suporta uma variedade de frameworks de aprendizado profundo, incluindo <code>TensorFlow, Caffe, Torch/PyTorch, e Darknet (YOLO)</code>. A principal vantagem do m\u00f3dulo DNN \u00e9 permitir o uso de modelos pr\u00e9-treinados de deep learning em aplica\u00e7\u00f5es de vis\u00e3o computacional diretamente com o OpenCV, sem depender dos frameworks originais.</p>"},{"location":"aulas/PDI/lab18/index.html#importacao-das-bibliotecas-necessarias","title":"Importa\u00e7\u00e3o das Bibliotecas Necess\u00e1rias","text":"<pre><code>import cv2\nimport numpy as np\n</code></pre> <ul> <li><code>cv2</code>: Biblioteca OpenCV para opera\u00e7\u00f5es de vis\u00e3o computacional.</li> <li><code>numpy</code>: Biblioteca para manipula\u00e7\u00e3o de arrays e matrizes de alta performance.</li> </ul>"},{"location":"aulas/PDI/lab18/index.html#carregamento-do-modelo-yolov5","title":"Carregamento do Modelo YOLOv5","text":"<pre><code>net = cv2.dnn.readNet('yolov5m.onnx')\n</code></pre> <p>Carrega o modelo pr\u00e9-treinado YOLOv5 (formato ONNX). O modelo \u00e9 respons\u00e1vel por realizar as predi\u00e7\u00f5es das localiza\u00e7\u00f5es dos objetos.</p> <p>A yolov5 disponibiliza algumas vers\u00f5es:</p> <ul> <li><code>yolov5m</code>: Modelo m\u00e9dio, oferece um equil\u00edbrio entre velocidade e precis\u00e3o. \u00c9 adequado para aplica\u00e7\u00f5es que necessitam de uma boa precis\u00e3o, mas ainda assim mant\u00eam a necessidade de ser relativamente r\u00e1pido. \u00c9 maior que o yolov5s, resultando em uma precis\u00e3o melhorada, por\u00e9m com uma velocidade um pouco reduzida.</li> <li><code>yolov5n</code>: Modelo nano, \u00e9 a vers\u00e3o mais leve e r\u00e1pida, projetada para ser extremamente r\u00e1pida e para funcionar em dispositivos com recursos limitados, como smartphones e dispositivos IoT. Ele sacrifica precis\u00e3o em prol de velocidade e baixo consumo de recursos.</li> <li><code>yolov5s</code>: Modelo pequeno, \u00e9 a vers\u00e3o que busca um equil\u00edbrio entre velocidade e uso de recursos, mantendo uma precis\u00e3o razo\u00e1vel. \u00c9 ideal para aplica\u00e7\u00f5es que necessitam de uma detec\u00e7\u00e3o de objetos razoavelmente r\u00e1pida e eficiente em termos de recursos.</li> </ul> <p>Warning</p> <p>Voc\u00ea deve ter esse arquivo baixado em usa m\u00e1quina, o arquivo \u00e9 encontrado no link: https://github.com/spmallick/learnopencv/tree/master/Object-Detection-using-YOLOv5-and-OpenCV-DNN-in-CPP-and-Python/models</p>"},{"location":"aulas/PDI/lab18/index.html#leitura-das-classes-possiveis","title":"Leitura das Classes Poss\u00edveis","text":"<pre><code>classesFile = \"coco.names\"\nwith open(classesFile, 'rt') as f:\n    classes = f.read().rstrip('\\n').split('\\n')\n</code></pre> <p>Carrega os nomes das classes que o modelo \u00e9 capaz de detectar (baseado no dataset COCO que foi usado no treinamento).</p> <p>Warning</p> <p>Voc\u00ea deve ter esse arquivo baixado em usa m\u00e1quina, o arquivo \u00e9 encontrado no link: https://github.com/spmallick/learnopencv/blob/master/Object-Detection-using-YOLOv5-and-OpenCV-DNN-in-CPP-and-Python/coco.names</p>"},{"location":"aulas/PDI/lab18/index.html#interpretacao-dos-resultados","title":"Interpreta\u00e7\u00e3o dos Resultados","text":"<p>As vari\u00e1veis <code>class_ids</code>, <code>confidences</code>, e <code>boxes</code> s\u00e3o criadas para armazenarem os IDs das classes, as confian\u00e7as das detec\u00e7\u00f5es e as coordenadas das caixas delimitadoras, respectivamente. Seguindo uma estrutura de listas.</p> <pre><code>class_ids = []\nconfidences = []\nboxes = []\n</code></pre>"},{"location":"aulas/PDI/lab18/index.html#leitura-da-imagem","title":"Leitura da Imagem","text":"<pre><code>image = cv2.imread('img.jpg')\n</code></pre> <p>Carrega uma imagem <code>image</code> para teste. Esta imagem ser\u00e1 usada para a detec\u00e7\u00e3o de objetos.</p>"},{"location":"aulas/PDI/lab18/index.html#preparacao-da-imagem-para-o-modelo","title":"Prepara\u00e7\u00e3o da Imagem para o Modelo","text":"<pre><code>blob = cv2.dnn.blobFromImage(image, 1/255.0, (640, 640), swapRB=True, crop=False)\nnet.setInput(blob)\n</code></pre> <ul> <li><code>blobFromImage</code>: Converte a imagem para o formato necess\u00e1rio pelo modelo (blob), realiza normaliza\u00e7\u00f5es (como escalonamento) e muda o layout de cores de BGR para RGB.</li> <li><code>setInput</code>: Define o blob como entrada para a rede.</li> </ul>"},{"location":"aulas/PDI/lab18/index.html#processamento-da-deteccao","title":"Processamento da Detec\u00e7\u00e3o","text":"<pre><code>output_layers = net.getUnconnectedOutLayersNames()\noutputs = net.forward(output_layers)\n</code></pre> <ul> <li><code>getUnconnectedOutLayersNames()</code>: Em modelos como YOLO, estas camadas de sa\u00edda s\u00e3o as que fornecem as previs\u00f5es finais ap\u00f3s a passagem da imagem pela rede. Essas camadas s\u00e3o importantes porque s\u00e3o elas que cont\u00eam as informa\u00e7\u00f5es sobre as detec\u00e7\u00f5es feitas pela rede, como coordenadas de caixas delimitadoras, classes detectadas e confian\u00e7as associadas a essas detec\u00e7\u00f5es.</li> <li><code>forward(output_layers)</code>: Executa a rede neural para processar a entrada fornecida (a imagem transformada em um blob). O m\u00e9todo forward \u00e9 usado para propagar o blob atrav\u00e9s da rede, calculando a sa\u00edda nas camadas especificadas pelo argumento output_layers.</li> </ul> <p>Warning</p> <p>O resultado, <code>outputs</code>, \u00e9 um conjunto de arrays. Cada array corresponde a uma das camadas de sa\u00edda especificadas e cont\u00e9m as informa\u00e7\u00f5es detectadas para diferentes partes da imagem. Para o YOLO, esses arrays incluem as coordenadas das caixas delimitadoras (x, y, largura, altura), a confian\u00e7a de que h\u00e1 um objeto dentro da caixa e as probabilidades de cada classe para o objeto detectado.</p>"},{"location":"aulas/PDI/lab18/index.html#entendendo-a-saida-outputs","title":"Entendendo a saida outputs","text":"<p><code>Outputs</code> \u00e9 uma lista onde cada elemento \u00e9 um array NumPy. Cada array corresponde \u00e0s detec\u00e7\u00f5es feitas em uma certa camada de sa\u00edda da rede neural. Para o YOLOv5, normalmente existem tr\u00eas arrays, um para cada escala de detec\u00e7\u00e3o.</p> <p>Cada array tem uma estrutura tridimensional, comummente descrita como <code>(1, N, M)</code>, onde:</p> <ul> <li>1 representa o batch size, ou seja, o n\u00famero de imagens processadas. Geralmente \u00e9 1, pois processa-se uma imagem de cada vez.</li> <li>N \u00e9 o n\u00famero de caixas de detec\u00e7\u00e3o produzidas pela camada. Por exemplo, 25200 caixas (bounding boxes) ou detec\u00e7\u00f5es potenciais que o modelo gera para a imagem. \u00c9 o resultado da multiplica\u00e7\u00e3o do n\u00famero de \u00e2ncoras (anchor boxes) por diferentes tamanhos de grade (grid sizes) em que a imagem \u00e9 dividida durante a detec\u00e7\u00e3o.</li> <li>M \u00e9 o n\u00famero de caracter\u00edsticas por caixa de detec\u00e7\u00e3o. No YOLO com o dataset COCO, M \u00e9 geralmente 85, que inclui:<ul> <li>4 valores para a localiza\u00e7\u00e3o da caixa delimitadora (cx, cy, largura, altura), indicando o centro, largura e altura da caixa.</li> <li>1 valor para a confian\u00e7a de que a caixa cont\u00e9m um objeto.</li> <li>80 valores representando a probabilidade de cada uma das 80 classes poss\u00edveis no dataset COCO.</li> </ul> </li> </ul>"},{"location":"aulas/PDI/lab18/index.html#interpretando-os-resultados","title":"Interpretando os resultados","text":"<p>Para extrair e utilizar as informa\u00e7\u00f5es de detec\u00e7\u00e3o a partir do outputs, voc\u00ea deve realizar os seguintes passos:</p> <ul> <li><code>Extra\u00e7\u00e3o de Dados</code>: Itere sobre cada elemento (caixa de detec\u00e7\u00e3o) do array. Cada elemento cont\u00e9m informa\u00e7\u00f5es detalhadas sobre uma detec\u00e7\u00e3o potencial.</li> <li><code>Processamento de Caixas</code>: Para cada caixa de detec\u00e7\u00e3o, extraia as coordenadas (cx, cy, largura, altura) e a confian\u00e7a. Aplique o fator de escala \u00e0s coordenadas para converter essas coordenadas do espa\u00e7o da imagem redimensionada para o espa\u00e7o da imagem original.</li> <li><code>Filtragem por Confian\u00e7a</code>: Verifique se a confian\u00e7a de que a caixa cont\u00e9m um objeto \u00e9 superior a um limiar (por exemplo, 0.5). Isso reduz o n\u00famero de falsos positivos.</li> <li><code>Identifica\u00e7\u00e3o da Classe</code>: Dentro dos 80 valores de probabilidade de classe, identifique o \u00edndice (classe) com a maior probabilidade. Esse \u00edndice corresponde \u00e0 classe do objeto detectado na caixa.</li> <li><code>Non-Max Suppression (NMS)</code>: Uma vez que v\u00e1rias caixas podem ser detectadas para o mesmo objeto, o NMS \u00e9 usado para filtrar e manter apenas a caixa com a maior confian\u00e7a, enquanto remove caixas que t\u00eam uma grande sobreposi\u00e7\u00e3o com ela.</li> </ul>"},{"location":"aulas/PDI/lab18/index.html#processamento-das-deteccoes","title":"Processamento das Detec\u00e7\u00f5es","text":"<pre><code>rows = outputs[0].shape[1]\nimage_height, image_width = image.shape[:2]\nx_factor = image_width / 640\ny_factor = image_height / 640\n\nfor r in range(rows):\n    row = outputs[0][0][r] # pega a linha r, que cont\u00e9m as coordenadas da caixa delimitadora, confian\u00e7a e probabilidades de classe\n    confidence = row[4] # pega a confian\u00e7a da detec\u00e7\u00e3o\n\n    # Discard bad detections and continue.\n    if confidence &gt;= 0.45:\n        classes_scores = row[5:] # pega as probabilidades de classe\n\n        # pega o indice com a classe de maior score.\n        class_id = np.argmax(classes_scores)\n\n        if (classes_scores[class_id] &gt; 0.5): # se o score for maior que 0.5\n            confidences.append(confidence)  # adiciona a confian\u00e7a\n            class_ids.append(class_id)    # adiciona o id da classe\n\n            cx, cy, w, h = row[0], row[1], row[2], row[3] # pega as coordenadas do centro x, centro y, largura e altura\n\n            left = int((cx - w/2) * x_factor) # calcula a coordenada x do canto superior esquerdo\n            top = int((cy - h/2) * y_factor) # calcula a coordenada y do canto superior esquerdo\n            width = int(w * x_factor) # calcula a largura\n            height = int(h * y_factor) # calcula a altura\n\n            box = np.array([left, top, width, height]) # cria um array com as coordenadas\n            boxes.append(box) # adiciona o array na lista de boxes\n</code></pre> <ul> <li> <p>rows = outputs[0].shape[1]: Esta linha obt\u00e9m o n\u00famero de detec\u00e7\u00f5es retornadas pela primeira camada de sa\u00edda da rede neural. Em modelos como o YOLO, outputs[0] \u00e9 um tensor que cont\u00e9m as detec\u00e7\u00f5es para a imagem, onde cada \"row (linha)\" representa uma detec\u00e7\u00e3o potencial. shape[1] se refere \u00e0 dimens\u00e3o que cont\u00e9m o n\u00famero de detec\u00e7\u00f5es.</p> </li> <li> <p><code>x_factor e y_factor</code>: fator de redimensionamento no eixo x (largura) e y (altura).</p> </li> <li> <p><code>for r in range(rows)</code>: Itera sobre cada uma das detec\u00e7\u00f5es. A vari\u00e1vel rows representa o n\u00famero total de detec\u00e7\u00f5es poss\u00edveis para uma escala de sa\u00edda do modelo.</p> </li> <li> <p><code>Extra\u00e7\u00e3o de dados para cada detec\u00e7\u00e3o</code>:</p> <ul> <li><code>row = outputs[0][0][r]</code>: Extrai a linha r do primeiro tensor de sa\u00edda, que cont\u00e9m todas as informa\u00e7\u00f5es necess\u00e1rias para essa detec\u00e7\u00e3o espec\u00edfica.</li> <li><code>confidence = row[4]</code>: Extrai a confian\u00e7a de que a caixa delimitadora cont\u00e9m algum objeto.</li> </ul> </li> <li> <p><code>Filtragem de detec\u00e7\u00f5es por confian\u00e7a</code>:</p> <ul> <li><code>if confidence &gt;= 0.45</code>: Processa apenas as detec\u00e7\u00f5es que t\u00eam uma confian\u00e7a de pelo menos 0.45. Isso ajuda a eliminar falsos positivos ou detec\u00e7\u00f5es de baixa qualidade.</li> </ul> </li> <li> <p>Extra\u00e7\u00e3o e verifica\u00e7\u00e3o das probabilidades das classes:</p> <ul> <li><code>classes_scores = row[5:]</code>: Obt\u00e9m as probabilidades de cada classe para a detec\u00e7\u00e3o atual.</li> <li><code>class_id = np.argmax(classes_scores)</code>: Identifica o \u00edndice da classe que tem a maior probabilidade (score mais alto).</li> <li><code>if (classes_scores[class_id] &gt; 0.5)</code>: Verifica se a maior probabilidade de classe excede 0.5, indicando uma alta confian\u00e7a na classifica\u00e7\u00e3o do objeto.</li> </ul> </li> <li> <p>Extra\u00e7\u00e3o das coordenadas da caixa delimitadora e ajuste para o tamanho original da imagem:</p> <ul> <li><code>cx, cy, w, h = row[0], row[1], row[2], row[3]</code>: Extrai as coordenadas do centro da caixa, sua largura e altura da detec\u00e7\u00e3o.</li> <li><code>left = int((cx - w/2) * x_factor)</code>: Calcula a coordenada x do canto superior esquerdo da caixa, ajustando para o tamanho original da imagem.</li> <li><code>top = int((cy - h/2) * y_factor)</code>: Calcula a coordenada y do canto superior esquerdo, tamb\u00e9m ajustando para o tamanho original.</li> <li><code>width = int(w * x_factor), height = int(h * y_factor)</code>: Calcula a largura e altura reais da caixa delimitadora no tamanho original da imagem.</li> </ul> </li> <li> <p>Armazenamento das caixas delimitadoras:</p> <ul> <li><code>box = np.array([left, top, width, height])</code>: Cria um array com as coordenadas ajustadas da caixa delimitadora.</li> <li><code>boxes.append(box)</code>: Adiciona o array das coordenadas da caixa \u00e0 lista de boxes, que ser\u00e1 usada mais tarde para desenhar as caixas na imagem e aplicar a supress\u00e3o de m\u00e1ximos n\u00e3o-m\u00e1ximos (NMS).</li> </ul> </li> </ul>"},{"location":"aulas/PDI/lab18/index.html#aplicacao-do-non-maximum-suppression-nms","title":"Aplica\u00e7\u00e3o do Non-Maximum Suppression (NMS)","text":"<pre><code>indices = cv2.dnn.NMSBoxes(boxes, confidences, 0.45, 0.45)\n</code></pre> <p>NMS \u00e9 usado para eliminar caixas delimitadoras redundantes, mantendo apenas as mais prov\u00e1veis para cada objeto.</p>"},{"location":"aulas/PDI/lab18/index.html#desenho-das-caixas-delimitadoras-e-rotulos-na-imagem","title":"Desenho das Caixas Delimitadoras e R\u00f3tulos na Imagem","text":"<pre><code>for i in indices:\n    ...\n    cv2.rectangle(image, (left, top), (left + width, top + height), (255,178,50), 3*1)\n    ...\n    cv2.putText(image, label, (left, top + dim[1]), FONT_FACE, FONT_SCALE, YELLOW, 1, cv2.LINE_AA)\n</code></pre> <p>Desenha ret\u00e2ngulos e texto para as detec\u00e7\u00f5es finais na imagem.</p>"},{"location":"aulas/PDI/lab18/index.html#exibicao-da-imagem","title":"Exibi\u00e7\u00e3o da Imagem","text":"<pre><code>cv2.imshow('Output', image)\ncv2.waitKey(0)\n</code></pre>"},{"location":"aulas/PDI/lab18/yolo.html","title":"Yolo","text":"In\u00a0[\u00a0]: Copied! <pre>import cv2\nimport numpy as np\n</pre> import cv2 import numpy as np In\u00a0[\u00a0]: Copied! <pre># Carregar o modelo YOLOv5 ONNX\nnet = cv2.dnn.readNet('yolov5m.onnx')\n</pre> # Carregar o modelo YOLOv5 ONNX net = cv2.dnn.readNet('yolov5m.onnx') In\u00a0[\u00a0]: Copied! <pre># Ler uma imagem\nimage = cv2.imread('img.jpg')\n</pre> # Ler uma imagem image = cv2.imread('img.jpg') In\u00a0[\u00a0]: Copied! <pre># Preparar a entrada para o modelo\nblob = cv2.dnn.blobFromImage(image, 1/255.0, (640, 640), swapRB=True, crop=False)\nnet.setInput(blob)\n</pre> # Preparar a entrada para o modelo blob = cv2.dnn.blobFromImage(image, 1/255.0, (640, 640), swapRB=True, crop=False) net.setInput(blob) In\u00a0[\u00a0]: Copied! <pre># Processar os resultados da detec\u00e7\u00e3o...\n# o forward retorna uma lista de tensores, cada tensor cont\u00e9m as detec\u00e7\u00f5es de um n\u00edvel de escala\noutput_layers = net.getUnconnectedOutLayersNames()\noutputs = net.forward(output_layers)\n</pre> # Processar os resultados da detec\u00e7\u00e3o... # o forward retorna uma lista de tensores, cada tensor cont\u00e9m as detec\u00e7\u00f5es de um n\u00edvel de escala output_layers = net.getUnconnectedOutLayersNames() outputs = net.forward(output_layers) In\u00a0[\u00a0]: Copied! <pre># Lists to hold respective values while unwrapping.\nclass_ids = []\nconfidences = []\nboxes = []\nclassesFile = \"coco.names\"\nclasses = None\nwith open(classesFile, 'rt') as f:\n    classes = f.read().rstrip('\\n').split('\\n')\nFONT_FACE = cv2.FONT_HERSHEY_SIMPLEX\nFONT_SCALE = 0.7\nBLACK  = (0,0,0)\nBLUE   = (255,178,50)\nYELLOW = (0,255,255)\nRED = (0,0,255)\n</pre> # Lists to hold respective values while unwrapping. class_ids = [] confidences = [] boxes = [] classesFile = \"coco.names\" classes = None with open(classesFile, 'rt') as f:     classes = f.read().rstrip('\\n').split('\\n') FONT_FACE = cv2.FONT_HERSHEY_SIMPLEX FONT_SCALE = 0.7 BLACK  = (0,0,0) BLUE   = (255,178,50) YELLOW = (0,255,255) RED = (0,0,255) In\u00a0[\u00a0]: Copied! <pre># vamos entender a sa\u00edda do modelo YOLOv5\n# cada detec\u00e7\u00e3o \u00e9 representada por 85 valores\n# 4 valores para as coordenadas da caixa delimitadora\n# 1 valor para a confian\u00e7a\n# 80 valores para as probabilidades de classe\n# outputs[0] \u00e9 o tensor de sa\u00edda do modelo, que cont\u00e9m as detec\u00e7\u00f5es do n\u00edvel de escala 0, que \u00e9 a escala original da imagem (640x640)\nprint(f'outputs[0].shape: {outputs[0].shape]}')\n</pre> # vamos entender a sa\u00edda do modelo YOLOv5 # cada detec\u00e7\u00e3o \u00e9 representada por 85 valores # 4 valores para as coordenadas da caixa delimitadora # 1 valor para a confian\u00e7a # 80 valores para as probabilidades de classe # outputs[0] \u00e9 o tensor de sa\u00edda do modelo, que cont\u00e9m as detec\u00e7\u00f5es do n\u00edvel de escala 0, que \u00e9 a escala original da imagem (640x640) print(f'outputs[0].shape: {outputs[0].shape]}') In\u00a0[\u00a0]: Copied! <pre># pega o n\u00famero de detec\u00e7\u00f5es\nrows = outputs[0].shape[1]\nimage_height, image_width = image.shape[:2]\n</pre> # pega o n\u00famero de detec\u00e7\u00f5es rows = outputs[0].shape[1] image_height, image_width = image.shape[:2] In\u00a0[\u00a0]: Copied! <pre># Resizing factor.\nx_factor = image_width / 640\ny_factor =  image_height / 640\n</pre> # Resizing factor. x_factor = image_width / 640 y_factor =  image_height / 640 In\u00a0[\u00a0]: Copied! <pre># Iterate through 25200 detections.\nfor r in range(rows):\n    row = outputs[0][0][r] # pega a linha r, que cont\u00e9m as coordenadas da caixa delimitadora, confian\u00e7a e probabilidades de classe\n    confidence = row[4] # pega a confian\u00e7a da detec\u00e7\u00e3o\n\n    # Discard bad detections and continue.\n    if confidence &gt;= 0.45:\n        classes_scores = row[5:] # pega as probabilidades de classe\n\n        # pega o indice com a classe de maior score.\n        class_id = np.argmax(classes_scores)\n\n        if (classes_scores[class_id] &gt; 0.5): # se o score for maior que 0.5\n            confidences.append(confidence)  # adiciona a confian\u00e7a\n            class_ids.append(class_id)    # adiciona o id da classe\n\n            cx, cy, w, h = row[0], row[1], row[2], row[3] # pega as coordenadas do centro x, centro y, largura e altura\n\n            left = int((cx - w/2) * x_factor) # calcula a coordenada x do canto superior esquerdo\n            top = int((cy - h/2) * y_factor) # calcula a coordenada y do canto superior esquerdo\n            width = int(w * x_factor) # calcula a largura\n            height = int(h * y_factor) # calcula a altura\n            \n            box = np.array([left, top, width, height]) # cria um array com as coordenadas\n            boxes.append(box) # adiciona o array na lista de boxes\n</pre> # Iterate through 25200 detections. for r in range(rows):     row = outputs[0][0][r] # pega a linha r, que cont\u00e9m as coordenadas da caixa delimitadora, confian\u00e7a e probabilidades de classe     confidence = row[4] # pega a confian\u00e7a da detec\u00e7\u00e3o      # Discard bad detections and continue.     if confidence &gt;= 0.45:         classes_scores = row[5:] # pega as probabilidades de classe          # pega o indice com a classe de maior score.         class_id = np.argmax(classes_scores)          if (classes_scores[class_id] &gt; 0.5): # se o score for maior que 0.5             confidences.append(confidence)  # adiciona a confian\u00e7a             class_ids.append(class_id)    # adiciona o id da classe              cx, cy, w, h = row[0], row[1], row[2], row[3] # pega as coordenadas do centro x, centro y, largura e altura              left = int((cx - w/2) * x_factor) # calcula a coordenada x do canto superior esquerdo             top = int((cy - h/2) * y_factor) # calcula a coordenada y do canto superior esquerdo             width = int(w * x_factor) # calcula a largura             height = int(h * y_factor) # calcula a altura                          box = np.array([left, top, width, height]) # cria um array com as coordenadas             boxes.append(box) # adiciona o array na lista de boxes In\u00a0[\u00a0]: Copied! <pre># Aplica o NMS, que \u00e9 um algoritmo que remove as caixas que se sobrep\u00f5em\n# Retorna os \u00edndices das caixas que devem ser mantidas\nindices = cv2.dnn.NMSBoxes(boxes, confidences, 0.45, 0.45) \nfor i in indices:\n    box = boxes[i]\n    left = box[0]\n    top = box[1]\n    width = box[2]\n    height = box[3]\n    cv2.rectangle(image, (left, top), (left + width, top + height), (255,178,50), 3*1)\n    label = \"{}:{:.2f}\".format(classes[class_ids[i]], confidences[i])\n   \n    text_size = cv2.getTextSize(label, FONT_FACE, FONT_SCALE, 1)\n    dim, baseline = text_size[0], text_size[1] \n    # desenha um ret\u00e2ngulo preto para o texto\n    cv2.rectangle(image, (left, top), (left + dim[0], top + dim[1] + baseline), BLACK, cv2.FILLED);\n    # escreve a classe e a confian\u00e7a\n    cv2.putText(image, label, (left, top + dim[1]), FONT_FACE, FONT_SCALE, YELLOW, 1, cv2.LINE_AA)\n</pre> # Aplica o NMS, que \u00e9 um algoritmo que remove as caixas que se sobrep\u00f5em # Retorna os \u00edndices das caixas que devem ser mantidas indices = cv2.dnn.NMSBoxes(boxes, confidences, 0.45, 0.45)  for i in indices:     box = boxes[i]     left = box[0]     top = box[1]     width = box[2]     height = box[3]     cv2.rectangle(image, (left, top), (left + width, top + height), (255,178,50), 3*1)     label = \"{}:{:.2f}\".format(classes[class_ids[i]], confidences[i])         text_size = cv2.getTextSize(label, FONT_FACE, FONT_SCALE, 1)     dim, baseline = text_size[0], text_size[1]      # desenha um ret\u00e2ngulo preto para o texto     cv2.rectangle(image, (left, top), (left + dim[0], top + dim[1] + baseline), BLACK, cv2.FILLED);     # escreve a classe e a confian\u00e7a     cv2.putText(image, label, (left, top + dim[1]), FONT_FACE, FONT_SCALE, YELLOW, 1, cv2.LINE_AA) In\u00a0[\u00a0]: Copied! <pre>cv2.imshow('Output', image)\ncv2.waitKey(0)\n</pre> cv2.imshow('Output', image) cv2.waitKey(0)"},{"location":"aulas/PDI/lab18/yolo_video.html","title":"Yolo video","text":"In\u00a0[\u00a0]: Copied! <pre>import cv2\nimport numpy as np\n</pre> import cv2 import numpy as np In\u00a0[\u00a0]: Copied! <pre># Carregar o modelo YOLOv5 ONNX\nnet = cv2.dnn.readNet('yolov5m.onnx')\n</pre> # Carregar o modelo YOLOv5 ONNX net = cv2.dnn.readNet('yolov5m.onnx') In\u00a0[\u00a0]: Copied! <pre># Abrir um v\u00eddeo\ncap = cv2.VideoCapture(0)\n</pre> # Abrir um v\u00eddeo cap = cv2.VideoCapture(0) In\u00a0[\u00a0]: Copied! <pre>classesFile = \"coco.names\"\nclasses = None\nwith open(classesFile, 'rt') as f:\n    classes = f.read().rstrip('\\n').split('\\n')\n</pre> classesFile = \"coco.names\" classes = None with open(classesFile, 'rt') as f:     classes = f.read().rstrip('\\n').split('\\n') In\u00a0[\u00a0]: Copied! <pre>FONT_FACE = cv2.FONT_HERSHEY_SIMPLEX\nFONT_SCALE = 0.7\nBLACK = (0, 0, 0)\nYELLOW = (0, 255, 255)\n</pre> FONT_FACE = cv2.FONT_HERSHEY_SIMPLEX FONT_SCALE = 0.7 BLACK = (0, 0, 0) YELLOW = (0, 255, 255) In\u00a0[\u00a0]: Copied! <pre>while True:\n    # Ler um frame do v\u00eddeo\n    ret, frame = cap.read()\n    if not ret:\n        break\n\n    # Preparar a entrada para o modelo\n    blob = cv2.dnn.blobFromImage(frame, 1/255.0, (640, 640), swapRB=True, crop=False)\n    net.setInput(blob)\n\n    # Executar a detec\u00e7\u00e3o de objetos\n    outputs = net.forward(net.getUnconnectedOutLayersNames())\n\n    # Processar os resultados da detec\u00e7\u00e3o\n    boxes = []\n    confidences = []\n    class_ids = []\n\n    rows = outputs[0].shape[1]\n    image_height, image_width = frame.shape[:2]\n    x_factor = image_width / 640\n    y_factor = image_height / 640\n\n    for r in range(rows):\n        row = outputs[0][0][r]\n        confidence = row[4]\n        if confidence &gt;= 0.45:\n            classes_scores = row[5:]\n            class_id = np.argmax(classes_scores)\n            if classes_scores[class_id] &gt; 0.2:\n                confidences.append(confidence)\n                class_ids.append(class_id)\n\n                cx, cy, w, h = row[0], row[1], row[2], row[3]\n                left = int((cx - w/2) * x_factor)\n                top = int((cy - h/2) * y_factor)\n                width = int(w * x_factor)\n                height = int(h * y_factor)\n                box = np.array([left, top, width, height])\n                boxes.append(box)\n\n    indices = cv2.dnn.NMSBoxes(boxes, confidences, 0.45, 0.45)\n    for i in indices:\n        box = boxes[i]\n        left = box[0]\n        top = box[1]\n        width = box[2]\n        height = box[3]\n        cv2.rectangle(frame, (left, top), (left + width, top + height), (255, 178, 50), 3)\n        label = \"{}:{:.2f}\".format(classes[class_ids[i]], confidences[i])\n        text_size = cv2.getTextSize(label, FONT_FACE, FONT_SCALE, 1)\n        dim, baseline = text_size[0], text_size[1]\n        cv2.rectangle(frame, (left, top), (left + dim[0], top + dim[1] + baseline), BLACK, cv2.FILLED)\n        cv2.putText(frame, label, (left, top + dim[1]), FONT_FACE, FONT_SCALE, YELLOW, 1, cv2.LINE_AA)\n\n    # Exibir o frame com os objetos detectados\n    cv2.imshow('Output', frame)\n    if cv2.waitKey(1) &amp; 0xFF == ord('q'):\n        break\n</pre> while True:     # Ler um frame do v\u00eddeo     ret, frame = cap.read()     if not ret:         break      # Preparar a entrada para o modelo     blob = cv2.dnn.blobFromImage(frame, 1/255.0, (640, 640), swapRB=True, crop=False)     net.setInput(blob)      # Executar a detec\u00e7\u00e3o de objetos     outputs = net.forward(net.getUnconnectedOutLayersNames())      # Processar os resultados da detec\u00e7\u00e3o     boxes = []     confidences = []     class_ids = []      rows = outputs[0].shape[1]     image_height, image_width = frame.shape[:2]     x_factor = image_width / 640     y_factor = image_height / 640      for r in range(rows):         row = outputs[0][0][r]         confidence = row[4]         if confidence &gt;= 0.45:             classes_scores = row[5:]             class_id = np.argmax(classes_scores)             if classes_scores[class_id] &gt; 0.2:                 confidences.append(confidence)                 class_ids.append(class_id)                  cx, cy, w, h = row[0], row[1], row[2], row[3]                 left = int((cx - w/2) * x_factor)                 top = int((cy - h/2) * y_factor)                 width = int(w * x_factor)                 height = int(h * y_factor)                 box = np.array([left, top, width, height])                 boxes.append(box)      indices = cv2.dnn.NMSBoxes(boxes, confidences, 0.45, 0.45)     for i in indices:         box = boxes[i]         left = box[0]         top = box[1]         width = box[2]         height = box[3]         cv2.rectangle(frame, (left, top), (left + width, top + height), (255, 178, 50), 3)         label = \"{}:{:.2f}\".format(classes[class_ids[i]], confidences[i])         text_size = cv2.getTextSize(label, FONT_FACE, FONT_SCALE, 1)         dim, baseline = text_size[0], text_size[1]         cv2.rectangle(frame, (left, top), (left + dim[0], top + dim[1] + baseline), BLACK, cv2.FILLED)         cv2.putText(frame, label, (left, top + dim[1]), FONT_FACE, FONT_SCALE, YELLOW, 1, cv2.LINE_AA)      # Exibir o frame com os objetos detectados     cv2.imshow('Output', frame)     if cv2.waitKey(1) &amp; 0xFF == ord('q'):         break In\u00a0[\u00a0]: Copied! <pre># Liberar recursos\ncap.release()\ncv2.destroyAllWindows()\n</pre> # Liberar recursos cap.release() cv2.destroyAllWindows()"},{"location":"aulas/PDI/solucoes/index.html","title":"Index","text":""},{"location":"aulas/PDI/solucoes/index.html#solucao-dos-labs","title":"Solu\u00e7\u00e3o dos labs","text":"<p>Um guia para voc\u00eas consultarem as solu\u00e7\u00f5es poss\u00edveis dos desafios propostos nos laborat\u00f3rios desenvolvidos em aula. Lembre-se de que a pr\u00e1tica \u00e9 essencial para o aprendizado, ent\u00e3o tente resolver os exerc\u00edcios por conta pr\u00f3pria antes de consultar as solu\u00e7\u00f5es.</p>"},{"location":"aulas/PDI/solucoes/index.html#indice","title":"\u00cdndice","text":"<ul> <li>Lab01 - Intro PID</li> <li>Lab02 - Seguimenta\u00e7\u00e3o por pixel</li> <li>Lab03 - Histograma e equaliza\u00e7\u00e3o</li> <li>Lab04 - Filtros de Convolu\u00e7\u00e3o</li> <li>Lab05 - Espa\u00e7o de cor e contorno </li> <li>Lab06 - Transformada de Hough e morfologia</li> <li>Lab07 - Traking de objetos e movimento</li> <li>Lab08 - Relacionamento e opera\u00e7\u00f5es entre imagens</li> <li>Lab09 - FFT</li> <li>Lab10 - Medidas aproximadas</li> <li> <p>Lab11 - Transformada de watershed</p> </li> <li> <p>Lab12 - Template matching</p> </li> <li>Lab13 - Features</li> <li>Lab14 - Detector haar Cascade</li> <li>Lab15 - Event Mouse</li> <li>Lab16 - Detector dlib</li> <li>Lab17 - Mediapipe</li> <li>Lab18 - Yolo</li> </ul>"},{"location":"aulas/PDI/solucoes/index.html#gs-24","title":"GS-24","text":"<ul> <li>Solu\u00e7\u00e3o GS-24</li> </ul>"},{"location":"aulas/iot/ex0/index.html","title":"Index","text":""},{"location":"aulas/iot/ex0/index.html#from-zero-to-hero","title":"From Zero to Hero!!","text":"<p>Espero que estejam animados para mergulhar no mundo dos Sistemas Embarcados e IoT com programa\u00e7\u00e3o em C/C++ usando o Arduino. </p> <p>Para come\u00e7ar do jeito certo e com o p\u00e9 direito!</p> <p>Pratique com essa lista de exerc\u00edcios que vai ajud\u00e1-lo a dominar os conceitos b\u00e1sicos de C/C++, focando apenas na programa\u00e7\u00e3o e utilizando o Monitor Serial para entrada e sa\u00edda de dados, sem se preocupar com hardware Arduino, por enquanto.</p> <p>S\u00e3o exerc\u00edcios abrangendo temas para praticar e aprimorar suas habilidades de programa\u00e7\u00e3o, independentemente do n\u00edvel de experi\u00eancia.</p>"},{"location":"aulas/iot/ex0/index.html#exercicios-conceitos-fundamentais-sem-hardware","title":"Exercicios: Conceitos Fundamentais sem Hardware","text":"<p>Exercise</p> <p>\"Hello, World!\" no Monitor Serial Familiarize-se com o Arduino IDE e o Monitor Serial, escrevendo um programa simples que imprime \"Hello, World!\" no Monitor Serial.</p> <p>Progress</p> <p>Solu\u00e7\u00e3o...</p> <p>Dica: https://docs.arduino.cc/software/ide-v2/tutorials/ide-v2-serial-monitor.</p> <p>Exercise</p> <p>Vari\u00e1veis e Opera\u00e7\u00f5es Matem\u00e1ticas Crie um programa que recebe dois n\u00fameros inteiros do Monitor Serial, realiza opera\u00e7\u00f5es matem\u00e1ticas b\u00e1sicas (adi\u00e7\u00e3o, subtra\u00e7\u00e3o, multiplica\u00e7\u00e3o e divis\u00e3o) e exibe os resultados no Monitor Serial.</p> <p>Exercise</p> <p>Estruturas de Controle: if, else e switch-case Escreva um programa que receba um n\u00famero inteiro do Monitor Serial e, usando estruturas de controle, verifique se o n\u00famero \u00e9 par ou \u00edmpar, positivo ou negativo e imprima o resultado no Monitor Serial.</p> <p>Exercise</p> <p>Estruturas de Repeti\u00e7\u00e3o: for e while Desenvolva um programa que imprima no Monitor Serial os primeiros N n\u00fameros da sequ\u00eancia de Fibonacci, onde N \u00e9 um n\u00famero inteiro fornecido pelo usu\u00e1rio atrav\u00e9s do Monitor Serial.</p> <p>Exercise</p> <p>Fun\u00e7\u00f5es Crie um programa que utiliza fun\u00e7\u00f5es para converter temperaturas entre graus Celsius e Fahrenheit. O usu\u00e1rio deve inserir a temperatura e a escala desejada (C ou F) no Monitor Serial, e o programa deve retornar a temperatura convertida.</p> <p>Exercise</p> <p>Vetores e manipula\u00e7\u00e3o de dados Desenvolva um programa que recebe uma sequ\u00eancia de N n\u00fameros inteiros pelo Monitor Serial, armazena em um vetor, e calcula a m\u00e9dia, o maior e o menor n\u00famero. Imprima os resultados no Monitor Serial.</p> <p>Exercise</p> <p>Manipula\u00e7\u00e3o de Strings Escreva um programa que receba uma string do Monitor Serial e determine o n\u00famero de palavras, o n\u00famero de vogais e o n\u00famero de consoantes na string. Imprima os resultados no Monitor Serial.</p> <p>Exercise</p> <p>Ponteiros Crie um programa que recebe dois n\u00fameros inteiros do Monitor Serial e troque seus valores usando ponteiros. Imprima os valores antes e depois da troca no Monitor Serial.</p> <p>Exercise</p> <p>Estruturas (structs) e Tipos Definidos pelo Usu\u00e1rio Crie um programa que gerencia informa\u00e7\u00f5es de alunos, como nome, idade e notas. Utilize structs para armazenar as informa\u00e7\u00f5es e fun\u00e7\u00f5es para realizar opera\u00e7\u00f5es, como adicionar um aluno, remover um aluno, calcular a m\u00e9dia das notas e exibir as informa\u00e7\u00f5es dos alunos no Monitor Serial.</p>"},{"location":"aulas/iot/ex0/solucao.html","title":"Solucao","text":""},{"location":"aulas/iot/ex0/solucao.html#solucao-from-zero-to-hero","title":"Solu\u00e7\u00e3o From Zero to Hero!!","text":""},{"location":"aulas/iot/ex0/solucao.html#exercicio-1","title":"Exercicio 1","text":"<p>Exercise</p> <p>\"Hello, World!\" no Monitor Serial</p> <p>Familiarize-se com o Arduino IDE e o Monitor Serial, escrevendo um programa simples que imprime \"Hello, World!\" no Monitor Serial.</p> <pre><code>void setup() {\n  // Inicia a comunica\u00e7\u00e3o serial com o monitor em 9600 bps\n  Serial.begin(9600);\n}\n\nvoid loop() {\n\n  Serial.println(\"Hello, World!\");\n  delay(1000); // Aguarda 1 segundo\n}\n</code></pre> <p>Progress</p> <p>Continuar...</p>"},{"location":"aulas/iot/ex0/solucao.html#exercicio-2","title":"Exercicio 2","text":"<p>Exercise</p> <p>Vari\u00e1veis e Opera\u00e7\u00f5es Matem\u00e1ticas</p> <p>Crie um programa que recebe dois n\u00fameros inteiros do Monitor Serial, realiza opera\u00e7\u00f5es matem\u00e1ticas b\u00e1sicas (adi\u00e7\u00e3o, subtra\u00e7\u00e3o, multiplica\u00e7\u00e3o e divis\u00e3o) e exibe os resultados no Monitor Serial.</p> <pre><code>int num1, num2;\n\nvoid setup() {\n  Serial.begin(9600);\n}\n\nvoid loop() {\n    Serial.println(\"Digite o primeiro n\u00famero:\");\n    while (Serial.available() == 0) {} // Aguarda o primeiro n\u00famero\n    num1 = Serial.parseInt();\n\n    Serial.println(\"Digite o segundo n\u00famero:\");\n    while (Serial.available() == 0) {} // Aguarda o segundo n\u00famero\n    num2 = Serial.parseInt();\n\n    Serial.print(\"Soma: \");\n    Serial.println(num1 + num2);\n\n    Serial.print(\"Subtra\u00e7\u00e3o: \");\n    Serial.println(num1 - num2);\n\n    Serial.print(\"Multiplica\u00e7\u00e3o: \");\n    Serial.println(num1 * num2);\n\n    if (num2 != 0) {\n      Serial.print(\"Divis\u00e3o: \");\n      Serial.println(num1 / num2);\n    } else {\n      Serial.println(\"Divis\u00e3o por zero n\u00e3o permitida.\");\n    }\n    delay(1000); // Aguarda 1 segundo\n}\n</code></pre> <p>Progress</p> <p>Continuar...</p>"},{"location":"aulas/iot/ex0/solucao.html#exercicio-3","title":"Exercicio 3","text":"<p>Exercise</p> <p>Estruturas de Controle: if, else e switch-case</p> <p>Escreva um programa que receba um n\u00famero inteiro do Monitor Serial e, usando estruturas de controle, verifique se o n\u00famero \u00e9 par ou \u00edmpar, positivo ou negativo e imprima o resultado no Monitor Serial.</p> <pre><code>void setup() {\n    Serial.begin(9600);\n    Serial.println(\"Digite um n\u00famero inteiro:\");\n}\n\nvoid loop() {\n\n    if (Serial.available() &gt; 0) {\n        int num = Serial.parseInt();\n\n        if (num % 2 == 0) {\n            Serial.println(\"O n\u00famero \u00e9 par.\");\n        } else {\n            Serial.println(\"O n\u00famero \u00e9 \u00edmpar.\");\n        }\n\n        if (num &gt; 0) {\n            Serial.println(\"O n\u00famero \u00e9 positivo.\");\n        } else if (num &lt; 0) {\n            Serial.println(\"O n\u00famero \u00e9 negativo.\");\n        } else {\n            Serial.println(\"O n\u00famero \u00e9 zero.\");\n        }\n        Serial.println(\"Digite um n\u00famero inteiro:\");  \n    }\n}\n</code></pre> <p>Progress</p> <p>Continuar...</p>"},{"location":"aulas/iot/ex0/solucao.html#exercicio-4","title":"Exercicio 4","text":"<p>Exercise</p> <p>Estruturas de Repeti\u00e7\u00e3o: for e while</p> <p>Desenvolva um programa que imprima no Monitor Serial os primeiros N n\u00fameros da sequ\u00eancia de Fibonacci, onde N \u00e9 um n\u00famero inteiro fornecido pelo usu\u00e1rio atrav\u00e9s do Monitor Serial.</p> <pre><code>int n;\n\nvoid setup() {\n  Serial.begin(9600);\n  Serial.println(\"Digite o valor de N:\");\n}\n\nvoid loop() {\n  if (Serial.available() &gt; 0) {\n    n = Serial.parseInt();\n    int a = 0, b = 1, c;\n\n    Serial.print(\"Sequ\u00eancia de Fibonacci: \");\n    Serial.print(a);\n    Serial.print(\", \");\n    Serial.print(b);\n\n    for (int i = 2; i &lt; n; i++) {\n      c = a + b;\n      Serial.print(\", \");\n      Serial.print(c);\n      a = b;\n      b = c;\n    }\n    Serial.println();\n    Serial.println(\"Digite o valor de N:\");\n  }\n}\n</code></pre> <p>Progress</p> <p>Continuar...</p>"},{"location":"aulas/iot/ex0/solucao.html#exercicio-5","title":"Exercicio 5","text":"<p>Exercise</p> <p>Fun\u00e7\u00f5es</p> <p>Crie um programa que utiliza fun\u00e7\u00f5es para converter temperaturas entre graus Celsius e Fahrenheit. O usu\u00e1rio deve inserir a temperatura e a escala desejada (C ou F) no Monitor Serial, e o programa deve retornar a temperatura convertida.</p> <pre><code>float converteFahrenheit(float celsius) {\n  return celsius * 9.0 / 5.0 + 32;\n}\n\nfloat converteCelsius(float fahrenheit) {\n    float valor = (fahrenheit - 32) * 5.0 / 9.0;\n  return valor;\n}\n\nvoid setup() {\n  Serial.begin(9600);\n  Serial.println(\"Digite a temperatura e a escala (C ou F):\");\n}\n\nvoid loop() {\n  if (Serial.available() &gt; 0) {\n    float temp = Serial.parseFloat();\n    char scale = Serial.read();\n\n    if (scale == 'C' || scale == 'c') {\n      Serial.print(\"Temperatura em Fahrenheit: \");\n      Serial.println(converteFahrenheit(temp));\n    } else if (scale == 'F' || scale == 'f') {\n      Serial.print(\"Temperatura em Celsius: \");\n      Serial.println(converteCelsius(temp));\n    } else {\n      Serial.println(\"Escala inv\u00e1lida.\");\n    }\n  }\n}\n</code></pre> <p>Progress</p> <p>Continuar...</p>"},{"location":"aulas/iot/ex0/solucao.html#exercicio-6","title":"Exercicio 6","text":"<p>Exercise</p> <p>Vetores e manipula\u00e7\u00e3o de dados</p> <p>Desenvolva um programa que recebe uma sequ\u00eancia de N n\u00fameros inteiros pelo Monitor Serial, armazena em um vetor, e calcula a m\u00e9dia, o maior e o menor n\u00famero. Imprima os resultados no Monitor Serial.</p> <pre><code>#define TAMANHO_MAXIMO 100  // Defina um tamanho m\u00e1ximo para o vetor\n\nint vetor[TAMANHO_MAXIMO];  // Vetor de tamanho fixo\n\nvoid setup() {\n  Serial.begin(9600);\n  Serial.println(\"Digite o numero de elementos no vetor:\");\n}\n\nvoid lerElementos(int vetor[], int tamanho) {\n  for (int i = 0; i &lt; tamanho; i++) {\n    Serial.print(\"Digite o numero \");\n    Serial.print(i + 1);\n    Serial.print(\": \");\n\n    while (Serial.available() == 0) {} // Aguarda input\n    vetor[i] = Serial.parseInt();\n    Serial.println(vetor[i]);\n  }\n}\n\nfloat calcularMedia(int vetor[], int tamanho) {\n  int soma = 0;\n  for (int i = 0; i &lt; tamanho; i++) {\n    soma += vetor[i];\n  }\n  float media = (float)soma / tamanho;\n  return media;\n}\n\nint encontrarMaior(int vetor[], int tamanho) {\n  int maior = vetor[0];\n  for (int i = 1; i &lt; tamanho; i++) {\n    if (vetor[i] &gt; maior) {\n      maior = vetor[i];\n    }\n  }\n  return maior;\n}\n\nint encontrarMenor(int vetor[], int tamanho) {\n  int menor = vetor[0];\n  for (int i = 1; i &lt; tamanho; i++) {\n    if (vetor[i] &lt; menor) {\n      menor = vetor[i];\n    }\n  }\n  return menor;\n}\n\nvoid loop() {\n  if (Serial.available() &gt; 0) {\n    int n = Serial.parseInt();\n\n    if (n &gt; TAMANHO_MAXIMO) {\n      Serial.print(\"Numero de elementos escolhido excede o tamanho m\u00e1ximo permitido de \");\n      Serial.println(TAMANHO_MAXIMO);\n      n = TAMANHO_MAXIMO;\n    }\n\n    Serial.print(\"Numero de elementos: \");\n    Serial.println(n);\n\n    lerElementos(vetor, n);\n\n\n    float media = calcularMedia(vetor, n);\n    int maior = encontrarMaior(vetor, n);\n    int menor = encontrarMenor(vetor, n);\n\n    Serial.print(\"Media: \");\n    Serial.println(media);\n\n    Serial.print(\"Maior numero: \");\n    Serial.println(maior);\n\n    Serial.print(\"Menor numero: \");\n    Serial.println(menor);\n\n    Serial.println(\"Digite o numero de elementos no vetor:\");\n\n  }\n}\n</code></pre> <p>Progress</p> <p>Continuar...</p>"},{"location":"aulas/iot/ex0/solucao.html#exercicio-7","title":"Exercicio 7","text":"<p>Exercise</p> <p>Manipula\u00e7\u00e3o de Strings</p> <p>Escreva um programa que receba uma string do Monitor Serial e determine o n\u00famero de palavras, o n\u00famero de vogais e o n\u00famero de consoantes na string. Imprima os resultados no Monitor Serial.</p> <p>Tip</p> <p>Esse ex\u00e9rcicio n\u00e3o funcionou no tinkercad, mas no wokwi deu certo.</p> <pre><code>#define TAMANHO_MAXIMO 100;  // Defina um tamanho m\u00e1ximo para o vetor\n\nvoid setup() {\n  Serial.begin(9600);\n  Serial.println(\"Digite uma string:\");\n}\n// O `\\0` \u00e9 o caractere nulo que indica o fim da string\n// || \u00e9 o operador l\u00f3gico OU e &amp;&amp; \u00e9 o operador l\u00f3gico E\n\n#define TAMANHO_MAXIMO 100\n\nvoid setup() {\n  Serial.begin(9600);\n  Serial.println(\"Digite uma string:\");\n}\n\nvoid loop() {\n\n  if (Serial.available() &gt; 0) {\n    char palavras[TAMANHO_MAXIMO]; // Array para armazenar a string com um tamanho m\u00e1ximo de 100 caracteres\n\n    lerString(palavras, TAMANHO_MAXIMO);\n\n    int numPalavras = contarPalavras(palavras);\n    int numVogais = contarVogais(palavras);\n    int numConsoantes = contarConsoantes(palavras);\n\n    // Imprime os resultados no Monitor Serial\n    Serial.print(\"N\u00famero de palavras: \");\n    Serial.println(numPalavras);\n    Serial.print(\"N\u00famero de vogais: \");\n    Serial.println(numVogais);\n    Serial.print(\"N\u00famero de consoantes: \");\n    Serial.println(numConsoantes);\n\n    // Aguarda nova entrada do usu\u00e1rio\n    Serial.println(\"Digite outra string:\");\n  }\n}\n\n// Fun\u00e7\u00e3o que l\u00ea uma string da Serial e armazena em um array de caracteres\nvoid lerString(char buffer[], int maxLength) {\n  int index = 0;\n\n  while (true) {\n    if (Serial.available() &gt; 0) {   // Verifica se h\u00e1 dados dispon\u00edveis na porta serial\n      char receivedChar = Serial.read(); // L\u00ea o caractere recebido\n\n      if (receivedChar == '\\n') {  // Verifica se o caractere \u00e9 uma nova linha (Enter)\n        buffer[index] = '\\0';    // Termina a string com um caractere nulo\n        Serial.print(\"Voc\u00ea digitou: \");\n        Serial.println(buffer);  // Imprime a string recebida\n        break;  // Sai do loop\n      } else {\n        buffer[index] = receivedChar; // Armazena o caractere no array\n        index++;  // Incrementa o \u00edndice\n\n        if (index &gt;= maxLength - 1) {  // Limita o tamanho da string para evitar estouro de mem\u00f3ria\n          Serial.println(\"String muito longa!\");\n          buffer[index] = '\\0';  // Termina a string com um caractere nulo\n          break;  // Sai do loop\n        }\n      }\n    }\n  }\n}\n\n// Fun\u00e7\u00e3o que conta o n\u00famero de palavras em uma string, considerando que uma palavra \u00e9 uma sequ\u00eancia de letras min\u00fasculas\nint contarPalavras(char input[]) {\n  int numPalavras = 0;\n  bool novaPalavra = true;\n  for (int i = 0; input[i] != '\\0'; i++) {\n    char c = input[i];\n    if (c &gt;= 'a' &amp;&amp; c &lt;= 'z') {\n      if (novaPalavra) {\n        numPalavras++;\n        novaPalavra = false;\n      }\n    } else {\n      novaPalavra = true;\n    }\n  }\n  return numPalavras;\n}\n\n// Fun\u00e7\u00e3o que conta o n\u00famero de vogais em uma string \nint contarVogais(char input[]) {\n  int numVogais = 0;\n  for (int i = 0; input[i] != '\\0'; i++) {\n    char c = input[i];\n    if (c == 'a' || c == 'e' || c == 'i' || c == 'o' || c == 'u') {\n      numVogais++;\n    }\n  }\n  return numVogais;\n}\n\n// Fun\u00e7\u00e3o que conta o n\u00famero de consoantes em uma string\nint contarConsoantes(char input[]) {\n  int numConsoantes = 0;\n  for (int i = 0; input[i] != '\\0'; i++) {\n    char c = input[i];\n    if (c &gt;= 'a' &amp;&amp; c &lt;= 'z' &amp;&amp; !(c == 'a' || c == 'e' || c == 'i' || c == 'o' || c == 'u')) {\n      numConsoantes++;\n    }\n  }\n  return numConsoantes;\n}\n</code></pre> <p>Progress</p> <p>Continuar...</p>"},{"location":"aulas/iot/ex0/solucao.html#exercicio-8","title":"Exercicio 8","text":"<p>Exercise</p> <p>Ponteiros</p> <p>Crie um programa que recebe dois n\u00fameros inteiros do Monitor Serial e troque seus valores usando ponteiros. Imprima os valores antes e depois da troca no Monitor Serial.</p> <pre><code>void troca(int *a, int *b) {\n    int temp = *a;\n    *a = *b;\n    *b = temp;\n  }\n\n  int num1, num2;\n\n  void setup() {\n    Serial.begin(9600);\n    Serial.println(\"Digite o primeiro n\u00famero:\");\n  }\n\n  void loop() {\n    if (Serial.available() &gt; 0) {\n      num1 = Serial.parseInt();\n      Serial.println(\"Digite o segundo n\u00famero:\");\n\n      while (Serial.available() == 0) {} // Aguarda o segundo n\u00famero\n      num2 = Serial.parseInt();\n\n      Serial.print(\"Antes da troca: num1 = \");\n      Serial.print(num1);\n      Serial.print(\", num2 = \");\n      Serial.println(num2);\n\n      troca(&amp;num1, &amp;num2);\n\n      Serial.print(\"Depois da troca: num1 = \");\n      Serial.print(num1);\n      Serial.print(\", num2 = \");\n      Serial.println(num2);\n\n      while (true); // Pausa o programa ap\u00f3s a execu\u00e7\u00e3o\n    }\n  }\n</code></pre> <p>Progress</p> <p>Continuar...</p>"},{"location":"aulas/iot/ex0/solucao.html#exercicio-9","title":"Exercicio 9","text":"<p>Exercise</p> <p>Estruturas (structs) e Tipos Definidos pelo Usu\u00e1rio</p> <p>Crie um programa que gerencia informa\u00e7\u00f5es de alunos, como nome, idade e notas. Utilize structs para armazenar as informa\u00e7\u00f5es e fun\u00e7\u00f5es para realizar opera\u00e7\u00f5es, como adicionar um aluno, remover um aluno, calcular a m\u00e9dia das notas e exibir as informa\u00e7\u00f5es dos alunos no Monitor Serial.</p> <p>Tip</p> <p>Esse eu fiz com ajuda do gpt, n\u00e3o consegui testar pra saber se est\u00e1 funcionando....</p> <pre><code>struct Aluno {\n    String nome;\n    int idade;\n    float notas[3];\n  };\n\n  Aluno alunos[10];\n  int alunoCount = 0;\n\n  void adicionarAluno() {\n    if (alunoCount &lt; 10) {\n      Serial.println(\"Digite o nome do aluno:\");\n      while (Serial.available() == 0) {}\n      alunos[alunoCount].nome = Serial.readString();\n\n      Serial.println(\"Digite a idade do aluno:\");\n      while (Serial.available() == 0) {}\n      alunos[alunoCount].idade = Serial.parseInt();\n\n      for (int i = 0; i &lt; 3; i++) {\n        Serial.print(\"Digite a nota \");\n        Serial.print(i + 1);\n        Serial.println(\":\");\n        while (Serial.available() == 0) {}\n        alunos[alunoCount].notas[i] = Serial.parseFloat();\n      }\n\n      alunoCount++;\n    } else {\n      Serial.println(\"N\u00famero m\u00e1ximo de alunos alcan\u00e7ado.\");\n    }\n  }\n\n  void exibirAlunos() {\n    for (int i = 0; i &lt; alunoCount; i++) {\n      Serial.print(\"Nome: \");\n      Serial.println(alunos[i].nome);\n      Serial.print(\"Idade: \");\n      Serial.println(alunos[i].idade);\n      float media = 0;\n      for (int j = 0; j &lt; 3; j++) {\n        Serial.print(\"Nota \");\n        Serial.print(j + 1);\n        Serial.print(\": \");\n        Serial.println(alunos[i].notas[j]);\n        media += alunos[i].notas[j];\n      }\n      Serial.print(\"M\u00e9dia: \");\n      Serial.println(media / 3);\n    }\n  }\n\n  void setup() {\n    Serial.begin(9600);\n    Serial.println(\"Gerenciamento de alunos:\");\n    adicionarAluno();\n    adicionarAluno();\n    exibirAlunos();\n  }\n\n  void loop() {}\n</code></pre>"},{"location":"aulas/iot/ex1/index.html","title":"Index","text":""},{"location":"aulas/iot/ex1/index.html#o-que-esse-codigo-faz","title":"O que esse c\u00f3digo faz?","text":"<p>Este c\u00f3digo de exemplo demonstra como piscar um LED com arduino (blink led).</p>"},{"location":"aulas/iot/ex1/index.html#circuito-protoboard","title":"Circuito protoboard","text":""},{"location":"aulas/iot/ex1/index.html#codigo","title":"C\u00f3digo","text":"<pre><code>int led = 13; //defindo o valor 13 para a vari\u00e1vel led\n\nvoid setup(){\n    pinMode(led,OUTPUT); //declara led (pino 13 do arduino) como saida (OUTPUT)\n}\n\nvoid loop(){\n    digitalWrite(led, HIGH); //acende (HIGH) o led\n    delay(1000); //delay em milisegundos (1 seg)\n    digitalWrite(led, LOW); //apaga o led (LOW)\n    delay(1000); //delay em milisegundos\n}\n</code></pre> Circuito simulador"},{"location":"aulas/iot/ex1/index.html#links-para-download","title":"Links para Download","text":"<ul> <li> <p>C\u00f3digo arduino </p> </li> <li> <p>Thinkercad online</p> </li> <li> <p>SimulIDE</p> </li> </ul>"},{"location":"aulas/iot/ex2/index.html","title":"Index","text":""},{"location":"aulas/iot/ex2/index.html#o-que-esse-codigo-faz","title":"O que esse c\u00f3digo faz?","text":"<p>Este c\u00f3digo de exemplo demonstra como acender e apagar um LED em um intervalo de 100 milissegundos ao pressionar um bot\u00e3o com Arduino.</p>"},{"location":"aulas/iot/ex2/index.html#circuito-protoboard","title":"Circuito protoboard","text":""},{"location":"aulas/iot/ex2/index.html#codigo","title":"C\u00f3digo","text":"<pre><code>const int led = 13; //define o apelido led para o valor 13\nconst int botao = 5; //define o apelido botao para o valor 5\n\nvoid setup(){\n  pinMode(led, OUTPUT); //declara o pino13 (led) como sa\u00edda\n  pinMode(botao, INPUT_PULLUP); //declara o pino5 (botao) como entrada\n}\n\nvoid loop(){\n  // Faz a leitura do botao\n  if (digitalRead(botao) == LOW) {\n    digitalWrite(led, HIGH); //acende o led\n    delay(100); //delay em milissegundos\n    digitalWrite(led, LOW); //apaga o led\n    delay(100); //delay em milissegundos\n  }\n}\n</code></pre> Circuito simulador"},{"location":"aulas/iot/ex2/index.html#links-para-download","title":"Links para Download","text":"<ul> <li> <p>C\u00f3digo arduino</p> </li> <li> <p>Thinkercad online</p> </li> </ul>"},{"location":"aulas/iot/ex3/index.html","title":"Index","text":""},{"location":"aulas/iot/ex3/index.html#o-que-esse-codigo-faz","title":"O que esse c\u00f3digo faz?","text":"<p>Este c\u00f3digo de exemplo demonstra como controlar dois LEDs com Arduino usando um bot\u00e3o e um potenci\u00f4metro. Um LED acende e apaga em um intervalo de 100 milissegundos ao pressionar um bot\u00e3o, enquanto o outro LED acende e apaga no mesmo intervalo quando o valor do potenci\u00f4metro \u00e9 maior ou igual a 500.</p>"},{"location":"aulas/iot/ex3/index.html#circuito-protoboard","title":"Circuito protoboard","text":""},{"location":"aulas/iot/ex3/index.html#codigo","title":"C\u00f3digo","text":"<pre><code>const int led = 13; //define o apelido led para o valor 13\nconst int botao = 5; //define o apelido botao para o valor 5\nconst int ledPwm = 11; //define o apelido ledPwm para o valor 11\nconst int potAD = A0; //define o apelido potenciometro para o valor A0\n\nvoid setup(){\n  // Entradas e sa\u00eddas digitais\n  pinMode(led, OUTPUT); //declara o pino13 (led) como sa\u00edda\n  pinMode(botao, INPUT_PULLUP); //declara o pino5 (botao) como entrada\n\n  // Entradas e sa\u00eddas anal\u00f3gicas\n  pinMode(ledPwm, OUTPUT); //declara o pino11 (ledPwm) como sa\u00edda\n  pinMode(potAD, INPUT); //declara o pinoA0 (potenciometro) como entrada\n}\n\nvoid loop(){\n  // Faz a leitura do botao\n  if (digitalRead(botao) == LOW) {\n    digitalWrite(led, HIGH); //acende o led\n    delay(100); //delay em milissegundos\n    digitalWrite(led, LOW); //apaga o led\n    delay(100); //delay em milissegundos\n  }\n  // Faz a leitura anal\u00f3gica do potenciometro\n  int pot = analogRead(potAD);\n  if (pot &gt;= 500) {\n    digitalWrite(ledPwm, HIGH); //acende o led\n    delay(100); //delay em milissegundos\n    digitalWrite(ledPwm, LOW); //apaga o led\n    delay(100); //delay em milissegundos\n  }\n}\n</code></pre> Circuito simulador"},{"location":"aulas/iot/ex3/index.html#links-para-download","title":"Links para Download","text":"<ul> <li> <p>C\u00f3digo arduino</p> </li> <li> <p>Thinkercad online</p> </li> </ul>"},{"location":"aulas/iot/ex4/index.html","title":"Index","text":""},{"location":"aulas/iot/ex4/index.html#o-que-esse-codigo-faz","title":"O que esse c\u00f3digo faz?","text":"<p>Este c\u00f3digo de exemplo demonstra como controlar dois LEDs com Arduino usando um bot\u00e3o e um potenci\u00f4metro, substituindo o uso de <code>delay()</code> por <code>millis()</code>. Um LED alterna seu estado a cada 100 milissegundos ao pressionar um bot\u00e3o, enquanto o outro LED alterna seu estado no mesmo intervalo quando o valor do potenci\u00f4metro \u00e9 maior ou igual a 500.</p>"},{"location":"aulas/iot/ex4/index.html#circuito-protoboard","title":"Circuito protoboard","text":""},{"location":"aulas/iot/ex4/index.html#codigo","title":"C\u00f3digo","text":"<pre><code>const int led = 13; //define o apelido led para o valor 13\nconst int botao = 5; //define o apelido botao para o valor 5\nconst int ledPwm = 11; //define o apelido ledPwm para o valor 11\nconst int potAD = A0; //define o apelido potenciometro para o valor A0\n\nunsigned long tempo1 = 0, tempo2 = 0;\n\nvoid setup() {\n  // Entradas e sa\u00eddas digitais\n  pinMode(led, OUTPUT); //declara o pino13 (led) como sa\u00edda\n  pinMode(botao, INPUT_PULLUP); //declara o pino5 (botao) como entrada\n\n  // Entradas e sa\u00eddas anal\u00f3gicas\n  pinMode(ledPwm, OUTPUT); //declara o pino11 (ledPwm) como sa\u00edda\n  pinMode(potAD, INPUT); //declara o pinoA0 (potenciometro) como entrada\n}\n\nvoid loop() {\n  //usando millis no lugar do delay\n  if (millis() - tempo1 &gt;= 100){\n    tempo1 = millis(); \n    if (digitalRead(botao) == LOW){\n      digitalWrite(led, !digitalRead(led));    \n    }\n  }\n  // usando millis \n  int pot = analogRead(potAD);\n  if (millis() - tempo2 &gt;= 100 &amp;&amp; pot &gt;= 500){\n    tempo2 = millis(); \n    digitalWrite(ledPwm, !digitalRead(ledPwm));     \n  }\n}\n</code></pre> Circuito simulador"},{"location":"aulas/iot/ex4/index.html#links-para-download","title":"Links para Download","text":"<ul> <li> <p>C\u00f3digo arduino</p> </li> <li> <p>Thinkercad online</p> </li> </ul>"},{"location":"aulas/iot/ex5/index.html","title":"Index","text":""},{"location":"aulas/iot/ex5/index.html#o-que-esse-codigo-faz","title":"O que esse c\u00f3digo faz?","text":"<p>Este c\u00f3digo de exemplo demonstra como controlar dois LEDs com Arduino usando um bot\u00e3o e um potenci\u00f4metro. Um LED \u00e9 acionado por uma interrup\u00e7\u00e3o externa quando o bot\u00e3o \u00e9 pressionado, e o outro LED alterna seu estado quando o valor do potenci\u00f4metro \u00e9 maior ou igual a 500.</p>"},{"location":"aulas/iot/ex5/index.html#circuito-protoboard","title":"Circuito protoboard","text":""},{"location":"aulas/iot/ex5/index.html#codigo","title":"C\u00f3digo","text":"<pre><code>const int led = 13; //define o apelido led para o valor 13\nconst int botao = 2; //define o apelido botao para o valor 2\nconst int ledPwm = 11; //define o apelido ledPwm para o valor 11\nconst int potAD = A0; //define o apelido potenciometro para o valor A0\n\nvoid setup(){\n  // Entradas e sa\u00eddas digitais\n  pinMode(led, OUTPUT); //declara o pino13 (led) como sa\u00edda\n  pinMode(botao, INPUT_PULLUP); //declara o pino2 (botao) como entrada\n  // Entradas e sa\u00eddas anal\u00f3gicas\n  pinMode(ledPwm, OUTPUT); //declara o pino11 (ledPwm) como sa\u00edda\n  pinMode(potAD, INPUT); //declara o pinoA0 (potenciometro) como entrada\n\n  // Configura\u00e7\u00e3o da Interrup\u00e7\u00e3o\n  attachInterrupt(digitalPinToInterrupt(botao), interrupcaoPino2, RISING);  // Configura o pino2 como interrup\u00e7\u00e3o externa do tipo Rising (borda de LOW para HIGH)\n}\n\nvoid loop(){  \n  // Programa principal\n  int pot = analogRead(potAD);\n  if (pot &gt;= 500){\n    digitalWrite(ledPwm, !digitalRead(ledPwm)); \n    delay(100);    \n  } \n}\n\nvoid interrupcaoPino2() // Fun\u00e7\u00e3o de interrup\u00e7\u00e3o do pino2, \u00e9 executado quando o bot\u00e3o do pino2 \u00e9 pressionado\n{                    \n  digitalWrite(led, !digitalRead(led));\n}\n</code></pre> Circuito simulador"},{"location":"aulas/iot/ex5/index.html#links-para-download","title":"Links para Download","text":"<ul> <li> <p>C\u00f3digo arduino</p> </li> <li> <p>Thinkercad online</p> </li> </ul>"},{"location":"aulas/iot/ex6/index.html","title":"Index","text":""},{"location":"aulas/iot/ex6/index.html#o-que-esse-codigo-faz","title":"O que esse c\u00f3digo faz?","text":"<p>Este c\u00f3digo de exemplo demonstra como realizar a comunica\u00e7\u00e3o serial entre um arduino e um computador, neste exeplo vamos usar um script python.</p> <p></p>"},{"location":"aulas/iot/ex6/index.html#um-pouquinho-de-teoria","title":"Um pouquinho de teoria","text":"<ul> <li> <p><code>Defini\u00e7\u00e3o de comunica\u00e7\u00e3o serial</code>: A comunica\u00e7\u00e3o serial \u00e9 um m\u00e9todo de comunica\u00e7\u00e3o de dados em que os bits de informa\u00e7\u00f5es s\u00e3o transmitidos sequencialmente, um ap\u00f3s o outro, atrav\u00e9s de um \u00fanico canal de comunica\u00e7\u00e3o. \u00c9 uma abordagem simples e comum para transferir dados entre dispositivos, como microcontroladores e computadores.</p> </li> <li> <p><code>Taxa de transmiss\u00e3o (baud rate)</code>: A taxa de transmiss\u00e3o, ou baud rate, \u00e9 a velocidade na qual os bits s\u00e3o transmitidos atrav\u00e9s do canal de comunica\u00e7\u00e3o serial. \u00c9 medida em bits por segundo (bps). Taxas de transmiss\u00e3o comuns comumente utilizadas incluem 9600, 19200 e 115200 bps. A taxa de transmiss\u00e3o deve ser configurada corretamente em ambos os dispositivos de comunica\u00e7\u00e3o (transmissor e receptor) para garantir que os dados sejam transmitidos e recebidos com precis\u00e3o.</p> </li> <li> <p><code>Protocolos de comunica\u00e7\u00e3o serial</code>: Existem v\u00e1rios protocolos de comunica\u00e7\u00e3o serial dispon\u00edveis, cada um com suas pr\u00f3prias especifica\u00e7\u00f5es e caracter\u00edsticas. Alguns dos protocolos mais comuns incluem UART (Universal Asynchronous Receiver/Transmitter), SPI (Serial Peripheral Interface) e I2C (Inter-Integrated Circuit). Neste tutorial, estamos usando a comunica\u00e7\u00e3o UART atrav\u00e9s da porta serial dispon\u00edvel no Arduino.</p> </li> <li> <p><code>Aplica\u00e7\u00f5es da comunica\u00e7\u00e3o serial</code>: A comunica\u00e7\u00e3o serial \u00e9 amplamente utilizada em v\u00e1rias aplica\u00e7\u00f5es, como comunica\u00e7\u00e3o entre microcontroladores e perif\u00e9ricos (por exemplo, sensores, displays, etc.), comunica\u00e7\u00e3o entre computadores e dispositivos eletr\u00f4nicos (por exemplo, impressoras, modems, etc.), e at\u00e9 mesmo em redes de comunica\u00e7\u00e3o industrial (por exemplo, Modbus, Profibus, etc.).</p> </li> <li> <p><code>Vantagens da comunica\u00e7\u00e3o serial</code>: Algumas das principais vantagens da comunica\u00e7\u00e3o serial incluem sua simplicidade, baixo custo, capacidade de transmitir dados a longas dist\u00e2ncias e baixa contagem de pinos nos dispositivos envolvidos.</p> </li> </ul>"},{"location":"aulas/iot/ex6/index.html#codigos","title":"C\u00f3digos","text":"<p>O c\u00f3digo funciona como um \"Eco\", o script Python enviar\u00e1 a mensagem para o Arduino, que a ler\u00e1 e a enviar\u00e1 de volta. A mensagem ser\u00e1 exibida no terminal ou prompt de comando.</p> <pre><code>void setup() {\n  Serial.begin(9600); // Inicia a comunica\u00e7\u00e3o serial com uma taxa de transmiss\u00e3o de 9600 bps\n}\n\nvoid loop() {\n  if (Serial.available() &gt; 0) { // Verifica se h\u00e1 dados dispon\u00edveis para leitura\n    String message = Serial.readString(); // L\u00ea a mensagem enviada pelo Python\n    Serial.println(message); // Envia a mensagem de volta para o Python\n  }\n}\n</code></pre> <p>A segunda parte \u00e9 o c\u00f3digo python (lembre-se de criar um arduino_serial.py)</p> <pre><code>import serial\nimport time\n\ndef main():\n    ser = serial.Serial('COM3', 9600) # Altere 'COM3' para a porta serial do seu Arduino\n    time.sleep(2) # D\u00e1 tempo para a conex\u00e3o ser estabelecida\n\n    while True:\n        msg = input(\"Digite uma mensagem para enviar ao Arduino: \")\n        ser.write(msg.encode()) # Envia a mensagem para o Arduino\n        time.sleep(1) # Aguarda a resposta do Arduino\n\n        while ser.inWaiting() &gt; 0:\n            response = ser.readline().decode().strip() # L\u00ea a resposta do Arduino\n            print(\"Resposta do Arduino:\", response)\n\nif __name__ == \"__main__\":\n    main()\n</code></pre>"},{"location":"aulas/iot/ex6/index.html#executando-o-script","title":"Executando o script","text":"<ul> <li>Abra o terminal ou prompt de comando e navegue at\u00e9 a pasta onde o arquivo \"arduino_serial.py\" est\u00e1 localizado.</li> <li>Execute o seguinte comando: python arduino_serial.py</li> <li>Digite a mensagem que deseja enviar para o Arduino e pressione Enter.</li> <li>O script Python enviar\u00e1 a mensagem para o Arduino, que a ler\u00e1 e a enviar\u00e1 de volta. A mensagem ser\u00e1 exibida no terminal ou prompt de comando.</li> </ul>"},{"location":"aulas/iot/ex6/index.html#desafios","title":"Desafios","text":""},{"location":"aulas/iot/ex6/index.html#desafio-1","title":"Desafio 1","text":"<p>Fa\u00e7a os ajustes necess\u00e1rios para solucionar o checkpoint.</p>"},{"location":"aulas/iot/ex7/index.html","title":"Index","text":""},{"location":"aulas/iot/ex7/index.html#o-que-esse-codigo-faz","title":"O que esse c\u00f3digo faz?","text":"<p>Este c\u00f3digo de exemplo demonstra o uso de PWM</p>"},{"location":"aulas/iot/ex7/index.html#circuito-protoboard","title":"Circuito protoboard","text":""},{"location":"aulas/iot/ex7/index.html#codigo","title":"C\u00f3digo","text":"<pre><code>    const int ledPin = 11; // Pino do LED (suporta PWM)\n    const int potPin = A0; // Pino do potenci\u00f4metro\n\n    void setup() {\n      pinMode(ledPin, OUTPUT);\n    }\n\n    void loop() {\n      int sensorValue = analogRead(potPin); // L\u00ea o valor do potenci\u00f4metro\n      int pwmValue = map(sensorValue, 0, 1023, 0, 255); // Mapeia o valor lido para o intervalo do PWM (0-255)\n      analogWrite(ledPin, pwmValue); // Define o duty cycle do PWM\n      delay(10);\n    }\n</code></pre> Circuito simulador"},{"location":"aulas/iot/ex7/index.html#links-para-download","title":"Links para Download","text":"<ul> <li> <p>C\u00f3digo arduino</p> </li> <li> <p>Thinkercad online</p> </li> </ul>"},{"location":"aulas/iot/intro/index.html","title":"Index","text":"<p>Fa\u00e7a o download do pdf de Introdu\u00e7\u00e3o.</p> <ul> <li>arquivo pdf: Introdu\u00e7\u00e3o</li> </ul>"},{"location":"aulas/iot/intro/dicas.html","title":"Dicas","text":""},{"location":"aulas/iot/intro/dicas.html#introducao-a-eletricidade-basica","title":"Introdu\u00e7\u00e3o \u00e0 Eletricidade B\u00e1sica","text":"<p>A eletr\u00f4nica \u00e9 o ramo da f\u00edsica que estuda o fluxo de el\u00e9trons em materiais semicondutores, condutores e isolantes. Compreender os conceitos fundamentais de eletricidade \u00e9 essencial para o desenvolvimento de circuitos e sistemas eletr\u00f4nicos.</p>"},{"location":"aulas/iot/intro/dicas.html#conceitos-fundamentais","title":"Conceitos Fundamentais","text":"<ul> <li>Carga El\u00e9trica ( Q ): Propriedade das part\u00edculas que determina as intera\u00e7\u00f5es eletromagn\u00e9ticas. Medida em coulombs (C).</li> <li>Corrente El\u00e9trica ( I ): Fluxo de cargas el\u00e9tricas atrav\u00e9s de um condutor. Medida em amperes (A).</li> </ul> <p>$$   I = \\frac{dQ}{dt}   $$</p> <ul> <li>Tens\u00e3o El\u00e9trica (Diferen\u00e7a de Potencial,  V ): Energia potencial el\u00e9trica por unidade de carga. Medida em volts (V).</li> <li>Resist\u00eancia El\u00e9trica ( R ): Oposi\u00e7\u00e3o ao fluxo de corrente em um material. Medida em ohms (\u03a9).</li> </ul>"},{"location":"aulas/iot/intro/dicas.html#lei-de-ohm","title":"Lei de Ohm","text":"<p>A rela\u00e7\u00e3o entre tens\u00e3o, corrente e resist\u00eancia \u00e9 dada pela Lei de Ohm:</p> <p>$$   V = R \\times I   $$</p> <p>Onde:</p> <ul> <li> V : Tens\u00e3o em volts (V)</li> <li> I : Corrente em amperes (A)</li> <li> R : Resist\u00eancia em ohms (\u03a9)</li> </ul>"},{"location":"aulas/iot/intro/dicas.html#simuladores-eletronicos","title":"Simuladores Eletr\u00f4nicos","text":"<p>Os simuladores eletr\u00f4nicos s\u00e3o ferramentas essenciais para projetar, testar e validar circuitos antes da montagem f\u00edsica. Eles permitem economizar tempo e recursos, identificando poss\u00edveis problemas antecipadamente.</p>"},{"location":"aulas/iot/intro/dicas.html#principais-simuladores","title":"Principais Simuladores","text":"<ul> <li>Wokwi: Simulador online gratuito que permite simular microcontroladores como Arduino, ESP32 e Raspberry Pi Pico, al\u00e9m de diversos componentes eletr\u00f4nicos.</li> </ul> <p>Wokwi - Simulador Online</p> <ul> <li>SimulIDE: Simulador offline em tempo real para eletr\u00f4nica, microcontroladores e Arduino. \u00c9 uma ferramenta leve que oferece simula\u00e7\u00e3o de circuitos anal\u00f3gicos e digitais.</li> </ul> <p>Site Oficial do SimulIDE</p> <ul> <li> <p>SPICE (Simulation Program with Integrated Circuit Emphasis): Um padr\u00e3o da ind\u00fastria para simula\u00e7\u00e3o de circuitos anal\u00f3gicos e digitais.</p> </li> <li> <p>LTspice: Gratuito, oferecido pela Analog Devices.     Download LTspice</p> </li> <li> <p>Proteus: Software que combina simula\u00e7\u00e3o de circuitos com simula\u00e7\u00e3o de microcontroladores.</p> </li> </ul> <p>Site Oficial do Proteus</p> <ul> <li>Tinkercad Circuits: Simulador online gratuito, ideal para iniciantes.</li> </ul> <p>Tinkercad Circuits</p>"},{"location":"aulas/iot/intro/dicas.html#vantagens-do-uso-de-simuladores","title":"Vantagens do Uso de Simuladores","text":"<ul> <li>Economia de Recursos: Evita desperd\u00edcio de componentes e materiais.</li> <li>Seguran\u00e7a: Permite testar circuitos sem risco de danos f\u00edsicos.</li> <li>An\u00e1lise Detalhada: Possibilidade de visualizar formas de onda, correntes e tens\u00f5es em diferentes pontos do circuito.</li> <li>Itera\u00e7\u00e3o R\u00e1pida: Facilita modifica\u00e7\u00f5es e otimiza\u00e7\u00f5es no projeto.</li> </ul>"},{"location":"aulas/iot/intro/dicas.html#protoboard","title":"Protoboard","text":"<p>A protoboard \u00e9 uma plataforma de prototipagem sem solda utilizada em eletr\u00f4nica para montar circuitos tempor\u00e1rios e testar configura\u00e7\u00f5es antes da implementa\u00e7\u00e3o final. Sua estrutura interna \u00e9 composta por trilhas condutoras de metal organizadas em linhas e colunas, permitindo conex\u00f5es r\u00e1pidas e reconfigur\u00e1veis entre componentes.</p>"},{"location":"aulas/iot/intro/dicas.html#estrutura-interna","title":"Estrutura Interna","text":"<ul> <li>Barramentos de Alimenta\u00e7\u00e3o: Localizados nas extremidades da protoboard, esses barramentos s\u00e3o utilizados para distribuir as tens\u00f5es de alimenta\u00e7\u00e3o e terra (GND) ao longo da placa. \u00c9 comum que sejam separados no meio, exigindo pontes de conex\u00e3o para continuidade el\u00e9trica.</li> <li>\u00c1reas de Conex\u00e3o: No centro, a protoboard possui grupos de cinco furos conectados eletricamente em colunas, permitindo a inser\u00e7\u00e3o de terminais de componentes e jumpers para interliga\u00e7\u00e3o.</li> </ul>"},{"location":"aulas/iot/intro/dicas.html#boas-praticas-de-utilizacao","title":"Boas Pr\u00e1ticas de Utiliza\u00e7\u00e3o","text":"<ul> <li>Organiza\u00e7\u00e3o dos Componentes: Posicione os componentes de maneira l\u00f3gica para minimizar o comprimento dos jumpers e reduzir interfer\u00eancias eletromagn\u00e9ticas. Componentes similares devem ser agrupados para facilitar a an\u00e1lise do circuito.</li> <li>Integridade das Conex\u00f5es: Utilize jumpers de qualidade e evite a inser\u00e7\u00e3o excessiva de componentes nos mesmos pontos para prevenir desgaste dos contatos internos, que pode levar a mau funcionamento devido a conex\u00f5es intermitentes.</li> <li>Desacoplamento de Alimenta\u00e7\u00e3o: Em circuitos com componentes sens\u00edveis ou de alta velocidade, adicione capacitores de desacoplamento pr\u00f3ximos aos pinos de alimenta\u00e7\u00e3o dos CI's para reduzir ru\u00eddos e instabilidades causadas por flutua\u00e7\u00f5es na tens\u00e3o de alimenta\u00e7\u00e3o.</li> <li>Limita\u00e7\u00f5es: Evite utilizar a protoboard para circuitos de alta frequ\u00eancia ou correntes elevadas, pois a indut\u00e2ncia e capacit\u00e2ncia parasitas podem afetar o desempenho do circuito.</li> </ul> <p>Tip</p> <p>Para um guia detalhado sobre a utiliza\u00e7\u00e3o eficiente da protoboard, consulte: https://portal.vidadesilicio.com.br/protoboard/</p>"},{"location":"aulas/iot/intro/dicas.html#chaves-e-botoes","title":"Chaves e Bot\u00f5es","text":"<p>Chaves e bot\u00f5es s\u00e3o componentes eletromec\u00e2nicos utilizados para controlar o fluxo de corrente em um circuito, funcionando como dispositivos de entrada em sistemas digitais.</p>"},{"location":"aulas/iot/intro/dicas.html#consideracoes-tecnicas","title":"Considera\u00e7\u00f5es T\u00e9cnicas","text":"<ul> <li>Tipos de Chaves: Existem diversos tipos, como SPST (Single Pole Single Throw), SPDT (Single Pole Double Throw), DPDT (Double Pole Double Throw), cada um adequado para aplica\u00e7\u00f5es espec\u00edficas conforme a necessidade de contatos e configura\u00e7\u00f5es de circuito.</li> <li>Debouncing: Devido \u00e0s caracter\u00edsticas mec\u00e2nicas, ao acionar uma chave ou bot\u00e3o, podem ocorrer m\u00faltiplos contatos r\u00e1pidos (bounce), gerando ru\u00eddos no sinal. \u00c9 importante implementar t\u00e9cnicas de debouncing, seja por hardware (capacitores, resistores) ou software (algoritmos de filtragem), para garantir a estabilidade do sinal de entrada.</li> <li>Pull-up e Pull-down Resistores: Utilizados para definir um n\u00edvel l\u00f3gico definido quando a chave est\u00e1 aberta, prevenindo estados flutuantes que podem causar comportamento indeterminado no circuito digital.</li> </ul> <p>Tip</p> <p>Para aprofundar-se no tema de chaves e bot\u00f5es, acesse: https://www.robocore.net/tutoriais/introducao-a-chaves-e-botoes</p>"},{"location":"aulas/iot/intro/dicas.html#leds","title":"LEDs","text":"<p>Os LEDs (Light Emitting Diodes) s\u00e3o dispositivos semicondutores que emitem luz quando polarizados diretamente. S\u00e3o utilizados nas mais diversas aplica\u00e7\u00f5es do nosso dia-a-dia como indicadores luminosos em circuitos eletr\u00f4nicos.</p>"},{"location":"aulas/iot/intro/dicas.html#caracteristicas-e-utilizacao","title":"Caracter\u00edsticas e Utiliza\u00e7\u00e3o","text":"<ul> <li>Polaridade: LEDs possuem anodo (+) e catodo (-). A corrente deve fluir do anodo para o catodo; a invers\u00e3o de polaridade impede a condu\u00e7\u00e3o e pode danificar o componente.</li> <li>Tens\u00e3o e Corrente: Cada LED possui uma tens\u00e3o direta ($ V_{\\text{LED}} ) espec\u00edfica, geralmente entre 1,8V e 3,3V, e uma corrente nominal ( I_{\\text{LED}} $), tipicamente 10mA a 20mA.</li> </ul>"},{"location":"aulas/iot/intro/dicas.html#calculo-do-resistor-limitador","title":"C\u00e1lculo do Resistor Limitador","text":"<p>Para limitar a corrente e proteger o LED, calcula-se o resistor em s\u00e9rie:</p> <p>$$   R = \\frac{V_{fonte} - V_{LED}}{I_{LED}}   $$</p> <p>Onde:</p> <ul> <li>$ V_{\\text{fonte}} $: Tens\u00e3o da fonte de alimenta\u00e7\u00e3o.</li> <li>$ V_{\\text{LED}} $: Queda de tens\u00e3o no LED.</li> <li>$ I_{\\text{LED}} $: Corrente desejada atrav\u00e9s do LED.</li> </ul> <p>Exemplo: Para um LED com $ V_{\\text{LED}} = 2V $ alimentado por uma fonte de 5V e corrente de 15mA:</p> <p>$$   R = \\frac{5V - 2V}{15mA} = 200 \\Omega   $$</p> <p>Nesse caso o valor comercial \u00e9 $R = 220 \\Omega $.</p>"},{"location":"aulas/iot/intro/dicas.html#aplicacoes-avancadas","title":"Aplica\u00e7\u00f5es Avan\u00e7adas","text":"<ul> <li>Controle por PWM: A modula\u00e7\u00e3o por largura de pulso permite controlar a intensidade luminosa do LED, variando o ciclo de trabalho do sinal de controle.</li> <li>Multiplexa\u00e7\u00e3o: Em sistemas com m\u00faltiplos LEDs, a multiplexa\u00e7\u00e3o permite controlar v\u00e1rios LEDs com menos pinos do microcontrolador, acionando-os em sequ\u00eancias r\u00e1pidas para criar a ilus\u00e3o de ilumina\u00e7\u00e3o cont\u00ednua.</li> <li>Matrizes de LEDs: Utilizadas em displays e pain\u00e9is, exigem t\u00e9cnicas espec\u00edficas de controle, como varredura de linhas e colunas, e cuidados com corrente total e dissipa\u00e7\u00e3o de calor.</li> </ul> <p>Tip</p> <p>Para mais detalhes sobre LEDs e circuitos associados, visite: https://www.makerhero.com/blog/aprenda-a-piscar-um-led-com-arduino/</p>"},{"location":"aulas/iot/intro/dicas.html#sensores-e-atuadores","title":"Sensores e Atuadores","text":"<p>Os sensores s\u00e3o dispositivos que detectam eventos ou mudan\u00e7as no ambiente f\u00edsico e fornecem uma sa\u00edda correspondente, geralmente sob a forma de um sinal el\u00e9trico. Atuadores convertem sinais el\u00e9tricos em a\u00e7\u00e3o f\u00edsica, permitindo ao sistema interagir com o ambiente.</p>"},{"location":"aulas/iot/intro/dicas.html#sensores","title":"Sensores","text":"<ul> <li>Tipos Comuns:</li> <li>Temperatura: Termistores, termopares, sensores digitais (DS18B20).</li> <li>Luminosidade: Fotoresistores (LDR), fotodiodos, fototransistores.</li> <li>Umidade: Sensores capacitivos e resistivos.</li> <li>Press\u00e3o: Sensores piezorresistivos, piezoel\u00e9tricos.</li> </ul>"},{"location":"aulas/iot/intro/dicas.html#atuadores","title":"Atuadores","text":"<ul> <li>Tipos Comuns:</li> <li>Motores DC: Convers\u00e3o de energia el\u00e9trica em movimento rotacional; requerem circuitos de controle como pontes H para revers\u00e3o de sentido.</li> <li>Servomotores: Oferecem controle preciso de posi\u00e7\u00e3o angular; controlados via sinal PWM espec\u00edfico.</li> <li>Rel\u00e9s: Permitem o acionamento de cargas de alta pot\u00eancia isolando o circuito de controle.</li> <li>Buzzer: Dispositivos piezoel\u00e9tricos utilizados para gerar som; podem ser controlados por sinais digitais ou anal\u00f3gicos.</li> </ul>"},{"location":"aulas/iot/intro/introarduino.html","title":"Introarduino","text":""},{"location":"aulas/iot/intro/introarduino.html#conceitos-basicos-e-introdutorios","title":"Conceitos b\u00e1sicos e introdut\u00f3rios","text":"<p>A programa\u00e7\u00e3o arduino n\u00e3o \u00e9 complicada, vou apresentar alguns conceitos importante relacionados a software, ferramentas e hardware para te ajudar a embarcar nesse universo.</p>"},{"location":"aulas/iot/intro/introarduino.html#placa-arduino","title":"Placa Arduino","text":"<p>Existem diversas placas e vers\u00f5es de Arduinos, vamos conhecer o mais simples e famoso, o Arduino UNO. Essa placa possui pinos que podem ser configurados como entradas e saidas para sensores atuadores ou para comunica\u00e7\u00e3o com outros sistemas de hardwares, como mostra a figura:</p> <p></p> <ol> <li>Microcontrolador - este \u00e9 o c\u00e9rebro de um Arduino, \u00e9 nele que carregamos os programas. Pense nisso como um min\u00fasculo computador, projetado para executar apenas um n\u00famero espec\u00edfico de coisas.</li> <li>Porta USB - usada para conectar sua placa Arduino a um computador.</li> <li>Chip USB para Serial - o USB para Serial, respons\u00e1vel por fazer a convers\u00e3o de protocolos, \u00e9 um componente importante, pois \u00e9 o que torna poss\u00edvel programar e comunicar a placa Arduino a partir do seu computador. </li> <li>Pinos digitais - pinos que usam l\u00f3gica digital (0,1 ou LOW/HIGH). Comumente usado para chaves e para ligar/desligar um LED.</li> <li>Pinos anal\u00f3gicos - pinos que podem ler valores anal\u00f3gicos em uma resolu\u00e7\u00e3o de 10 bits (0-1023).</li> <li>Pinos de 5V / 3,3V - esses pinos s\u00e3o usados para alimentar (energia) componentes externos.</li> <li>GND - tamb\u00e9m conhecido como terra, negativo, Ground, \u00e9 utilizado para completar um circuito, onde o n\u00edvel el\u00e9trico est\u00e1 em 0 volt.</li> <li>VIN - significa Voltage In, onde voc\u00ea pode conectar fontes de alimenta\u00e7\u00e3o externas.</li> </ol>"},{"location":"aulas/iot/intro/introarduino.html#pinagem","title":"Pinagem","text":"<p>A placa do Arduino UNO possui 14 pinos que podem ser configurados como Entrada/Saida (INPUT/OUTPUT) Digitai, 6 pinos de entrada Analogica com resolu\u00e7\u00e3o de 10 bits, Alguns pinos podem ser configurados para fun\u00e7\u00f5es especificas como Serial, PWM, SPI, TWI(I2C), ISR entre outros...   </p> <p></p>"},{"location":"aulas/iot/intro/introarduino.html#software-embarcado","title":"Software Embarcado","text":"<p>O software embarcado \u00e9 o programa que define o funcionamento de um sistema embarcado, ou sej\u00e1, \u00e9 o c\u00f3digo que fica gravado no chip da placa Arduino. Ele \u00e9 projetado para executar tarefas espec\u00edficas, com um alto grau de efici\u00eancia e confiabilidade. De forma geral, a estrutura de um c\u00f3digo segue um padr\u00e3o, que pode ser dividido em tr\u00eas partes principais:</p> <ol> <li>Inicializa\u00e7\u00e3o: Nesta etapa, o c\u00f3digo realiza a configura\u00e7\u00e3o inicial dos perif\u00e9ricos, como sensores e atuadores, e estabelece a comunica\u00e7\u00e3o com outros dispositivos ou sistemas. Isso inclui a configura\u00e7\u00e3o de pinos de entrada e sa\u00edda, taxas de comunica\u00e7\u00e3o, entre outros, no Arduino inclue a \"void setup()\".</li> <li>La\u00e7o de Repeti\u00e7\u00e3o Infinito: O la\u00e7o infinito, tamb\u00e9m conhecido no Arduino como \"void loop()\", \u00e9 o cora\u00e7\u00e3o do software embarcado. Ele \u00e9 respons\u00e1vel por manter o programa em execu\u00e7\u00e3o cont\u00ednua, permitindo que o sistema embarcado execute suas tarefas de forma repetitiva e ininterrupta.</li> <li>Interrup\u00e7\u00f5es: As interrup\u00e7\u00f5es s\u00e3o eventos que ocorrem de forma ass\u00edncrona ao la\u00e7o infinito, permitindo que o software embarcado responda a eventos externos ou internos, como sinais de sensores ou temporizadores. Esses eventos s\u00e3o geralmente tratados por fun\u00e7\u00f5es espec\u00edficas chamadas rotinas de servi\u00e7o de interrup\u00e7\u00e3o (ISR). </li> </ol> <p>Neste exemplo, a fun\u00e7\u00e3o \"setup()\" \u00e9 respons\u00e1vel pela inicializa\u00e7\u00e3o, enquanto a fun\u00e7\u00e3o \"loop()\" cont\u00e9m as tarefas a serem executadas repetidamente no la\u00e7o infinito.</p> <p><pre><code>int led = 13;\n\nvoid setup(){\n    pinMode(led,OUTPUT);\n}\n\nvoid loop(){\n    digitalWrite(led, HIGH); \n    delay(1000); \n    digitalWrite(led, LOW); \n    delay(1000); \n}\n</code></pre> A representa\u00e7\u00e3o deste programa pode ser visualizada na figura abaixo: </p> <p></p> <p>Para saber mais desse exemplo acesse: <code>Laborat\u00f3rio -&gt; IoT e Sistemas Embarcados --&gt; Blink led</code></p>"},{"location":"aulas/iot/intro/introarduino.html#a-linguagem-arduino","title":"A linguagem arduino","text":"<p>A linguagem Arduino \u00e9 propria, MAS \u00e9 baseada em C/C++ e simplifica a programa\u00e7\u00e3o de microcontroladores atrav\u00e9s de um ambiente de desenvolvimento integrado (IDE) amig\u00e1vel e simples.</p> <p>Agumas semelhan\u00e7as com as linguagens C/C++ (e outras tambem...) s\u00e3o:</p> <ul> <li> <p>Sintaxes e Estrutura b\u00e1sica: A estrutura b\u00e1sica do c\u00f3digo Arduino, incluindo a defini\u00e7\u00e3o de fun\u00e7\u00f5es, vari\u00e1veis, constantes e operadores, \u00e9 semelhante \u00e0 encontrada em C e C++.</p> </li> <li> <p>Fun\u00e7\u00f5es e bibliotecas: A linguagem Arduino permite a utiliza\u00e7\u00e3o de fun\u00e7\u00f5es e bibliotecas padr\u00e3o de C/C++, al\u00e9m de bibliotecas espec\u00edficas para Arduino.</p> </li> <li> <p>Ponteiros e aloca\u00e7\u00e3o de mem\u00f3ria: Assim como em C e C++, a linguagem Arduino permite o uso de ponteiros e a manipula\u00e7\u00e3o de mem\u00f3ria.</p> </li> </ul>"},{"location":"aulas/iot/intro/introarduino.html#entendo-elementos-basicos-de-codigo","title":"Entendo elementos b\u00e1sicos de c\u00f3digo","text":"<p>De forma geral a programa\u00e7\u00e3o de sistemas embarcados envolve o desenvolvimento de aplica\u00e7\u00f5es que interagem com o mundo f\u00edsico atrav\u00e9s de sensores e atuadores. Para compreender e dominar essas intera\u00e7\u00f5es, \u00e9 crucial aprender sobre os conceitos fundamentais, como Entrada e Sa\u00edda Digital, Debounce de bot\u00e3o Digital, Entrada e Sa\u00edda Anal\u00f3gica, Interrup\u00e7\u00e3o Externa e Interfaces de comunica\u00e7\u00e3o como UART/I2C/SPI (Comunica\u00e7\u00e3o Serial).</p>"},{"location":"aulas/iot/intro/introarduino.html#saida-digital","title":"Sa\u00edda Digital","text":"<p>A sa\u00edda digital \u00e9 uma forma b\u00e1sica de comunica\u00e7\u00e3o com componentes externos, como LEDs e rel\u00e9s. Os pinos de sa\u00edda digital podem ser configurados para atuar como fonte ou dreno de corrente, dependendo da necessidade do circuito. Os sinais s\u00e3o transmitidos como valores discretos, geralmente <code>0 (LOW) e 1 (HIGH)</code>. No Arduino, \u00e9 poss\u00edvel configurar os pinos de entrada/sa\u00edda como sa\u00edda digital usando a fun\u00e7\u00e3o pinMode() e controlar o estado do pino usando a fun\u00e7\u00e3o <code>digitalWrite()</code>.</p> Dica <p>Veja o lab Blink led</p>"},{"location":"aulas/iot/intro/introarduino.html#entrada-digital","title":"Entrada Digital","text":"<p>A entrada digital permite que um microcontrolador leia sinais digitais externos, geralmente <code>0 (LOW) e 1 (HIGH)</code>. No Arduino, os pinos de entrada/sa\u00edda podem ser configurados como entrada digital usando a fun\u00e7\u00e3o pinMode() e ler o estado do pino com a fun\u00e7\u00e3o <code>digitalRead()</code>.</p> Dica <p>Veja o lab Led bot\u00e3o</p>"},{"location":"aulas/iot/intro/introarduino.html#entrada-analogica","title":"Entrada Anal\u00f3gica","text":"<p>A convers\u00e3o de sinais anal\u00f3gicos em valores digitais \u00e9 realizada por um conversor anal\u00f3gico-digital (ADC) presente no microcontrolador. O ADC possui uma resolu\u00e7\u00e3o espec\u00edfica, geralmente 10 bits no Arduino UNO, que determina a quantidade de valores poss\u00edveis para representar o sinal anal\u00f3gico.</p> Dica <p>Veja o lab Bot\u00e3o pod led</p>"},{"location":"aulas/iot/intro/introarduino.html#pwm-saida-analogica","title":"PWM (Sa\u00edda \"Anal\u00f3gica\")","text":"<p>A t\u00e9cnica PWM permite controlar a energia entregue a dispositivos externos atrav\u00e9s da varia\u00e7\u00e3o do tempo de ativa\u00e7\u00e3o do sinal digital. A frequ\u00eancia do sinal PWM \u00e9 geralmente fixa, enquanto o duty cycle (raz\u00e3o entre o tempo de ativa\u00e7\u00e3o e o per\u00edodo do sinal) varia entre 0 e 100%. No Arduino UNO esse valor \u00e9 definido em 8bits, ou seja, de 0 at\u00e9 255.</p> Dica <p>Veja o lab PWM</p>"},{"location":"aulas/iot/intro/introarduino.html#interrupcao-externa","title":"Interrup\u00e7\u00e3o Externa","text":"<p>As interrup\u00e7\u00f5es externas podem ser configuradas para serem disparadas em diferentes condi\u00e7\u00f5es, como mudan\u00e7a de estado, n\u00edvel alto ou baixo e bordas de subida ou descida. Ao ser disparada, a interrup\u00e7\u00e3o executa a rotina de tratamento de interrup\u00e7\u00e3o, interrompendo temporariamente o fluxo principal do programa.</p> Dica <p>Veja o lab Interrup\u00e7\u00e3o de pino</p>"},{"location":"aulas/iot/intro/introarduino.html#o-uso-de-delay-em-sistemas-embarcados","title":"O uso de delay em sistemas embarcados","text":"<p>Evitar delays \u00e9 fundamental para garantir o bom funcionamento e a efici\u00eancia do sistema embarcado. O uso excessivo de delays pode resultar em um desempenho inadequado e na incapacidade de responder a eventos em tempo real. Ao inv\u00e9s de utilizar a fun\u00e7\u00e3o delay(), opte por utilizar millis() e t\u00e9cnicas de programa\u00e7\u00e3o n\u00e3o bloqueantes para criar temporiza\u00e7\u00f5es.</p> Dica <p>Veja o lab Fun\u00e7\u00e3o millis    </p>"},{"location":"aulas/iot/intro/introarduino.html#uart-comunicacao-serial","title":"UART (Comunica\u00e7\u00e3o Serial)","text":"<p>UART (Universal Asynchronous Receiver-Transmitter) \u00e9 um protocolo de comunica\u00e7\u00e3o serial que permite a transmiss\u00e3o de dados entre dispositivos de forma ass\u00edncrona, sem a necessidade de um clock de refer\u00eancia compartilhado. No Arduino, a comunica\u00e7\u00e3o serial \u00e9 geralmente implementada usando as fun\u00e7\u00f5es <code>Serial.begin(), Serial.print(), Serial.println() e Serial.read()</code>.</p> Dica <p>Veja o lab Comunica\u00e7\u00e3o Serial </p>"},{"location":"aulas/iot/intro/introarduino.html#referencias","title":"Refer\u00eancias","text":"<p>A comunidade Arduino \u00e9 muito grande e gera muito material de qualidade, \u00e9 facil encontrar foruns, tutoriais e videos que te auxiliam no aprendizado. De toda a forma, abaixo tem alguns link da documenta\u00e7\u00e3o oficial que podem te ajudar.</p> <ul> <li>https://www.arduino.cc/reference/en/?_gl=1*19zvap6*_ga*MTA5MDMxODM2My4xNjgyNTEwNDg3*_ga_NEXN8H46L5*MTY4MjUyNzkzMS4yLjEuMTY4MjUyODg0Ni4wLjAuMA..</li> <li>https://docs.arduino.cc/learn/starting-guide/getting-started-arduino#general</li> <li></li> </ul>"},{"location":"aulas/iot/lab1/index.html","title":"Index","text":""},{"location":"aulas/iot/lab1/index.html#lab1-desafios","title":"Lab1 - Desafios","text":"<p>Os desafios 1, 2 e 3 devem ser entregues e comp\u00f5em parte da nota do CP6.</p>"},{"location":"aulas/iot/lab1/index.html#desafio-1","title":"Desafio 1","text":"<p>Com base no exemplo Blink led, fa\u00e7a:</p> <p></p> <p>Monte um circuito com 2 LEDs, usando como refer\u00eancia a imagem acima. Escreva um c\u00f3digo que fa\u00e7a os LEDs piscarem de forma s\u00edncrona a cada 0,5 segundos.</p>"},{"location":"aulas/iot/lab1/index.html#desafio-2","title":"Desafio 2","text":"<p>Agora, fa\u00e7a os LEDs acenderem conforme a carta de tempo abaixo. Onde:</p> <p>1 = n\u00edvel l\u00f3gico alto (HIGH)</p> <p>0 = n\u00edvel l\u00f3gico baixo (LOW)</p> <p>delay = 500ms</p> <p></p>"},{"location":"aulas/iot/lab1/index.html#desafio-3","title":"Desafio 3","text":"<p>Utilizando o Buzzer, fa\u00e7a seu nome em C\u00f3digo Morse. Use como refer\u00eancia a tabela abaixo.</p> <p></p>"},{"location":"aulas/iot/lab10/index.html","title":"Index","text":""},{"location":"aulas/iot/lab10/index.html#o-que-vamos-ver-neste-lab","title":"O que vamos ver neste lab?","text":"<ul> <li>Configurar um servidor web Flask na Raspberry Pi.</li> <li>Controlar um LED atrav\u00e9s de uma interface web.</li> <li>Compreender os conceitos b\u00e1sicos de programa\u00e7\u00e3o GPIO com a Raspberry Pi.</li> </ul>"},{"location":"aulas/iot/lab10/index.html#montando-um-webserver-em-flask","title":"Montando um Webserver em Flask","text":"<p>Vamos montar um webserver na raspberry pi com flask. A ideia deste exemplo \u00e9 controlar por um navegador web o status de um led entre ligado e desligado:</p> <p></p>"},{"location":"aulas/iot/lab10/index.html#instalando-o-flask-e-configurando-o-ambiente","title":"Instalando o Flask e configurando o ambiente","text":"<p>Warning</p> <p>Ligue a Raspberry PI, fa\u00e7a o acesso SSH e certifique que est\u00e1 com acesso a internet. </p> <p>No terminal da raspberry pi, atualize os reposit\u00f3rios:</p> <pre><code>sudo apt update\n</code></pre> <p>Instale os pacotes do flask</p> <pre><code>sudo apt-get install python3-flask\n</code></pre> <p>Agora vamos criar nossa arvore de projeto:</p> <p><pre><code>- webserver\n    - static\n        - index.css\n    - templates\n        - index.html\n    - app.py\n</code></pre> onde: </p> <ul> <li>webserver: diret\u00f3rio principal do projeto.<ul> <li>static: diret\u00f3rio para arquivos est\u00e1ticos.<ul> <li>index.css: arquivo de estilos CSS para a interface web.</li> </ul> </li> <li>templates: diret\u00f3rio para arquivos HTML.<ul> <li>index.html: arquivo HTML principal da aplica\u00e7\u00e3o.</li> </ul> </li> <li>app.py: script Python que cont\u00e9m a l\u00f3gica do servidor Flask e a programa\u00e7\u00e3o GPIO.</li> </ul> </li> </ul> <p>No terminal da Raspberry PI, crie a estrutura de diret\u00f3rios:</p> <pre><code>cd ~\nmkdir webserver\ncd webserver\nmkdir static templates\nls\n</code></pre> <p>Exercise</p> <p>O comando <code>ls</code> lista os arquivos e diret\u00f3rios no diret\u00f3rio atual. Leia a saida do terminal e verifique se os diretorios foram criados corretamente.</p>"},{"location":"aulas/iot/lab10/index.html#vamos-criar-o-apppy","title":"Vamos criar o <code>app.py</code>.","text":"<p>No terminal da Raspberry PI, digite:</p> <pre><code>nano app.py\n</code></pre> <p>Com o editor nano aberto, insira o seguinte c\u00f3digo:</p> <pre><code>'''\n    Servidor web com flask para controle de um LED.\n'''\nimport RPi.GPIO as GPIO\nfrom flask import Flask, render_template, request\n\napp = Flask(__name__)\n\nGPIO.setmode(GPIO.BCM)\nGPIO.setwarnings(False)\n\n# Define o pino GPIO para o LED\nledRed = 2\n\n# Inicializa o status do LED como desligado\nledRedSts = 0\n\n# Define o pino do LED como sa\u00edda\nGPIO.setup(ledRed, GPIO.OUT)   \n\n# Desliga o LED inicialmente\nGPIO.output(ledRed, GPIO.LOW)\n\n@app.route(\"/\")\ndef index():\n    # L\u00ea o status do GPIO\n    ledRedSts = GPIO.input(ledRed)\n\n    templateData = {\n            'ledRed'  : ledRedSts,\n        }\n    return render_template('index.html', **templateData)\n\n@app.route(\"/&lt;deviceName&gt;/&lt;action&gt;\")\ndef action(deviceName, action):\n    if deviceName == 'ledRed':\n        actuator = ledRed\n\n    if action == \"on\":\n        GPIO.output(actuator, GPIO.HIGH)\n    if action == \"off\":\n        GPIO.output(actuator, GPIO.LOW)\n\n    ledRedSts = GPIO.input(ledRed)\n\n    templateData = {\n            'ledRed'  : ledRedSts,\n    }\n    return render_template('index.html', **templateData)\n\nif __name__ == \"__main__\":\n   app.run(host='0.0.0.0', port=80, debug=True)\n</code></pre> <p>Shooooooowwwwww! N\u00e3o esque\u00e7a de Salvar e fechar o editor nano. Ctrl+X &gt;&gt; Y</p>"},{"location":"aulas/iot/lab10/index.html#vamos-criar-a-pagina-html-indexhtml","title":"Vamos criar a pagina html <code>index.html</code>.","text":"<p>No terminal da Raspberry Pi, navegue at\u00e9 o diret\u00f3rio <code>templates</code> e crie o arquivo <code>index.html</code>:</p> <pre><code>cd templates\nnano index.html\n</code></pre> <p>Insira o seguinte c\u00f3digo:</p> <pre><code>&lt;!DOCTYPE html&gt;\n   &lt;head&gt;\n      &lt;title&gt;Webserver&lt;/title&gt;\n      &lt;link rel=\"stylesheet\" href='../static/index.css'/&gt;\n   &lt;/head&gt;\n\n   &lt;body&gt;\n\n        &lt;h2&gt; Controle LED &lt;/h2&gt;\n\n        &lt;h3&gt; RED LED ==&gt;  {{ ledRed  }}  ==&gt;  \n            {% if  ledRed   == 1 %}\n                &lt;a href=\"/ledRed/off\"class=\"button\"&gt;TURN OFF&lt;/a&gt;\n            {% else %}\n                &lt;a href=\"/ledRed/on\" class=\"button\"&gt;TURN ON&lt;/a&gt; \n            {% endif %} \n        &lt;/h3&gt;\n\n   &lt;/body&gt;\n&lt;/html&gt;\n</code></pre> <p>Shooooooowwwwww! N\u00e3o esque\u00e7a de Salvar e fechar o editor nano. Ctrl+X &gt;&gt; Y</p>"},{"location":"aulas/iot/lab10/index.html#vamos-criar-o-arquivo-de-estilo-css-indexcss","title":"Vamos criar o arquivo de estilo css <code>index.css</code>.","text":"<p>No terminal da Raspberry Pi, navegue at\u00e9 o diret\u00f3rio <code>static</code> e crie o arquivo <code>index.css</code>:</p> <pre><code>cd ..\ncd static\nnano index.html\n</code></pre> <p>Com o editor nano aberto digite:</p> <pre><code>body {\n   background: blue;\n   color: yellow;\n}\n\n.button {\n  font: bold 15px Arial;\n  text-decoration: none;\n  background-color: #EEEEEE;\n  color: #333333;\n  padding: 2px 6px 2px 6px;\n  border-collapse: separete;\n  border-spacing: 0;\n  border-top: 1px solid #CCCCCC;\n  border-right: 1px solid #333333;\n  border-bottom: 1px solid #333333;\n  border-left: 1px solid #CCCCCC;\n}\n</code></pre> <p>Shooooooowwwwww! N\u00e3o esque\u00e7a de Salvar e fechar o editor nano. Ctrl+X &gt;&gt; Y</p>"},{"location":"aulas/iot/lab10/index.html#hora-de-testar","title":"Hora de testar","text":"<p>Vamos testar nosso webserver simples.</p> <p>No terminal da Raspberry Pi, retorne ao diret\u00f3rio principal e execute o script:</p> <pre><code>cd ..\nsudo python app.py\n</code></pre> <p>Deixe o Flask rodando na Raspberry Pi. Em um computador ou smartphone (que deve estar na mesma rede da Raspberry Pi), abra um navegador web e digite o IP da Raspberry Pi. Para encontrar o IP da Raspberry Pi, voc\u00ea pode usar o comando:</p> <pre><code>hostname -I\n</code></pre> <p>Warning</p> <p>O resultado esperado \u00e9 abrir uma p\u00e1gina web onde voc\u00ea pode controlar o LED.</p>"},{"location":"aulas/iot/lab10/index.html#desafios","title":"Desafios","text":"<p>Agora que j\u00e1 entendemos a estrutura b\u00e1sica do webserver em Python, fa\u00e7a os <code>Desafios</code> abaixo.</p> <p>Exercise</p> <p>Compreenda o c\u00f3digo app.py e monte o circuito adequado para conseguir visualizar o led acender e apagar.</p> <p>Exercise</p> <p>Altere o c\u00f3digo app.py e adicione mais 2 led e 2 bot\u00f5es (totalizando 3 leds, 2 bot\u00f5es), lembre-se de adaptar os arquivos HTML para exibir os status no frontend. </p> <p>Exercise</p> <p>Utilize seus conhecimentos web e proponha melhorias de UI/UX para o exerc\u00edcio anterior. Explore bibliotecas CSS como Bootstrap ou Materialize para aprimorar a interface.</p>"},{"location":"aulas/iot/lab2/index.html","title":"Index","text":""},{"location":"aulas/iot/lab2/index.html#lab2-desafios","title":"Lab2 - Desafios","text":"<p>Os desafios 1, 2 e 3 devem ser entregues e comp\u00f5em parte da nota do CP6.</p>"},{"location":"aulas/iot/lab2/index.html#desafio-1","title":"Desafio 1","text":"<p>Neste desafio vamos explorar como realizar a leitura de um pino digital do arduino, para isso monte o circuito do abaixo e vamos explorar o seu funcionamento:</p> <p></p> <p>Use esse c\u00f3digo de base:</p> <pre><code>// const \u00e9 uma constante. logo o valor n\u00e3o muda\nconst int buttonPin = 2;\nconst int ledPin = 13;\n// cria uma vari\u00e1vel\nint buttonState = 0;\n\nvoid setup() {\n    // configura bot\u00e3o no pino do arduino como entrada:\n    pinMode(ledPin, OUTPUT);\n    // configura bot\u00e3o no pino do arduino como entrada:\n    pinMode(buttonPin, INPUT_PULLUP);\n}\n\nvoid loop() {\n    // L\u00ea o estado do bot\u00e3o:\n    buttonState = digitalRead(buttonPin);\n    // se o bot\u00e3o estiver em n\u00edvel l\u00f3gico alto\n    if (buttonState == LOW) {\n        // liga o led\n        digitalWrite(ledPin, HIGH);\n    } else {\n        // apaga o led\n        digitalWrite(ledPin, LOW);\n        delay(1000);\n    }\n}\n</code></pre> <ol> <li> <p>Rode o c\u00f3digo fornecido de base. Observe, entenda e anote o seu funcionamento;</p> <ul> <li>O que acontece quando pressiona e solta o bot\u00e3o?</li> <li>\u25cb O que acontece quando pressiona e segura o bot\u00e3o?</li> </ul> </li> </ol> <p>Warning</p> <p>Repare que o seu funcionamento \u00e9 um pouco lento e as vezes, parece que ele n\u00e3o funciona corretamente. </p> <p>Showwww agora vamos avan\u00e7ar um pouquinho\u2026.</p> <ol> <li> <p>Altere o c\u00f3digo para funcionar da seguinte forma:</p> <ul> <li> <p>Quando pressionar e soltar o bot\u00e3o:</p> <ul> <li>O led muda o seu estado, de apagado para ligado e vice-versa\u2026</li> </ul> </li> <li> <p>Quando pressionar e segurar o bot\u00e3o:</p> <ul> <li>O led muda o seu estado uma \u00fanica vez. (Se estava ligado, apaga e fica apagado)</li> </ul> </li> </ul> </li> </ol> <p>Tip</p> <p>Para funcionar corretamente precisamos dominar o conceito de <code>debounce de bot\u00f5es</code>, ele \u00e9 um conceito importante ao trabalhar com o Arduino ou qualquer microcontrolador. Ele se refere ao processo de evitar leituras falsas ou inst\u00e1veis quando um bot\u00e3o f\u00edsico \u00e9 pressionado ou liberado. Isso \u00e9 especialmente importante porque os bot\u00f5es mec\u00e2nicos podem gerar ru\u00eddos el\u00e9tricos durante essas a\u00e7\u00f5es, levando a m\u00faltiplas leituras em vez de uma \u00fanica leitura limpa. Existem diversas formas de criar um debounce, vamos seguir boas as boas pr\u00e1ticas e implementar o debounce com a fun\u00e7\u00e3o <code>millis()</code>, como no exemplo abaixo. Note que esse c\u00f3digo \u00e9 parte da solu\u00e7\u00e3o e n\u00e3o a solu\u00e7\u00e3o completa, voc\u00ea precisa entender e ajustar ao desafio proposto.</p> <pre><code>const int buttonPin = 2;   // Pino do bot\u00e3o\nint lastButtonState = HIGH; // \u00daltimo estado do bot\u00e3o\nint buttonState;            // Estado atual do bot\u00e3o\nunsigned long lastDebounceTime = 0;  // \u00daltimo tempo de debounce\nunsigned long debounceDelay = 50;    // Tempo de debounce de 50ms\n\nvoid setup() {\n  pinMode(buttonPin, INPUT_PULLUP);\n}\n\nvoid loop() {\n  int leBotao = digitalRead(buttonPin);\n\n  if (leBotao != lastButtonState) {\n    lastDebounceTime = millis();\n  }\n\n  if ((millis() - lastDebounceTime) &gt; debounceDelay) {\n    if (leBotao != buttonState) {\n      buttonState = leBotao;\n\n      if (buttonState == LOW) {\n        // Bot\u00e3o pressionado\n      }\n    }\n  }\n\n  lastButtonState = leBotao;\n}\n</code></pre>"},{"location":"aulas/iot/lab2/index.html#desafio-2","title":"Desafio 2","text":"<p>Altere o c\u00f3digo do desafio 1 e implemente um log que exibe o status do bot\u00e3o e do led.</p> <p>Tip</p> <p>Para conseguir resolver esse desafio, Voc\u00ea deve inicialiar o periferico de comunica\u00e7\u00e3o serial. Fazemos isso com a instru\u00e7\u00e3o <code>Serial.begin(9600);</code> dentro da fun\u00e7\u00e3o <code>void setup()</code>.</p> <p><pre><code>void setup() {\n  // Inicia a comunica\u00e7\u00e3o serial com uma taxa de 9600 bps\n  Serial.begin(9600);\n}\n\nvoid loop() {\n  // Seu c\u00f3digo aqui\n}\n</code></pre> Al\u00e9m disso, depois de usar <code>Serial.begin()</code>, voc\u00ea pode usar a fun\u00e7\u00e3o <code>Serial.print()</code> ou <code>Serial.println()</code> para enviar dados pela serial e criar seu log. Para visualizar, use o <code>Serial Monitor</code> no arduinoIDE clique em <code>Ferramentas -&gt; Monitor Serial</code></p>"},{"location":"aulas/iot/lab2/index.html#desafio-3","title":"Desafio 3","text":"<p>Neste desafio vamos explorar novos recursos do arduino. Para isso implemente um c\u00f3digo que faz a leitura do pino analogico A0 que altera o tempo de delay do led. Monte o circuito abaixo:</p> <p></p> <p>Tip</p> <p>Vamos conhecer e utilizar as fun\u00e7\u00f5es do arduino <code>analogRead()</code> e <code>analogWrite()</code>.</p> <ul> <li> <p>analogRead: A fun\u00e7\u00e3o analogRead \u00e9 usada para ler valores de sinais anal\u00f3gicos atrav\u00e9s de pinos anal\u00f3gicos no Arduino. Ela converte a tens\u00e3o anal\u00f3gica presente no pino em um valor digital que pode variar de 0 a 1023, correspondendo a uma faixa de 0 a 5 volts (no Arduino Uno e outros modelos semelhantes).</p> <pre><code>int analogValue = analogRead(A0); // L\u00ea o valor anal\u00f3gico do pino A0\n</code></pre> </li> <li> <p>analogWrite: A fun\u00e7\u00e3o analogWrite \u00e9 usada para gerar uma sa\u00edda PWM (modula\u00e7\u00e3o por largura de pulso) em um pino digital. Embora seja chamada de \"analogWrite\", na verdade ela gera um sinal digital pulsante com diferentes larguras de pulso, simulando uma sa\u00edda anal\u00f3gica. Ela \u00e9 frequentemente usada para controlar a intensidade luminosa de LEDs ou a velocidade de motores. </p> </li> <li> <p>Importante destacar que a fun\u00e7\u00e3o <code>analogWrite</code> funciona apenas em pinos espec\u00edficos do Arduino que suportam PWM, geralmente marcados com o s\u00edmbolo <code>\"~\"</code>.</p> <pre><code>int pwmValue = 128;\nanalogWrite(9, pwmValue); // Gera um sinal PWM no pino 9 com ciclo de trabalho de 50%\n</code></pre> </li> <li> <p>Utilize a fun\u00e7\u00e3o <code>map()</code> do arduino para fazer a convers\u00e3o de valores. Pesquise no google essa fun\u00e7\u00e3o.</p> </li> </ul>"},{"location":"aulas/iot/lab3/index.html","title":"Index","text":""},{"location":"aulas/iot/lab3/index.html#comunicacao-serial","title":"comunica\u00e7\u00e3o serial","text":"<p>A comunica\u00e7\u00e3o serial permite que o Arduino se comunique com o computador e outros dispositivos. Neste laborat\u00f3rio, exploraremos a comunica\u00e7\u00e3o serial em detalhes.</p>"},{"location":"aulas/iot/lab3/index.html#desafio-1-comunicacao-entre-arduino-e-computador","title":"Desafio 1: Comunica\u00e7\u00e3o entre Arduino e Computador","text":"<p>Neste desafio, vamos estabelecer uma comunica\u00e7\u00e3o b\u00e1sica entre o Arduino e o computador usando o Serial Monitor.</p> <p>Carregue o seguinte c\u00f3digo no seu Arduino:</p> <pre><code>void setup() {\n  Serial.begin(9600); // Inicia a comunica\u00e7\u00e3o serial a 9600 bps\n}\n\nvoid loop() {\n  Serial.println(\"Ol\u00e1, Mundo!\"); // Envia a mensagem \"Ol\u00e1, Mundo!\" para o computador\n  delay(1000); // Espera 1 segundo\n}\n</code></pre> <ul> <li> <p>Abra o Serial Monitor no Arduino IDE (Ferramentas -&gt; Monitor Serial).</p> </li> <li> <p>Voc\u00ea deve ver a mensagem \"Ol\u00e1, Mundo!\" sendo exibida a cada segundo.</p> </li> </ul> <p></p> <p>Tip</p> <p>Certifique-se de que a taxa de baud no Serial Monitor esteja definida como 9600 para corresponder ao c\u00f3digo.</p>"},{"location":"aulas/iot/lab3/index.html#desafio-2-recebendo-dados-do-computador","title":"Desafio 2: Recebendo Dados do Computador","text":"<p>Agora, vamos fazer o Arduino responder a comandos enviados do computador.</p> <p>Carregue o seguinte c\u00f3digo no seu Arduino:</p> <pre><code>String comando = \"\"; // Vari\u00e1vel para armazenar o comando recebido\n\nvoid setup() {\n  Serial.begin(9600);\n  pinMode(13, OUTPUT); // Define o pino 13 como sa\u00edda\n}\n\nvoid loop() {\n  if (Serial.available()) { // Verifica se h\u00e1 dados dispon\u00edveis para leitura\n    comando = Serial.readString(); // L\u00ea a string enviada pelo computador\n    if (comando == \"LIGAR\") {\n      digitalWrite(13, HIGH); // Acende o LED no pino 13\n      Serial.println(\"LED Ligado!\");\n    } else if (comando == \"DESLIGAR\") {\n      digitalWrite(13, LOW); // Apaga o LED no pino 13\n      Serial.println(\"LED Desligado!\");\n    }\n  }\n}\n</code></pre> <p>Com o Serial Monitor aberto, digite <code>LIGAR</code> e pressione Enter. O LED no pino 13 do Arduino deve acender. Digite <code>DESLIGAR</code> e pressione Enter. O LED deve apagar.</p> <p></p> <p>Warning</p> <p>A comunica\u00e7\u00e3o serial \u00e9 sens\u00edvel a mai\u00fasculas e min\u00fasculas. Certifique-se de digitar os comandos exatamente como est\u00e3o no c\u00f3digo.</p>"},{"location":"aulas/iot/lab3/index.html#desafio-3-comunicacao-entre-dois-arduinos","title":"Desafio 3: Comunica\u00e7\u00e3o entre Dois Arduinos","text":"<p>Neste desafio, vamos fazer dois Arduinos se comunicarem entre si.</p> <p>Vamos preciar de 2 arduinos cada arduino conectado em um computador.</p> <p></p> <p>Carregue o seguinte c\u00f3digo no Arduino 1 (Transmissor):</p> <pre><code>void setup() {\n  Serial.begin(9600);\n}\n\nvoid loop() {\n  Serial.println(\"Mensagem do Arduino 1\");\n  delay(2000);\n}\n</code></pre> <p>Carregue o seguinte c\u00f3digo no Arduino 2 (Receptor):</p> <pre><code>void setup() {\n  Serial.begin(9600);\n}\n\nvoid loop() {\n  if (Serial.available()) {\n    String mensagem = Serial.readString();\n    Serial.println(\"Recebido: \" + mensagem);\n  }\n}\n</code></pre> <p>Conecte o pino TX do Arduino 1 ao pino RX do Arduino 2 e vice-versa. Abra o Serial Monitor para o Arduino 2. Voc\u00ea deve ver as mensagens enviadas pelo Arduino 1 sendo exibidas.</p> <p>Tip</p> <p>Lembre-se de conectar os GNDs dos dois Arduinos juntos para garantir uma refer\u00eancia comum.</p>"},{"location":"aulas/iot/lab3/index.html#desafio-4-recebendo-dados-de-sensores","title":"Desafio 4: Recebendo dados de sensores","text":"<p>Fa\u00e7a as altera\u00e7\u00f5es necess\u00e1rias nos dois c\u00f3digos anteriores para que funcione da seguinte forma: </p> <ul> <li>Conecte um bot\u00e3o ao arduino transmissor, quando pressionar o bot\u00e3o envie uma mensagem.</li> <li>Conecte um led ao arduino receptor, quando receber o comando de ligar, o led liga e quando for desligar, apaga o led.  </li> </ul>"},{"location":"aulas/iot/lab4/index.html","title":"Index","text":""},{"location":"aulas/iot/lab4/index.html#memoria-eeprom","title":"Memoria EEPROM","text":"<p>A mem\u00f3ria EEPROM (Electrically Erasable Programmable Read-Only Memory) \u00e9 uma mem\u00f3ria n\u00e3o vol\u00e1til, o que significa que os dados armazenados nela persistem mesmo depois de desligar o Arduino. \u00c9 \u00fatil para armazenar pequenas quantidades de dados que precisam ser preservados entre reinicializa\u00e7\u00f5es, como configura\u00e7\u00f5es ou contadores.</p> <p>Warning</p> <p>Essa memoria n\u00e3o \u00e9 infinita, pelo contrario! a memoria EEPROM \u00e9 bem pequena, no caso do Arduino UNO \u00e9 de apenas 1KB (1000 Bytes) tenha isso em mente para n\u00e3o ultrapassar esse valor.</p>"},{"location":"aulas/iot/lab4/index.html#desafio-1-escrevendo-e-lendo-dados-na-eeprom","title":"Desafio 1: Escrevendo e Lendo Dados na EEPROM","text":"<p>Neste desafio, vamos aprender a escrever e ler dados na mem\u00f3ria EEPROM. Vamos escrever apenas 1 unico valor inteiro.</p> <p>Monte um circuito com um bot\u00e3o no pino 2 e carregue o seguinte c\u00f3digo no seu Arduino:</p> <pre><code>#include &lt;EEPROM.h&gt;\n\nconst int buttonPin = 2; // Pino do bot\u00e3o\nint lastButtonState = HIGH;\nint buttonState; \n\nunsigned long lastDebounceTime = 0;\nunsigned long debounceDelay = 50;    \n\nvoid setup() {\n  Serial.begin(9600);\n  pinMode(buttonPin, INPUT_PULLUP); \n\n  EEPROM.write(0, 123); // Escreve o valor 123 na posi\u00e7\u00e3o 0 da EEPROM\n  delay(10); // Pequeno delay para garantir a escrita na memoria\n}\n\nvoid loop() {\n  int reading = digitalRead(buttonPin); // L\u00ea o estado do bot\u00e3o\n  if (reading != lastButtonState) {\n    lastDebounceTime = millis();\n  }\n  if ((millis() - lastDebounceTime) &gt; debounceDelay) {\n    if (reading != buttonState) {\n      buttonState = reading;\n\n      // Se o bot\u00e3o estiver pressionado (estado LOW devido ao pull-up)\n      if (buttonState == LOW) {\n\n        int valor = EEPROM.read(0); // L\u00ea o valor na posi\u00e7\u00e3o 0 da EEPROM\n        Serial.println(valor); // Imprime o valor\n      }\n    }\n  }\n\n  lastButtonState = reading; // Atualiza o estado anterior do bot\u00e3o\n}\n</code></pre>"},{"location":"aulas/iot/lab4/index.html#desafio-2-armazenando-e-recuperando-strings","title":"Desafio 2: Armazenando e Recuperando Strings","text":"<p>Agora altere o c\u00f3digo para escrever e ler <code>Strings</code>. </p> <p>Altre o c\u00f3digo do desafio 1 para:</p> <pre><code>- Salve na memoria EEPROM a frase: `Let's Rock the Future` \n- Recuperar o valor salvo na memoria quando apertar o bot\u00e3o.\n</code></pre> <p>Tip</p> <ul> <li>Defina a frase como do tipo String. <code>String frase = \"sua frase aqui\"</code></li> <li>Conhe\u00e7a um pouco mais do objeto String lendo a documenta\u00e7\u00e3o aqui</li> <li>Para salvar na memoria EEPROM temos que rodar um <code>la\u00e7o for</code> para salvar caractere por caractere. <code>for (int i = 0; i &lt; frase.length(); i++){}</code></li> <li>Dentro do la\u00e7o for, defina a posi\u00e7\u00e3o inicial da memoria e salve cada indice do frase <code>EEPROM.write(startPos + i, frase[i]);</code></li> <li>Fa\u00e7a a mesma coisa para recuperar os dados.     </li> </ul>"},{"location":"aulas/iot/lab4/index.html#desafio-3-exiba-os-resultados-em-um-display-lcd","title":"Desafio 3: Exiba os resultados em um display LCD","text":"<p>Agora vamos exibir o valor da memoria EEPROM em um display LCD. Para isso, busque por refer\u00eancias na internet de como realizar a liga\u00e7\u00e3o e elaborar o circuito.  </p> <p>Tip</p> <p>execute os codigo exemplo que encontrar na internet para verificar o funcionamento do circuito antes de escrever seu proprio c\u00f3digo</p>"},{"location":"aulas/iot/lab5/index.html","title":"Index","text":"<p>Neste Laborat\u00f3rio vamos trabalhar com Node-red e conhecer o protocolo MQTT.</p> <ul> <li>arquivo pdf do laborat\u00f3rio: laborat\u00f3rio5</li> </ul>"},{"location":"aulas/iot/lab5/index.html#introducao-a-iot","title":"Introdu\u00e7\u00e3o \u00e0 IoT","text":""},{"location":"aulas/iot/lab5/index.html#agenda","title":"Agenda","text":"<ul> <li>Instala\u00e7\u00e3o do Node-RED e primeiros testes</li> <li>Montagem de um dashboard no Node-RED</li> <li>Cria\u00e7\u00e3o de um end-point</li> <li>Apresenta\u00e7\u00e3o do MQTT</li> </ul>"},{"location":"aulas/iot/lab5/index.html#conectando-dispositivos-a-aplicacoes","title":"Conectando dispositivos a aplica\u00e7\u00f5es","text":"<p>Agora que j\u00e1 exploramos as funcionalidades do Arduino e sua capacidade de conectar sensores e atuadores, vamos prosseguir conectando o Arduino a aplica\u00e7\u00f5es que fazem uso desse dispositivo.</p> <p>Em primeiro lugar, vamos relembrar a arquitetura que usaremos para os dispositivos de IoT se conectarem \u00e0s suas aplica\u00e7\u00f5es.</p>"},{"location":"aulas/iot/lab5/index.html#arquitetura-basica-de-iot","title":"Arquitetura b\u00e1sica de IoT","text":"<p>A arquitetura de implanta\u00e7\u00e3o apresentada aqui \u00e9 um modelo padr\u00e3o para inspirar projetos reais. Ela inclui os elementos fundamentais para a conectividade, sem detalhar solu\u00e7\u00f5es para problemas acess\u00f3rios.</p> <p></p> <ul> <li>Interoperabilidade: facilita a compatibilidade entre diferentes projetos de IoT.</li> <li>Modularidade: define m\u00f3dulos que podem ser criados separadamente ou usados como \"off-the-shelf\".</li> </ul>"},{"location":"aulas/iot/lab5/index.html#dispositivos-de-iot","title":"Dispositivos de IoT","text":"<p>Os dispositivos de IoT interagem com o ambiente ao seu redor, capturando dados de sensores ou executando comandos por meio de atuadores.</p> <ul> <li>Cada funcionalidade no dispositivo pode ser considerada uma aplica\u00e7\u00e3o (Endpoint Application).</li> <li>Cada aplica\u00e7\u00e3o deve ser univocamente endere\u00e7\u00e1vel.</li> </ul>"},{"location":"aulas/iot/lab5/index.html#conector-de-iot","title":"Conector de IoT","text":"<p>Os conectores de IoT gerenciam mensagens que chegam dos dispositivos ou s\u00e3o destinadas a eles, adaptando-as ao protocolo de cada dispositivo.</p> <ul> <li>Pode haver conectores diferentes para protocolos variados.</li> <li>Protocolos comuns em IoT: MQTT, WebSocket, CoAP, LoRaWAN.</li> </ul>"},{"location":"aulas/iot/lab5/index.html#gerenciamento-de-dispositivos-e-dados","title":"Gerenciamento de dispositivos e dados","text":"<p>Este componente faz o gerenciamento remoto dos dispositivos e de seus dados, autorizando o acesso de outras aplica\u00e7\u00f5es.</p> <ul> <li>Cadastra novos dispositivos e aplica\u00e7\u00f5es.</li> <li>Monitora a disponibilidade dos dispositivos.</li> <li>Envia comandos de gerenciamento, como inicializa\u00e7\u00e3o, reinicializa\u00e7\u00e3o, desligamento e atualiza\u00e7\u00e3o de firmware.</li> </ul>"},{"location":"aulas/iot/lab5/index.html#bancos-de-dados-e-analise-de-dados","title":"Bancos de dados e an\u00e1lise de dados","text":"<p>Armazena dados provenientes das aplica\u00e7\u00f5es e comandos destinados aos dispositivos.</p> <ul> <li>Bancos de dados NoSQL s\u00e3o mais indicados para a IoT devido \u00e0 natureza diversificada e em constante mudan\u00e7a dos dados.</li> <li>Analisadores de dados monitoram os dados para melhor aproveitamento.</li> </ul>"},{"location":"aulas/iot/lab5/index.html#gateway","title":"Gateway","text":"<p>O gateway conecta dispositivos sem acesso direto \u00e0 internet e realiza a convers\u00e3o de protocolos entre os dispositivos de IoT e o conector de IoT.</p> <p></p> <ul> <li>Gerencia m\u00faltiplos protocolos, especialmente em LAN\u2019s, PAN\u2019s e HAN\u2019s (ex: Zigbee, Bluetooth, LoRa, Thread/6LoWPAN).</li> </ul>"},{"location":"aulas/iot/lab5/index.html#node-red","title":"Node-RED","text":"<p>O Node-RED \u00e9 uma plataforma de programa\u00e7\u00e3o visual para sistemas baseados em eventos. Ele executa como um servidor web e \u00e9 amplamente utilizado para conectar dispositivos de IoT.</p> <ul> <li>Programado em Node.js, \u00e9 uma ferramenta visual para editar fluxos de mensagens.</li> <li>Dispon\u00edvel em servi\u00e7os de Cloud como o IBM Bluemix.</li> </ul>"},{"location":"aulas/iot/lab5/index.html#instalacao-do-node-red","title":"Instala\u00e7\u00e3o do Node-RED","text":"<ol> <li>Instale o Node.js (vers\u00e3o LTS) no site Node.js.</li> <li>No terminal, digite:      <pre><code>npm install -g --unsafe-perm node-red\n</code></pre></li> <li>Para rodar o Node-RED:      <pre><code>node-red\n</code></pre></li> <li>Acesse no navegador: http://localhost:1880</li> </ol>"},{"location":"aulas/iot/lab5/index.html#primeiro-fluxo-no-node-red","title":"Primeiro fluxo no Node-RED","text":"<ul> <li>Conecte um n\u00f3 de entrada do tipo \"inject\" a um n\u00f3 \"debug\", fa\u00e7a o deploy e observe o resultado no painel de debug.</li> <li>Modifique o n\u00f3 \"inject\" e veja as altera\u00e7\u00f5es no resultado.</li> </ul>"},{"location":"aulas/iot/lab5/index.html#desafios-no-node-red","title":"Desafios no Node-RED","text":""},{"location":"aulas/iot/lab5/index.html#desafio-1-monitor-de-clima","title":"Desafio 1: Monitor de clima","text":"<ol> <li>Cadastre-se no site OpenWeather, crie um token e leia a documenta\u00e7\u00e3o da API Current.</li> <li>Crie uma URL para obter o tempo de uma cidade de sua prefer\u00eancia e compare o resultado com a sa\u00edda no Node-RED.</li> </ol>"},{"location":"aulas/iot/lab5/index.html#desafio-2-dashboard","title":"Desafio 2: Dashboard","text":"<p>Crie um dashboard que exiba informa\u00e7\u00f5es de duas ou mais cidades, incluindo: - Temperatura atual - Temperatura m\u00ednima - Temperatura m\u00e1xima - Velocidade do vento - Umidade relativa - Sensa\u00e7\u00e3o t\u00e9rmica</p> <p>Atualize os dados a cada 3 ou 5 segundos.</p>"},{"location":"aulas/iot/lab5/index.html#mqtt-message-queuing-telemetry-transport","title":"MQTT (Message Queuing Telemetry Transport)","text":"<p>O MQTT \u00e9 um protocolo de comunica\u00e7\u00e3o leve projetado especificamente para dispositivos com recursos limitados, como sensores e atuadores, e cen\u00e1rios de redes com alta lat\u00eancia e baixa largura de banda. Sua simplicidade e baixo overhead o tornam ideal para a Internet das Coisas (IoT).</p> <p></p>"},{"location":"aulas/iot/lab5/index.html#caracteristicas-principais-do-mqtt","title":"Caracter\u00edsticas principais do MQTT:","text":"<ul> <li>Modelo Publish/Subscribe: O MQTT usa um modelo de comunica\u00e7\u00e3o ass\u00edncrono, onde os clientes se inscrevem (subscribe) em t\u00f3picos espec\u00edficos para receber mensagens e publicam (publish) mensagens nesses t\u00f3picos para serem recebidas por outros clientes.</li> <li>Broker: O broker \u00e9 o servidor central que gerencia as mensagens publicadas e as distribui para os clientes inscritos em t\u00f3picos espec\u00edficos.</li> <li>Qualidade de Servi\u00e7o (QoS): O MQTT oferece tr\u00eas n\u00edveis de QoS que controlam a entrega das mensagens, garantindo diferentes n\u00edveis de confiabilidade:</li> <li>QoS 0 - At most once: A mensagem \u00e9 entregue no m\u00e1ximo uma vez, sem confirma\u00e7\u00e3o de recebimento. Risco de perda de mensagem.</li> <li>QoS 1 - At least once: A mensagem \u00e9 entregue ao menos uma vez. H\u00e1 confirma\u00e7\u00e3o de recebimento, mas pode ocorrer duplica\u00e7\u00e3o de mensagens.</li> <li> <p>QoS 2 - Exactly once: A mensagem \u00e9 entregue exatamente uma vez, garantindo a entrega sem duplica\u00e7\u00e3o ou perda, por\u00e9m com maior overhead.</p> </li> <li> <p>Retained Messages: Uma mensagem publicada pode ser marcada como \"retida\", o que significa que o broker armazenar\u00e1 essa \u00faltima mensagem publicada no t\u00f3pico e enviar\u00e1 imediatamente aos novos clientes que se inscreverem no t\u00f3pico, mesmo ap\u00f3s a publica\u00e7\u00e3o original.</p> </li> <li>Last Will and Testament (LWT): O LWT \u00e9 uma mensagem que o broker envia automaticamente caso um cliente MQTT se desconecte inesperadamente, notificando os outros clientes da rede sobre a falha.</li> </ul> <p></p>"},{"location":"aulas/iot/lab5/index.html#funcionamento-do-mqtt","title":"Funcionamento do MQTT:","text":"<ol> <li>Publica\u00e7\u00e3o de Mensagens: Um cliente publica uma mensagem em um t\u00f3pico espec\u00edfico no broker.</li> <li>Inscri\u00e7\u00e3o em T\u00f3picos: Outros clientes se inscrevem em t\u00f3picos de interesse e, quando uma mensagem \u00e9 publicada nesses t\u00f3picos, o broker a entrega aos inscritos.</li> <li>Filtragem por T\u00f3picos: O MQTT utiliza hierarquias de t\u00f3picos, permitindo o uso de caracteres coringa para subscri\u00e7\u00e3o:</li> <li>+: Corresponde a um \u00fanico n\u00edvel de um t\u00f3pico. Exemplo: <code>sala/+/temperatura</code> se inscreve em todos os sensores de temperatura de diferentes salas.</li> <li>#: Corresponde a todos os n\u00edveis subsequentes do t\u00f3pico. Exemplo: <code>sala/#</code> se inscreve em todos os t\u00f3picos que come\u00e7am com \"sala\".</li> </ol>"},{"location":"aulas/iot/lab5/index.html#exemplos-de-brokers-mqtt","title":"Exemplos de Brokers MQTT:","text":"<ul> <li>Brokers P\u00fablicos:</li> <li>iot.eclipse.org</li> <li>test.mosquitto.org</li> <li>dev.rabbitmq.com</li> <li>broker.mqttdashboard.com</li> </ul>"},{"location":"aulas/iot/lab5/index.html#desafio-3-cliente-mqtt-no-node-red","title":"Desafio 3: Cliente MQTT no Node-RED","text":"<p>No Node-RED, um fluxo pode ser criado para simular um chat entre dois ou mais clientes MQTT. Para isso, deve-se configurar t\u00f3picos que sigam boas pr\u00e1ticas de nomea\u00e7\u00e3o, como camelCase, e criar dois n\u00f3s principais:</p> <ul> <li>Node MQTT In: Subscreva-se a um t\u00f3pico espec\u00edfico e receba mensagens publicadas nesse t\u00f3pico.</li> <li>Node MQTT Out: Publique mensagens em um t\u00f3pico que os outros clientes est\u00e3o escutando.</li> </ul> <p></p> <p>Exemplo de configura\u00e7\u00e3o:</p> <ul> <li>T\u00f3pico de envio: <code>arnaldoAVianaJr/chat/mensagem</code></li> <li>Para receber mensagens, crie um n\u00f3 que se inscreva em: arnaldoAVianaJr/#.</li> </ul> <p></p> <p>Tip</p> <p>Esse fluxo de comunica\u00e7\u00e3o pode ser testado em um ambiente local ou em um dos brokers p\u00fablicos mencionados anteriormente.</p>"},{"location":"aulas/iot/lab6/index.html","title":"Index","text":""},{"location":"aulas/iot/lab6/index.html#lab6-desafios","title":"Lab6 - Desafios","text":"<p>Os <code>desafios 1, 2 e 3</code> devem ser entregues e comp\u00f5em parte da nota do CP6.</p>"},{"location":"aulas/iot/lab6/index.html#conteudo-deste-laboratorio","title":"Conte\u00fado deste laborat\u00f3rio","text":"<ul> <li> <p>Instala\u00e7\u00e3o e uso de bibliotecas externas para arduino</p> <ul> <li>Arduino JSON</li> <li>Sensor de temperatura e umidade DHT11</li> </ul> </li> <li> <p>Comunica\u00e7\u00e3o serial entre Arduino e o Node-RED</p> <ul> <li>Como mandar dados do arduino para o node-RED no formato JSON</li> </ul> </li> <li> <p>Como desenvolver um sistema supervis\u00f3rio para monitoramento de temperatura e umidade</p> </li> </ul>"},{"location":"aulas/iot/lab6/index.html#instalacao-e-uso-de-bibliotecas-externas-para-arduino","title":"Instala\u00e7\u00e3o e uso de bibliotecas externas para arduino","text":"<p>Normalmente os criadores das bibliotecas descrevem o passo-a-passo para utilizar as bibliotecas criadas, mas de forma geral podemos instalar uma biblioteca externa de duas formas: </p> <ul> <li> <p>Por Download: </p> <ul> <li>Fazer o download do arquivo .zip da biblioteca </li> <li>Descompactar o arquivo dentro da pasta <code>documentos/Arduino/libraries/</code></li> <li>Pronto! Podemos usar em nosso projeto.</li> <li>De forma geral \u00e9 isso, eventualmente o criador da biblioteca ir\u00e1 orientar eventuais etapas adicionais. </li> </ul> </li> <li> <p>Pelo gerenciador de bibliotecas:</p> <ul> <li>abra o Arduino IDE</li> <li>acesse: Sketch ==&gt; Include Library ==&gt; Manage Libraries\u2026 </li> <li>Digite na busca o nome da biblioteca</li> <li>Encontre a op\u00e7\u00e3o desejada e clique em instalar</li> <li>Pronto! Podemos usar em nosso projeto.</li> <li>Algumas libs dependem de outras de outras libs, nesse caso \u00e9 necess\u00e1rio instalar todas as libs.</li> </ul> </li> </ul> Imagem passo-a-passo <p></p> <p>DICA: Explore a documenta\u00e7\u00e3o e os exemplos da biblioteca instalada.   </p>"},{"location":"aulas/iot/lab6/index.html#biblioteca-arduinojson","title":"Biblioteca ArduinoJson","text":"<p>A biblioteca ArduinoJSON \u00e9 escrita em C++ para realizar a comunica\u00e7\u00e3o de dados no formato JSON (JavaScript Object Notation) com aplica\u00e7\u00f5es para IoT.  Pra quem conhece Python a estrutura \u00e9 muito parecida com a de dicion\u00e1rios:</p> <p>{\"Key1\":\"Value1\", \"Key2\":\"Value2\", \"Key3\":\"Value3\",\"....\":.\"....\"}  </p> <p>Documenta\u00e7\u00e3o oficial em: arduinoJSON - https://arduinojson.org/</p> <p>Exercise</p> <p>Fa\u00e7a a instala\u00e7\u00e3o da biblioteca arduinoJSON direto pelo ArduinoIDE, no campo de busca digite <code>ArduinoJson</code> e instale a biblioteca. Para mais detalhes de como realizar a instala\u00e7\u00e3o acesse aqui a documenta\u00e7\u00e3o oficial - https://arduinojson.org/v6/doc/installation/</p>"},{"location":"aulas/iot/lab6/index.html#sensor-dht11","title":"Sensor DHT11","text":"<p>O DHT11 \u00e9 um sensor digital de temperatura e umidade muito utilizado em diversas aplica\u00e7\u00f5es. Para facilitar o trabalho utilizamos uma biblioteca para realizar as leituras de temperatura e umidade. </p> <p></p> Pino Descri\u00e7\u00e3o 1 Alimenta\u00e7\u00e3o, VCC, 3,5V ~ 5,5V 2 DATA, transmiss\u00e3o de dados 3 NC, N\u00e3o Conectado 4 Alimenta\u00e7\u00e3o, GND, 0v <p>Cuidado para n\u00e3o inverter os pinos de alimenta\u00e7\u00e3o. </p> <p>Exercise</p> <p>Fa\u00e7a a instala\u00e7\u00e3o das bibliotecas para usar o DHT11: Adafruit Unified Sensor Libs: </p> <ol> <li> <p>Adafruit Sensor</p> </li> <li> <p>DHT Sensor. </p> </li> </ol> <p>Ap\u00f3s o download descompacte o arquivo .zip e mova-o para a pasta <code>~/Arduino/Libraries/</code></p>"},{"location":"aulas/iot/lab6/index.html#testando-o-sensor-dht11","title":"Testando o sensor DHT11","text":"<p>Para testar o funcionamento do sensor vamos executar 2 etapas: Montagem do hardware e Desenvolvimento do Software.</p>"},{"location":"aulas/iot/lab6/index.html#o-hardware-de-teste","title":"O hardware de teste","text":"<p>Monte o circuito da imagem abaixo e n\u00e3o esque\u00e7a de conectar o resistor </p> <p></p> <p>Exercise</p> <p>De acordo com o circuito qual o pino do arduino \u00e9 utilizado para realizar comunica\u00e7\u00e3o digital com o sensor DHT11?</p>"},{"location":"aulas/iot/lab6/index.html#o-codigo-de-teste","title":"O c\u00f3digo de teste","text":"<p>Crie um novo projeto no ArduinoIDE e tilize o c\u00f3digo de teste abaixo: Este c\u00f3digo foi adaptado do site filipeflop</p> <pre><code>/*\nC\u00f3digo para teste do sensor DHT11 \n\n*/\n#include \"DHT.h\"\n#define DHTPIN  7  //define o pino usado no arduino\n#define DHTTYPE DHT11\nDHT dht(DHTPIN, DHTTYPE); //declara a objeto da classe\n\nvoid setup() \n{\n  Serial.begin(9600);\n  Serial.println(\"DHTxx test!\");\n  dht.begin();\n}\n\nvoid loop() \n{\n  float h = dht.readHumidity();  // faz leitura da umidade\n  float t = dht.readTemperature();  // faz leitura da temperatura\n\n  // testa se retorno \u00e9 valido, caso contr\u00e1rio algo est\u00e1 errado.\n  if (isnan(t) || isnan(h)) \n  {\n    Serial.println(\"Falha na leitura do sensor DHT\");\n  } \n  else\n  {\n    Serial.print(\"Umidade: \");\n    Serial.print(h);\n    Serial.print(\" %t\");\n    Serial.print(\"Temperatura: \");\n    Serial.print(t);\n    Serial.println(\" *C\");\n  }\n  delay(500); //delay de 0,5s\n}\n</code></pre>"},{"location":"aulas/iot/lab6/index.html#o-teste","title":"O teste","text":"<p>Ap\u00f3s montar o circuito e escrever o c\u00f3digo, carregue o c\u00f3digo no arduino e abra o Monitor Serial para visualizar o funcionamento com mas medidas da temperatura e umidade, o resultado esperado deve ser igual da imagem abaixo.</p> <p></p> <p>Parab\u00e9ns!! Primeira parte concluida, vamos em frente... </p>"},{"location":"aulas/iot/lab6/index.html#usando-a-biblioteca-arduinojson","title":"Usando a biblioteca ArduinoJson","text":"<p>Vamos alterar nosso c\u00f3digo para enviar as informa\u00e7\u00f5es do sensor DHT11 em formato JSON, observe o c\u00f3digo abaixo com as altera\u00e7\u00f5es:</p> <pre><code>/*\nC\u00f3digo exemplo demonstrando o funcionamento do Sensor DHT11 enviando \ninforma\u00e7\u00f5es via serial no formato JSON para o servidor node-Red que recebe e transmite via protocolo MQTT \n\n*/\n\n/////Json\n#include &lt;ArduinoJson.h&gt;\nconst int TAMANHO = 50;  //define o tamanho do buffer para o json\n\n///// Sensor DHT\n#include \"DHT.h\"\n#define DHTPIN  7  //define o pino usado no arduino\n#define DHTTYPE DHT11\nDHT dht(DHTPIN, DHTTYPE); //declara a objeto da classe\n\n////// Outras declara\u00e7\u00f5es\n#define led 13 //define led conectado no pino 13\n\nvoid setup() \n{\n  //inicialia c sensor\n  dht.begin();\n\n  //inicializa comunica\u00e7\u00e3o serial\n  Serial.begin(9600);\n\n  //configura pinos de saida do arduinos\n  pinMode(led, OUTPUT);\n}\n\nvoid loop() \n{\n  StaticJsonDocument&lt;TAMANHO&gt; json; //Aloca buffer para objeto json\n\n  // Faz a leitura da temperatura  \n  float temp = dht.readTemperature();\n  // faz a leitura da humidade\n  float umi = dht.readHumidity();\n\n  //formato de escrita do json\n  json[\"temperatura\"] = temp;\n  json[\"umidade\"] = umi;\n\n  serializeJson(json, Serial);\n  Serial.println();\n\n  //delay\n  delay(500);\n}\n</code></pre> <p>Um ponto importante: Definir a variavel <code>TAMANHO</code> que serve como buffer em bytes para alocar o JSON que vamos trabalhar. Para isso podemos utilizar o <code>ArduinoJson Assistant</code> neste link: https://arduinojson.org/v6/assistant/#/step1, siga o passo-a-passo da ferramenta para descobrir o valor minimo que devemos utilizar. </p> <p>Exercise</p> <p>Utilizando o <code>ArduinoJson Assistant</code> qual o valor recomendado para o json do exemplo abaixo?</p> <pre><code>{\n\"valorSensor1\":10.10258,\n\"valorSensor2\":50.28546\n}    \n</code></pre> <p>Etapa 2 concluida! Agora o nosso programa envia dados no formato Json, facilitando a integra\u00e7\u00e3o com outros sistemas incluindo o Node-RED.</p>"},{"location":"aulas/iot/lab6/index.html#comunicacao-serial-com-node-red","title":"Comunica\u00e7\u00e3o serial com node-RED","text":"<p>No flow do node-red, vamos usar o node <code>serialport</code> para realizar a comunica\u00e7\u00e3o serial entre o node-red e o arduino conectado na porta que conectado na porta USB, por padr\u00e3o esse n\u00e3o vem instalado. Fa\u00e7a a instala\u00e7\u00e3o do node <code>node-red-node-serialport</code>.</p> <p></p> <p>No node-RED monte o flow:</p> <p></p> <p>Agora configure o node da serial da seguinte forma: </p> <pre><code>- Serial Port: com o nome da porta COM que est\u00e1 alocada para o arduino\n- baud rate: para 9600.\n</code></pre> <p></p> <p>Fa\u00e7a o deplay e se tudo estiver correto, no debug vai aparecer as mensagens recebidas pelo arduino.</p> <p></p>"},{"location":"aulas/iot/lab6/index.html#desenvolvimento-de-um-sistema-supervisorio-para-monitoramento-de-temperatura-e-umidade","title":"Desenvolvimento de um sistema supervis\u00f3rio para monitoramento de temperatura e umidade","text":"<p>Para o desenvolvimento do sistema de supervis\u00f3rio ficar completo basta adaptar o fluxo que temos no node-RED para receber os t\u00f3picos de temperatura e umidade separados e enviar para o dashboard.</p> <p>Exercise</p> <p>Fa\u00e7a as adapta\u00e7\u00f5es necess\u00e1rias para exibir os valores de temperatura e umidade em 2 gauge e 2 chart como na imagem abaixo:</p> <p></p> <p>Exercise</p> <p>Baseado na solu\u00e7\u00e3o do desafio anterior, altere o fluxo para enviar os dados do node-RED via protocolo MQTT. Agora em um segundo computador crie um fluxo no node-RED que recebe os topicos enviados pelo primeiro flow em MQTT.</p>"},{"location":"aulas/iot/lab6/index.html#controlando-o-arduino-pelo-node-red","title":"Controlando o arduino pelo node-RED","text":"<p>Chegou a hora de fazer o caminho de volta, ja mandamos dados para o node-RED, agora \u00e9 vez de receber dados do node-RED. </p> <p>Exercise</p> <p>Adicione um <code>dashboard switch</code> e configure para enviar a string \u201cliga\u201d e \u201cdesliga\u201d pela serial, para controlar um LED do arduino. DICA: Veja o exemplo abaixo como refer\u00eancia.</p> <pre><code>#include &lt;ArduinoJson.h&gt;\nconst int LED = 3;\nconst int TAMANHO = 200;\nvoid setup() {\n  Serial.begin(9600);\n  //O valor padr\u00e3o de 1000ms \u00e9 muito tempo\n  Serial.setTimeout(10);\n  pinMode(LED,OUTPUT);\n}\nvoid loop() {\n  if (Serial.available() &gt; 0) {\n    //L\u00ea o JSON dispon\u00edvel na porta serial:\n    StaticJsonDocument&lt;TAMANHO&gt; json;\n    deserializeJson(json, Serial);\n    if(json.containsKey(\"led\")) {\n      int valor = json[\"led\"];\n      analogWrite(LED, valor);\n    }\n  } \n  delay(300);\n}\n</code></pre>"},{"location":"aulas/iot/lab6/index.html#desafios","title":"Desafios","text":"<p>J\u00e1 construimos toda a infraestrutura com a base necess\u00e1ria para desenvolver os desafios deste lab.</p>"},{"location":"aulas/iot/lab6/index.html#desafio-1-alerta-de-condicoes-climaticas","title":"Desafio 1: Alerta de Condi\u00e7\u00f5es Clim\u00e1ticas","text":"<p>Objetivo: Criar um sistema de alerta que notifica o usu\u00e1rio quando a temperatura e/ou umidade ultrapassam um limite definido.</p>"},{"location":"aulas/iot/lab6/index.html#instrucoes","title":"Instru\u00e7\u00f5es:","text":"<ul> <li>Utilize o Node-RED para definir limites de temperatura e umidade (por exemplo, temperatura acima de 30\u00b0C e umidade abaixo de 40%).</li> <li>Quando os valores lidos pelo sensor DHT11 ultrapassarem esses limites, um alerta deve ser exibido no dashboard.</li> <li>Adicione um LED no Arduino para acender quando os limites forem ultrapassados.</li> </ul>"},{"location":"aulas/iot/lab6/index.html#desafio-2-registro-de-dados","title":"Desafio 2: Registro de Dados","text":"<p>Objetivo: Armazenar os dados de temperatura e umidade em um banco de dados ou arquivo para an\u00e1lise posterior.</p>"},{"location":"aulas/iot/lab6/index.html#instrucoes_1","title":"Instru\u00e7\u00f5es:","text":"<ul> <li>Utilize o Node-RED para encaminhar os dados recebidos do Arduino para um banco de dados de sua escolha (pode ser um banco de dados SQL, NoSQL ou at\u00e9 mesmo um arquivo CSV).</li> </ul>"},{"location":"aulas/iot/lab6/index.html#desafio-3-integracao-com-outros-sensores","title":"Desafio 3: Integra\u00e7\u00e3o com Outros Sensores","text":"<p>Objetivo: Integrar outros sensores ao sistema e exibir seus dados no Node-RED.</p>"},{"location":"aulas/iot/lab6/index.html#instrucoes_2","title":"Instru\u00e7\u00f5es:","text":"<ul> <li>Escolha um ou mais sensores adicionais compat\u00edveis com Arduino (por exemplo, sensor de luminosidade, sensor de movimento, sensor de g\u00e1s, etc.).</li> <li>Integre o(s) sensor(es) escolhido(s) ao seu circuito Arduino.</li> <li>Modifique o c\u00f3digo do Arduino para ler os dados do(s) novo(s) sensor(es) e enviar esses dados para o Node-RED em formato JSON, juntamente com os dados de temperatura e umidade.</li> <li>No Node-RED, configure o dashboard para exibir os dados do(s) novo(s) sensor(es) em tempo real, seja atrav\u00e9s de gr\u00e1ficos, medidores ou outros widgets relevantes.</li> </ul> <p>Como um desafio adicional configurar alertas ou a\u00e7\u00f5es espec\u00edficas com base nos dados do(s) novo(s) sensor(es). Por exemplo, se um sensor de luminosidade detectar que est\u00e1 escuro, um LED pode ser acionado automaticamente.</p>"},{"location":"aulas/iot/lab7/index.html","title":"Index","text":""},{"location":"aulas/iot/lab7/index.html#lab7-api-rest-json-node-red","title":"Lab7 - API REST JSON NODE-RED","text":""},{"location":"aulas/iot/lab7/index.html#criando-servidor-no-node-red","title":"Criando servidor no Node-Red","text":""},{"location":"aulas/iot/lab7/index.html#estrutura-da-api","title":"Estrutura da API:","text":"<ol> <li> <p>Acender ou apagar o LED:</p> </li> <li> <p>Endpoint: <code>/led</code></p> </li> <li> <p>M\u00e9todos:</p> <ul> <li>GET: Retorna o estado atual do LED (0 ou 1).</li> <li>POST: Muda o estado do LED. O corpo da solicita\u00e7\u00e3o deve conter um JSON com o novo estado.</li> <li>PUT: Mesma funcionalidade do POST.</li> <li>DELETE: Desliga o LED.</li> </ul> </li> <li> <p>Capturar o status do bot\u00e3o:</p> </li> <li> <p>Endpoint: <code>/button</code></p> </li> <li>M\u00e9todo:<ul> <li>GET: Retorna o estado atual do bot\u00e3o (pressionado ou n\u00e3o pressionado).</li> </ul> </li> </ol> <p>O objetivo \u00e9 criar os endponts <code>/led</code> e <code>/button</code> que v\u00e3o representar o estado do sensor e atuador conectado ao dispositivo inteligente IoT. </p> <p>O resultado das rotas ser\u00e1:</p> <ul> <li>Endpoint <code>/led</code>:</li> </ul> <p></p> <ul> <li>Endpoint <code>/button</code>:</li> </ul> <p></p> <ul> <li>Monte o fluxo e teste:</li> </ul> <p></p> <p>onde:</p> <ul> <li>function10:</li> </ul> <pre><code>// Supondo que o estado do LED \u00e9 armazenado em uma vari\u00e1vel global.\nvar ledState = global.get(\"ledState\") || 0; // Se n\u00e3o estiver definido, assume 0.\nmsg.payload = {\n    \"state\": ledState\n};\nreturn msg;\n</code></pre> <ul> <li>function11:</li> </ul> <pre><code>var newState = msg.payload.state;\nif (newState === 0 || newState === 1) {\n    global.set(\"ledState\", newState);\n    msg.payload = {\n        \"message\": \"LED atualizado com sucesso.\"\n    };\n} else {\n    msg.payload = {\n        \"message\": \"Estado inv\u00e1lido.\"\n    };\n    msg.statusCode = 400; // C\u00f3digo de erro para \"Bad Request\"\n}\nreturn msg;\n</code></pre> <ul> <li>function12:</li> </ul> <pre><code>global.set(\"ledState\", 0);\nmsg.payload = {\n    \"message\": \"LED desligado com sucesso.\"\n};\nreturn msg;\n</code></pre> <ul> <li>function13:</li> </ul> <pre><code>// Supondo que o estado do bot\u00e3o \u00e9 armazenado em uma vari\u00e1vel global.\nvar buttonState = global.get(\"buttonState\") || 0; \nmsg.payload = {\n    \"state\": buttonState\n};\nreturn msg;\n</code></pre> <ul> <li>function14:</li> </ul> <pre><code>global.set(\"buttonState\", 1);\nreturn msg;\n</code></pre> <ul> <li>function15:</li> </ul> <pre><code>global.set(\"buttonState\", 0);\nreturn msg;\n</code></pre>"},{"location":"aulas/iot/lab7/index.html#cors-cross-origin-resource-sharing","title":"CORS - Cross-Origin Resource Sharing","text":"<p>Quando voc\u00ea cria uma API REST, especialmente para aplica\u00e7\u00f5es de IoT, \u00e9 comum que diferentes clientes (como navegadores web, aplicativos m\u00f3veis ou outros dispositivos) tentem acess\u00e1-la de diferentes origens. Portanto, lidar com o Controle de Acesso de Origem Cruzada (CORS - Cross-Origin Resource Sharing) \u00e9 uma considera\u00e7\u00e3o importante.</p> <p>Por padr\u00e3o, por motivos de seguran\u00e7a, os navegadores restringem solicita\u00e7\u00f5es HTTP de serem feitas entre sites. Isso significa que, se voc\u00ea tiver uma interface web rodando em um dom\u00ednio ou porta e tentar fazer uma solicita\u00e7\u00e3o AJAX para sua API Node-RED em um dom\u00ednio ou porta diferente, o navegador bloquear\u00e1 a solicita\u00e7\u00e3o, a menos que a API indique que essas solicita\u00e7\u00f5es cruzadas s\u00e3o aceit\u00e1veis.</p> <p>O cabe\u00e7alho <code>\"Content-Type\":\"application/json\"</code> informa aos clientes que a API retornar\u00e1 dados no formato JSON. O cabe\u00e7alho <code>\"Access-Control-Allow-Origin\":\"*\"</code> permite que qualquer site fa\u00e7a solicita\u00e7\u00f5es \u00e0 sua API. Isso \u00e9 adequado para desenvolvimento ou em ambientes controlados, mas tenha cuidado ao usar essa configura\u00e7\u00e3o em produ\u00e7\u00e3o devido a considera\u00e7\u00f5es de seguran\u00e7a.</p>"},{"location":"aulas/iot/lab7/index.html#dicas-para-realizar-requisicoes","title":"Dicas para realizar requisi\u00e7\u00f5es","text":"<p>Utilizar o <code>curl</code> \u00e9 uma forma simples de testar APIs diretamente do terminal ou linha de comando.</p> <p>No <code>Windows</code> o <code>CMD</code> interpreta alguns caracteres de maneira especial, a gente precisa ajustar a sintaxe ou usar o <code>PowerShell</code> em vez do CMD.</p> <p>Se for no CMD, o ajuste \u00e9 <code>\\\"</code> para usar <code>\"</code> interna da chave do JSON e fica:</p> <pre><code>curl -X POST -H \"Content-Type: application/json\" -d \"{\\\"state\\\": 0}\" http://localhost:1880/led\n</code></pre> <p>Se for no PowerShell, n\u00e3o muda: permanece:</p> <pre><code>curl -X POST -H 'Content-Type: application/json' -d '{\"state\": 0}' http://localhost:1880/led\n ```\n\nOs outros comandos permanecem iguais:\n\n\n```bash\ncurl -X GET http://localhost:1880/led\n\ncurl -X DELETE http://localhost:1880/led\n\ncurl -X GET http://localhost:1880/button\n</code></pre> <p>Se utilizar o Postman n\u00e3o ter\u00e1 esse problema. </p> <p></p>"},{"location":"aulas/iot/lab7/index.html#mais-informacoes","title":"Mais informa\u00e7\u00f5es","text":"<p>Fa\u00e7a o download do pdf da aula.</p> <ul> <li>arquivo pdf: lab7</li> </ul>"},{"location":"aulas/iot/lab8/index.html","title":"Index","text":""},{"location":"aulas/iot/lab8/index.html#raspberry-pi","title":"Raspberry PI","text":"<p>At\u00e9 agora em nosso curso, trabalhamos com pequenos projetos envolvendo sensores e atuadores, utilizando o Arduino UNO como nossa principal plataforma de hardware. Tamb\u00e9m exploramos integra\u00e7\u00f5es com Python e Node-Red.</p> <p>Neste m\u00f3dulo, iniciaremos nossa imers\u00e3o em computa\u00e7\u00e3o embarcada voltada para a Internet das Coisas (IoT) utilizando o <code>Raspberry PI</code>. Abordaremos t\u00f3picos como: introdu\u00e7\u00e3o \u00e0 Raspberry Pi, Sistema Operacional Linux, inicializa\u00e7\u00e3o da placa Raspberry PI, configura\u00e7\u00e3o e uso dos GPIOs, integra\u00e7\u00e3o com Arduino, Node-Red e muito mais.</p>"},{"location":"aulas/iot/lab8/index.html#conteudo-deste-laboratorio","title":"Conte\u00fado deste Laborat\u00f3rio","text":"<ul> <li>Introdu\u00e7\u00e3o \u00e0 Raspberry PI e compara\u00e7\u00e3o com o Arduino.</li> <li>Primeiros passos com a Raspberry Pi:<ul> <li>Conhecendo o hardware.</li> <li>Instalando o Sistema Operacional na Raspberry PI.</li> <li>Modos de uso: GUI vs. Headless.<ul> <li>Configura\u00e7\u00e3o para acesso via SSH e Wi-Fi no modo Headless.</li> <li>Uso do VNC Viewer.</li> <li>Modo Desktop (GUI).</li> </ul> </li> <li>Controlando os GPIOs: Exemplo com LED.<ul> <li>Controle via linha de comando.</li> <li>Uso de Shell Script.</li> <li>E mais...</li> </ul> </li> </ul> </li> </ul>"},{"location":"aulas/iot/lab8/index.html#raspberry-pi-vs-arduino","title":"Raspberry PI vs. Arduino","text":"<p>Lembrando do Arduino UNO que utilizamos, ele \u00e9 baseado em um <code>microcontrolador</code> de 8-bit (datasheet). Sua arquitetura RISC \u00e9 adequada para sistemas embarcados simples, mas n\u00e3o suporta um sistema operacional completo, o que pode limitar a implementa\u00e7\u00e3o de sistemas mais avan\u00e7ados.</p> <p>Para executar um sistema operacional completo, precisamos de um <code>processador</code>, como os modelos Intel 386, i5, i7, Celeron, entre outros (datasheet do Intel i7). Em aplica\u00e7\u00f5es de computa\u00e7\u00e3o embarcada, muitas vezes optamos por uma alternativa mais compacta e econ\u00f4mica ao computador tradicional, como os <code>SBCs</code> (Single Board Computers).</p> <p>Os SBCs s\u00e3o computadores completos em uma \u00fanica placa, combinando processador, mem\u00f3ria, suporte de rede, v\u00eddeo, \u00e1udio e outros recursos. S\u00e3o compactos e geralmente mais acess\u00edveis que um computador convencional.</p> <p>A <code>Raspberry PI</code> \u00e9 um dos SBCs mais populares e vers\u00e1teis dispon\u00edveis. Foi lan\u00e7ada em 2012 pela Raspberry Pi Foundation e utiliza processadores ARM da Broadcom, similares aos encontrados em smartphones. Desde seu lan\u00e7amento, diversos modelos foram introduzidos, como a Raspberry PI 3, 4, Zero, entre outros.</p> <p>Documenta\u00e7\u00e3o oficial da Raspberry PI</p> <p>Outros modelos de SBCs</p> <p>Com essa introdu\u00e7\u00e3o, vamos aprender a utilizar a Raspberry PI.</p>"},{"location":"aulas/iot/lab8/index.html#desafio-1","title":"Desafio 1","text":"<p>Responda as perguntas abaixo:</p> <p>Question</p> <p>Pergunta 1: Qual dos dois, Raspberry PI ou Arduino, \u00e9 mais adequado para rodar um sistema operacional completo?</p> <ul> <li> Raspberry PI</li> <li> Arduino</li> <li> Ambos</li> </ul> <p>Answer</p> <p>O Raspberry PI possui capacidade de rodar um SO completo.</p> <p>Question</p> <p>Pergunta 2: O Arduino UNO \u00e9 baseado em qual tipo de componente central?</p> <ul> <li> Microcontrolador</li> <li> Processador</li> <li> Disco r\u00edgido</li> <li> Placa de v\u00eddeo </li> </ul> <p>Answer</p> <p>O arduino UNO \u00e9 baseado em um microcontrolador.</p> <p>Question</p> <p>Pergunta 3: Qual \u00e9 a principal vantagem dos computadores de placa \u00fanica (SBC) como o Raspberry PI em rela\u00e7\u00e3o aos computadores convencionais?</p> <ul> <li> Eles t\u00eam mais poder de processamento.</li> <li> Eles podem executar m\u00faltiplos sistemas operacionais simultaneamente.</li> <li> Eles s\u00e3o mais caros e robustos.</li> <li> Eles s\u00e3o de baixo custo e possuem pequenas dimens\u00f5es.</li> </ul> <p>Answer</p> <p>Eles s\u00e3o de baixo custo e possuem pequenas dimens\u00f5es.</p> <p>Progress</p> <p>Continuar...</p>"},{"location":"aulas/iot/lab8/index.html#raspberry-pi-primeiros-passos","title":"Raspberry PI - Primeiros Passos","text":""},{"location":"aulas/iot/lab8/index.html#visao-geral","title":"Vis\u00e3o Geral","text":"<p>H\u00e1 v\u00e1rios modelos de Raspberry PI dispon\u00edveis. Em nosso curso, focaremos na <code>Raspberry PI 3 Model B+</code>.</p> <p></p> <p></p> <p>Complemento: - Fonte de Alimenta\u00e7\u00e3o: 5V @ &gt;2A - Cart\u00e3o SD: micro SD Card &gt;8GB Classe 10 ou superior</p>"},{"location":"aulas/iot/lab8/index.html#sistema-operacional","title":"Sistema Operacional","text":"<p>Existem v\u00e1rias distribui\u00e7\u00f5es de sistemas operacionais compat\u00edveis com a Raspberry PI, incluindo:</p> <ul> <li>Raspbian - Uso geral.</li> <li>Ubuntu - Uso geral.</li> <li>RetroPie - Emulador de videogame.</li> <li>OSMC - Media Center.</li> <li>Home Assistant - Automa\u00e7\u00e3o residencial.</li> <li>E muitos outros...</li> </ul> <p>Chega de teoria! Vamos \u00e0 pr\u00e1tica. Siga este guia atentamente e execute todos os passos.</p> <p>Progress</p> <p>Continuar...</p>"},{"location":"aulas/iot/lab8/index.html#instalando-o-sistema-operacional","title":"Instalando o Sistema Operacional","text":"<p>O sistema operacional da Raspberry PI \u00e9 armazenado em um <code>micro SD Card</code>. Recomenda-se usar um cart\u00e3o de pelo menos 8GB Classe 10 ou superior. Existem v\u00e1rias maneiras de instalar o sistema operacional, e aqui, vamos gui\u00e1-lo passo a passo.</p> <p>As vers\u00f5es do sistema operacional podem ser encontradas aqui. Em nosso curso, utilizaremos o <code>Raspberry Pi OS (legacy)</code>, baseado no Debian 10 (Buster).</p> <p></p> <p>Info</p> <p>Para facilitar, aqui est\u00e1 o link para download.</p> <p>Para gravar o cart\u00e3o SD, recomendamos o uso do <code>Balena Etcher</code>, dispon\u00edvel para v\u00e1rias plataformas.</p> <p>Link para download do Balena Etcher</p> <p>Siga os passos abaixo para preparar seu cart\u00e3o SD:</p> <ol> <li>Insira o cart\u00e3o SD no adaptador USB e conecte-o ao seu computador.</li> <li>Baixe o Raspberry Pi OS.</li> <li>Baixe e instale o Balena Etcher.</li> <li>Abra o Balena Etcher e siga os passos para gravar o cart\u00e3o SD.</li> <li>Ap\u00f3s a grava\u00e7\u00e3o, reconecte o adaptador USB ao computador.</li> <li>Voc\u00ea deve ver duas parti\u00e7\u00f5es, uma delas chamada \"boot\". Se n\u00e3o, formate o cart\u00e3o SD em FAT32 e repita o processo.</li> </ol> <p>Progress</p> <p>Continuar...</p>"},{"location":"aulas/iot/lab8/index.html#modo-de-uso-interface-grafica","title":"Modo de Uso - Interface Gr\u00e1fica","text":"<p>Nota: Esta se\u00e7\u00e3o \u00e9 apenas para conhecimento adicional, pois n\u00e3o usaremos a Raspberry PI desta maneira em nosso curso.</p> <p>Para usar a Raspberry PI como um computador convencional, conecte um monitor via HDMI, um teclado e um mouse. Insira o cart\u00e3o SD gravado e conecte a fonte de alimenta\u00e7\u00e3o. O sistema operacional ser\u00e1 inicializado e estar\u00e1 pronto para uso.</p> <p></p> <p></p>"},{"location":"aulas/iot/lab8/index.html#modo-de-uso-headless","title":"Modo de Uso - Headless","text":"<p>Nesta se\u00e7\u00e3o, aprenderemos a usar a Raspberry PI no modo <code>Headless</code>, sem a necessidade de monitor, teclado ou mouse. Algumas configura\u00e7\u00f5es s\u00e3o necess\u00e1rias antes de iniciar a Raspberry PI neste modo.</p>"},{"location":"aulas/iot/lab8/index.html#habilitando-ssh","title":"Habilitando SSH","text":"<p>Para ativar o acesso SSH, crie um arquivo vazio chamado \"ssh\" na pasta \"boot\" do cart\u00e3o SD.</p> <p>Siga os passos abaixo:</p> <ol> <li>Conecte o cart\u00e3o SD ao adaptador USB e insira-o no computador.</li> <li>Acesse a parti\u00e7\u00e3o chamada \"boot\".</li> <li>Crie um arquivo chamado \"ssh\" (sem extens\u00e3o) na raiz da parti\u00e7\u00e3o.</li> </ol> <p>O resultado deve ser semelhante ao mostrado na imagem:</p> <p></p> <p>Progress</p> <p>Continuar...</p>"},{"location":"aulas/iot/lab8/index.html#configurando-a-rede-wi-fi","title":"Configurando a Rede Wi-Fi","text":"<p>A configura\u00e7\u00e3o da rede Wi-Fi \u00e9 feita atrav\u00e9s do arquivo \"wpa_supplicant.conf\", que deve ser criado na pasta \"boot\" do cart\u00e3o SD.</p> <p>Siga as instru\u00e7\u00f5es abaixo para configurar sua rede Wi-Fi:</p> <ol> <li>Crie um arquivo chamado \"wpa_supplicant.conf\" na raiz da parti\u00e7\u00e3o \"boot\".</li> <li>Abra o arquivo com um editor de texto e configure-o de acordo com o exemplo fornecido.</li> </ol> <p>Nota: Certifique-se de estar conectado \u00e0 mesma rede Wi-Fi que a Raspberry PI.</p> <p>Agora, com tudo configurado, \u00e9 hora de ligar a Raspberry PI e test\u00e1-la.</p>"},{"location":"aulas/iot/lab8/index.html#desafio-2","title":"Desafio 2","text":"<p>Responda as perguntas abaixo:</p> <p>Question</p> <p>Pergunta 4: Qual \u00e9 a principal fun\u00e7\u00e3o do arquivo <code>wpa_supplicant.conf</code> na pasta <code>boot</code> do Raspberry PI?</p> <ul> <li> Habilitar o SSH.</li> <li> Configurar a rede Wi-Fi.</li> <li> Iniciar o sistema operacional.</li> <li> Configurar a sa\u00edda de v\u00eddeo.</li> </ul> <p>Answer</p> <p>Configurar a rede Wi-Fi.</p> <p>Question</p> <p>Pergunta 5: Ao configurar o Raspberry PI no modo <code>Headless</code>, o que \u00e9 necess\u00e1rio fazer para habilitar o acesso SSH?</p> <ul> <li> Criar um arquivo chamado <code>ssh</code> na pasta <code>home</code>.</li> <li> Criar um arquivo chamado <code>ssh</code> na pasta <code>boot</code>.</li> <li> Instalar um software adicional.</li> <li> Configurar o firewall para permitir o acesso SSH.</li> </ul> <p>Answer</p> <p>Criar um arquivo chamado <code>ssh</code> na pasta <code>boot</code>.</p> <p>Question</p> <p>Pergunta 6: Qual software \u00e9 recomendado para acessar o Raspberry PI via SSH a partir de um computador?</p> <ul> <li> WinRAR</li> <li> Balena Etcher</li> <li> PuTTY</li> <li> Microsoft Word</li> </ul> <p>Answer</p> <p>PuTTY</p> <p>Progress</p> <p>Continuar...</p>"},{"location":"aulas/iot/lab8/index.html#primeiro-teste-com-a-raspberry-pi","title":"Primeiro Teste com a Raspberry PI","text":"<p>Para nosso primeiro teste, montaremos um circuito simples para acender um LED. Siga o esquema abaixo:</p> <p></p> <p>No terminal da Raspberry PI, execute os comandos a seguir para controlar o LED:</p> <pre><code># Configura o pino GPIO 17 como sa\u00edda (output)\necho \"17\" &gt; /sys/class/gpio/export\necho \"out\" &gt; /sys/class/gpio/gpio17/direction\n\n# Acende o LED (n\u00edvel l\u00f3gico alto)\necho \"1\" &gt; /sys/class/gpio/gpio17/value\n\n# Apaga o LED (n\u00edvel l\u00f3gico baixo)\necho \"0\" &gt; /sys/class/gpio/gpio17/value\n\n# Libera o pino GPIO 17\necho \"17\" &gt; /sys/class/gpio/unexport\n</code></pre> <p>Se tudo funcionou corretamente, voc\u00ea deve ter visto o LED acender e apagar.</p>"},{"location":"aulas/iot/lab8/index.html#desafio-3-opcional","title":"Desafio 3 (opcional)","text":"<p>Agora \u00e9 sua vez! A Raspberry PI permite controlar seus pinos GPIO usando v\u00e1rias linguagens de programa\u00e7\u00e3o. Escolha sua linguagem preferida e escreva um c\u00f3digo para fazer o LED piscar a cada segundo. Aqui est\u00e1 um exemplo para ajud\u00e1-lo. Acesse Aqui </p>"},{"location":"aulas/iot/lab9/index.html","title":"Index","text":""},{"location":"aulas/iot/lab9/index.html#o-que-vamos-ver-neste-lab","title":"O que vamos ver neste lab?","text":"<ul> <li>Raspberry Pi: <ul> <li>Conhecendo os pinos</li> <li>Usando a biblioteca RPI.GPIO </li> </ul> </li> </ul>"},{"location":"aulas/iot/lab9/index.html#conhecendo-os-pinos-da-raspberry-pi","title":"Conhecendo os pinos da Raspberry Pi","text":"<p>Podemos utilizar a Raspberry Pi para conectar sensores e atuadores, de forma semelhante como foi feito utilizando o Arduino, para isso utilizamos os barramento de pinos da Raspberry Pi chamado de GPIO (General Purpose Input Output). Ao todo s\u00e3o 40 pinos (para RPI 2 ou superior) e de forma geral cada pino possui uma fun\u00e7\u00e3o ou caracteristica especifica.</p> <p>Warning</p> <p>Cuidado: Devemos ter aten\u00e7\u00e3o para n\u00e3o conectar os perifericos na placa de forma incorreta. Existe risco de queimar a Raspberry Pi.  </p> <p>A imagem abaixo \u00e9 um guia simples para cada pino. Parece complicado na primeira vez, mas \u00e9 tranquilo.</p> <p></p> <p>Vamos conhecer o que \u00e9 cada pino:</p> <pre><code>- Pinos de Alimenta\u00e7\u00e3o: \n    - 3.3V (ao todo 2 pinos)\n    - 5V (ao todo 2 pinos)\n    - GND/Ground/0V (ao todo 8 pinos)\n\n- Pinos de interface:\n    - GPIO (General purpose input and output): S\u00e3o os pinos de entrada/saida. A tens\u00e3o de saida \u00e9 de 3.3V.\n    - I2C/SPI/UART: Protocolos de comunica\u00e7\u00e3o especificos utilizados para realizar a interface m\u00f3dulos epecificos com a Raspberry Pi.\n</code></pre> <p>Warning</p> <p>Aten\u00e7\u00e3o: Observe a correla\u00e7\u00e3o dos pinos para n\u00e3o ligar invertido. </p> <p>Exercise</p> <p>Quantos pinos GPIO est\u00e3o disponiveis?</p> <p>Progress</p> <p>Continuar...</p>"},{"location":"aulas/iot/lab9/index.html#configurando-os-gpios","title":"Configurando os GPIOs","text":"<p>No final do lab07 montamos um simples pisca led e programamos configurando os valores dos registradores. Existem formas mais simples de programar os GPIOs da rasbperry pi, vamos programar em Python :) </p> <p>Vamos utilizara biblioteca <code>RPI.GPIO</code>, que permite de forma simples configurar e usar os GPIOs com script em Python, vamos preparar o nosso ambiente de desenvolvimento:</p> <p>Exercise</p> <ul> <li> <p>Inicialize a Raspberry Pi. (modo Desktop ou SSH).</p> <ul> <li>Se tiver d\u00favida de como fazer, volte para o lab07.</li> </ul> </li> <li> <p>Abra o terminal da raspberry pi.</p> </li> <li> <p>Certifique-se de estar com acesso a internet.</p> </li> </ul> <p>No terminal da raspberry pi, atualize os reposit\u00f3rios:</p> <pre><code>sudo apt update\n</code></pre> <p>Em seguida, tente instalar o pacote RPi.GPIO: A documenta\u00e7\u00e3o da biblioteca est\u00e1 disponivel no aqui.</p> <pre><code>sudo apt install rpi.gpio\n</code></pre> <p>Se ainda n\u00e3o estiver instalado, ser\u00e1 instalado. Se j\u00e1 estiver instalado, ser\u00e1 atualizado se uma vers\u00e3o mais recente estiver dispon\u00edvel.</p> <p>Progress</p> <p>Continuar...</p>"},{"location":"aulas/iot/lab9/index.html#conhecendo-a-biblioteca-rpigpio","title":"Conhecendo a biblioteca RPi.GPIO","text":"<p>\u00c9 uma biblioteca simples de usar e vamos ver as principais fun\u00e7\u00f5es da RPi.GPIO atrav\u00e9s do c\u00f3digo de exemplo abaixo:</p> <ul> <li> <p><code>GPIO.setmode()</code> = Define o modo de acesso aos pino da raspberry pi, existem 2 modos de definir a mesma coisa:</p> <ul> <li>GPIO.BOARD  = Posi\u00e7\u00e3o f\u00edsica do pino na raspberry pi</li> <li>GPIO.BCM    = Numero ap\u00f3s GPIOxx</li> </ul> </li> </ul> <p>exemplo: BOARD 11 = GPIO17</p> <ul> <li> <p><code>GPIO.setup()</code> = Define a fun\u00e7\u00e3o do pino, entrada (GPIO.IN) ou saida (GPIO.OUT)</p> </li> <li> <p><code>GPIO.output()</code> = Define o estado do pino definido como saida em nivel logico baixo (GPIO.LOW) ou alto (GPIO.HIGH)</p> </li> <li> <p><code>GPIO.input()</code> = Faz a leitura do estado do pino definido como entrada. Geralmente quando usamos um pino como entrada configuramos no setup o parametro pull_up_down (como exemplo: GPIO.setup(18, GPIO.IN, pull_up_down=GPIO.PUD_UP))</p> </li> </ul> <p>Exercise</p> <p>Monte o circuito abaixo:</p> <p></p> <ul> <li>No terminal da RPI, digite:</li> </ul> <pre><code>cd ~\nmkdir src\ncd src\ntouch blinkled.py  \n</code></pre> <ul> <li>Criamos um diretorio chamado src e um arquivo python chamado blinkled.py</li> <li>Abra o arquivo blinkled.py e escreva o c\u00f3digo abaixo.</li> <li>Para abrir o arquivo digite: nano blinkled.py</li> <li>Ap\u00f3s digitar o c\u00f3digo python, salve e feche o arquivo: Ctlr+X &gt;&gt;&gt; Y </li> <li> <p>Vamos rodar nosso c\u00f3digo python, no terminal digite:</p> <ul> <li>python blinkled.py</li> </ul> </li> <li> <p>Se tudo deu certo, o led est\u00e1 piscando. :)</p> <ul> <li>para interromper o c\u00f3digo aperte Ctrl+C.</li> </ul> </li> </ul> <p>Warning</p> <p>Os 2 c\u00f3digos realizam a mesma fun\u00e7\u00e3o, a diferen\u00e7a est\u00e1 apenas no setmode. Escolha um dos c\u00f3digos para testar. </p> <pre><code>import RPi.GPIO as GPIO  ### import da biblioteca gpio\nimport time\n\n# usando o a posi\u00e7\u00e3o fis\u00edca do pino na raspberry pi\nGPIO.setmode(GPIO.BOARD)\n\n# configura o pino fisico 11 como saida\nGPIO.setup(11, GPIO.OUT)\n\nwhille True:  \n    # escreve no pino 11 nivel logico alto\n    GPIO.output(11, GPIO.HIGH)\n    time.sleep(1) # delay de 1s\n\n    # escreve no pino 11 nivel logico baixo\n    GPIO.output(11, GPIO.LOW)\n    time.sleep(1) # delay de 1s\n\nGPIO.cleanup()  # Limpa configura\u00e7\u00e3o finaliza o programa\n</code></pre> <pre><code>import RPi.GPIO as GPIO  ### import da biblioteca gpio\n\n# usando o numero ap\u00f3s GPIOxx da raspberry pi\nGPIO.setmode(GPIO.BCM)\n\n# configura o GPIO17 como saida\nGPIO.setup(17, GPIO.OUT)\n\nwhille True:  \n    # escreve no GPIO17 nivel logico alto\n    GPIO.output(17, GPIO.HIGH)\n    time.sleep(1) # delay de 1s\n\n    # escreve no GPIO17 nivel logico baixo\n    GPIO.output(17, GPIO.LOW)\n    time.sleep(1) # delay de 1s\n\nGPIO.cleanup()  # Limpa configura\u00e7\u00e3o finaliza o programa\n</code></pre>"},{"location":"aulas/iot/lab9/index.html#desafios","title":"Desafios","text":"<p>Agora que j\u00e1 entendemos a estrutura b\u00e1sica do script python, fa\u00e7a os <code>Desafios</code> abaixo.</p> <p>Exercise</p> <p>Sem\u00e1faro de transito: </p> <pre><code>- Monte um circuito com 3 leds (1 verde, 1 amarelo, 1 vermelho);\n- crie um novo script chamado semaforo.py;\n- Escreva um c\u00f3digo que ir\u00e1 acender os leds na sequ\u00eancia e intervalo:\n    - Verde (5segundos)\n    - Amarelo (3segundos)\n    - Vermelho (6segundos)\n    - loop (volta para o verde)\n</code></pre> <p>Exercise</p> <p>leitura de bot\u00e3o e Led: </p> <ul> <li>Monte o circuito: </li> </ul> <p></p> <ul> <li>Escreva um c\u00f3digo que:<ul> <li>Enquanto nenhum bot\u00e3o for pressionado, os leds ficam apagados;</li> <li>Se o bot\u00e3o1 for pressionado:<ul> <li>os leds acendem na sequ\u00eancia: Verde - Amarelo - Vermelho</li> </ul> </li> <li>Se o bot\u00e3o2 for pressionado:<ul> <li>os leds acendem na sequencia: Vermelho - Amarelo - Verde </li> </ul> </li> </ul> </li> </ul> <p>Dica: Geralmente quando usamos algum pino como entrada configuramos no setup o parametro pull_up_down (como exemplo: GPIO.setup(18, GPIO.IN, pull_up_down=GPIO.PUD_UP) ou GPIO.setup(18, GPIO.IN, pull_up_down=GPIO.PUD_DOWN).</p> <p>Exercise</p> <p>Sensor de temperatura: Para quem tiver curiosidade pode dar uma olhada como utilizar o sensor de temperatura DTH11 neste link.</p> <p>Exercise</p> <p></p> <p>Desenvolva um Sensor de estacionamento veicular. A id\u00e9ia \u00e9 simples. Vamos utilizar 1 sensor de dist\u00e2ncia ultrass\u00f4nico e 3 leds de cores difenciadas. Parte do problema j\u00e1 est\u00e1 resolvido voc\u00ea pode acessar o tutorial adaptar o c\u00f3digo do Sensor HC-SR04 e implementar a logica dos led.</p>"},{"location":"aulas/iot/modulos/modulo1.html","title":"M\u00f3dulo 1: Introdu\u00e7\u00e3o ao Arduino IDE e Fundamentos de Programa\u00e7\u00e3o","text":"<p>Bem-vindo ao M\u00f3dulo 1 do curso \"Programa\u00e7\u00e3o em Arduino: Conceitos Fundamentais sem Hardware\". Neste m\u00f3dulo, voc\u00ea ser\u00e1 introduzido ao ambiente de desenvolvimento Arduino IDE e aos fundamentos da programa\u00e7\u00e3o em C/C++ no contexto do Arduino. O foco ser\u00e1 na compreens\u00e3o da estrutura b\u00e1sica de um sketch (programa Arduino) e nos conceitos iniciais de vari\u00e1veis e tipos de dados.</p>"},{"location":"aulas/iot/modulos/modulo1.html#objetivos-do-modulo","title":"Objetivos do M\u00f3dulo","text":"<ul> <li>Instalar e configurar o Arduino IDE.</li> <li>Compreender a estrutura b\u00e1sica de um sketch Arduino.</li> <li>Familiarizar-se com as fun\u00e7\u00f5es <code>setup()</code> e <code>loop()</code>.</li> <li>Escrever e executar o primeiro programa \"Hello, World!\" usando o Monitor Serial.</li> <li>Entender a declara\u00e7\u00e3o e inicializa\u00e7\u00e3o de vari\u00e1veis.</li> <li>Conhecer os tipos de dados primitivos em Arduino: <code>int</code>, <code>float</code>, <code>char</code>, <code>boolean</code>.</li> </ul>"},{"location":"aulas/iot/modulos/modulo1.html#1-introducao-ao-arduino-ide","title":"1. Introdu\u00e7\u00e3o ao Arduino IDE","text":""},{"location":"aulas/iot/modulos/modulo1.html#11-o-que-e-o-arduino-ide","title":"1.1 O que \u00e9 o Arduino IDE?","text":"<p>O Arduino IDE (Integrated Development Environment) \u00e9 um ambiente de desenvolvimento integrado que permite escrever, compilar e enviar c\u00f3digo para placas Arduino. Ele fornece uma interface simples e intuitiva para programar microcontroladores usando uma linguagem baseada em C/C++.</p>"},{"location":"aulas/iot/modulos/modulo1.html#12-instalacao-do-arduino-ide","title":"1.2 Instala\u00e7\u00e3o do Arduino IDE","text":"<p>Passos para instalar o Arduino IDE:</p>"},{"location":"aulas/iot/modulos/modulo1.html#download","title":"Download:","text":"<ol> <li>Acesse o site oficial: https://www.arduino.cc/en/software</li> <li>Escolha a vers\u00e3o compat\u00edvel com o seu sistema operacional (Windows, macOS, Linux).</li> </ol>"},{"location":"aulas/iot/modulos/modulo1.html#instalacao","title":"Instala\u00e7\u00e3o:","text":"<ol> <li>Execute o arquivo baixado e siga as instru\u00e7\u00f5es de instala\u00e7\u00e3o padr\u00e3o.</li> <li>Aceite os termos de licen\u00e7a e selecione os componentes que deseja instalar.</li> </ol>"},{"location":"aulas/iot/modulos/modulo1.html#primeira-execucao","title":"Primeira Execu\u00e7\u00e3o:","text":"<ol> <li>Abra o Arduino IDE ap\u00f3s a instala\u00e7\u00e3o para verificar se est\u00e1 funcionando corretamente.</li> </ol> <p>Nota: Para este curso, n\u00e3o \u00e9 necess\u00e1rio ter uma placa Arduino conectada ao computador, pois utilizaremos o Monitor Serial e simuladores quando necess\u00e1rio.</p>"},{"location":"aulas/iot/modulos/modulo1.html#2-estrutura-basica-de-um-sketch-arduino","title":"2. Estrutura B\u00e1sica de um Sketch Arduino","text":"<p>Um sketch \u00e9 o nome dado a um programa escrito para o Arduino. Todo sketch possui uma estrutura b\u00e1sica composta pelas fun\u00e7\u00f5es <code>setup()</code> e <code>loop()</code>.</p>"},{"location":"aulas/iot/modulos/modulo1.html#21-funcao-setup","title":"2.1 Fun\u00e7\u00e3o <code>setup()</code>","text":"<pre><code>void setup() {\n  // C\u00f3digo a ser executado uma vez no in\u00edcio\n}\n</code></pre> <p>Prop\u00f3sito: A fun\u00e7\u00e3o <code>setup()</code> \u00e9 chamada uma vez quando o programa inicia. \u00c9 usada para inicializar vari\u00e1veis, configurar pinos e iniciar bibliotecas.</p>"},{"location":"aulas/iot/modulos/modulo1.html#22-funcao-loop","title":"2.2 Fun\u00e7\u00e3o <code>loop()</code>","text":"<pre><code>void loop() {\n  // C\u00f3digo a ser executado continuamente\n}\n</code></pre> <p>Prop\u00f3sito: Ap\u00f3s a execu\u00e7\u00e3o da <code>setup()</code>, a fun\u00e7\u00e3o <code>loop()</code> \u00e9 chamada repetidamente em um ciclo infinito. \u00c9 onde o c\u00f3digo principal do programa \u00e9 executado, permitindo que ele responda a eventos e execute tarefas cont\u00ednuas.</p>"},{"location":"aulas/iot/modulos/modulo1.html#23-exemplo-de-estrutura-basica","title":"2.3 Exemplo de Estrutura B\u00e1sica","text":"<pre><code>void setup() {\n  // Inicializa\u00e7\u00f5es\n}\n\nvoid loop() {\n  // C\u00f3digo principal\n}\n</code></pre>"},{"location":"aulas/iot/modulos/modulo1.html#3-primeiro-programa-hello-world-no-monitor-serial","title":"3. Primeiro Programa: \"Hello, World!\" no Monitor Serial","text":"<p>Vamos escrever um programa simples que imprime \"Hello, World!\" no Monitor Serial do Arduino IDE.</p>"},{"location":"aulas/iot/modulos/modulo1.html#31-o-que-e-o-monitor-serial","title":"3.1 O que \u00e9 o Monitor Serial?","text":"<p>O Monitor Serial \u00e9 uma ferramenta integrada no Arduino IDE que permite enviar e receber dados pela porta serial. Ele \u00e9 \u00fatil para depura\u00e7\u00e3o e intera\u00e7\u00e3o com o programa em execu\u00e7\u00e3o.</p>"},{"location":"aulas/iot/modulos/modulo1.html#32-escrevendo-o-programa","title":"3.2 Escrevendo o Programa","text":"<p>Passo 1: Abra o Arduino IDE e crie um novo sketch.</p> <p>Passo 2: Digite o seguinte c\u00f3digo:</p> <pre><code>void setup() {\n  Serial.begin(9600); // Inicia a comunica\u00e7\u00e3o serial a 9600 bps\n}\n\nvoid loop() {\n  Serial.println(\"Hello, World!\"); // Imprime \"Hello, World!\" no Monitor Serial\n  delay(1000); // Aguarda 1 segundo\n}\n</code></pre> <p>Explica\u00e7\u00e3o do C\u00f3digo:</p> <ul> <li><code>Serial.begin(9600);</code> inicia a comunica\u00e7\u00e3o serial na taxa de 9600 bits por segundo (bps).</li> <li><code>Serial.println(\"Hello, World!\");</code> envia a string \"Hello, World!\" seguida de uma nova linha para o Monitor Serial.</li> <li><code>delay(1000);</code> pausa a execu\u00e7\u00e3o por 1000 milissegundos (1 segundo).</li> </ul> <p>Passo 3: Compilar e Executar</p> <ul> <li>Compilar: Clique no bot\u00e3o de verifica\u00e7\u00e3o (\u2714) para compilar o c\u00f3digo e verificar se h\u00e1 erros.</li> <li>Executar: Como n\u00e3o estamos usando hardware f\u00edsico, podemos simular a execu\u00e7\u00e3o ou simplesmente entender que o c\u00f3digo enviaria \"Hello, World!\" ao Monitor Serial a cada segundo.</li> </ul> <p>Passo 4: Abrir o Monitor Serial</p> <ol> <li>No Arduino IDE, clique em Ferramentas &gt; Monitor Serial ou pressione <code>Ctrl + Shift + M</code>.</li> <li>Configure a taxa de transmiss\u00e3o para 9600 baud (deve corresponder ao valor definido em <code>Serial.begin()</code>).</li> </ol> <p>Resultado Esperado:</p> <pre><code>Hello, World!\nHello, World!\nHello, World!\n...\n</code></pre> <p>A mensagem ser\u00e1 repetida a cada segundo.</p>"},{"location":"aulas/iot/modulos/modulo1.html#4-variaveis-e-tipos-de-dados","title":"4. Vari\u00e1veis e Tipos de Dados","text":"<p>Vari\u00e1veis s\u00e3o espa\u00e7os na mem\u00f3ria do microcontrolador que armazenam valores que podem ser alterados durante a execu\u00e7\u00e3o do programa. Em Arduino, as vari\u00e1veis devem ser declaradas com um tipo de dado espec\u00edfico.</p>"},{"location":"aulas/iot/modulos/modulo1.html#41-declaracao-e-inicializacao-de-variaveis","title":"4.1 Declara\u00e7\u00e3o e Inicializa\u00e7\u00e3o de Vari\u00e1veis","text":"<p>Declara\u00e7\u00e3o: Informar ao compilador o nome e o tipo da vari\u00e1vel.</p> <pre><code>int numero; // Declara uma vari\u00e1vel inteira chamada 'numero'\n</code></pre> <p>Inicializa\u00e7\u00e3o: Atribuir um valor inicial \u00e0 vari\u00e1vel.</p> <pre><code>numero = 10; // Atribui o valor 10 \u00e0 vari\u00e1vel 'numero'\n</code></pre> <p>Declara\u00e7\u00e3o e Inicializa\u00e7\u00e3o Simult\u00e2nea:</p> <pre><code>int numero = 10; // Declara e inicializa 'numero' com 10\n</code></pre>"},{"location":"aulas/iot/modulos/modulo1.html#42-tipos-de-dados-primitivos","title":"4.2 Tipos de Dados Primitivos","text":""},{"location":"aulas/iot/modulos/modulo1.html#421-int-inteiro","title":"4.2.1 <code>int</code> (Inteiro)","text":"<ul> <li>Descri\u00e7\u00e3o: Armazena n\u00fameros inteiros, positivos ou negativos, sem decimais.</li> <li>Tamanho: Geralmente 16 bits no Arduino Uno (varia conforme a placa).</li> <li>Intervalo: De -32.768 a 32.767 (para 16 bits).</li> <li>Exemplo:</li> </ul> <pre><code>int idade = 25;\n</code></pre>"},{"location":"aulas/iot/modulos/modulo1.html#422-float-ponto-flutuante","title":"4.2.2 <code>float</code> (Ponto Flutuante)","text":"<ul> <li>Descri\u00e7\u00e3o: Armazena n\u00fameros com casas decimais.</li> <li>Tamanho: 32 bits.</li> <li>Precis\u00e3o: Aproximadamente 6 a 7 d\u00edgitos significativos.</li> <li>Exemplo:</li> </ul> <pre><code>float temperatura = 36.5;\n</code></pre>"},{"location":"aulas/iot/modulos/modulo1.html#423-char-caractere","title":"4.2.3 <code>char</code> (Caractere)","text":"<ul> <li>Descri\u00e7\u00e3o: Armazena um \u00fanico caractere ou pequenos n\u00fameros inteiros.</li> <li>Tamanho: 8 bits.</li> <li>Intervalo: De -128 a 127.</li> <li>Exemplo:</li> </ul> <pre><code>char letra = 'A';\n</code></pre>"},{"location":"aulas/iot/modulos/modulo1.html#424-boolean-booleano","title":"4.2.4 <code>boolean</code> (Booleano)","text":"<ul> <li>Descri\u00e7\u00e3o: Armazena valores l\u00f3gicos <code>true</code> (verdadeiro) ou <code>false</code> (falso).</li> <li>Tamanho: 8 bits (apesar de usar apenas 1 bit).</li> <li>Exemplo:</li> </ul> <pre><code>boolean estado = true;\n</code></pre>"},{"location":"aulas/iot/modulos/modulo1.html#43-exemplo-pratico-usando-variaveis","title":"4.3 Exemplo Pr\u00e1tico: Usando Vari\u00e1veis","text":"<p>Vamos criar um programa que declara diferentes tipos de vari\u00e1veis e as imprime no Monitor Serial.</p> <p>C\u00f3digo:</p> <pre><code>void setup() {\n  Serial.begin(9600);\n\n  int numero = 42;\n  float pi = 3.1416;\n  char caractere = 'C';\n  boolean verdade = true;\n\n  Serial.print(\"N\u00famero inteiro: \");\n  Serial.println(numero);\n\n  Serial.print(\"N\u00famero float: \");\n  Serial.println(pi);\n\n  Serial.print(\"Caractere: \");\n  Serial.println(caractere);\n\n  Serial.print(\"Valor booleano: \");\n  Serial.println(verdade);\n}\n\nvoid loop() {\n  // N\u00e3o h\u00e1 c\u00f3digo no loop\n}\n</code></pre> <p>Explica\u00e7\u00e3o do C\u00f3digo:</p> <ul> <li><code>Serial.print()</code> vs. <code>Serial.println()</code>:</li> <li><code>Serial.print()</code> envia o dado sem pular para a pr\u00f3xima linha.</li> <li><code>Serial.println()</code> envia o dado e adiciona uma nova linha.</li> <li>As vari\u00e1veis s\u00e3o declaradas e inicializadas dentro da fun\u00e7\u00e3o <code>setup()</code>.</li> </ul> <p>Resultado Esperado no Monitor Serial:</p> <pre><code>N\u00famero inteiro: 42\nN\u00famero float: 3.14\nCaractere: C\nValor booleano: 1\n</code></pre> <p>Observa\u00e7\u00e3o:</p> <ul> <li>O valor booleano <code>true</code> \u00e9 impresso como <code>1</code>, e <code>false</code> seria <code>0</code>.</li> <li>O n\u00famero <code>float</code> pode ser arredondado dependendo da configura\u00e7\u00e3o.</li> </ul>"},{"location":"aulas/iot/modulos/modulo1.html#5-exercicios-praticos","title":"5. Exerc\u00edcios Pr\u00e1ticos","text":""},{"location":"aulas/iot/modulos/modulo1.html#exercicio-1-modificar-o-hello-world","title":"Exerc\u00edcio 1: Modificar o \"Hello, World!\"","text":"<p>Tarefa: Altere o programa \"Hello, World!\" para que ele pe\u00e7a ao usu\u00e1rio um nome (via Monitor Serial) e ent\u00e3o exiba \"Hello, [Nome]!\".</p> <p>Dicas:</p> <ul> <li>Use <code>Serial.readString()</code> para ler a entrada do usu\u00e1rio.</li> <li>Lembre-se de configurar o Monitor Serial para enviar nova linha ou retorno de carro ap\u00f3s a entrada.</li> </ul> <p>C\u00f3digo Exemplo:</p> <pre><code>String nome; // Declara uma vari\u00e1vel do tipo String\n\nvoid setup() {\n  Serial.begin(9600);\n  Serial.println(\"Digite seu nome:\");\n\n  // Aguarda at\u00e9 que haja dados dispon\u00edveis\n  while (Serial.available() == 0) {\n    // Aguarda o usu\u00e1rio digitar\n  }\n\n  nome = Serial.readString(); // L\u00ea a string digitada\n  Serial.print(\"Hello, \");\n  Serial.print(nome);\n}\n\nvoid loop() {\n  // C\u00f3digo vazio\n}\n</code></pre>"},{"location":"aulas/iot/modulos/modulo1.html#exercicio-2-calculadora-simples","title":"Exerc\u00edcio 2: Calculadora Simples","text":"<p>Tarefa: Escreva um programa que solicite dois n\u00fameros inteiros ao usu\u00e1rio e exiba a soma, subtra\u00e7\u00e3o, multiplica\u00e7\u00e3o e divis\u00e3o desses n\u00fameros.</p> <p>Dicas:</p> <ul> <li>Use <code>Serial.parseInt()</code> para ler n\u00fameros inteiros do Monitor Serial.</li> <li>Cuidado com a divis\u00e3o por zero.</li> </ul>"},{"location":"aulas/iot/modulos/modulo1.html#6-conceitos-importantes","title":"6. Conceitos Importantes","text":""},{"location":"aulas/iot/modulos/modulo1.html#61-comentarios-no-codigo","title":"6.1 Coment\u00e1rios no C\u00f3digo","text":"<p>Coment\u00e1rios de Linha \u00danica: Usando <code>//</code></p> <pre><code>// Este \u00e9 um coment\u00e1rio de linha \u00fanica\n</code></pre> <p>Coment\u00e1rios de M\u00faltiplas Linhas: Usando <code>/* */</code></p> <pre><code>/*\n   Este \u00e9 um coment\u00e1rio\n   de m\u00faltiplas linhas\n*/\n</code></pre> <p>Import\u00e2ncia: Coment\u00e1rios ajudam a documentar o c\u00f3digo, tornando-o mais leg\u00edvel e f\u00e1cil de entender.</p>"},{"location":"aulas/iot/modulos/modulo1.html#62-boas-praticas","title":"6.2 Boas Pr\u00e1ticas","text":"<ul> <li>Nomes de Vari\u00e1veis Descritivos: Use nomes que indiquem o prop\u00f3sito da vari\u00e1vel.</li> </ul> <pre><code>int contador; // Melhor que 'c' ou 'x'\n</code></pre> <ul> <li>Indenta\u00e7\u00e3o e Formata\u00e7\u00e3o: Organize o c\u00f3digo com indenta\u00e7\u00e3o consistente para melhorar a legibilidade.</li> <li>Evitar Vari\u00e1veis Globais Desnecess\u00e1rias: Declare vari\u00e1veis dentro do menor escopo poss\u00edvel.</li> </ul>"},{"location":"aulas/iot/modulos/modulo10.html","title":"M\u00f3dulo 10: Comunica\u00e7\u00e3o Serial Avan\u00e7ada","text":"<p>Bem-vindo ao M\u00f3dulo 10 do curso \"Programa\u00e7\u00e3o em Arduino: Conceitos Fundamentais sem Hardware\". Neste m\u00f3dulo, voc\u00ea ir\u00e1 aprofundar seu conhecimento sobre comunica\u00e7\u00e3o serial na linguagem de programa\u00e7\u00e3o Arduino (C/C++). A comunica\u00e7\u00e3o serial \u00e9 essencial para a troca de dados entre o Arduino e outros dispositivos, como computadores, m\u00f3dulos de comunica\u00e7\u00e3o e outros microcontroladores.</p>"},{"location":"aulas/iot/modulos/modulo10.html#objetivos-do-modulo","title":"Objetivos do M\u00f3dulo","text":"<ul> <li>Compreender os conceitos avan\u00e7ados de comunica\u00e7\u00e3o serial.</li> <li>Aprender a configurar e utilizar diferentes protocolos de comunica\u00e7\u00e3o serial, incluindo UART, I2C e SPI.</li> <li>Implementar comunica\u00e7\u00e3o serial entre m\u00faltiplos dispositivos Arduino.</li> <li>Utilizar a biblioteca <code>SoftwareSerial</code> para criar portas seriais adicionais.</li> <li>Gerenciar a transfer\u00eancia e o parsing de dados de forma eficiente.</li> <li>Resolver exerc\u00edcios pr\u00e1ticos para consolidar o conhecimento sobre comunica\u00e7\u00e3o serial avan\u00e7ada.</li> </ul>"},{"location":"aulas/iot/modulos/modulo10.html#1-introducao-a-comunicacao-serial-avancada","title":"1. Introdu\u00e7\u00e3o \u00e0 Comunica\u00e7\u00e3o Serial Avan\u00e7ada","text":""},{"location":"aulas/iot/modulos/modulo10.html#11-revisao-da-comunicacao-serial-basica","title":"1.1 Revis\u00e3o da Comunica\u00e7\u00e3o Serial B\u00e1sica","text":"<p>Anteriormente, aprendemos a utilizar o Monitor Serial para enviar e receber dados entre o Arduino e o computador. Neste m\u00f3dulo, expandiremos esse conhecimento para incluir comunica\u00e7\u00e3o entre dispositivos e utiliza\u00e7\u00e3o de protocolos mais complexos.</p>"},{"location":"aulas/iot/modulos/modulo10.html#12-importancia-da-comunicacao-serial-avancada","title":"1.2 Import\u00e2ncia da Comunica\u00e7\u00e3o Serial Avan\u00e7ada","text":"<ul> <li>Interconectividade: Permite que o Arduino se comunique com uma variedade de dispositivos, como sensores avan\u00e7ados, m\u00f3dulos de comunica\u00e7\u00e3o (Wi-Fi, Bluetooth) e outros microcontroladores.</li> <li>Controle Remoto: Facilita o controle e monitoramento do Arduino a partir de dispositivos externos.</li> <li>Transfer\u00eancia de Dados: Habilita a troca eficiente de grandes volumes de dados entre dispositivos.</li> </ul>"},{"location":"aulas/iot/modulos/modulo10.html#2-protocolos-de-comunicacao-serial","title":"2. Protocolos de Comunica\u00e7\u00e3o Serial","text":""},{"location":"aulas/iot/modulos/modulo10.html#21-uart-universal-asynchronous-receivertransmitter","title":"2.1 UART (Universal Asynchronous Receiver/Transmitter)","text":"<p>UART \u00e9 um protocolo de comunica\u00e7\u00e3o serial ass\u00edncrona que utiliza dois fios principais: TX (transmiss\u00e3o) e RX (recep\u00e7\u00e3o).</p> <p>Caracter\u00edsticas:</p> <ul> <li>Comunica\u00e7\u00e3o ponto a ponto.</li> <li>N\u00e3o requer um rel\u00f3gio compartilhado.</li> <li>Configura\u00e7\u00f5es comuns: baud rate, paridade, bits de dados e bits de parada.</li> </ul> <p>Exemplo de Configura\u00e7\u00e3o UART:</p> <pre><code>void setup() {\n    Serial.begin(9600); // Inicializa a comunica\u00e7\u00e3o serial a 9600 baud\n}\n\nvoid loop() {\n    if (Serial.available() &gt; 0) {\n        char recebido = Serial.read();\n        Serial.print(\"Voc\u00ea digitou: \");\n        Serial.println(recebido);\n    }\n}\n</code></pre>"},{"location":"aulas/iot/modulos/modulo10.html#22-i2c-inter-integrated-circuit","title":"2.2 I2C (Inter-Integrated Circuit)","text":"<p>I2C \u00e9 um protocolo de comunica\u00e7\u00e3o serial s\u00edncrona que utiliza dois fios: SDA (Serial Data) e SCL (Serial Clock).</p> <p>Caracter\u00edsticas:</p> <ul> <li>Comunica\u00e7\u00e3o multi-mestre e multi-escravo.</li> <li>Utiliza endere\u00e7amento para identificar dispositivos.</li> <li>Ideal para comunica\u00e7\u00e3o com sensores e dispositivos que possuem suporte a I2C.</li> </ul> <p>Exemplo de Comunica\u00e7\u00e3o I2C:</p> <pre><code>#include &lt;Wire.h&gt;\n\nvoid setup() {\n    Wire.begin(); // Inicia o I2C como mestre\n    Serial.begin(9600);\n}\n\nvoid loop() {\n    Wire.beginTransmission(8); // Endere\u00e7o do dispositivo escravo\n    Wire.write(\"Hello\");\n    Wire.endTransmission();\n    delay(1000);\n}\n</code></pre>"},{"location":"aulas/iot/modulos/modulo10.html#23-spi-serial-peripheral-interface","title":"2.3 SPI (Serial Peripheral Interface)","text":"<p>SPI \u00e9 um protocolo de comunica\u00e7\u00e3o serial s\u00edncrona que utiliza quatro fios: MOSI (Master Out Slave In), MISO (Master In Slave Out), SCK (Serial Clock) e SS (Slave Select).</p> <p>Caracter\u00edsticas:</p> <ul> <li>Comunica\u00e7\u00e3o full-duplex.</li> <li>Alta velocidade de transfer\u00eancia de dados.</li> <li>Utilizado para comunica\u00e7\u00e3o com dispositivos de alta velocidade, como cart\u00f5es SD e displays LCD.</li> </ul> <p>Exemplo de Comunica\u00e7\u00e3o SPI:</p> <pre><code>#include &lt;SPI.h&gt;\n\nvoid setup() {\n    SPI.begin(); // Inicia o SPI como mestre\n    pinMode(10, OUTPUT); // SS\n    digitalWrite(10, HIGH);\n    Serial.begin(9600);\n}\n\nvoid loop() {\n    digitalWrite(10, LOW);\n    SPI.transfer(0xFF); // Envia byte\n    digitalWrite(10, HIGH);\n    delay(1000);\n}\n</code></pre>"},{"location":"aulas/iot/modulos/modulo10.html#3-comunicacao-serial-entre-multiplos-dispositivos-arduino","title":"3. Comunica\u00e7\u00e3o Serial Entre M\u00faltiplos Dispositivos Arduino","text":""},{"location":"aulas/iot/modulos/modulo10.html#31-comunicacao-uart-entre-dois-arduinos","title":"3.1 Comunica\u00e7\u00e3o UART Entre Dois Arduinos","text":"<p>Configura\u00e7\u00e3o:</p> <ul> <li>Conectar o pino TX do Arduino A ao pino RX do Arduino B.</li> <li>Conectar o pino RX do Arduino A ao pino TX do Arduino B.</li> <li>Conectar GND entre os dois Arduinos.</li> </ul> <p>Exemplo de C\u00f3digo para o Arduino A (Transmissor):</p> <pre><code>void setup() {\n    Serial.begin(9600);\n}\n\nvoid loop() {\n    Serial.println(\"Ol\u00e1 Arduino B!\");\n    delay(1000);\n}\n</code></pre> <p>Exemplo de C\u00f3digo para o Arduino B (Receptor):</p> <pre><code>void setup() {\n    Serial.begin(9600);\n}\n\nvoid loop() {\n    if (Serial.available() &gt; 0) {\n        String mensagem = Serial.readString();\n        Serial.print(\"Recebi: \");\n        Serial.println(mensagem);\n    }\n}\n</code></pre>"},{"location":"aulas/iot/modulos/modulo10.html#32-comunicacao-i2c-entre-multiplos-dispositivos-arduino","title":"3.2 Comunica\u00e7\u00e3o I2C Entre M\u00faltiplos Dispositivos Arduino","text":"<p>Configura\u00e7\u00e3o:</p> <ul> <li>Conectar SDA a SDA e SCL a SCL entre os Arduinos.</li> <li>Definir endere\u00e7os \u00fanicos para cada dispositivo escravo.</li> </ul> <p>Exemplo de C\u00f3digo para o Arduino Mestre:</p> <pre><code>#include &lt;Wire.h&gt;\n\nvoid setup() {\n    Wire.begin(); // Inicia como mestre\n    Serial.begin(9600);\n}\n\nvoid loop() {\n    Wire.beginTransmission(8); // Endere\u00e7o do escravo\n    Wire.write(\"Dados do Mestre\");\n    Wire.endTransmission();\n    delay(1000);\n}\n</code></pre> <p>Exemplo de C\u00f3digo para o Arduino Escravo:</p> <pre><code>#include &lt;Wire.h&gt;\n\nvoid setup() {\n    Wire.begin(8); // Endere\u00e7o do escravo\n    Wire.onReceive(receiveEvent);\n    Serial.begin(9600);\n}\n\nvoid loop() {\n    // N\u00e3o h\u00e1 c\u00f3digo no loop\n}\n\nvoid receiveEvent(int bytes) {\n    while (Wire.available()) {\n        char c = Wire.read();\n        Serial.print(c);\n    }\n    Serial.println();\n}\n</code></pre>"},{"location":"aulas/iot/modulos/modulo10.html#4-utilizando-a-biblioteca-softwareserial","title":"4. Utilizando a Biblioteca <code>SoftwareSerial</code>","text":"<p>A biblioteca <code>SoftwareSerial</code> permite criar portas seriais adicionais em pinos digitais, permitindo comunica\u00e7\u00e3o com m\u00faltiplos dispositivos seriais.</p>"},{"location":"aulas/iot/modulos/modulo10.html#41-configuracao-da-softwareserial","title":"4.1 Configura\u00e7\u00e3o da <code>SoftwareSerial</code>","text":"<p>Exemplo de Uso:</p> <pre><code>#include &lt;SoftwareSerial.h&gt;\n\n// Define os pinos RX e TX para a SoftwareSerial\nSoftwareSerial meuSerial(10, 11); // RX, TX\n\nvoid setup() {\n    Serial.begin(9600);        // Porta serial padr\u00e3o\n    meuSerial.begin(4800);     // Porta serial adicional\n    Serial.println(\"Iniciando comunica\u00e7\u00e3o serial...\");\n}\n\nvoid loop() {\n    if (meuSerial.available()) {\n        char c = meuSerial.read();\n        Serial.print(\"Recebi via SoftwareSerial: \");\n        Serial.println(c);\n    }\n\n    if (Serial.available()) {\n        char c = Serial.read();\n        meuSerial.print(c);\n    }\n}\n</code></pre> <p>Explica\u00e7\u00e3o:</p> <ul> <li>Defini\u00e7\u00e3o: <code>SoftwareSerial meuSerial(10, 11);</code> define pinos 10 e 11 como RX e TX adicionais.</li> <li>Inicializa\u00e7\u00e3o: <code>meuSerial.begin(4800);</code> configura a velocidade da porta serial adicional.</li> <li>Transfer\u00eancia de Dados: Dados recebidos na <code>SoftwareSerial</code> s\u00e3o enviados para a porta serial padr\u00e3o e vice-versa.</li> </ul>"},{"location":"aulas/iot/modulos/modulo10.html#5-gerenciamento-de-transferencia-e-parsing-de-dados","title":"5. Gerenciamento de Transfer\u00eancia e Parsing de Dados","text":""},{"location":"aulas/iot/modulos/modulo10.html#51-formatacao-de-dados","title":"5.1 Formata\u00e7\u00e3o de Dados","text":"<p>Para uma comunica\u00e7\u00e3o eficiente, \u00e9 importante definir um protocolo de formata\u00e7\u00e3o de dados, utilizando delimitadores ou estruturas espec\u00edficas.</p> <p>Exemplo de Dados Delimitados por V\u00edrgulas:</p> <pre><code>String dados = \"23.5,47.8,15.2\"; // Temperatura, Umidade, Press\u00e3o\nSerial.println(dados);\n</code></pre>"},{"location":"aulas/iot/modulos/modulo10.html#52-parsing-de-dados-recebidos","title":"5.2 Parsing de Dados Recebidos","text":"<p>No lado receptor, os dados podem ser divididos e convertidos para os tipos apropriados.</p> <p>Exemplo de Parsing:</p> <pre><code>void setup() {\n    Serial.begin(9600);\n}\n\nvoid loop() {\n    if (Serial.available() &gt; 0) {\n        String recebidos = Serial.readStringUntil('\\n');\n        int primeiraVirgula = recebidos.indexOf(',');\n        int segundaVirgula = recebidos.indexOf(',', primeiraVirgula + 1);\n\n        float temperatura = recebidos.substring(0, primeiraVirgula).toFloat();\n        float umidade = recebidos.substring(primeiraVirgula + 1, segundaVirgula).toFloat();\n        float pressao = recebidos.substring(segundaVirgula + 1).toFloat();\n\n        Serial.print(\"Temperatura: \");\n        Serial.println(temperatura);\n        Serial.print(\"Umidade: \");\n        Serial.println(umidade);\n        Serial.print(\"Press\u00e3o: \");\n        Serial.println(pressao);\n    }\n}\n</code></pre> <p>Explica\u00e7\u00e3o:</p> <ul> <li>Delimita\u00e7\u00e3o: Utiliza v\u00edrgulas para separar os valores.</li> <li>Parsing: Usa <code>indexOf</code> e <code>substring</code> para extrair e converter os valores para <code>float</code>.</li> </ul>"},{"location":"aulas/iot/modulos/modulo10.html#6-comunicacao-serial-com-multiplos-dispositivos","title":"6. Comunica\u00e7\u00e3o Serial com M\u00faltiplos Dispositivos","text":""},{"location":"aulas/iot/modulos/modulo10.html#61-comunicacao-entre-arduino-e-computador-via-serial-usb","title":"6.1 Comunica\u00e7\u00e3o entre Arduino e Computador via Serial USB","text":"<p>O Arduino pode se comunicar com o computador atrav\u00e9s da porta USB utilizando a porta serial padr\u00e3o.</p> <p>Exemplo de Envio de Dados para o Computador:</p> <pre><code>void setup() {\n    Serial.begin(9600);\n}\n\nvoid loop() {\n    Serial.println(\"Dados do Arduino\");\n    delay(1000);\n}\n</code></pre>"},{"location":"aulas/iot/modulos/modulo10.html#62-comunicacao-entre-arduino-e-modulos-bluetooth","title":"6.2 Comunica\u00e7\u00e3o entre Arduino e M\u00f3dulos Bluetooth","text":"<p>Utilizando m\u00f3dulos como o HC-05, o Arduino pode se comunicar sem fio com dispositivos como smartphones.</p> <p>Exemplo de Configura\u00e7\u00e3o com <code>SoftwareSerial</code>:</p> <pre><code>#include &lt;SoftwareSerial.h&gt;\n\nSoftwareSerial bluetooth(10, 11); // RX, TX\n\nvoid setup() {\n    Serial.begin(9600);\n    bluetooth.begin(9600);\n    Serial.println(\"Conectado ao Bluetooth.\");\n}\n\nvoid loop() {\n    if (bluetooth.available()) {\n        char c = bluetooth.read();\n        Serial.print(\"Recebi via Bluetooth: \");\n        Serial.println(c);\n    }\n\n    if (Serial.available()) {\n        char c = Serial.read();\n        bluetooth.print(c);\n    }\n}\n</code></pre> <p>Explica\u00e7\u00e3o:</p> <ul> <li>Defini\u00e7\u00e3o: Pinos 10 e 11 s\u00e3o usados para comunica\u00e7\u00e3o serial com o m\u00f3dulo Bluetooth.</li> <li>Transfer\u00eancia de Dados: Dados recebidos do Bluetooth s\u00e3o enviados para o Monitor Serial e vice-versa.</li> </ul>"},{"location":"aulas/iot/modulos/modulo10.html#7-exemplos-praticos","title":"7. Exemplos Pr\u00e1ticos","text":""},{"location":"aulas/iot/modulos/modulo10.html#71-comunicacao-serial-entre-dois-arduinos-usando-i2c","title":"7.1 Comunica\u00e7\u00e3o Serial Entre Dois Arduinos Usando I2C","text":"<pre><code>// C\u00f3digo para o Arduino Mestre\n#include &lt;Wire.h&gt;\n\nvoid setup() {\n    Wire.begin(); // Inicia como mestre\n    Serial.begin(9600);\n}\n\nvoid loop() {\n    Wire.beginTransmission(8); // Endere\u00e7o do escravo\n    Wire.write(\"Dados do Mestre\");\n    Wire.endTransmission();\n    delay(1000);\n}\n</code></pre> <pre><code>// C\u00f3digo para o Arduino Escravo\n#include &lt;Wire.h&gt;\n\nvoid setup() {\n    Wire.begin(8); // Endere\u00e7o do escravo\n    Wire.onReceive(receiveEvent);\n    Serial.begin(9600);\n}\n\nvoid loop() {\n    // N\u00e3o h\u00e1 c\u00f3digo no loop\n}\n\nvoid receiveEvent(int bytes) {\n    while (Wire.available()) {\n        char c = Wire.read();\n        Serial.print(c);\n    }\n    Serial.println();\n}\n</code></pre> <p>Explica\u00e7\u00e3o:</p> <ul> <li>Mestre: Envia uma string \"Dados do Mestre\" para o escravo a cada segundo.</li> <li>Escravo: Recebe os dados e os imprime no Monitor Serial.</li> </ul>"},{"location":"aulas/iot/modulos/modulo10.html#72-utilizando-softwareserial-para-comunicacao-com-um-modulo-bluetooth","title":"7.2 Utilizando <code>SoftwareSerial</code> para Comunica\u00e7\u00e3o com um M\u00f3dulo Bluetooth","text":"<pre><code>#include &lt;SoftwareSerial.h&gt;\n\nSoftwareSerial bluetooth(10, 11); // RX, TX\n\nvoid setup() {\n    Serial.begin(9600);\n    bluetooth.begin(9600);\n    Serial.println(\"Conectado ao Bluetooth.\");\n}\n\nvoid loop() {\n    if (bluetooth.available()) {\n        char c = bluetooth.read();\n        Serial.print(\"Recebi via Bluetooth: \");\n        Serial.println(c);\n    }\n\n    if (Serial.available()) {\n        char c = Serial.read();\n        bluetooth.print(c);\n    }\n}\n</code></pre> <p>Explica\u00e7\u00e3o:</p> <ul> <li>Envio e Recebimento: Permite enviar e receber dados entre o Arduino e um dispositivo Bluetooth, como um smartphone, utilizando a porta serial adicional criada pela biblioteca <code>SoftwareSerial</code>.</li> </ul>"},{"location":"aulas/iot/modulos/modulo10.html#73-comunicacao-serial-com-parsing-de-dados-delimitados","title":"7.3 Comunica\u00e7\u00e3o Serial com Parsing de Dados Delimitados","text":"<pre><code>void setup() {\n    Serial.begin(9600);\n    Serial.println(\"Envie dados no formato: temperatura,umidade,pressao\");\n}\n\nvoid loop() {\n    if (Serial.available() &gt; 0) {\n        String recebidos = Serial.readStringUntil('\\n');\n        int primeiraVirgula = recebidos.indexOf(',');\n        int segundaVirgula = recebidos.indexOf(',', primeiraVirgula + 1);\n\n        if (primeiraVirgula &gt; 0 &amp;&amp; segundaVirgula &gt; primeiraVirgula) {\n            float temperatura = recebidos.substring(0, primeiraVirgula).toFloat();\n            float umidade = recebidos.substring(primeiraVirgula + 1, segundaVirgula).toFloat();\n            float pressao = recebidos.substring(segundaVirgula + 1).toFloat();\n\n            Serial.print(\"Temperatura: \");\n            Serial.println(temperatura);\n            Serial.print(\"Umidade: \");\n            Serial.println(umidade);\n            Serial.print(\"Press\u00e3o: \");\n            Serial.println(pressao);\n        } else {\n            Serial.println(\"Formato inv\u00e1lido. Tente novamente.\");\n        }\n    }\n}\n</code></pre> <p>Explica\u00e7\u00e3o:</p> <ul> <li>Formato de Dados: Espera uma string no formato \"temperatura,umidade,pressao\".</li> <li>Parsing: Divide a string com base nas v\u00edrgulas e converte os segmentos para <code>float</code>.</li> <li>Valida\u00e7\u00e3o: Verifica se o formato dos dados est\u00e1 correto antes de processar.</li> </ul>"},{"location":"aulas/iot/modulos/modulo10.html#8-exercicios-praticos","title":"8. Exerc\u00edcios Pr\u00e1ticos","text":""},{"location":"aulas/iot/modulos/modulo10.html#exercicio-1-comunicacao-serial-entre-arduino-e-pc-com-comando-de-controle","title":"Exerc\u00edcio 1: Comunica\u00e7\u00e3o Serial Entre Arduino e PC com Comando de Controle","text":"<ul> <li> <p>Tarefa: Crie um programa onde o Arduino recebe comandos do computador via Serial para ligar e desligar um LED. Use comandos como \"LIGAR\" e \"DESLIGAR\".</p> </li> <li> <p>Dicas:</p> </li> <li>Utilize <code>Serial.readStringUntil('\\n')</code> para ler comandos completos.</li> <li> <p>Compare strings para identificar o comando recebido.</p> </li> <li> <p>Exemplo de C\u00f3digo:</p> </li> </ul> <pre><code>const int ledPin = 13;\n\nvoid setup() {\n    pinMode(ledPin, OUTPUT);\n    Serial.begin(9600);\n    Serial.println(\"Digite 'LIGAR' ou 'DESLIGAR' para controlar o LED.\");\n}\n\nvoid loop() {\n    if (Serial.available() &gt; 0) {\n        String comando = Serial.readStringUntil('\\n');\n        comando.trim(); // Remove espa\u00e7os em branco\n\n        if (comando.equalsIgnoreCase(\"LIGAR\")) {\n            digitalWrite(ledPin, HIGH);\n            Serial.println(\"LED Ligado.\");\n        } else if (comando.equalsIgnoreCase(\"DESLIGAR\")) {\n            digitalWrite(ledPin, LOW);\n            Serial.println(\"LED Desligado.\");\n        } else {\n            Serial.println(\"Comando inv\u00e1lido. Use 'LIGAR' ou 'DESLIGAR'.\");\n        }\n    }\n}\n</code></pre>"},{"location":"aulas/iot/modulos/modulo10.html#exercicio-2-comunicacao-serial-com-arduino-e-modulo-bluetooth-para-controle-de-servo","title":"Exerc\u00edcio 2: Comunica\u00e7\u00e3o Serial com Arduino e M\u00f3dulo Bluetooth para Controle de Servo","text":"<ul> <li> <p>Tarefa: Desenvolva um sistema onde um smartphone envia comandos via Bluetooth para o Arduino controlar a posi\u00e7\u00e3o de um servo motor. Utilize comandos como \"ESQUERDA\" e \"DIREITA\" para ajustar o \u00e2ngulo do servo.</p> </li> <li> <p>Dicas:</p> </li> <li>Utilize a biblioteca <code>SoftwareSerial</code> para comunica\u00e7\u00e3o com o m\u00f3dulo Bluetooth.</li> <li> <p>Controle o servo utilizando a biblioteca <code>Servo</code>.</p> </li> <li> <p>Exemplo de C\u00f3digo:</p> </li> </ul> <pre><code>#include &lt;SoftwareSerial.h&gt;\n#include &lt;Servo.h&gt;\n\nSoftwareSerial bluetooth(10, 11); // RX, TX\nServo meuServo;\n\nvoid setup() {\n    Serial.begin(9600);\n    bluetooth.begin(9600);\n    meuServo.attach(9); // Servo conectado ao pino 9\n    meuServo.write(90); // Posi\u00e7\u00e3o inicial\n    Serial.println(\"Controle do Servo via Bluetooth iniciado.\");\n}\n\nvoid loop() {\n    if (bluetooth.available() &gt; 0) {\n        String comando = bluetooth.readStringUntil('\\n');\n        comando.trim();\n\n        if (comando.equalsIgnoreCase(\"ESQUERDA\")) {\n            int pos = meuServo.read();\n            pos -= 10;\n            if (pos &lt; 0) pos = 0;\n            meuServo.write(pos);\n            Serial.print(\"Servo movido para a esquerda: \");\n            Serial.println(pos);\n        } else if (comando.equalsIgnoreCase(\"DIREITA\")) {\n            int pos = meuServo.read();\n            pos += 10;\n            if (pos &gt; 180) pos = 180;\n            meuServo.write(pos);\n            Serial.print(\"Servo movido para a direita: \");\n            Serial.println(pos);\n        } else {\n            Serial.println(\"Comando inv\u00e1lido. Use 'ESQUERDA' ou 'DIREITA'.\");\n        }\n    }\n}\n</code></pre>"},{"location":"aulas/iot/modulos/modulo10.html#exercicio-3-comunicacao-serial-com-parsing-de-dados-para-monitoramento-de-sensores","title":"Exerc\u00edcio 3: Comunica\u00e7\u00e3o Serial com Parsing de Dados para Monitoramento de Sensores","text":"<ul> <li> <p>Tarefa: Crie um programa onde o Arduino envia dados de m\u00faltiplos sensores formatados em JSON para o computador. Utilize parsing para organizar os dados recebidos.</p> </li> <li> <p>Dicas:</p> </li> <li>Utilize delimitadores para estruturar os dados em formato JSON.</li> <li> <p>Implemente fun\u00e7\u00f5es para criar e interpretar strings JSON.</p> </li> <li> <p>Exemplo de C\u00f3digo:</p> </li> </ul> <pre><code>#include &lt;ArduinoJson.h&gt;\n\nvoid setup() {\n    Serial.begin(9600);\n    Serial.println(\"Monitoramento de Sensores Iniciado.\");\n}\n\nvoid loop() {\n    // Simula\u00e7\u00e3o de leituras de sensores\n    float temperatura = 23.5;\n    float umidade = 47.8;\n    float pressao = 1013.25;\n\n    // Cria um documento JSON\n    StaticJsonDocument&lt;200&gt; doc;\n    doc[\"temperatura\"] = temperatura;\n    doc[\"umidade\"] = umidade;\n    doc[\"pressao\"] = pressao;\n\n    // Serializa o JSON\n    String output;\n    serializeJson(doc, output);\n    Serial.println(output);\n\n    delay(1000);\n}\n</code></pre> <p>Explica\u00e7\u00e3o:</p> <ul> <li>Biblioteca <code>ArduinoJson</code>: Facilita a cria\u00e7\u00e3o e parsing de dados em formato JSON.</li> <li>Cria\u00e7\u00e3o do JSON: Armazena os valores dos sensores em um documento JSON e o envia via Serial.</li> <li>Monitoramento: O computador pode receber e interpretar os dados estruturados para visualiza\u00e7\u00e3o ou processamento.</li> </ul>"},{"location":"aulas/iot/modulos/modulo10.html#9-conceitos-importantes","title":"9. Conceitos Importantes","text":""},{"location":"aulas/iot/modulos/modulo10.html#91-baud-rate","title":"9.1 Baud Rate","text":"<ul> <li>Defini\u00e7\u00e3o: Taxa de transmiss\u00e3o de dados na comunica\u00e7\u00e3o serial, medida em bits por segundo (bps).</li> <li>Considera\u00e7\u00f5es:</li> <li>Deve ser consistente entre os dispositivos comunicantes.</li> <li>Baud rates comuns: 9600, 19200, 38400, 57600, 115200.</li> </ul>"},{"location":"aulas/iot/modulos/modulo10.html#92-paridade-e-bits-de-parada","title":"9.2 Paridade e Bits de Parada","text":"<ul> <li>Paridade: M\u00e9todo de verifica\u00e7\u00e3o de erros que adiciona um bit extra para garantir a integridade dos dados.</li> <li>Bits de Parada: Indicam o final de um byte de dados.</li> <li>Configura\u00e7\u00e3o: Geralmente configurada como 8N1 (8 bits de dados, sem paridade, 1 bit de parada).</li> </ul>"},{"location":"aulas/iot/modulos/modulo10.html#93-softwareserial-vs-hardwareserial","title":"9.3 SoftwareSerial vs. HardwareSerial","text":"<ul> <li>HardwareSerial:</li> <li>Utiliza a porta serial padr\u00e3o do Arduino.</li> <li>Mais eficiente e r\u00e1pido.</li> <li> <p>Limitado a uma \u00fanica porta serial (exceto em Arduinos com m\u00faltiplas portas seriais).</p> </li> <li> <p>SoftwareSerial:</p> </li> <li>Permite criar portas seriais adicionais em pinos digitais.</li> <li>Menos eficiente e pode ser mais lenta.</li> <li>\u00datil para comunica\u00e7\u00e3o com m\u00faltiplos dispositivos seriais.</li> </ul>"},{"location":"aulas/iot/modulos/modulo10.html#94-parsing-de-dados","title":"9.4 Parsing de Dados","text":"<ul> <li>Defini\u00e7\u00e3o: Processo de interpretar e extrair informa\u00e7\u00f5es de uma string ou fluxo de dados.</li> <li>Import\u00e2ncia: Essencial para organizar e utilizar dados recebidos de forma estruturada.</li> </ul>"},{"location":"aulas/iot/modulos/modulo10.html#95-boas-praticas-na-comunicacao-serial","title":"9.5 Boas Pr\u00e1ticas na Comunica\u00e7\u00e3o Serial","text":"<ul> <li>Consist\u00eancia: Mantenha as configura\u00e7\u00f5es de baud rate e par\u00e2metros de comunica\u00e7\u00e3o consistentes entre os dispositivos.</li> <li>Delimita\u00e7\u00e3o de Dados: Utilize delimitadores claros para separar diferentes partes dos dados.</li> <li>Valida\u00e7\u00e3o: Sempre verifique e valide os dados recebidos para evitar erros de interpreta\u00e7\u00e3o.</li> <li>Gerenciamento de Buffer: Evite sobrecarregar o buffer serial, controlando a quantidade e a frequ\u00eancia dos dados enviados.</li> </ul>"},{"location":"aulas/iot/modulos/modulo10.html#10-recursos-adicionais","title":"10. Recursos Adicionais","text":"<ul> <li> <p>Documenta\u00e7\u00e3o Oficial do Arduino:</p> </li> <li> <p>Comunica\u00e7\u00e3o Serial</p> </li> <li>Biblioteca <code>SoftwareSerial</code></li> <li> <p>Biblioteca <code>ArduinoJson</code></p> </li> <li> <p>Tutoriais e Guias:</p> </li> <li> <p>Guia Completo de Comunica\u00e7\u00e3o Serial no Arduino</p> </li> <li>Utilizando I2C e SPI no Arduino</li> <li> <p>Introdu\u00e7\u00e3o ao JSON com Arduino</p> </li> <li> <p>V\u00eddeos Educacionais:</p> </li> <li> <p>Comunica\u00e7\u00e3o Serial Avan\u00e7ada no Arduino</p> </li> <li>Entendendo I2C e SPI no Arduino</li> <li>Utilizando a Biblioteca <code>ArduinoJson</code></li> </ul>"},{"location":"aulas/iot/modulos/modulo10.html#11-conclusao-do-modulo","title":"11. Conclus\u00e3o do M\u00f3dulo","text":"<p>Neste m\u00f3dulo, voc\u00ea aprendeu:</p> <ul> <li>Conceitos avan\u00e7ados de comunica\u00e7\u00e3o serial, incluindo UART, I2C e SPI.</li> <li>Como configurar e utilizar diferentes protocolos de comunica\u00e7\u00e3o serial no Arduino.</li> <li>Implementa\u00e7\u00e3o de comunica\u00e7\u00e3o serial entre m\u00faltiplos dispositivos Arduino.</li> <li>Utiliza\u00e7\u00e3o da biblioteca <code>SoftwareSerial</code> para criar portas seriais adicionais.</li> <li>T\u00e9cnicas de transfer\u00eancia e parsing de dados para comunica\u00e7\u00e3o eficiente.</li> <li>Integra\u00e7\u00e3o de comunica\u00e7\u00e3o serial com m\u00f3dulos de comunica\u00e7\u00e3o como Bluetooth.</li> <li>Praticou com exemplos e exerc\u00edcios que refor\u00e7am o entendimento da comunica\u00e7\u00e3o serial avan\u00e7ada.</li> </ul> <p>Voc\u00ea est\u00e1 agora preparado para avan\u00e7ar para o pr\u00f3ximo m\u00f3dulo, onde exploraremos Controle de Motores e Atuadores, aprofundando seu conhecimento em automa\u00e7\u00e3o e controle com Arduino.</p>"},{"location":"aulas/iot/modulos/modulo10.html#12-proximos-passos","title":"12. Pr\u00f3ximos Passos","text":"<ul> <li>Revisar o conte\u00fado deste m\u00f3dulo e certificar-se de que compreendeu os conceitos apresentados.</li> <li>Completar os exerc\u00edcios propostos para consolidar o aprendizado.</li> <li>Preparar-se para o M\u00f3dulo 11: Controle de Motores e Atuadores.</li> </ul> <p>Se tiver d\u00favidas ou precisar de assist\u00eancia, n\u00e3o hesite em procurar recursos adicionais ou participar de comunidades de aprendizagem para obter suporte.</p> <p>Bom trabalho e continue assim!</p>"},{"location":"aulas/iot/modulos/modulo11.html","title":"M\u00f3dulo 11: Controle de Motores e Atuadores","text":"<p>Bem-vindo ao M\u00f3dulo 11 do curso \"Programa\u00e7\u00e3o em Arduino: Conceitos Fundamentais sem Hardware\". Neste m\u00f3dulo, voc\u00ea ir\u00e1 aprender a controlar diferentes tipos de motores e atuadores utilizando o Arduino. O controle eficiente de motores \u00e9 essencial para uma ampla gama de aplica\u00e7\u00f5es, desde rob\u00f3tica at\u00e9 automa\u00e7\u00e3o residencial.</p>"},{"location":"aulas/iot/modulos/modulo11.html#objetivos-do-modulo","title":"Objetivos do M\u00f3dulo","text":"<ul> <li>Compreender os diferentes tipos de motores e atuadores dispon\u00edveis para Arduino.</li> <li>Aprender a controlar motores DC, servos e motores de passo.</li> <li>Entender como utilizar drivers de motor para controlar a dire\u00e7\u00e3o e velocidade dos motores.</li> <li>Implementar controle de motores utilizando sinais digitais e PWM.</li> <li>Utilizar bibliotecas espec\u00edficas para facilitar o controle de motores e atuadores.</li> <li>Resolver exerc\u00edcios pr\u00e1ticos para consolidar o conhecimento sobre controle de motores e atuadores.</li> </ul>"},{"location":"aulas/iot/modulos/modulo11.html#1-introducao-a-motores-e-atuadores","title":"1. Introdu\u00e7\u00e3o a Motores e Atuadores","text":""},{"location":"aulas/iot/modulos/modulo11.html#11-o-que-sao-motores-e-atuadores","title":"1.1 O que s\u00e3o Motores e Atuadores?","text":"<p>Motores s\u00e3o dispositivos que convertem energia el\u00e9trica em movimento mec\u00e2nico. Atuadores s\u00e3o dispositivos que recebem comandos el\u00e9tricos para realizar uma a\u00e7\u00e3o f\u00edsica, como mover uma parte de um rob\u00f4 ou abrir uma v\u00e1lvula.</p>"},{"location":"aulas/iot/modulos/modulo11.html#12-tipos-comuns-de-motores-e-atuadores","title":"1.2 Tipos Comuns de Motores e Atuadores","text":"<ul> <li>Motor DC (Corrente Cont\u00ednua): Simples de controlar, ideal para aplica\u00e7\u00f5es que requerem movimento cont\u00ednuo.</li> <li>Servo Motor: Permite controle preciso de posi\u00e7\u00e3o angular, amplamente utilizado em rob\u00f3tica e sistemas de controle.</li> <li>Motor de Passo: Move-se em passos discretos, permitindo controle preciso de posi\u00e7\u00e3o e velocidade.</li> <li>Rel\u00e9s: Atuadores eletromec\u00e2nicos usados para controlar circuitos de alta pot\u00eancia com sinais de baixa pot\u00eancia.</li> <li>Solenoides: Atuadores lineares que convertem energia el\u00e9trica em movimento linear.</li> </ul>"},{"location":"aulas/iot/modulos/modulo11.html#2-controle-de-motores-dc","title":"2. Controle de Motores DC","text":""},{"location":"aulas/iot/modulos/modulo11.html#21-componentes-necessarios","title":"2.1 Componentes Necess\u00e1rios","text":"<ul> <li>Motor DC</li> <li>Driver de Motor (por exemplo, L298N, L293D)</li> <li>Fonte de Alimenta\u00e7\u00e3o Adequada</li> <li>Cabos de Conex\u00e3o</li> <li>Arduino</li> </ul>"},{"location":"aulas/iot/modulos/modulo11.html#22-conectando-o-motor-dc-ao-arduino","title":"2.2 Conectando o Motor DC ao Arduino","text":"<p>Os motores DC requerem um driver de motor para controlar a dire\u00e7\u00e3o e velocidade. O driver atua como um interruptor que permite ao Arduino controlar o motor de forma segura.</p> <p>Exemplo de Conex\u00e3o com L298N:</p> <ul> <li>Motor DC:</li> <li>Conecte os terminais do motor \u00e0s sa\u00eddas do driver (OUT1 e OUT2).</li> <li>Driver L298N:</li> <li>IN1 e IN2: Conectados a pinos digitais do Arduino para controle de dire\u00e7\u00e3o.</li> <li>ENA: Conectado a um pino PWM do Arduino para controle de velocidade.</li> <li>VCC e GND: Conectados \u00e0 fonte de alimenta\u00e7\u00e3o adequada.</li> <li>Arduino:</li> <li>Conecte os pinos de controle (IN1, IN2, ENA) aos pinos digitais e PWM.</li> </ul>"},{"location":"aulas/iot/modulos/modulo11.html#23-exemplo-de-codigo-para-controle-de-motor-dc","title":"2.3 Exemplo de C\u00f3digo para Controle de Motor DC","text":"<pre><code>// Defini\u00e7\u00e3o dos pinos\nconst int IN1 = 9;\nconst int IN2 = 8;\nconst int ENA = 10;\n\nvoid setup() {\n    // Configura os pinos como sa\u00edda\n    pinMode(IN1, OUTPUT);\n    pinMode(IN2, OUTPUT);\n    pinMode(ENA, OUTPUT);\n}\n\nvoid loop() {\n    // Motor girando para frente\n    digitalWrite(IN1, HIGH);\n    digitalWrite(IN2, LOW);\n    analogWrite(ENA, 200); // Controle de velocidade (0-255)\n    delay(2000);\n\n    // Motor girando para tr\u00e1s\n    digitalWrite(IN1, LOW);\n    digitalWrite(IN2, HIGH);\n    analogWrite(ENA, 200); // Controle de velocidade (0-255)\n    delay(2000);\n\n    // Motor desligado\n    digitalWrite(IN1, LOW);\n    digitalWrite(IN2, LOW);\n    analogWrite(ENA, 0); // Velocidade zero\n    delay(2000);\n}\n</code></pre> <p>Explica\u00e7\u00e3o:</p> <ul> <li>Dire\u00e7\u00e3o do Motor: Controlada pelos pinos IN1 e IN2. Configurar IN1 alto e IN2 baixo faz o motor girar para frente, e vice-versa para girar para tr\u00e1s.</li> <li>Velocidade do Motor: Controlada pelo pino ENA usando PWM (<code>analogWrite</code>). O valor varia de 0 (parado) a 255 (velocidade m\u00e1xima).</li> </ul>"},{"location":"aulas/iot/modulos/modulo11.html#3-controle-de-servo-motors","title":"3. Controle de Servo Motors","text":""},{"location":"aulas/iot/modulos/modulo11.html#31-o-que-e-um-servo-motor","title":"3.1 O que \u00e9 um Servo Motor?","text":"<p>Um servo motor \u00e9 um motor que permite controle preciso de posi\u00e7\u00e3o angular. \u00c9 composto por um motor DC, um conjunto de engrenagens, um potenci\u00f4metro e um circuito de controle.</p>"},{"location":"aulas/iot/modulos/modulo11.html#32-conectando-um-servo-motor-ao-arduino","title":"3.2 Conectando um Servo Motor ao Arduino","text":"<p>Componentes Necess\u00e1rios:</p> <ul> <li>Servo Motor</li> <li>Cabos de Conex\u00e3o</li> <li>Fonte de Alimenta\u00e7\u00e3o Adequada (se necess\u00e1rio)</li> <li>Arduino</li> </ul> <p>Conex\u00e3o:</p> <ul> <li>VCC (Vermelho): Conectado a 5V ou a uma fonte de alimenta\u00e7\u00e3o externa.</li> <li>GND (Preto ou Marrom): Conectado ao GND do Arduino.</li> <li>Sinal (Amarelo ou Branco): Conectado a um pino digital do Arduino (por exemplo, pino 9).</li> </ul>"},{"location":"aulas/iot/modulos/modulo11.html#33-exemplo-de-codigo-para-controle-de-servo-motor","title":"3.3 Exemplo de C\u00f3digo para Controle de Servo Motor","text":"<pre><code>#include &lt;Servo.h&gt;\n\nServo meuServo; // Cria um objeto Servo\n\nconst int pinoServo = 9; // Pino conectado ao servo\n\nvoid setup() {\n    meuServo.attach(pinoServo); // Anexa o servo ao pino especificado\n}\n\nvoid loop() {\n    // Move o servo para 0 graus\n    meuServo.write(0);\n    delay(1000);\n\n    // Move o servo para 90 graus\n    meuServo.write(90);\n    delay(1000);\n\n    // Move o servo para 180 graus\n    meuServo.write(180);\n    delay(1000);\n}\n</code></pre> <p>Explica\u00e7\u00e3o:</p> <ul> <li>Biblioteca Servo: Facilita o controle de servo motors.</li> <li>M\u00e9todo <code>write()</code>: Define a posi\u00e7\u00e3o do servo em graus (0 a 180).</li> </ul>"},{"location":"aulas/iot/modulos/modulo11.html#4-controle-de-motores-de-passo","title":"4. Controle de Motores de Passo","text":""},{"location":"aulas/iot/modulos/modulo11.html#41-o-que-e-um-motor-de-passo","title":"4.1 O que \u00e9 um Motor de Passo?","text":"<p>Um motor de passo \u00e9 um motor que divide uma rota\u00e7\u00e3o completa em um n\u00famero de passos iguais. Permite controle preciso de posi\u00e7\u00e3o e velocidade sem a necessidade de sensores de feedback.</p>"},{"location":"aulas/iot/modulos/modulo11.html#42-conectando-um-motor-de-passo-ao-arduino","title":"4.2 Conectando um Motor de Passo ao Arduino","text":"<p>Componentes Necess\u00e1rios:</p> <ul> <li>Motor de Passo (Bipolar ou Unipolar)</li> <li>Driver de Motor de Passo (por exemplo, A4988, ULN2003)</li> <li>Fonte de Alimenta\u00e7\u00e3o Adequada</li> <li>Cabos de Conex\u00e3o</li> <li>Arduino</li> </ul> <p>Conex\u00e3o com ULN2003 (para motores unipolares):</p> <ul> <li>Motor de Passo:</li> <li>Conecte as bobinas do motor aos terminais do driver ULN2003.</li> <li>Driver ULN2003:</li> <li>IN1, IN2, IN3, IN4: Conectados a pinos digitais do Arduino para controle.</li> <li>VCC e GND: Conectados \u00e0 fonte de alimenta\u00e7\u00e3o e ao GND do Arduino.</li> <li>Arduino:</li> <li>Conecte os pinos de controle (IN1-IN4) aos pinos digitais.</li> </ul>"},{"location":"aulas/iot/modulos/modulo11.html#43-exemplo-de-codigo-para-controle-de-motor-de-passo-com-uln2003","title":"4.3 Exemplo de C\u00f3digo para Controle de Motor de Passo com ULN2003","text":"<pre><code>// Defini\u00e7\u00e3o dos pinos\nconst int IN1 = 8;\nconst int IN2 = 9;\nconst int IN3 = 10;\nconst int IN4 = 11;\n\n// Sequ\u00eancia de passos para motor de passo\nint passos[4][4] = {\n    {1, 0, 0, 1},\n    {1, 1, 0, 0},\n    {0, 1, 1, 0},\n    {0, 0, 1, 1}\n};\n\nvoid setup() {\n    // Configura os pinos como sa\u00edda\n    pinMode(IN1, OUTPUT);\n    pinMode(IN2, OUTPUT);\n    pinMode(IN3, OUTPUT);\n    pinMode(IN4, OUTPUT);\n}\n\nvoid loop() {\n    // Gira o motor para frente\n    for(int i = 0; i &lt; 4; i++) {\n        digitalWrite(IN1, passos[i][0]);\n        digitalWrite(IN2, passos[i][1]);\n        digitalWrite(IN3, passos[i][2]);\n        digitalWrite(IN4, passos[i][3]);\n        delay(100);\n    }\n\n    delay(1000);\n\n    // Gira o motor para tr\u00e1s\n    for(int i = 3; i &gt;= 0; i--) {\n        digitalWrite(IN1, passos[i][0]);\n        digitalWrite(IN2, passos[i][1]);\n        digitalWrite(IN3, passos[i][2]);\n        digitalWrite(IN4, passos[i][3]);\n        delay(100);\n    }\n\n    delay(1000);\n}\n</code></pre> <p>Explica\u00e7\u00e3o:</p> <ul> <li>Sequ\u00eancia de Passos: Define a sequ\u00eancia de ativa\u00e7\u00e3o dos pinos para girar o motor.</li> <li>Controle Direcional: Alterando a ordem da sequ\u00eancia, o motor gira para frente ou para tr\u00e1s.</li> <li>Delay: Controla a velocidade de rota\u00e7\u00e3o do motor.</li> </ul>"},{"location":"aulas/iot/modulos/modulo11.html#5-utilizando-drivers-de-motor-avancados","title":"5. Utilizando Drivers de Motor Avan\u00e7ados","text":""},{"location":"aulas/iot/modulos/modulo11.html#51-driver-l298n","title":"5.1 Driver L298N","text":"<p>O L298N \u00e9 um driver de motor dual que permite controlar dois motores DC ou um motor de passo com facilidade.</p> <p>Caracter\u00edsticas:</p> <ul> <li>Suporta motores de at\u00e9 46V e 2A por canal.</li> <li>Permite controle de dire\u00e7\u00e3o e velocidade.</li> <li>Inclui termina\u00e7\u00e3o de prote\u00e7\u00e3o e dissipa\u00e7\u00e3o de calor.</li> </ul>"},{"location":"aulas/iot/modulos/modulo11.html#52-conectando-o-l298n-ao-arduino","title":"5.2 Conectando o L298N ao Arduino","text":"<p>Componentes Necess\u00e1rios:</p> <ul> <li>Driver L298N</li> <li>Motores DC ou de Passo</li> <li>Fonte de Alimenta\u00e7\u00e3o Adequada</li> <li>Cabos de Conex\u00e3o</li> <li>Arduino</li> </ul> <p>Conex\u00e3o:</p> <ul> <li>Motor 1 e Motor 2: Conectados \u00e0s sa\u00eddas do driver.</li> <li>IN1, IN2, IN3, IN4: Conectados a pinos digitais do Arduino para controle de dire\u00e7\u00e3o.</li> <li>ENA e ENB: Conectados a pinos PWM do Arduino para controle de velocidade.</li> <li>VCC e GND: Conectados \u00e0 fonte de alimenta\u00e7\u00e3o e ao GND do Arduino.</li> <li>12V: Alimenta\u00e7\u00e3o dos motores (se aplic\u00e1vel).</li> </ul>"},{"location":"aulas/iot/modulos/modulo11.html#53-exemplo-de-codigo-para-controle-de-dois-motores-dc-com-l298n","title":"5.3 Exemplo de C\u00f3digo para Controle de Dois Motores DC com L298N","text":"<pre><code>// Defini\u00e7\u00e3o dos pinos para Motor 1\nconst int IN1 = 8;\nconst int IN2 = 9;\nconst int ENA = 10;\n\n// Defini\u00e7\u00e3o dos pinos para Motor 2\nconst int IN3 = 11;\nconst int IN4 = 12;\nconst int ENB = 13;\n\nvoid setup() {\n    // Configura os pinos como sa\u00edda\n    pinMode(IN1, OUTPUT);\n    pinMode(IN2, OUTPUT);\n    pinMode(IN3, OUTPUT);\n    pinMode(IN4, OUTPUT);\n    pinMode(ENA, OUTPUT);\n    pinMode(ENB, OUTPUT);\n}\n\nvoid loop() {\n    // Motor 1 para frente\n    digitalWrite(IN1, HIGH);\n    digitalWrite(IN2, LOW);\n    analogWrite(ENA, 200);\n\n    // Motor 2 para tr\u00e1s\n    digitalWrite(IN3, LOW);\n    digitalWrite(IN4, HIGH);\n    analogWrite(ENB, 200);\n\n    delay(2000);\n\n    // Motor 1 para tr\u00e1s\n    digitalWrite(IN1, LOW);\n    digitalWrite(IN2, HIGH);\n    analogWrite(ENA, 200);\n\n    // Motor 2 para frente\n    digitalWrite(IN3, HIGH);\n    digitalWrite(IN4, LOW);\n    analogWrite(ENB, 200);\n\n    delay(2000);\n}\n</code></pre> <p>Explica\u00e7\u00e3o:</p> <ul> <li>Controle Dual: Permite controlar dois motores independentes, facilitando aplica\u00e7\u00f5es como rob\u00f4s com rodas duplas.</li> <li>Velocidade e Dire\u00e7\u00e3o: Utiliza sinais digitais para dire\u00e7\u00e3o e PWM para velocidade.</li> </ul>"},{"location":"aulas/iot/modulos/modulo11.html#6-bibliotecas-para-controle-de-motores","title":"6. Bibliotecas para Controle de Motores","text":""},{"location":"aulas/iot/modulos/modulo11.html#61-biblioteca-servo","title":"6.1 Biblioteca Servo","text":"<p>A biblioteca <code>Servo</code> facilita o controle de servo motors, permitindo mover o servo para posi\u00e7\u00f5es espec\u00edficas com facilidade.</p> <p>Instala\u00e7\u00e3o:</p> <p>A biblioteca <code>Servo</code> geralmente vem pr\u00e9-instalada no IDE do Arduino. Caso n\u00e3o esteja, pode ser instalada atrav\u00e9s do gerenciador de bibliotecas.</p>"},{"location":"aulas/iot/modulos/modulo11.html#62-biblioteca-stepper","title":"6.2 Biblioteca Stepper","text":"<p>A biblioteca <code>Stepper</code> simplifica o controle de motores de passo, gerenciando a sequ\u00eancia de passos automaticamente.</p> <p>Instala\u00e7\u00e3o:</p> <p>A biblioteca <code>Stepper</code> tamb\u00e9m est\u00e1 inclu\u00edda na IDE do Arduino. Para motores de passo mais avan\u00e7ados, bibliotecas como <code>AccelStepper</code> podem ser utilizadas.</p>"},{"location":"aulas/iot/modulos/modulo11.html#63-biblioteca-adafruit-motor-shield","title":"6.3 Biblioteca Adafruit Motor Shield","text":"<p>O Adafruit Motor Shield oferece uma interface f\u00e1cil para controlar motores DC, motores de passo e servos, utilizando menos pinos do Arduino.</p> <p>Instala\u00e7\u00e3o:</p> <p>Pode ser instalada atrav\u00e9s do gerenciador de bibliotecas do Arduino:</p> <ol> <li>Abra o IDE do Arduino.</li> <li>V\u00e1 para Sketch &gt; Include Library &gt; Manage Libraries...</li> <li>Procure por \"Adafruit Motor Shield\" e instale a biblioteca.</li> </ol> <p>Exemplo de Uso com Adafruit Motor Shield:</p> <pre><code>#include &lt;Wire.h&gt;\n#include &lt;Adafruit_MotorShield.h&gt;\n\n// Cria o objeto do Motor Shield\nAdafruit_MotorShield AFMS = Adafruit_MotorShield();\n\n// Seleciona o motor DC no slot M1\nAdafruit_DCMotor *motor1 = AFMS.getMotor(1);\n\nvoid setup() {\n    Serial.begin(9600);\n    if (!AFMS.begin()) { // Inicializa o Motor Shield\n        Serial.println(\"Motor Shield n\u00e3o encontrado.\");\n        while (1);\n    }\n\n    motor1-&gt;setSpeed(150); // Define a velocidade (0-255)\n    motor1-&gt;run(FORWARD);  // Motor gira para frente\n}\n\nvoid loop() {\n    motor1-&gt;run(FORWARD);\n    delay(2000);\n\n    motor1-&gt;run(BACKWARD);\n    delay(2000);\n\n    motor1-&gt;run(RELEASE);\n    delay(1000);\n}\n</code></pre> <p>Explica\u00e7\u00e3o:</p> <ul> <li>Inicializa\u00e7\u00e3o: Verifica se o Motor Shield est\u00e1 conectado corretamente.</li> <li>Controle: Utiliza m\u00e9todos da biblioteca para definir a velocidade e dire\u00e7\u00e3o do motor.</li> </ul>"},{"location":"aulas/iot/modulos/modulo11.html#7-exemplos-praticos","title":"7. Exemplos Pr\u00e1ticos","text":""},{"location":"aulas/iot/modulos/modulo11.html#71-controlando-um-servo-motor-com-inputs-do-usuario","title":"7.1 Controlando um Servo Motor com Inputs do Usu\u00e1rio","text":"<pre><code>#include &lt;Servo.h&gt;\n\nServo meuServo;\nconst int pinoServo = 9;\n\nvoid setup() {\n    Serial.begin(9600);\n    meuServo.attach(pinoServo);\n    Serial.println(\"Digite um \u00e2ngulo entre 0 e 180:\");\n}\n\nvoid loop() {\n    if (Serial.available() &gt; 0) {\n        int angulo = Serial.parseInt();\n        if (angulo &gt;= 0 &amp;&amp; angulo &lt;= 180) {\n            meuServo.write(angulo);\n            Serial.print(\"Servo movido para: \");\n            Serial.println(angulo);\n        } else {\n            Serial.println(\"\u00c2ngulo inv\u00e1lido. Tente novamente.\");\n        }\n    }\n}\n</code></pre> <p>Explica\u00e7\u00e3o:</p> <ul> <li>Input do Usu\u00e1rio: Recebe um valor de \u00e2ngulo via Monitor Serial e move o servo para a posi\u00e7\u00e3o correspondente.</li> <li>Valida\u00e7\u00e3o: Garante que o \u00e2ngulo esteja dentro do intervalo v\u00e1lido (0 a 180 graus).</li> </ul>"},{"location":"aulas/iot/modulos/modulo11.html#72-controlando-a-velocidade-de-um-motor-dc-com-potenciometro","title":"7.2 Controlando a Velocidade de um Motor DC com Potenci\u00f4metro","text":"<pre><code>const int ENA = 10;\nconst int IN1 = 9;\nconst int IN2 = 8;\nconst int pinoPot = A0;\n\nvoid setup() {\n    pinMode(IN1, OUTPUT);\n    pinMode(IN2, OUTPUT);\n    pinMode(ENA, OUTPUT);\n    Serial.begin(9600);\n}\n\nvoid loop() {\n    int valorPot = analogRead(pinoPot);\n    int velocidade = map(valorPot, 0, 1023, 0, 255);\n    analogWrite(ENA, velocidade);\n    Serial.print(\"Velocidade: \");\n    Serial.println(velocidade);\n    delay(100);\n}\n</code></pre> <p>Explica\u00e7\u00e3o:</p> <ul> <li>Controle Anal\u00f3gico: Utiliza um potenci\u00f4metro para ajustar a velocidade do motor DC em tempo real.</li> <li>Mapeamento: Converte o valor anal\u00f3gico (0-1023) para um valor PWM (0-255).</li> </ul>"},{"location":"aulas/iot/modulos/modulo11.html#73-implementando-movimento-preciso-com-motor-de-passo","title":"7.3 Implementando Movimento Preciso com Motor de Passo","text":"<pre><code>#include &lt;Stepper.h&gt;\n\n// Define o n\u00famero de passos por revolu\u00e7\u00e3o do motor\nconst int passosPorRevolucao = 200;\n\n// Inicializa a biblioteca Stepper\nStepper meuStepper(passosPorRevolucao, 8, 9, 10, 11);\n\nvoid setup() {\n    Serial.begin(9600);\n    meuStepper.setSpeed(60); // Define a velocidade (RPM)\n}\n\nvoid loop() {\n    Serial.println(\"Giro para frente\");\n    meuStepper.step(passosPorRevolucao); // Gira uma revolu\u00e7\u00e3o\n    delay(1000);\n\n    Serial.println(\"Giro para tr\u00e1s\");\n    meuStepper.step(-passosPorRevolucao); // Gira uma revolu\u00e7\u00e3o na dire\u00e7\u00e3o oposta\n    delay(1000);\n}\n</code></pre> <p>Explica\u00e7\u00e3o:</p> <ul> <li>Biblioteca Stepper: Facilita o controle de motores de passo, gerenciando a sequ\u00eancia de passos.</li> <li>Controle Direcional: Passos positivos giram o motor para frente e passos negativos para tr\u00e1s.</li> </ul>"},{"location":"aulas/iot/modulos/modulo11.html#8-exercicios-praticos","title":"8. Exerc\u00edcios Pr\u00e1ticos","text":""},{"location":"aulas/iot/modulos/modulo11.html#exercicio-1-controlar-dois-motores-dc-independentes","title":"Exerc\u00edcio 1: Controlar Dois Motores DC Independentes","text":"<ul> <li> <p>Tarefa: Crie um projeto que controla dois motores DC independentemente, permitindo que cada motor gire para frente ou para tr\u00e1s com diferentes velocidades.</p> </li> <li> <p>Dicas:</p> </li> <li>Utilize um driver de motor dual como o L298N.</li> <li> <p>Controle a dire\u00e7\u00e3o e velocidade de cada motor separadamente.</p> </li> <li> <p>Exemplo de C\u00f3digo:</p> </li> </ul> <pre><code>// Defini\u00e7\u00e3o dos pinos para Motor 1\nconst int IN1 = 8;\nconst int IN2 = 9;\nconst int ENA = 10;\n\n// Defini\u00e7\u00e3o dos pinos para Motor 2\nconst int IN3 = 11;\nconst int IN4 = 12;\nconst int ENB = 13;\n\nvoid setup() {\n    // Configura os pinos como sa\u00edda\n    pinMode(IN1, OUTPUT);\n    pinMode(IN2, OUTPUT);\n    pinMode(IN3, OUTPUT);\n    pinMode(IN4, OUTPUT);\n    pinMode(ENA, OUTPUT);\n    pinMode(ENB, OUTPUT);\n}\n\nvoid loop() {\n    // Motor 1 para frente com velocidade 200\n    digitalWrite(IN1, HIGH);\n    digitalWrite(IN2, LOW);\n    analogWrite(ENA, 200);\n\n    // Motor 2 para tr\u00e1s com velocidade 150\n    digitalWrite(IN3, LOW);\n    digitalWrite(IN4, HIGH);\n    analogWrite(ENB, 150);\n\n    delay(3000);\n\n    // Motor 1 para tr\u00e1s com velocidade 200\n    digitalWrite(IN1, LOW);\n    digitalWrite(IN2, HIGH);\n    analogWrite(ENA, 200);\n\n    // Motor 2 para frente com velocidade 150\n    digitalWrite(IN3, HIGH);\n    digitalWrite(IN4, LOW);\n    analogWrite(ENB, 150);\n\n    delay(3000);\n}\n</code></pre>"},{"location":"aulas/iot/modulos/modulo11.html#exercicio-2-controlar-a-posicao-de-um-servo-com-botoes","title":"Exerc\u00edcio 2: Controlar a Posi\u00e7\u00e3o de um Servo com Bot\u00f5es","text":"<ul> <li> <p>Tarefa: Desenvolva um sistema onde dois bot\u00f5es controlam a posi\u00e7\u00e3o de um servo motor, movendo-o para a esquerda ou para a direita.</p> </li> <li> <p>Dicas:</p> </li> <li>Utilize resistores de pull-down para os bot\u00f5es.</li> <li> <p>Controle a posi\u00e7\u00e3o do servo incrementando ou decrementando o \u00e2ngulo.</p> </li> <li> <p>Exemplo de C\u00f3digo:</p> </li> </ul> <pre><code>#include &lt;Servo.h&gt;\n\nServo meuServo;\nconst int pinoServo = 9;\nconst int botaoEsquerda = 2;\nconst int botaoDireita = 3;\n\nint posicao = 90; // Posi\u00e7\u00e3o inicial\n\nvoid setup() {\n    meuServo.attach(pinoServo);\n    pinMode(botaoEsquerda, INPUT_PULLUP);\n    pinMode(botaoDireita, INPUT_PULLUP);\n    meuServo.write(posicao);\n    Serial.begin(9600);\n}\n\nvoid loop() {\n    if (digitalRead(botaoEsquerda) == LOW) {\n        posicao -= 5;\n        if (posicao &lt; 0) posicao = 0;\n        meuServo.write(posicao);\n        Serial.print(\"Posi\u00e7\u00e3o: \");\n        Serial.println(posicao);\n        delay(200); // Debounce\n    }\n\n    if (digitalRead(botaoDireita) == LOW) {\n        posicao += 5;\n        if (posicao &gt; 180) posicao = 180;\n        meuServo.write(posicao);\n        Serial.print(\"Posi\u00e7\u00e3o: \");\n        Serial.println(posicao);\n        delay(200); // Debounce\n    }\n}\n</code></pre> <p>Explica\u00e7\u00e3o:</p> <ul> <li>Bot\u00f5es: Dois bot\u00f5es conectados aos pinos 2 e 3 controlam a dire\u00e7\u00e3o do movimento do servo.</li> <li>Controle de Posi\u00e7\u00e3o: Incrementa ou decrementa o \u00e2ngulo do servo em 5 graus a cada pressionamento.</li> </ul>"},{"location":"aulas/iot/modulos/modulo11.html#exercicio-3-controlar-um-motor-de-passo-com-potenciometro","title":"Exerc\u00edcio 3: Controlar um Motor de Passo com Potenci\u00f4metro","text":"<ul> <li> <p>Tarefa: Implemente um sistema onde a velocidade de um motor de passo \u00e9 controlada por um potenci\u00f4metro.</p> </li> <li> <p>Dicas:</p> </li> <li>Utilize a biblioteca <code>Stepper</code> para facilitar o controle.</li> <li> <p>Mapeie a leitura do potenci\u00f4metro para a velocidade do motor.</p> </li> <li> <p>Exemplo de C\u00f3digo:</p> </li> </ul> <pre><code>#include &lt;Stepper.h&gt;\n\nconst int passosPorRevolucao = 200;\nStepper meuStepper(passosPorRevolucao, 8, 9, 10, 11);\n\nconst int pinoPot = A0;\n\nvoid setup() {\n    Serial.begin(9600);\n}\n\nvoid loop() {\n    int valorPot = analogRead(pinoPot);\n    int velocidade = map(valorPot, 0, 1023, 0, 60); // Mapeia para 0-60 RPM\n    meuStepper.setSpeed(velocidade);\n    meuStepper.step(100); // Move 100 passos\n    Serial.print(\"Velocidade: \");\n    Serial.println(velocidade);\n    delay(500);\n}\n</code></pre> <p>Explica\u00e7\u00e3o:</p> <ul> <li>Controle de Velocidade: Utiliza um potenci\u00f4metro para ajustar a velocidade do motor de passo em tempo real.</li> <li>Mapeamento: Converte a leitura anal\u00f3gica (0-1023) para uma velocidade em RPM (0-60).</li> </ul>"},{"location":"aulas/iot/modulos/modulo11.html#9-conceitos-importantes","title":"9. Conceitos Importantes","text":""},{"location":"aulas/iot/modulos/modulo11.html#91-drivers-de-motor","title":"9.1 Drivers de Motor","text":"<ul> <li>Defini\u00e7\u00e3o: Circuitos que permitem ao Arduino controlar motores de alta pot\u00eancia de forma segura.</li> <li>Tipos Comuns: L298N, L293D, A4988, ULN2003.</li> <li>Considera\u00e7\u00f5es: Escolha o driver adequado com base na corrente e tens\u00e3o do motor.</li> </ul>"},{"location":"aulas/iot/modulos/modulo11.html#92-pwm-pulse-width-modulation","title":"9.2 PWM (Pulse Width Modulation)","text":"<ul> <li>Defini\u00e7\u00e3o: T\u00e9cnica de controle de velocidade de motores ajustando a largura dos pulsos de tens\u00e3o.</li> <li>Aplica\u00e7\u00e3o: Utilizada para controlar a velocidade de motores DC e a intensidade de LEDs.</li> <li>Frequ\u00eancia: Importante para evitar ru\u00eddos e vibra\u00e7\u00f5es indesejadas.</li> </ul>"},{"location":"aulas/iot/modulos/modulo11.html#93-controlando-direcao-e-velocidade","title":"9.3 Controlando Dire\u00e7\u00e3o e Velocidade","text":"<ul> <li>Dire\u00e7\u00e3o: Controlada atrav\u00e9s da invers\u00e3o dos sinais de controle nos pinos de dire\u00e7\u00e3o.</li> <li>Velocidade: Controlada ajustando o valor de PWM aplicado ao driver do motor.</li> </ul>"},{"location":"aulas/iot/modulos/modulo11.html#94-bibliotecas-para-facilitar-o-controle","title":"9.4 Bibliotecas para Facilitar o Controle","text":"<ul> <li>Servo: Simplifica o controle de servo motors.</li> <li>Stepper: Facilita o controle de motores de passo.</li> <li>Adafruit Motor Shield: Oferece uma interface simplificada para controlar m\u00faltiplos motores e atuadores.</li> </ul>"},{"location":"aulas/iot/modulos/modulo11.html#95-boas-praticas-no-controle-de-motores","title":"9.5 Boas Pr\u00e1ticas no Controle de Motores","text":"<ul> <li>Prote\u00e7\u00e3o contra Sobrecorrente: Utilize fus\u00edveis ou circuitos de prote\u00e7\u00e3o para evitar danos aos componentes.</li> <li>Alimenta\u00e7\u00e3o Adequada: Certifique-se de que a fonte de alimenta\u00e7\u00e3o atende \u00e0s necessidades dos motores.</li> <li>Gerenciamento de Calor: Drivers de motor podem aquecer; utilize dissipadores de calor se necess\u00e1rio.</li> <li>Isolamento de Sinais: Utilize optoacopladores para isolar o Arduino dos circuitos de alta pot\u00eancia, se aplic\u00e1vel.</li> </ul>"},{"location":"aulas/iot/modulos/modulo11.html#10-recursos-adicionais","title":"10. Recursos Adicionais","text":"<ul> <li> <p>Documenta\u00e7\u00e3o Oficial do Arduino:</p> </li> <li> <p>Servo Library</p> </li> <li>Stepper Library</li> <li> <p>Motor Shield Library</p> </li> <li> <p>Tutoriais e Guias:</p> </li> <li> <p>Controle de Motores DC com Arduino</p> </li> <li>Controlando Servo Motors</li> <li> <p>Controlando Motores de Passo</p> </li> <li> <p>V\u00eddeos Educacionais:</p> </li> <li> <p>Controlando Motores DC com Arduino</p> </li> <li>Controle de Servo Motor com Arduino</li> <li>Motor de Passo com Arduino</li> </ul>"},{"location":"aulas/iot/modulos/modulo11.html#11-conclusao-do-modulo","title":"11. Conclus\u00e3o do M\u00f3dulo","text":"<p>Neste m\u00f3dulo, voc\u00ea aprendeu:</p> <ul> <li>Os diferentes tipos de motores e atuadores e suas aplica\u00e7\u00f5es.</li> <li>Como controlar motores DC utilizando drivers de motor e sinais PWM.</li> <li>Como utilizar a biblioteca <code>Servo</code> para controlar servo motors com precis\u00e3o.</li> <li>O funcionamento e controle de motores de passo utilizando a biblioteca <code>Stepper</code>.</li> <li>Como utilizar drivers de motor avan\u00e7ados como o L298N e Adafruit Motor Shield.</li> <li>Conceitos fundamentais como PWM, controle direcional e velocidade.</li> <li>Praticou com exemplos e exerc\u00edcios que refor\u00e7am o entendimento do controle de motores e atuadores.</li> </ul> <p>Voc\u00ea est\u00e1 agora preparado para avan\u00e7ar para o pr\u00f3ximo m\u00f3dulo, onde exploraremos Sensores e Aquisi\u00e7\u00e3o de Dados, aprofundando seu conhecimento em leitura e interpreta\u00e7\u00e3o de dados de sensores com Arduino.</p>"},{"location":"aulas/iot/modulos/modulo11.html#12-proximos-passos","title":"12. Pr\u00f3ximos Passos","text":"<ul> <li>Revisar o conte\u00fado deste m\u00f3dulo e certificar-se de que compreendeu os conceitos apresentados.</li> <li>Completar os exerc\u00edcios propostos para consolidar o aprendizado.</li> <li>Preparar-se para o M\u00f3dulo 12: Sensores e Aquisi\u00e7\u00e3o de Dados.</li> </ul> <p>Se tiver d\u00favidas ou precisar de assist\u00eancia, n\u00e3o hesite em procurar recursos adicionais ou participar de comunidades de aprendizagem para obter suporte.</p> <p>Bom trabalho e continue assim!</p>"},{"location":"aulas/iot/modulos/modulo12.html","title":"M\u00f3dulo 12: Sensores e Aquisi\u00e7\u00e3o de Dados","text":"<p>Bem-vindo ao M\u00f3dulo 12 do curso \"Programa\u00e7\u00e3o em Arduino: Conceitos Fundamentais sem Hardware\". Neste m\u00f3dulo, voc\u00ea ir\u00e1 explorar o uso de sensores e as t\u00e9cnicas de aquisi\u00e7\u00e3o de dados com o Arduino. Sensores s\u00e3o componentes essenciais que permitem ao Arduino interagir com o ambiente f\u00edsico, coletando informa\u00e7\u00f5es que podem ser processadas e utilizadas em diversos projetos.</p>"},{"location":"aulas/iot/modulos/modulo12.html#objetivos-do-modulo","title":"Objetivos do M\u00f3dulo","text":"<ul> <li>Compreender os diferentes tipos de sensores dispon\u00edveis para Arduino.</li> <li>Aprender a conectar e configurar sensores com o Arduino.</li> <li>Implementar a leitura de dados de sensores utilizando entradas anal\u00f3gicas e digitais.</li> <li>Utilizar bibliotecas espec\u00edficas para facilitar a comunica\u00e7\u00e3o com sensores complexos.</li> <li>Processar e interpretar os dados coletados de sensores.</li> <li>Resolver exerc\u00edcios pr\u00e1ticos para consolidar o conhecimento sobre sensores e aquisi\u00e7\u00e3o de dados.</li> </ul>"},{"location":"aulas/iot/modulos/modulo12.html#1-introducao-a-sensores-e-aquisicao-de-dados","title":"1. Introdu\u00e7\u00e3o a Sensores e Aquisi\u00e7\u00e3o de Dados","text":""},{"location":"aulas/iot/modulos/modulo12.html#11-o-que-sao-sensores","title":"1.1 O que s\u00e3o Sensores?","text":"<p>Sensores s\u00e3o dispositivos que detectam eventos ou mudan\u00e7as no ambiente f\u00edsico e convertem essas informa\u00e7\u00f5es em sinais el\u00e9tricos que podem ser processados pelo Arduino. Eles permitem que o Arduino interaja com o mundo real, tornando poss\u00edvel a cria\u00e7\u00e3o de projetos inteligentes e responsivos.</p>"},{"location":"aulas/iot/modulos/modulo12.html#12-importancia-da-aquisicao-de-dados","title":"1.2 Import\u00e2ncia da Aquisi\u00e7\u00e3o de Dados","text":"<p>A aquisi\u00e7\u00e3o de dados envolve a coleta, processamento e an\u00e1lise de informa\u00e7\u00f5es provenientes de sensores. \u00c9 um componente fundamental em sistemas de automa\u00e7\u00e3o, monitoramento ambiental, rob\u00f3tica e muitas outras aplica\u00e7\u00f5es que requerem intera\u00e7\u00e3o com o ambiente.</p>"},{"location":"aulas/iot/modulos/modulo12.html#13-tipos-comuns-de-sensores-para-arduino","title":"1.3 Tipos Comuns de Sensores para Arduino","text":"<ul> <li>Sensores de Temperatura: Como o LM35 e o DHT11/DHT22.</li> <li>Sensores de Umidade: Integrados em sensores como o DHT11/DHT22.</li> <li>Sensores de Movimento: Como o PIR (Passive Infrared) e aceler\u00f4metros.</li> <li>Sensores de Luz: Como o LDR (Light Dependent Resistor).</li> <li>Sensores de Dist\u00e2ncia: Como o Ultrass\u00f4nico HC-SR04.</li> <li>Sensores de G\u00e1s: Como o MQ-2 e MQ-135.</li> <li>Sensores de Press\u00e3o: Como o BMP180 e BMP280.</li> </ul>"},{"location":"aulas/iot/modulos/modulo12.html#2-interfacing-sensores-com-arduino","title":"2. Interfacing Sensores com Arduino","text":""},{"location":"aulas/iot/modulos/modulo12.html#21-conexoes-basicas-de-sensores","title":"2.1 Conex\u00f5es B\u00e1sicas de Sensores","text":"<p>A maneira como voc\u00ea conecta um sensor ao Arduino depende do tipo de sensor e das suas especifica\u00e7\u00f5es. A seguir, veremos exemplos de como conectar sensores comuns.</p>"},{"location":"aulas/iot/modulos/modulo12.html#22-sensores-digitais-vs-analogicos","title":"2.2 Sensores Digitais vs. Anal\u00f3gicos","text":"<ul> <li>Sensores Digitais: Enviam sinais digitais (HIGH ou LOW) para o Arduino. Exemplo: Sensor de movimento PIR.</li> <li>Sensores Anal\u00f3gicos: Enviam sinais anal\u00f3gicos que variam entre 0 e 5V. O Arduino utiliza um conversor anal\u00f3gico-digital (ADC) para interpretar esses sinais. Exemplo: LDR (Light Dependent Resistor).</li> </ul>"},{"location":"aulas/iot/modulos/modulo12.html#23-exemplo-de-conexao-de-um-ldr","title":"2.3 Exemplo de Conex\u00e3o de um LDR","text":"<p>Componentes Necess\u00e1rios:</p> <ul> <li>LDR (Light Dependent Resistor)</li> <li>Resistores (10k\u03a9)</li> <li>Cabos de Conex\u00e3o</li> <li>Protoboard</li> <li>Arduino</li> </ul> <p>Conex\u00e3o:</p> <ol> <li>Conecte uma extremidade do LDR ao pino 5V do Arduino.</li> <li>Conecte a outra extremidade do LDR a um terminal do resistor de 10k\u03a9.</li> <li>Conecte o outro terminal do resistor ao GND do Arduino.</li> <li>Conecte o ponto de jun\u00e7\u00e3o entre o LDR e o resistor ao pino anal\u00f3gico A0 do Arduino.</li> </ol>"},{"location":"aulas/iot/modulos/modulo12.html#3-leitura-de-dados-de-sensores","title":"3. Leitura de Dados de Sensores","text":""},{"location":"aulas/iot/modulos/modulo12.html#31-leitura-de-sensores-analogicos","title":"3.1 Leitura de Sensores Anal\u00f3gicos","text":"<p>Os sensores anal\u00f3gicos fornecem um valor cont\u00ednuo que pode ser lido pelo Arduino usando a fun\u00e7\u00e3o <code>analogRead()</code>.</p> <p>Exemplo de C\u00f3digo para Ler um LDR:</p> <p>\u02dc\u02dc\u02dccpp const int pinoLDR = A0;</p> <p>void setup() {     Serial.begin(9600);     pinMode(pinoLDR, INPUT); }</p> <p>void loop() {     int valorLDR = analogRead(pinoLDR);     Serial.print(\"Valor do LDR: \");     Serial.println(valorLDR);     delay(500); } \u02dc\u02dc\u02dc</p> <p>Explica\u00e7\u00e3o:</p> <ul> <li><code>analogRead(pinoLDR)</code>: L\u00ea o valor anal\u00f3gico do pino A0, retornando um valor entre 0 e 1023.</li> <li>Serial Monitor: Exibe o valor lido, permitindo monitorar a varia\u00e7\u00e3o da luz ambiente.</li> </ul>"},{"location":"aulas/iot/modulos/modulo12.html#32-leitura-de-sensores-digitais","title":"3.2 Leitura de Sensores Digitais","text":"<p>Sensores digitais enviam sinais HIGH ou LOW. A leitura \u00e9 feita usando a fun\u00e7\u00e3o <code>digitalRead()</code>.</p> <p>Exemplo de C\u00f3digo para Ler um Sensor PIR:</p> <p>\u02dc\u02dc\u02dccpp const int pinoPIR = 2; volatile bool movimentoDetectado = false;</p> <p>void setup() {     Serial.begin(9600);     pinMode(pinoPIR, INPUT); }</p> <p>void loop() {     int estadoPIR = digitalRead(pinoPIR);     if (estadoPIR == HIGH) {         if (!movimentoDetectado) {             Serial.println(\"Movimento Detectado!\");             movimentoDetectado = true;         }     } else {         if (movimentoDetectado) {             Serial.println(\"Movimento Terminado.\");             movimentoDetectado = false;         }     }     delay(100); } \u02dc\u02dc\u02dc</p> <p>Explica\u00e7\u00e3o:</p> <ul> <li><code>digitalRead(pinoPIR)</code>: L\u00ea o estado do pino 2, detectando movimento.</li> <li>Detec\u00e7\u00e3o de Mudan\u00e7a: Evita m\u00faltiplas mensagens ao verificar se o estado mudou.</li> </ul>"},{"location":"aulas/iot/modulos/modulo12.html#4-utilizando-bibliotecas-para-sensores-complexos","title":"4. Utilizando Bibliotecas para Sensores Complexos","text":"<p>Alguns sensores requerem o uso de bibliotecas espec\u00edficas para facilitar a comunica\u00e7\u00e3o e o processamento dos dados.</p>"},{"location":"aulas/iot/modulos/modulo12.html#41-biblioteca-dht-para-sensores-de-temperatura-e-umidade","title":"4.1 Biblioteca DHT para Sensores de Temperatura e Umidade","text":"<p>Os sensores DHT11 e DHT22 s\u00e3o populares para medir temperatura e umidade. A biblioteca <code>DHT</code> simplifica a leitura desses sensores.</p> <p>Instala\u00e7\u00e3o da Biblioteca DHT:</p> <ol> <li>Abra o IDE do Arduino.</li> <li>V\u00e1 para Sketch &gt; Include Library &gt; Manage Libraries...</li> <li>Procure por \"DHT sensor library\" e instale a biblioteca de Adafruit.</li> </ol>"},{"location":"aulas/iot/modulos/modulo12.html#42-exemplo-de-codigo-com-biblioteca-dht","title":"4.2 Exemplo de C\u00f3digo com Biblioteca DHT","text":"<p>\u02dc\u02dc\u02dccpp</p>"},{"location":"aulas/iot/modulos/modulo12.html#include-dhth","title":"include \"DHT.h\"","text":""},{"location":"aulas/iot/modulos/modulo12.html#define-dhtpin-2-pino-conectado-ao-sensor","title":"define DHTPIN 2     // Pino conectado ao sensor","text":""},{"location":"aulas/iot/modulos/modulo12.html#define-dhttype-dht22-dht-22-am2302","title":"define DHTTYPE DHT22   // DHT 22 (AM2302)","text":"<p>DHT dht(DHTPIN, DHTTYPE);</p> <p>void setup() {     Serial.begin(9600);     dht.begin(); }</p> <p>void loop() {     // Aguarda alguns segundos entre as leituras     delay(2000);</p> <pre><code>// L\u00ea a umidade\nfloat umidade = dht.readHumidity();\n// L\u00ea a temperatura em Celsius\nfloat temperatura = dht.readTemperature();\n\n// Verifica se alguma leitura falhou\nif (isnan(umidade) || isnan(temperatura)) {\n    Serial.println(\"Falha na leitura do sensor DHT!\");\n    return;\n}\n\nSerial.print(\"Umidade: \");\nSerial.print(umidade);\nSerial.print(\" %\\t\");\nSerial.print(\"Temperatura: \");\nSerial.print(temperatura);\nSerial.println(\" *C\");\n</code></pre> <p>} \u02dc\u02dc\u02dc</p> <p>Explica\u00e7\u00e3o:</p> <ul> <li>Inicializa\u00e7\u00e3o: Configura o sensor DHT22 no pino 2.</li> <li>Leitura de Dados: Obt\u00e9m valores de umidade e temperatura.</li> <li>Valida\u00e7\u00e3o: Verifica se as leituras s\u00e3o v\u00e1lidas antes de exibir.</li> </ul>"},{"location":"aulas/iot/modulos/modulo12.html#5-processamento-e-interpretacao-de-dados","title":"5. Processamento e Interpreta\u00e7\u00e3o de Dados","text":"<p>Ap\u00f3s a aquisi\u00e7\u00e3o dos dados, \u00e9 importante process\u00e1-los para obter informa\u00e7\u00f5es \u00fateis e tomar decis\u00f5es baseadas nesses dados.</p>"},{"location":"aulas/iot/modulos/modulo12.html#51-mapeamento-de-valores","title":"5.1 Mapeamento de Valores","text":"<p>O mapeamento \u00e9 usado para converter valores de um intervalo para outro.</p> <p>Exemplo: Mapeando Valores de Temperatura para Controle de LED:</p> <p>\u02dc\u02dc\u02dccpp const int pinoLED = 9;</p> <p>void setup() {     pinMode(pinoLED, OUTPUT);     Serial.begin(9600); }</p> <p>void loop() {     // Supondo que temperatura seja lida de um sensor     float temperatura = 25.0; // Valor de exemplo     // Mapeia temperatura de 0-50\u00b0C para 0-255 (PWM)     int intensidade = map(temperatura * 10, 0, 500, 0, 255);     analogWrite(pinoLED, intensidade);     Serial.print(\"Temperatura: \");     Serial.print(temperatura);     Serial.print(\" *C\\tLED Intensidade: \");     Serial.println(intensidade);     delay(1000); } \u02dc\u02dc\u02dc</p> <p>Explica\u00e7\u00e3o:</p> <ul> <li><code>map()</code>: Converte a temperatura em um valor PWM para controlar a intensidade do LED.</li> <li>Controle de LED: A intensidade do LED varia conforme a temperatura lida.</li> </ul>"},{"location":"aulas/iot/modulos/modulo12.html#52-filtragem-de-dados","title":"5.2 Filtragem de Dados","text":"<p>A filtragem \u00e9 usada para remover ru\u00eddos e obter leituras mais precisas.</p> <p>Exemplo: M\u00e9dia M\u00f3vel para Filtrar Ru\u00eddo em Leituras de Sensor:</p> <p>\u02dc\u02dc\u02dccpp const int pinoSensor = A0; const int tamanhoJanela = 10; int valores[tamanhoJanela]; int indice = 0; long soma = 0;</p> <p>void setup() {     Serial.begin(9600);     for(int i = 0; i &lt; tamanhoJanela; i++) {         valores[i] = 0;     } }</p> <p>void loop() {     // L\u00ea o novo valor do sensor     int novoValor = analogRead(pinoSensor);     // Subtrai o valor antigo da soma     soma -= valores[indice];     // Adiciona o novo valor \u00e0 soma     soma += novoValor;     // Armazena o novo valor na janela     valores[indice] = novoValor;     // Incrementa o \u00edndice e reinicia se necess\u00e1rio     indice = (indice + 1) % tamanhoJanela;     // Calcula a m\u00e9dia     float media = soma / (float)tamanhoJanela;     Serial.print(\"M\u00e9dia: \");     Serial.println(media);     delay(500); } \u02dc\u02dc\u02dc</p> <p>Explica\u00e7\u00e3o:</p> <ul> <li>Janela de M\u00e9dia: Mant\u00e9m os \u00faltimos 10 valores lidos.</li> <li>C\u00e1lculo da M\u00e9dia: Obt\u00e9m a m\u00e9dia dos valores para filtrar ru\u00eddos.</li> </ul>"},{"location":"aulas/iot/modulos/modulo12.html#6-exemplos-praticos","title":"6. Exemplos Pr\u00e1ticos","text":""},{"location":"aulas/iot/modulos/modulo12.html#61-monitoramento-de-temperatura-e-controle-de-ventilador","title":"6.1 Monitoramento de Temperatura e Controle de Ventilador","text":"<p>Este exemplo utiliza um sensor de temperatura para monitorar a temperatura ambiente e controla um ventilador (motor DC) com base nas leituras.</p> <p>\u02dc\u02dc\u02dccpp</p>"},{"location":"aulas/iot/modulos/modulo12.html#include-dhth_1","title":"include \"DHT.h\"","text":""},{"location":"aulas/iot/modulos/modulo12.html#define-dhtpin-2","title":"define DHTPIN 2","text":""},{"location":"aulas/iot/modulos/modulo12.html#define-dhttype-dht22","title":"define DHTTYPE DHT22","text":"<p>DHT dht(DHTPIN, DHTTYPE);</p> <p>const int IN1 = 9; const int IN2 = 8; const int ENA = 10;</p> <p>void setup() {     Serial.begin(9600);     dht.begin();     pinMode(IN1, OUTPUT);     pinMode(IN2, OUTPUT);     pinMode(ENA, OUTPUT); }</p> <p>void loop() {     delay(2000);     float temperatura = dht.readTemperature();     if (isnan(temperatura)) {         Serial.println(\"Falha na leitura do sensor DHT!\");         return;     }</p> <pre><code>Serial.print(\"Temperatura: \");\nSerial.print(temperatura);\nSerial.println(\" *C\");\n\nif (temperatura &gt; 25.0) {\n    // Liga o ventilador\n    digitalWrite(IN1, HIGH);\n    digitalWrite(IN2, LOW);\n    analogWrite(ENA, 200);\n    Serial.println(\"Ventilador Ligado.\");\n} else {\n    // Desliga o ventilador\n    digitalWrite(IN1, LOW);\n    digitalWrite(IN2, LOW);\n    analogWrite(ENA, 0);\n    Serial.println(\"Ventilador Desligado.\");\n}\n</code></pre> <p>} \u02dc\u02dc\u02dc</p> <p>Explica\u00e7\u00e3o:</p> <ul> <li>Leitura de Temperatura: Utiliza o sensor DHT22 para obter a temperatura ambiente.</li> <li>Controle do Ventilador: Liga o ventilador se a temperatura exceder 25\u00b0C e desliga caso contr\u00e1rio.</li> </ul>"},{"location":"aulas/iot/modulos/modulo12.html#62-sistema-de-alarme-com-sensor-de-gas","title":"6.2 Sistema de Alarme com Sensor de G\u00e1s","text":"<p>Este exemplo utiliza um sensor de g\u00e1s para detectar a presen\u00e7a de gases nocivos e aciona um alarme (LED e buzzer) quando n\u00edveis perigosos s\u00e3o detectados.</p> <p>\u02dc\u02dc\u02dccpp const int pinoG\u00e1s = A0; const int pinoLED = 13; const int pinoBuzzer = 12; const int limiarG\u00e1s = 300; // Valor de exemplo</p> <p>void setup() {     Serial.begin(9600);     pinMode(pinoLED, OUTPUT);     pinMode(pinoBuzzer, OUTPUT); }</p> <p>void loop() {     int valorG\u00e1s = analogRead(pinoG\u00e1s);     Serial.print(\"N\u00edvel de G\u00e1s: \");     Serial.println(valorG\u00e1s);</p> <pre><code>if (valorG\u00e1s &gt; limiarG\u00e1s) {\n    digitalWrite(pinoLED, HIGH);\n    digitalWrite(pinoBuzzer, HIGH);\n    Serial.println(\"Alerta! N\u00edvel de g\u00e1s perigoso!\");\n} else {\n    digitalWrite(pinoLED, LOW);\n    digitalWrite(pinoBuzzer, LOW);\n}\ndelay(1000);\n</code></pre> <p>} \u02dc\u02dc\u02dc</p> <p>Explica\u00e7\u00e3o:</p> <ul> <li>Leitura do Sensor de G\u00e1s: Monitora continuamente os n\u00edveis de g\u00e1s.</li> <li>Ativa\u00e7\u00e3o do Alarme: Aciona LED e buzzer quando o n\u00edvel de g\u00e1s ultrapassa o limiar definido.</li> </ul>"},{"location":"aulas/iot/modulos/modulo12.html#63-monitoramento-de-distancia-com-ultrassonico-e-display-lcd","title":"6.3 Monitoramento de Dist\u00e2ncia com Ultrass\u00f4nico e Display LCD","text":"<p>Este exemplo utiliza um sensor ultrass\u00f4nico para medir a dist\u00e2ncia at\u00e9 um objeto e exibe os resultados em um display LCD.</p> <p>\u02dc\u02dc\u02dccpp</p>"},{"location":"aulas/iot/modulos/modulo12.html#include","title":"include  <p>// Defini\u00e7\u00e3o dos pinos do LCD LiquidCrystal lcd(12, 11, 5, 4, 3, 2);</p> <p>// Defini\u00e7\u00e3o dos pinos do sensor ultrass\u00f4nico const int trigPin = 9; const int echoPin = 10;</p> <p>void setup() {     lcd.begin(16, 2);     pinMode(trigPin, OUTPUT);     pinMode(echoPin, INPUT);     lcd.print(\"Medindo Distancia\"); }</p> <p>void loop() {     // Limpa o pino Trig     digitalWrite(trigPin, LOW);     delayMicroseconds(2);</p> <pre><code>// Envia pulso de 10us\ndigitalWrite(trigPin, HIGH);\ndelayMicroseconds(10);\ndigitalWrite(trigPin, LOW);\n\n// Calcula a dura\u00e7\u00e3o do pulso\nlong duracao = pulseIn(echoPin, HIGH);\n\n// Calcula a dist\u00e2ncia em cent\u00edmetros\nfloat distancia = duracao * 0.034 / 2;\n\n// Exibe a dist\u00e2ncia no LCD\nlcd.clear();\nlcd.setCursor(0, 0);\nlcd.print(\"Distancia: \");\nlcd.print(distancia);\nlcd.print(\" cm\");\n\nSerial.print(\"Distancia: \");\nSerial.print(distancia);\nSerial.println(\" cm\");\n\ndelay(1000);\n</code></pre> <p>} \u02dc\u02dc\u02dc</p> <p>Explica\u00e7\u00e3o:</p> <ul> <li>Sensor Ultrass\u00f4nico: Emite um pulso sonoro e mede o tempo de retorno para calcular a dist\u00e2ncia.</li> <li>Display LCD: Exibe a dist\u00e2ncia medida em tempo real.</li> </ul>","text":""},{"location":"aulas/iot/modulos/modulo12.html#7-exercicios-praticos","title":"7. Exerc\u00edcios Pr\u00e1ticos","text":""},{"location":"aulas/iot/modulos/modulo12.html#exercicio-1-monitoramento-de-temperatura-e-acionamento-de-ventilador-com-hysteresis","title":"Exerc\u00edcio 1: Monitoramento de Temperatura e Acionamento de Ventilador com Hysteresis","text":"<ul> <li> <p>Tarefa: Modifique o exemplo de monitoramento de temperatura para incluir hysteresis, evitando que o ventilador ligue e desligue repetidamente em torno do ponto de corte.</p> </li> <li> <p>Dicas:</p> </li> <li>Defina dois limiares: um para ligar e outro para desligar o ventilador.</li> <li> <p>Utilize uma vari\u00e1vel para rastrear o estado atual do ventilador.</p> </li> <li> <p>Exemplo de C\u00f3digo:</p> </li> </ul> <p>\u02dc\u02dc\u02dccpp</p>"},{"location":"aulas/iot/modulos/modulo12.html#include-dhth_2","title":"include \"DHT.h\"","text":""},{"location":"aulas/iot/modulos/modulo12.html#define-dhtpin-2_1","title":"define DHTPIN 2","text":""},{"location":"aulas/iot/modulos/modulo12.html#define-dhttype-dht22_1","title":"define DHTTYPE DHT22 <p>DHT dht(DHTPIN, DHTTYPE);</p> <p>const int IN1 = 9; const int IN2 = 8; const int ENA = 10;</p> <p>const float limiarLigar = 25.0; const float limiarDesligar = 23.0; bool ventiladorLigado = false;</p> <p>void setup() {     Serial.begin(9600);     dht.begin();     pinMode(IN1, OUTPUT);     pinMode(IN2, OUTPUT);     pinMode(ENA, OUTPUT); }</p> <p>void loop() {     delay(2000);     float temperatura = dht.readTemperature();     if (isnan(temperatura)) {         Serial.println(\"Falha na leitura do sensor DHT!\");         return;     }</p> <pre><code>Serial.print(\"Temperatura: \");\nSerial.print(temperatura);\nSerial.println(\" *C\");\n\nif (!ventiladorLigado &amp;&amp; temperatura &gt; limiarLigar) {\n    // Liga o ventilador\n    digitalWrite(IN1, HIGH);\n    digitalWrite(IN2, LOW);\n    analogWrite(ENA, 200);\n    ventiladorLigado = true;\n    Serial.println(\"Ventilador Ligado.\");\n} else if (ventiladorLigado &amp;&amp; temperatura &lt; limiarDesligar) {\n    // Desliga o ventilador\n    digitalWrite(IN1, LOW);\n    digitalWrite(IN2, LOW);\n    analogWrite(ENA, 0);\n    ventiladorLigado = false;\n    Serial.println(\"Ventilador Desligado.\");\n}\n</code></pre> <p>} \u02dc\u02dc\u02dc</p>","text":""},{"location":"aulas/iot/modulos/modulo12.html#exercicio-2-sistema-de-irrigacao-automatica-com-sensor-de-umidade-do-solo","title":"Exerc\u00edcio 2: Sistema de Irriga\u00e7\u00e3o Autom\u00e1tica com Sensor de Umidade do Solo","text":"<ul> <li> <p>Tarefa: Desenvolva um sistema que l\u00ea a umidade do solo e ativa uma bomba de \u00e1gua quando a umidade estiver abaixo de um determinado limiar.</p> </li> <li> <p>Dicas:</p> </li> <li>Utilize um sensor de umidade do solo anal\u00f3gico.</li> <li> <p>Controle a bomba utilizando um rel\u00e9 ou driver de motor.</p> </li> <li> <p>Exemplo de C\u00f3digo:</p> </li> </ul> <p>\u02dc\u02dc\u02dccpp const int pinoUmidade = A0; const int pinoRel\u00e9 = 7; const int limiarUmidade = 400; // Valor de exemplo</p> <p>void setup() {     Serial.begin(9600);     pinMode(pinoRel\u00e9, OUTPUT);     digitalWrite(pinoRel\u00e9, LOW); // Bomba desligada inicialmente }</p> <p>void loop() {     int valorUmidade = analogRead(pinoUmidade);     Serial.print(\"Umidade do Solo: \");     Serial.println(valorUmidade);</p> <pre><code>if (valorUmidade &lt; limiarUmidade) {\n    digitalWrite(pinoRel\u00e9, HIGH); // Liga a bomba\n    Serial.println(\"Bomba Ligada.\");\n} else {\n    digitalWrite(pinoRel\u00e9, LOW); // Desliga a bomba\n    Serial.println(\"Bomba Desligada.\");\n}\ndelay(1000);\n</code></pre> <p>} \u02dc\u02dc\u02dc</p> <p>Explica\u00e7\u00e3o:</p> <ul> <li>Sensor de Umidade do Solo: Mede a umidade do solo em tempo real.</li> <li>Controle da Bomba: Liga a bomba quando a umidade est\u00e1 abaixo do limiar e desliga quando est\u00e1 acima.</li> </ul>"},{"location":"aulas/iot/modulos/modulo12.html#exercicio-3-interface-de-sensores-com-display-oled","title":"Exerc\u00edcio 3: Interface de Sensores com Display OLED","text":"<ul> <li> <p>Tarefa: Implemente um sistema que l\u00ea dados de m\u00faltiplos sensores (temperatura, umidade e dist\u00e2ncia) e exibe as informa\u00e7\u00f5es em um display OLED.</p> </li> <li> <p>Dicas:</p> </li> <li>Utilize a biblioteca <code>Adafruit_SSD1306</code> para controlar o display OLED.</li> <li> <p>Organize os dados de forma clara e leg\u00edvel no display.</p> </li> <li> <p>Exemplo de C\u00f3digo:</p> </li> </ul> <p>\u02dc\u02dc\u02dccpp</p>"},{"location":"aulas/iot/modulos/modulo12.html#include_1","title":"include","text":""},{"location":"aulas/iot/modulos/modulo12.html#include_2","title":"include","text":""},{"location":"aulas/iot/modulos/modulo12.html#include_3","title":"include","text":""},{"location":"aulas/iot/modulos/modulo12.html#include-dhth_3","title":"include \"DHT.h\"","text":""},{"location":"aulas/iot/modulos/modulo12.html#define-screen_width-128","title":"define SCREEN_WIDTH 128","text":""},{"location":"aulas/iot/modulos/modulo12.html#define-screen_height-64","title":"define SCREEN_HEIGHT 64","text":""},{"location":"aulas/iot/modulos/modulo12.html#define-oled_reset-1","title":"define OLED_RESET     -1 <p>Adafruit_SSD1306 display(SCREEN_WIDTH, SCREEN_HEIGHT, &amp;Wire, OLED_RESET);</p>","text":""},{"location":"aulas/iot/modulos/modulo12.html#define-dhtpin-2_2","title":"define DHTPIN 2","text":""},{"location":"aulas/iot/modulos/modulo12.html#define-dhttype-dht22_2","title":"define DHTTYPE DHT22 <p>DHT dht(DHTPIN, DHTTYPE);</p> <p>const int trigPin = 9; const int echoPin = 10;</p> <p>void setup() {     Serial.begin(9600);     dht.begin();</p> <pre><code>// Inicializa o display OLED\nif(!display.begin(SSD1306_SWITCHCAPVCC, 0x3C)) {\n    Serial.println(F(\"Falha ao inicializar o display OLED!\"));\n    for(;;);\n}\ndelay(1000);\ndisplay.clearDisplay();\ndisplay.setTextSize(1);\ndisplay.setTextColor(SSD1306_WHITE);\n</code></pre> <p>}</p> <p>void loop() {     // Leitura do sensor DHT22     float temperatura = dht.readTemperature();     float umidade = dht.readHumidity();</p> <pre><code>// Leitura do sensor ultrass\u00f4nico\ndigitalWrite(trigPin, LOW);\ndelayMicroseconds(2);\ndigitalWrite(trigPin, HIGH);\ndelayMicroseconds(10);\ndigitalWrite(trigPin, LOW);\nlong duracao = pulseIn(echoPin, HIGH);\nfloat distancia = duracao * 0.034 / 2;\n\n// Verifica se as leituras s\u00e3o v\u00e1lidas\nif (isnan(temperatura) || isnan(umidade)) {\n    Serial.println(\"Falha na leitura do sensor DHT!\");\n    return;\n}\n\n// Exibe os dados no display OLED\ndisplay.clearDisplay();\ndisplay.setCursor(0,0);\ndisplay.print(\"Temp: \");\ndisplay.print(temperatura);\ndisplay.println(\" C\");\n\ndisplay.print(\"Umid: \");\ndisplay.print(umidade);\ndisplay.println(\" %\");\n\ndisplay.print(\"Dist: \");\ndisplay.print(distancia);\ndisplay.println(\" cm\");\n\ndisplay.display();\n\nSerial.print(\"Temperatura: \");\nSerial.print(temperatura);\nSerial.print(\" *C\\tUmidade: \");\nSerial.print(umidade);\nSerial.print(\" %\\tDistancia: \");\nSerial.print(distancia);\nSerial.println(\" cm\");\n\ndelay(2000);\n</code></pre> <p>} \u02dc\u02dc\u02dc</p> <p>Explica\u00e7\u00e3o:</p> <ul> <li>Display OLED: Utiliza a biblioteca <code>Adafruit_SSD1306</code> para exibir informa\u00e7\u00f5es dos sensores.</li> <li>Organiza\u00e7\u00e3o de Dados: As informa\u00e7\u00f5es s\u00e3o organizadas de forma clara e atualizadas a cada 2 segundos.</li> </ul>","text":""},{"location":"aulas/iot/modulos/modulo12.html#8-conceitos-importantes","title":"8. Conceitos Importantes","text":""},{"location":"aulas/iot/modulos/modulo12.html#81-calibracao-de-sensores","title":"8.1 Calibra\u00e7\u00e3o de Sensores","text":"<ul> <li>Defini\u00e7\u00e3o: Ajustar os sensores para garantir que as leituras sejam precisas.</li> <li>M\u00e9todos:</li> <li>Comparar as leituras com instrumentos de refer\u00eancia.</li> <li>Ajustar valores de offset e escala no c\u00f3digo.</li> </ul>"},{"location":"aulas/iot/modulos/modulo12.html#82-uso-de-variaveis-volateis","title":"8.2 Uso de Vari\u00e1veis Vol\u00e1teis","text":"<ul> <li>Defini\u00e7\u00e3o: Vari\u00e1veis que podem ser modificadas por ISRs ou m\u00faltiplas threads.</li> <li>Uso: Declarar vari\u00e1veis compartilhadas entre o loop principal e ISRs como <code>volatile</code> para garantir leituras corretas.</li> </ul>"},{"location":"aulas/iot/modulos/modulo12.html#83-tecnicas-de-filtragem-de-dados","title":"8.3 T\u00e9cnicas de Filtragem de Dados","text":"<ul> <li>M\u00e9dia M\u00f3vel: Suaviza as leituras ao calcular a m\u00e9dia de um conjunto de valores.</li> <li>Filtro de Kalman: Avan\u00e7ado m\u00e9todo de filtragem que estima o estado de um sistema.</li> <li>Desvio Padr\u00e3o: Identifica e descarta leituras que se desviam significativamente da m\u00e9dia.</li> </ul>"},{"location":"aulas/iot/modulos/modulo12.html#84-gerenciamento-de-energia","title":"8.4 Gerenciamento de Energia","text":"<ul> <li>Import\u00e2ncia: Sensores e m\u00f3dulos adicionais podem aumentar o consumo de energia.</li> <li>Pr\u00e1ticas:</li> <li>Desligar sensores quando n\u00e3o estiverem em uso.</li> <li>Utilizar modos de baixo consumo do Arduino.</li> <li>Escolher sensores com baixo consumo de energia.</li> </ul>"},{"location":"aulas/iot/modulos/modulo12.html#85-boas-praticas-na-aquisicao-de-dados","title":"8.5 Boas Pr\u00e1ticas na Aquisi\u00e7\u00e3o de Dados","text":"<ul> <li>Consist\u00eancia: Realizar leituras em intervalos regulares.</li> <li>Valida\u00e7\u00e3o: Verificar a validade das leituras antes de utiliz\u00e1-las.</li> <li>Armazenamento: Utilizar estruturas de dados adequadas para armazenar e processar os dados coletados.</li> <li>Seguran\u00e7a: Proteger os circuitos contra sobrecargas e interfer\u00eancias.</li> </ul>"},{"location":"aulas/iot/modulos/modulo12.html#9-recursos-adicionais","title":"9. Recursos Adicionais","text":"<ul> <li> <p>Documenta\u00e7\u00e3o Oficial do Arduino:</p> </li> <li> <p>Sensor Library</p> </li> <li>LiquidCrystal Library</li> <li> <p>Adafruit SSD1306 Library</p> </li> <li> <p>Tutoriais e Guias:</p> </li> <li> <p>Guia Completo de Sensores no Arduino</p> </li> <li>Interfacing Sensors with Arduino</li> <li> <p>Processamento de Dados com Arduino</p> </li> <li> <p>V\u00eddeos Educacionais:</p> </li> <li> <p>Interfacing Sensors with Arduino</p> </li> <li>Arduino Sensor Calibration</li> <li>Data Acquisition Systems with Arduino</li> </ul>"},{"location":"aulas/iot/modulos/modulo12.html#10-exemplos-praticos","title":"10. Exemplos Pr\u00e1ticos","text":""},{"location":"aulas/iot/modulos/modulo12.html#101-sistema-de-monitoramento-ambiental-com-multiplos-sensores","title":"10.1 Sistema de Monitoramento Ambiental com M\u00faltiplos Sensores","text":"<p>\u02dc\u02dc\u02dccpp</p>"},{"location":"aulas/iot/modulos/modulo12.html#include-dhth_4","title":"include \"DHT.h\"","text":""},{"location":"aulas/iot/modulos/modulo12.html#include_4","title":"include","text":""},{"location":"aulas/iot/modulos/modulo12.html#include_5","title":"include","text":""},{"location":"aulas/iot/modulos/modulo12.html#define-screen_width-128_1","title":"define SCREEN_WIDTH 128","text":""},{"location":"aulas/iot/modulos/modulo12.html#define-screen_height-64_1","title":"define SCREEN_HEIGHT 64","text":""},{"location":"aulas/iot/modulos/modulo12.html#define-oled_reset-1_1","title":"define OLED_RESET     -1 <p>Adafruit_SSD1306 display(SCREEN_WIDTH, SCREEN_HEIGHT, &amp;Wire, OLED_RESET);</p>","text":""},{"location":"aulas/iot/modulos/modulo12.html#define-dhtpin-2_3","title":"define DHTPIN 2","text":""},{"location":"aulas/iot/modulos/modulo12.html#define-dhttype-dht22_3","title":"define DHTTYPE DHT22 <p>DHT dht(DHTPIN, DHTTYPE);</p> <p>const int trigPin = 9; const int echoPin = 10;</p> <p>void setup() {     Serial.begin(9600);     dht.begin();</p> <pre><code>// Inicializa o display OLED\nif(!display.begin(SSD1306_SWITCHCAPVCC, 0x3C)) {\n    Serial.println(F(\"Falha ao inicializar o display OLED!\"));\n    for(;;);\n}\ndelay(1000);\ndisplay.clearDisplay();\ndisplay.setTextSize(1);\ndisplay.setTextColor(SSD1306_WHITE);\n</code></pre> <p>}</p> <p>void loop() {     // Leitura do sensor DHT22     float temperatura = dht.readTemperature();     float umidade = dht.readHumidity();</p> <pre><code>// Leitura do sensor ultrass\u00f4nico\ndigitalWrite(trigPin, LOW);\ndelayMicroseconds(2);\ndigitalWrite(trigPin, HIGH);\ndelayMicroseconds(10);\ndigitalWrite(trigPin, LOW);\nlong duracao = pulseIn(echoPin, HIGH);\nfloat distancia = duracao * 0.034 / 2;\n\n// Verifica se as leituras s\u00e3o v\u00e1lidas\nif (isnan(temperatura) || isnan(umidade)) {\n    Serial.println(\"Falha na leitura do sensor DHT!\");\n    return;\n}\n\n// Exibe os dados no display OLED\ndisplay.clearDisplay();\ndisplay.setCursor(0,0);\ndisplay.print(\"Temp: \");\ndisplay.print(temperatura);\ndisplay.println(\" C\");\n\ndisplay.print(\"Umid: \");\ndisplay.print(umidade);\ndisplay.println(\" %\");\n\ndisplay.print(\"Dist: \");\ndisplay.print(distancia);\ndisplay.println(\" cm\");\n\ndisplay.display();\n\nSerial.print(\"Temperatura: \");\nSerial.print(temperatura);\nSerial.print(\" *C\\tUmidade: \");\nSerial.print(umidade);\nSerial.print(\" %\\tDistancia: \");\nSerial.print(distancia);\nSerial.println(\" cm\");\n\ndelay(2000);\n</code></pre> <p>} \u02dc\u02dc\u02dc</p> <p>Explica\u00e7\u00e3o:</p> <ul> <li>M\u00faltiplos Sensores: Integra um sensor de temperatura e umidade (DHT22) e um sensor de dist\u00e2ncia ultrass\u00f4nico.</li> <li>Display OLED: Exibe as leituras dos sensores em tempo real.</li> <li>Monitoramento Ambiental: Permite visualizar as condi\u00e7\u00f5es ambientais de forma clara e organizada.</li> </ul>","text":""},{"location":"aulas/iot/modulos/modulo12.html#102-sistema-de-alarme-de-incendio-com-sensor-de-gas-e-sirene","title":"10.2 Sistema de Alarme de Inc\u00eandio com Sensor de G\u00e1s e Sirene","text":"<p>\u02dc\u02dc\u02dccpp const int pinoGas = A0; const int pinoLED = 13; const int pinoSirene = 12; const int limiarGas = 300; // Valor de exemplo</p> <p>void setup() {     Serial.begin(9600);     pinMode(pinoLED, OUTPUT);     pinMode(pinoSirene, OUTPUT); }</p> <p>void loop() {     int valorGas = analogRead(pinoGas);     Serial.print(\"N\u00edvel de G\u00e1s: \");     Serial.println(valorGas);</p> <pre><code>if (valorGas &gt; limiarGas) {\n    digitalWrite(pinoLED, HIGH);\n    digitalWrite(pinoSirene, HIGH);\n    Serial.println(\"Alerta! Inc\u00eandio detectado!\");\n} else {\n    digitalWrite(pinoLED, LOW);\n    digitalWrite(pinoSirene, LOW);\n}\ndelay(1000);\n</code></pre> <p>} \u02dc\u02dc\u02dc</p> <p>Explica\u00e7\u00e3o:</p> <ul> <li>Sensor de G\u00e1s: Detecta a presen\u00e7a de gases inflam\u00e1veis.</li> <li>Atua\u00e7\u00e3o do Alarme: Aciona um LED e uma sirene quando n\u00edveis perigosos de g\u00e1s s\u00e3o detectados.</li> <li>Seguran\u00e7a: Proporciona uma resposta r\u00e1pida em caso de detec\u00e7\u00e3o de inc\u00eandio.</li> </ul>"},{"location":"aulas/iot/modulos/modulo12.html#103-interface-de-sensores-com-comunicacao-serial-e-parsing-de-dados","title":"10.3 Interface de Sensores com Comunica\u00e7\u00e3o Serial e Parsing de Dados","text":"<p>\u02dc\u02dc\u02dccpp</p>"},{"location":"aulas/iot/modulos/modulo12.html#include_6","title":"include  <p>const int pinoTemperatura = A0; const int pinoUmidade = A1; const int pinoDistancia = A2;</p> <p>void setup() {     Serial.begin(9600);     Serial.println(\"Sistema de Monitoramento Iniciado.\"); }</p> <p>void loop() {     // Leitura dos sensores     float temperatura = analogRead(pinoTemperatura) * (5.0 / 1023.0) * 100; // Exemplo de convers\u00e3o     float umidade = analogRead(pinoUmidade) * (5.0 / 1023.0) * 100; // Exemplo de convers\u00e3o     float distancia = analogRead(pinoDistancia) * (5.0 / 1023.0) * 200; // Exemplo de convers\u00e3o</p> <pre><code>// Cria um documento JSON\nStaticJsonDocument&lt;200&gt; doc;\ndoc[\"temperatura\"] = temperatura;\ndoc[\"umidade\"] = umidade;\ndoc[\"distancia\"] = distancia;\n\n// Serializa o JSON\nString output;\nserializeJson(doc, output);\nSerial.println(output);\n\ndelay(1000);\n</code></pre> <p>} \u02dc\u02dc\u02dc</p> <p>Explica\u00e7\u00e3o:</p> <ul> <li>Formato JSON: Estrutura os dados dos sensores em formato JSON para facilitar o parsing e a integra\u00e7\u00e3o com outros sistemas.</li> <li>ArduinoJson: Utiliza a biblioteca <code>ArduinoJson</code> para criar e serializar o documento JSON.</li> <li>Comunica\u00e7\u00e3o Eficiente: Facilita a transfer\u00eancia de dados para sistemas externos, como computadores ou servidores.</li> </ul>","text":""},{"location":"aulas/iot/modulos/modulo12.html#9-conceitos-importantes","title":"9. Conceitos Importantes","text":""},{"location":"aulas/iot/modulos/modulo12.html#91-calibracao-de-sensores","title":"9.1 Calibra\u00e7\u00e3o de Sensores","text":"<ul> <li>Defini\u00e7\u00e3o: Processo de ajustar os sensores para garantir que as leituras sejam precisas e consistentes.</li> <li>M\u00e9todos:</li> <li>Calibra\u00e7\u00e3o em Ambiente Controlado: Comparar as leituras do sensor com instrumentos de refer\u00eancia.</li> <li>Ajustes de Offset e Escala: Modificar os valores lidos para corresponder aos valores reais.</li> </ul>"},{"location":"aulas/iot/modulos/modulo12.html#92-uso-de-variaveis-volateis","title":"9.2 Uso de Vari\u00e1veis Vol\u00e1teis","text":"<ul> <li>Defini\u00e7\u00e3o: Vari\u00e1veis que podem ser modificadas por ISRs ou diferentes threads de execu\u00e7\u00e3o.</li> <li>Import\u00e2ncia: Garantem que o compilador n\u00e3o otimize ou ignore as atualiza\u00e7\u00f5es feitas em ISRs.</li> <li>Exemplo: <pre><code>volatile int contador = 0;\n</code></pre></li> </ul>"},{"location":"aulas/iot/modulos/modulo12.html#93-tecnicas-de-filtragem-de-dados","title":"9.3 T\u00e9cnicas de Filtragem de Dados","text":"<ul> <li>M\u00e9dia M\u00f3vel: Calcula a m\u00e9dia de um conjunto de leituras para suavizar flutua\u00e7\u00f5es.</li> <li>Filtro de Kalman: T\u00e9cnica avan\u00e7ada para estimar o estado de um sistema a partir de medi\u00e7\u00f5es ruidosas.</li> <li>Desvio Padr\u00e3o: Identifica e remove outliers das leituras.</li> </ul>"},{"location":"aulas/iot/modulos/modulo12.html#94-gerenciamento-de-energia","title":"9.4 Gerenciamento de Energia","text":"<ul> <li>Import\u00e2ncia: Sensores e m\u00f3dulos adicionais podem aumentar significativamente o consumo de energia do sistema.</li> <li>Boas Pr\u00e1ticas:</li> <li>Desligar Sensores Quando N\u00e3o Est\u00e3o em Uso: Economiza energia prolongando a vida \u00fatil da bateria.</li> <li>Utilizar Modos de Baixo Consumo: Aproveitar os modos de economia de energia do Arduino.</li> <li>Escolher Sensores Eficientes: Optar por sensores com baixo consumo de energia quando apropriado.</li> </ul>"},{"location":"aulas/iot/modulos/modulo12.html#95-boas-praticas-na-aquisicao-de-dados","title":"9.5 Boas Pr\u00e1ticas na Aquisi\u00e7\u00e3o de Dados","text":"<ul> <li>Consist\u00eancia nas Leituras: Realizar leituras em intervalos regulares para garantir dados consistentes.</li> <li>Valida\u00e7\u00e3o das Leituras: Verificar se os dados lidos s\u00e3o v\u00e1lidos antes de process\u00e1-los.</li> <li>Organiza\u00e7\u00e3o dos Dados: Utilizar estruturas de dados adequadas para armazenar e processar informa\u00e7\u00f5es.</li> <li>Seguran\u00e7a e Prote\u00e7\u00e3o: Proteger os circuitos contra sobrecargas, interfer\u00eancias e ru\u00eddos el\u00e9tricos.</li> </ul>"},{"location":"aulas/iot/modulos/modulo12.html#10-recursos-adicionais","title":"10. Recursos Adicionais","text":"<ul> <li> <p>Documenta\u00e7\u00e3o Oficial do Arduino:</p> </li> <li> <p>Arduino Sensor Libraries</p> </li> <li>ArduinoJson Library</li> <li> <p>LiquidCrystal Library</p> </li> <li> <p>Tutoriais e Guias:</p> </li> <li> <p>Interfacing Sensors with Arduino</p> </li> <li>Data Acquisition with Arduino</li> <li> <p>Using Arduino with JSON</p> </li> <li> <p>V\u00eddeos Educacionais:</p> </li> <li> <p>Arduino Sensor Integration Tutorial</p> </li> <li>Data Filtering Techniques with Arduino</li> <li>Energy Management in Arduino Projects</li> </ul>"},{"location":"aulas/iot/modulos/modulo12.html#11-conclusao-do-modulo","title":"11. Conclus\u00e3o do M\u00f3dulo","text":"<p>Neste m\u00f3dulo, voc\u00ea aprendeu:</p> <ul> <li>Os diferentes tipos de sensores dispon\u00edveis para Arduino e suas aplica\u00e7\u00f5es.</li> <li>Como conectar e configurar sensores anal\u00f3gicos e digitais com o Arduino.</li> <li>T\u00e9cnicas de leitura e interpreta\u00e7\u00e3o de dados de sensores.</li> <li>Utiliza\u00e7\u00e3o de bibliotecas espec\u00edficas para facilitar a comunica\u00e7\u00e3o com sensores complexos.</li> <li>M\u00e9todos de processamento e filtragem de dados para obter informa\u00e7\u00f5es precisas e \u00fateis.</li> <li>Integra\u00e7\u00e3o de sensores com componentes adicionais, como displays OLED e m\u00f3dulos de comunica\u00e7\u00e3o.</li> <li>Praticou com exemplos e exerc\u00edcios que refor\u00e7am o entendimento dos conceitos de sensores e aquisi\u00e7\u00e3o de dados.</li> </ul> <p>Voc\u00ea completou todos os m\u00f3dulos do curso \"Programa\u00e7\u00e3o em Arduino: Conceitos Fundamentais sem Hardware\". Parab\u00e9ns pelo empenho e dedica\u00e7\u00e3o!</p>"},{"location":"aulas/iot/modulos/modulo12.html#12-proximos-passos","title":"12. Pr\u00f3ximos Passos","text":"<ul> <li>Revisar todo o conte\u00fado do curso para consolidar o aprendizado.</li> <li>Explorar projetos avan\u00e7ados que combinam m\u00faltiplos conceitos aprendidos.</li> <li>Participar de comunidades e f\u00f3runs de Arduino para trocar experi\u00eancias e obter suporte cont\u00ednuo.</li> <li>Considerar cursos avan\u00e7ados ou especializa\u00e7\u00f5es em \u00e1reas espec\u00edficas de interesse, como rob\u00f3tica, IoT ou automa\u00e7\u00e3o industrial.</li> </ul> <p>Se tiver d\u00favidas ou precisar de assist\u00eancia, continue participando de comunidades de aprendizagem ou consulte os recursos adicionais fornecidos ao longo dos m\u00f3dulos.</p> <p>Parab\u00e9ns por concluir o curso! Continue explorando e criando projetos incr\u00edveis com Arduino!</p>"},{"location":"aulas/iot/modulos/modulo13.html","title":"M\u00f3dulo 13: Internet das Coisas (IoT) com Arduino","text":"<p>Bem-vindo ao M\u00f3dulo 13 do curso \"Programa\u00e7\u00e3o em Arduino: Conceitos Fundamentais sem Hardware\". Neste m\u00f3dulo, voc\u00ea ir\u00e1 explorar a Internet das Coisas (IoT) com o Arduino, aprendendo a conectar seus projetos \u00e0 internet para coletar, enviar e visualizar dados em tempo real. A integra\u00e7\u00e3o com a IoT amplia significativamente as possibilidades dos seus projetos, permitindo monitoramento remoto, automa\u00e7\u00e3o e intera\u00e7\u00e3o com outros dispositivos e servi\u00e7os online.</p>"},{"location":"aulas/iot/modulos/modulo13.html#objetivos-do-modulo","title":"Objetivos do M\u00f3dulo","text":"<ul> <li>Compreender os conceitos b\u00e1sicos de Internet das Coisas (IoT).</li> <li>Aprender a conectar o Arduino \u00e0 internet utilizando m\u00f3dulos Wi-Fi (ESP8266, ESP32) e Ethernet.</li> <li>Implementar comunica\u00e7\u00e3o com servi\u00e7os de nuvem para armazenamento e visualiza\u00e7\u00e3o de dados.</li> <li>Utilizar protocolos de comunica\u00e7\u00e3o como HTTP e MQTT para troca de informa\u00e7\u00f5es.</li> <li>Desenvolver projetos que integrem sensores, atuadores e comunica\u00e7\u00e3o com a internet.</li> <li>Resolver exerc\u00edcios pr\u00e1ticos para consolidar o conhecimento sobre IoT com Arduino.</li> </ul>"},{"location":"aulas/iot/modulos/modulo13.html#1-introducao-a-internet-das-coisas-iot","title":"1. Introdu\u00e7\u00e3o \u00e0 Internet das Coisas (IoT)","text":""},{"location":"aulas/iot/modulos/modulo13.html#11-o-que-e-iot","title":"1.1 O que \u00e9 IoT?","text":"<p>Internet das Coisas (IoT) refere-se \u00e0 interconex\u00e3o de dispositivos f\u00edsicos atrav\u00e9s da internet, permitindo que eles coletem e compartilhem dados. Com o Arduino, voc\u00ea pode criar dispositivos inteligentes que interagem com o ambiente e com outros dispositivos de forma aut\u00f4noma.</p>"},{"location":"aulas/iot/modulos/modulo13.html#12-importancia-da-iot","title":"1.2 Import\u00e2ncia da IoT","text":"<ul> <li>Monitoramento Remoto: Permite acompanhar o estado de dispositivos e sensores de qualquer lugar.</li> <li>Automa\u00e7\u00e3o: Facilita a cria\u00e7\u00e3o de sistemas automatizados que respondem a eventos sem interven\u00e7\u00e3o humana.</li> <li>Coleta de Dados: Gera grandes volumes de dados que podem ser analisados para tomar decis\u00f5es informadas.</li> <li>Interconectividade: Integra diferentes dispositivos e servi\u00e7os, ampliando as funcionalidades dos projetos.</li> </ul>"},{"location":"aulas/iot/modulos/modulo13.html#13-componentes-basicos-de-um-sistema-iot","title":"1.3 Componentes B\u00e1sicos de um Sistema IoT","text":"<ul> <li>Dispositivo: Arduino ou microcontrolador com conectividade \u00e0 internet.</li> <li>Sensores e Atuadores: Para coletar dados e interagir com o ambiente.</li> <li>Conex\u00e3o de Rede: Wi-Fi, Ethernet, LoRa, etc.</li> <li>Servi\u00e7os de Nuvem: Para armazenamento, processamento e visualiza\u00e7\u00e3o de dados.</li> <li>Interface de Usu\u00e1rio: Aplicativos m\u00f3veis, dashboards web, etc.</li> </ul>"},{"location":"aulas/iot/modulos/modulo13.html#2-conectando-o-arduino-a-internet","title":"2. Conectando o Arduino \u00e0 Internet","text":""},{"location":"aulas/iot/modulos/modulo13.html#21-modulos-de-conectividade","title":"2.1 M\u00f3dulos de Conectividade","text":"<ul> <li>ESP8266: M\u00f3dulo Wi-Fi de baixo custo, ideal para projetos IoT simples.</li> <li>ESP32: Vers\u00e3o avan\u00e7ada do ESP8266, com Bluetooth, mais GPIOs e maior desempenho.</li> <li>Ethernet Shield: Permite conex\u00e3o via cabo Ethernet, \u00fatil para ambientes com conex\u00e3o est\u00e1vel.</li> </ul>"},{"location":"aulas/iot/modulos/modulo13.html#22-configuracao-do-esp8266-com-arduino","title":"2.2 Configura\u00e7\u00e3o do ESP8266 com Arduino","text":"<p>Componentes Necess\u00e1rios:</p> <ul> <li>Arduino Uno</li> <li>M\u00f3dulo ESP8266</li> <li>Adaptador de n\u00edvel l\u00f3gico (opcional)</li> <li>Cabos de conex\u00e3o</li> <li>Fonte de alimenta\u00e7\u00e3o adequada</li> </ul> <p>Conex\u00e3o:</p> <ol> <li>VCC do ESP8266: Conectado ao 3.3V do Arduino.</li> <li>GND do ESP8266: Conectado ao GND do Arduino.</li> <li>TX do ESP8266: Conectado ao RX do Arduino (pino 0).</li> <li>RX do ESP8266: Conectado ao TX do Arduino (pino 1) atrav\u00e9s de um divisor de tens\u00e3o ou adaptador de n\u00edvel l\u00f3gico.</li> <li>CH_PD do ESP8266: Conectado ao 3.3V para ativar o m\u00f3dulo.</li> </ol>"},{"location":"aulas/iot/modulos/modulo13.html#23-exemplo-de-codigo-para-conexao-wi-fi-com-esp8266","title":"2.3 Exemplo de C\u00f3digo para Conex\u00e3o Wi-Fi com ESP8266","text":"<pre><code>#include &lt;SoftwareSerial.h&gt;\n\nSoftwareSerial esp8266(2, 3); // RX, TX\n\nconst char* ssid = \"Seu_SSID\";\nconst char* password = \"Sua_Senha\";\n\nvoid setup() {\n    Serial.begin(9600);\n    esp8266.begin(115200);\n\n    delay(1000);\n    Serial.println(\"Conectando ao Wi-Fi...\");\n    esp8266.println(\"AT+CWJAP=\\\"\" + String(ssid) + \"\\\",\\\"\" + String(password) + \"\\\"\");\n}\n\nvoid loop() {\n    if (esp8266.available()) {\n        Serial.write(esp8266.read());\n    }\n\n    if (Serial.available()) {\n        esp8266.write(Serial.read());\n    }\n}\n</code></pre> <p>Explica\u00e7\u00e3o:</p> <ul> <li>SoftwareSerial: Cria uma porta serial adicional para comunica\u00e7\u00e3o com o ESP8266.</li> <li>Conex\u00e3o Wi-Fi: Envia o comando AT para conectar o m\u00f3dulo ESP8266 \u00e0 rede Wi-Fi especificada.</li> <li>Monitoramento: Permite monitorar a comunica\u00e7\u00e3o entre o Arduino e o ESP8266 atrav\u00e9s do Monitor Serial.</li> </ul>"},{"location":"aulas/iot/modulos/modulo13.html#3-comunicacao-com-servicos-de-nuvem","title":"3. Comunica\u00e7\u00e3o com Servi\u00e7os de Nuvem","text":""},{"location":"aulas/iot/modulos/modulo13.html#31-utilizando-o-thingspeak","title":"3.1 Utilizando o ThingSpeak","text":"<p>ThingSpeak \u00e9 uma plataforma IoT que permite coletar, armazenar e visualizar dados de sensores.</p> <p>Passos para Utilizar o ThingSpeak:</p> <ol> <li>Criar uma Conta: Acesse ThingSpeak e crie uma conta gratuita.</li> <li>Criar um Canal: Adicione um novo canal para armazenar os dados do seu projeto.</li> <li>Obter a API Key: Cada canal possui uma chave de API para autentica\u00e7\u00e3o.</li> </ol>"},{"location":"aulas/iot/modulos/modulo13.html#32-exemplo-de-envio-de-dados-para-o-thingspeak","title":"3.2 Exemplo de Envio de Dados para o ThingSpeak","text":"<pre><code>#include &lt;ESP8266WiFi.h&gt;\n\nconst char* ssid = \"Seu_SSID\";\nconst char* password = \"Sua_Senha\";\nconst char* host = \"api.thingspeak.com\";\nconst char* writeAPIKey = \"SUA_API_KEY\";\n\nvoid setup() {\n    Serial.begin(115200);\n    delay(10);\n\n    // Conectando ao Wi-Fi\n    WiFi.begin(ssid, password);\n    Serial.println();\n    Serial.println(\"Conectando ao Wi-Fi...\");\n\n    while (WiFi.status() != WL_CONNECTED) {\n        delay(500);\n        Serial.print(\".\");\n    }\n\n    Serial.println(\"\");\n    Serial.println(\"Wi-Fi conectado.\");\n    Serial.println(\"Endere\u00e7o IP: \");\n    Serial.println(WiFi.localIP());\n}\n\nvoid loop() {\n    WiFiClient client;\n    const int httpPort = 80;\n\n    if (!client.connect(host, httpPort)) {\n        Serial.println(\"Falha na conex\u00e3o\");\n        return;\n    }\n\n    // Simula\u00e7\u00e3o de leitura de sensor\n    float temperatura = 25.5;\n\n    // Criando a requisi\u00e7\u00e3o HTTP\n    String url = \"/update?api_key=\" + String(writeAPIKey) + \"&amp;field1=\" + String(temperatura);\n\n    Serial.print(\"Requisi\u00e7\u00e3o: \");\n    Serial.println(url);\n\n    client.print(String(\"GET \") + url + \" HTTP/1.1\\r\\n\" +\n                 \"Host: \" + host + \"\\r\\n\" + \n                 \"Connection: close\\r\\n\\r\\n\");\n    delay(20000); // Envia dados a cada 20 segundos\n}\n</code></pre> <p>Explica\u00e7\u00e3o:</p> <ul> <li>Conex\u00e3o Wi-Fi: Estabelece a conex\u00e3o com a rede Wi-Fi.</li> <li>Requisi\u00e7\u00e3o HTTP: Envia os dados de temperatura para o ThingSpeak utilizando uma requisi\u00e7\u00e3o GET.</li> <li>Atualiza\u00e7\u00e3o de Dados: O loop envia a temperatura simulada a cada 20 segundos.</li> </ul>"},{"location":"aulas/iot/modulos/modulo13.html#33-visualizando-dados-no-thingspeak","title":"3.3 Visualizando Dados no ThingSpeak","text":"<p>Ap\u00f3s enviar os dados, acesse o painel do seu canal no ThingSpeak para visualizar gr\u00e1ficos e estat\u00edsticas em tempo real.</p>"},{"location":"aulas/iot/modulos/modulo13.html#4-utilizando-o-mqtt-para-comunicacao-iot","title":"4. Utilizando o MQTT para Comunica\u00e7\u00e3o IoT","text":""},{"location":"aulas/iot/modulos/modulo13.html#41-o-que-e-mqtt","title":"4.1 O que \u00e9 MQTT?","text":"<p>MQTT (Message Queuing Telemetry Transport) \u00e9 um protocolo de mensagem leve, ideal para aplica\u00e7\u00f5es IoT devido \u00e0 sua efici\u00eancia e baixo consumo de largura de banda.</p>"},{"location":"aulas/iot/modulos/modulo13.html#42-configuracao-do-mqtt-com-arduino","title":"4.2 Configura\u00e7\u00e3o do MQTT com Arduino","text":"<p>Componentes Necess\u00e1rios:</p> <ul> <li>Arduino com conectividade \u00e0 internet (ESP8266, ESP32)</li> <li>Servidor MQTT (pode ser um broker p\u00fablico ou configurado localmente)</li> <li>Biblioteca MQTT para Arduino (PubSubClient)</li> </ul>"},{"location":"aulas/iot/modulos/modulo13.html#43-exemplo-de-codigo-para-publicar-dados-no-mqtt","title":"4.3 Exemplo de C\u00f3digo para Publicar Dados no MQTT","text":"<pre><code>#include &lt;ESP8266WiFi.h&gt;\n#include &lt;PubSubClient.h&gt;\n\n// Configura\u00e7\u00f5es de rede\nconst char* ssid = \"Seu_SSID\";\nconst char* password = \"Sua_Senha\";\n\n// Configura\u00e7\u00f5es do MQTT\nconst char* mqtt_server = \"broker.hivemq.com\";\n\nWiFiClient espClient;\nPubSubClient client(espClient);\n\nvoid setup_wifi() {\n    delay(10);\n    Serial.println();\n    Serial.print(\"Conectando ao Wi-Fi \");\n    Serial.println(ssid);\n\n    WiFi.begin(ssid, password);\n\n    while (WiFi.status() != WL_CONNECTED) {\n        delay(500);\n        Serial.print(\".\");\n    }\n\n    Serial.println(\"\");\n    Serial.println(\"Wi-Fi conectado\");\n    Serial.println(\"Endere\u00e7o IP: \");\n    Serial.println(WiFi.localIP());\n}\n\nvoid reconnect() {\n    // Loop at\u00e9 reconectar\n    while (!client.connected()) {\n        Serial.print(\"Tentando conex\u00e3o MQTT...\");\n        if (client.connect(\"ArduinoClient\")) {\n            Serial.println(\"conectado\");\n        } else {\n            Serial.print(\"falhou, rc=\");\n            Serial.print(client.state());\n            Serial.println(\" tentando novamente em 5 segundos\");\n            delay(5000);\n        }\n    }\n}\n\nvoid setup() {\n    Serial.begin(115200);\n    setup_wifi();\n    client.setServer(mqtt_server, 1883);\n}\n\nvoid loop() {\n    if (!client.connected()) {\n        reconnect();\n    }\n    client.loop();\n\n    // Simula\u00e7\u00e3o de leitura de sensor\n    float temperatura = 26.3;\n    char msg[50];\n    snprintf(msg, 50, \"Temperatura: %.2f\", temperatura);\n\n    // Publica no t\u00f3pico \"arduino/temperatura\"\n    client.publish(\"arduino/temperatura\", msg);\n    Serial.println(\"Mensagem publicada\");\n\n    delay(10000); // Envia dados a cada 10 segundos\n}\n</code></pre> <p>Explica\u00e7\u00e3o:</p> <ul> <li>Biblioteca PubSubClient: Facilita a implementa\u00e7\u00e3o do protocolo MQTT no Arduino.</li> <li>Conex\u00e3o MQTT: Estabelece a conex\u00e3o com o broker MQTT especificado.</li> <li>Publica\u00e7\u00e3o de Mensagens: Envia mensagens de temperatura para o t\u00f3pico \"arduino/temperatura\" a cada 10 segundos.</li> </ul>"},{"location":"aulas/iot/modulos/modulo13.html#44-subscricao-a-topicos-mqtt","title":"4.4 Subscri\u00e7\u00e3o a T\u00f3picos MQTT","text":"<p>Al\u00e9m de publicar, o Arduino pode subscrever a t\u00f3picos para receber mensagens.</p> <pre><code>#include &lt;ESP8266WiFi.h&gt;\n#include &lt;PubSubClient.h&gt;\n\n// Configura\u00e7\u00f5es de rede\nconst char* ssid = \"Seu_SSID\";\nconst char* password = \"Sua_Senha\";\n\n// Configura\u00e7\u00f5es do MQTT\nconst char* mqtt_server = \"broker.hivemq.com\";\n\nWiFiClient espClient;\nPubSubClient client(espClient);\n\n// Callback quando uma mensagem \u00e9 recebida\nvoid callback(char* topic, byte* payload, unsigned int length) {\n    Serial.print(\"Mensagem recebida no t\u00f3pico: \");\n    Serial.println(topic);\n    Serial.print(\"Conte\u00fado: \");\n    for (int i = 0; i &lt; length; i++) {\n        Serial.print((char)payload[i]);\n    }\n    Serial.println();\n}\n\nvoid setup_wifi() {\n    delay(10);\n    Serial.println();\n    Serial.print(\"Conectando ao Wi-Fi \");\n    Serial.println(ssid);\n\n    WiFi.begin(ssid, password);\n\n    while (WiFi.status() != WL_CONNECTED) {\n        delay(500);\n        Serial.print(\".\");\n    }\n\n    Serial.println(\"\");\n    Serial.println(\"Wi-Fi conectado\");\n    Serial.println(\"Endere\u00e7o IP: \");\n    Serial.println(WiFi.localIP());\n}\n\nvoid reconnect() {\n    // Loop at\u00e9 reconectar\n    while (!client.connected()) {\n        Serial.print(\"Tentando conex\u00e3o MQTT...\");\n        if (client.connect(\"ArduinoClient\")) {\n            Serial.println(\"conectado\");\n            client.subscribe(\"arduino/comando\");\n        } else {\n            Serial.print(\"falhou, rc=\");\n            Serial.print(client.state());\n            Serial.println(\" tentando novamente em 5 segundos\");\n            delay(5000);\n        }\n    }\n}\n\nvoid setup() {\n    Serial.begin(115200);\n    setup_wifi();\n    client.setServer(mqtt_server, 1883);\n    client.setCallback(callback);\n}\n\nvoid loop() {\n    if (!client.connected()) {\n        reconnect();\n    }\n    client.loop();\n}\n</code></pre> <p>Explica\u00e7\u00e3o:</p> <ul> <li>Callback: Fun\u00e7\u00e3o chamada sempre que uma mensagem \u00e9 recebida no t\u00f3pico subscrito.</li> <li>Subscri\u00e7\u00e3o: Subscrive ao t\u00f3pico \"arduino/comando\" para receber comandos.</li> <li>Processamento de Mensagens: Exibe as mensagens recebidas no Monitor Serial.</li> </ul>"},{"location":"aulas/iot/modulos/modulo13.html#5-desenvolvimento-de-projetos-iot-com-arduino","title":"5. Desenvolvimento de Projetos IoT com Arduino","text":""},{"location":"aulas/iot/modulos/modulo13.html#51-sistema-de-monitoramento-de-ambiente-com-notificacoes","title":"5.1 Sistema de Monitoramento de Ambiente com Notifica\u00e7\u00f5es","text":"<p>Desenvolva um sistema que monitora temperatura e umidade, envia os dados para a nuvem e recebe notifica\u00e7\u00f5es quando os valores excedem determinados limiares.</p>"},{"location":"aulas/iot/modulos/modulo13.html#52-automacao-residencial","title":"5.2 Automa\u00e7\u00e3o Residencial","text":"<p>Crie um sistema de automa\u00e7\u00e3o para controlar luzes, ventiladores e outros dispositivos eletr\u00f4nicos atrav\u00e9s de comandos enviados pela internet ou aplicativos m\u00f3veis.</p>"},{"location":"aulas/iot/modulos/modulo13.html#53-integracao-com-assistentes-virtuais","title":"5.3 Integra\u00e7\u00e3o com Assistentes Virtuais","text":"<p>Integre o Arduino com assistentes virtuais como Alexa ou Google Assistant para controlar dispositivos por voz.</p>"},{"location":"aulas/iot/modulos/modulo13.html#6-conceitos-importantes","title":"6. Conceitos Importantes","text":""},{"location":"aulas/iot/modulos/modulo13.html#61-seguranca-na-iot","title":"6.1 Seguran\u00e7a na IoT","text":"<ul> <li>Autentica\u00e7\u00e3o e Autoriza\u00e7\u00e3o: Garantir que apenas dispositivos e usu\u00e1rios autorizados possam acessar os dados.</li> <li>Criptografia: Proteger os dados transmitidos para evitar intercepta\u00e7\u00f5es.</li> <li>Atualiza\u00e7\u00f5es de Firmware: Manter o software do Arduino e dos m\u00f3dulos de conectividade atualizado para corrigir vulnerabilidades.</li> </ul>"},{"location":"aulas/iot/modulos/modulo13.html#62-gerenciamento-de-energia","title":"6.2 Gerenciamento de Energia","text":"<ul> <li>Efici\u00eancia Energ\u00e9tica: Otimize o consumo de energia dos dispositivos conectados.</li> <li>Alimenta\u00e7\u00e3o de Baixo Consumo: Utilize modos de baixo consumo quando os dispositivos n\u00e3o estiverem ativos.</li> <li>Fontes de Energia Adequadas: Escolha fontes que atendam \u00e0s necessidades de energia dos dispositivos IoT.</li> </ul>"},{"location":"aulas/iot/modulos/modulo13.html#63-protocolos-de-comunicacao","title":"6.3 Protocolos de Comunica\u00e7\u00e3o","text":"<ul> <li>HTTP/HTTPS: Utilizados para comunica\u00e7\u00e3o web padr\u00e3o.</li> <li>MQTT: Ideal para aplica\u00e7\u00f5es que requerem comunica\u00e7\u00e3o leve e eficiente.</li> <li>WebSockets: Permite comunica\u00e7\u00e3o bidirecional em tempo real.</li> <li>CoAP: Protocolo de aplica\u00e7\u00e3o otimizado para dispositivos com recursos limitados.</li> </ul>"},{"location":"aulas/iot/modulos/modulo13.html#64-armazenamento-e-processamento-de-dados","title":"6.4 Armazenamento e Processamento de Dados","text":"<ul> <li>Servi\u00e7os de Nuvem: ThingSpeak, Adafruit IO, AWS IoT, Google Cloud IoT.</li> <li>Banco de Dados: Armazenar grandes volumes de dados para an\u00e1lise e visualiza\u00e7\u00e3o.</li> <li>An\u00e1lise de Dados: Utilizar ferramentas para interpretar os dados coletados e obter insights.</li> </ul>"},{"location":"aulas/iot/modulos/modulo13.html#65-boas-praticas-na-iot","title":"6.5 Boas Pr\u00e1ticas na IoT","text":"<ul> <li>Modularidade: Desenvolva sistemas modulares para facilitar atualiza\u00e7\u00f5es e manuten\u00e7\u00f5es.</li> <li>Escalabilidade: Planeje sistemas que possam ser facilmente escalados para incluir mais dispositivos.</li> <li>Resili\u00eancia: Assegure que o sistema continue operando mesmo em caso de falhas de alguns componentes.</li> <li>Documenta\u00e7\u00e3o: Mantenha uma documenta\u00e7\u00e3o detalhada dos projetos para facilitar futuras modifica\u00e7\u00f5es e integra\u00e7\u00f5es.</li> </ul>"},{"location":"aulas/iot/modulos/modulo13.html#7-recursos-adicionais","title":"7. Recursos Adicionais","text":"<ul> <li> <p>Documenta\u00e7\u00e3o Oficial do Arduino:</p> </li> <li> <p>ESP8266WiFi Library</p> </li> <li>PubSubClient Library</li> <li> <p>ArduinoJson Library</p> </li> <li> <p>Tutoriais e Guias:</p> </li> <li> <p>Introdu\u00e7\u00e3o \u00e0 IoT com Arduino</p> </li> <li>Utilizando MQTT com Arduino</li> <li> <p>Integra\u00e7\u00e3o do Arduino com Servi\u00e7os de Nuvem</p> </li> <li> <p>V\u00eddeos Educacionais:</p> </li> <li> <p>Arduino IoT Tutorial</p> </li> <li>Configurando MQTT com Arduino</li> <li>Projetos IoT com Arduino</li> </ul>"},{"location":"aulas/iot/modulos/modulo13.html#8-exemplos-praticos","title":"8. Exemplos Pr\u00e1ticos","text":""},{"location":"aulas/iot/modulos/modulo13.html#81-monitoramento-de-temperatura-e-umidade-com-notificacoes-via-mqtt","title":"8.1 Monitoramento de Temperatura e Umidade com Notifica\u00e7\u00f5es via MQTT","text":"<pre><code>#include &lt;ESP8266WiFi.h&gt;\n#include &lt;PubSubClient.h&gt;\n#include \"DHT.h\"\n\n// Configura\u00e7\u00f5es de rede\nconst char* ssid = \"Seu_SSID\";\nconst char* password = \"Sua_Senha\";\n\n// Configura\u00e7\u00f5es do MQTT\nconst char* mqtt_server = \"broker.hivemq.com\";\n\nWiFiClient espClient;\nPubSubClient client(espClient);\n\n// Configura\u00e7\u00f5es do DHT\n#define DHTPIN 2\n#define DHTTYPE DHT22\nDHT dht(DHTPIN, DHTTYPE);\n\n// Limiar para notifica\u00e7\u00f5es\nconst float limiarTemperatura = 30.0;\nconst float limiarUmidade = 70.0;\n\nvoid setup_wifi() {\n    delay(10);\n    Serial.println();\n    Serial.print(\"Conectando ao Wi-Fi \");\n    Serial.println(ssid);\n\n    WiFi.begin(ssid, password);\n\n    while (WiFi.status() != WL_CONNECTED) {\n        delay(500);\n        Serial.print(\".\");\n    }\n\n    Serial.println(\"\");\n    Serial.println(\"Wi-Fi conectado\");\n    Serial.println(\"Endere\u00e7o IP: \");\n    Serial.println(WiFi.localIP());\n}\n\nvoid callback(char* topic, byte* payload, unsigned int length) {\n    // Callback para mensagens recebidas (n\u00e3o utilizado neste exemplo)\n}\n\nvoid reconnect() {\n    while (!client.connected()) {\n        Serial.print(\"Tentando conex\u00e3o MQTT...\");\n        if (client.connect(\"ArduinoClient\")) {\n            Serial.println(\"conectado\");\n        } else {\n            Serial.print(\"Falhou, rc=\");\n            Serial.print(client.state());\n            Serial.println(\" tentando novamente em 5 segundos\");\n            delay(5000);\n        }\n    }\n}\n\nvoid setup() {\n    Serial.begin(115200);\n    setup_wifi();\n    client.setServer(mqtt_server, 1883);\n    client.setCallback(callback);\n    dht.begin();\n}\n\nvoid loop() {\n    if (!client.connected()) {\n        reconnect();\n    }\n    client.loop();\n\n    // Leitura dos sensores\n    float temperatura = dht.readTemperature();\n    float umidade = dht.readHumidity();\n\n    if (isnan(temperatura) || isnan(umidade)) {\n        Serial.println(\"Falha na leitura do sensor DHT!\");\n        return;\n    }\n\n    // Publica os dados\n    char msg[50];\n    snprintf(msg, 50, \"Temperatura: %.2f, Umidade: %.2f\", temperatura, umidade);\n    client.publish(\"arduino/ambiente\", msg);\n    Serial.println(\"Dados publicados no MQTT\");\n\n    // Envia notifica\u00e7\u00f5es se os limiares forem excedidos\n    if (temperatura &gt; limiarTemperatura) {\n        client.publish(\"arduino/alertas\", \"Temperatura alta!\");\n        Serial.println(\"Alerta: Temperatura alta!\");\n    }\n\n    if (umidade &gt; limiarUmidade) {\n        client.publish(\"arduino/alertas\", \"Umidade alta!\");\n        Serial.println(\"Alerta: Umidade alta!\");\n    }\n\n    delay(10000); // Aguarda 10 segundos antes da pr\u00f3xima leitura\n}\n</code></pre> <p>Explica\u00e7\u00e3o:</p> <ul> <li>Leitura de Sensores: Obt\u00e9m os valores de temperatura e umidade do sensor DHT22.</li> <li>Publica\u00e7\u00e3o MQTT: Envia os dados para o t\u00f3pico \"arduino/ambiente\".</li> <li>Notifica\u00e7\u00f5es: Publica alertas nos t\u00f3picos \"arduino/alertas\" se os valores excederem os limiares definidos.</li> </ul>"},{"location":"aulas/iot/modulos/modulo13.html#82-sistema-de-controle-de-luz-inteligente-com-arduino-e-mqtt","title":"8.2 Sistema de Controle de Luz Inteligente com Arduino e MQTT","text":"<pre><code>#include &lt;ESP8266WiFi.h&gt;\n#include &lt;PubSubClient.h&gt;\n\n// Configura\u00e7\u00f5es de rede\nconst char* ssid = \"Seu_SSID\";\nconst char* password = \"Sua_Senha\";\n\n// Configura\u00e7\u00f5es do MQTT\nconst char* mqtt_server = \"broker.hivemq.com\";\n\nWiFiClient espClient;\nPubSubClient client(espClient);\n\n// Pino do LED\nconst int pinoLED = 5;\n\n// Fun\u00e7\u00e3o de callback para receber mensagens\nvoid callback(char* topic, byte* payload, unsigned int length) {\n    String mensagem;\n    for (unsigned int i = 0; i &lt; length; i++) {\n        mensagem += (char)payload[i];\n    }\n    Serial.print(\"Mensagem recebida no t\u00f3pico [\");\n    Serial.print(topic);\n    Serial.print(\"]: \");\n    Serial.println(mensagem);\n\n    if (mensagem == \"ON\") {\n        digitalWrite(pinoLED, HIGH);\n    } else if (mensagem == \"OFF\") {\n        digitalWrite(pinoLED, LOW);\n    }\n}\n\nvoid setup_wifi() {\n    delay(10);\n    Serial.println();\n    Serial.print(\"Conectando ao Wi-Fi \");\n    Serial.println(ssid);\n\n    WiFi.begin(ssid, password);\n\n    while (WiFi.status() != WL_CONNECTED) {\n        delay(500);\n        Serial.print(\".\");\n    }\n\n    Serial.println(\"\");\n    Serial.println(\"Wi-Fi conectado\");\n    Serial.println(\"Endere\u00e7o IP: \");\n    Serial.println(WiFi.localIP());\n}\n\nvoid reconnect() {\n    while (!client.connected()) {\n        Serial.print(\"Tentando conex\u00e3o MQTT...\");\n        if (client.connect(\"ArduinoClient\")) {\n            Serial.println(\"conectado\");\n            client.subscribe(\"arduino/luz\");\n        } else {\n            Serial.print(\"Falhou, rc=\");\n            Serial.print(client.state());\n            Serial.println(\" tentando novamente em 5 segundos\");\n            delay(5000);\n        }\n    }\n}\n\nvoid setup() {\n    pinMode(pinoLED, OUTPUT);\n    digitalWrite(pinoLED, LOW);\n    Serial.begin(115200);\n    setup_wifi();\n    client.setServer(mqtt_server, 1883);\n    client.setCallback(callback);\n}\n\nvoid loop() {\n    if (!client.connected()) {\n        reconnect();\n    }\n    client.loop();\n}\n</code></pre> <p>Explica\u00e7\u00e3o:</p> <ul> <li>Subscri\u00e7\u00e3o MQTT: Subscreve ao t\u00f3pico \"arduino/luz\" para receber comandos de controle.</li> <li>Controle de LED: Liga ou desliga o LED com base nas mensagens recebidas (\"ON\" ou \"OFF\").</li> <li>Interface de Controle: Pode ser controlado atrav\u00e9s de aplicativos MQTT ou dashboards web.</li> </ul>"},{"location":"aulas/iot/modulos/modulo13.html#83-sistema-de-irrigacao-automatica-com-sensores-e-mqtt","title":"8.3 Sistema de Irriga\u00e7\u00e3o Autom\u00e1tica com Sensores e MQTT","text":"<pre><code>#include &lt;ESP8266WiFi.h&gt;\n#include &lt;PubSubClient.h&gt;\n#include \"DHT.h\"\n\n// Configura\u00e7\u00f5es de rede\nconst char* ssid = \"Seu_SSID\";\nconst char* password = \"Sua_Senha\";\n\n// Configura\u00e7\u00f5es do MQTT\nconst char* mqtt_server = \"broker.hivemq.com\";\n\nWiFiClient espClient;\nPubSubClient client(espClient);\n\n// Configura\u00e7\u00f5es do DHT\n#define DHTPIN 2\n#define DHTTYPE DHT22\nDHT dht(DHTPIN, DHTTYPE);\n\n// Pino do rel\u00e9\nconst int pinoRele = 5;\n\n// Limiar de umidade para irriga\u00e7\u00e3o\nconst float limiarUmidade = 30.0;\n\nvoid setup_wifi() {\n    delay(10);\n    Serial.println();\n    Serial.print(\"Conectando ao Wi-Fi \");\n    Serial.println(ssid);\n\n    WiFi.begin(ssid, password);\n\n    while (WiFi.status() != WL_CONNECTED) {\n        delay(500);\n        Serial.print(\".\");\n    }\n\n    Serial.println(\"\");\n    Serial.println(\"Wi-Fi conectado\");\n    Serial.println(\"Endere\u00e7o IP: \");\n    Serial.println(WiFi.localIP());\n}\n\nvoid reconnect() {\n    while (!client.connected()) {\n        Serial.print(\"Tentando conex\u00e3o MQTT...\");\n        if (client.connect(\"ArduinoClient\")) {\n            Serial.println(\"conectado\");\n        } else {\n            Serial.print(\"Falhou, rc=\");\n            Serial.print(client.state());\n            Serial.println(\" tentando novamente em 5 segundos\");\n            delay(5000);\n        }\n    }\n}\n\nvoid setup() {\n    pinMode(pinoRele, OUTPUT);\n    digitalWrite(pinoRele, LOW);\n    Serial.begin(115200);\n    setup_wifi();\n    client.setServer(mqtt_server, 1883);\n    dht.begin();\n}\n\nvoid loop() {\n    if (!client.connected()) {\n        reconnect();\n    }\n    client.loop();\n\n    // Leitura do sensor DHT22\n    float umidade = dht.readHumidity();\n\n    if (isnan(umidade)) {\n        Serial.println(\"Falha na leitura do sensor DHT!\");\n        return;\n    }\n\n    Serial.print(\"Umidade do Solo: \");\n    Serial.println(umidade);\n\n    // Publica a umidade no MQTT\n    char msg[50];\n    snprintf(msg, 50, \"Umidade: %.2f\", umidade);\n    client.publish(\"arduino/irrigacao\", msg);\n\n    // Controle da irriga\u00e7\u00e3o\n    if (umidade &lt; limiarUmidade) {\n        digitalWrite(pinoRele, HIGH); // Liga a bomba\n        Serial.println(\"Bomba Ligada.\");\n    } else {\n        digitalWrite(pinoRele, LOW); // Desliga a bomba\n        Serial.println(\"Bomba Desligada.\");\n    }\n\n    delay(10000); // Aguarda 10 segundos antes da pr\u00f3xima leitura\n}\n</code></pre> <p>Explica\u00e7\u00e3o:</p> <ul> <li>Leitura de Umidade: Obt\u00e9m a umidade do solo utilizando o sensor DHT22.</li> <li>Publica\u00e7\u00e3o MQTT: Envia a umidade para o t\u00f3pico \"arduino/irrigacao\".</li> <li>Controle da Bomba: Liga a bomba de irriga\u00e7\u00e3o se a umidade estiver abaixo do limiar definido e desliga caso contr\u00e1rio.</li> <li>Automatiza\u00e7\u00e3o: Permite que o sistema realize irriga\u00e7\u00e3o autom\u00e1tica com base nas condi\u00e7\u00f5es do solo.</li> </ul>"},{"location":"aulas/iot/modulos/modulo13.html#9-conceitos-importantes","title":"9. Conceitos Importantes","text":""},{"location":"aulas/iot/modulos/modulo13.html#91-seguranca-na-iot","title":"9.1 Seguran\u00e7a na IoT","text":"<ul> <li>Autentica\u00e7\u00e3o e Autoriza\u00e7\u00e3o: Implementar mecanismos para garantir que apenas dispositivos e usu\u00e1rios autorizados possam acessar os dados e controlar os dispositivos.</li> <li>Criptografia de Dados: Utilizar protocolos seguros (como HTTPS) para proteger os dados transmitidos entre o Arduino e os servi\u00e7os de nuvem.</li> <li>Atualiza\u00e7\u00f5es de Firmware: Manter o firmware do Arduino e dos m\u00f3dulos de conectividade atualizado para corrigir vulnerabilidades e melhorar a seguran\u00e7a.</li> </ul>"},{"location":"aulas/iot/modulos/modulo13.html#92-gerenciamento-de-energia","title":"9.2 Gerenciamento de Energia","text":"<ul> <li>Efici\u00eancia Energ\u00e9tica: Projetar sistemas que utilizem menos energia, prolongando a vida \u00fatil de baterias em dispositivos port\u00e1teis.</li> <li>Modos de Economia de Energia: Utilizar modos de baixo consumo quando o dispositivo n\u00e3o estiver ativo, reduzindo o consumo geral.</li> <li>Fontes de Energia Adequadas: Selecionar fontes de energia que atendam \u00e0s necessidades dos sensores e atuadores utilizados no projeto.</li> </ul>"},{"location":"aulas/iot/modulos/modulo13.html#93-protocolos-de-comunicacao","title":"9.3 Protocolos de Comunica\u00e7\u00e3o","text":"<ul> <li>HTTP/HTTPS: Utilizados para comunica\u00e7\u00e3o web padr\u00e3o, ideal para requisi\u00e7\u00f5es simples e integra\u00e7\u00e3o com APIs REST.</li> <li>MQTT: Protocolo de mensagens leve, ideal para aplica\u00e7\u00f5es IoT que requerem comunica\u00e7\u00e3o eficiente e em tempo real.</li> <li>WebSockets: Permite comunica\u00e7\u00e3o bidirecional em tempo real, \u00fatil para aplica\u00e7\u00f5es que necessitam de atualiza\u00e7\u00f5es instant\u00e2neas.</li> <li>CoAP: Protocolo de aplica\u00e7\u00e3o otimizado para dispositivos com recursos limitados, similar ao HTTP mas mais eficiente.</li> </ul>"},{"location":"aulas/iot/modulos/modulo13.html#94-armazenamento-e-processamento-de-dados","title":"9.4 Armazenamento e Processamento de Dados","text":"<ul> <li>Servi\u00e7os de Nuvem: Plataformas como ThingSpeak, Adafruit IO, AWS IoT e Google Cloud IoT permitem armazenar, processar e visualizar dados de sensores.</li> <li>Banco de Dados: Utilizar bancos de dados para armazenar grandes volumes de dados coletados, facilitando an\u00e1lises futuras.</li> <li>An\u00e1lise de Dados: Aplicar t\u00e9cnicas de an\u00e1lise para interpretar os dados coletados e extrair insights valiosos para o projeto.</li> </ul>"},{"location":"aulas/iot/modulos/modulo13.html#95-boas-praticas-na-iot","title":"9.5 Boas Pr\u00e1ticas na IoT","text":"<ul> <li>Modularidade e Escalabilidade: Desenvolver sistemas modulares que possam ser facilmente escalados para incluir mais dispositivos e funcionalidades.</li> <li>Resili\u00eancia e Redund\u00e2ncia: Assegurar que o sistema continue operando mesmo em caso de falhas de alguns componentes, implementando redund\u00e2ncias quando necess\u00e1rio.</li> <li>Documenta\u00e7\u00e3o Completa: Manter uma documenta\u00e7\u00e3o detalhada do projeto, facilitando manuten\u00e7\u00f5es e futuras expans\u00f5es.</li> <li>Prote\u00e7\u00e3o F\u00edsica: Garantir que os componentes eletr\u00f4nicos estejam protegidos contra danos f\u00edsicos e interfer\u00eancias ambientais.</li> </ul>"},{"location":"aulas/iot/modulos/modulo13.html#10-recursos-adicionais","title":"10. Recursos Adicionais","text":"<ul> <li> <p>Documenta\u00e7\u00e3o Oficial do Arduino:</p> </li> <li> <p>ESP8266WiFi Library</p> </li> <li>PubSubClient Library</li> <li> <p>ArduinoJson Library</p> </li> <li> <p>Tutoriais e Guias:</p> </li> <li> <p>Introdu\u00e7\u00e3o \u00e0 IoT com Arduino</p> </li> <li>Utilizando MQTT com Arduino</li> <li> <p>Integra\u00e7\u00e3o do Arduino com Servi\u00e7os de Nuvem</p> </li> <li> <p>V\u00eddeos Educacionais:</p> </li> <li> <p>Arduino IoT Tutorial</p> </li> <li>Configurando MQTT com Arduino</li> <li>Projetos IoT com Arduino</li> </ul>"},{"location":"aulas/iot/modulos/modulo13.html#11-conclusao-do-modulo","title":"11. Conclus\u00e3o do M\u00f3dulo","text":"<p>Neste m\u00f3dulo, voc\u00ea aprendeu:</p> <ul> <li>Os conceitos b\u00e1sicos e avan\u00e7ados de Internet das Coisas (IoT).</li> <li>Como conectar o Arduino \u00e0 internet utilizando m\u00f3dulos Wi-Fi e Ethernet.</li> <li>Implementa\u00e7\u00e3o de comunica\u00e7\u00e3o com servi\u00e7os de nuvem como ThingSpeak e MQTT.</li> <li>T\u00e9cnicas de publica\u00e7\u00e3o e subscri\u00e7\u00e3o de dados utilizando protocolos eficientes.</li> <li>Desenvolvimento de projetos IoT integrando sensores, atuadores e comunica\u00e7\u00e3o online.</li> <li>Import\u00e2ncia da seguran\u00e7a, gerenciamento de energia e boas pr\u00e1ticas na cria\u00e7\u00e3o de sistemas IoT.</li> <li>Praticou com exemplos e exerc\u00edcios que refor\u00e7am o entendimento dos conceitos de IoT com Arduino.</li> </ul> <p>Voc\u00ea completou todos os m\u00f3dulos do curso \"Programa\u00e7\u00e3o em Arduino: Conceitos Fundamentais sem Hardware\". Parab\u00e9ns pelo empenho e dedica\u00e7\u00e3o!</p>"},{"location":"aulas/iot/modulos/modulo13.html#12-proximos-passos","title":"12. Pr\u00f3ximos Passos","text":"<ul> <li>Revisar todo o conte\u00fado do curso para consolidar o aprendizado.</li> <li>Explorar projetos avan\u00e7ados que combinam m\u00faltiplos conceitos aprendidos, como rob\u00f3tica, automa\u00e7\u00e3o residencial ou sistemas de monitoramento ambiental.</li> <li>Participar de comunidades e f\u00f3runs de Arduino para trocar experi\u00eancias e obter suporte cont\u00ednuo.</li> <li>Considerar cursos avan\u00e7ados ou especializa\u00e7\u00f5es em \u00e1reas espec\u00edficas de interesse, como desenvolvimento de firmware, integra\u00e7\u00e3o com plataformas de IoT ou design de hardware.</li> <li>Desenvolver seu pr\u00f3prio portf\u00f3lio de projetos Arduino para demonstrar suas habilidades e conhecimentos adquiridos.</li> </ul> <p>Se tiver d\u00favidas ou precisar de assist\u00eancia, continue participando de comunidades de aprendizagem ou consulte os recursos adicionais fornecidos ao longo dos m\u00f3dulos.</p> <p>Parab\u00e9ns por concluir o curso! Continue explorando e criando projetos incr\u00edveis com Arduino!</p>"},{"location":"aulas/iot/modulos/modulo14.html","title":"M\u00f3dulo 14: Integra\u00e7\u00e3o com Assistentes Virtuais e Controle por Voz","text":"<p>Bem-vindo ao M\u00f3dulo 14 do curso \"Programa\u00e7\u00e3o em Arduino: Conceitos Fundamentais sem Hardware\". Neste m\u00f3dulo, voc\u00ea ir\u00e1 aprender a integrar o Arduino com assistentes virtuais como Amazon Alexa e Google Assistant, permitindo o controle por voz de dispositivos conectados. Esta integra\u00e7\u00e3o amplia as possibilidades dos seus projetos, tornando-os mais interativos e acess\u00edveis.</p>"},{"location":"aulas/iot/modulos/modulo14.html#objetivos-do-modulo","title":"Objetivos do M\u00f3dulo","text":"<ul> <li>Compreender os conceitos b\u00e1sicos de assistentes virtuais e controle por voz.</li> <li>Aprender a configurar o Arduino para comunica\u00e7\u00e3o com plataformas de assistentes virtuais.</li> <li>Implementar comandos de voz para controlar LEDs, motores e outros atuadores.</li> <li>Utilizar servi\u00e7os como IFTTT para facilitar a integra\u00e7\u00e3o entre o Arduino e assistentes virtuais.</li> <li>Desenvolver projetos que respondem a comandos de voz para realizar a\u00e7\u00f5es espec\u00edficas.</li> <li>Resolver exerc\u00edcios pr\u00e1ticos para consolidar o conhecimento sobre integra\u00e7\u00e3o com assistentes virtuais.</li> </ul>"},{"location":"aulas/iot/modulos/modulo14.html#1-introducao-a-integracao-com-assistentes-virtuais","title":"1. Introdu\u00e7\u00e3o \u00e0 Integra\u00e7\u00e3o com Assistentes Virtuais","text":""},{"location":"aulas/iot/modulos/modulo14.html#11-o-que-sao-assistentes-virtuais","title":"1.1 O que s\u00e3o Assistentes Virtuais?","text":"<p>Assistentes virtuais s\u00e3o programas baseados em intelig\u00eancia artificial que interagem com os usu\u00e1rios por meio de comandos de voz. Exemplos populares incluem Amazon Alexa, Google Assistant e Apple Siri. Eles permitem controlar dispositivos conectados, obter informa\u00e7\u00f5es, definir lembretes e muito mais.</p>"},{"location":"aulas/iot/modulos/modulo14.html#12-importancia-do-controle-por-voz","title":"1.2 Import\u00e2ncia do Controle por Voz","text":"<ul> <li>Conveni\u00eancia: Permite controlar dispositivos sem a necessidade de interfaces f\u00edsicas.</li> <li>Acessibilidade: Facilita o uso para pessoas com limita\u00e7\u00f5es f\u00edsicas.</li> <li>Automa\u00e7\u00e3o: Integra facilmente com sistemas de automa\u00e7\u00e3o residencial para criar ambientes inteligentes.</li> </ul>"},{"location":"aulas/iot/modulos/modulo14.html#13-componentes-basicos-para-integracao","title":"1.3 Componentes B\u00e1sicos para Integra\u00e7\u00e3o","text":"<ul> <li>Arduino com Conectividade \u00e0 Internet: Utilizando m\u00f3dulos como ESP8266 ou ESP32.</li> <li>Servi\u00e7os de Integra\u00e7\u00e3o: Como IFTTT (If This Then That).</li> <li>Assistente Virtual: Amazon Alexa, Google Assistant, etc.</li> <li>Plataforma de Comunica\u00e7\u00e3o: Webhooks, APIs REST.</li> </ul>"},{"location":"aulas/iot/modulos/modulo14.html#2-configurando-o-arduino-para-controle-por-voz","title":"2. Configurando o Arduino para Controle por Voz","text":""},{"location":"aulas/iot/modulos/modulo14.html#21-utilizando-o-ifttt-para-integracao","title":"2.1 Utilizando o IFTTT para Integra\u00e7\u00e3o","text":"<p>IFTTT \u00e9 um servi\u00e7o que conecta diferentes aplicativos e dispositivos por meio de \"applets\". Ele facilita a integra\u00e7\u00e3o entre o Arduino e assistentes virtuais sem a necessidade de programa\u00e7\u00e3o complexa.</p> <p>Passos para Utilizar o IFTTT:</p> <ol> <li>Criar uma Conta no IFTTT: Acesse IFTTT e crie uma conta gratuita.</li> <li>Criar um Applet: Defina um gatilho (trigger) e uma a\u00e7\u00e3o (action).</li> <li>Configurar Webhooks: Utilize o servi\u00e7o Webhooks para enviar requisi\u00e7\u00f5es HTTP ao Arduino.</li> </ol>"},{"location":"aulas/iot/modulos/modulo14.html#22-exemplo-de-integracao-com-amazon-alexa","title":"2.2 Exemplo de Integra\u00e7\u00e3o com Amazon Alexa","text":"<p>Objetivo: Controlar um LED conectado ao Arduino usando comandos de voz via Amazon Alexa.</p> <p>Componentes Necess\u00e1rios:</p> <ul> <li>Arduino Uno com m\u00f3dulo ESP8266 ou ESP32.</li> <li>LED e resistor de 220\u03a9.</li> <li>Cabos de conex\u00e3o.</li> <li>Conta na Amazon Alexa e no IFTTT.</li> </ul>"},{"location":"aulas/iot/modulos/modulo14.html#23-exemplo-de-codigo-para-controle-de-led-via-ifttt","title":"2.3 Exemplo de C\u00f3digo para Controle de LED via IFTTT","text":"<pre><code>#include &lt;ESP8266WiFi.h&gt;\n#include &lt;ESP8266HTTPClient.h&gt;\n\n// Configura\u00e7\u00f5es de rede\nconst char* ssid = \"Seu_SSID\";\nconst char* password = \"Sua_Senha\";\n\n// Endere\u00e7o do Webhook do IFTTT\nconst char* serverName = \"http://maker.ifttt.com/trigger/LED_ON/with/key/SUA_CHAVE_IFTTT\";\n\n// Pino do LED\nconst int pinoLED = 5;\n\nvoid setup() {\n    Serial.begin(115200);\n    pinMode(pinoLED, OUTPUT);\n    digitalWrite(pinoLED, LOW);\n\n    // Conecta ao Wi-Fi\n    WiFi.begin(ssid, password);\n    Serial.print(\"Conectando ao Wi-Fi\");\n    while (WiFi.status() != WL_CONNECTED) {\n        delay(500);\n        Serial.print(\".\");\n    }\n    Serial.println(\" Conectado!\");\n}\n\nvoid loop() {\n    if (WiFi.status() == WL_CONNECTED) {\n        HTTPClient http;\n\n        http.begin(serverName);\n        int httpResponseCode = http.GET();\n\n        if (httpResponseCode &gt; 0) {\n            Serial.print(\"C\u00f3digo de resposta HTTP: \");\n            Serial.println(httpResponseCode);\n            if (httpResponseCode == 200) {\n                digitalWrite(pinoLED, HIGH); // Liga o LED\n                delay(5000); // Mant\u00e9m o LED ligado por 5 segundos\n                digitalWrite(pinoLED, LOW); // Desliga o LED\n            }\n        } else {\n            Serial.print(\"Erro na requisi\u00e7\u00e3o: \");\n            Serial.println(httpResponseCode);\n        }\n        http.end();\n    } else {\n        Serial.println(\"Erro na conex\u00e3o Wi-Fi\");\n    }\n    delay(20000); // Aguarda 20 segundos antes da pr\u00f3xima requisi\u00e7\u00e3o\n}\n</code></pre> <p>Explica\u00e7\u00e3o:</p> <ul> <li>Conex\u00e3o Wi-Fi: O Arduino conecta-se \u00e0 rede Wi-Fi especificada.</li> <li>Requisi\u00e7\u00e3o HTTP: Envia uma requisi\u00e7\u00e3o GET para o Webhook do IFTTT quando acionado.</li> <li>Controle do LED: Liga o LED quando recebe uma resposta HTTP 200 (sucesso) e o desliga ap\u00f3s 5 segundos.</li> </ul>"},{"location":"aulas/iot/modulos/modulo14.html#3-implementando-comandos-de-voz-com-google-assistant","title":"3. Implementando Comandos de Voz com Google Assistant","text":""},{"location":"aulas/iot/modulos/modulo14.html#31-configuracao-do-ifttt-com-google-assistant","title":"3.1 Configura\u00e7\u00e3o do IFTTT com Google Assistant","text":"<p>Objetivo: Controlar um motor DC usando comandos de voz via Google Assistant.</p> <p>Passos:</p> <ol> <li>Criar um Applet no IFTTT:</li> <li>If This: Escolha o servi\u00e7o Google Assistant e defina o comando de voz (por exemplo, \"girar motor\").</li> <li> <p>Then That: Escolha o servi\u00e7o Webhooks e configure a URL do Arduino para acionar o motor.</p> </li> <li> <p>Configurar o Arduino para Receber Requisi\u00e7\u00f5es:</p> </li> <li>Utilize o mesmo m\u00e9todo mostrado no exemplo anterior para receber e interpretar as requisi\u00e7\u00f5es HTTP.</li> </ol>"},{"location":"aulas/iot/modulos/modulo14.html#32-exemplo-de-codigo-para-controle-de-motor-dc-via-ifttt","title":"3.2 Exemplo de C\u00f3digo para Controle de Motor DC via IFTTT","text":"<pre><code>#include &lt;ESP8266WiFi.h&gt;\n#include &lt;ESP8266HTTPClient.h&gt;\n\n// Configura\u00e7\u00f5es de rede\nconst char* ssid = \"Seu_SSID\";\nconst char* password = \"Sua_Senha\";\n\n// Endere\u00e7o do Webhook do IFTTT\nconst char* serverName = \"http://maker.ifttt.com/trigger/MOTOR_ON/with/key/SUA_CHAVE_IFTTT\";\n\n// Pinos do Motor DC\nconst int IN1 = D1;\nconst int IN2 = D2;\nconst int ENA = D3;\n\nvoid setup() {\n    Serial.begin(115200);\n    pinMode(IN1, OUTPUT);\n    pinMode(IN2, OUTPUT);\n    pinMode(ENA, OUTPUT);\n    digitalWrite(IN1, LOW);\n    digitalWrite(IN2, LOW);\n    analogWrite(ENA, 0);\n\n    // Conecta ao Wi-Fi\n    WiFi.begin(ssid, password);\n    Serial.print(\"Conectando ao Wi-Fi\");\n    while (WiFi.status() != WL_CONNECTED) {\n        delay(500);\n        Serial.print(\".\");\n    }\n    Serial.println(\" Conectado!\");\n}\n\nvoid loop() {\n    if (WiFi.status() == WL_CONNECTED) {\n        HTTPClient http;\n\n        http.begin(serverName);\n        int httpResponseCode = http.GET();\n\n        if (httpResponseCode &gt; 0) {\n            Serial.print(\"C\u00f3digo de resposta HTTP: \");\n            Serial.println(httpResponseCode);\n            if (httpResponseCode == 200) {\n                // Gira o motor para frente\n                digitalWrite(IN1, HIGH);\n                digitalWrite(IN2, LOW);\n                analogWrite(ENA, 200); // Velocidade do motor\n                delay(5000); // Mant\u00e9m o motor girando por 5 segundos\n\n                // Para o motor\n                digitalWrite(IN1, LOW);\n                digitalWrite(IN2, LOW);\n                analogWrite(ENA, 0);\n            }\n        } else {\n            Serial.print(\"Erro na requisi\u00e7\u00e3o: \");\n            Serial.println(httpResponseCode);\n        }\n        http.end();\n    } else {\n        Serial.println(\"Erro na conex\u00e3o Wi-Fi\");\n    }\n    delay(20000); // Aguarda 20 segundos antes da pr\u00f3xima requisi\u00e7\u00e3o\n}\n</code></pre> <p>Explica\u00e7\u00e3o:</p> <ul> <li>Controle Direcional: Define a dire\u00e7\u00e3o do motor DC ao configurar os pinos IN1 e IN2.</li> <li>Velocidade do Motor: Controlada pelo pino ENA utilizando PWM.</li> <li>Automa\u00e7\u00e3o: Gira o motor para frente por 5 segundos quando recebe uma requisi\u00e7\u00e3o v\u00e1lida.</li> </ul>"},{"location":"aulas/iot/modulos/modulo14.html#4-desenvolvendo-projetos-com-controle-por-voz","title":"4. Desenvolvendo Projetos com Controle por Voz","text":""},{"location":"aulas/iot/modulos/modulo14.html#41-controle-de-luzes-e-aparelhos-domesticos","title":"4.1 Controle de Luzes e Aparelhos Dom\u00e9sticos","text":"<p>Crie um sistema onde voc\u00ea pode ligar e desligar luzes, ventiladores e outros aparelhos eletr\u00f4nicos usando comandos de voz atrav\u00e9s do Alexa ou Google Assistant.</p>"},{"location":"aulas/iot/modulos/modulo14.html#42-automacao-de-portas-e-valvulas","title":"4.2 Automa\u00e7\u00e3o de Portas e V\u00e1lvulas","text":"<p>Implemente o controle de portas autom\u00e1ticas, cortinas e v\u00e1lvulas de irriga\u00e7\u00e3o por meio de comandos de voz, proporcionando maior comodidade e efici\u00eancia no gerenciamento do ambiente.</p>"},{"location":"aulas/iot/modulos/modulo14.html#43-monitoramento-e-resposta-a-eventos","title":"4.3 Monitoramento e Resposta a Eventos","text":"<p>Desenvolva sistemas que monitoram eventos espec\u00edficos (como detec\u00e7\u00e3o de movimento ou mudan\u00e7a de temperatura) e respondem automaticamente a esses eventos, podendo tamb\u00e9m enviar notifica\u00e7\u00f5es por meio de assistentes virtuais.</p>"},{"location":"aulas/iot/modulos/modulo14.html#5-conceitos-avancados-de-controle-por-voz","title":"5. Conceitos Avan\u00e7ados de Controle por Voz","text":""},{"location":"aulas/iot/modulos/modulo14.html#51-utilizando-apis-de-assistentes-virtuais","title":"5.1 Utilizando APIs de Assistentes Virtuais","text":"<p>Aprofunde-se no uso de APIs fornecidas por assistentes virtuais para criar intera\u00e7\u00f5es mais complexas e personalizadas entre o Arduino e os servi\u00e7os de voz.</p>"},{"location":"aulas/iot/modulos/modulo14.html#52-seguranca-e-autenticacao","title":"5.2 Seguran\u00e7a e Autentica\u00e7\u00e3o","text":"<p>Implemente m\u00e9todos de seguran\u00e7a para garantir que apenas comandos autorizados possam controlar os dispositivos conectados, protegendo seu sistema contra acessos n\u00e3o desejados.</p>"},{"location":"aulas/iot/modulos/modulo14.html#53-gerenciamento-de-multiplos-dispositivos","title":"5.3 Gerenciamento de M\u00faltiplos Dispositivos","text":"<p>Aprenda a controlar m\u00faltiplos dispositivos simultaneamente, permitindo uma automa\u00e7\u00e3o residencial mais abrangente e integrada.</p>"},{"location":"aulas/iot/modulos/modulo14.html#6-exemplos-praticos","title":"6. Exemplos Pr\u00e1ticos","text":""},{"location":"aulas/iot/modulos/modulo14.html#61-sistema-de-iluminacao-inteligente-com-controle-por-voz","title":"6.1 Sistema de Ilumina\u00e7\u00e3o Inteligente com Controle por Voz","text":"<p>Este exemplo demonstra como controlar m\u00faltiplos LEDs conectados ao Arduino utilizando comandos de voz via Amazon Alexa.</p> <pre><code>#include &lt;ESP8266WiFi.h&gt;\n#include &lt;ESP8266HTTPClient.h&gt;\n\n// Configura\u00e7\u00f5es de rede\nconst char* ssid = \"Seu_SSID\";\nconst char* password = \"Sua_Senha\";\n\n// Endere\u00e7o do Webhook do IFTTT para ligar as luzes\nconst char* serverOn = \"http://maker.ifttt.com/trigger/Luzes_ON/with/key/SUA_CHAVE_IFTTT\";\n// Endere\u00e7o do Webhook do IFTTT para desligar as luzes\nconst char* serverOff = \"http://maker.ifttt.com/trigger/Luzes_OFF/with/key/SUA_CHAVE_IFTTT\";\n\n// Pinos dos LEDs\nconst int led1 = D1;\nconst int led2 = D2;\n\nvoid setup() {\n    Serial.begin(115200);\n    pinMode(led1, OUTPUT);\n    pinMode(led2, OUTPUT);\n    digitalWrite(led1, LOW);\n    digitalWrite(led2, LOW);\n\n    // Conecta ao Wi-Fi\n    WiFi.begin(ssid, password);\n    Serial.print(\"Conectando ao Wi-Fi\");\n    while (WiFi.status() != WL_CONNECTED) {\n        delay(500);\n        Serial.print(\".\");\n    }\n    Serial.println(\" Conectado!\");\n}\n\nvoid ligarLuzes() {\n    HTTPClient http;\n    http.begin(serverOn);\n    int httpResponseCode = http.GET();\n\n    if (httpResponseCode == 200) {\n        digitalWrite(led1, HIGH);\n        digitalWrite(led2, HIGH);\n        Serial.println(\"Luzes Ligadas.\");\n    } else {\n        Serial.println(\"Falha ao ligar as luzes.\");\n    }\n    http.end();\n}\n\nvoid desligarLuzes() {\n    HTTPClient http;\n    http.begin(serverOff);\n    int httpResponseCode = http.GET();\n\n    if (httpResponseCode == 200) {\n        digitalWrite(led1, LOW);\n        digitalWrite(led2, LOW);\n        Serial.println(\"Luzes Desligadas.\");\n    } else {\n        Serial.println(\"Falha ao desligar as luzes.\");\n    }\n    http.end();\n}\n\nvoid loop() {\n    // Nenhuma a\u00e7\u00e3o no loop principal\n    delay(1000);\n}\n</code></pre> <p>Explica\u00e7\u00e3o:</p> <ul> <li>M\u00faltiplos LEDs: Controla dois LEDs simultaneamente.</li> <li>Webhooks Diferenciados: Utiliza Webhooks distintos para ligar e desligar as luzes.</li> <li>Automa\u00e7\u00e3o Residencial: Permite controlar a ilumina\u00e7\u00e3o da casa por meio de comandos de voz.</li> </ul>"},{"location":"aulas/iot/modulos/modulo14.html#62-controle-de-sistema-de-irrigacao-com-voz-e-sensor-de-umidade","title":"6.2 Controle de Sistema de Irriga\u00e7\u00e3o com Voz e Sensor de Umidade","text":"<p>Este exemplo integra controle por voz com sensores de umidade do solo para automatizar a irriga\u00e7\u00e3o de plantas.</p> <pre><code>#include &lt;ESP8266WiFi.h&gt;\n#include &lt;ESP8266HTTPClient.h&gt;\n#include \"DHT.h\"\n\n// Configura\u00e7\u00f5es de rede\nconst char* ssid = \"Seu_SSID\";\nconst char* password = \"Sua_Senha\";\n\n// Endere\u00e7o do Webhook do IFTTT para ligar a irriga\u00e7\u00e3o\nconst char* serverOn = \"http://maker.ifttt.com/trigger/Irrigacao_ON/with/key/SUA_CHAVE_IFTTT\";\n// Endere\u00e7o do Webhook do IFTTT para desligar a irriga\u00e7\u00e3o\nconst char* serverOff = \"http://maker.ifttt.com/trigger/Irrigacao_OFF/with/key/SUA_CHAVE_IFTTT\";\n\n// Configura\u00e7\u00f5es do DHT\n#define DHTPIN 2\n#define DHTTYPE DHT22\nDHT dht(DHTPIN, DHTTYPE);\n\n// Pino do rel\u00e9 da bomba\nconst int pinoRele = D1;\n\n// Limiar de umidade\nconst float limiarUmidade = 30.0;\n\nvoid setup() {\n    Serial.begin(115200);\n    pinMode(pinoRele, OUTPUT);\n    digitalWrite(pinoRele, LOW);\n    dht.begin();\n\n    // Conecta ao Wi-Fi\n    WiFi.begin(ssid, password);\n    Serial.print(\"Conectando ao Wi-Fi\");\n    while (WiFi.status() != WL_CONNECTED) {\n        delay(500);\n        Serial.print(\".\");\n    }\n    Serial.println(\" Conectado!\");\n}\n\nvoid ligarIrrigacao() {\n    HTTPClient http;\n    http.begin(serverOn);\n    int httpResponseCode = http.GET();\n\n    if (httpResponseCode == 200) {\n        digitalWrite(pinoRele, HIGH);\n        Serial.println(\"Irriga\u00e7\u00e3o Ligada.\");\n    } else {\n        Serial.println(\"Falha ao ligar a irriga\u00e7\u00e3o.\");\n    }\n    http.end();\n}\n\nvoid desligarIrrigacao() {\n    HTTPClient http;\n    http.begin(serverOff);\n    int httpResponseCode = http.GET();\n\n    if (httpResponseCode == 200) {\n        digitalWrite(pinoRele, LOW);\n        Serial.println(\"Irriga\u00e7\u00e3o Desligada.\");\n    } else {\n        Serial.println(\"Falha ao desligar a irriga\u00e7\u00e3o.\");\n    }\n    http.end();\n}\n\nvoid loop() {\n    float umidade = dht.readHumidity();\n\n    if (isnan(umidade)) {\n        Serial.println(\"Falha na leitura do sensor DHT!\");\n        return;\n    }\n\n    Serial.print(\"Umidade do Solo: \");\n    Serial.println(umidade);\n\n    if (umidade &lt; limiarUmidade) {\n        ligarIrrigacao();\n    } else {\n        desligarIrrigacao();\n    }\n\n    delay(10000); // Aguarda 10 segundos antes da pr\u00f3xima leitura\n}\n</code></pre> <p>Explica\u00e7\u00e3o:</p> <ul> <li>Sensor de Umidade: Monitora a umidade do solo.</li> <li>Controle Autom\u00e1tico: Liga a bomba de irriga\u00e7\u00e3o quando a umidade est\u00e1 abaixo do limiar e desliga quando est\u00e1 acima.</li> <li>Comando por Voz: Permite ativar ou desativar a irriga\u00e7\u00e3o manualmente via comandos de voz.</li> </ul>"},{"location":"aulas/iot/modulos/modulo14.html#63-sistema-de-seguranca-com-deteccao-de-movimento-e-controle-por-voz","title":"6.3 Sistema de Seguran\u00e7a com Detec\u00e7\u00e3o de Movimento e Controle por Voz","text":"<p>Este exemplo combina detec\u00e7\u00e3o de movimento com controle por voz para criar um sistema de seguran\u00e7a inteligente.</p> <pre><code>#include &lt;ESP8266WiFi.h&gt;\n#include &lt;ESP8266HTTPClient.h&gt;\n\n// Configura\u00e7\u00f5es de rede\nconst char* ssid = \"Seu_SSID\";\nconst char* password = \"Sua_Senha\";\n\n// Endere\u00e7o do Webhook do IFTTT para acionar o alarme\nconst char* serverAlarm = \"http://maker.ifttt.com/trigger/Alarme_ON/with/key/SUA_CHAVE_IFTTT\";\n\n// Pino do sensor PIR\nconst int pinoPIR = D2;\n// Pino do LED de Alarme\nconst int pinoLED = D1;\n\nvoid setup() {\n    Serial.begin(115200);\n    pinMode(pinoPIR, INPUT);\n    pinMode(pinoLED, OUTPUT);\n    digitalWrite(pinoLED, LOW);\n\n    // Conecta ao Wi-Fi\n    WiFi.begin(ssid, password);\n    Serial.print(\"Conectando ao Wi-Fi\");\n    while (WiFi.status() != WL_CONNECTED) {\n        delay(500);\n        Serial.print(\".\");\n    }\n    Serial.println(\" Conectado!\");\n}\n\nvoid acionarAlarme() {\n    HTTPClient http;\n    http.begin(serverAlarm);\n    int httpResponseCode = http.GET();\n\n    if (httpResponseCode == 200) {\n        digitalWrite(pinoLED, HIGH);\n        Serial.println(\"Alarme Acionado!\");\n    } else {\n        Serial.println(\"Falha ao acionar o alarme.\");\n    }\n    http.end();\n}\n\nvoid loop() {\n    int estadoPIR = digitalRead(pinoPIR);\n    if (estadoPIR == HIGH) {\n        acionarAlarme();\n        delay(10000); // Evita m\u00faltiplas acionamentos\n    } else {\n        digitalWrite(pinoLED, LOW);\n    }\n    delay(100);\n}\n</code></pre> <p>Explica\u00e7\u00e3o:</p> <ul> <li>Sensor PIR: Detecta movimento na \u00e1rea monitorada.</li> <li>Acionamento do Alarme: Liga um LED como sinal de alarme quando movimento \u00e9 detectado e envia uma notifica\u00e7\u00e3o via IFTTT.</li> <li>Controle por Voz: Permite desativar o alarme manualmente atrav\u00e9s de comandos de voz.</li> </ul>"},{"location":"aulas/iot/modulos/modulo14.html#7-exercicios-praticos","title":"7. Exerc\u00edcios Pr\u00e1ticos","text":""},{"location":"aulas/iot/modulos/modulo14.html#exercicio-1-controle-de-dispositivos-multiplos-por-voz","title":"Exerc\u00edcio 1: Controle de Dispositivos M\u00faltiplos por Voz","text":"<ul> <li> <p>Tarefa: Crie um projeto onde voc\u00ea pode controlar m\u00faltiplos dispositivos (como LEDs, ventiladores e motores) usando comandos de voz via Amazon Alexa ou Google Assistant.</p> </li> <li> <p>Dicas:</p> </li> <li>Utilize m\u00faltiplos Webhooks no IFTTT para diferentes comandos.</li> <li> <p>Organize o c\u00f3digo para gerenciar diferentes dispositivos com efici\u00eancia.</p> </li> <li> <p>Exemplo de C\u00f3digo:</p> </li> </ul> <pre><code>#include &lt;ESP8266WiFi.h&gt;\n#include &lt;ESP8266HTTPClient.h&gt;\n\n// Configura\u00e7\u00f5es de rede\nconst char* ssid = \"Seu_SSID\";\nconst char* password = \"Sua_Senha\";\n\n// Endere\u00e7os dos Webhooks do IFTTT\nconst char* serverLEDOn = \"http://maker.ifttt.com/trigger/LED_ON/with/key/SUA_CHAVE_IFTTT\";\nconst char* serverLEDOff = \"http://maker.ifttt.com/trigger/LED_OFF/with/key/SUA_CHAVE_IFTTT\";\nconst char* serverFanOn = \"http://maker.ifttt.com/trigger/FAN_ON/with/key/SUA_CHAVE_IFTTT\";\nconst char* serverFanOff = \"http://maker.ifttt.com/trigger/FAN_OFF/with/key/SUA_CHAVE_IFTTT\";\n\n// Pinos dos dispositivos\nconst int pinoLED = D1;\nconst int pinoFan = D2;\n\nvoid setup() {\n    Serial.begin(115200);\n    pinMode(pinoLED, OUTPUT);\n    pinMode(pinoFan, OUTPUT);\n    digitalWrite(pinoLED, LOW);\n    digitalWrite(pinoFan, LOW);\n\n    // Conecta ao Wi-Fi\n    WiFi.begin(ssid, password);\n    Serial.print(\"Conectando ao Wi-Fi\");\n    while (WiFi.status() != WL_CONNECTED) {\n        delay(500);\n        Serial.print(\".\");\n    }\n    Serial.println(\" Conectado!\");\n}\n\nvoid ligarLED() {\n    HTTPClient http;\n    http.begin(serverLEDOn);\n    int httpResponseCode = http.GET();\n\n    if (httpResponseCode == 200) {\n        digitalWrite(pinoLED, HIGH);\n        Serial.println(\"LED Ligado.\");\n    } else {\n        Serial.println(\"Falha ao ligar o LED.\");\n    }\n    http.end();\n}\n\nvoid desligarLED() {\n    HTTPClient http;\n    http.begin(serverLEDOff);\n    int httpResponseCode = http.GET();\n\n    if (httpResponseCode == 200) {\n        digitalWrite(pinoLED, LOW);\n        Serial.println(\"LED Desligado.\");\n    } else {\n        Serial.println(\"Falha ao desligar o LED.\");\n    }\n    http.end();\n}\n\nvoid ligarFan() {\n    HTTPClient http;\n    http.begin(serverFanOn);\n    int httpResponseCode = http.GET();\n\n    if (httpResponseCode == 200) {\n        digitalWrite(pinoFan, HIGH);\n        Serial.println(\"Ventilador Ligado.\");\n    } else {\n        Serial.println(\"Falha ao ligar o ventilador.\");\n    }\n    http.end();\n}\n\nvoid desligarFan() {\n    HTTPClient http;\n    http.begin(serverFanOff);\n    int httpResponseCode = http.GET();\n\n    if (httpResponseCode == 200) {\n        digitalWrite(pinoFan, LOW);\n        Serial.println(\"Ventilador Desligado.\");\n    } else {\n        Serial.println(\"Falha ao desligar o ventilador.\");\n    }\n    http.end();\n}\n\nvoid loop() {\n    // Nenhuma a\u00e7\u00e3o no loop principal\n    delay(1000);\n}\n</code></pre>"},{"location":"aulas/iot/modulos/modulo14.html#exercicio-2-sistema-de-alerta-de-seguranca-com-comandos-de-voz","title":"Exerc\u00edcio 2: Sistema de Alerta de Seguran\u00e7a com Comandos de Voz","text":"<ul> <li> <p>Tarefa: Desenvolva um sistema que envia alertas de seguran\u00e7a via assistente virtual quando sensores de movimento ou de g\u00e1s detectam atividades suspeitas, al\u00e9m de permitir o controle manual via comandos de voz.</p> </li> <li> <p>Dicas:</p> </li> <li>Integre m\u00faltiplos sensores (PIR e sensor de g\u00e1s).</li> <li>Utilize Webhooks diferentes para cada tipo de alerta.</li> <li> <p>Adicione feedback visual (LEDs) e auditivo (buzzer) para alertas.</p> </li> <li> <p>Exemplo de C\u00f3digo:</p> </li> </ul> <pre><code>#include &lt;ESP8266WiFi.h&gt;\n#include &lt;ESP8266HTTPClient.h&gt;\n\n// Configura\u00e7\u00f5es de rede\nconst char* ssid = \"Seu_SSID\";\nconst char* password = \"Sua_Senha\";\n\n// Endere\u00e7os dos Webhooks do IFTTT\nconst char* serverAlarmeMovimento = \"http://maker.ifttt.com/trigger/Alarme_Movimento/with/key/SUA_CHAVE_IFTTT\";\nconst char* serverAlarmeGas = \"http://maker.ifttt.com/trigger/Alarme_Gas/with/key/SUA_CHAVE_IFTTT\";\n\n// Pinos dos sensores e atuadores\nconst int pinoPIR = D1;\nconst int pinoGas = A0;\nconst int pinoLED = D2;\nconst int pinoBuzzer = D3;\n\n// Limiar de g\u00e1s\nconst int limiarGas = 300;\n\nvoid setup() {\n    Serial.begin(115200);\n    pinMode(pinoPIR, INPUT);\n    pinMode(pinoGas, INPUT);\n    pinMode(pinoLED, OUTPUT);\n    pinMode(pinoBuzzer, OUTPUT);\n    digitalWrite(pinoLED, LOW);\n    digitalWrite(pinoBuzzer, LOW);\n\n    // Conecta ao Wi-Fi\n    WiFi.begin(ssid, password);\n    Serial.print(\"Conectando ao Wi-Fi\");\n    while (WiFi.status() != WL_CONNECTED) {\n        delay(500);\n        Serial.print(\".\");\n    }\n    Serial.println(\" Conectado!\");\n}\n\nvoid acionarAlarmeMovimento() {\n    HTTPClient http;\n    http.begin(serverAlarmeMovimento);\n    int httpResponseCode = http.GET();\n\n    if (httpResponseCode == 200) {\n        digitalWrite(pinoLED, HIGH);\n        digitalWrite(pinoBuzzer, HIGH);\n        Serial.println(\"Alarme de Movimento Acionado!\");\n    } else {\n        Serial.println(\"Falha ao acionar o alarme de movimento.\");\n    }\n    http.end();\n}\n\nvoid acionarAlarmeGas() {\n    HTTPClient http;\n    http.begin(serverAlarmeGas);\n    int httpResponseCode = http.GET();\n\n    if (httpResponseCode == 200) {\n        digitalWrite(pinoLED, HIGH);\n        digitalWrite(pinoBuzzer, HIGH);\n        Serial.println(\"Alarme de G\u00e1s Acionado!\");\n    } else {\n        Serial.println(\"Falha ao acionar o alarme de g\u00e1s.\");\n    }\n    http.end();\n}\n\nvoid loop() {\n    // Verifica movimento\n    int estadoPIR = digitalRead(pinoPIR);\n    if (estadoPIR == HIGH) {\n        acionarAlarmeMovimento();\n        delay(10000); // Evita m\u00faltiplos acionamentos\n    } else {\n        digitalWrite(pinoLED, LOW);\n        digitalWrite(pinoBuzzer, LOW);\n    }\n\n    // Verifica g\u00e1s\n    int valorGas = analogRead(pinoGas);\n    if (valorGas &gt; limiarGas) {\n        acionarAlarmeGas();\n        delay(10000); // Evita m\u00faltiplos acionamentos\n    } else {\n        digitalWrite(pinoLED, LOW);\n        digitalWrite(pinoBuzzer, LOW);\n    }\n\n    delay(100);\n}\n</code></pre> <p>Explica\u00e7\u00e3o:</p> <ul> <li>M\u00faltiplos Sensores: Monitora movimento e n\u00edveis de g\u00e1s simultaneamente.</li> <li>Alertas Diferenciados: Aciona alarmes distintos para cada tipo de detec\u00e7\u00e3o.</li> <li>Feedback Visual e Auditivo: Utiliza LEDs e buzzers para indicar alertas.</li> </ul>"},{"location":"aulas/iot/modulos/modulo14.html#exercicio-3-automacao-de-ambientes-com-controle-por-voz-e-sensores","title":"Exerc\u00edcio 3: Automa\u00e7\u00e3o de Ambientes com Controle por Voz e Sensores","text":"<ul> <li> <p>Tarefa: Desenvolva um sistema de automa\u00e7\u00e3o que ajusta a ilumina\u00e7\u00e3o e a temperatura de um ambiente com base em comandos de voz e leituras de sensores de luminosidade e temperatura.</p> </li> <li> <p>Dicas:</p> </li> <li>Integre sensores de luz (LDR) e temperatura (DHT22).</li> <li>Utilize comandos de voz para ajustar configura\u00e7\u00f5es manualmente.</li> <li> <p>Automatize ajustes com base nas leituras dos sensores.</p> </li> <li> <p>Exemplo de C\u00f3digo:</p> </li> </ul> <pre><code>#include &lt;ESP8266WiFi.h&gt;\n#include &lt;ESP8266HTTPClient.h&gt;\n#include \"DHT.h\"\n\n// Configura\u00e7\u00f5es de rede\nconst char* ssid = \"Seu_SSID\";\nconst char* password = \"Sua_Senha\";\n\n// Endere\u00e7os dos Webhooks do IFTTT\nconst char* serverLuzOn = \"http://maker.ifttt.com/trigger/Luz_ON/with/key/SUA_CHAVE_IFTTT\";\nconst char* serverLuzOff = \"http://maker.ifttt.com/trigger/Luz_OFF/with/key/SUA_CHAVE_IFTTT\";\nconst char* serverTemperatura = \"http://maker.ifttt.com/trigger/Temperatura_Ajustada/with/key/SUA_CHAVE_IFTTT\";\n\n// Configura\u00e7\u00f5es do DHT\n#define DHTPIN 2\n#define DHTTYPE DHT22\nDHT dht(DHTPIN, DHTTYPE);\n\n// Pinos dos atuadores\nconst int pinoLuz = D1;\nconst int pinoVentilador = D2;\n\nvoid setup() {\n    Serial.begin(115200);\n    pinMode(pinoLuz, OUTPUT);\n    pinMode(pinoVentilador, OUTPUT);\n    digitalWrite(pinoLuz, LOW);\n    digitalWrite(pinoVentilador, LOW);\n    dht.begin();\n\n    // Conecta ao Wi-Fi\n    WiFi.begin(ssid, password);\n    Serial.print(\"Conectando ao Wi-Fi\");\n    while (WiFi.status() != WL_CONNECTED) {\n        delay(500);\n        Serial.print(\".\");\n    }\n    Serial.println(\" Conectado!\");\n}\n\nvoid ligarLuz() {\n    HTTPClient http;\n    http.begin(serverLuzOn);\n    int httpResponseCode = http.GET();\n\n    if (httpResponseCode == 200) {\n        digitalWrite(pinoLuz, HIGH);\n        Serial.println(\"Luz Ligada.\");\n    } else {\n        Serial.println(\"Falha ao ligar a luz.\");\n    }\n    http.end();\n}\n\nvoid desligarLuz() {\n    HTTPClient http;\n    http.begin(serverLuzOff);\n    int httpResponseCode = http.GET();\n\n    if (httpResponseCode == 200) {\n        digitalWrite(pinoLuz, LOW);\n        Serial.println(\"Luz Desligada.\");\n    } else {\n        Serial.println(\"Falha ao desligar a luz.\");\n    }\n    http.end();\n}\n\nvoid ajustarTemperatura(float temperatura) {\n    HTTPClient http;\n    String url = String(serverTemperatura) + \"?value=\" + String(temperatura);\n    http.begin(url.c_str());\n    int httpResponseCode = http.GET();\n\n    if (httpResponseCode == 200) {\n        if (temperatura &gt; 25.0) {\n            digitalWrite(pinoVentilador, HIGH);\n            Serial.println(\"Ventilador Ligado.\");\n        } else {\n            digitalWrite(pinoVentilador, LOW);\n            Serial.println(\"Ventilador Desligado.\");\n        }\n    } else {\n        Serial.println(\"Falha ao ajustar a temperatura.\");\n    }\n    http.end();\n}\n\nvoid loop() {\n    // Leitura dos sensores\n    float temperatura = dht.readTemperature();\n    int valorLDR = analogRead(A0);\n\n    if (isnan(temperatura)) {\n        Serial.println(\"Falha na leitura do sensor DHT!\");\n        return;\n    }\n\n    Serial.print(\"Temperatura: \");\n    Serial.print(temperatura);\n    Serial.print(\" *C\\tLuz: \");\n    Serial.println(valorLDR);\n\n    // Automatiza\u00e7\u00e3o com base nos sensores\n    if (valorLDR &lt; 300) { // Ambiente escuro\n        ligarLuz();\n    } else {\n        desligarLuz();\n    }\n\n    if (temperatura &gt; 25.0) {\n        ajustarTemperatura(temperatura);\n    } else {\n        ajustarTemperatura(temperatura);\n    }\n\n    delay(5000); // Aguarda 5 segundos antes da pr\u00f3xima leitura\n}\n</code></pre> <p>Explica\u00e7\u00e3o:</p> <ul> <li>Sensores Integrados: Utiliza sensores de luminosidade e temperatura para automatizar dispositivos.</li> <li>Controle por Voz e Autom\u00e1tico: Permite tanto comandos de voz quanto ajustes autom\u00e1ticos com base nas leituras dos sensores.</li> <li>Feedback via Serial: Monitora as a\u00e7\u00f5es no Monitor Serial para depura\u00e7\u00e3o e verifica\u00e7\u00e3o.</li> </ul>"},{"location":"aulas/iot/modulos/modulo14.html#8-conceitos-importantes","title":"8. Conceitos Importantes","text":""},{"location":"aulas/iot/modulos/modulo14.html#81-seguranca-na-integracao-com-assistentes-virtuais","title":"8.1 Seguran\u00e7a na Integra\u00e7\u00e3o com Assistentes Virtuais","text":"<ul> <li>Autentica\u00e7\u00e3o: Utilize chaves API seguras e mantenha-as confidenciais.</li> <li>Criptografia: Assegure que as comunica\u00e7\u00f5es entre o Arduino e os servi\u00e7os de nuvem sejam criptografadas.</li> <li>Permiss\u00f5es Restritas: Garanta que apenas os comandos necess\u00e1rios sejam permitidos para evitar abusos.</li> </ul>"},{"location":"aulas/iot/modulos/modulo14.html#82-latencia-e-tempo-de-resposta","title":"8.2 Lat\u00eancia e Tempo de Resposta","text":"<ul> <li>Import\u00e2ncia: A lat\u00eancia pode afetar a experi\u00eancia do usu\u00e1rio ao controlar dispositivos por voz.</li> <li>Redu\u00e7\u00e3o de Lat\u00eancia: Utilize conex\u00f5es Wi-Fi est\u00e1veis e otimize o c\u00f3digo para respostas r\u00e1pidas.</li> </ul>"},{"location":"aulas/iot/modulos/modulo14.html#83-gerenciamento-de-estados","title":"8.3 Gerenciamento de Estados","text":"<ul> <li>Estados dos Dispositivos: Mantenha o controle dos estados atuais dos dispositivos para evitar comandos redundantes.</li> <li>Sincroniza\u00e7\u00e3o: Assegure que os estados dos dispositivos estejam sincronizados entre o Arduino e a interface do usu\u00e1rio.</li> </ul>"},{"location":"aulas/iot/modulos/modulo14.html#84-escalabilidade","title":"8.4 Escalabilidade","text":"<ul> <li>M\u00faltiplos Dispositivos: Planeje sistemas que possam expandir para controlar m\u00faltiplos dispositivos sem complica\u00e7\u00f5es.</li> <li>Organiza\u00e7\u00e3o do C\u00f3digo: Utilize estruturas de c\u00f3digo modulares para facilitar a manuten\u00e7\u00e3o e expans\u00e3o.</li> </ul>"},{"location":"aulas/iot/modulos/modulo14.html#85-boas-praticas-na-integracao-com-assistentes-virtuais","title":"8.5 Boas Pr\u00e1ticas na Integra\u00e7\u00e3o com Assistentes Virtuais","text":"<ul> <li>Testes Rigorosos: Teste exaustivamente os comandos de voz para garantir que respondam conforme esperado.</li> <li>Feedback ao Usu\u00e1rio: Forne\u00e7a feedback visual ou auditivo para confirmar a execu\u00e7\u00e3o dos comandos.</li> <li>Documenta\u00e7\u00e3o: Mantenha uma documenta\u00e7\u00e3o clara dos comandos dispon\u00edveis e das funcionalidades implementadas.</li> </ul>"},{"location":"aulas/iot/modulos/modulo14.html#9-recursos-adicionais","title":"9. Recursos Adicionais","text":"<ul> <li> <p>Documenta\u00e7\u00e3o Oficial do Arduino:</p> </li> <li> <p>ESP8266WiFi Library</p> </li> <li>PubSubClient Library</li> <li>ArduinoJson Library</li> <li> <p>IFTTT Webhooks</p> </li> <li> <p>Tutoriais e Guias:</p> </li> <li> <p>Integra\u00e7\u00e3o do Arduino com Amazon Alexa</p> </li> <li>Utilizando IFTTT com Arduino</li> <li> <p>Controle por Voz com Google Assistant e Arduino</p> </li> <li> <p>V\u00eddeos Educacionais:</p> </li> <li> <p>Controlando o Arduino com Alexa</p> </li> <li>Integra\u00e7\u00e3o Arduino e Google Assistant</li> <li>Uso de IFTTT com Arduino</li> </ul>"},{"location":"aulas/iot/modulos/modulo14.html#10-exemplos-praticos","title":"10. Exemplos Pr\u00e1ticos","text":""},{"location":"aulas/iot/modulos/modulo14.html#101-sistema-de-controle-de-iluminacao-com-alexa","title":"10.1 Sistema de Controle de Ilumina\u00e7\u00e3o com Alexa","text":"<pre><code>#include &lt;ESP8266WiFi.h&gt;\n#include &lt;ESP8266HTTPClient.h&gt;\n\n// Configura\u00e7\u00f5es de rede\nconst char* ssid = \"Seu_SSID\";\nconst char* password = \"Sua_Senha\";\n\n// Endere\u00e7o do Webhook do IFTTT para ligar a luz\nconst char* serverOn = \"http://maker.ifttt.com/trigger/Luz_ON/with/key/SUA_CHAVE_IFTTT\";\n// Endere\u00e7o do Webhook do IFTTT para desligar a luz\nconst char* serverOff = \"http://maker.ifttt.com/trigger/Luz_OFF/with/key/SUA_CHAVE_IFTTT\";\n\n// Pino do LED\nconst int pinoLED = D1;\n\nvoid setup() {\n    Serial.begin(115200);\n    pinMode(pinoLED, OUTPUT);\n    digitalWrite(pinoLED, LOW);\n\n    // Conecta ao Wi-Fi\n    WiFi.begin(ssid, password);\n    Serial.print(\"Conectando ao Wi-Fi\");\n    while (WiFi.status() != WL_CONNECTED) {\n        delay(500);\n        Serial.print(\".\");\n    }\n    Serial.println(\" Conectado!\");\n}\n\nvoid ligarLuz() {\n    HTTPClient http;\n    http.begin(serverOn);\n    int httpResponseCode = http.GET();\n\n    if (httpResponseCode == 200) {\n        digitalWrite(pinoLED, HIGH);\n        Serial.println(\"Luz Ligada.\");\n    } else {\n        Serial.println(\"Falha ao ligar a luz.\");\n    }\n    http.end();\n}\n\nvoid desligarLuz() {\n    HTTPClient http;\n    http.begin(serverOff);\n    int httpResponseCode = http.GET();\n\n    if (httpResponseCode == 200) {\n        digitalWrite(pinoLED, LOW);\n        Serial.println(\"Luz Desligada.\");\n    } else {\n        Serial.println(\"Falha ao desligar a luz.\");\n    }\n    http.end();\n}\n\nvoid loop() {\n    // Nenhuma a\u00e7\u00e3o no loop principal\n    delay(1000);\n}\n</code></pre> <p>Explica\u00e7\u00e3o:</p> <ul> <li>Controle Simples: Permite ligar e desligar um LED conectado ao Arduino usando comandos de voz via Alexa.</li> <li>Webhooks IFTTT: Utiliza Webhooks diferentes para cada a\u00e7\u00e3o (ligar/desligar).</li> </ul>"},{"location":"aulas/iot/modulos/modulo14.html#102-sistema-de-monitoramento-com-alertas-por-voz","title":"10.2 Sistema de Monitoramento com Alertas por Voz","text":"<pre><code>#include &lt;ESP8266WiFi.h&gt;\n#include &lt;ESP8266HTTPClient.h&gt;\n#include \"DHT.h\"\n\n// Configura\u00e7\u00f5es de rede\nconst char* ssid = \"Seu_SSID\";\nconst char* password = \"Sua_Senha\";\n\n// Endere\u00e7o do Webhook do IFTTT para enviar alertas\nconst char* serverAlerta = \"http://maker.ifttt.com/trigger/Alerta_Temp/with/key/SUA_CHAVE_IFTTT\";\n\n// Configura\u00e7\u00f5es do DHT\n#define DHTPIN 2\n#define DHTTYPE DHT22\nDHT dht(DHTPIN, DHTTYPE);\n\n// Pino do LED de Alerta\nconst int pinoLED = D1;\n\nvoid setup() {\n    Serial.begin(115200);\n    pinMode(pinoLED, OUTPUT);\n    digitalWrite(pinoLED, LOW);\n    dht.begin();\n\n    // Conecta ao Wi-Fi\n    WiFi.begin(ssid, password);\n    Serial.print(\"Conectando ao Wi-Fi\");\n    while (WiFi.status() != WL_CONNECTED) {\n        delay(500);\n        Serial.print(\".\");\n    }\n    Serial.println(\" Conectado!\");\n}\n\nvoid enviarAlerta(float temperatura) {\n    HTTPClient http;\n    String url = String(serverAlerta) + \"?value=\" + String(temperatura);\n    http.begin(url.c_str());\n    int httpResponseCode = http.GET();\n\n    if (httpResponseCode == 200) {\n        digitalWrite(pinoLED, HIGH);\n        Serial.println(\"Alerta de Temperatura Enviado!\");\n        delay(5000);\n        digitalWrite(pinoLED, LOW);\n    } else {\n        Serial.println(\"Falha ao enviar o alerta.\");\n    }\n    http.end();\n}\n\nvoid loop() {\n    float temperatura = dht.readTemperature();\n\n    if (isnan(temperatura)) {\n        Serial.println(\"Falha na leitura do sensor DHT!\");\n        return;\n    }\n\n    Serial.print(\"Temperatura: \");\n    Serial.print(temperatura);\n    Serial.println(\" *C\");\n\n    if (temperatura &gt; 30.0) { // Limiar de temperatura\n        enviarAlerta(temperatura);\n    }\n\n    delay(10000); // Aguarda 10 segundos antes da pr\u00f3xima leitura\n}\n</code></pre> <p>Explica\u00e7\u00e3o:</p> <ul> <li>Monitoramento Cont\u00ednuo: L\u00ea a temperatura do ambiente em intervalos regulares.</li> <li>Envio de Alertas: Envia um alerta via IFTTT e aciona um LED quando a temperatura excede o limiar definido.</li> <li>Feedback Visual: Indica o envio do alerta atrav\u00e9s do LED.</li> </ul>"},{"location":"aulas/iot/modulos/modulo14.html#103-controle-de-ventilador-com-voz-e-sensor-de-temperatura","title":"10.3 Controle de Ventilador com Voz e Sensor de Temperatura","text":"<pre><code>#include &lt;ESP8266WiFi.h&gt;\n#include &lt;ESP8266HTTPClient.h&gt;\n#include \"DHT.h\"\n\n// Configura\u00e7\u00f5es de rede\nconst char* ssid = \"Seu_SSID\";\nconst char* password = \"Sua_Senha\";\n\n// Endere\u00e7o do Webhook do IFTTT para ligar o ventilador\nconst char* serverVentiladorOn = \"http://maker.ifttt.com/trigger/Ventilador_ON/with/key/SUA_CHAVE_IFTTT\";\n// Endere\u00e7o do Webhook do IFTTT para desligar o ventilador\nconst char* serverVentiladorOff = \"http://maker.ifttt.com/trigger/Ventilador_OFF/with/key/SUA_CHAVE_IFTTT\";\n\n// Configura\u00e7\u00f5es do DHT\n#define DHTPIN 2\n#define DHTTYPE DHT22\nDHT dht(DHTPIN, DHTTYPE);\n\n// Pino do ventilador (controlado por rel\u00e9)\nconst int pinoVentilador = D1;\n\nvoid setup() {\n    Serial.begin(115200);\n    pinMode(pinoVentilador, OUTPUT);\n    digitalWrite(pinoVentilador, LOW);\n    dht.begin();\n\n    // Conecta ao Wi-Fi\n    WiFi.begin(ssid, password);\n    Serial.print(\"Conectando ao Wi-Fi\");\n    while (WiFi.status() != WL_CONNECTED) {\n        delay(500);\n        Serial.print(\".\");\n    }\n    Serial.println(\" Conectado!\");\n}\n\nvoid ligarVentilador() {\n    HTTPClient http;\n    http.begin(serverVentiladorOn);\n    int httpResponseCode = http.GET();\n\n    if (httpResponseCode == 200) {\n        digitalWrite(pinoVentilador, HIGH);\n        Serial.println(\"Ventilador Ligado.\");\n    } else {\n        Serial.println(\"Falha ao ligar o ventilador.\");\n    }\n    http.end();\n}\n\nvoid desligarVentilador() {\n    HTTPClient http;\n    http.begin(serverVentiladorOff);\n    int httpResponseCode = http.GET();\n\n    if (httpResponseCode == 200) {\n        digitalWrite(pinoVentilador, LOW);\n        Serial.println(\"Ventilador Desligado.\");\n    } else {\n        Serial.println(\"Falha ao desligar o ventilador.\");\n    }\n    http.end();\n}\n\nvoid loop() {\n    float temperatura = dht.readTemperature();\n\n    if (isnan(temperatura)) {\n        Serial.println(\"Falha na leitura do sensor DHT!\");\n        return;\n    }\n\n    Serial.print(\"Temperatura: \");\n    Serial.print(temperatura);\n    Serial.println(\" *C\");\n\n    // Controle autom\u00e1tico com base na temperatura\n    if (temperatura &gt; 28.0) { // Limiar para ligar o ventilador\n        ligarVentilador();\n    } else if (temperatura &lt; 25.0) { // Limiar para desligar o ventilador\n        desligarVentilador();\n    }\n\n    delay(10000); // Aguarda 10 segundos antes da pr\u00f3xima leitura\n}\n</code></pre> <p>Explica\u00e7\u00e3o:</p> <ul> <li>Controle Autom\u00e1tico e Manual: Liga o ventilador automaticamente com base na temperatura e permite controle manual via comandos de voz.</li> <li>Rel\u00e9 para Ventilador: Utiliza um rel\u00e9 para controlar a alimenta\u00e7\u00e3o do ventilador de forma segura.</li> <li>Feedback via Serial: Monitora as a\u00e7\u00f5es no Monitor Serial para depura\u00e7\u00e3o e verifica\u00e7\u00e3o.</li> </ul>"},{"location":"aulas/iot/modulos/modulo14.html#9-conceitos-importantes","title":"9. Conceitos Importantes","text":""},{"location":"aulas/iot/modulos/modulo14.html#91-apis-de-assistentes-virtuais","title":"9.1 APIs de Assistentes Virtuais","text":"<ul> <li>Defini\u00e7\u00e3o: Interfaces que permitem a comunica\u00e7\u00e3o entre o Arduino e assistentes virtuais, facilitando o envio e recebimento de comandos.</li> <li>Uso: Permite a cria\u00e7\u00e3o de funcionalidades personalizadas e integra\u00e7\u00f5es avan\u00e7adas.</li> </ul>"},{"location":"aulas/iot/modulos/modulo14.html#92-webhooks-e-endpoints","title":"9.2 Webhooks e Endpoints","text":"<ul> <li>Webhooks: URLs que recebem requisi\u00e7\u00f5es HTTP para acionar a\u00e7\u00f5es espec\u00edficas.</li> <li>Endpoints: Pontos de acesso onde o Arduino pode enviar ou receber dados para interagir com servi\u00e7os externos.</li> </ul>"},{"location":"aulas/iot/modulos/modulo14.html#93-seguranca-na-comunicacao","title":"9.3 Seguran\u00e7a na Comunica\u00e7\u00e3o","text":"<ul> <li>Autentica\u00e7\u00e3o: Utilize chaves API e tokens para autenticar as requisi\u00e7\u00f5es.</li> <li>Criptografia: Sempre que poss\u00edvel, utilize HTTPS para proteger os dados transmitidos.</li> <li>Valida\u00e7\u00e3o de Dados: Verifique e valide os dados recebidos para evitar comandos maliciosos.</li> </ul>"},{"location":"aulas/iot/modulos/modulo14.html#94-latencia-e-resposta-em-tempo-real","title":"9.4 Lat\u00eancia e Resposta em Tempo Real","text":"<ul> <li>Import\u00e2ncia: Reduzir a lat\u00eancia \u00e9 crucial para uma experi\u00eancia de usu\u00e1rio fluida e responsiva.</li> <li>Otimiza\u00e7\u00e3o: Utilize conex\u00f5es de rede est\u00e1veis e minimize o processamento dentro das requisi\u00e7\u00f5es.</li> </ul>"},{"location":"aulas/iot/modulos/modulo14.html#95-boas-praticas-na-integracao-com-assistentes-virtuais","title":"9.5 Boas Pr\u00e1ticas na Integra\u00e7\u00e3o com Assistentes Virtuais","text":"<ul> <li>Modularidade: Mantenha o c\u00f3digo organizado e modular para facilitar manuten\u00e7\u00f5es e expans\u00f5es.</li> <li>Feedback ao Usu\u00e1rio: Forne\u00e7a feedback visual ou auditivo para confirmar a execu\u00e7\u00e3o dos comandos.</li> <li>Documenta\u00e7\u00e3o: Documente os comandos e funcionalidades implementadas para facilitar o uso e futuras modifica\u00e7\u00f5es.</li> </ul>"},{"location":"aulas/iot/modulos/modulo14.html#10-recursos-adicionais","title":"10. Recursos Adicionais","text":"<ul> <li> <p>Documenta\u00e7\u00e3o Oficial do Arduino:</p> </li> <li> <p>ESP8266WiFi Library</p> </li> <li>PubSubClient Library</li> <li>ArduinoJson Library</li> <li> <p>IFTTT Webhooks</p> </li> <li> <p>Tutoriais e Guias:</p> </li> <li> <p>Controlando o Arduino com Amazon Alexa</p> </li> <li>Integra\u00e7\u00e3o Arduino e Google Assistant</li> <li> <p>Uso de IFTTT com Arduino</p> </li> <li> <p>V\u00eddeos Educacionais:</p> </li> <li> <p>Controlando o Arduino com Alexa</p> </li> <li>Integra\u00e7\u00e3o Arduino e Google Assistant</li> <li>Uso de IFTTT com Arduino</li> </ul>"},{"location":"aulas/iot/modulos/modulo14.html#11-conclusao-do-modulo","title":"11. Conclus\u00e3o do M\u00f3dulo","text":"<p>Neste m\u00f3dulo, voc\u00ea aprendeu:</p> <ul> <li>Conceitos B\u00e1sicos e Avan\u00e7ados: Entendeu os fundamentos dos assistentes virtuais e como integr\u00e1-los com o Arduino.</li> <li>Configura\u00e7\u00e3o e Integra\u00e7\u00e3o: Aprendeu a configurar o Arduino para comunica\u00e7\u00e3o com plataformas como Amazon Alexa e Google Assistant atrav\u00e9s do IFTTT.</li> <li>Implementa\u00e7\u00e3o de Comandos de Voz: Implementou comandos de voz para controlar dispositivos conectados, como LEDs e motores.</li> <li>Projetos Pr\u00e1ticos: Desenvolveu projetos que respondem a comandos de voz e utilizam sensores para automa\u00e7\u00e3o inteligente.</li> <li>Seguran\u00e7a e Boas Pr\u00e1ticas: Compreendeu a import\u00e2ncia da seguran\u00e7a na comunica\u00e7\u00e3o e as melhores pr\u00e1ticas para integra\u00e7\u00e3o eficiente.</li> </ul> <p>Voc\u00ea completou todos os m\u00f3dulos do curso \"Programa\u00e7\u00e3o em Arduino: Conceitos Fundamentais sem Hardware\". Parab\u00e9ns pelo empenho e dedica\u00e7\u00e3o!</p>"},{"location":"aulas/iot/modulos/modulo14.html#12-proximos-passos","title":"12. Pr\u00f3ximos Passos","text":"<ul> <li>Revisar todo o conte\u00fado do curso para consolidar o aprendizado.</li> <li>Explorar projetos avan\u00e7ados que combinam m\u00faltiplos conceitos aprendidos, como rob\u00f3tica, automa\u00e7\u00e3o residencial ou sistemas de monitoramento ambiental.</li> <li>Participar de comunidades e f\u00f3runs de Arduino para trocar experi\u00eancias e obter suporte cont\u00ednuo.</li> <li>Considerar cursos avan\u00e7ados ou especializa\u00e7\u00f5es em \u00e1reas espec\u00edficas de interesse, como desenvolvimento de firmware, integra\u00e7\u00e3o com plataformas de IoT ou design de hardware.</li> <li>Desenvolver seu pr\u00f3prio portf\u00f3lio de projetos Arduino para demonstrar suas habilidades e conhecimentos adquiridos.</li> </ul> <p>Se tiver d\u00favidas ou precisar de assist\u00eancia, continue participando de comunidades de aprendizagem ou consulte os recursos adicionais fornecidos ao longo dos m\u00f3dulos.</p> <p>Parab\u00e9ns por concluir o curso! Continue explorando e criando projetos incr\u00edveis com Arduino!</p>"},{"location":"aulas/iot/modulos/modulo15.html","title":"M\u00f3dulo 15: Rob\u00f3tica com Arduino","text":"<p>Bem-vindo ao M\u00f3dulo 16 do curso \"Programa\u00e7\u00e3o em Arduino: Conceitos Fundamentais sem Hardware\". Neste m\u00f3dulo, voc\u00ea ir\u00e1 explorar o fascinante mundo da rob\u00f3tica utilizando o Arduino como c\u00e9rebro dos seus projetos. Voc\u00ea aprender\u00e1 a construir e programar rob\u00f4s que podem interagir com o ambiente, tomar decis\u00f5es aut\u00f4nomas e executar tarefas espec\u00edficas. Este m\u00f3dulo abrange desde os conceitos b\u00e1sicos de rob\u00f3tica at\u00e9 a implementa\u00e7\u00e3o de funcionalidades avan\u00e7adas, proporcionando uma compreens\u00e3o completa para criar rob\u00f4s funcionais e inteligentes.</p>"},{"location":"aulas/iot/modulos/modulo15.html#objetivos-do-modulo","title":"Objetivos do M\u00f3dulo","text":"<ul> <li>Compreender os fundamentos da rob\u00f3tica e os componentes essenciais de um rob\u00f4.</li> <li>Aprender a conectar e controlar motores e servos para movimenta\u00e7\u00e3o.</li> <li>Implementar sensores para permitir que o rob\u00f4 perceba o ambiente.</li> <li>Desenvolver algoritmos de controle para navega\u00e7\u00e3o e tomada de decis\u00f5es.</li> <li>Integrar comunica\u00e7\u00e3o sem fio para controle remoto e monitoramento.</li> <li>Resolver exerc\u00edcios pr\u00e1ticos para consolidar o conhecimento sobre rob\u00f3tica com Arduino.</li> </ul>"},{"location":"aulas/iot/modulos/modulo15.html#1-introducao-a-robotica-com-arduino","title":"1. Introdu\u00e7\u00e3o \u00e0 Rob\u00f3tica com Arduino","text":""},{"location":"aulas/iot/modulos/modulo15.html#11-o-que-e-robotica","title":"1.1 O que \u00e9 Rob\u00f3tica?","text":"<p>Rob\u00f3tica \u00e9 a \u00e1rea da tecnologia que envolve o design, constru\u00e7\u00e3o, opera\u00e7\u00e3o e uso de rob\u00f4s. Rob\u00f4s s\u00e3o m\u00e1quinas program\u00e1veis que podem executar uma s\u00e9rie de tarefas automaticamente ou sob controle humano. Com o Arduino, voc\u00ea pode construir rob\u00f4s personalizados que atendem a necessidades espec\u00edficas, desde simples ve\u00edculos movidos a controle remoto at\u00e9 rob\u00f4s aut\u00f4nomos complexos.</p>"},{"location":"aulas/iot/modulos/modulo15.html#12-importancia-da-robotica","title":"1.2 Import\u00e2ncia da Rob\u00f3tica","text":"<ul> <li>Automa\u00e7\u00e3o: Realiza tarefas repetitivas ou perigosas sem interven\u00e7\u00e3o humana.</li> <li>Educa\u00e7\u00e3o: Ferramenta poderosa para ensinar programa\u00e7\u00e3o, eletr\u00f4nica e engenharia.</li> <li>Inova\u00e7\u00e3o: Facilita o desenvolvimento de solu\u00e7\u00f5es criativas para problemas do mundo real.</li> <li>Intera\u00e7\u00e3o com o Ambiente: Rob\u00f4s podem coletar dados, realizar inspe\u00e7\u00f5es e interagir com objetos de forma precisa.</li> </ul>"},{"location":"aulas/iot/modulos/modulo15.html#13-componentes-basicos-de-um-robo-com-arduino","title":"1.3 Componentes B\u00e1sicos de um Rob\u00f4 com Arduino","text":"<ul> <li>Arduino Board: O c\u00e9rebro do rob\u00f4, respons\u00e1vel pelo processamento e controle.</li> <li>Motores e Servos: Para movimenta\u00e7\u00e3o e controle de partes m\u00f3veis.</li> <li>Sensores: Para percep\u00e7\u00e3o do ambiente (dist\u00e2ncia, luz, temperatura, etc.).</li> <li>Chassi e Estrutura: A base f\u00edsica do rob\u00f4.</li> <li>Fonte de Alimenta\u00e7\u00e3o: Baterias ou adaptadores para fornecer energia.</li> <li>M\u00f3dulos de Comunica\u00e7\u00e3o: Wi-Fi, Bluetooth ou RF para controle remoto.</li> </ul>"},{"location":"aulas/iot/modulos/modulo15.html#2-componentes-e-hardware-para-robotica","title":"2. Componentes e Hardware para Rob\u00f3tica","text":""},{"location":"aulas/iot/modulos/modulo15.html#21-motores-e-servos","title":"2.1 Motores e Servos","text":"<ul> <li>Motores DC: Utilizados para movimenta\u00e7\u00e3o cont\u00ednua, como rodas de um rob\u00f4 m\u00f3vel.</li> <li>Servos: Precisos e controlados por posi\u00e7\u00e3o, ideais para bra\u00e7os rob\u00f3ticos ou mecanismos que requerem movimentos espec\u00edficos.</li> <li>Drivers de Motor: Controlam a dire\u00e7\u00e3o e velocidade dos motores DC (exemplo: L298N).</li> </ul>"},{"location":"aulas/iot/modulos/modulo15.html#22-sensores-comuns-em-robotica","title":"2.2 Sensores Comuns em Rob\u00f3tica","text":"<ul> <li>Sensor Ultrass\u00f4nico (HC-SR04): Mede dist\u00e2ncia at\u00e9 obst\u00e1culos.</li> <li>Sensor de Linha (IR): Detecta linhas no ch\u00e3o para seguimento de trajet\u00f3ria.</li> <li>Aceler\u00f4metro e Girosc\u00f3pio (MPU6050): Detecta movimento e orienta\u00e7\u00e3o.</li> <li>Sensor de Luz (LDR): Mede intensidade de luz ambiente.</li> </ul>"},{"location":"aulas/iot/modulos/modulo15.html#23-chassi-e-estrutura","title":"2.3 Chassi e Estrutura","text":"<ul> <li>Chassis de Rob\u00f4: Dispon\u00edvel em kits ou personalizado para atender \u00e0s necessidades do projeto.</li> <li>Rod\u00edzios e Trilhos: Para movimenta\u00e7\u00e3o suave e controle de dire\u00e7\u00e3o.</li> <li>Placas de Montagem: Facilitam a fixa\u00e7\u00e3o de componentes eletr\u00f4nicos e mec\u00e2nicos.</li> </ul>"},{"location":"aulas/iot/modulos/modulo15.html#24-fonte-de-alimentacao","title":"2.4 Fonte de Alimenta\u00e7\u00e3o","text":"<ul> <li>Baterias Recarreg\u00e1veis: Fornecem mobilidade ao rob\u00f4.</li> <li>Adaptadores de Energia: Conectam o rob\u00f4 a uma fonte de energia fixa.</li> <li>Gerenciamento de Energia: Reguladores de tens\u00e3o e circuitos de prote\u00e7\u00e3o para garantir estabilidade.</li> </ul>"},{"location":"aulas/iot/modulos/modulo15.html#3-montagem-do-robo-basico","title":"3. Montagem do Rob\u00f4 B\u00e1sico","text":""},{"location":"aulas/iot/modulos/modulo15.html#31-componentes-necessarios","title":"3.1 Componentes Necess\u00e1rios","text":"<ul> <li>Arduino Uno ou Mega</li> <li>Driver de Motor L298N</li> <li>Motores DC (2 unidades)</li> <li>Sensor Ultrass\u00f4nico HC-SR04</li> <li>Sensor de Linha IR</li> <li>Chassi de Rob\u00f4</li> <li>Fonte de Alimenta\u00e7\u00e3o (baterias)</li> <li>Cabos de Conex\u00e3o</li> <li>Protoboard</li> </ul>"},{"location":"aulas/iot/modulos/modulo15.html#32-passo-a-passo-da-montagem","title":"3.2 Passo a Passo da Montagem","text":"<ol> <li>Montagem do Chassi:</li> <li>Fixe os motores DC no chassi.</li> <li> <p>Instale os rod\u00edzios nas eixos dos motores.</p> </li> <li> <p>Conex\u00e3o do Driver de Motor:</p> </li> <li>Conecte os motores DC aos terminais de sa\u00edda do L298N.</li> <li>Conecte os pinos IN1, IN2, IN3 e IN4 do L298N aos pinos digitais do Arduino.</li> <li> <p>Conecte o pino ENA e ENB aos pinos PWM do Arduino para controle de velocidade.</p> </li> <li> <p>Instala\u00e7\u00e3o dos Sensores:</p> </li> <li>Monte o sensor ultrass\u00f4nico na frente do rob\u00f4 para detec\u00e7\u00e3o de obst\u00e1culos.</li> <li> <p>Posicione o sensor de linha na parte inferior do chassi para seguimento de trajet\u00f3rias.</p> </li> <li> <p>Conex\u00e3o dos Sensores ao Arduino:</p> </li> <li>Conecte os pinos VCC e GND dos sensores ao Arduino.</li> <li> <p>Conecte os pinos de sinal dos sensores aos pinos anal\u00f3gicos ou digitais correspondentes.</p> </li> <li> <p>Fonte de Alimenta\u00e7\u00e3o:</p> </li> <li>Conecte as baterias ao L298N para alimentar os motores e o Arduino.</li> <li>Assegure-se de que as conex\u00f5es de energia estejam seguras e protegidas.</li> </ol>"},{"location":"aulas/iot/modulos/modulo15.html#4-programacao-do-robo","title":"4. Programa\u00e7\u00e3o do Rob\u00f4","text":""},{"location":"aulas/iot/modulos/modulo15.html#41-controle-de-movimentacao-basico","title":"4.1 Controle de Movimenta\u00e7\u00e3o B\u00e1sico","text":"<p>O primeiro passo na programa\u00e7\u00e3o do rob\u00f4 \u00e9 controlar a movimenta\u00e7\u00e3o dos motores. Vamos criar um c\u00f3digo simples que permite ao rob\u00f4 avan\u00e7ar, retroceder, girar \u00e0 esquerda e \u00e0 direita.</p> <pre><code>const int IN1 = 9;\nconst int IN2 = 8;\nconst int ENA = 10;\nconst int IN3 = 7;\nconst int IN4 = 6;\nconst int ENB = 5;\n\nvoid setup() {\n    pinMode(IN1, OUTPUT);\n    pinMode(IN2, OUTPUT);\n    pinMode(ENA, OUTPUT);\n    pinMode(IN3, OUTPUT);\n    pinMode(IN4, OUTPUT);\n    pinMode(ENB, OUTPUT);\n}\n\nvoid loop() {\n    // Avan\u00e7ar\n    digitalWrite(IN1, HIGH);\n    digitalWrite(IN2, LOW);\n    digitalWrite(IN3, HIGH);\n    digitalWrite(IN4, LOW);\n    analogWrite(ENA, 200);\n    analogWrite(ENB, 200);\n    delay(2000);\n\n    // Parar\n    digitalWrite(IN1, LOW);\n    digitalWrite(IN2, LOW);\n    digitalWrite(IN3, LOW);\n    digitalWrite(IN4, LOW);\n    delay(1000);\n\n    // Retroceder\n    digitalWrite(IN1, LOW);\n    digitalWrite(IN2, HIGH);\n    digitalWrite(IN3, LOW);\n    digitalWrite(IN4, HIGH);\n    analogWrite(ENA, 200);\n    analogWrite(ENB, 200);\n    delay(2000);\n\n    // Parar\n    digitalWrite(IN1, LOW);\n    digitalWrite(IN2, LOW);\n    digitalWrite(IN3, LOW);\n    digitalWrite(IN4, LOW);\n    delay(1000);\n\n    // Girar \u00e0 Esquerda\n    digitalWrite(IN1, LOW);\n    digitalWrite(IN2, HIGH);\n    digitalWrite(IN3, HIGH);\n    digitalWrite(IN4, LOW);\n    analogWrite(ENA, 200);\n    analogWrite(ENB, 200);\n    delay(1500);\n\n    // Parar\n    digitalWrite(IN1, LOW);\n    digitalWrite(IN2, LOW);\n    digitalWrite(IN3, LOW);\n    digitalWrite(IN4, LOW);\n    delay(1000);\n\n    // Girar \u00e0 Direita\n    digitalWrite(IN1, HIGH);\n    digitalWrite(IN2, LOW);\n    digitalWrite(IN3, LOW);\n    digitalWrite(IN4, HIGH);\n    analogWrite(ENA, 200);\n    analogWrite(ENB, 200);\n    delay(1500);\n\n    // Parar\n    digitalWrite(IN1, LOW);\n    digitalWrite(IN2, LOW);\n    digitalWrite(IN3, LOW);\n    digitalWrite(IN4, LOW);\n    delay(1000);\n}\n</code></pre> <p>Explica\u00e7\u00e3o:</p> <ul> <li>Dire\u00e7\u00e3o do Motor: Controlada pelos pinos IN1, IN2, IN3 e IN4. Configurar IN1 alto e IN2 baixo faz um motor girar em uma dire\u00e7\u00e3o, enquanto IN1 baixo e IN2 alto faz girar na dire\u00e7\u00e3o oposta.</li> <li>Controle de Velocidade: Utiliza PWM nos pinos ENA e ENB para ajustar a velocidade dos motores DC.</li> <li>Sequ\u00eancia de Movimentos: O loop principal faz o rob\u00f4 avan\u00e7ar, parar, retroceder, parar, girar \u00e0 esquerda, parar, girar \u00e0 direita e parar novamente.</li> </ul>"},{"location":"aulas/iot/modulos/modulo15.html#42-implementacao-de-sensores-para-navegacao","title":"4.2 Implementa\u00e7\u00e3o de Sensores para Navega\u00e7\u00e3o","text":"<p>Agora, vamos integrar os sensores ao rob\u00f4 para permitir que ele navegue de forma aut\u00f4noma, evitando obst\u00e1culos e seguindo linhas.</p> <p>Exemplo de C\u00f3digo com Sensor Ultrass\u00f4nico:</p> <pre><code>const int trigPin = A0;\nconst int echoPin = A1;\nconst int IN1 = 9;\nconst int IN2 = 8;\nconst int ENA = 10;\nconst int IN3 = 7;\nconst int IN4 = 6;\nconst int ENB = 5;\n\nlong duration;\nint distance;\n\nvoid setup() {\n    pinMode(trigPin, OUTPUT);\n    pinMode(echoPin, INPUT);\n    pinMode(IN1, OUTPUT);\n    pinMode(IN2, OUTPUT);\n    pinMode(ENA, OUTPUT);\n    pinMode(IN3, OUTPUT);\n    pinMode(IN4, OUTPUT);\n    pinMode(ENB, OUTPUT);\n    Serial.begin(9600);\n}\n\nvoid loop() {\n    // Emite um pulso ultrass\u00f4nico\n    digitalWrite(trigPin, LOW);\n    delayMicroseconds(2);\n    digitalWrite(trigPin, HIGH);\n    delayMicroseconds(10);\n    digitalWrite(trigPin, LOW);\n\n    // Calcula a dura\u00e7\u00e3o do pulso\n    duration = pulseIn(echoPin, HIGH);\n\n    // Calcula a dist\u00e2ncia em cm\n    distance = duration * 0.034 / 2;\n\n    Serial.print(\"Dist\u00e2ncia: \");\n    Serial.println(distance);\n\n    if (distance &lt; 20) { // Se um obst\u00e1culo estiver a menos de 20 cm\n        // Parar os motores\n        digitalWrite(IN1, LOW);\n        digitalWrite(IN2, LOW);\n        digitalWrite(IN3, LOW);\n        digitalWrite(IN4, LOW);\n        analogWrite(ENA, 0);\n        analogWrite(ENB, 0);\n        delay(1000);\n\n        // Girar \u00e0 direita para evitar o obst\u00e1culo\n        digitalWrite(IN1, HIGH);\n        digitalWrite(IN2, LOW);\n        digitalWrite(IN3, LOW);\n        digitalWrite(IN4, HIGH);\n        analogWrite(ENA, 200);\n        analogWrite(ENB, 200);\n        delay(1500);\n    } else {\n        // Avan\u00e7ar normalmente\n        digitalWrite(IN1, HIGH);\n        digitalWrite(IN2, LOW);\n        digitalWrite(IN3, HIGH);\n        digitalWrite(IN4, LOW);\n        analogWrite(ENA, 200);\n        analogWrite(ENB, 200);\n    }\n}\n</code></pre> <p>Explica\u00e7\u00e3o:</p> <ul> <li>Sensor Ultrass\u00f4nico: Mede a dist\u00e2ncia at\u00e9 obst\u00e1culos na frente do rob\u00f4.</li> <li>Evitar Obst\u00e1culos: Se um obst\u00e1culo for detectado a menos de 20 cm, o rob\u00f4 para e gira \u00e0 direita para evitar a colis\u00e3o.</li> <li>Movimenta\u00e7\u00e3o Aut\u00f4noma: O rob\u00f4 continua avan\u00e7ando quando n\u00e3o h\u00e1 obst\u00e1culos detectados.</li> </ul>"},{"location":"aulas/iot/modulos/modulo15.html#43-controle-remoto-via-bluetooth","title":"4.3 Controle Remoto via Bluetooth","text":"<p>Para adicionar controle manual ao seu rob\u00f4, podemos integrar um m\u00f3dulo Bluetooth que permitir\u00e1 controlar os movimentos via smartphone.</p> <p>Exemplo de C\u00f3digo para Controle Bluetooth:</p> <pre><code>#include &lt;SoftwareSerial.h&gt;\n\nSoftwareSerial bluetooth(10, 11); // RX, TX\n\nconst int IN1 = 9;\nconst int IN2 = 8;\nconst int IN3 = 7;\nconst int IN4 = 6;\nconst int ENA = 5;\nconst int ENB = 4;\n\nvoid setup() {\n    Serial.begin(9600);\n    bluetooth.begin(9600);\n\n    pinMode(IN1, OUTPUT);\n    pinMode(IN2, OUTPUT);\n    pinMode(IN3, OUTPUT);\n    pinMode(IN4, OUTPUT);\n    pinMode(ENA, OUTPUT);\n    pinMode(ENB, OUTPUT);\n}\n\nvoid loop() {\n    if (bluetooth.available()) {\n        char comando = bluetooth.read();\n        Serial.println(comando);\n\n        switch (comando) {\n            case 'F': // Avan\u00e7ar\n                digitalWrite(IN1, HIGH);\n                digitalWrite(IN2, LOW);\n                digitalWrite(IN3, HIGH);\n                digitalWrite(IN4, LOW);\n                analogWrite(ENA, 200);\n                analogWrite(ENB, 200);\n                break;\n            case 'B': // Retroceder\n                digitalWrite(IN1, LOW);\n                digitalWrite(IN2, HIGH);\n                digitalWrite(IN3, LOW);\n                digitalWrite(IN4, HIGH);\n                analogWrite(ENA, 200);\n                analogWrite(ENB, 200);\n                break;\n            case 'L': // Girar \u00e0 esquerda\n                digitalWrite(IN1, LOW);\n                digitalWrite(IN2, HIGH);\n                digitalWrite(IN3, HIGH);\n                digitalWrite(IN4, LOW);\n                analogWrite(ENA, 200);\n                analogWrite(ENB, 200);\n                break;\n            case 'R': // Girar \u00e0 direita\n                digitalWrite(IN1, HIGH);\n                digitalWrite(IN2, LOW);\n                digitalWrite(IN3, LOW);\n                digitalWrite(IN4, HIGH);\n                analogWrite(ENA, 200);\n                analogWrite(ENB, 200);\n                break;\n            case 'S': // Parar\n                digitalWrite(IN1, LOW);\n                digitalWrite(IN2, LOW);\n                digitalWrite(IN3, LOW);\n                digitalWrite(IN4, LOW);\n                analogWrite(ENA, 0);\n                analogWrite(ENB, 0);\n                break;\n        }\n    }\n}\n</code></pre> <p>Explica\u00e7\u00e3o:</p> <ul> <li>SoftwareSerial: Cria uma porta serial adicional para comunica\u00e7\u00e3o com o m\u00f3dulo Bluetooth.</li> <li>Comandos de Controle: Define comandos ('F' para avan\u00e7ar, 'B' para retroceder, 'L' para girar \u00e0 esquerda, 'R' para girar \u00e0 direita, 'S' para parar) que podem ser enviados via aplicativo de controle Bluetooth no smartphone.</li> <li>Controle Manual: Permite que o usu\u00e1rio controle o rob\u00f4 remotamente atrav\u00e9s de um dispositivo Bluetooth.</li> </ul>"},{"location":"aulas/iot/modulos/modulo15.html#5-desenvolvimento-de-projetos-roboticos","title":"5. Desenvolvimento de Projetos Rob\u00f3ticos","text":""},{"location":"aulas/iot/modulos/modulo15.html#51-robo-seguidor-de-linha","title":"5.1 Rob\u00f4 Seguidor de Linha","text":"<p>Desenvolva um rob\u00f4 que segue uma linha no ch\u00e3o utilizando sensores de linha IR. Este projeto ensina a integrar sensores para navega\u00e7\u00e3o precisa.</p>"},{"location":"aulas/iot/modulos/modulo15.html#52-braco-robotico-controlado-por-servo","title":"5.2 Bra\u00e7o Rob\u00f3tico Controlado por Servo","text":"<p>Construa um bra\u00e7o rob\u00f3tico que pode ser controlado para mover objetos, utilizando servos para articula\u00e7\u00f5es e sensores para precis\u00e3o.</p>"},{"location":"aulas/iot/modulos/modulo15.html#53-robo-autonomo-com-navegacao-inteligente","title":"5.3 Rob\u00f4 Aut\u00f4nomo com Navega\u00e7\u00e3o Inteligente","text":"<p>Crie um rob\u00f4 que navega autonomamente por um ambiente complexo, evitando obst\u00e1culos e mapeando o espa\u00e7o utilizando m\u00faltiplos sensores.</p>"},{"location":"aulas/iot/modulos/modulo15.html#6-conceitos-importantes","title":"6. Conceitos Importantes","text":""},{"location":"aulas/iot/modulos/modulo15.html#61-algoritmos-de-controle","title":"6.1 Algoritmos de Controle","text":"<ul> <li>PID (Proporcional, Integral, Derivativo): Algoritmo usado para controlar a velocidade e posi\u00e7\u00e3o de motores de forma precisa.</li> <li>FSM (M\u00e1quina de Estados Finitos): Modelo para gerenciar diferentes estados e transi\u00e7\u00f5es em sistemas de controle.</li> </ul>"},{"location":"aulas/iot/modulos/modulo15.html#62-processamento-de-sinais","title":"6.2 Processamento de Sinais","text":"<ul> <li>Filtragem: Remo\u00e7\u00e3o de ru\u00eddos das leituras dos sensores para obter dados mais precisos.</li> <li>Debouncing: T\u00e9cnica para evitar m\u00faltiplas leituras r\u00e1pidas indesejadas de sensores digitais.</li> </ul>"},{"location":"aulas/iot/modulos/modulo15.html#63-integracao-de-sensores-e-atuadores","title":"6.3 Integra\u00e7\u00e3o de Sensores e Atuadores","text":"<ul> <li>Sincroniza\u00e7\u00e3o: Garantir que os sensores e atuadores trabalhem de forma coordenada para realizar tarefas complexas.</li> <li>Calibra\u00e7\u00e3o: Ajustar sensores para garantir leituras precisas e confi\u00e1veis.</li> </ul>"},{"location":"aulas/iot/modulos/modulo15.html#64-comunicacao-entre-componentes","title":"6.4 Comunica\u00e7\u00e3o entre Componentes","text":"<ul> <li>I2C e SPI: Protocolos de comunica\u00e7\u00e3o para conectar m\u00faltiplos dispositivos e sensores ao Arduino.</li> <li>UART: Comunica\u00e7\u00e3o serial para interligar m\u00f3dulos como Bluetooth e GPS.</li> </ul>"},{"location":"aulas/iot/modulos/modulo15.html#65-boas-praticas-na-construcao-de-robos","title":"6.5 Boas Pr\u00e1ticas na Constru\u00e7\u00e3o de Rob\u00f4s","text":"<ul> <li>Organiza\u00e7\u00e3o dos Cabos: Mant\u00e9m o sistema limpo e evita curtos-circuitos.</li> <li>Montagem Segura: Assegura que todos os componentes estejam firmemente fixados para evitar movimentos indesejados.</li> <li>Teste Modular: Teste cada m\u00f3dulo (movimenta\u00e7\u00e3o, sensores, comunica\u00e7\u00e3o) separadamente antes da integra\u00e7\u00e3o completa.</li> </ul>"},{"location":"aulas/iot/modulos/modulo15.html#7-recursos-adicionais","title":"7. Recursos Adicionais","text":"<ul> <li> <p>Documenta\u00e7\u00e3o Oficial do Arduino:</p> </li> <li> <p>Motor Shield Library</p> </li> <li>Servo Library</li> <li>Wire Library (I2C)</li> <li> <p>SPI Library</p> </li> <li> <p>Tutoriais e Guias:</p> </li> <li> <p>Construindo um Rob\u00f4 Seguidor de Linha com Arduino</p> </li> <li>Bra\u00e7o Rob\u00f3tico com Arduino e Servos</li> <li> <p>Rob\u00f4 Aut\u00f4nomo com Navega\u00e7\u00e3o Inteligente</p> </li> <li> <p>V\u00eddeos Educacionais:</p> </li> <li> <p>Tutorial de Rob\u00f3tica com Arduino</p> </li> <li>Controle de Motores e Servos para Rob\u00f4s</li> <li>Integrando Sensores em Projetos Rob\u00f3ticos</li> </ul>"},{"location":"aulas/iot/modulos/modulo15.html#8-exemplos-praticos","title":"8. Exemplos Pr\u00e1ticos","text":""},{"location":"aulas/iot/modulos/modulo15.html#81-robo-seguidor-de-linha-com-pid","title":"8.1 Rob\u00f4 Seguidor de Linha com PID","text":"<p>Este exemplo demonstra como implementar um rob\u00f4 seguidor de linha utilizando sensores IR e controle PID para uma navega\u00e7\u00e3o mais precisa.</p> <pre><code>#include &lt;PID_v1.h&gt;\n\n// Pinos dos sensores de linha\nconst int sensorEsquerdo = A0;\nconst int sensorDireito = A1;\n\n// Pinos dos motores\nconst int IN1 = 9;\nconst int IN2 = 8;\nconst int ENA = 10;\nconst int IN3 = 7;\nconst int IN4 = 6;\nconst int ENB = 5;\n\n// Vari\u00e1veis para PID\ndouble Setpoint, Input, Output;\ndouble Kp=2, Ki=5, Kd=1;\n\n// Cria\u00e7\u00e3o do objeto PID\nPID myPID(&amp;Input, &amp;Output, &amp;Setpoint, Kp, Ki, Kd, DIRECT);\n\nvoid setup() {\n    pinMode(sensorEsquerdo, INPUT);\n    pinMode(sensorDireito, INPUT);\n\n    pinMode(IN1, OUTPUT);\n    pinMode(IN2, OUTPUT);\n    pinMode(IN3, OUTPUT);\n    pinMode(IN4, OUTPUT);\n    pinMode(ENA, OUTPUT);\n    pinMode(ENB, OUTPUT);\n\n    // Define o ponto de ajuste para 0 (linha central)\n    Setpoint = 0;\n\n    // Inicializa o PID\n    myPID.SetMode(AUTOMATIC);\n}\n\nvoid loop() {\n    int leituraEsquerda = analogRead(sensorEsquerdo);\n    int leituraDireita = analogRead(sensorDireito);\n\n    // Calcula o erro: diferen\u00e7a entre as leituras dos sensores\n    Input = leituraEsquerda - leituraDireita;\n\n    // Atualiza o PID\n    myPID.Compute();\n\n    // Ajusta a velocidade dos motores com base na sa\u00edda do PID\n    int velocidadeEsquerda = 200 + Output;\n    int velocidadeDireita = 200 - Output;\n\n    // Limita os valores de PWM para 0-255\n    velocidadeEsquerda = constrain(velocidadeEsquerda, 0, 255);\n    velocidadeDireita = constrain(velocidadeDireita, 0, 255);\n\n    // Define a dire\u00e7\u00e3o dos motores\n    if (velocidadeEsquerda &gt; 200) {\n        digitalWrite(IN1, HIGH);\n        digitalWrite(IN2, LOW);\n    } else {\n        digitalWrite(IN1, LOW);\n        digitalWrite(IN2, HIGH);\n    }\n\n    if (velocidadeDireita &gt; 200) {\n        digitalWrite(IN3, HIGH);\n        digitalWrite(IN4, LOW);\n    } else {\n        digitalWrite(IN3, LOW);\n        digitalWrite(IN4, HIGH);\n    }\n\n    // Aplica a velocidade\n    analogWrite(ENA, velocidadeEsquerda);\n    analogWrite(ENB, velocidadeDireita);\n\n    delay(100);\n}\n</code></pre> <p>Explica\u00e7\u00e3o:</p> <ul> <li>Controle PID: Utiliza o algoritmo PID para ajustar a velocidade dos motores com base no erro de alinhamento detectado pelos sensores de linha.</li> <li>Leitura dos Sensores: Obt\u00e9m as leituras dos sensores de linha IR para determinar a posi\u00e7\u00e3o relativa do rob\u00f4 em rela\u00e7\u00e3o \u00e0 linha.</li> <li>Ajuste de Velocidade: Calcula a diferen\u00e7a entre as leituras para determinar a dire\u00e7\u00e3o e a magnitude do ajuste necess\u00e1rio.</li> <li>Movimenta\u00e7\u00e3o Suave: Permite que o rob\u00f4 siga a linha de forma mais precisa e est\u00e1vel.</li> </ul>"},{"location":"aulas/iot/modulos/modulo15.html#82-braco-robotico-controlado-por-servo","title":"8.2 Bra\u00e7o Rob\u00f3tico Controlado por Servo","text":"<p>Este exemplo demonstra como construir e controlar um bra\u00e7o rob\u00f3tico utilizando servos para as articula\u00e7\u00f5es.</p> <pre><code>#include &lt;Servo.h&gt;\n\n// Defini\u00e7\u00e3o dos servos\nServo base;\nServo ombro;\nServo cotovelo;\nServo garra;\n\n// Pinos dos servos\nconst int pinoBase = 3;\nconst int pinoOmbro = 5;\nconst int pinoCotovelo = 6;\nconst int pinoGarra = 9;\n\nvoid setup() {\n    // Anexa os servos aos pinos\n    base.attach(pinoBase);\n    ombro.attach(pinoOmbro);\n    cotovelo.attach(pinoCotovelo);\n    garra.attach(pinoGarra);\n\n    // Inicializa as posi\u00e7\u00f5es\n    base.write(90);\n    ombro.write(90);\n    cotovelo.write(90);\n    garra.write(10);\n}\n\nvoid loop() {\n    // Movimenta a base para a esquerda\n    base.write(60);\n    delay(1000);\n\n    // Movimenta a base para a direita\n    base.write(120);\n    delay(1000);\n\n    // Movimenta o ombro para cima\n    ombro.write(60);\n    delay(1000);\n\n    // Movimenta o ombro para baixo\n    ombro.write(120);\n    delay(1000);\n\n    // Movimenta o cotovelo para cima\n    cotovelo.write(60);\n    delay(1000);\n\n    // Movimenta o cotovelo para baixo\n    cotovelo.write(120);\n    delay(1000);\n\n    // Abre a garra\n    garra.write(10);\n    delay(1000);\n\n    // Fecha a garra\n    garra.write(80);\n    delay(1000);\n}\n</code></pre> <p>Explica\u00e7\u00e3o:</p> <ul> <li>Servos para Articula\u00e7\u00f5es: Utiliza servos para controlar a base, ombro, cotovelo e garra do bra\u00e7o rob\u00f3tico.</li> <li>Movimenta\u00e7\u00e3o Coordenada: Define movimentos sequenciais para cada articula\u00e7\u00e3o, permitindo que o bra\u00e7o execute a\u00e7\u00f5es como pegar e mover objetos.</li> <li>Controle Simples: Movimenta os servos entre posi\u00e7\u00f5es predefinidas para demonstrar o funcionamento b\u00e1sico do bra\u00e7o.</li> </ul>"},{"location":"aulas/iot/modulos/modulo15.html#83-robo-autonomo-com-navegacao-inteligente","title":"8.3 Rob\u00f4 Aut\u00f4nomo com Navega\u00e7\u00e3o Inteligente","text":"<p>Este exemplo integra m\u00faltiplos sensores e algoritmos avan\u00e7ados para criar um rob\u00f4 aut\u00f4nomo que navega por um ambiente complexo.</p> <pre><code>#include &lt;Servo.h&gt;\n#include &lt;Wire.h&gt;\n#include &lt;Adafruit_Sensor.h&gt;\n#include &lt;Adafruit_MPU6050.h&gt;\n\n// Defini\u00e7\u00e3o dos servos para dire\u00e7\u00e3o\nServo servoEsquerdo;\nServo servoDireito;\n\n// Pinos dos servos\nconst int pinoServoEsquerdo = 3;\nconst int pinoServoDireito = 5;\n\n// Defini\u00e7\u00e3o dos sensores\nAdafruit_MPU6050 mpu;\n\n// Pinos dos sensores de dist\u00e2ncia\nconst int trigPin = A0;\nconst int echoPin = A1;\n\nlong duration;\nint distance;\n\nvoid setup() {\n    Serial.begin(9600);\n\n    // Inicializa os servos\n    servoEsquerdo.attach(pinoServoEsquerdo);\n    servoDireito.attach(pinoServoDireito);\n\n    // Inicializa os sensores ultrass\u00f4nicos\n    pinMode(trigPin, OUTPUT);\n    pinMode(echoPin, INPUT);\n\n    // Inicializa o MPU6050\n    if (!mpu.begin()) {\n        Serial.println(\"Falha ao inicializar o MPU6050!\");\n        while (1);\n    }\n    mpu.setAccelerometerRange(MPU6050_RANGE_8_G);\n    mpu.setGyroRange(MPU6050_RANGE_500_DEG);\n    mpu.setFilterBandwidth(MPU6050_BAND_21_HZ);\n\n    // Define a posi\u00e7\u00e3o inicial dos servos\n    servoEsquerdo.write(90);\n    servoDireito.write(90);\n}\n\nvoid loop() {\n    // Leitura do sensor ultrass\u00f4nico\n    digitalWrite(trigPin, LOW);\n    delayMicroseconds(2);\n    digitalWrite(trigPin, HIGH);\n    delayMicroseconds(10);\n    digitalWrite(trigPin, LOW);\n\n    duration = pulseIn(echoPin, HIGH);\n    distance = duration * 0.034 / 2;\n\n    Serial.print(\"Dist\u00e2ncia: \");\n    Serial.println(distance);\n\n    // Leitura do MPU6050\n    sensors_event_t a, g, temp;\n    mpu.getEvent(&amp;a, &amp;g, &amp;temp);\n\n    Serial.print(\"Aceler\u00f4metro X: \"); Serial.println(a.acceleration.x);\n    Serial.print(\"Girosc\u00f3pio Z: \"); Serial.println(g.gyro.z);\n\n    // Decis\u00e3o de movimento baseada nos sensores\n    if (distance &lt; 20) {\n        // Obst\u00e1culo detectado, girar \u00e0 direita\n        servoEsquerdo.write(60);\n        servoDireito.write(120);\n        delay(1000);\n    } else {\n        // Avan\u00e7ar\n        servoEsquerdo.write(90);\n        servoDireito.write(90);\n    }\n\n    delay(500);\n}\n</code></pre> <p>Explica\u00e7\u00e3o:</p> <ul> <li>MPU6050: Utiliza um aceler\u00f4metro e girosc\u00f3pio para detectar movimentos e inclina\u00e7\u00f5es, ajudando na estabiliza\u00e7\u00e3o e navega\u00e7\u00e3o do rob\u00f4.</li> <li>Sensor Ultrass\u00f4nico: Detecta obst\u00e1culos \u00e0 frente do rob\u00f4, permitindo que ele tome decis\u00f5es para evit\u00e1-los.</li> <li>Controle de Dire\u00e7\u00e3o Inteligente: Ajusta a dire\u00e7\u00e3o dos servos com base nas leituras dos sensores para navegar de forma aut\u00f4noma pelo ambiente.</li> </ul>"},{"location":"aulas/iot/modulos/modulo15.html#9-conceitos-importantes","title":"9. Conceitos Importantes","text":""},{"location":"aulas/iot/modulos/modulo15.html#91-algoritmos-de-navegacao","title":"9.1 Algoritmos de Navega\u00e7\u00e3o","text":"<ul> <li>Navega\u00e7\u00e3o Baseada em Sensores: Utiliza dados de sensores para tomar decis\u00f5es de movimenta\u00e7\u00e3o e evitar obst\u00e1culos.</li> <li>Mapeamento e Localiza\u00e7\u00e3o: T\u00e9cnicas para criar mapas do ambiente e determinar a posi\u00e7\u00e3o do rob\u00f4 dentro dele.</li> <li>Planejamento de Trajet\u00f3ria: Algoritmos para determinar o melhor caminho a ser seguido pelo rob\u00f4.</li> </ul>"},{"location":"aulas/iot/modulos/modulo15.html#92-controle-de-movimento","title":"9.2 Controle de Movimento","text":"<ul> <li>Controle de Velocidade: Ajuste preciso da velocidade dos motores para movimentos suaves e est\u00e1veis.</li> <li>Dire\u00e7\u00e3o e Orienta\u00e7\u00e3o: T\u00e9cnicas para controlar a dire\u00e7\u00e3o do rob\u00f4 e manter sua orienta\u00e7\u00e3o correta.</li> <li>Estabiliza\u00e7\u00e3o: Uso de sensores como aceler\u00f4metros e girosc\u00f3pios para manter o rob\u00f4 equilibrado.</li> </ul>"},{"location":"aulas/iot/modulos/modulo15.html#93-integracao-de-multiplos-sensores","title":"9.3 Integra\u00e7\u00e3o de M\u00faltiplos Sensores","text":"<ul> <li>Sincroniza\u00e7\u00e3o de Dados: Coordena\u00e7\u00e3o das leituras de m\u00faltiplos sensores para obter uma vis\u00e3o abrangente do ambiente.</li> <li>Fus\u00e3o de Sensores: Combina\u00e7\u00e3o de dados de diferentes sensores para melhorar a precis\u00e3o e confiabilidade das informa\u00e7\u00f5es.</li> </ul>"},{"location":"aulas/iot/modulos/modulo15.html#94-comunicacao-entre-componentes","title":"9.4 Comunica\u00e7\u00e3o entre Componentes","text":"<ul> <li>I2C e SPI: Protocolos para comunica\u00e7\u00e3o entre o Arduino e sensores avan\u00e7ados como o MPU6050.</li> <li>Serial Communication: Comunica\u00e7\u00e3o serial para interligar m\u00f3dulos adicionais como Bluetooth e GPS.</li> </ul>"},{"location":"aulas/iot/modulos/modulo15.html#95-boas-praticas-na-construcao-de-robos","title":"9.5 Boas Pr\u00e1ticas na Constru\u00e7\u00e3o de Rob\u00f4s","text":"<ul> <li>Modularidade: Desenvolver sistemas modulares para facilitar atualiza\u00e7\u00f5es e manuten\u00e7\u00f5es.</li> <li>Organiza\u00e7\u00e3o de Cabos: Manter os cabos organizados para evitar interfer\u00eancias e facilitar a depura\u00e7\u00e3o.</li> <li>Teste e Depura\u00e7\u00e3o: Testar cada componente separadamente antes da integra\u00e7\u00e3o completa para identificar e resolver problemas rapidamente.</li> </ul>"},{"location":"aulas/iot/modulos/modulo15.html#10-recursos-adicionais","title":"10. Recursos Adicionais","text":"<ul> <li> <p>Documenta\u00e7\u00e3o Oficial do Arduino:</p> </li> <li> <p>Motor Shield Library</p> </li> <li>Servo Library</li> <li>Wire Library (I2C)</li> <li> <p>Adafruit MPU6050 Library</p> </li> <li> <p>Tutoriais e Guias:</p> </li> <li> <p>Construindo um Rob\u00f4 Seguidor de Linha com PID</p> </li> <li>Bra\u00e7o Rob\u00f3tico com Arduino e Servos</li> <li> <p>Rob\u00f4 Aut\u00f4nomo com Navega\u00e7\u00e3o Inteligente</p> </li> <li> <p>V\u00eddeos Educacionais:</p> </li> <li> <p>Tutorial de Rob\u00f3tica com Arduino</p> </li> <li>Controle de Motores e Servos para Rob\u00f4s</li> <li>Integrando Sensores em Projetos Rob\u00f3ticos</li> </ul>"},{"location":"aulas/iot/modulos/modulo15.html#11-conclusao-do-modulo","title":"11. Conclus\u00e3o do M\u00f3dulo","text":"<p>Neste m\u00f3dulo, voc\u00ea aprendeu:</p> <ul> <li>Fundamentos da Rob\u00f3tica: Entendeu os componentes essenciais e como eles interagem para formar um rob\u00f4 funcional.</li> <li>Controle de Movimenta\u00e7\u00e3o: Aprendeu a controlar motores e servos para movimenta\u00e7\u00e3o precisa.</li> <li>Integra\u00e7\u00e3o de Sensores: Implementou sensores para percep\u00e7\u00e3o do ambiente e navega\u00e7\u00e3o aut\u00f4noma.</li> <li>Algoritmos de Controle: Utilizou algoritmos como PID para melhorar a precis\u00e3o e estabilidade do rob\u00f4.</li> <li>Projetos Pr\u00e1ticos: Desenvolveu projetos como rob\u00f4s seguidores de linha, bra\u00e7os rob\u00f3ticos e rob\u00f4s aut\u00f4nomos com navega\u00e7\u00e3o inteligente.</li> <li>Boas Pr\u00e1ticas: Compreendeu a import\u00e2ncia da organiza\u00e7\u00e3o, modularidade e teste na constru\u00e7\u00e3o de rob\u00f4s.</li> </ul> <p>Voc\u00ea est\u00e1 agora preparado para avan\u00e7ar para projetos mais complexos e integrar rob\u00f4s com outras tecnologias, ampliando ainda mais as possibilidades dos seus projetos com Arduino.</p>"},{"location":"aulas/iot/modulos/modulo15.html#12-proximos-passos","title":"12. Pr\u00f3ximos Passos","text":"<ul> <li>Revisar todo o conte\u00fado do curso para consolidar o aprendizado.</li> <li>Explorar projetos avan\u00e7ados que combinam m\u00faltiplos conceitos aprendidos, como integra\u00e7\u00e3o com IoT, automa\u00e7\u00e3o residencial ou sistemas de monitoramento ambiental.</li> <li>Participar de comunidades e f\u00f3runs de Arduino para trocar experi\u00eancias e obter suporte cont\u00ednuo.</li> <li>Considerar cursos avan\u00e7ados ou especializa\u00e7\u00f5es em \u00e1reas espec\u00edficas de interesse, como rob\u00f3tica avan\u00e7ada, intelig\u00eancia artificial ou design de hardware.</li> <li>Desenvolver seu pr\u00f3prio portf\u00f3lio de projetos Arduino para demonstrar suas habilidades e conhecimentos adquiridos.</li> </ul> <p>Se tiver d\u00favidas ou precisar de assist\u00eancia, continue participando de comunidades de aprendizagem ou consulte os recursos adicionais fornecidos ao longo dos m\u00f3dulos.</p> <p>**Parab\u00e9ns por concluir o curso! Continue explorando e criando projetos incr\u00edveis com Arduino!</p>"},{"location":"aulas/iot/modulos/modulo16.html","title":"M\u00f3dulo 16: Controle Avan\u00e7ado e Algoritmos de Controle","text":"<p>Bem-vindo ao M\u00f3dulo 15 do curso \"Programa\u00e7\u00e3o em Arduino: Conceitos Fundamentais sem Hardware\". Neste m\u00f3dulo, voc\u00ea ir\u00e1 explorar t\u00e9cnicas avan\u00e7adas de controle e algoritmos de controle que permitem ao Arduino gerenciar sistemas complexos de maneira eficiente e precisa. Abordaremos desde os fundamentos do controle PID at\u00e9 a implementa\u00e7\u00e3o de m\u00e1quinas de estados finitos (FSM), proporcionando ferramentas essenciais para o desenvolvimento de projetos mais sofisticados e robustos.</p>"},{"location":"aulas/iot/modulos/modulo16.html#objetivos-do-modulo","title":"Objetivos do M\u00f3dulo","text":"<ul> <li>Compreender os fundamentos dos algoritmos de controle PID e FSM.</li> <li>Implementar controle PID no Arduino para aplica\u00e7\u00f5es como regula\u00e7\u00e3o de temperatura e velocidade de motores.</li> <li>Desenvolver m\u00e1quinas de estados finitos para gerenciar diferentes modos de opera\u00e7\u00e3o em sistemas automatizados.</li> <li>Aplicar t\u00e9cnicas avan\u00e7adas de filtragem de dados para melhorar a precis\u00e3o das leituras dos sensores.</li> <li>Resolver exerc\u00edcios pr\u00e1ticos para consolidar o conhecimento sobre controle avan\u00e7ado com Arduino.</li> </ul>"},{"location":"aulas/iot/modulos/modulo16.html#1-introducao-aos-algoritmos-de-controle","title":"1. Introdu\u00e7\u00e3o aos Algoritmos de Controle","text":""},{"location":"aulas/iot/modulos/modulo16.html#11-o-que-e-um-algoritmo-de-controle","title":"1.1 O que \u00e9 um Algoritmo de Controle?","text":"<p>Algoritmos de controle s\u00e3o procedimentos matem\u00e1ticos utilizados para regular o comportamento de sistemas din\u00e2micos. Eles processam informa\u00e7\u00f5es de entrada (como dados de sensores) e determinam as a\u00e7\u00f5es de sa\u00edda necess\u00e1rias para atingir um objetivo espec\u00edfico, como manter uma temperatura constante ou controlar a velocidade de um motor.</p>"},{"location":"aulas/iot/modulos/modulo16.html#12-importancia-dos-algoritmos-de-controle","title":"1.2 Import\u00e2ncia dos Algoritmos de Controle","text":"<ul> <li>Precis\u00e3o e Estabilidade: Garantem que o sistema opere de forma precisa e est\u00e1vel, mesmo diante de varia\u00e7\u00f5es externas.</li> <li>Automa\u00e7\u00e3o: Permitem que sistemas automatizados respondam de maneira inteligente a mudan\u00e7as no ambiente.</li> <li>Efici\u00eancia: Otimizam o desempenho do sistema, reduzindo desperd\u00edcios e melhorando a efici\u00eancia energ\u00e9tica.</li> </ul>"},{"location":"aulas/iot/modulos/modulo16.html#13-tipos-de-algoritmos-de-controle","title":"1.3 Tipos de Algoritmos de Controle","text":"<ul> <li>Controle P (Proporcional): Ajusta a sa\u00edda proporcionalmente ao erro atual.</li> <li>Controle PI (Proporcional-Integral): Combina controle proporcional com a soma do erro ao longo do tempo.</li> <li>Controle PID (Proporcional-Integral-Derivativo): Adiciona um termo derivativo para prever futuras tend\u00eancias do erro.</li> <li>M\u00e1quinas de Estados Finitos (FSM): Gerenciam diferentes estados e transi\u00e7\u00f5es de um sistema com base em eventos ou condi\u00e7\u00f5es.</li> </ul>"},{"location":"aulas/iot/modulos/modulo16.html#2-controle-pid-no-arduino","title":"2. Controle PID no Arduino","text":""},{"location":"aulas/iot/modulos/modulo16.html#21-fundamentos-do-controle-pid","title":"2.1 Fundamentos do Controle PID","text":"<p>O controle PID \u00e9 uma t\u00e9cnica amplamente utilizada para regular sistemas din\u00e2micos. Ele consiste em tr\u00eas componentes:</p> <ul> <li>Proporcional (P): Reage ao erro atual.</li> <li>Integral (I): Reage \u00e0 soma dos erros passados.</li> <li>Derivativo (D): Reage \u00e0 taxa de varia\u00e7\u00e3o do erro.</li> </ul>"},{"location":"aulas/iot/modulos/modulo16.html#22-implementacao-do-controle-pid","title":"2.2 Implementa\u00e7\u00e3o do Controle PID","text":"<p>Para implementar o controle PID no Arduino, utilizaremos a biblioteca PID_v1, que facilita o processo de ajuste e aplica\u00e7\u00e3o do algoritmo.</p>"},{"location":"aulas/iot/modulos/modulo16.html#23-exemplo-de-codigo-para-controle-de-temperatura-com-pid","title":"2.3 Exemplo de C\u00f3digo para Controle de Temperatura com PID","text":"<pre><code>#include &lt;PID_v1.h&gt;\n\n// Defini\u00e7\u00e3o dos pinos\nconst int pinoSensor = A0; // Sensor de temperatura\nconst int pinoAquecedor = 9; // Atuador (exemplo: aquecedor)\n\n// Vari\u00e1veis para leitura do sensor\ndouble Setpoint, Input, Output;\n\n// Par\u00e2metros do PID\ndouble Kp = 2.0, Ki = 5.0, Kd = 1.0;\n\n// Cria\u00e7\u00e3o do objeto PID\nPID myPID(&amp;Input, &amp;Output, &amp;Setpoint, Kp, Ki, Kd, DIRECT);\n\nvoid setup() {\n    Serial.begin(9600);\n    pinMode(pinoAquecedor, OUTPUT);\n\n    // Define o ponto de ajuste (temperatura desejada)\n    Setpoint = 25.0; // 25\u00b0C\n\n    // Inicializa o PID\n    myPID.SetMode(AUTOMATIC);\n}\n\nvoid loop() {\n    // Leitura do sensor de temperatura\n    int leituraAnalogica = analogRead(pinoSensor);\n    Input = leituraAnalogica * (5.0 / 1023.0) * 100; // Convers\u00e3o exemplo\n\n    // Computa o PID\n    myPID.Compute();\n\n    // Controla o aquecedor\n    analogWrite(pinoAquecedor, Output);\n\n    // Exibe os valores no Monitor Serial\n    Serial.print(\"Temperatura: \");\n    Serial.print(Input);\n    Serial.print(\"\u00b0C\\tOutput: \");\n    Serial.println(Output);\n\n    delay(1000);\n}\n</code></pre> <p>Explica\u00e7\u00e3o:</p> <ul> <li>Leitura do Sensor: Obt\u00e9m a temperatura atual do sensor conectado ao pino A0.</li> <li>Algoritmo PID: Calcula a sa\u00edda necess\u00e1ria para ajustar a temperatura em dire\u00e7\u00e3o ao ponto de ajuste definido.</li> <li>Controle do Atuador: Ajusta a pot\u00eancia do aquecedor com base na sa\u00edda do PID.</li> <li>Monitoramento: Exibe a temperatura e a sa\u00edda do PID no Monitor Serial para an\u00e1lise e ajustes.</li> </ul>"},{"location":"aulas/iot/modulos/modulo16.html#3-maquinas-de-estados-finitos-fsm","title":"3. M\u00e1quinas de Estados Finitos (FSM)","text":""},{"location":"aulas/iot/modulos/modulo16.html#31-conceitos-basicos-de-fsm","title":"3.1 Conceitos B\u00e1sicos de FSM","text":"<p>Uma M\u00e1quina de Estados Finitos (FSM) \u00e9 um modelo computacional usado para projetar algoritmos que podem estar em um n\u00famero finito de estados. As transi\u00e7\u00f5es entre esses estados s\u00e3o determinadas por eventos ou condi\u00e7\u00f5es espec\u00edficas.</p>"},{"location":"aulas/iot/modulos/modulo16.html#32-implementacao-de-fsm-no-arduino","title":"3.2 Implementa\u00e7\u00e3o de FSM no Arduino","text":"<p>FSMs s\u00e3o \u00fateis para gerenciar diferentes modos de opera\u00e7\u00e3o em sistemas complexos, como rob\u00f4s que precisam alternar entre modos de movimento, detec\u00e7\u00e3o e resposta.</p>"},{"location":"aulas/iot/modulos/modulo16.html#33-exemplo-de-codigo-para-fsm-em-um-sistema-de-iluminacao-automatica","title":"3.3 Exemplo de C\u00f3digo para FSM em um Sistema de Ilumina\u00e7\u00e3o Autom\u00e1tica","text":"<pre><code>enum Estado {\n    APAGADO,\n    LIGANDO,\n    LIGADO,\n    DESLIGANDO\n};\n\nEstado estadoAtual = APAGADO;\n\nconst int pinoLuz = 8;\nconst int tempoTransicao = 2000; // 2 segundos\n\nunsigned long tempoInicio;\n\nvoid setup() {\n    pinMode(pinoLuz, OUTPUT);\n    digitalWrite(pinoLuz, LOW);\n}\n\nvoid loop() {\n    switch (estadoAtual) {\n        case APAGADO:\n            // Aguarda comando para ligar\n            if (/* condi\u00e7\u00e3o para ligar */) {\n                estadoAtual = LIGANDO;\n                tempoInicio = millis();\n            }\n            break;\n\n        case LIGANDO:\n            digitalWrite(pinoLuz, HIGH);\n            if (millis() - tempoInicio &gt;= tempoTransicao) {\n                estadoAtual = LIGADO;\n            }\n            break;\n\n        case LIGADO:\n            // Aguarda comando para desligar\n            if (/* condi\u00e7\u00e3o para desligar */) {\n                estadoAtual = DESLIGANDO;\n                tempoInicio = millis();\n            }\n            break;\n\n        case DESLIGANDO:\n            digitalWrite(pinoLuz, LOW);\n            if (millis() - tempoInicio &gt;= tempoTransicao) {\n                estadoAtual = APAGADO;\n            }\n            break;\n    }\n}\n</code></pre> <p>Explica\u00e7\u00e3o:</p> <ul> <li>Estados Definidos: APAGADO, LIGANDO, LIGADO e DESLIGANDO representam os diferentes modos do sistema de ilumina\u00e7\u00e3o.</li> <li>Transi\u00e7\u00f5es: As mudan\u00e7as de estado s\u00e3o acionadas por condi\u00e7\u00f5es espec\u00edficas, como um bot\u00e3o sendo pressionado.</li> <li>Temporiza\u00e7\u00e3o: Utiliza <code>millis()</code> para gerenciar o tempo de transi\u00e7\u00e3o entre os estados.</li> </ul>"},{"location":"aulas/iot/modulos/modulo16.html#4-filtragem-avancada-de-dados","title":"4. Filtragem Avan\u00e7ada de Dados","text":""},{"location":"aulas/iot/modulos/modulo16.html#41-filtros-passa-baixa-passa-alta-e-passa-banda","title":"4.1 Filtros Passa-Baixa, Passa-Alta e Passa-Banda","text":"<p>Filtros s\u00e3o utilizados para remover ru\u00eddos e melhorar a qualidade dos dados dos sensores.</p> <ul> <li>Passa-Baixa: Permite a passagem de frequ\u00eancias abaixo de um determinado corte, atenuando as acima.</li> <li>Passa-Alta: Permite a passagem de frequ\u00eancias acima de um determinado corte, atenuando as abaixo.</li> <li>Passa-Banda: Permite a passagem de uma faixa espec\u00edfica de frequ\u00eancias, atenuando as fora dessa faixa.</li> </ul>"},{"location":"aulas/iot/modulos/modulo16.html#42-implementacao-de-filtros-digitais-no-arduino","title":"4.2 Implementa\u00e7\u00e3o de Filtros Digitais no Arduino","text":"<p>Os filtros digitais podem ser implementados diretamente no c\u00f3digo do Arduino para processar os dados dos sensores em tempo real.</p>"},{"location":"aulas/iot/modulos/modulo16.html#43-exemplo-de-codigo-para-filtro-de-media-movel","title":"4.3 Exemplo de C\u00f3digo para Filtro de M\u00e9dia M\u00f3vel","text":"<pre><code>const int pinoSensor = A0;\nconst int tamanhoJanela = 5;\nint leituras[tamanhoJanela];\nint indice = 0;\nlong soma = 0;\nfloat media = 0;\n\nvoid setup() {\n    Serial.begin(9600);\n    for (int i = 0; i &lt; tamanhoJanela; i++) {\n        leituras[i] = 0;\n    }\n}\n\nvoid loop() {\n    // Leitura atual\n    int leitura = analogRead(pinoSensor);\n\n    // Subtrai a leitura que ser\u00e1 descartada\n    soma = soma - leituras[indice];\n\n    // Adiciona a nova leitura\n    leituras[indice] = leitura;\n    soma = soma + leituras[indice];\n\n    // Avan\u00e7a o \u00edndice e reinicia se necess\u00e1rio\n    indice = (indice + 1) % tamanhoJanela;\n\n    // Calcula a m\u00e9dia\n    media = soma / (float)tamanhoJanela;\n\n    // Exibe a m\u00e9dia\n    Serial.print(\"M\u00e9dia: \");\n    Serial.println(media);\n\n    delay(500);\n}\n</code></pre> <p>Explica\u00e7\u00e3o:</p> <ul> <li>Janela de M\u00e9dia: Calcula a m\u00e9dia das \u00faltimas 5 leituras para suavizar os dados.</li> <li>Atualiza\u00e7\u00e3o da Soma: Subtrai a leitura mais antiga e adiciona a nova para manter a soma atualizada.</li> <li>C\u00e1lculo da M\u00e9dia: Divide a soma pelo tamanho da janela para obter a m\u00e9dia m\u00f3vel.</li> <li>Aplica\u00e7\u00e3o Pr\u00e1tica: Reduz flutua\u00e7\u00f5es r\u00e1pidas nos dados dos sensores, melhorando a precis\u00e3o das medi\u00e7\u00f5es.</li> </ul>"},{"location":"aulas/iot/modulos/modulo16.html#5-exercicios-praticos","title":"5. Exerc\u00edcios Pr\u00e1ticos","text":""},{"location":"aulas/iot/modulos/modulo16.html#exercicio-1-implementar-um-controle-pid-para-velocidade-de-motor-dc","title":"Exerc\u00edcio 1: Implementar um Controle PID para Velocidade de Motor DC","text":"<ul> <li> <p>Tarefa: Desenvolva um sistema que regula a velocidade de um motor DC utilizando controle PID. Ajuste os par\u00e2metros PID para alcan\u00e7ar uma resposta est\u00e1vel e eficiente.</p> </li> <li> <p>Dicas:</p> </li> <li>Utilize um encoder para medir a velocidade real do motor.</li> <li>Teste diferentes valores de Kp, Ki e Kd para encontrar os melhores ajustes.</li> <li> <p>Monitore a velocidade e o erro no Monitor Serial para ajustes finos.</p> </li> <li> <p>Exemplo de C\u00f3digo:   Utilize o exemplo de controle de temperatura apresentado na se\u00e7\u00e3o 2.3, adaptando-o para controlar a velocidade do motor com base nas leituras do encoder.</p> </li> </ul>"},{"location":"aulas/iot/modulos/modulo16.html#exercicio-2-desenvolver-uma-maquina-de-estados-para-um-sistema-de-alarme","title":"Exerc\u00edcio 2: Desenvolver uma M\u00e1quina de Estados para um Sistema de Alarme","text":"<ul> <li> <p>Tarefa: Crie uma m\u00e1quina de estados finitos para gerenciar um sistema de alarme que alterna entre os estados APAGADO, ARMADO e ALARMANDO com base em detec\u00e7\u00f5es de sensores de movimento e bot\u00f5es de controle.</p> </li> <li> <p>Dicas:</p> </li> <li>Defina claramente os estados e as transi\u00e7\u00f5es entre eles.</li> <li>Utilize vari\u00e1veis globais para manter o estado atual.</li> <li> <p>Implemente fun\u00e7\u00f5es para cada transi\u00e7\u00e3o de estado.</p> </li> <li> <p>Exemplo de C\u00f3digo:   Utilize o exemplo de FSM apresentado na se\u00e7\u00e3o 3.3, adaptando-o para incluir um estado ARMADO e condi\u00e7\u00f5es de transi\u00e7\u00e3o baseadas em sensores de movimento.</p> </li> </ul>"},{"location":"aulas/iot/modulos/modulo16.html#exercicio-3-aplicar-filtros-digitais-em-leituras-de-sensores","title":"Exerc\u00edcio 3: Aplicar Filtros Digitais em Leituras de Sensores","text":"<ul> <li> <p>Tarefa: Implemente diferentes tipos de filtros (m\u00e9dia m\u00f3vel, passa-baixa) nas leituras de um sensor de temperatura para melhorar a precis\u00e3o dos dados.</p> </li> <li> <p>Dicas:</p> </li> <li>Compare os resultados dos diferentes filtros.</li> <li>Ajuste o tamanho da janela de m\u00e9dia m\u00f3vel para observar os efeitos.</li> <li> <p>Visualize as leituras filtradas e n\u00e3o filtradas no Monitor Serial.</p> </li> <li> <p>Exemplo de C\u00f3digo:   Utilize o exemplo de filtro de m\u00e9dia m\u00f3vel apresentado na se\u00e7\u00e3o 4.3 e experimente implementar um filtro passa-baixa simples para comparar os resultados.</p> </li> </ul>"},{"location":"aulas/iot/modulos/modulo16.html#6-conceitos-importantes","title":"6. Conceitos Importantes","text":""},{"location":"aulas/iot/modulos/modulo16.html#61-algoritmos-de-controle-pid","title":"6.1 Algoritmos de Controle PID","text":"<ul> <li>Defini\u00e7\u00e3o: Algoritmo que ajusta a sa\u00edda de um sistema com base no erro atual, acumulado e na taxa de varia\u00e7\u00e3o do erro.</li> <li>Aplica\u00e7\u00f5es: Controle de temperatura, velocidade de motores, posi\u00e7\u00e3o de servos.</li> <li>Ajuste de Par\u00e2metros: Import\u00e2ncia de ajustar corretamente Kp, Ki e Kd para obter uma resposta adequada.</li> </ul>"},{"location":"aulas/iot/modulos/modulo16.html#62-maquinas-de-estados-finitos-fsm","title":"6.2 M\u00e1quinas de Estados Finitos (FSM)","text":"<ul> <li>Defini\u00e7\u00e3o: Modelo de computa\u00e7\u00e3o que consiste em um n\u00famero finito de estados e transi\u00e7\u00f5es entre eles baseadas em eventos ou condi\u00e7\u00f5es.</li> <li>Vantagens: Facilita o gerenciamento de sistemas complexos com m\u00faltiplos modos de opera\u00e7\u00e3o.</li> <li>Implementa\u00e7\u00e3o: Utiliza\u00e7\u00e3o de estruturas de controle como <code>switch-case</code> no Arduino para gerenciar estados.</li> </ul>"},{"location":"aulas/iot/modulos/modulo16.html#63-filtragem-de-dados","title":"6.3 Filtragem de Dados","text":"<ul> <li>Objetivo: Remover ru\u00eddos e melhorar a qualidade dos dados coletados dos sensores.</li> <li>T\u00e9cnicas: M\u00e9dia m\u00f3vel, filtros passa-baixa, filtros Kalman.</li> <li>Aplica\u00e7\u00f5es: Processamento de sinais de sensores, estabiliza\u00e7\u00e3o de leituras.</li> </ul>"},{"location":"aulas/iot/modulos/modulo16.html#64-controle-de-movimento-avancado","title":"6.4 Controle de Movimento Avan\u00e7ado","text":"<ul> <li>Trajet\u00f3rias Suaves: Planejamento de movimentos que evitam oscila\u00e7\u00f5es e movimentos bruscos.</li> <li>Controle de Acelera\u00e7\u00e3o: Ajuste gradual da velocidade para evitar sobrecargas nos atuadores.</li> <li>Sincroniza\u00e7\u00e3o de Atuadores: Coordena\u00e7\u00e3o de m\u00faltiplos motores e servos para movimentos complexos.</li> </ul>"},{"location":"aulas/iot/modulos/modulo16.html#65-boas-praticas-no-uso-de-algoritmos-de-controle","title":"6.5 Boas Pr\u00e1ticas no Uso de Algoritmos de Controle","text":"<ul> <li>Teste e Valida\u00e7\u00e3o: Testar os algoritmos em diferentes condi\u00e7\u00f5es para garantir robustez.</li> <li>Monitoramento: Utilizar o Monitor Serial para acompanhar o comportamento dos algoritmos em tempo real.</li> <li>Documenta\u00e7\u00e3o: Manter registros claros dos par\u00e2metros utilizados e dos resultados obtidos durante os testes.</li> </ul>"},{"location":"aulas/iot/modulos/modulo16.html#7-recursos-adicionais","title":"7. Recursos Adicionais","text":"<ul> <li> <p>Documenta\u00e7\u00e3o Oficial do Arduino:</p> </li> <li> <p>PID Library</p> </li> <li>Servo Library</li> <li> <p>State Machine Library</p> </li> <li> <p>Tutoriais e Guias:</p> </li> <li> <p>Implementando Controle PID no Arduino</p> </li> <li>M\u00e1quinas de Estados Finitos com Arduino</li> <li> <p>Filtragem de Dados em Projetos Arduino</p> </li> <li> <p>V\u00eddeos Educacionais:</p> </li> <li> <p>Controle PID com Arduino</p> </li> <li>M\u00e1quinas de Estados Finitos para Iniciantes</li> <li>T\u00e9cnicas de Filtragem de Dados no Arduino</li> </ul>"},{"location":"aulas/iot/modulos/modulo16.html#8-exemplos-praticos","title":"8. Exemplos Pr\u00e1ticos","text":""},{"location":"aulas/iot/modulos/modulo16.html#81-controle-de-temperatura-com-pid","title":"8.1 Controle de Temperatura com PID","text":"<p>Este exemplo demonstra como implementar um controlador PID para regular a temperatura de um ambiente utilizando um sensor de temperatura e um atuador (como um aquecedor).</p> <pre><code>#include &lt;PID_v1.h&gt;\n\n// Defini\u00e7\u00e3o dos pinos\nconst int pinoSensor = A0; // Sensor de temperatura\nconst int pinoAquecedor = 9; // Atuador (exemplo: aquecedor)\n\n// Vari\u00e1veis para leitura do sensor\ndouble Setpoint, Input, Output;\n\n// Par\u00e2metros do PID\ndouble Kp = 2.0, Ki = 5.0, Kd = 1.0;\n\n// Cria\u00e7\u00e3o do objeto PID\nPID myPID(&amp;Input, &amp;Output, &amp;Setpoint, Kp, Ki, Kd, DIRECT);\n\nvoid setup() {\n    Serial.begin(9600);\n    pinMode(pinoAquecedor, OUTPUT);\n\n    // Define o ponto de ajuste (temperatura desejada)\n    Setpoint = 25.0; // 25\u00b0C\n\n    // Inicializa o PID\n    myPID.SetMode(AUTOMATIC);\n}\n\nvoid loop() {\n    // Leitura do sensor de temperatura\n    int leituraAnalogica = analogRead(pinoSensor);\n    Input = leituraAnalogica * (5.0 / 1023.0) * 100; // Convers\u00e3o exemplo\n\n    // Computa o PID\n    myPID.Compute();\n\n    // Controla o aquecedor\n    analogWrite(pinoAquecedor, Output);\n\n    // Exibe os valores no Monitor Serial\n    Serial.print(\"Temperatura: \");\n    Serial.print(Input);\n    Serial.print(\"\u00b0C\\tOutput: \");\n    Serial.println(Output);\n\n    delay(1000);\n}\n</code></pre> <p>Explica\u00e7\u00e3o:</p> <ul> <li>Leitura do Sensor: Obt\u00e9m a temperatura atual do sensor conectado ao pino A0.</li> <li>Algoritmo PID: Calcula a sa\u00edda necess\u00e1ria para ajustar a temperatura em dire\u00e7\u00e3o ao ponto de ajuste definido.</li> <li>Controle do Atuador: Ajusta a pot\u00eancia do aquecedor com base na sa\u00edda do PID.</li> <li>Monitoramento: Exibe a temperatura e a sa\u00edda do PID no Monitor Serial para an\u00e1lise e ajustes.</li> </ul>"},{"location":"aulas/iot/modulos/modulo16.html#82-maquina-de-estados-para-sistema-de-alarme","title":"8.2 M\u00e1quina de Estados para Sistema de Alarme","text":"<p>Este exemplo demonstra como utilizar uma m\u00e1quina de estados finitos para gerenciar um sistema de alarme com diferentes modos de opera\u00e7\u00e3o.</p> <pre><code>enum Estado {\n    APAGADO,\n    ARMADO,\n    ALARMANDO\n};\n\nEstado estadoAtual = APAGADO;\n\nconst int pinoSensor = 7; // Sensor de movimento\nconst int pinoAlarme = 8; // Atuador (exemplo: buzzer)\nconst int pinoBotao = 2; // Bot\u00e3o de controle\n\nunsigned long tempoInicio;\n\nvoid setup() {\n    Serial.begin(9600);\n    pinMode(pinoSensor, INPUT);\n    pinMode(pinoAlarme, OUTPUT);\n    pinMode(pinoBotao, INPUT_PULLUP);\n}\n\nvoid loop() {\n    bool botaoPressionado = digitalRead(pinoBotao) == LOW;\n    bool movimentoDetectado = digitalRead(pinoSensor) == HIGH;\n\n    switch (estadoAtual) {\n        case APAGADO:\n            if (botaoPressionado) {\n                estadoAtual = ARMADO;\n                Serial.println(\"Sistema Armado.\");\n            }\n            break;\n\n        case ARMADO:\n            if (movimentoDetectado) {\n                estadoAtual = ALARMANDO;\n                tempoInicio = millis();\n                Serial.println(\"Movimento Detectado! Alarme Ativado!\");\n            }\n            if (botaoPressionado) {\n                estadoAtual = APAGADO;\n                Serial.println(\"Sistema Desarmado.\");\n            }\n            break;\n\n        case ALARMANDO:\n            digitalWrite(pinoAlarme, HIGH);\n            if (millis() - tempoInicio &gt;= 5000) { // Alarme por 5 segundos\n                digitalWrite(pinoAlarme, LOW);\n                estadoAtual = APAGADO;\n                Serial.println(\"Alarme Desativado.\");\n            }\n            break;\n    }\n}\n</code></pre> <p>Explica\u00e7\u00e3o:</p> <ul> <li>Estados Definidos: APAGADO, ARMADO e ALARMANDO representam os diferentes modos do sistema de alarme.</li> <li>Transi\u00e7\u00f5es: Mudan\u00e7as de estado s\u00e3o acionadas pelo bot\u00e3o de controle e pela detec\u00e7\u00e3o de movimento.</li> <li>Acionamento do Alarme: Quando em estado ALARMANDO, o alarme \u00e9 ativado por 5 segundos antes de retornar ao estado APAGADO.</li> </ul>"},{"location":"aulas/iot/modulos/modulo16.html#83-aplicacao-de-filtros-passa-baixa-em-leituras-de-sensor","title":"8.3 Aplica\u00e7\u00e3o de Filtros Passa-Baixa em Leituras de Sensor","text":"<p>Este exemplo demonstra como implementar um filtro passa-baixa para suavizar as leituras de um sensor de temperatura.</p> <pre><code>const int pinoSensor = A0;\nconst float alpha = 0.1; // Constante do filtro (0 &lt; alpha &lt; 1)\nfloat temperaturaFiltrada = 0.0;\n\nvoid setup() {\n    Serial.begin(9600);\n}\n\nvoid loop() {\n    // Leitura do sensor de temperatura\n    int leitura = analogRead(pinoSensor);\n    float temperatura = leitura * (5.0 / 1023.0) * 100; // Convers\u00e3o exemplo\n\n    // Aplica\u00e7\u00e3o do filtro passa-baixa\n    temperaturaFiltrada = alpha * temperatura + (1 - alpha) * temperaturaFiltrada;\n\n    // Exibe as temperaturas no Monitor Serial\n    Serial.print(\"Temperatura Bruta: \");\n    Serial.print(temperatura);\n    Serial.print(\"\u00b0C\\tTemperatura Filtrada: \");\n    Serial.println(temperaturaFiltrada);\n\n    delay(1000);\n}\n</code></pre> <p>Explica\u00e7\u00e3o:</p> <ul> <li>Filtro Passa-Baixa: Suaviza as leituras removendo varia\u00e7\u00f5es r\u00e1pidas e ru\u00eddos.</li> <li>Constante Alpha: Determina a influ\u00eancia das leituras atuais em rela\u00e7\u00e3o \u00e0s passadas. Valores menores resultam em maior suaviza\u00e7\u00e3o.</li> <li>Monitoramento: Compara a temperatura bruta com a filtrada no Monitor Serial para observar os efeitos do filtro.</li> </ul>"},{"location":"aulas/iot/modulos/modulo16.html#9-conceitos-importantes","title":"9. Conceitos Importantes","text":""},{"location":"aulas/iot/modulos/modulo16.html#91-algoritmos-de-controle-pid","title":"9.1 Algoritmos de Controle PID","text":"<ul> <li>Defini\u00e7\u00e3o: Algoritmo que ajusta a sa\u00edda de um sistema com base no erro atual, acumulado e na taxa de varia\u00e7\u00e3o do erro.</li> <li>Aplica\u00e7\u00f5es: Controle de temperatura, velocidade de motores, posi\u00e7\u00e3o de servos.</li> <li>Ajuste de Par\u00e2metros: Import\u00e2ncia de ajustar corretamente Kp, Ki e Kd para obter uma resposta adequada.</li> </ul>"},{"location":"aulas/iot/modulos/modulo16.html#92-maquinas-de-estados-finitos-fsm","title":"9.2 M\u00e1quinas de Estados Finitos (FSM)","text":"<ul> <li>Defini\u00e7\u00e3o: Modelo de computa\u00e7\u00e3o que consiste em um n\u00famero finito de estados e transi\u00e7\u00f5es entre eles baseadas em eventos ou condi\u00e7\u00f5es.</li> <li>Vantagens: Facilita o gerenciamento de sistemas complexos com m\u00faltiplos modos de opera\u00e7\u00e3o.</li> <li>Implementa\u00e7\u00e3o: Utiliza\u00e7\u00e3o de estruturas de controle como <code>switch-case</code> no Arduino para gerenciar estados.</li> </ul>"},{"location":"aulas/iot/modulos/modulo16.html#93-filtragem-de-dados","title":"9.3 Filtragem de Dados","text":"<ul> <li>Objetivo: Remover ru\u00eddos e melhorar a qualidade dos dados coletados dos sensores.</li> <li>T\u00e9cnicas: M\u00e9dia m\u00f3vel, filtros passa-baixa, filtros Kalman.</li> <li>Aplica\u00e7\u00f5es: Processamento de sinais de sensores, estabiliza\u00e7\u00e3o de leituras.</li> </ul>"},{"location":"aulas/iot/modulos/modulo16.html#94-controle-de-movimento-avancado","title":"9.4 Controle de Movimento Avan\u00e7ado","text":"<ul> <li>Trajet\u00f3rias Suaves: Planejamento de movimentos que evitam oscila\u00e7\u00f5es e movimentos bruscos.</li> <li>Controle de Acelera\u00e7\u00e3o: Ajuste gradual da velocidade para evitar sobrecargas nos atuadores.</li> <li>Sincroniza\u00e7\u00e3o de Atuadores: Coordena\u00e7\u00e3o de m\u00faltiplos motores e servos para movimentos complexos.</li> </ul>"},{"location":"aulas/iot/modulos/modulo16.html#95-boas-praticas-no-uso-de-algoritmos-de-controle","title":"9.5 Boas Pr\u00e1ticas no Uso de Algoritmos de Controle","text":"<ul> <li>Teste e Valida\u00e7\u00e3o: Testar os algoritmos em diferentes condi\u00e7\u00f5es para garantir robustez.</li> <li>Monitoramento: Utilizar o Monitor Serial para acompanhar o comportamento dos algoritmos em tempo real.</li> <li>Documenta\u00e7\u00e3o: Manter registros claros dos par\u00e2metros utilizados e dos resultados obtidos durante os testes.</li> </ul>"},{"location":"aulas/iot/modulos/modulo16.html#10-recursos-adicionais","title":"10. Recursos Adicionais","text":"<ul> <li> <p>Documenta\u00e7\u00e3o Oficial do Arduino:</p> </li> <li> <p>PID Library</p> </li> <li>Servo Library</li> <li> <p>State Machine Library</p> </li> <li> <p>Tutoriais e Guias:</p> </li> <li> <p>Implementando Controle PID no Arduino</p> </li> <li>M\u00e1quinas de Estados Finitos com Arduino</li> <li> <p>Filtragem de Dados em Projetos Arduino</p> </li> <li> <p>V\u00eddeos Educacionais:</p> </li> <li> <p>Controle PID com Arduino</p> </li> <li>M\u00e1quinas de Estados Finitos para Iniciantes</li> <li>T\u00e9cnicas de Filtragem de Dados no Arduino</li> </ul>"},{"location":"aulas/iot/modulos/modulo16.html#11-conclusao-do-modulo","title":"11. Conclus\u00e3o do M\u00f3dulo","text":"<p>Neste m\u00f3dulo, voc\u00ea aprendeu:</p> <ul> <li>Algoritmos de Controle PID: Entendeu os fundamentos do controle PID e como implement\u00e1-lo no Arduino para regular sistemas din\u00e2micos.</li> <li>M\u00e1quinas de Estados Finitos (FSM): Aprendeu a gerenciar diferentes modos de opera\u00e7\u00e3o em sistemas automatizados utilizando FSM.</li> <li>Filtragem Avan\u00e7ada de Dados: Aplicou t\u00e9cnicas de filtragem para melhorar a precis\u00e3o das leituras dos sensores.</li> <li>Controle de Movimento Avan\u00e7ado: Desenvolveu habilidades para planejar e executar movimentos suaves e coordenados em projetos com m\u00faltiplos atuadores.</li> <li>Boas Pr\u00e1ticas: Compreendeu a import\u00e2ncia do teste, monitoramento e documenta\u00e7\u00e3o na implementa\u00e7\u00e3o de algoritmos de controle.</li> </ul> <p>Com este conhecimento, voc\u00ea est\u00e1 preparado para desenvolver sistemas mais sofisticados e eficientes, capazes de responder de maneira inteligente a diferentes condi\u00e7\u00f5es e desafios.</p>"},{"location":"aulas/iot/modulos/modulo16.html#12-proximos-passos","title":"12. Pr\u00f3ximos Passos","text":"<ul> <li>Revisar todo o conte\u00fado do m\u00f3dulo para consolidar o aprendizado.</li> <li>Explorar projetos avan\u00e7ados que combinam algoritmos de controle com outros conceitos aprendidos, como rob\u00f3tica e IoT.</li> <li>Participar de comunidades e f\u00f3runs de Arduino para trocar experi\u00eancias e obter suporte cont\u00ednuo.</li> <li>Considerar cursos avan\u00e7ados ou especializa\u00e7\u00f5es em \u00e1reas espec\u00edficas de interesse, como controle autom\u00e1tico, processamento de sinais ou design de sistemas embarcados.</li> <li>Desenvolver seu pr\u00f3prio portf\u00f3lio de projetos Arduino, aplicando os conceitos de controle avan\u00e7ado para resolver problemas reais.</li> </ul> <p>Se tiver d\u00favidas ou precisar de assist\u00eancia, continue participando de comunidades de aprendizagem ou consulte os recursos adicionais fornecidos ao longo dos m\u00f3dulos.</p> <p>**Parab\u00e9ns por concluir o M\u00f3dulo 15! Continue explorando e criando projetos incr\u00edveis com Arduino!</p>"},{"location":"aulas/iot/modulos/modulo17.html","title":"M\u00f3dulo 17: Gest\u00e3o de Energia e Efici\u00eancia em Projetos Arduino","text":"<p>Bem-vindo ao M\u00f3dulo 17 do curso \"Programa\u00e7\u00e3o em Arduino: Conceitos Fundamentais sem Hardware\". Neste m\u00f3dulo, voc\u00ea ir\u00e1 aprender sobre gest\u00e3o de energia e efici\u00eancia energ\u00e9tica em projetos Arduino. Com o crescimento dos dispositivos IoT e a necessidade de solu\u00e7\u00f5es sustent\u00e1veis, entender como otimizar o consumo de energia dos seus projetos \u00e9 essencial. Este m\u00f3dulo aborda t\u00e9cnicas e pr\u00e1ticas para reduzir o consumo de energia, prolongar a vida \u00fatil das baterias e garantir que seus projetos sejam mais sustent\u00e1veis e eficientes.</p>"},{"location":"aulas/iot/modulos/modulo17.html#objetivos-do-modulo","title":"Objetivos do M\u00f3dulo","text":"<ul> <li>Compreender os fundamentos do consumo de energia em projetos Arduino.</li> <li>Aprender a medir e analisar o consumo de energia de um circuito.</li> <li>Implementar modos de economia de energia no Arduino para prolongar a vida \u00fatil das baterias.</li> <li>Selecionar componentes de baixo consumo e otimizar o uso de energia em projetos.</li> <li>Aplicar t\u00e9cnicas de gerenciamento de energia em projetos IoT.</li> <li>Resolver exerc\u00edcios pr\u00e1ticos para consolidar o conhecimento sobre gest\u00e3o de energia e efici\u00eancia.</li> </ul>"},{"location":"aulas/iot/modulos/modulo17.html#1-introducao-a-gestao-de-energia","title":"1. Introdu\u00e7\u00e3o \u00e0 Gest\u00e3o de Energia","text":""},{"location":"aulas/iot/modulos/modulo17.html#11-importancia-da-gestao-de-energia","title":"1.1 Import\u00e2ncia da Gest\u00e3o de Energia","text":"<p>A gest\u00e3o de energia em projetos Arduino \u00e9 crucial para:</p> <ul> <li>Prolongar a Vida \u00datil: Reduzir o consumo de energia permite que dispositivos alimentados por bateria funcionem por mais tempo.</li> <li>Sustentabilidade: Projetos eficientes energeticamente contribuem para a sustentabilidade ambiental.</li> <li>Desempenho e Estabilidade: Sistemas com gerenciamento de energia adequado evitam sobrecargas e falhas devido \u00e0 falta de energia.</li> </ul>"},{"location":"aulas/iot/modulos/modulo17.html#12-fontes-de-energia-para-arduino","title":"1.2 Fontes de Energia para Arduino","text":"<ul> <li>Baterias Recarreg\u00e1veis: Li-Ion, Li-Po, NiMH, alcalinas.</li> <li>Adaptadores de Energia: Conectados \u00e0 rede el\u00e9trica.</li> <li>Energia Solar: Utiliza\u00e7\u00e3o de pain\u00e9is solares para projetos sustent\u00e1veis.</li> <li>Supercapacitores: Para armazenamento de energia de alta pot\u00eancia em curto prazo.</li> </ul>"},{"location":"aulas/iot/modulos/modulo17.html#2-medicao-e-analise-do-consumo-de-energia","title":"2. Medi\u00e7\u00e3o e An\u00e1lise do Consumo de Energia","text":""},{"location":"aulas/iot/modulos/modulo17.html#21-ferramentas-para-medir-consumo-de-energia","title":"2.1 Ferramentas para Medir Consumo de Energia","text":"<ul> <li>Mult\u00edmetros: Medem corrente, tens\u00e3o e resist\u00eancia.</li> <li>Shunts de Corrente: Resistores de baixa resist\u00eancia usados para medir correntes elevadas.</li> <li>Sensores de Corrente: Como o ACS712, que fornece uma sa\u00edda anal\u00f3gica proporcional \u00e0 corrente.</li> <li>Analisadores de Energia: Ferramentas avan\u00e7adas para an\u00e1lise detalhada do consumo energ\u00e9tico.</li> </ul>"},{"location":"aulas/iot/modulos/modulo17.html#22-exemplo-de-codigo-para-medicao-de-corrente-com-acs712","title":"2.2 Exemplo de C\u00f3digo para Medi\u00e7\u00e3o de Corrente com ACS712","text":"<pre><code>const int pinoSensorCorrente = A0; // Pino anal\u00f3gico conectado ao ACS712\nconst float fatorConversao = 5.0 / 1023.0; // Tens\u00e3o de refer\u00eancia / resolu\u00e7\u00e3o ADC\n\nvoid setup() {\n    Serial.begin(9600);\n    pinMode(pinoSensorCorrente, INPUT);\n}\n\nvoid loop() {\n    int leitura = analogRead(pinoSensorCorrente);\n    float tensao = leitura * fatorConversao;\n    float corrente = (tensao - 2.5) / 0.185; // 2.5V \u00e9 o ponto de refer\u00eancia, 0.185 V/A para ACS712 5A\n\n    Serial.print(\"Corrente: \");\n    Serial.print(corrente);\n    Serial.println(\" A\");\n\n    delay(1000);\n}\n</code></pre> <p>Explica\u00e7\u00e3o:</p> <ul> <li>Leitura do Sensor: O sensor ACS712 fornece uma tens\u00e3o que varia com a corrente. O ponto de refer\u00eancia \u00e9 2.5V no meio da faixa.</li> <li>C\u00e1lculo da Corrente: Subtrai-se 2.5V da leitura e divide-se pelo fator de convers\u00e3o espec\u00edfico do sensor (0.185 V/A para o modelo 5A).</li> <li>Monitoramento: Exibe a corrente medida no Monitor Serial para an\u00e1lise.</li> </ul>"},{"location":"aulas/iot/modulos/modulo17.html#3-modos-de-economia-de-energia-no-arduino","title":"3. Modos de Economia de Energia no Arduino","text":""},{"location":"aulas/iot/modulos/modulo17.html#31-sleep-modes-do-arduino","title":"3.1 Sleep Modes do Arduino","text":"<p>O Arduino possui diferentes modos de opera\u00e7\u00e3o para reduzir o consumo de energia quando n\u00e3o est\u00e1 ativo:</p> <ul> <li>Idle Mode: Reduz algumas fun\u00e7\u00f5es sem interromper completamente o funcionamento.</li> <li>ADC Noise Reduction Mode: Minimiza o ru\u00eddo durante leituras anal\u00f3gicas.</li> <li>Power-save Mode: Desativa timers e mant\u00e9m apenas as interrup\u00e7\u00f5es essenciais.</li> <li>Standby e Power-down Modes: Minimiza o consumo ao m\u00e1ximo, desativando quase todos os componentes internos.</li> </ul>"},{"location":"aulas/iot/modulos/modulo17.html#32-implementacao-do-sleep-mode-no-arduino","title":"3.2 Implementa\u00e7\u00e3o do Sleep Mode no Arduino","text":"<p>Para implementar o modo de sleep no Arduino, utilizaremos a biblioteca LowPower.</p>"},{"location":"aulas/iot/modulos/modulo17.html#33-exemplo-de-codigo-para-sleep-mode-com-lowpower","title":"3.3 Exemplo de C\u00f3digo para Sleep Mode com LowPower","text":"<pre><code>#include &lt;LowPower.h&gt;\n\nconst int pinoBotao = 2; // Pino conectado a um bot\u00e3o\n\nvoid setup() {\n    pinMode(pinoBotao, INPUT_PULLUP);\n    Serial.begin(9600);\n    Serial.println(\"Sistema Inativo. Pressione o bot\u00e3o para acordar.\");\n}\n\nvoid loop() {\n    // Entra em modo de sleep por 8 segundos\n    LowPower.powerDown(SLEEP_8S, ADC_OFF, BOD_OFF);\n\n    // Verifica se o bot\u00e3o foi pressionado\n    if (digitalRead(pinoBotao) == LOW) {\n        Serial.println(\"Bot\u00e3o Pressionado! Sistema Ativo.\");\n        // C\u00f3digo para executar quando acordar\n        delay(1000); // Tempo para estabilizar\n    }\n}\n</code></pre> <p>Explica\u00e7\u00e3o:</p> <ul> <li>Biblioteca LowPower: Facilita a implementa\u00e7\u00e3o dos modos de sleep no Arduino.</li> <li>Modo powerDown: Reduz o consumo ao m\u00ednimo, mantendo apenas as interrup\u00e7\u00f5es essenciais.</li> <li>Despertar com Interrup\u00e7\u00e3o: No exemplo, o bot\u00e3o pressiona para acordar o sistema.</li> </ul>"},{"location":"aulas/iot/modulos/modulo17.html#4-selecao-de-componentes-de-baixo-consumo","title":"4. Sele\u00e7\u00e3o de Componentes de Baixo Consumo","text":""},{"location":"aulas/iot/modulos/modulo17.html#41-sensores-e-atuadores-eficientes","title":"4.1 Sensores e Atuadores Eficientes","text":"<ul> <li>Sensores de Baixo Consumo: Optar por sensores que possuem modos de baixa pot\u00eancia ou que consomem menos energia.</li> <li>Motores e Servos Eficientes: Selecionar motores com baixo consumo e que podem ser controlados eficientemente com PWM.</li> </ul>"},{"location":"aulas/iot/modulos/modulo17.html#42-reguladores-de-tensao-e-conversores-dc-dc","title":"4.2 Reguladores de Tens\u00e3o e Conversores DC-DC","text":"<ul> <li>Reguladores de Baixa Queda (LDO): Minimiza a dissipa\u00e7\u00e3o de energia ao converter tens\u00f5es.</li> <li>Conversores Buck e Boost: Mais eficientes que os LDOs para convers\u00f5es de tens\u00e3o maiores.</li> </ul>"},{"location":"aulas/iot/modulos/modulo17.html#43-exemplos-de-componentes-de-baixo-consumo","title":"4.3 Exemplos de Componentes de Baixo Consumo","text":"<ul> <li>OLED Displays: Menor consumo comparado a displays LCD tradicionais.</li> <li>M\u00f3dulos de Comunica\u00e7\u00e3o de Baixo Consumo: Como o ESP32 em modos de sleep ou LoRa para comunica\u00e7\u00e3o eficiente.</li> </ul>"},{"location":"aulas/iot/modulos/modulo17.html#5-gerenciamento-de-energia-em-projetos-iot","title":"5. Gerenciamento de Energia em Projetos IoT","text":""},{"location":"aulas/iot/modulos/modulo17.html#51-estrategias-para-dispositivos-alimentados-por-bateria","title":"5.1 Estrat\u00e9gias para Dispositivos Alimentados por Bateria","text":"<ul> <li>Uso de Sleep Modes: Minimizar o tempo ativo do microcontrolador.</li> <li>Transmiss\u00f5es Eficientes: Reduzir a frequ\u00eancia de comunica\u00e7\u00e3o sem fio.</li> <li>Componentes de Baixo Consumo: Selecionar sensores e atuadores que consomem menos energia.</li> </ul>"},{"location":"aulas/iot/modulos/modulo17.html#52-otimizacao-de-comunicacao-sem-fio","title":"5.2 Otimiza\u00e7\u00e3o de Comunica\u00e7\u00e3o Sem Fio","text":"<ul> <li>Protocolos de Baixo Consumo: Utilizar protocolos como MQTT com QoS apropriado ou LoRa para comunica\u00e7\u00f5es de longo alcance com baixo consumo.</li> <li>Duty Cycling: Alternar entre estados ativos e inativos de forma eficiente para reduzir o consumo geral.</li> </ul>"},{"location":"aulas/iot/modulos/modulo17.html#53-exemplo-de-projeto-iot-com-gestao-de-energia","title":"5.3 Exemplo de Projeto IoT com Gest\u00e3o de Energia","text":"<p>Desenvolva um sistema de monitoramento ambiental que coleta dados de sensores, envia informa\u00e7\u00f5es para a nuvem e entra em modo de sleep entre as transmiss\u00f5es para economizar energia.</p> <pre><code>#include &lt;Wire.h&gt;\n#include &lt;SPI.h&gt;\n#include &lt;LowPower.h&gt;\n#include &lt;WiFiNINA.h&gt;\n#include &lt;MQTT.h&gt;\n\n// Defini\u00e7\u00f5es de rede\nconst char* ssid = \"Seu_SSID\";\nconst char* password = \"Sua_Senha\";\n\n// Defini\u00e7\u00f5es do MQTT\nconst char* broker = \"broker.hivemq.com\";\nconst int port = 1883;\nconst char* topic = \"arduino/monitoramento\";\n\n// Pinos dos sensores\nconst int pinoSensorTemp = A0;\nconst int pinoSensorUmid = A1;\n\n// Inst\u00e2ncia do cliente MQTT\nWiFiClient net;\nMQTTClient client;\n\nvoid messageReceived(String &amp;topic, String &amp;payload) {\n    // N\u00e3o utilizado neste exemplo\n}\n\nvoid setup() {\n    Serial.begin(9600);\n    pinMode(pinoSensorTemp, INPUT);\n    pinMode(pinoSensorUmid, INPUT);\n\n    // Conecta ao Wi-Fi\n    WiFi.begin(ssid, password);\n    while (WiFi.status() != WL_CONNECTED) {\n        delay(500);\n        Serial.print(\".\");\n    }\n    Serial.println(\"Conectado ao Wi-Fi\");\n\n    // Conecta ao broker MQTT\n    client.begin(broker, port, net);\n    while (!client.connect(\"ArduinoClient\")) {\n        Serial.print(\".\");\n        delay(1000);\n    }\n    Serial.println(\"Conectado ao MQTT broker\");\n    client.onMessage(messageReceived);\n}\n\nvoid loop() {\n    // Leitura dos sensores\n    int leituraTemp = analogRead(pinoSensorTemp);\n    int leituraUmid = analogRead(pinoSensorUmid);\n\n    // Convers\u00e3o das leituras\n    float temperatura = leituraTemp * (5.0 / 1023.0) * 100; // Exemplo\n    float umidade = leituraUmid * (5.0 / 1023.0) * 100; // Exemplo\n\n    // Publica os dados no MQTT\n    String mensagem = \"Temperatura: \" + String(temperatura) + \"C, Umidade: \" + String(umidade) + \"%\";\n    client.publish(topic, mensagem);\n    Serial.println(\"Dados enviados: \" + mensagem);\n\n    // Desconecta do MQTT\n    client.disconnect();\n\n    // Entra em modo de sleep por 8 segundos\n    LowPower.powerDown(SLEEP_8S, ADC_OFF, BOD_OFF);\n}\n</code></pre> <p>Explica\u00e7\u00e3o:</p> <ul> <li>Conex\u00e3o ao Wi-Fi e MQTT: Estabelece conex\u00e3o com a rede Wi-Fi e o broker MQTT para envio de dados.</li> <li>Leitura e Convers\u00e3o de Sensores: L\u00ea os valores anal\u00f3gicos dos sensores e converte para unidades compreens\u00edveis.</li> <li>Publica\u00e7\u00e3o MQTT: Envia os dados para o t\u00f3pico especificado no broker MQTT.</li> <li>Modo de Sleep: Ap\u00f3s enviar os dados, o Arduino entra em modo de sleep por 8 segundos para economizar energia antes de repetir o processo.</li> </ul>"},{"location":"aulas/iot/modulos/modulo17.html#6-conceitos-importantes","title":"6. Conceitos Importantes","text":""},{"location":"aulas/iot/modulos/modulo17.html#61-eficiencia-energetica","title":"6.1 Efici\u00eancia Energ\u00e9tica","text":"<ul> <li>Defini\u00e7\u00e3o: Maximizar o desempenho do sistema enquanto minimiza o consumo de energia.</li> <li>T\u00e9cnicas: Uso de componentes de baixo consumo, otimiza\u00e7\u00e3o do c\u00f3digo para reduzir ciclos de processamento, e gerenciamento eficaz dos modos de opera\u00e7\u00e3o.</li> </ul>"},{"location":"aulas/iot/modulos/modulo17.html#62-modos-de-economia-de-energia","title":"6.2 Modos de Economia de Energia","text":"<ul> <li>Sleep Modes: Reduzem o consumo desligando partes do sistema que n\u00e3o est\u00e3o em uso.</li> <li>Wake-up Sources: Fontes que podem despertar o microcontrolador do modo de sleep, como interrup\u00e7\u00f5es de bot\u00f5es ou sensores.</li> <li>Duty Cycling: Alternar entre estados ativos e inativos para minimizar o consumo total.</li> </ul>"},{"location":"aulas/iot/modulos/modulo17.html#63-selecao-de-componentes","title":"6.3 Sele\u00e7\u00e3o de Componentes","text":"<ul> <li>Sensores e Atuadores: Escolher dispositivos que oferecem baixo consumo de energia sem comprometer o desempenho necess\u00e1rio.</li> <li>Reguladores de Tens\u00e3o: Utilizar reguladores eficientes para reduzir a dissipa\u00e7\u00e3o de energia.</li> <li>Displays e Interfaces: Optar por displays OLED ou LCD de baixo consumo e minimizar o uso de interfaces que demandam energia constante.</li> </ul>"},{"location":"aulas/iot/modulos/modulo17.html#64-gerenciamento-de-energia-em-projetos-iot","title":"6.4 Gerenciamento de Energia em Projetos IoT","text":"<ul> <li>Otimizando Transmiss\u00f5es: Reduzir a frequ\u00eancia de envio de dados e utilizar protocolos eficientes para comunica\u00e7\u00e3o.</li> <li>Armazenamento de Energia: Utilizar baterias de alta capacidade e considerar fontes de energia alternativas como pain\u00e9is solares.</li> <li>Monitoramento do Consumo: Implementar sistemas que monitoram o consumo de energia em tempo real para identificar e eliminar desperd\u00edcios.</li> </ul>"},{"location":"aulas/iot/modulos/modulo17.html#65-boas-praticas-na-gestao-de-energia","title":"6.5 Boas Pr\u00e1ticas na Gest\u00e3o de Energia","text":"<ul> <li>Teste e Medi\u00e7\u00e3o: Sempre medir o consumo de energia antes e depois de implementar t\u00e9cnicas de economia.</li> <li>Documenta\u00e7\u00e3o: Manter registros detalhados das t\u00e9cnicas e componentes utilizados para facilitar futuras otimiza\u00e7\u00f5es.</li> <li>Otimiza\u00e7\u00e3o Cont\u00ednua: Revisar e melhorar continuamente o gerenciamento de energia conforme o projeto evolui.</li> </ul>"},{"location":"aulas/iot/modulos/modulo17.html#7-recursos-adicionais","title":"7. Recursos Adicionais","text":"<ul> <li> <p>Documenta\u00e7\u00e3o Oficial do Arduino:</p> </li> <li> <p>LowPower Library</p> </li> <li>Energy Consumption Basics</li> <li> <p>ADC Precision</p> </li> <li> <p>Tutoriais e Guias:</p> </li> <li> <p>Gerenciamento de Energia com Arduino</p> </li> <li>Implementando Sleep Modes no Arduino</li> <li> <p>Medi\u00e7\u00e3o de Consumo de Energia com Arduino</p> </li> <li> <p>V\u00eddeos Educacionais:</p> </li> <li> <p>Economizando Energia no Arduino</p> </li> <li>Sleep Modes e Gest\u00e3o de Energia</li> <li>Otimizando Projetos Arduino para IoT</li> </ul>"},{"location":"aulas/iot/modulos/modulo17.html#8-exemplos-praticos","title":"8. Exemplos Pr\u00e1ticos","text":""},{"location":"aulas/iot/modulos/modulo17.html#81-implementacao-de-sleep-mode-com-despertar-por-interrupcao","title":"8.1 Implementa\u00e7\u00e3o de Sleep Mode com Despertar por Interrup\u00e7\u00e3o","text":"<p>Este exemplo demonstra como colocar o Arduino em modo de sleep e acord\u00e1-lo usando uma interrup\u00e7\u00e3o externa, como um bot\u00e3o.</p> <pre><code>#include &lt;LowPower.h&gt;\n\nconst int pinoBotao = 2; // Pino conectado a um bot\u00e3o\n\nvoid despertar() {\n    // Fun\u00e7\u00e3o vazia para a interrup\u00e7\u00e3o\n}\n\nvoid setup() {\n    pinMode(pinoBotao, INPUT_PULLUP);\n    Serial.begin(9600);\n    Serial.println(\"Sistema em Sleep. Pressione o bot\u00e3o para acordar.\");\n}\n\nvoid loop() {\n    // Configura a interrup\u00e7\u00e3o na borda de descida do bot\u00e3o\n    attachInterrupt(digitalPinToInterrupt(pinoBotao), despertar, FALLING);\n\n    // Entra em modo de sleep por 8 segundos ou at\u00e9 interrup\u00e7\u00e3o\n    LowPower.powerDown(SLEEP_FOREVER, ADC_OFF, BOD_OFF);\n\n    // Desconecta a interrup\u00e7\u00e3o ap\u00f3s acordar\n    detachInterrupt(digitalPinToInterrupt(pinoBotao));\n\n    // Executa a\u00e7\u00f5es ap\u00f3s acordar\n    Serial.println(\"Sistema Acordado!\");\n    delay(1000); // Tempo para estabilizar\n}\n</code></pre> <p>Explica\u00e7\u00e3o:</p> <ul> <li>Interrup\u00e7\u00e3o Externa: O bot\u00e3o pressiona para gerar uma interrup\u00e7\u00e3o que acorda o Arduino do modo de sleep.</li> <li>Fun\u00e7\u00e3o de Despertar: Uma fun\u00e7\u00e3o vazia que serve apenas para despertar o sistema.</li> <li>Modo SLEEP_FOREVER: Mant\u00e9m o Arduino em modo de sleep at\u00e9 que uma interrup\u00e7\u00e3o ocorra.</li> <li>Desconex\u00e3o da Interrup\u00e7\u00e3o: Ap\u00f3s acordar, a interrup\u00e7\u00e3o \u00e9 removida para evitar m\u00faltiplos acordes indesejados.</li> </ul>"},{"location":"aulas/iot/modulos/modulo17.html#82-projeto-de-monitoramento-de-bateria-com-alerta-de-baixo-nivel","title":"8.2 Projeto de Monitoramento de Bateria com Alerta de Baixo N\u00edvel","text":"<p>Este exemplo implementa um sistema que monitora o n\u00edvel de bateria e envia um alerta quando o n\u00edvel est\u00e1 baixo.</p> <pre><code>#include &lt;LowPower.h&gt;\n#include &lt;WiFiNINA.h&gt;\n#include &lt;MQTT.h&gt;\n\n// Defini\u00e7\u00f5es de rede\nconst char* ssid = \"Seu_SSID\";\nconst char* password = \"Sua_Senha\";\n\n// Defini\u00e7\u00f5es do MQTT\nconst char* broker = \"broker.hivemq.com\";\nconst int port = 1883;\nconst char* topicAlerta = \"arduino/alertas\";\n\n// Pinos\nconst int pinoSensorBateria = A0;\nconst int pinoLEDAlerta = 13;\n\n// Limiar de bateria\nconst float limiarBateria = 3.3; // Exemplo para uma bateria de 3.3V\n\n// Inst\u00e2ncia do cliente MQTT\nWiFiClient net;\nMQTTClient client;\n\nvoid setup() {\n    pinMode(pinoLEDAlerta, OUTPUT);\n    digitalWrite(pinoLEDAlerta, LOW);\n\n    Serial.begin(9600);\n\n    // Conecta ao Wi-Fi\n    WiFi.begin(ssid, password);\n    while (WiFi.status() != WL_CONNECTED) {\n        delay(500);\n        Serial.print(\".\");\n    }\n    Serial.println(\"\\nConectado ao Wi-Fi\");\n\n    // Conecta ao broker MQTT\n    client.begin(broker, port, net);\n    while (!client.connect(\"ArduinoClient\")) {\n        Serial.print(\".\");\n        delay(1000);\n    }\n    Serial.println(\"\\nConectado ao MQTT broker\");\n}\n\nvoid loop() {\n    // Leitura do sensor de bateria\n    int leitura = analogRead(pinoSensorBateria);\n    float tensao = leitura * (5.0 / 1023.0); // Convers\u00e3o exemplo\n\n    Serial.print(\"Tens\u00e3o da Bateria: \");\n    Serial.print(tensao);\n    Serial.println(\" V\");\n\n    // Verifica se a tens\u00e3o est\u00e1 abaixo do limiar\n    if (tensao &lt; limiarBateria) {\n        // Aciona o LED de alerta\n        digitalWrite(pinoLEDAlerta, HIGH);\n\n        // Envia alerta via MQTT\n        String mensagem = \"Alerta: N\u00edvel de bateria baixo!\";\n        client.publish(topicAlerta, mensagem);\n        Serial.println(\"Alerta enviado: N\u00edvel de bateria baixo!\");\n    } else {\n        // Desativa o LED de alerta\n        digitalWrite(pinoLEDAlerta, LOW);\n    }\n\n    // Desconecta do MQTT\n    client.disconnect();\n\n    // Entra em modo de sleep por 8 segundos para economizar energia\n    LowPower.powerDown(SLEEP_8S, ADC_OFF, BOD_OFF);\n}\n</code></pre> <p>Explica\u00e7\u00e3o:</p> <ul> <li>Monitoramento de Tens\u00e3o: L\u00ea a tens\u00e3o da bateria atrav\u00e9s de um sensor anal\u00f3gico.</li> <li>Alerta de Baixo N\u00edvel: Aciona um LED e envia uma mensagem MQTT quando a tens\u00e3o est\u00e1 abaixo do limiar definido.</li> <li>Economia de Energia: O Arduino entra em modo de sleep por 8 segundos entre as leituras para reduzir o consumo energ\u00e9tico.</li> </ul>"},{"location":"aulas/iot/modulos/modulo17.html#83-otimizacao-de-codigo-para-reduzir-o-consumo-de-energia","title":"8.3 Otimiza\u00e7\u00e3o de C\u00f3digo para Reduzir o Consumo de Energia","text":"<p>Este exemplo mostra como otimizar o c\u00f3digo do Arduino para reduzir o consumo de energia, minimizando o uso de loops intensivos e desligando perif\u00e9ricos desnecess\u00e1rios.</p> <pre><code>#include &lt;LowPower.h&gt;\n\nconst int pinoLED = 13;\n\nvoid setup() {\n    pinMode(pinoLED, OUTPUT);\n    digitalWrite(pinoLED, LOW);\n}\n\nvoid loop() {\n    // Liga o LED por 1 segundo\n    digitalWrite(pinoLED, HIGH);\n    delay(1000);\n\n    // Desliga o LED\n    digitalWrite(pinoLED, LOW);\n\n    // Entra em modo de sleep por 8 segundos\n    LowPower.powerDown(SLEEP_8S, ADC_OFF, BOD_OFF);\n}\n</code></pre> <p>Explica\u00e7\u00e3o:</p> <ul> <li>Minimiza\u00e7\u00e3o de Processamento Ativo: Evita loops intensivos que mant\u00eam o microcontrolador ativo continuamente.</li> <li>Desligamento de Perif\u00e9ricos: Desliga componentes que n\u00e3o est\u00e3o em uso para reduzir o consumo de energia.</li> <li>Uso de Delays com Sleep: Utiliza delays acompanhados de modos de sleep para manter o Arduino inativo durante per\u00edodos de espera.</li> </ul>"},{"location":"aulas/iot/modulos/modulo17.html#9-conceitos-importantes","title":"9. Conceitos Importantes","text":""},{"location":"aulas/iot/modulos/modulo17.html#91-eficiencia-energetica","title":"9.1 Efici\u00eancia Energ\u00e9tica","text":"<ul> <li>Defini\u00e7\u00e3o: Maximizar o desempenho do sistema enquanto minimiza o consumo de energia.</li> <li>T\u00e9cnicas: Uso de componentes de baixo consumo, otimiza\u00e7\u00e3o do c\u00f3digo para reduzir ciclos de processamento, e gerenciamento eficaz dos modos de opera\u00e7\u00e3o.</li> </ul>"},{"location":"aulas/iot/modulos/modulo17.html#92-modos-de-economia-de-energia","title":"9.2 Modos de Economia de Energia","text":"<ul> <li>Sleep Modes: Reduzem o consumo desligando partes do sistema que n\u00e3o est\u00e3o em uso.</li> <li>Wake-up Sources: Fontes que podem despertar o microcontrolador do modo de sleep, como interrup\u00e7\u00f5es de bot\u00f5es ou sensores.</li> <li>Duty Cycling: Alternar entre estados ativos e inativos para minimizar o consumo total.</li> </ul>"},{"location":"aulas/iot/modulos/modulo17.html#93-selecao-de-componentes","title":"9.3 Sele\u00e7\u00e3o de Componentes","text":"<ul> <li>Sensores e Atuadores: Escolher dispositivos que oferecem baixo consumo de energia sem comprometer o desempenho necess\u00e1rio.</li> <li>Reguladores de Tens\u00e3o: Utilizar reguladores eficientes para reduzir a dissipa\u00e7\u00e3o de energia.</li> <li>Displays e Interfaces: Optar por displays OLED ou LCD de baixo consumo e minimizar o uso de interfaces que demandam energia constante.</li> </ul>"},{"location":"aulas/iot/modulos/modulo17.html#94-gerenciamento-de-energia-em-projetos-iot","title":"9.4 Gerenciamento de Energia em Projetos IoT","text":"<ul> <li>Otimizando Transmiss\u00f5es: Reduzir a frequ\u00eancia de envio de dados e utilizar protocolos eficientes para comunica\u00e7\u00e3o.</li> <li>Armazenamento de Energia: Utilizar baterias de alta capacidade e considerar fontes de energia alternativas como pain\u00e9is solares.</li> <li>Monitoramento do Consumo: Implementar sistemas que monitoram o consumo de energia em tempo real para identificar e eliminar desperd\u00edcios.</li> </ul>"},{"location":"aulas/iot/modulos/modulo17.html#95-boas-praticas-na-gestao-de-energia","title":"9.5 Boas Pr\u00e1ticas na Gest\u00e3o de Energia","text":"<ul> <li>Teste e Medi\u00e7\u00e3o: Sempre medir o consumo de energia antes e depois de implementar t\u00e9cnicas de economia.</li> <li>Documenta\u00e7\u00e3o: Manter registros detalhados das t\u00e9cnicas e componentes utilizados para facilitar futuras otimiza\u00e7\u00f5es.</li> <li>Otimiza\u00e7\u00e3o Cont\u00ednua: Revisar e melhorar continuamente o gerenciamento de energia conforme o projeto evolui.</li> </ul>"},{"location":"aulas/iot/modulos/modulo17.html#10-recursos-adicionais","title":"10. Recursos Adicionais","text":"<ul> <li> <p>Documenta\u00e7\u00e3o Oficial do Arduino:</p> </li> <li> <p>LowPower Library</p> </li> <li>Energy Consumption Basics</li> <li> <p>ADC Precision</p> </li> <li> <p>Tutoriais e Guias:</p> </li> <li> <p>Gerenciamento de Energia com Arduino</p> </li> <li>Implementando Sleep Modes no Arduino</li> <li> <p>Medi\u00e7\u00e3o de Consumo de Energia com Arduino</p> </li> <li> <p>V\u00eddeos Educacionais:</p> </li> <li> <p>Economizando Energia no Arduino</p> </li> <li>Sleep Modes e Gest\u00e3o de Energia</li> <li>Otimizando Projetos Arduino para IoT</li> </ul>"},{"location":"aulas/iot/modulos/modulo17.html#11-conclusao-do-modulo","title":"11. Conclus\u00e3o do M\u00f3dulo","text":"<p>Neste m\u00f3dulo, voc\u00ea aprendeu:</p> <ul> <li>Fundamentos da Gest\u00e3o de Energia: Compreendeu a import\u00e2ncia de gerenciar o consumo energ\u00e9tico em projetos Arduino.</li> <li>Medi\u00e7\u00e3o de Consumo: Aprendeu a medir e analisar o consumo de energia utilizando ferramentas e sensores.</li> <li>Implementa\u00e7\u00e3o de Sleep Modes: Aplicou modos de sleep para reduzir o consumo de energia quando o Arduino n\u00e3o est\u00e1 ativo.</li> <li>Sele\u00e7\u00e3o de Componentes Eficientes: Selecionou componentes de baixo consumo para otimizar seus projetos.</li> <li>Gerenciamento de Energia em IoT: Desenvolveu estrat\u00e9gias para projetos IoT eficientes energeticamente.</li> <li>Boas Pr\u00e1ticas: Entendeu a import\u00e2ncia de testar, documentar e otimizar continuamente o consumo de energia.</li> </ul> <p>Com este conhecimento, voc\u00ea est\u00e1 preparado para desenvolver projetos mais sustent\u00e1veis, eficientes e com maior autonomia, utilizando as melhores pr\u00e1ticas de gest\u00e3o de energia.</p>"},{"location":"aulas/iot/modulos/modulo17.html#12-proximos-passos","title":"12. Pr\u00f3ximos Passos","text":"<ul> <li>Revisar todo o conte\u00fado do m\u00f3dulo para consolidar o aprendizado.</li> <li>Explorar projetos avan\u00e7ados que combinam gest\u00e3o de energia com outros conceitos aprendidos, como IoT e rob\u00f3tica.</li> <li>Participar de comunidades e f\u00f3runs de Arduino para trocar experi\u00eancias e obter suporte cont\u00ednuo.</li> <li>Considerar cursos avan\u00e7ados ou especializa\u00e7\u00f5es em \u00e1reas espec\u00edficas de interesse, como design de sistemas de energia ou otimiza\u00e7\u00e3o de desempenho.</li> <li>Desenvolver seu pr\u00f3prio portf\u00f3lio de projetos Arduino, aplicando t\u00e9cnicas de gest\u00e3o de energia para resolver problemas reais.</li> </ul> <p>Se tiver d\u00favidas ou precisar de assist\u00eancia, continue participando de comunidades de aprendizagem ou consulte os recursos adicionais fornecidos ao longo dos m\u00f3dulos.</p> <p>**Parab\u00e9ns por concluir o M\u00f3dulo 17! Continue explorando e criando projetos incr\u00edveis com Arduino!</p>"},{"location":"aulas/iot/modulos/modulo18.html","title":"M\u00f3dulo 19: An\u00e1lise de Dados e Visualiza\u00e7\u00e3o","text":"<p>Bem-vindo ao M\u00f3dulo 19 do curso \"Programa\u00e7\u00e3o em Arduino: Conceitos Fundamentais sem Hardware\". Neste m\u00f3dulo, voc\u00ea ir\u00e1 aprender sobre an\u00e1lise de dados e visualiza\u00e7\u00e3o em projetos Arduino. Com a crescente quantidade de dados gerados por sensores e dispositivos conectados, \u00e9 essencial saber como coletar, armazenar, analisar e apresentar esses dados de maneira eficaz. Este m\u00f3dulo abordar\u00e1 t\u00e9cnicas e ferramentas para transformar dados brutos em informa\u00e7\u00f5es \u00fateis e visualmente atraentes.</p>"},{"location":"aulas/iot/modulos/modulo18.html#objetivos-do-modulo","title":"Objetivos do M\u00f3dulo","text":"<ul> <li>Compreender os m\u00e9todos de coleta e armazenamento de dados em projetos Arduino.</li> <li>Aprender t\u00e9cnicas b\u00e1sicas de an\u00e1lise de dados para identificar padr\u00f5es e tend\u00eancias.</li> <li>Implementar ferramentas de visualiza\u00e7\u00e3o para apresentar os dados de forma clara e compreens\u00edvel.</li> <li>Utilizar linguagens de programa\u00e7\u00e3o como Python para an\u00e1lise avan\u00e7ada de dados coletados pelo Arduino.</li> <li>Resolver exerc\u00edcios pr\u00e1ticos para consolidar o conhecimento sobre an\u00e1lise de dados e visualiza\u00e7\u00e3o.</li> </ul>"},{"location":"aulas/iot/modulos/modulo18.html#1-coleta-e-armazenamento-de-dados","title":"1. Coleta e Armazenamento de Dados","text":""},{"location":"aulas/iot/modulos/modulo18.html#11-metodos-de-coleta-de-dados","title":"1.1 M\u00e9todos de Coleta de Dados","text":"<p>A coleta de dados em projetos Arduino pode ser realizada de diversas formas, dependendo dos sensores utilizados e dos requisitos do projeto. Alguns m\u00e9todos comuns incluem:</p> <ul> <li>Leituras Cont\u00ednuas: Coleta de dados em intervalos regulares usando loops ou temporizadores.</li> <li>Interrup\u00e7\u00f5es: Coleta de dados baseada em eventos espec\u00edficos, como a detec\u00e7\u00e3o de um sinal ou a mudan\u00e7a de estado de um sensor.</li> <li>Streaming de Dados: Envio cont\u00ednuo de dados para uma interface externa, como um computador ou um servi\u00e7o de nuvem.</li> </ul>"},{"location":"aulas/iot/modulos/modulo18.html#12-armazenamento-de-dados","title":"1.2 Armazenamento de Dados","text":"<p>Os dados coletados podem ser armazenados localmente ou enviados para a nuvem para posterior an\u00e1lise. Algumas op\u00e7\u00f5es incluem:</p> <ul> <li>Cart\u00f5es SD: Utilizados para armazenar grandes quantidades de dados localmente.</li> <li>EEPROM: Mem\u00f3ria interna do Arduino para armazenar pequenas quantidades de dados.</li> <li>Servi\u00e7os de Nuvem: Plataformas como Google Sheets, Firebase ou ThingSpeak para armazenar e acessar dados remotamente.</li> </ul>"},{"location":"aulas/iot/modulos/modulo18.html#13-exemplo-de-codigo-para-armazenamento-de-dados-em-cartao-sd","title":"1.3 Exemplo de C\u00f3digo para Armazenamento de Dados em Cart\u00e3o SD","text":"<pre><code>#include &lt;SPI.h&gt;\n#include &lt;SD.h&gt;\n\nconst int pinoCS = 10; // Pino de sele\u00e7\u00e3o do cart\u00e3o SD\nFile arquivo;\n\nvoid setup() {\n    Serial.begin(9600);\n    while (!Serial) {}\n\n    Serial.print(\"Inicializando cart\u00e3o SD...\");\n    if (!SD.begin(pinoCS)) {\n        Serial.println(\"Falha na inicializa\u00e7\u00e3o!\");\n        while (1);\n    }\n    Serial.println(\"Cart\u00e3o SD inicializado.\");\n\n    // Abre o arquivo para escrita\n    arquivo = SD.open(\"dados.txt\", FILE_WRITE);\n    if (arquivo) {\n        Serial.println(\"Arquivo aberto com sucesso.\");\n        arquivo.println(\"Tempo (ms), Temperatura (C)\");\n        arquivo.close();\n    } else {\n        Serial.println(\"Falha ao abrir o arquivo.\");\n    }\n}\n\nvoid loop() {\n    // Exemplo de coleta de dados\n    unsigned long tempo = millis();\n    float temperatura = analogRead(A0) * (5.0 / 1023.0) * 100; // Convers\u00e3o exemplo\n\n    // Abre o arquivo para adicionar dados\n    arquivo = SD.open(\"dados.txt\", FILE_WRITE);\n    if (arquivo) {\n        arquivo.print(tempo);\n        arquivo.print(\", \");\n        arquivo.println(temperatura);\n        arquivo.close();\n        Serial.println(\"Dados registrados.\");\n    } else {\n        Serial.println(\"Falha ao abrir o arquivo para escrita.\");\n    }\n\n    delay(1000); // Intervalo de 1 segundo entre as leituras\n}\n</code></pre> <p>Explica\u00e7\u00e3o:</p> <ul> <li>Inicializa\u00e7\u00e3o do Cart\u00e3o SD: Configura e verifica a conex\u00e3o com o cart\u00e3o SD.</li> <li>Cria\u00e7\u00e3o e Abertura do Arquivo: Cria ou abre o arquivo \"dados.txt\" para escrever os dados coletados.</li> <li>Registro de Dados: Escreve o tempo e a temperatura no arquivo a cada segundo.</li> <li>Monitoramento: Exibe mensagens no Monitor Serial para indicar o status da grava\u00e7\u00e3o de dados.</li> </ul>"},{"location":"aulas/iot/modulos/modulo18.html#2-analise-de-dados","title":"2. An\u00e1lise de Dados","text":""},{"location":"aulas/iot/modulos/modulo18.html#21-tecnicas-basicas-de-analise-de-dados","title":"2.1 T\u00e9cnicas B\u00e1sicas de An\u00e1lise de Dados","text":"<p>A an\u00e1lise de dados envolve a aplica\u00e7\u00e3o de t\u00e9cnicas para transformar dados brutos em informa\u00e7\u00f5es \u00fateis. Algumas t\u00e9cnicas b\u00e1sicas incluem:</p> <ul> <li>C\u00e1lculo de M\u00e9dia e Mediana: Identifica valores centrais nos dados.</li> <li>Desvio Padr\u00e3o: Mede a dispers\u00e3o dos dados em rela\u00e7\u00e3o \u00e0 m\u00e9dia.</li> <li>Identifica\u00e7\u00e3o de Tend\u00eancias: Detecta padr\u00f5es ou tend\u00eancias ao longo do tempo.</li> </ul>"},{"location":"aulas/iot/modulos/modulo18.html#22-utilizacao-de-python-para-analise-de-dados-do-arduino","title":"2.2 Utiliza\u00e7\u00e3o de Python para An\u00e1lise de Dados do Arduino","text":"<p>Python \u00e9 uma linguagem poderosa para an\u00e1lise de dados, oferecendo bibliotecas como Pandas e Matplotlib para manipula\u00e7\u00e3o e visualiza\u00e7\u00e3o de dados.</p>"},{"location":"aulas/iot/modulos/modulo18.html#23-exemplo-de-codigo-em-python-para-analise-de-dados","title":"2.3 Exemplo de C\u00f3digo em Python para An\u00e1lise de Dados","text":"<pre><code>import pandas as pd\nimport matplotlib.pyplot as plt\n\n# Carrega os dados do arquivo CSV\ndados = pd.read_csv('dados.txt', sep=',', names=['Tempo', 'Temperatura'])\n\n# Calcula estat\u00edsticas b\u00e1sicas\nmedia_temp = dados['Temperatura'].mean()\nmediana_temp = dados['Temperatura'].median()\ndesvio_temp = dados['Temperatura'].std()\n\nprint(f\"Temperatura M\u00e9dia: {media_temp:.2f}\u00b0C\")\nprint(f\"Temperatura Mediana: {mediana_temp:.2f}\u00b0C\")\nprint(f\"Desvio Padr\u00e3o: {desvio_temp:.2f}\u00b0C\")\n\n# Plotagem dos dados\nplt.figure(figsize=(10,5))\nplt.plot(dados['Tempo'], dados['Temperatura'], label='Temperatura')\nplt.axhline(media_temp, color='r', linestyle='--', label='M\u00e9dia')\nplt.title('Monitoramento de Temperatura')\nplt.xlabel('Tempo (ms)')\nplt.ylabel('Temperatura (C)')\nplt.legend()\nplt.show()\n</code></pre> <p>Explica\u00e7\u00e3o:</p> <ul> <li>Carregamento de Dados: Utiliza o Pandas para ler o arquivo \"dados.txt\" e organizar os dados em um DataFrame.</li> <li>C\u00e1lculo de Estat\u00edsticas: Calcula a m\u00e9dia, mediana e desvio padr\u00e3o das temperaturas registradas.</li> <li>Visualiza\u00e7\u00e3o: Utiliza o Matplotlib para plotar a temperatura ao longo do tempo, destacando a m\u00e9dia.</li> </ul>"},{"location":"aulas/iot/modulos/modulo18.html#3-visualizacao-de-dados","title":"3. Visualiza\u00e7\u00e3o de Dados","text":""},{"location":"aulas/iot/modulos/modulo18.html#31-ferramentas-de-visualizacao","title":"3.1 Ferramentas de Visualiza\u00e7\u00e3o","text":"<p>A visualiza\u00e7\u00e3o de dados permite apresentar informa\u00e7\u00f5es de forma clara e compreens\u00edvel. Algumas ferramentas populares incluem:</p> <ul> <li>Matplotlib: Biblioteca de plotagem para Python.</li> <li>Grafana: Plataforma de visualiza\u00e7\u00e3o para m\u00e9tricas de s\u00e9ries temporais.</li> <li>Tableau: Ferramenta avan\u00e7ada de visualiza\u00e7\u00e3o de dados (n\u00e3o necessariamente gratuita).</li> </ul>"},{"location":"aulas/iot/modulos/modulo18.html#32-criacao-de-dashboards-com-grafana","title":"3.2 Cria\u00e7\u00e3o de Dashboards com Grafana","text":"<p>Grafana \u00e9 uma ferramenta poderosa para criar dashboards interativos, permitindo a visualiza\u00e7\u00e3o de dados em tempo real a partir de diversas fontes.</p>"},{"location":"aulas/iot/modulos/modulo18.html#33-exemplo-de-configuracao-do-grafana-para-dados-arduino","title":"3.3 Exemplo de Configura\u00e7\u00e3o do Grafana para Dados Arduino","text":"<pre><code>1. **Instala\u00e7\u00e3o do Grafana:**\n   - Baixe e instale o Grafana a partir do [site oficial](https://grafana.com/get).\n\n2. **Configura\u00e7\u00e3o da Fonte de Dados:**\n   - Abra o Grafana e adicione uma nova fonte de dados (por exemplo, InfluxDB ou MySQL) onde os dados do Arduino est\u00e3o armazenados.\n\n3. **Cria\u00e7\u00e3o de Painel:**\n   - Crie um novo dashboard e adicione pain\u00e9is de gr\u00e1ficos.\n   - Configure os pain\u00e9is para exibir as m\u00e9tricas desejadas, como temperatura e umidade ao longo do tempo.\n\n4. **Personaliza\u00e7\u00e3o:**\n   - Ajuste os estilos dos gr\u00e1ficos, cores e intervalos de tempo para melhor visualiza\u00e7\u00e3o.\n\n5. **Monitoramento em Tempo Real:**\n   - Utilize a funcionalidade de atualiza\u00e7\u00e3o autom\u00e1tica do Grafana para monitorar os dados em tempo real.\n</code></pre> <p>Explica\u00e7\u00e3o:</p> <ul> <li>Instala\u00e7\u00e3o e Configura\u00e7\u00e3o: Guia passo a passo para instalar e configurar o Grafana.</li> <li>Fonte de Dados: Explica como conectar o Grafana \u00e0 fonte de dados onde os dados do Arduino s\u00e3o armazenados.</li> <li>Cria\u00e7\u00e3o de Pain\u00e9is: Detalha como criar gr\u00e1ficos e personalizar dashboards para visualizar os dados coletados.</li> <li>Monitoramento: Demonstra como configurar atualiza\u00e7\u00f5es autom\u00e1ticas para monitorar os dados em tempo real.</li> </ul>"},{"location":"aulas/iot/modulos/modulo18.html#4-relatorios-e-monitoramento-em-tempo-real","title":"4. Relat\u00f3rios e Monitoramento em Tempo Real","text":""},{"location":"aulas/iot/modulos/modulo18.html#41-geracao-de-relatorios-automaticos","title":"4.1 Gera\u00e7\u00e3o de Relat\u00f3rios Autom\u00e1ticos","text":"<p>Automatizar a gera\u00e7\u00e3o de relat\u00f3rios permite a documenta\u00e7\u00e3o cont\u00ednua do desempenho e condi\u00e7\u00f5es monitoradas pelos projetos Arduino.</p>"},{"location":"aulas/iot/modulos/modulo18.html#42-configuracao-de-alertas-e-notificacoes","title":"4.2 Configura\u00e7\u00e3o de Alertas e Notifica\u00e7\u00f5es","text":"<p>Implementar alertas ajuda a responder rapidamente a condi\u00e7\u00f5es cr\u00edticas detectadas pelos sensores, como temperaturas excessivas ou n\u00edveis de umidade fora do normal.</p>"},{"location":"aulas/iot/modulos/modulo18.html#43-exemplo-de-codigo-para-envio-de-alertas-via-email-com-arduino","title":"4.3 Exemplo de C\u00f3digo para Envio de Alertas via Email com Arduino","text":"<pre><code>#include &lt;SPI.h&gt;\n#include &lt;WiFiNINA.h&gt;\n#include &lt;SMTPClient.h&gt;\n\n// Defini\u00e7\u00f5es de rede\nchar ssid[] = \"Seu_SSID\";\nchar pass[] = \"Sua_Senha\";\n\n// Defini\u00e7\u00f5es do SMTP\nconst char* smtpServer = \"smtp.gmail.com\";\nconst int smtpPort = 587;\nconst char* emailUsuario = \"seu_email@gmail.com\";\nconst char* emailSenha = \"sua_senha\";\nconst char* emailDestino = \"destino_email@gmail.com\";\n\nSMTPClient smtpClient;\n\nconst int pinoSensorTemp = A0;\nconst float limiarTemp = 30.0; // Temperatura de alerta\n\nvoid setup() {\n    Serial.begin(9600);\n    pinMode(pinoSensorTemp, INPUT);\n\n    // Conecta ao Wi-Fi\n    while (WiFi.begin(ssid, pass) != WL_CONNECTED) {\n        Serial.print(\".\");\n        delay(1000);\n    }\n    Serial.println(\"\\nConectado ao Wi-Fi\");\n}\n\nvoid loop() {\n    // Leitura do sensor de temperatura\n    int leitura = analogRead(pinoSensorTemp);\n    float tensao = leitura * (5.0 / 1023.0); // Convers\u00e3o exemplo\n\n    Serial.print(\"Tens\u00e3o da Bateria: \");\n    Serial.print(tensao);\n    Serial.println(\" V\");\n\n    // Verifica se a tens\u00e3o est\u00e1 abaixo do limiar\n    if (tensao &lt; limiarTemp) {\n        // Aciona o LED de alerta\n        digitalWrite(pinoLEDAlerta, HIGH);\n\n        // Envia alerta via MQTT\n        String mensagem = \"Alerta: N\u00edvel de bateria baixo!\";\n        client.publish(topicAlerta, mensagem);\n        Serial.println(\"Alerta enviado: N\u00edvel de bateria baixo!\");\n    } else {\n        // Desativa o LED de alerta\n        digitalWrite(pinoLEDAlerta, LOW);\n    }\n\n    // Desconecta do MQTT\n    client.disconnect();\n\n    // Entra em modo de sleep por 8 segundos para economizar energia\n    LowPower.powerDown(SLEEP_8S, ADC_OFF, BOD_OFF);\n}\n</code></pre> <p>Explica\u00e7\u00e3o:</p> <ul> <li>Monitoramento de Tens\u00e3o: L\u00ea a tens\u00e3o da bateria atrav\u00e9s de um sensor anal\u00f3gico.</li> <li>Alerta de Baixo N\u00edvel: Aciona um LED e envia uma mensagem MQTT quando a tens\u00e3o est\u00e1 abaixo do limiar definido.</li> <li>Economia de Energia: O Arduino entra em modo de sleep por 8 segundos entre as leituras para reduzir o consumo energ\u00e9tico.</li> </ul>"},{"location":"aulas/iot/modulos/modulo18.html#5-exercicios-praticos","title":"5. Exerc\u00edcios Pr\u00e1ticos","text":""},{"location":"aulas/iot/modulos/modulo18.html#exercicio-1-coletar-e-armazenar-dados-em-um-cartao-sd","title":"Exerc\u00edcio 1: Coletar e Armazenar Dados em um Cart\u00e3o SD","text":"<ul> <li> <p>Tarefa: Desenvolva um sistema que coleta dados de temperatura e umidade e os armazena em um cart\u00e3o SD.</p> </li> <li> <p>Dicas:</p> </li> <li>Utilize sensores como DHT22 para coletar dados ambientais.</li> <li>Formate os dados em formato CSV para facilitar a an\u00e1lise.</li> <li> <p>Implemente a grava\u00e7\u00e3o cont\u00ednua de dados no cart\u00e3o SD.</p> </li> <li> <p>Exemplo de C\u00f3digo: Utilize o exemplo de armazenamento de dados em cart\u00e3o SD apresentado na se\u00e7\u00e3o 1.3, adaptando-o para incluir a leitura de um sensor de umidade.</p> </li> </ul>"},{"location":"aulas/iot/modulos/modulo18.html#exercicio-2-analisar-dados-com-python","title":"Exerc\u00edcio 2: Analisar Dados com Python","text":"<ul> <li> <p>Tarefa: Importe os dados coletados do cart\u00e3o SD para um script Python e realize uma an\u00e1lise b\u00e1sica, calculando m\u00e9dia, mediana e desvio padr\u00e3o das temperaturas.</p> </li> <li> <p>Dicas:</p> </li> <li>Utilize a biblioteca Pandas para manipula\u00e7\u00e3o de dados.</li> <li>Visualize os dados utilizando gr\u00e1ficos de linha com Matplotlib.</li> <li> <p>Identifique tend\u00eancias ou picos nos dados coletados.</p> </li> <li> <p>Exemplo de C\u00f3digo: Utilize o exemplo de an\u00e1lise de dados em Python apresentado na se\u00e7\u00e3o 2.3, adaptando-o para trabalhar com os dados coletados.</p> </li> </ul>"},{"location":"aulas/iot/modulos/modulo18.html#exercicio-3-criar-um-dashboard-interativo-com-grafana","title":"Exerc\u00edcio 3: Criar um Dashboard Interativo com Grafana","text":"<ul> <li> <p>Tarefa: Configure o Grafana para criar um dashboard que visualize os dados de temperatura e umidade coletados pelo Arduino em tempo real.</p> </li> <li> <p>Dicas:</p> </li> <li>Configure uma fonte de dados adequada (como InfluxDB ou MySQL) no Grafana.</li> <li>Crie gr\u00e1ficos de linha para monitorar as m\u00e9tricas ao longo do tempo.</li> <li> <p>Personalize o layout do dashboard para facilitar a interpreta\u00e7\u00e3o dos dados.</p> </li> <li> <p>Exemplo de Configura\u00e7\u00e3o: Siga o guia apresentado na se\u00e7\u00e3o 3.3 para configurar o Grafana e criar pain\u00e9is de visualiza\u00e7\u00e3o dos dados coletados.</p> </li> </ul>"},{"location":"aulas/iot/modulos/modulo18.html#6-conceitos-importantes","title":"6. Conceitos Importantes","text":""},{"location":"aulas/iot/modulos/modulo18.html#61-analise-de-dados","title":"6.1 An\u00e1lise de Dados","text":"<ul> <li>Defini\u00e7\u00e3o: Processo de inspe\u00e7\u00e3o, limpeza e modelagem de dados com o objetivo de descobrir informa\u00e7\u00f5es \u00fateis, informar conclus\u00f5es e apoiar a tomada de decis\u00f5es.</li> <li>Import\u00e2ncia: Permite transformar dados brutos em insights acion\u00e1veis, melhorando a efici\u00eancia e efic\u00e1cia dos projetos.</li> </ul>"},{"location":"aulas/iot/modulos/modulo18.html#62-visualizacao-de-dados","title":"6.2 Visualiza\u00e7\u00e3o de Dados","text":"<ul> <li>Defini\u00e7\u00e3o: Representa\u00e7\u00e3o gr\u00e1fica dos dados para facilitar a compreens\u00e3o e comunica\u00e7\u00e3o das informa\u00e7\u00f5es.</li> <li>Ferramentas: Bibliotecas como Matplotlib, plataformas como Grafana e ferramentas de BI como Tableau.</li> </ul>"},{"location":"aulas/iot/modulos/modulo18.html#63-tecnicas-de-filtragem-de-dados","title":"6.3 T\u00e9cnicas de Filtragem de Dados","text":"<ul> <li>M\u00e9dia M\u00f3vel: Suaviza as flutua\u00e7\u00f5es nos dados calculando a m\u00e9dia de um conjunto de pontos de dados.</li> <li>Filtros Passa-Baixa: Permitem a passagem de frequ\u00eancias baixas e atenuam as altas, reduzindo o ru\u00eddo nos dados.</li> </ul>"},{"location":"aulas/iot/modulos/modulo18.html#64-integracao-com-linguagens-de-programacao-para-analise","title":"6.4 Integra\u00e7\u00e3o com Linguagens de Programa\u00e7\u00e3o para An\u00e1lise","text":"<ul> <li>Python: Utilizada amplamente para an\u00e1lise de dados devido \u00e0 sua simplicidade e \u00e0s poderosas bibliotecas dispon\u00edveis.</li> <li>R: Outra linguagem popular para an\u00e1lise estat\u00edstica e visualiza\u00e7\u00e3o de dados.</li> </ul>"},{"location":"aulas/iot/modulos/modulo18.html#65-boas-praticas-na-analise-e-visualizacao-de-dados","title":"6.5 Boas Pr\u00e1ticas na An\u00e1lise e Visualiza\u00e7\u00e3o de Dados","text":"<ul> <li>Organiza\u00e7\u00e3o dos Dados: Manter os dados bem estruturados e organizados facilita a an\u00e1lise e a visualiza\u00e7\u00e3o.</li> <li>Documenta\u00e7\u00e3o: Registrar os processos e m\u00e9todos utilizados na an\u00e1lise para futuras refer\u00eancias e replica\u00e7\u00f5es.</li> <li>Visualiza\u00e7\u00f5es Claras: Criar gr\u00e1ficos e dashboards que comuniquem efetivamente as informa\u00e7\u00f5es sem sobrecarregar o usu\u00e1rio com dados desnecess\u00e1rios.</li> </ul>"},{"location":"aulas/iot/modulos/modulo18.html#7-recursos-adicionais","title":"7. Recursos Adicionais","text":"<ul> <li> <p>Documenta\u00e7\u00e3o Oficial do Arduino:</p> </li> <li> <p>SD Library</p> </li> <li>DHT Sensor Library</li> <li>ArduinoBLE Library</li> <li> <p>SPI Library</p> </li> <li> <p>Tutoriais e Guias:</p> </li> <li> <p>Coletando e Armazenando Dados com Arduino e SD Card</p> </li> <li>An\u00e1lise de Dados com Python para Projetos Arduino</li> <li> <p>Criando Dashboards Interativos com Grafana</p> </li> <li> <p>V\u00eddeos Educacionais:</p> </li> <li> <p>Coletando e Armazenando Dados com Arduino e SD Card</p> </li> <li>An\u00e1lise de Dados com Python</li> <li>Criando Dashboards com Grafana</li> </ul>"},{"location":"aulas/iot/modulos/modulo18.html#8-exemplos-praticos","title":"8. Exemplos Pr\u00e1ticos","text":""},{"location":"aulas/iot/modulos/modulo18.html#81-sistema-de-monitoramento-ambiental-completo","title":"8.1 Sistema de Monitoramento Ambiental Completo","text":"<p>Este exemplo integra a coleta de dados, armazenamento, an\u00e1lise e visualiza\u00e7\u00e3o para criar um sistema de monitoramento ambiental completo.</p> <pre><code>#include &lt;SPI.h&gt;\n#include &lt;SD.h&gt;\n#include &lt;DHT.h&gt;\n#include &lt;WiFiNINA.h&gt;\n#include &lt;MQTTClient.h&gt;\n\n#define DHTPIN 2\n#define DHTTYPE DHT22\nDHT dht(DHTPIN, DHTTYPE);\n\nconst int pinoCS = 10; // Pino de sele\u00e7\u00e3o do cart\u00e3o SD\nFile arquivo;\n\nconst char* ssid = \"Seu_SSID\";\nconst char* password = \"Sua_Senha\";\nconst char* broker = \"broker.hivemq.com\";\nconst int port = 1883;\nconst char* topic = \"arduino/monitoramento\";\n\nWiFiClient net;\nMQTTClient client;\n\nvoid setup() {\n    Serial.begin(9600);\n    while (!Serial);\n\n    pinMode(pinoCS, OUTPUT);\n    if (!SD.begin(pinoCS)) {\n        Serial.println(\"Falha na inicializa\u00e7\u00e3o do cart\u00e3o SD!\");\n        while (1);\n    }\n    Serial.println(\"Cart\u00e3o SD inicializado.\");\n\n    arquivo = SD.open(\"dados.csv\", FILE_WRITE);\n    if (arquivo) {\n        arquivo.println(\"Tempo,Temperatura,Umidade\");\n        arquivo.close();\n    } else {\n        Serial.println(\"Falha ao abrir o arquivo.\");\n    }\n\n    dht.begin();\n\n    // Conecta ao Wi-Fi\n    WiFi.begin(ssid, password);\n    while (WiFi.status() != WL_CONNECTED) {\n        delay(500);\n        Serial.print(\".\");\n    }\n    Serial.println(\"\\nConectado ao Wi-Fi\");\n\n    // Conecta ao MQTT broker\n    client.begin(broker, port, net);\n    while (!client.connect(\"ArduinoClient\")) {\n        Serial.print(\".\");\n        delay(1000);\n    }\n    Serial.println(\"\\nConectado ao MQTT broker\");\n}\n\nvoid loop() {\n    // Leitura dos sensores\n    unsigned long tempo = millis();\n    float temperatura = dht.readTemperature();\n    float umidade = dht.readHumidity();\n\n    if (isnan(temperatura) || isnan(umidade)) {\n        Serial.println(\"Falha na leitura dos sensores DHT!\");\n        return;\n    }\n\n    // Armazenamento dos dados no cart\u00e3o SD\n    arquivo = SD.open(\"dados.csv\", FILE_WRITE);\n    if (arquivo) {\n        arquivo.print(tempo);\n        arquivo.print(\",\");\n        arquivo.print(temperatura);\n        arquivo.print(\",\");\n        arquivo.println(umidade);\n        arquivo.close();\n        Serial.println(\"Dados registrados no cart\u00e3o SD.\");\n    } else {\n        Serial.println(\"Falha ao abrir o arquivo para escrita.\");\n    }\n\n    // Envio dos dados via MQTT\n    String mensagem = \"Tempo: \" + String(tempo) + \" ms, Temperatura: \" + String(temperatura) + \"\u00b0C, Umidade: \" + String(umidade) + \"%\";\n    client.publish(topic, mensagem);\n    Serial.println(\"Dados enviados via MQTT: \" + mensagem);\n\n    delay(60000); // Aguarda 1 minuto antes da pr\u00f3xima leitura\n}\n</code></pre> <p>Explica\u00e7\u00e3o:</p> <ul> <li>Coleta de Dados: L\u00ea a temperatura e umidade do sensor DHT22.</li> <li>Armazenamento Local: Grava os dados no cart\u00e3o SD em formato CSV para f\u00e1cil importa\u00e7\u00e3o e an\u00e1lise.</li> <li>Envio de Dados via MQTT: Transmite os dados para um broker MQTT, permitindo a integra\u00e7\u00e3o com dashboards e sistemas de monitoramento.</li> <li>Monitoramento Cont\u00ednuo: Realiza a coleta e envio de dados a cada minuto.</li> </ul>"},{"location":"aulas/iot/modulos/modulo18.html#82-analise-de-dados-com-pandas-e-visualizacao-com-matplotlib","title":"8.2 An\u00e1lise de Dados com Pandas e Visualiza\u00e7\u00e3o com Matplotlib","text":"<p>Este exemplo demonstra como importar os dados coletados do cart\u00e3o SD para um script Python, realizar an\u00e1lises estat\u00edsticas b\u00e1sicas e visualizar os resultados.</p> <pre><code>import pandas as pd\nimport matplotlib.pyplot as plt\n\n# Carrega os dados do arquivo CSV\ndados = pd.read_csv('dados.csv')\n\n# Exibe as primeiras linhas do DataFrame\nprint(dados.head())\n\n# Calcula estat\u00edsticas b\u00e1sicas\nmedia_temp = dados['Temperatura'].mean()\nmediana_temp = dados['Temperatura'].median()\ndesvio_temp = dados['Temperatura'].std()\n\nmedia_umid = dados['Umidade'].mean()\nmediana_umid = dados['Umidade'].median()\ndesvio_umid = dados['Umidade'].std()\n\nprint(f\"Temperatura M\u00e9dia: {media_temp:.2f}\u00b0C\")\nprint(f\"Temperatura Mediana: {mediana_temp:.2f}\u00b0C\")\nprint(f\"Desvio Padr\u00e3o da Temperatura: {desvio_temp:.2f}\u00b0C\")\n\nprint(f\"Umidade M\u00e9dia: {media_umid:.2f}%\")\nprint(f\"Umidade Mediana: {mediana_umid:.2f}%\")\nprint(f\"Desvio Padr\u00e3o da Umidade: {desvio_umid:.2f}%\")\n\n# Plotagem dos dados\nplt.figure(figsize=(12,6))\n\nplt.subplot(2,1,1)\nplt.plot(dados['Tempo'], dados['Temperatura'], label='Temperatura')\nplt.axhline(media_temp, color='r', linestyle='--', label='M\u00e9dia')\nplt.title('Monitoramento de Temperatura')\nplt.xlabel('Tempo (ms)')\nplt.ylabel('Temperatura (C)')\nplt.legend()\n\nplt.subplot(2,1,2)\nplt.plot(dados['Tempo'], dados['Umidade'], label='Umidade', color='g')\nplt.axhline(media_umid, color='r', linestyle='--', label='M\u00e9dia')\nplt.title('Monitoramento de Umidade')\nplt.xlabel('Tempo (ms)')\nplt.ylabel('Umidade (%)')\nplt.legend()\n\nplt.tight_layout()\nplt.show()\n</code></pre> <p>Explica\u00e7\u00e3o:</p> <ul> <li>Importa\u00e7\u00e3o de Dados: Utiliza o Pandas para ler o arquivo CSV contendo os dados de tempo, temperatura e umidade.</li> <li>An\u00e1lise Estat\u00edstica: Calcula a m\u00e9dia, mediana e desvio padr\u00e3o para cada m\u00e9trica.</li> <li>Visualiza\u00e7\u00e3o: Cria gr\u00e1ficos de linha para visualizar as tend\u00eancias de temperatura e umidade ao longo do tempo, destacando a m\u00e9dia.</li> </ul>"},{"location":"aulas/iot/modulos/modulo18.html#7-conceitos-importantes","title":"7. Conceitos Importantes","text":""},{"location":"aulas/iot/modulos/modulo18.html#71-analise-de-dados","title":"7.1 An\u00e1lise de Dados","text":"<ul> <li>Defini\u00e7\u00e3o: Processo de inspe\u00e7\u00e3o, limpeza e modelagem de dados com o objetivo de descobrir informa\u00e7\u00f5es \u00fateis, informar conclus\u00f5es e apoiar a tomada de decis\u00f5es.</li> <li>Import\u00e2ncia: Permite transformar dados brutos em insights acion\u00e1veis, melhorando a efici\u00eancia e efic\u00e1cia dos projetos.</li> </ul>"},{"location":"aulas/iot/modulos/modulo18.html#72-visualizacao-de-dados","title":"7.2 Visualiza\u00e7\u00e3o de Dados","text":"<ul> <li>Defini\u00e7\u00e3o: Representa\u00e7\u00e3o gr\u00e1fica dos dados para facilitar a compreens\u00e3o e comunica\u00e7\u00e3o das informa\u00e7\u00f5es.</li> <li>Ferramentas: Bibliotecas como Matplotlib, plataformas como Grafana e ferramentas de BI como Tableau.</li> </ul>"},{"location":"aulas/iot/modulos/modulo18.html#73-tecnicas-de-filtragem-de-dados","title":"7.3 T\u00e9cnicas de Filtragem de Dados","text":"<ul> <li>M\u00e9dia M\u00f3vel: Suaviza as flutua\u00e7\u00f5es nos dados calculando a m\u00e9dia de um conjunto de pontos de dados.</li> <li>Filtros Passa-Baixa: Permitem a passagem de frequ\u00eancias baixas e atenuam as altas, reduzindo o ru\u00eddo nos dados.</li> </ul>"},{"location":"aulas/iot/modulos/modulo18.html#74-integracao-com-linguagens-de-programacao-para-analise","title":"7.4 Integra\u00e7\u00e3o com Linguagens de Programa\u00e7\u00e3o para An\u00e1lise","text":"<ul> <li>Python: Utilizada amplamente para an\u00e1lise de dados devido \u00e0 sua simplicidade e \u00e0s poderosas bibliotecas dispon\u00edveis.</li> <li>R: Outra linguagem popular para an\u00e1lise estat\u00edstica e visualiza\u00e7\u00e3o de dados.</li> </ul>"},{"location":"aulas/iot/modulos/modulo18.html#75-boas-praticas-na-analise-e-visualizacao-de-dados","title":"7.5 Boas Pr\u00e1ticas na An\u00e1lise e Visualiza\u00e7\u00e3o de Dados","text":"<ul> <li>Organiza\u00e7\u00e3o dos Dados: Manter os dados bem estruturados e organizados facilita a an\u00e1lise e a visualiza\u00e7\u00e3o.</li> <li>Documenta\u00e7\u00e3o: Registrar os processos e m\u00e9todos utilizados na an\u00e1lise para futuras refer\u00eancias e replica\u00e7\u00f5es.</li> <li>Visualiza\u00e7\u00f5es Claras: Criar gr\u00e1ficos e dashboards que comuniquem efetivamente as informa\u00e7\u00f5es sem sobrecarregar o usu\u00e1rio com dados desnecess\u00e1rios.</li> </ul>"},{"location":"aulas/iot/modulos/modulo18.html#8-recursos-adicionais","title":"8. Recursos Adicionais","text":"<ul> <li> <p>Documenta\u00e7\u00e3o Oficial do Arduino:</p> </li> <li> <p>SD Library</p> </li> <li>DHT Sensor Library</li> <li>ArduinoBLE Library</li> <li> <p>SPI Library</p> </li> <li> <p>Tutoriais e Guias:</p> </li> <li> <p>Coletando e Armazenando Dados com Arduino e SD Card</p> </li> <li>An\u00e1lise de Dados com Python para Projetos Arduino</li> <li> <p>Criando Dashboards Interativos com Grafana</p> </li> <li> <p>V\u00eddeos Educacionais:</p> </li> <li> <p>Coletando e Armazenando Dados com Arduino e SD Card</p> </li> <li>An\u00e1lise de Dados com Python</li> <li>Criando Dashboards com Grafana</li> </ul>"},{"location":"aulas/iot/modulos/modulo18.html#9-exemplos-praticos","title":"9. Exemplos Pr\u00e1ticos","text":""},{"location":"aulas/iot/modulos/modulo18.html#91-sistema-de-monitoramento-ambiental-completo","title":"9.1 Sistema de Monitoramento Ambiental Completo","text":"<p>Este exemplo integra a coleta de dados, armazenamento, an\u00e1lise e visualiza\u00e7\u00e3o para criar um sistema de monitoramento ambiental completo.</p> <pre><code>#include &lt;SPI.h&gt;\n#include &lt;SD.h&gt;\n#include &lt;DHT.h&gt;\n#include &lt;WiFiNINA.h&gt;\n#include &lt;MQTTClient.h&gt;\n\n#define DHTPIN 2\n#define DHTTYPE DHT22\nDHT dht(DHTPIN, DHTTYPE);\n\nconst int pinoCS = 10; // Pino de sele\u00e7\u00e3o do cart\u00e3o SD\nFile arquivo;\n\nconst char* ssid = \"Seu_SSID\";\nconst char* password = \"Sua_Senha\";\nconst char* broker = \"broker.hivemq.com\";\nconst int port = 1883;\nconst char* topic = \"arduino/monitoramento\";\n\nWiFiClient net;\nMQTTClient client;\n\nvoid setup() {\n    Serial.begin(9600);\n    while (!Serial);\n\n    pinMode(pinoCS, OUTPUT);\n    if (!SD.begin(pinoCS)) {\n        Serial.println(\"Falha na inicializa\u00e7\u00e3o do cart\u00e3o SD!\");\n        while (1);\n    }\n    Serial.println(\"Cart\u00e3o SD inicializado.\");\n\n    arquivo = SD.open(\"dados.csv\", FILE_WRITE);\n    if (arquivo) {\n        arquivo.println(\"Tempo,Temperatura,Umidade\");\n        arquivo.close();\n    } else {\n        Serial.println(\"Falha ao abrir o arquivo.\");\n    }\n\n    dht.begin();\n\n    // Conecta ao Wi-Fi\n    WiFi.begin(ssid, password);\n    while (WiFi.status() != WL_CONNECTED) {\n        delay(500);\n        Serial.print(\".\");\n    }\n    Serial.println(\"\\nConectado ao Wi-Fi\");\n\n    // Conecta ao MQTT broker\n    client.begin(broker, port, net);\n    while (!client.connect(\"ArduinoClient\")) {\n        Serial.print(\".\");\n        delay(1000);\n    }\n    Serial.println(\"\\nConectado ao MQTT broker\");\n}\n\nvoid loop() {\n    // Leitura dos sensores\n    unsigned long tempo = millis();\n    float temperatura = dht.readTemperature();\n    float umidade = dht.readHumidity();\n\n    if (isnan(temperatura) || isnan(umidade)) {\n        Serial.println(\"Falha na leitura dos sensores DHT!\");\n        return;\n    }\n\n    // Armazenamento dos dados no cart\u00e3o SD\n    arquivo = SD.open(\"dados.csv\", FILE_WRITE);\n    if (arquivo) {\n        arquivo.print(tempo);\n        arquivo.print(\",\");\n        arquivo.print(temperatura);\n        arquivo.print(\",\");\n        arquivo.println(umidade);\n        arquivo.close();\n        Serial.println(\"Dados registrados no cart\u00e3o SD.\");\n    } else {\n        Serial.println(\"Falha ao abrir o arquivo para escrita.\");\n    }\n\n    // Envio dos dados via MQTT\n    String mensagem = \"Tempo: \" + String(tempo) + \" ms, Temperatura: \" + String(temperatura) + \"\u00b0C, Umidade: \" + String(umidade) + \"%\";\n    client.publish(topic, mensagem);\n    Serial.println(\"Dados enviados via MQTT: \" + mensagem);\n\n    delay(60000); // Aguarda 1 minuto antes da pr\u00f3xima leitura\n}\n</code></pre> <p>Explica\u00e7\u00e3o:</p> <ul> <li>Coleta de Dados: L\u00ea a temperatura e umidade do sensor DHT22.</li> <li>Armazenamento Local: Grava os dados no cart\u00e3o SD em formato CSV para f\u00e1cil importa\u00e7\u00e3o e an\u00e1lise.</li> <li>Envio de Dados via MQTT: Transmite os dados para um broker MQTT, permitindo a integra\u00e7\u00e3o com dashboards e sistemas de monitoramento.</li> <li>Monitoramento Cont\u00ednuo: Realiza a coleta e envio de dados a cada minuto.</li> </ul>"},{"location":"aulas/iot/modulos/modulo18.html#92-analise-de-dados-com-pandas-e-visualizacao-com-matplotlib","title":"9.2 An\u00e1lise de Dados com Pandas e Visualiza\u00e7\u00e3o com Matplotlib","text":"<p>Este exemplo demonstra como importar os dados coletados do cart\u00e3o SD para um script Python, realizar an\u00e1lises estat\u00edsticas b\u00e1sicas e visualizar os resultados.</p> <pre><code>import pandas as pd\nimport matplotlib.pyplot as plt\n\n# Carrega os dados do arquivo CSV\ndados = pd.read_csv('dados.csv')\n\n# Exibe as primeiras linhas do DataFrame\nprint(dados.head())\n\n# Calcula estat\u00edsticas b\u00e1sicas\nmedia_temp = dados['Temperatura'].mean()\nmediana_temp = dados['Temperatura'].median()\ndesvio_temp = dados['Temperatura'].std()\n\nmedia_umid = dados['Umidade'].mean()\nmediana_umid = dados['Umidade'].median()\ndesvio_umid = dados['Umidade'].std()\n\nprint(f\"Temperatura M\u00e9dia: {media_temp:.2f}\u00b0C\")\nprint(f\"Temperatura Mediana: {mediana_temp:.2f}\u00b0C\")\nprint(f\"Desvio Padr\u00e3o da Temperatura: {desvio_temp:.2f}\u00b0C\")\n\nprint(f\"Umidade M\u00e9dia: {media_umid:.2f}%\")\nprint(f\"Umidade Mediana: {mediana_umid:.2f}%\")\nprint(f\"Desvio Padr\u00e3o da Umidade: {desvio_umid:.2f}%\")\n\n# Plotagem dos dados\nplt.figure(figsize=(12,6))\n\nplt.subplot(2,1,1)\nplt.plot(dados['Tempo'], dados['Temperatura'], label='Temperatura')\nplt.axhline(media_temp, color='r', linestyle='--', label='M\u00e9dia')\nplt.title('Monitoramento de Temperatura')\nplt.xlabel('Tempo (ms)')\nplt.ylabel('Temperatura (C)')\nplt.legend()\n\nplt.subplot(2,1,2)\nplt.plot(dados['Tempo'], dados['Umidade'], label='Umidade', color='g')\nplt.axhline(media_umid, color='r', linestyle='--', label='M\u00e9dia')\nplt.title('Monitoramento de Umidade')\nplt.xlabel('Tempo (ms)')\nplt.ylabel('Umidade (%)')\nplt.legend()\n\nplt.tight_layout()\nplt.show()\n</code></pre> <p>Explica\u00e7\u00e3o:</p> <ul> <li>Importa\u00e7\u00e3o de Dados: Utiliza o Pandas para ler o arquivo CSV contendo os dados de tempo, temperatura e umidade.</li> <li>An\u00e1lise Estat\u00edstica: Calcula a m\u00e9dia, mediana e desvio padr\u00e3o para cada m\u00e9trica.</li> <li>Visualiza\u00e7\u00e3o: Cria gr\u00e1ficos de linha para visualizar as tend\u00eancias de temperatura e umidade ao longo do tempo, destacando a m\u00e9dia.</li> </ul>"},{"location":"aulas/iot/modulos/modulo18.html#7-conceitos-importantes_1","title":"7. Conceitos Importantes","text":""},{"location":"aulas/iot/modulos/modulo18.html#71-analise-de-dados_1","title":"7.1 An\u00e1lise de Dados","text":"<ul> <li>Defini\u00e7\u00e3o: Processo de inspe\u00e7\u00e3o, limpeza e modelagem de dados com o objetivo de descobrir informa\u00e7\u00f5es \u00fateis, informar conclus\u00f5es e apoiar a tomada de decis\u00f5es.</li> <li>Import\u00e2ncia: Permite transformar dados brutos em insights acion\u00e1veis, melhorando a efici\u00eancia e efic\u00e1cia dos projetos.</li> </ul>"},{"location":"aulas/iot/modulos/modulo18.html#72-visualizacao-de-dados_1","title":"7.2 Visualiza\u00e7\u00e3o de Dados","text":"<ul> <li>Defini\u00e7\u00e3o: Representa\u00e7\u00e3o gr\u00e1fica dos dados para facilitar a compreens\u00e3o e comunica\u00e7\u00e3o das informa\u00e7\u00f5es.</li> <li>Ferramentas: Bibliotecas como Matplotlib, plataformas como Grafana e ferramentas de BI como Tableau.</li> </ul>"},{"location":"aulas/iot/modulos/modulo18.html#73-tecnicas-de-filtragem-de-dados_1","title":"7.3 T\u00e9cnicas de Filtragem de Dados","text":"<ul> <li>M\u00e9dia M\u00f3vel: Suaviza as flutua\u00e7\u00f5es nos dados calculando a m\u00e9dia de um conjunto de pontos de dados.</li> <li>Filtros Passa-Baixa: Permitem a passagem de frequ\u00eancias baixas e atenuam as altas, reduzindo o ru\u00eddo nos dados.</li> </ul>"},{"location":"aulas/iot/modulos/modulo18.html#74-integracao-com-linguagens-de-programacao-para-analise_1","title":"7.4 Integra\u00e7\u00e3o com Linguagens de Programa\u00e7\u00e3o para An\u00e1lise","text":"<ul> <li>Python: Utilizada amplamente para an\u00e1lise de dados devido \u00e0 sua simplicidade e \u00e0s poderosas bibliotecas dispon\u00edveis.</li> <li>R: Outra linguagem popular para an\u00e1lise estat\u00edstica e visualiza\u00e7\u00e3o de dados.</li> </ul>"},{"location":"aulas/iot/modulos/modulo18.html#75-boas-praticas-na-analise-e-visualizacao-de-dados_1","title":"7.5 Boas Pr\u00e1ticas na An\u00e1lise e Visualiza\u00e7\u00e3o de Dados","text":"<ul> <li>Organiza\u00e7\u00e3o dos Dados: Manter os dados bem estruturados e organizados facilita a an\u00e1lise e a visualiza\u00e7\u00e3o.</li> <li>Documenta\u00e7\u00e3o: Registrar os processos e m\u00e9todos utilizados na an\u00e1lise para futuras refer\u00eancias e replica\u00e7\u00f5es.</li> <li>Visualiza\u00e7\u00f5es Claras: Criar gr\u00e1ficos e dashboards que comuniquem efetivamente as informa\u00e7\u00f5es sem sobrecarregar o usu\u00e1rio com dados desnecess\u00e1rios.</li> </ul>"},{"location":"aulas/iot/modulos/modulo18.html#8-recursos-adicionais_1","title":"8. Recursos Adicionais","text":"<ul> <li> <p>Documenta\u00e7\u00e3o Oficial do Arduino:</p> </li> <li> <p>SD Library</p> </li> <li>DHT Sensor Library</li> <li>ArduinoBLE Library</li> <li> <p>SPI Library</p> </li> <li> <p>Tutoriais e Guias:</p> </li> <li> <p>Coletando e Armazenando Dados com Arduino e SD Card</p> </li> <li>An\u00e1lise de Dados com Python para Projetos Arduino</li> <li> <p>Criando Dashboards Interativos com Grafana</p> </li> <li> <p>V\u00eddeos Educacionais:</p> </li> <li> <p>Coletando e Armazenando Dados com Arduino e SD Card</p> </li> <li>An\u00e1lise de Dados com Python</li> <li>Criando Dashboards com Grafana</li> </ul>"},{"location":"aulas/iot/modulos/modulo18.html#9-exemplos-praticos_1","title":"9. Exemplos Pr\u00e1ticos","text":""},{"location":"aulas/iot/modulos/modulo18.html#91-sistema-de-monitoramento-ambiental-completo_1","title":"9.1 Sistema de Monitoramento Ambiental Completo","text":"<p>Este exemplo integra a coleta de dados, armazenamento, an\u00e1lise e visualiza\u00e7\u00e3o para criar um sistema de monitoramento ambiental completo.</p> <pre><code>#include &lt;SPI.h&gt;\n#include &lt;SD.h&gt;\n#include &lt;DHT.h&gt;\n#include &lt;WiFiNINA.h&gt;\n#include &lt;MQTTClient.h&gt;\n\n#define DHTPIN 2\n#define DHTTYPE DHT22\nDHT dht(DHTPIN, DHTTYPE);\n\nconst int pinoCS = 10; // Pino de sele\u00e7\u00e3o do cart\u00e3o SD\nFile arquivo;\n\nconst char* ssid = \"Seu_SSID\";\nconst char* password = \"Sua_Senha\";\nconst char* broker = \"broker.hivemq.com\";\nconst int port = 1883;\nconst char* topic = \"arduino/monitoramento\";\n\nWiFiClient net;\nMQTTClient client;\n\nvoid setup() {\n    Serial.begin(9600);\n    while (!Serial);\n\n    pinMode(pinoCS, OUTPUT);\n    if (!SD.begin(pinoCS)) {\n        Serial.println(\"Falha na inicializa\u00e7\u00e3o do cart\u00e3o SD!\");\n        while (1);\n    }\n    Serial.println(\"Cart\u00e3o SD inicializado.\");\n\n    arquivo = SD.open(\"dados.csv\", FILE_WRITE);\n    if (arquivo) {\n        arquivo.println(\"Tempo,Temperatura,Umidade\");\n        arquivo.close();\n    } else {\n        Serial.println(\"Falha ao abrir o arquivo.\");\n    }\n\n    dht.begin();\n\n    // Conecta ao Wi-Fi\n    WiFi.begin(ssid, password);\n    while (WiFi.status() != WL_CONNECTED) {\n        delay(500);\n        Serial.print(\".\");\n    }\n    Serial.println(\"\\nConectado ao Wi-Fi\");\n\n    // Conecta ao MQTT broker\n    client.begin(broker, port, net);\n    while (!client.connect(\"ArduinoClient\")) {\n        Serial.print(\".\");\n        delay(1000);\n    }\n    Serial.println(\"\\nConectado ao MQTT broker\");\n}\n\nvoid loop() {\n    // Leitura dos sensores\n    unsigned long tempo = millis();\n    float temperatura = dht.readTemperature();\n    float umidade = dht.readHumidity();\n\n    if (isnan(temperatura) || isnan(umidade)) {\n        Serial.println(\"Falha na leitura dos sensores DHT!\");\n        return;\n    }\n\n    // Armazenamento dos dados no cart\u00e3o SD\n    arquivo = SD.open(\"dados.csv\", FILE_WRITE);\n    if (arquivo) {\n        arquivo.print(tempo);\n        arquivo.print(\",\");\n        arquivo.print(temperatura);\n        arquivo.print(\",\");\n        arquivo.println(umidade);\n        arquivo.close();\n        Serial.println(\"Dados registrados no cart\u00e3o SD.\");\n    } else {\n        Serial.println(\"Falha ao abrir o arquivo para escrita.\");\n    }\n\n    // Envio dos dados via MQTT\n    String mensagem = \"Tempo: \" + String(tempo) + \" ms, Temperatura: \" + String(temperatura) + \"\u00b0C, Umidade: \" + String(umidade) + \"%\";\n    client.publish(topic, mensagem);\n    Serial.println(\"Dados enviados via MQTT: \" + mensagem);\n\n    delay(60000); // Aguarda 1 minuto antes da pr\u00f3xima leitura\n}\n</code></pre> <p>Explica\u00e7\u00e3o:</p> <ul> <li>Coleta de Dados: L\u00ea a temperatura e umidade do sensor DHT22.</li> <li>Armazenamento Local: Grava os dados no cart\u00e3o SD em formato CSV para f\u00e1cil importa\u00e7\u00e3o e an\u00e1lise.</li> <li>Envio de Dados via MQTT: Transmite os dados para um broker MQTT, permitindo a integra\u00e7\u00e3o com dashboards e sistemas de monitoramento.</li> <li>Monitoramento Cont\u00ednuo: Realiza a coleta e envio de dados a cada minuto.</li> </ul>"},{"location":"aulas/iot/modulos/modulo18.html#92-analise-de-dados-com-pandas-e-visualizacao-com-matplotlib_1","title":"9.2 An\u00e1lise de Dados com Pandas e Visualiza\u00e7\u00e3o com Matplotlib","text":"<p>Este exemplo demonstra como importar os dados coletados do cart\u00e3o SD para um script Python, realizar an\u00e1lises estat\u00edsticas b\u00e1sicas e visualizar os resultados.</p> <pre><code>import pandas as pd\nimport matplotlib.pyplot as plt\n\n# Carrega os dados do arquivo CSV\ndados = pd.read_csv('dados.csv')\n\n# Exibe as primeiras linhas do DataFrame\nprint(dados.head())\n\n# Calcula estat\u00edsticas b\u00e1sicas\nmedia_temp = dados['Temperatura'].mean()\nmediana_temp = dados['Temperatura'].median()\ndesvio_temp = dados['Temperatura'].std()\n\nmedia_umid = dados['Umidade'].mean()\nmediana_umid = dados['Umidade'].median()\ndesvio_umid = dados['Umidade'].std()\n\nprint(f\"Temperatura M\u00e9dia: {media_temp:.2f}\u00b0C\")\nprint(f\"Temperatura Mediana: {mediana_temp:.2f}\u00b0C\")\nprint(f\"Desvio Padr\u00e3o da Temperatura: {desvio_temp:.2f}\u00b0C\")\n\nprint(f\"Umidade M\u00e9dia: {media_umid:.2f}%\")\nprint(f\"Umidade Mediana: {mediana_umid:.2f}%\")\nprint(f\"Desvio Padr\u00e3o da Umidade: {desvio_umid:.2f}%\")\n\n# Plotagem dos dados\nplt.figure(figsize=(12,6))\n\nplt.subplot(2,1,1)\nplt.plot(dados['Tempo'], dados['Temperatura'], label='Temperatura')\nplt.axhline(media_temp, color='r', linestyle='--', label='M\u00e9dia')\nplt.title('Monitoramento de Temperatura')\nplt.xlabel('Tempo (ms)')\nplt.ylabel('Temperatura (C)')\nplt.legend()\n\nplt.subplot(2,1,2)\nplt.plot(dados['Tempo'], dados['Umidade'], label='Umidade', color='g')\nplt.axhline(media_umid, color='r', linestyle='--', label='M\u00e9dia')\nplt.title('Monitoramento de Umidade')\nplt.xlabel('Tempo (ms)')\nplt.ylabel('Umidade (%)')\nplt.legend()\n\nplt.tight_layout()\nplt.show()\n</code></pre> <p>Explica\u00e7\u00e3o:</p> <ul> <li>Importa\u00e7\u00e3o de Dados: Utiliza o Pandas para ler o arquivo CSV contendo os dados de tempo, temperatura e umidade.</li> <li>An\u00e1lise Estat\u00edstica: Calcula a m\u00e9dia, mediana e desvio padr\u00e3o para cada m\u00e9trica.</li> <li>Visualiza\u00e7\u00e3o: Cria gr\u00e1ficos de linha para visualizar as tend\u00eancias de temperatura e umidade ao longo do tempo, destacando a m\u00e9dia.</li> </ul>"},{"location":"aulas/iot/modulos/modulo18.html#10-conceitos-importantes","title":"10. Conceitos Importantes","text":""},{"location":"aulas/iot/modulos/modulo18.html#101-analise-de-dados","title":"10.1 An\u00e1lise de Dados","text":"<ul> <li>Defini\u00e7\u00e3o: Processo de inspe\u00e7\u00e3o, limpeza e modelagem de dados com o objetivo de descobrir informa\u00e7\u00f5es \u00fateis, informar conclus\u00f5es e apoiar a tomada de decis\u00f5es.</li> <li>Import\u00e2ncia: Permite transformar dados brutos em insights acion\u00e1veis, melhorando a efici\u00eancia e efic\u00e1cia dos projetos.</li> </ul>"},{"location":"aulas/iot/modulos/modulo18.html#102-visualizacao-de-dados","title":"10.2 Visualiza\u00e7\u00e3o de Dados","text":"<ul> <li>Defini\u00e7\u00e3o: Representa\u00e7\u00e3o gr\u00e1fica dos dados para facilitar a compreens\u00e3o e comunica\u00e7\u00e3o das informa\u00e7\u00f5es.</li> <li>Ferramentas: Bibliotecas como Matplotlib, plataformas como Grafana e ferramentas de BI como Tableau.</li> </ul>"},{"location":"aulas/iot/modulos/modulo18.html#103-tecnicas-de-filtragem-de-dados","title":"10.3 T\u00e9cnicas de Filtragem de Dados","text":"<ul> <li>M\u00e9dia M\u00f3vel: Suaviza as flutua\u00e7\u00f5es nos dados calculando a m\u00e9dia de um conjunto de pontos de dados.</li> <li>Filtros Passa-Baixa: Permitem a passagem de frequ\u00eancias baixas e atenuam as altas, reduzindo o ru\u00eddo nos dados.</li> </ul>"},{"location":"aulas/iot/modulos/modulo18.html#104-integracao-com-linguagens-de-programacao-para-analise","title":"10.4 Integra\u00e7\u00e3o com Linguagens de Programa\u00e7\u00e3o para An\u00e1lise","text":"<ul> <li>Python: Utilizada amplamente para an\u00e1lise de dados devido \u00e0 sua simplicidade e \u00e0s poderosas bibliotecas dispon\u00edveis.</li> <li>R: Outra linguagem popular para an\u00e1lise estat\u00edstica e visualiza\u00e7\u00e3o de dados.</li> </ul>"},{"location":"aulas/iot/modulos/modulo18.html#105-boas-praticas-na-analise-e-visualizacao-de-dados","title":"10.5 Boas Pr\u00e1ticas na An\u00e1lise e Visualiza\u00e7\u00e3o de Dados","text":"<ul> <li>Organiza\u00e7\u00e3o dos Dados: Manter os dados bem estruturados e organizados facilita a an\u00e1lise e a visualiza\u00e7\u00e3o.</li> <li>Documenta\u00e7\u00e3o: Registrar os processos e m\u00e9todos utilizados na an\u00e1lise para futuras refer\u00eancias e replica\u00e7\u00f5es.</li> <li>Visualiza\u00e7\u00f5es Claras: Criar gr\u00e1ficos e dashboards que comuniquem efetivamente as informa\u00e7\u00f5es sem sobrecarregar o usu\u00e1rio com dados desnecess\u00e1rios.</li> </ul>"},{"location":"aulas/iot/modulos/modulo18.html#11-recursos-adicionais","title":"11. Recursos Adicionais","text":"<ul> <li> <p>Documenta\u00e7\u00e3o Oficial do Arduino:</p> </li> <li> <p>SD Library</p> </li> <li>DHT Sensor Library</li> <li>ArduinoBLE Library</li> <li> <p>SPI Library</p> </li> <li> <p>Tutoriais e Guias:</p> </li> <li> <p>Coletando e Armazenando Dados com Arduino e SD Card</p> </li> <li>An\u00e1lise de Dados com Python para Projetos Arduino</li> <li> <p>Criando Dashboards Interativos com Grafana</p> </li> <li> <p>V\u00eddeos Educacionais:</p> </li> <li> <p>Coletando e Armazenando Dados com Arduino e SD Card</p> </li> <li>An\u00e1lise de Dados com Python</li> <li>Criando Dashboards com Grafana</li> </ul>"},{"location":"aulas/iot/modulos/modulo18.html#12-exemplos-praticos","title":"12. Exemplos Pr\u00e1ticos","text":""},{"location":"aulas/iot/modulos/modulo18.html#121-sistema-de-monitoramento-ambiental-completo","title":"12.1 Sistema de Monitoramento Ambiental Completo","text":"<p>Este exemplo integra a coleta de dados, armazenamento, an\u00e1lise e visualiza\u00e7\u00e3o para criar um sistema de monitoramento ambiental completo.</p> <pre><code>#include &lt;SPI.h&gt;\n#include &lt;SD.h&gt;\n#include &lt;DHT.h&gt;\n#include &lt;WiFiNINA.h&gt;\n#include &lt;MQTTClient.h&gt;\n\n#define DHTPIN 2\n#define DHTTYPE DHT22\nDHT dht(DHTPIN, DHTTYPE);\n\nconst int pinoCS = 10; // Pino de sele\u00e7\u00e3o do cart\u00e3o SD\nFile arquivo;\n\nconst char* ssid = \"Seu_SSID\";\nconst char* password = \"Sua_Senha\";\nconst char* broker = \"broker.hivemq.com\";\nconst int port = 1883;\nconst char* topic = \"arduino/monitoramento\";\n\nWiFiClient net;\nMQTTClient client;\n\nvoid setup() {\n    Serial.begin(9600);\n    while (!Serial);\n\n    pinMode(pinoCS, OUTPUT);\n    if (!SD.begin(pinoCS)) {\n        Serial.println(\"Falha na inicializa\u00e7\u00e3o do cart\u00e3o SD!\");\n        while (1);\n    }\n    Serial.println(\"Cart\u00e3o SD inicializado.\");\n\n    arquivo = SD.open(\"dados.csv\", FILE_WRITE);\n    if (arquivo) {\n        arquivo.println(\"Tempo,Temperatura,Umidade\");\n        arquivo.close();\n    } else {\n        Serial.println(\"Falha ao abrir o arquivo.\");\n    }\n\n    dht.begin();\n\n    // Conecta ao Wi-Fi\n    WiFi.begin(ssid, password);\n    while (WiFi.status() != WL_CONNECTED) {\n        delay(500);\n        Serial.print(\".\");\n    }\n    Serial.println(\"\\nConectado ao Wi-Fi\");\n\n    // Conecta ao MQTT broker\n    client.begin(broker, port, net);\n    while (!client.connect(\"ArduinoClient\")) {\n        Serial.print(\".\");\n        delay(1000);\n    }\n    Serial.println(\"\\nConectado ao MQTT broker\");\n}\n\nvoid loop() {\n    // Leitura dos sensores\n    unsigned long tempo = millis();\n    float temperatura = dht.readTemperature();\n    float umidade = dht.readHumidity();\n\n    if (isnan(temperatura) || isnan(umidade)) {\n        Serial.println(\"Falha na leitura dos sensores DHT!\");\n        return;\n    }\n\n    // Armazenamento dos dados no cart\u00e3o SD\n    arquivo = SD.open(\"dados.csv\", FILE_WRITE);\n    if (arquivo) {\n        arquivo.print(tempo);\n        arquivo.print(\",\");\n        arquivo.print(temperatura);\n        arquivo.print(\",\");\n        arquivo.println(umidade);\n        arquivo.close();\n        Serial.println(\"Dados registrados no cart\u00e3o SD.\");\n    } else {\n        Serial.println(\"Falha ao abrir o arquivo para escrita.\");\n    }\n\n    // Envio dos dados via MQTT\n    String mensagem = \"Tempo: \" + String(tempo) + \" ms, Temperatura: \" + String(temperatura) + \"\u00b0C, Umidade: \" + String(umidade) + \"%\";\n    client.publish(topic, mensagem);\n    Serial.println(\"Dados enviados via MQTT: \" + mensagem);\n\n    delay(60000); // Aguarda 1 minuto antes da pr\u00f3xima leitura\n}\n</code></pre> <p>Explica\u00e7\u00e3o:</p> <ul> <li>Coleta de Dados: L\u00ea a temperatura e umidade do sensor DHT22.</li> <li>Armazenamento Local: Grava os dados no cart\u00e3o SD em formato CSV para f\u00e1cil importa\u00e7\u00e3o e an\u00e1lise.</li> <li>Envio de Dados via MQTT: Transmite os dados para um broker MQTT, permitindo a integra\u00e7\u00e3o com dashboards e sistemas de monitoramento.</li> <li>Monitoramento Cont\u00ednuo: Realiza a coleta e envio de dados a cada minuto.</li> </ul>"},{"location":"aulas/iot/modulos/modulo18.html#122-analise-de-dados-com-pandas-e-visualizacao-com-matplotlib","title":"12.2 An\u00e1lise de Dados com Pandas e Visualiza\u00e7\u00e3o com Matplotlib","text":"<p>Este exemplo demonstra como importar os dados coletados do cart\u00e3o SD para um script Python, realizar an\u00e1lises estat\u00edsticas b\u00e1sicas e visualizar os resultados.</p> <pre><code>import pandas as pd\nimport matplotlib.pyplot as plt\n\n# Carrega os dados do arquivo CSV\ndados = pd.read_csv('dados.csv')\n\n# Exibe as primeiras linhas do DataFrame\nprint(dados.head())\n\n# Calcula estat\u00edsticas b\u00e1sicas\nmedia_temp = dados['Temperatura'].mean()\nmediana_temp = dados['Temperatura'].median()\ndesvio_temp = dados['Temperatura'].std()\n\nmedia_umid = dados['Umidade'].mean()\nmediana_umid = dados['Umidade'].median()\ndesvio_umid = dados['Umidade'].std()\n\nprint(f\"Temperatura M\u00e9dia: {media_temp:.2f}\u00b0C\")\nprint(f\"Temperatura Mediana: {mediana_temp:.2f}\u00b0C\")\nprint(f\"Desvio Padr\u00e3o da Temperatura: {desvio_temp:.2f}\u00b0C\")\n\nprint(f\"Umidade M\u00e9dia: {media_umid:.2f}%\")\nprint(f\"Umidade Mediana: {mediana_umid:.2f}%\")\nprint(f\"Desvio Padr\u00e3o da Umidade: {desvio_umid:.2f}%\")\n\n# Plotagem dos dados\nplt.figure(figsize=(12,6))\n\nplt.subplot(2,1,1)\nplt.plot(dados['Tempo'], dados['Temperatura'], label='Temperatura')\nplt.axhline(media_temp, color='r', linestyle='--', label='M\u00e9dia')\nplt.title('Monitoramento de Temperatura')\nplt.xlabel('Tempo (ms)')\nplt.ylabel('Temperatura (C)')\nplt.legend()\n\nplt.subplot(2,1,2)\nplt.plot(dados['Tempo'], dados['Umidade'], label='Umidade', color='g')\nplt.axhline(media_umid, color='r', linestyle='--', label='M\u00e9dia')\nplt.title('Monitoramento de Umidade')\nplt.xlabel('Tempo (ms)')\nplt.ylabel('Umidade (%)')\nplt.legend()\n\nplt.tight_layout()\nplt.show()\n</code></pre> <p>Explica\u00e7\u00e3o:</p> <ul> <li>Importa\u00e7\u00e3o de Dados: Utiliza o Pandas para ler o arquivo CSV contendo os dados de tempo, temperatura e umidade.</li> <li>An\u00e1lise Estat\u00edstica: Calcula a m\u00e9dia, mediana e desvio padr\u00e3o para cada m\u00e9trica.</li> <li>Visualiza\u00e7\u00e3o: Cria gr\u00e1ficos de linha para visualizar as tend\u00eancias de temperatura e umidade ao longo do tempo, destacando a m\u00e9dia.</li> </ul>"},{"location":"aulas/iot/modulos/modulo18.html#11-conclusao-do-modulo","title":"11. Conclus\u00e3o do M\u00f3dulo","text":"<p>Neste m\u00f3dulo, voc\u00ea aprendeu:</p> <ul> <li>M\u00e9todos de Coleta e Armazenamento de Dados: Entendeu diferentes formas de coletar dados com Arduino e armazen\u00e1-los localmente ou na nuvem.</li> <li>T\u00e9cnicas de An\u00e1lise de Dados: Aprendeu como aplicar t\u00e9cnicas b\u00e1sicas para identificar padr\u00f5es e tend\u00eancias nos dados coletados.</li> <li>Ferramentas de Visualiza\u00e7\u00e3o: Utilizou ferramentas como Matplotlib e Grafana para criar representa\u00e7\u00f5es gr\u00e1ficas dos dados.</li> <li>Integra\u00e7\u00e3o com Python: Compreendeu como utilizar Python para an\u00e1lises mais avan\u00e7adas e personalizadas.</li> <li>Boas Pr\u00e1ticas: Entendeu a import\u00e2ncia de organizar, documentar e visualizar os dados de maneira eficaz para obter insights valiosos.</li> </ul> <p>Com este conhecimento, voc\u00ea est\u00e1 preparado para transformar os dados coletados pelos seus projetos Arduino em informa\u00e7\u00f5es \u00fateis e visualmente atraentes, melhorando a tomada de decis\u00f5es e a efici\u00eancia dos seus sistemas.</p>"},{"location":"aulas/iot/modulos/modulo18.html#12-proximos-passos","title":"12. Pr\u00f3ximos Passos","text":"<ul> <li>Revisar todo o conte\u00fado do m\u00f3dulo para consolidar o aprendizado.</li> <li>Explorar projetos avan\u00e7ados que combinam an\u00e1lise de dados com outros conceitos aprendidos, como IoT, automa\u00e7\u00e3o residencial ou rob\u00f3tica.</li> <li>Participar de comunidades e f\u00f3runs de Arduino para trocar experi\u00eancias e obter suporte cont\u00ednuo.</li> <li>Considerar cursos avan\u00e7ados ou especializa\u00e7\u00f5es em \u00e1reas espec\u00edficas de interesse, como ci\u00eancia de dados, intelig\u00eancia artificial aplicada ou visualiza\u00e7\u00e3o de dados avan\u00e7ada.</li> <li>Desenvolver seu pr\u00f3prio portf\u00f3lio de projetos Arduino, aplicando t\u00e9cnicas de an\u00e1lise de dados e visualiza\u00e7\u00e3o para resolver problemas reais.</li> </ul> <p>Se tiver d\u00favidas ou precisar de assist\u00eancia, continue participando de comunidades de aprendizagem ou consulte os recursos adicionais fornecidos ao longo dos m\u00f3dulos.</p> <p>**Parab\u00e9ns por concluir o M\u00f3dulo 19! Continue explorando e criando projetos incr\u00edveis com Arduino!</p>"},{"location":"aulas/iot/modulos/modulo2.html","title":"M\u00f3dulo 2: Operadores e Express\u00f5es","text":"<p>Bem-vindo ao M\u00f3dulo 2 do curso \"Programa\u00e7\u00e3o em Arduino: Conceitos Fundamentais sem Hardware\". Neste m\u00f3dulo, voc\u00ea explorar\u00e1 os operadores e express\u00f5es na linguagem de programa\u00e7\u00e3o Arduino (C/C++). Compreender os diferentes tipos de operadores e como eles interagem em express\u00f5es \u00e9 essencial para desenvolver programas eficientes e funcionais.</p>"},{"location":"aulas/iot/modulos/modulo2.html#objetivos-do-modulo","title":"Objetivos do M\u00f3dulo","text":"<ul> <li>Compreender os diferentes tipos de operadores dispon\u00edveis em Arduino.</li> <li>Aplicar operadores aritm\u00e9ticos, relacionais, l\u00f3gicos, de atribui\u00e7\u00e3o e incrementais/decrementais.</li> <li>Entender a preced\u00eancia e associatividade de operadores.</li> <li>Construir express\u00f5es complexas utilizando m\u00faltiplos operadores.</li> <li>Resolver exerc\u00edcios pr\u00e1ticos para consolidar o conhecimento sobre operadores e express\u00f5es.</li> </ul>"},{"location":"aulas/iot/modulos/modulo2.html#1-introducao-aos-operadores-e-expressoes","title":"1. Introdu\u00e7\u00e3o aos Operadores e Express\u00f5es","text":""},{"location":"aulas/iot/modulos/modulo2.html#11-o-que-sao-operadores","title":"1.1 O que s\u00e3o Operadores?","text":"<p>Operadores s\u00e3o s\u00edmbolos ou palavras reservadas que informam ao compilador para realizar opera\u00e7\u00f5es espec\u00edficas entre os operandos (valores ou vari\u00e1veis). Eles s\u00e3o fundamentais para criar express\u00f5es que manipulam dados.</p>"},{"location":"aulas/iot/modulos/modulo2.html#12-o-que-sao-expressoes","title":"1.2 O que s\u00e3o Express\u00f5es?","text":"<p>Uma express\u00e3o \u00e9 uma combina\u00e7\u00e3o de operadores e operandos que o compilador avalia para produzir um novo valor. Por exemplo, <code>a + b</code> \u00e9 uma express\u00e3o que soma os valores de <code>a</code> e <code>b</code>.</p>"},{"location":"aulas/iot/modulos/modulo2.html#2-tipos-de-operadores","title":"2. Tipos de Operadores","text":""},{"location":"aulas/iot/modulos/modulo2.html#21-operadores-aritmeticos","title":"2.1 Operadores Aritm\u00e9ticos","text":"<p>Operadores utilizados para realizar opera\u00e7\u00f5es matem\u00e1ticas b\u00e1sicas.</p> <ul> <li>Adi\u00e7\u00e3o (<code>+</code>)</li> </ul> <p>Soma dois operandos.</p> <pre><code>int soma = a + b;\n</code></pre> <ul> <li>Subtra\u00e7\u00e3o (<code>-</code>)</li> </ul> <p>Subtrai o segundo operando do primeiro.</p> <pre><code>int subtracao = a - b;\n</code></pre> <ul> <li>Multiplica\u00e7\u00e3o (<code>*</code>)</li> </ul> <p>Multiplica dois operandos.</p> <pre><code>int multiplicacao = a * b;\n</code></pre> <ul> <li>Divis\u00e3o (<code>/</code>)</li> </ul> <p>Divide o primeiro operando pelo segundo.</p> <pre><code>int divisao = a / b;\n</code></pre> <ul> <li>M\u00f3dulo (<code>%</code>)</li> </ul> <p>Retorna o resto da divis\u00e3o do primeiro operando pelo segundo.</p> <pre><code>int resto = a % b;\n</code></pre>"},{"location":"aulas/iot/modulos/modulo2.html#22-operadores-relacionais","title":"2.2 Operadores Relacionais","text":"<p>Operadores que comparam dois operandos e retornam um valor booleano (<code>true</code> ou <code>false</code>).</p> <ul> <li>Igual a (<code>==</code>)</li> </ul> <p>Verifica se os operandos s\u00e3o iguais.</p> <pre><code>bool igual = (a == b);\n</code></pre> <ul> <li>Diferente de (<code>!=</code>)</li> </ul> <p>Verifica se os operandos s\u00e3o diferentes.</p> <pre><code>bool diferente = (a != b);\n</code></pre> <ul> <li>Maior que (<code>&gt;</code>)</li> </ul> <p>Verifica se o primeiro operando \u00e9 maior que o segundo.</p> <pre><code>bool maior = (a &gt; b);\n</code></pre> <ul> <li>Menor que (<code>&lt;</code>)</li> </ul> <p>Verifica se o primeiro operando \u00e9 menor que o segundo.</p> <pre><code>bool menor = (a &lt; b);\n</code></pre> <ul> <li>Maior ou igual a (<code>&gt;=</code>)</li> </ul> <p>Verifica se o primeiro operando \u00e9 maior ou igual ao segundo.</p> <pre><code>bool maiorIgual = (a &gt;= b);\n</code></pre> <ul> <li>Menor ou igual a (<code>&lt;=</code>)</li> </ul> <p>Verifica se o primeiro operando \u00e9 menor ou igual ao segundo.</p> <pre><code>bool menorIgual = (a &lt;= b);\n</code></pre>"},{"location":"aulas/iot/modulos/modulo2.html#23-operadores-logicos","title":"2.3 Operadores L\u00f3gicos","text":"<p>Operadores que combinam express\u00f5es booleanas.</p> <ul> <li>AND L\u00f3gico (<code>&amp;&amp;</code>)</li> </ul> <p>Retorna <code>true</code> se ambas as express\u00f5es forem verdadeiras.</p> <pre><code>bool resultado = (a &gt; b) &amp;&amp; (c &lt; d);\n</code></pre> <ul> <li>OR L\u00f3gico (<code>||</code>)</li> </ul> <p>Retorna <code>true</code> se pelo menos uma das express\u00f5es for verdadeira.</p> <pre><code>bool resultado = (a &gt; b) || (c &lt; d);\n</code></pre> <ul> <li>NOT L\u00f3gico (<code>!</code>)</li> </ul> <p>Inverte o valor l\u00f3gico da express\u00e3o.</p> <pre><code>bool resultado = !(a &gt; b);\n</code></pre>"},{"location":"aulas/iot/modulos/modulo2.html#24-operadores-de-atribuicao","title":"2.4 Operadores de Atribui\u00e7\u00e3o","text":"<p>Operadores que atribuem valores \u00e0s vari\u00e1veis.</p> <ul> <li>Atribui\u00e7\u00e3o Simples (<code>=</code>)</li> </ul> <p>Atribui o valor do operando direito ao operando esquerdo.</p> <pre><code>int a = 5;\n</code></pre> <ul> <li>Atribui\u00e7\u00e3o com Adi\u00e7\u00e3o (<code>+=</code>)</li> </ul> <p>Adiciona o valor do operando direito ao operando esquerdo e atribui o resultado ao operando esquerdo.</p> <pre><code>a += 3; // Equivale a a = a + 3;\n</code></pre> <ul> <li>Atribui\u00e7\u00e3o com Subtra\u00e7\u00e3o (<code>-=</code>)</li> </ul> <p>Subtrai o valor do operando direito do operando esquerdo e atribui o resultado ao operando esquerdo.</p> <pre><code>a -= 2; // Equivale a a = a - 2;\n</code></pre> <ul> <li>Atribui\u00e7\u00e3o com Multiplica\u00e7\u00e3o (<code>*=</code>)</li> </ul> <p>Multiplica o operando esquerdo pelo operando direito e atribui o resultado ao operando esquerdo.</p> <pre><code>a *= 4; // Equivale a a = a * 4;\n</code></pre> <ul> <li>Atribui\u00e7\u00e3o com Divis\u00e3o (<code>/=</code>)</li> </ul> <p>Divide o operando esquerdo pelo operando direito e atribui o resultado ao operando esquerdo.</p> <pre><code>a /= 2; // Equivale a a = a / 2;\n</code></pre> <ul> <li>Atribui\u00e7\u00e3o com M\u00f3dulo (<code>%=</code>)</li> </ul> <p>Calcula o m\u00f3dulo do operando esquerdo pelo operando direito e atribui o resultado ao operando esquerdo.</p> <pre><code>a %= 3; // Equivale a a = a % 3;\n</code></pre>"},{"location":"aulas/iot/modulos/modulo2.html#25-operadores-incrementais-e-decrementais","title":"2.5 Operadores Incrementais e Decrementais","text":"<p>Operadores que aumentam ou diminuem o valor de uma vari\u00e1vel em 1.</p> <ul> <li>Incremento (<code>++</code>)</li> </ul> <p>Aumenta o valor da vari\u00e1vel em 1.</p> <pre><code>a++; // Equivale a a = a + 1;\n</code></pre> <ul> <li>Decremento (<code>--</code>)</li> </ul> <p>Diminui o valor da vari\u00e1vel em 1.</p> <pre><code>a--; // Equivale a a = a - 1;\n</code></pre>"},{"location":"aulas/iot/modulos/modulo2.html#26-operadores-bitwise","title":"2.6 Operadores Bitwise","text":"<p>Operadores que realizam opera\u00e7\u00f5es bit a bit.</p> <ul> <li>AND Bitwise (<code>&amp;</code>)</li> </ul> <p>Retorna 1 apenas se ambos os bits forem 1.</p> <pre><code>int resultado = a &amp; b;\n</code></pre> <ul> <li>OR Bitwise (<code>|</code>)</li> </ul> <p>Retorna 1 se pelo menos um dos bits for 1.</p> <pre><code>int resultado = a | b;\n</code></pre> <ul> <li>XOR Bitwise (<code>^</code>)</li> </ul> <p>Retorna 1 se os bits forem diferentes.</p> <pre><code>int resultado = a ^ b;\n</code></pre> <ul> <li>NOT Bitwise (<code>~</code>)</li> </ul> <p>Inverte todos os bits.</p> <pre><code>int resultado = ~a;\n</code></pre> <ul> <li>Shift Left (<code>&lt;&lt;</code>)</li> </ul> <p>Desloca os bits para a esquerda, preenchendo com zeros.</p> <pre><code>int resultado = a &lt;&lt; 2;\n</code></pre> <ul> <li>Shift Right (<code>&gt;&gt;</code>)</li> </ul> <p>Desloca os bits para a direita.</p> <pre><code>int resultado = a &gt;&gt; 1;\n</code></pre>"},{"location":"aulas/iot/modulos/modulo2.html#3-precedencia-e-associatividade-de-operadores","title":"3. Preced\u00eancia e Associatividade de Operadores","text":"<p>A preced\u00eancia de operadores determina a ordem em que os operadores s\u00e3o avaliados em uma express\u00e3o. A associatividade determina a ordem em que os operadores com a mesma preced\u00eancia s\u00e3o avaliados.</p>"},{"location":"aulas/iot/modulos/modulo2.html#31-tabela-de-precedencia","title":"3.1 Tabela de Preced\u00eancia","text":"<p>Abaixo est\u00e1 uma tabela simplificada de preced\u00eancia de operadores em C/C++:</p> <ol> <li>Operadores de Incremento e Decremento: <code>++</code>, <code>--</code></li> <li>Operadores Multiplica\u00e7\u00e3o, Divis\u00e3o e M\u00f3dulo: <code>*</code>, <code>/</code>, <code>%</code></li> <li>Operadores Adi\u00e7\u00e3o e Subtra\u00e7\u00e3o: <code>+</code>, <code>-</code></li> <li>Operadores Relacionais: <code>&gt;</code>, <code>&lt;</code>, <code>&gt;=</code>, <code>&lt;=</code></li> <li>Operadores de Igualdade: <code>==</code>, <code>!=</code></li> <li>Operadores L\u00f3gicos AND: <code>&amp;&amp;</code></li> <li>Operadores L\u00f3gicos OR: <code>||</code></li> <li>Operadores de Atribui\u00e7\u00e3o: <code>=</code>, <code>+=</code>, <code>-=</code>, etc.</li> </ol>"},{"location":"aulas/iot/modulos/modulo2.html#32-associatividade","title":"3.2 Associatividade","text":"<p>A associatividade determina a ordem em que os operadores com a mesma preced\u00eancia s\u00e3o avaliados:</p> <ul> <li>Associatividade da Esquerda para a Direita:</li> </ul> <p>A maioria dos operadores possui associatividade da esquerda para a direita. Por exemplo:</p> <pre><code>int resultado = a + b - c;\n// \u00c9 interpretado como (a + b) - c\n</code></pre> <ul> <li>Associatividade da Direita para a Esquerda:</li> </ul> <p>Operadores de atribui\u00e7\u00e3o possuem associatividade da direita para a esquerda. Por exemplo:</p> <pre><code>a = b = c;\n// \u00c9 interpretado como a = (b = c)\n</code></pre>"},{"location":"aulas/iot/modulos/modulo2.html#33-exemplos-praticos","title":"3.3 Exemplos Pr\u00e1ticos","text":"<ul> <li>Exemplo 1:</li> </ul> <pre><code>int a = 5 + 3 * 2;\n</code></pre> <p>Explica\u00e7\u00e3o:</p> <ul> <li>A multiplica\u00e7\u00e3o (<code>3 * 2</code>) tem maior preced\u00eancia que a adi\u00e7\u00e3o (<code>5 +</code>), ent\u00e3o \u00e9 avaliada primeiro.</li> <li><code>a = 5 + 6;</code></li> <li> <p><code>a = 11;</code></p> </li> <li> <p>Exemplo 2:</p> </li> </ul> <pre><code>bool resultado = (a &gt; b) &amp;&amp; (c &lt; d);\n</code></pre> <p>Explica\u00e7\u00e3o:</p> <ul> <li>As express\u00f5es dentro dos par\u00eanteses s\u00e3o avaliadas primeiro devido \u00e0 preced\u00eancia dos par\u00eanteses.</li> <li><code>resultado</code> ser\u00e1 <code>true</code> somente se ambas as compara\u00e7\u00f5es forem verdadeiras.</li> </ul>"},{"location":"aulas/iot/modulos/modulo2.html#4-exemplos-praticos","title":"4. Exemplos Pr\u00e1ticos","text":""},{"location":"aulas/iot/modulos/modulo2.html#41-calculadora-simples","title":"4.1 Calculadora Simples","text":"<p>Vamos criar um programa que realiza opera\u00e7\u00f5es aritm\u00e9ticas b\u00e1sicas com base em dois n\u00fameros fornecidos pelo usu\u00e1rio.</p> <pre><code>int num1;\nint num2;\nchar operacao;\n\nvoid setup() {\n  Serial.begin(9600);\n  Serial.println(\"Calculadora Simples\");\n  Serial.println(\"Digite o primeiro n\u00famero:\");\n}\n\nvoid loop() {\n  if (Serial.available() &gt; 0) {\n    num1 = Serial.parseInt();\n    Serial.println(\"Digite a opera\u00e7\u00e3o (+, -, *, /):\");\n\n    while (Serial.available() == 0) {\n      // Aguarda a opera\u00e7\u00e3o\n    }\n\n    operacao = (char)Serial.read();\n    Serial.println(\"Digite o segundo n\u00famero:\");\n\n    while (Serial.available() == 0) {\n      // Aguarda o segundo n\u00famero\n    }\n\n    num2 = Serial.parseInt();\n\n    float resultado;\n\n    switch (operacao) {\n      case '+':\n        resultado = num1 + num2;\n        Serial.print(\"Resultado: \");\n        Serial.println(resultado);\n        break;\n      case '-':\n        resultado = num1 - num2;\n        Serial.print(\"Resultado: \");\n        Serial.println(resultado);\n        break;\n      case '*':\n        resultado = num1 * num2;\n        Serial.print(\"Resultado: \");\n        Serial.println(resultado);\n        break;\n      case '/':\n        if (num2 != 0) {\n          resultado = (float)num1 / num2;\n          Serial.print(\"Resultado: \");\n          Serial.println(resultado);\n        } else {\n          Serial.println(\"Erro: Divis\u00e3o por zero.\");\n        }\n        break;\n      default:\n        Serial.println(\"Opera\u00e7\u00e3o inv\u00e1lida.\");\n    }\n\n    Serial.println(\"Digite o primeiro n\u00famero para uma nova opera\u00e7\u00e3o:\");\n  }\n}\n</code></pre> <p>Explica\u00e7\u00e3o do C\u00f3digo:</p> <ul> <li>O programa solicita ao usu\u00e1rio que insira dois n\u00fameros e uma opera\u00e7\u00e3o aritm\u00e9tica.</li> <li>Utiliza estruturas de controle (<code>switch-case</code>) para determinar qual opera\u00e7\u00e3o realizar.</li> <li>Exibe o resultado no Monitor Serial.</li> <li>Cuida da divis\u00e3o por zero, exibindo uma mensagem de erro se necess\u00e1rio.</li> </ul>"},{"location":"aulas/iot/modulos/modulo2.html#5-exercicios-praticos","title":"5. Exerc\u00edcios Pr\u00e1ticos","text":""},{"location":"aulas/iot/modulos/modulo2.html#exercicio-1-calculadora-avancada","title":"Exerc\u00edcio 1: Calculadora Avan\u00e7ada","text":"<ul> <li> <p>Tarefa: Expanda a calculadora simples para incluir opera\u00e7\u00f5es de m\u00f3dulo (<code>%</code>) e exponencia\u00e7\u00e3o (<code>^</code>).</p> </li> <li> <p>Dicas:</p> </li> <li> <p>Para exponencia\u00e7\u00e3o, voc\u00ea pode usar a fun\u00e7\u00e3o <code>pow()</code> da biblioteca <code>math.h</code>.</p> </li> </ul> <pre><code>#include &lt;math.h&gt;\n\n// Dentro do switch-case\ncase '^':\n  resultado = pow(num1, num2);\n  Serial.print(\"Resultado: \");\n  Serial.println(resultado);\n  break;\n</code></pre>"},{"location":"aulas/iot/modulos/modulo2.html#exercicio-2-operador-ternario","title":"Exerc\u00edcio 2: Operador Tern\u00e1rio","text":"<ul> <li> <p>Tarefa: Escreva um programa que verifica se um n\u00famero fornecido \u00e9 positivo ou negativo usando o operador tern\u00e1rio (<code>? :</code>).</p> </li> <li> <p>Exemplo de C\u00f3digo:</p> </li> </ul> <pre><code>int numero;\n\nvoid setup() {\n  Serial.begin(9600);\n  Serial.println(\"Digite um n\u00famero:\");\n}\n\nvoid loop() {\n  if (Serial.available() &gt; 0) {\n    numero = Serial.parseInt();\n    String resultado = (numero &gt;= 0) ? \"Positivo\" : \"Negativo\";\n    Serial.print(\"O n\u00famero \u00e9: \");\n    Serial.println(resultado);\n    Serial.println(\"Digite outro n\u00famero:\");\n  }\n}\n</code></pre>"},{"location":"aulas/iot/modulos/modulo2.html#exercicio-3-precedencia-de-operadores","title":"Exerc\u00edcio 3: Preced\u00eancia de Operadores","text":"<ul> <li>Tarefa: Crie um programa que recebe tr\u00eas n\u00fameros e realiza a seguinte opera\u00e7\u00e3o:</li> </ul> <p><code>resultado = a + b * c;</code></p> <p>Imprima o resultado e explique a ordem de avalia\u00e7\u00e3o dos operadores.</p>"},{"location":"aulas/iot/modulos/modulo2.html#6-conceitos-importantes","title":"6. Conceitos Importantes","text":""},{"location":"aulas/iot/modulos/modulo2.html#61-parenteses-em-expressoes","title":"6.1 Par\u00eanteses em Express\u00f5es","text":"<p>Os par\u00eanteses <code>()</code> podem ser usados para alterar a preced\u00eancia de operadores, garantindo que determinadas opera\u00e7\u00f5es sejam realizadas primeiro.</p> <pre><code>int resultado = (a + b) * c;\n</code></pre> <p>Explica\u00e7\u00e3o:</p> <ul> <li>Com os par\u00eanteses, a adi\u00e7\u00e3o <code>a + b</code> \u00e9 realizada antes da multiplica\u00e7\u00e3o pelo <code>c</code>.</li> <li>Isso pode mudar o resultado final da express\u00e3o.</li> </ul>"},{"location":"aulas/iot/modulos/modulo2.html#62-operador-incremental-pre-e-pos","title":"6.2 Operador Incremental Pr\u00e9 e P\u00f3s","text":"<p>Os operadores incrementais (<code>++</code>) e decrementais (<code>--</code>) podem ser usados antes ou depois da vari\u00e1vel, influenciando o valor retornado pela express\u00e3o.</p> <ul> <li>Pr\u00e9-incremento (<code>++a</code>):</li> </ul> <p>Incrementa a vari\u00e1vel antes de retornar seu valor.</p> <pre><code>int a = 5;\nint b = ++a; // a = 6, b = 6\n</code></pre> <ul> <li>P\u00f3s-incremento (<code>a++</code>):</li> </ul> <p>Retorna o valor atual da vari\u00e1vel antes de increment\u00e1-la.</p> <pre><code>int a = 5;\nint b = a++; // a = 6, b = 5\n</code></pre>"},{"location":"aulas/iot/modulos/modulo2.html#63-cuidado-com-a-precedencia","title":"6.3 Cuidado com a Preced\u00eancia","text":"<p>Ao combinar diferentes tipos de operadores em uma express\u00e3o, \u00e9 crucial entender a preced\u00eancia para evitar resultados inesperados.</p> <p>Exemplo:</p> <pre><code>int a = 5;\nint b = 2;\nint c = 3;\n\nint resultado = a + b * c; // resultado = 5 + (2 * 3) = 11\n</code></pre>"},{"location":"aulas/iot/modulos/modulo3.html","title":"M\u00f3dulo 3: Estruturas de Controle de Fluxo","text":"<p>Bem-vindo ao M\u00f3dulo 3 do curso \"Programa\u00e7\u00e3o em Arduino: Conceitos Fundamentais sem Hardware\". Neste m\u00f3dulo, voc\u00ea ir\u00e1 explorar as estruturas de controle de fluxo na linguagem de programa\u00e7\u00e3o Arduino (C/C++). Estas estruturas s\u00e3o essenciais para criar programas que possam tomar decis\u00f5es e executar tarefas repetitivas de forma eficiente.</p>"},{"location":"aulas/iot/modulos/modulo3.html#objetivos-do-modulo","title":"Objetivos do M\u00f3dulo","text":"<ul> <li>Compreender as estruturas de controle de fluxo: condicionais (<code>if</code>, <code>else</code>, <code>switch-case</code>) e loops (<code>for</code>, <code>while</code>, <code>do-while</code>).</li> <li>Aplicar condicionais para tomar decis\u00f5es baseadas em condi\u00e7\u00f5es l\u00f3gicas.</li> <li>Utilizar loops para executar tarefas repetitivas.</li> <li>Entender a diferen\u00e7a entre diferentes tipos de loops e quando utiliz\u00e1-los.</li> <li>Resolver exerc\u00edcios pr\u00e1ticos para consolidar o conhecimento sobre estruturas de controle de fluxo.</li> </ul>"},{"location":"aulas/iot/modulos/modulo3.html#1-introducao-as-estruturas-de-controle-de-fluxo","title":"1. Introdu\u00e7\u00e3o \u00e0s Estruturas de Controle de Fluxo","text":"<p>As estruturas de controle de fluxo permitem que o programa desvie seu caminho de execu\u00e7\u00e3o com base em condi\u00e7\u00f5es ou repita certas partes do c\u00f3digo v\u00e1rias vezes. Elas s\u00e3o fundamentais para criar programas din\u00e2micos e eficientes.</p>"},{"location":"aulas/iot/modulos/modulo3.html#11-por-que-usar-estruturas-de-controle-de-fluxo","title":"1.1 Por que Usar Estruturas de Controle de Fluxo?","text":"<p>Sem estruturas de controle de fluxo, os programas seriam lineares e incapazes de responder a diferentes situa\u00e7\u00f5es ou de realizar tarefas repetitivas de forma eficiente. Elas permitem:</p> <ul> <li>Tomada de Decis\u00e3o: Executar diferentes blocos de c\u00f3digo com base em condi\u00e7\u00f5es.</li> <li>Repeti\u00e7\u00e3o: Executar blocos de c\u00f3digo m\u00faltiplas vezes sem duplica\u00e7\u00e3o.</li> <li>Organiza\u00e7\u00e3o: Melhorar a legibilidade e manuten\u00e7\u00e3o do c\u00f3digo.</li> </ul>"},{"location":"aulas/iot/modulos/modulo3.html#2-condicionais-if-else-e-switch-case","title":"2. Condicionais: <code>if</code>, <code>else</code> e <code>switch-case</code>","text":""},{"location":"aulas/iot/modulos/modulo3.html#21-estrutura-if-e-else","title":"2.1 Estrutura <code>if</code> e <code>else</code>","text":"<p>A estrutura <code>if</code> \u00e9 usada para executar um bloco de c\u00f3digo se uma condi\u00e7\u00e3o espec\u00edfica for verdadeira. A estrutura <code>else</code> pode ser usada para executar um bloco de c\u00f3digo alternativo se a condi\u00e7\u00e3o for falsa.</p>"},{"location":"aulas/iot/modulos/modulo3.html#sintaxe-do-if","title":"Sintaxe do <code>if</code>:","text":"<pre><code>if (condi\u00e7\u00e3o) {\n    // C\u00f3digo a ser executado se a condi\u00e7\u00e3o for verdadeira\n}\n</code></pre>"},{"location":"aulas/iot/modulos/modulo3.html#sintaxe-do-if-else","title":"Sintaxe do <code>if-else</code>:","text":"<pre><code>if (condi\u00e7\u00e3o) {\n    // C\u00f3digo a ser executado se a condi\u00e7\u00e3o for verdadeira\n} else {\n    // C\u00f3digo a ser executado se a condi\u00e7\u00e3o for falsa\n}\n</code></pre>"},{"location":"aulas/iot/modulos/modulo3.html#exemplo-pratico","title":"Exemplo Pr\u00e1tico:","text":"<pre><code>int idade = 20;\n\nvoid setup() {\n  Serial.begin(9600);\n\n  if (idade &gt;= 18) {\n    Serial.println(\"Voc\u00ea \u00e9 maior de idade.\");\n  } else {\n    Serial.println(\"Voc\u00ea \u00e9 menor de idade.\");\n  }\n}\n\nvoid loop() {\n  // N\u00e3o h\u00e1 c\u00f3digo no loop\n}\n</code></pre> <p>Explica\u00e7\u00e3o:</p> <ul> <li>Se a vari\u00e1vel <code>idade</code> for maior ou igual a 18, o Monitor Serial exibir\u00e1 \"Voc\u00ea \u00e9 maior de idade.\".</li> <li>Caso contr\u00e1rio, exibir\u00e1 \"Voc\u00ea \u00e9 menor de idade.\".</li> </ul>"},{"location":"aulas/iot/modulos/modulo3.html#22-estrutura-switch-case","title":"2.2 Estrutura <code>switch-case</code>","text":"<p>A estrutura <code>switch-case</code> \u00e9 uma forma mais organizada de lidar com m\u00faltiplas condi\u00e7\u00f5es baseadas no valor de uma \u00fanica vari\u00e1vel.</p>"},{"location":"aulas/iot/modulos/modulo3.html#sintaxe-do-switch-case","title":"Sintaxe do <code>switch-case</code>:","text":"<pre><code>switch (express\u00e3o) {\n    case valor1:\n        // C\u00f3digo a ser executado se express\u00e3o == valor1\n        break;\n    case valor2:\n        // C\u00f3digo a ser executado se express\u00e3o == valor2\n        break;\n    ...\n    default:\n        // C\u00f3digo a ser executado se express\u00e3o n\u00e3o corresponder a nenhum caso\n}\n</code></pre>"},{"location":"aulas/iot/modulos/modulo3.html#exemplo-pratico_1","title":"Exemplo Pr\u00e1tico:","text":"<pre><code>char opcao = 'B';\n\nvoid setup() {\n  Serial.begin(9600);\n\n  switch (opcao) {\n    case 'A':\n      Serial.println(\"Op\u00e7\u00e3o A selecionada.\");\n      break;\n    case 'B':\n      Serial.println(\"Op\u00e7\u00e3o B selecionada.\");\n      break;\n    case 'C':\n      Serial.println(\"Op\u00e7\u00e3o C selecionada.\");\n      break;\n    default:\n      Serial.println(\"Op\u00e7\u00e3o inv\u00e1lida.\");\n  }\n}\n\nvoid loop() {\n  // N\u00e3o h\u00e1 c\u00f3digo no loop\n}\n</code></pre> <p>Explica\u00e7\u00e3o:</p> <ul> <li>O programa verifica o valor da vari\u00e1vel <code>opcao</code>.</li> <li>Se <code>opcao</code> for 'A', 'B' ou 'C', imprime a mensagem correspondente.</li> <li>Se n\u00e3o corresponder a nenhum dos casos, executa o bloco <code>default</code>.</li> </ul>"},{"location":"aulas/iot/modulos/modulo3.html#23-exemplos-de-uso","title":"2.3 Exemplos de Uso","text":""},{"location":"aulas/iot/modulos/modulo3.html#exemplo-1-verificar-nota","title":"Exemplo 1: Verificar Nota","text":"<pre><code>int nota = 85;\n\nvoid setup() {\n  Serial.begin(9600);\n\n  if (nota &gt;= 90) {\n    Serial.println(\"A\");\n  } else if (nota &gt;= 80) {\n    Serial.println(\"B\");\n  } else if (nota &gt;= 70) {\n    Serial.println(\"C\");\n  } else if (nota &gt;= 60) {\n    Serial.println(\"D\");\n  } else {\n    Serial.println(\"F\");\n  }\n}\n\nvoid loop() {\n  // N\u00e3o h\u00e1 c\u00f3digo no loop\n}\n</code></pre> <p>Explica\u00e7\u00e3o:</p> <ul> <li>Dependendo do valor da vari\u00e1vel <code>nota</code>, uma letra correspondente \u00e0 faixa de nota \u00e9 exibida.</li> </ul>"},{"location":"aulas/iot/modulos/modulo3.html#exemplo-2-selecao-de-dia-da-semana","title":"Exemplo 2: Sele\u00e7\u00e3o de Dia da Semana","text":"<pre><code>int dia = 3;\n\nvoid setup() {\n  Serial.begin(9600);\n\n  switch (dia) {\n    case 1:\n      Serial.println(\"Domingo\");\n      break;\n    case 2:\n      Serial.println(\"Segunda-feira\");\n      break;\n    case 3:\n      Serial.println(\"Ter\u00e7a-feira\");\n      break;\n    case 4:\n      Serial.println(\"Quarta-feira\");\n      break;\n    case 5:\n      Serial.println(\"Quinta-feira\");\n      break;\n    case 6:\n      Serial.println(\"Sexta-feira\");\n      break;\n    case 7:\n      Serial.println(\"S\u00e1bado\");\n      break;\n    default:\n      Serial.println(\"Dia inv\u00e1lido\");\n  }\n}\n\nvoid loop() {\n  // N\u00e3o h\u00e1 c\u00f3digo no loop\n}\n</code></pre> <p>Explica\u00e7\u00e3o:</p> <ul> <li>O programa imprime o nome do dia da semana com base no valor da vari\u00e1vel <code>dia</code>.</li> </ul>"},{"location":"aulas/iot/modulos/modulo3.html#3-lacos-de-repeticao-for-while-e-do-while","title":"3. La\u00e7os de Repeti\u00e7\u00e3o: <code>for</code>, <code>while</code> e <code>do-while</code>","text":""},{"location":"aulas/iot/modulos/modulo3.html#31-estrutura-for","title":"3.1 Estrutura <code>for</code>","text":"<p>O la\u00e7o <code>for</code> \u00e9 usado quando o n\u00famero de itera\u00e7\u00f5es \u00e9 conhecido previamente. Ele consiste em tr\u00eas partes: inicializa\u00e7\u00e3o, condi\u00e7\u00e3o e incremento/decremento.</p>"},{"location":"aulas/iot/modulos/modulo3.html#sintaxe-do-for","title":"Sintaxe do <code>for</code>:","text":"<pre><code>for (inicializa\u00e7\u00e3o; condi\u00e7\u00e3o; incremento) {\n    // C\u00f3digo a ser repetido\n}\n</code></pre>"},{"location":"aulas/iot/modulos/modulo3.html#exemplo-pratico_2","title":"Exemplo Pr\u00e1tico:","text":"<pre><code>void setup() {\n  Serial.begin(9600);\n\n  for (int i = 1; i &lt;= 5; i++) {\n    Serial.print(\"Contagem: \");\n    Serial.println(i);\n  }\n}\n\nvoid loop() {\n  // N\u00e3o h\u00e1 c\u00f3digo no loop\n}\n</code></pre> <p>Explica\u00e7\u00e3o:</p> <ul> <li>O la\u00e7o inicia com <code>i = 1</code>.</li> <li>Enquanto <code>i &lt;= 5</code>, executa o bloco de c\u00f3digo.</li> <li>Ap\u00f3s cada itera\u00e7\u00e3o, incrementa <code>i</code> em 1.</li> </ul>"},{"location":"aulas/iot/modulos/modulo3.html#32-estrutura-while","title":"3.2 Estrutura <code>while</code>","text":"<p>O la\u00e7o <code>while</code> \u00e9 usado quando o n\u00famero de itera\u00e7\u00f5es n\u00e3o \u00e9 conhecido e depende de uma condi\u00e7\u00e3o ser verdadeira.</p>"},{"location":"aulas/iot/modulos/modulo3.html#sintaxe-do-while","title":"Sintaxe do <code>while</code>:","text":"<pre><code>while (condi\u00e7\u00e3o) {\n    // C\u00f3digo a ser repetido\n}\n</code></pre>"},{"location":"aulas/iot/modulos/modulo3.html#exemplo-pratico_3","title":"Exemplo Pr\u00e1tico:","text":"<pre><code>int contador = 1;\n\nvoid setup() {\n  Serial.begin(9600);\n\n  while (contador &lt;= 5) {\n    Serial.print(\"Contagem: \");\n    Serial.println(contador);\n    contador++;\n  }\n}\n\nvoid loop() {\n  // N\u00e3o h\u00e1 c\u00f3digo no loop\n}\n</code></pre> <p>Explica\u00e7\u00e3o:</p> <ul> <li>Enquanto <code>contador &lt;= 5</code>, o bloco de c\u00f3digo \u00e9 executado.</li> <li>Incrementa <code>contador</code> em cada itera\u00e7\u00e3o para evitar um loop infinito.</li> </ul>"},{"location":"aulas/iot/modulos/modulo3.html#33-estrutura-do-while","title":"3.3 Estrutura <code>do-while</code>","text":"<p>O la\u00e7o <code>do-while</code> \u00e9 similar ao <code>while</code>, mas garante que o bloco de c\u00f3digo seja executado pelo menos uma vez antes de verificar a condi\u00e7\u00e3o.</p>"},{"location":"aulas/iot/modulos/modulo3.html#sintaxe-do-do-while","title":"Sintaxe do <code>do-while</code>:","text":"<pre><code>do {\n    // C\u00f3digo a ser repetido\n} while (condi\u00e7\u00e3o);\n</code></pre>"},{"location":"aulas/iot/modulos/modulo3.html#exemplo-pratico_4","title":"Exemplo Pr\u00e1tico:","text":"<pre><code>int contador = 1;\n\nvoid setup() {\n  Serial.begin(9600);\n\n  do {\n    Serial.print(\"Contagem: \");\n    Serial.println(contador);\n    contador++;\n  } while (contador &lt;= 5);\n}\n\nvoid loop() {\n  // N\u00e3o h\u00e1 c\u00f3digo no loop\n}\n</code></pre> <p>Explica\u00e7\u00e3o:</p> <ul> <li>O bloco de c\u00f3digo dentro do <code>do</code> \u00e9 executado primeiro.</li> <li>Depois, a condi\u00e7\u00e3o \u00e9 verificada para determinar se o la\u00e7o deve continuar.</li> </ul>"},{"location":"aulas/iot/modulos/modulo3.html#34-comparacao-entre-for-while-e-do-while","title":"3.4 Compara\u00e7\u00e3o entre <code>for</code>, <code>while</code> e <code>do-while</code>","text":"<ul> <li><code>for</code>: Ideal quando o n\u00famero de itera\u00e7\u00f5es \u00e9 conhecido.</li> <li><code>while</code>: \u00datil quando o n\u00famero de itera\u00e7\u00f5es depende de uma condi\u00e7\u00e3o que pode mudar dinamicamente.</li> <li><code>do-while</code>: Garante que o bloco de c\u00f3digo seja executado pelo menos uma vez.</li> </ul>"},{"location":"aulas/iot/modulos/modulo3.html#35-exemplos-de-uso","title":"3.5 Exemplos de Uso","text":""},{"location":"aulas/iot/modulos/modulo3.html#exemplo-1-sequencia-de-fibonacci-com-for","title":"Exemplo 1: Sequ\u00eancia de Fibonacci com <code>for</code>","text":"<pre><code>int n = 10;\n\nvoid setup() {\n  Serial.begin(9600);\n\n  int a = 0, b = 1, c;\n  Serial.println(\"Sequ\u00eancia de Fibonacci:\");\n\n  for (int i = 0; i &lt; n; i++) {\n    Serial.println(a);\n    c = a + b;\n    a = b;\n    b = c;\n  }\n}\n\nvoid loop() {\n  // N\u00e3o h\u00e1 c\u00f3digo no loop\n}\n</code></pre> <p>Explica\u00e7\u00e3o:</p> <ul> <li>Imprime os primeiros <code>n</code> n\u00fameros da sequ\u00eancia de Fibonacci usando um la\u00e7o <code>for</code>.</li> </ul>"},{"location":"aulas/iot/modulos/modulo3.html#exemplo-2-verificar-se-um-numero-e-primo-com-while","title":"Exemplo 2: Verificar se um N\u00famero \u00e9 Primo com <code>while</code>","text":"<pre><code>int numero = 29;\nbool isPrimo = true;\nint i = 2;\n\nvoid setup() {\n  Serial.begin(9600);\n\n  if (numero &lt;= 1) {\n    isPrimo = false;\n  }\n\n  while (i &lt;= numero / 2) {\n    if (numero % i == 0) {\n      isPrimo = false;\n      break;\n    }\n    i++;\n  }\n\n  if (isPrimo) {\n    Serial.println(numero);\n    Serial.println(\" \u00e9 um n\u00famero primo.\");\n  } else {\n    Serial.println(numero);\n    Serial.println(\" n\u00e3o \u00e9 um n\u00famero primo.\");\n  }\n}\n\nvoid loop() {\n  // N\u00e3o h\u00e1 c\u00f3digo no loop\n}\n</code></pre> <p>Explica\u00e7\u00e3o:</p> <ul> <li>Verifica se <code>numero</code> \u00e9 primo utilizando um la\u00e7o <code>while</code>.</li> <li>Se encontrar um divisor, define <code>isPrimo</code> como <code>false</code> e sai do la\u00e7o.</li> </ul>"},{"location":"aulas/iot/modulos/modulo3.html#exemplo-3-solicitar-entradas-do-usuario-com-do-while","title":"Exemplo 3: Solicitar Entradas do Usu\u00e1rio com <code>do-while</code>","text":"<pre><code>int numero;\n\nvoid setup() {\n  Serial.begin(9600);\n\n  do {\n    Serial.println(\"Digite um n\u00famero positivo:\");\n    while (Serial.available() == 0) {\n      // Aguarda a entrada do usu\u00e1rio\n    }\n    numero = Serial.parseInt();\n  } while (numero &lt;= 0);\n\n  Serial.print(\"Voc\u00ea digitou: \");\n  Serial.println(numero);\n}\n\nvoid loop() {\n  // N\u00e3o h\u00e1 c\u00f3digo no loop\n}\n</code></pre> <p>Explica\u00e7\u00e3o:</p> <ul> <li>Solicita ao usu\u00e1rio que digite um n\u00famero positivo.</li> <li>Repete a solicita\u00e7\u00e3o at\u00e9 que o usu\u00e1rio insira um n\u00famero maior que 0.</li> </ul>"},{"location":"aulas/iot/modulos/modulo3.html#4-exemplos-praticos","title":"4. Exemplos Pr\u00e1ticos","text":""},{"location":"aulas/iot/modulos/modulo3.html#41-sequencia-de-fibonacci","title":"4.1 Sequ\u00eancia de Fibonacci","text":"<p>Vamos criar um programa que imprime a sequ\u00eancia de Fibonacci at\u00e9 o N-\u00e9simo termo.</p> <pre><code>int n = 10;\n\nvoid setup() {\n  Serial.begin(9600);\n\n  int a = 0, b = 1, c;\n  Serial.println(\"Sequ\u00eancia de Fibonacci:\");\n\n  for (int i = 0; i &lt; n; i++) {\n    Serial.println(a);\n    c = a + b;\n    a = b;\n    b = c;\n  }\n}\n\nvoid loop() {\n  // N\u00e3o h\u00e1 c\u00f3digo no loop\n}\n</code></pre>"},{"location":"aulas/iot/modulos/modulo3.html#42-verificar-numero-primo","title":"4.2 Verificar N\u00famero Primo","text":"<p>Crie um programa que verifica se um n\u00famero fornecido pelo usu\u00e1rio \u00e9 primo.</p> <pre><code>int numero = 29;\nbool isPrimo = true;\nint i = 2;\n\nvoid setup() {\n  Serial.begin(9600);\n\n  if (numero &lt;= 1) {\n    isPrimo = false;\n  }\n\n  while (i &lt;= numero / 2) {\n    if (numero % i == 0) {\n      isPrimo = false;\n      break;\n    }\n    i++;\n  }\n\n  if (isPrimo) {\n    Serial.println(numero);\n    Serial.println(\" \u00e9 um n\u00famero primo.\");\n  } else {\n    Serial.println(numero);\n    Serial.println(\" n\u00e3o \u00e9 um n\u00famero primo.\");\n  }\n}\n\nvoid loop() {\n  // N\u00e3o h\u00e1 c\u00f3digo no loop\n}\n</code></pre>"},{"location":"aulas/iot/modulos/modulo3.html#43-calculadora-de-numeros-positivos","title":"4.3 Calculadora de N\u00fameros Positivos","text":"<p>Escreva um programa que solicita ao usu\u00e1rio que digite n\u00fameros positivos at\u00e9 que um n\u00famero negativo seja inserido.</p> <pre><code>int numero;\n\nvoid setup() {\n  Serial.begin(9600);\n\n  do {\n    Serial.println(\"Digite um n\u00famero positivo:\");\n    while (Serial.available() == 0) {\n      // Aguarda a entrada do usu\u00e1rio\n    }\n    numero = Serial.parseInt();\n    if (numero &gt; 0) {\n      Serial.print(\"Voc\u00ea digitou: \");\n      Serial.println(numero);\n    }\n  } while (numero &gt;= 0);\n\n  Serial.println(\"N\u00famero negativo detectado. Programa encerrado.\");\n}\n\nvoid loop() {\n  // N\u00e3o h\u00e1 c\u00f3digo no loop\n}\n</code></pre>"},{"location":"aulas/iot/modulos/modulo3.html#5-exercicios-praticos","title":"5. Exerc\u00edcios Pr\u00e1ticos","text":""},{"location":"aulas/iot/modulos/modulo3.html#exercicio-1-sequencia-de-fatorial","title":"Exerc\u00edcio 1: Sequ\u00eancia de Fatorial","text":"<ul> <li> <p>Tarefa: Crie um programa que imprime o fatorial de um n\u00famero fornecido pelo usu\u00e1rio.</p> </li> <li> <p>Dicas:</p> </li> <li> <p>Utilize um la\u00e7o <code>for</code> para calcular o fatorial.</p> </li> </ul> <pre><code>long fatorial = 1;\nint numero = 5;\n\nfor (int i = 1; i &lt;= numero; i++) {\n  fatorial *= i;\n}\n\nSerial.print(\"Fatorial de \");\nSerial.print(numero);\nSerial.print(\" \u00e9 \");\nSerial.println(fatorial);\n</code></pre>"},{"location":"aulas/iot/modulos/modulo3.html#exercicio-2-contagem-regressiva","title":"Exerc\u00edcio 2: Contagem Regressiva","text":"<ul> <li> <p>Tarefa: Escreva um programa que realiza uma contagem regressiva de 10 at\u00e9 0 utilizando um la\u00e7o <code>while</code>.</p> </li> <li> <p>Exemplo de C\u00f3digo:</p> </li> </ul> <pre><code>int contador = 10;\n\nvoid setup() {\n  Serial.begin(9600);\n\n  while (contador &gt;= 0) {\n    Serial.println(contador);\n    contador--;\n    delay(1000); // Aguarda 1 segundo\n  }\n\n  Serial.println(\"Contagem finalizada!\");\n}\n\nvoid loop() {\n  // N\u00e3o h\u00e1 c\u00f3digo no loop\n}\n</code></pre>"},{"location":"aulas/iot/modulos/modulo3.html#exercicio-3-verificacao-de-paridade","title":"Exerc\u00edcio 3: Verifica\u00e7\u00e3o de Paridade","text":"<ul> <li> <p>Tarefa: Desenvolva um programa que solicita ao usu\u00e1rio um n\u00famero e verifica se ele \u00e9 par ou \u00edmpar usando uma estrutura <code>if-else</code>.</p> </li> <li> <p>Exemplo de C\u00f3digo:</p> </li> </ul> <pre><code>int numero;\n\nvoid setup() {\n  Serial.begin(9600);\n  Serial.println(\"Digite um n\u00famero:\");\n}\n\nvoid loop() {\n  if (Serial.available() &gt; 0) {\n    numero = Serial.parseInt();\n\n    if (numero % 2 == 0) {\n      Serial.print(numero);\n      Serial.println(\" \u00e9 um n\u00famero par.\");\n    } else {\n      Serial.print(numero);\n      Serial.println(\" \u00e9 um n\u00famero \u00edmpar.\");\n    }\n\n    Serial.println(\"Digite outro n\u00famero:\");\n  }\n}\n</code></pre>"},{"location":"aulas/iot/modulos/modulo3.html#6-conceitos-importantes","title":"6. Conceitos Importantes","text":""},{"location":"aulas/iot/modulos/modulo3.html#61-controle-de-fluxo","title":"6.1 Controle de Fluxo","text":"<p>Controlar o fluxo de execu\u00e7\u00e3o do programa \u00e9 essencial para criar programas que respondem a diferentes condi\u00e7\u00f5es e realizam tarefas de forma eficiente.</p>"},{"location":"aulas/iot/modulos/modulo3.html#62-evitar-loops-infinitos","title":"6.2 Evitar Loops Infinitos","text":"<p>Certifique-se de que os loops (<code>for</code>, <code>while</code>, <code>do-while</code>) tenham condi\u00e7\u00f5es que eventualmente se tornar\u00e3o falsas, evitando que o programa fique travado em um loop infinito.</p> <p>Exemplo de Loop Infinito:</p> <pre><code>while (true) {\n    // C\u00f3digo que nunca termina\n}\n</code></pre>"},{"location":"aulas/iot/modulos/modulo3.html#63-uso-adequado-de-break-e-continue","title":"6.3 Uso Adequado de <code>break</code> e <code>continue</code>","text":"<ul> <li><code>break</code>: Sai imediatamente do loop ou da estrutura <code>switch-case</code>.</li> <li><code>continue</code>: Pula para a pr\u00f3xima itera\u00e7\u00e3o do loop, ignorando o restante do c\u00f3digo no bloco atual.</li> </ul> <p>Exemplo de Uso de <code>break</code>:</p> <pre><code>for (int i = 0; i &lt; 10; i++) {\n    if (i == 5) {\n        break; // Sai do loop quando i \u00e9 5\n    }\n    Serial.println(i);\n}\n</code></pre> <p>Exemplo de Uso de <code>continue</code>:</p> <pre><code>for (int i = 0; i &lt; 10; i++) {\n    if (i % 2 == 0) {\n        continue; // Pula os n\u00fameros pares\n    }\n    Serial.println(i); // Imprime apenas os n\u00fameros \u00edmpares\n}\n</code></pre>"},{"location":"aulas/iot/modulos/modulo3.html#64-melhores-praticas","title":"6.4 Melhores Pr\u00e1ticas","text":"<ul> <li>Nomea\u00e7\u00e3o de Vari\u00e1veis: Use nomes significativos que reflitam o prop\u00f3sito da vari\u00e1vel.</li> </ul> <pre><code>int contador; // Melhor que 'c' ou 'x'\n</code></pre> <ul> <li>Indenta\u00e7\u00e3o Consistente: Ajuda a manter o c\u00f3digo leg\u00edvel e organizado.</li> </ul> <pre><code>if (condicao) {\n      // C\u00f3digo\n} else {\n      // Outro c\u00f3digo\n}\n</code></pre> <ul> <li>Evitar Repeti\u00e7\u00e3o de C\u00f3digo: Utilize fun\u00e7\u00f5es para reutilizar blocos de c\u00f3digo que se repetem</li> </ul>"},{"location":"aulas/iot/modulos/modulo4.html","title":"M\u00f3dulo 4: Fun\u00e7\u00f5es e Modulariza\u00e7\u00e3o","text":"<p>Bem-vindo ao M\u00f3dulo 4 do curso \"Programa\u00e7\u00e3o em Arduino: Conceitos Fundamentais sem Hardware\". Neste m\u00f3dulo, voc\u00ea ir\u00e1 aprofundar seu conhecimento sobre fun\u00e7\u00f5es na linguagem de programa\u00e7\u00e3o Arduino (C/C++) e aprender\u00e1 sobre modulariza\u00e7\u00e3o de c\u00f3digo. Compreender como criar e utilizar fun\u00e7\u00f5es de forma eficiente \u00e9 essencial para escrever c\u00f3digos mais organizados, reutiliz\u00e1veis e f\u00e1ceis de manter.</p>"},{"location":"aulas/iot/modulos/modulo4.html#objetivos-do-modulo","title":"Objetivos do M\u00f3dulo","text":"<ul> <li>Compreender o conceito de fun\u00e7\u00f5es e sua import\u00e2ncia na programa\u00e7\u00e3o.</li> <li>Aprender a definir e chamar fun\u00e7\u00f5es em Arduino.</li> <li>Trabalhar com par\u00e2metros e valores de retorno em fun\u00e7\u00f5es.</li> <li>Entender o escopo de vari\u00e1veis e a diferen\u00e7a entre vari\u00e1veis locais e globais.</li> <li>Implementar modulariza\u00e7\u00e3o de c\u00f3digo para melhorar a organiza\u00e7\u00e3o e reutiliza\u00e7\u00e3o.</li> <li>Resolver exerc\u00edcios pr\u00e1ticos para consolidar o conhecimento sobre fun\u00e7\u00f5es e modulariza\u00e7\u00e3o.</li> </ul>"},{"location":"aulas/iot/modulos/modulo4.html#1-introducao-as-funcoes","title":"1. Introdu\u00e7\u00e3o \u00e0s Fun\u00e7\u00f5es","text":""},{"location":"aulas/iot/modulos/modulo4.html#11-o-que-sao-funcoes","title":"1.1 O que s\u00e3o Fun\u00e7\u00f5es?","text":"<p>Fun\u00e7\u00f5es s\u00e3o blocos de c\u00f3digo que realizam tarefas espec\u00edficas e podem ser reutilizadas em diferentes partes de um programa. Elas ajudam a dividir um programa em partes menores e mais gerenci\u00e1veis, facilitando o desenvolvimento e a manuten\u00e7\u00e3o do c\u00f3digo.</p>"},{"location":"aulas/iot/modulos/modulo4.html#12-beneficios-do-uso-de-funcoes","title":"1.2 Benef\u00edcios do Uso de Fun\u00e7\u00f5es","text":"<ul> <li>Reutiliza\u00e7\u00e3o de C\u00f3digo: Escreva o c\u00f3digo uma vez e use-o m\u00faltiplas vezes.</li> <li>Organiza\u00e7\u00e3o: Separe o c\u00f3digo em blocos l\u00f3gicos para melhorar a legibilidade.</li> <li>Manuten\u00e7\u00e3o: Facilite a corre\u00e7\u00e3o e atualiza\u00e7\u00e3o do c\u00f3digo.</li> <li>Abstra\u00e7\u00e3o: Simplifique a complexidade do programa escondendo detalhes de implementa\u00e7\u00e3o.</li> </ul>"},{"location":"aulas/iot/modulos/modulo4.html#2-definindo-e-chamando-funcoes","title":"2. Definindo e Chamando Fun\u00e7\u00f5es","text":""},{"location":"aulas/iot/modulos/modulo4.html#21-definicao-de-funcoes","title":"2.1 Defini\u00e7\u00e3o de Fun\u00e7\u00f5es","text":"<p>Para definir uma fun\u00e7\u00e3o em Arduino, voc\u00ea especifica o tipo de retorno, o nome da fun\u00e7\u00e3o e, opcionalmente, os par\u00e2metros que ela recebe.</p> <p>Sintaxe:</p> <pre><code>tipo_retorno nome_funcao(tipo_parametro1 param1, tipo_parametro2 param2, ...) {\n    // Corpo da fun\u00e7\u00e3o\n}\n</code></pre> <p>Exemplo:</p> <pre><code>void saudacao() {\n    Serial.println(\"Bem-vindo ao curso de Arduino!\");\n}\n</code></pre>"},{"location":"aulas/iot/modulos/modulo4.html#22-chamando-funcoes","title":"2.2 Chamando Fun\u00e7\u00f5es","text":"<p>Ap\u00f3s definir uma fun\u00e7\u00e3o, voc\u00ea pode cham\u00e1-la em qualquer parte do seu c\u00f3digo (desde que esteja no escopo correto).</p> <p>Exemplo de Chamada:</p> <pre><code>void setup() {\n    Serial.begin(9600);\n    saudacao(); // Chamada da fun\u00e7\u00e3o saudacao\n}\n\nvoid loop() {\n    // C\u00f3digo do loop\n}\n</code></pre> <p>Explica\u00e7\u00e3o:</p> <ul> <li>A fun\u00e7\u00e3o <code>saudacao()</code> \u00e9 chamada dentro da fun\u00e7\u00e3o <code>setup()</code>.</li> <li>Quando o programa \u00e9 executado, o texto \"Bem-vindo ao curso de Arduino!\" ser\u00e1 impresso no Monitor Serial uma vez no in\u00edcio.</li> </ul>"},{"location":"aulas/iot/modulos/modulo4.html#3-parametros-e-valores-de-retorno","title":"3. Par\u00e2metros e Valores de Retorno","text":""},{"location":"aulas/iot/modulos/modulo4.html#31-funcoes-com-parametros","title":"3.1 Fun\u00e7\u00f5es com Par\u00e2metros","text":"<p>Par\u00e2metros permitem que voc\u00ea passe informa\u00e7\u00f5es para as fun\u00e7\u00f5es, tornando-as mais flex\u00edveis e reutiliz\u00e1veis.</p> <p>Sintaxe:</p> <pre><code>void nome_funcao(tipo_parametro1 param1, tipo_parametro2 param2) {\n    // Corpo da fun\u00e7\u00e3o\n}\n</code></pre> <p>Exemplo:</p> <pre><code>void imprimirMensagem(String mensagem) {\n    Serial.println(mensagem);\n}\n\nvoid setup() {\n    Serial.begin(9600);\n    imprimirMensagem(\"Ol\u00e1, Arduino!\");\n}\n\nvoid loop() {\n    // C\u00f3digo do loop\n}\n</code></pre> <p>Explica\u00e7\u00e3o:</p> <ul> <li>A fun\u00e7\u00e3o <code>imprimirMensagem</code> recebe uma <code>String</code> como par\u00e2metro e imprime no Monitor Serial.</li> <li>Isso permite que voc\u00ea passe diferentes mensagens para a fun\u00e7\u00e3o sem precisar alter\u00e1-la.</li> </ul>"},{"location":"aulas/iot/modulos/modulo4.html#32-funcoes-com-retorno","title":"3.2 Fun\u00e7\u00f5es com Retorno","text":"<p>Fun\u00e7\u00f5es podem retornar valores que podem ser utilizados em outras partes do programa.</p> <p>Sintaxe:</p> <pre><code>tipo_retorno nome_funcao(tipo_parametro1 param1, tipo_parametro2 param2) {\n    // Corpo da fun\u00e7\u00e3o\n    return valor;\n}\n</code></pre> <p>Exemplo:</p> <pre><code>int soma(int a, int b) {\n    return a + b;\n}\n\nvoid setup() {\n    Serial.begin(9600);\n    int resultado = soma(5, 3);\n    Serial.print(\"Resultado da soma: \");\n    Serial.println(resultado);\n}\n\nvoid loop() {\n    // C\u00f3digo do loop\n}\n</code></pre> <p>Explica\u00e7\u00e3o:</p> <ul> <li>A fun\u00e7\u00e3o <code>soma</code> recebe dois inteiros como par\u00e2metros e retorna a soma deles.</li> <li>O valor retornado \u00e9 armazenado na vari\u00e1vel <code>resultado</code> e impresso no Monitor Serial.</li> </ul>"},{"location":"aulas/iot/modulos/modulo4.html#4-escopo-de-variaveis","title":"4. Escopo de Vari\u00e1veis","text":""},{"location":"aulas/iot/modulos/modulo4.html#41-variaveis-locais","title":"4.1 Vari\u00e1veis Locais","text":"<p>Vari\u00e1veis declaradas dentro de uma fun\u00e7\u00e3o s\u00e3o chamadas de vari\u00e1veis locais e s\u00f3 podem ser acessadas dentro dessa fun\u00e7\u00e3o.</p> <p>Exemplo:</p> <pre><code>void setup() {\n    Serial.begin(9600);\n    int numero = 10; // Vari\u00e1vel local\n    Serial.println(numero);\n}\n\nvoid loop() {\n    // N\u00e3o h\u00e1 c\u00f3digo no loop\n}\n</code></pre> <p>Explica\u00e7\u00e3o:</p> <ul> <li>A vari\u00e1vel <code>numero</code> s\u00f3 existe dentro da fun\u00e7\u00e3o <code>setup()</code>.</li> <li>Tentativas de acessar <code>numero</code> fora de <code>setup()</code> resultar\u00e3o em erro.</li> </ul>"},{"location":"aulas/iot/modulos/modulo4.html#42-variaveis-globais","title":"4.2 Vari\u00e1veis Globais","text":"<p>Vari\u00e1veis declaradas fora de todas as fun\u00e7\u00f5es s\u00e3o chamadas de vari\u00e1veis globais e podem ser acessadas por qualquer fun\u00e7\u00e3o no programa.</p> <p>Exemplo:</p> <pre><code>int contador = 0; // Vari\u00e1vel global\n\nvoid setup() {\n    Serial.begin(9600);\n    Serial.println(contador);\n}\n\nvoid loop() {\n    contador++;\n    Serial.println(contador);\n    delay(1000);\n}\n</code></pre> <p>Explica\u00e7\u00e3o:</p> <ul> <li>A vari\u00e1vel <code>contador</code> \u00e9 acess\u00edvel tanto em <code>setup()</code> quanto em <code>loop()</code>.</li> <li>O valor de <code>contador</code> \u00e9 incrementado e impresso a cada segundo.</li> </ul>"},{"location":"aulas/iot/modulos/modulo4.html#5-modularizacao-de-codigo","title":"5. Modulariza\u00e7\u00e3o de C\u00f3digo","text":""},{"location":"aulas/iot/modulos/modulo4.html#51-por-que-modularizar","title":"5.1 Por que Modularizar?","text":"<p>Modularizar significa dividir o c\u00f3digo em m\u00f3dulos ou fun\u00e7\u00f5es menores que realizam tarefas espec\u00edficas. Isso melhora a legibilidade, facilita a manuten\u00e7\u00e3o e permite a reutiliza\u00e7\u00e3o de c\u00f3digo.</p>"},{"location":"aulas/iot/modulos/modulo4.html#52-exemplos-de-modularizacao","title":"5.2 Exemplos de Modulariza\u00e7\u00e3o","text":"<p>Exemplo 1: Separar C\u00e1lculo da Impress\u00e3o</p> <pre><code>int calcularSoma(int a, int b) {\n    return a + b;\n}\n\nvoid imprimirSoma(int a, int b) {\n    int resultado = calcularSoma(a, b);\n    Serial.print(\"A soma de \");\n    Serial.print(a);\n    Serial.print(\" e \");\n    Serial.print(b);\n    Serial.print(\" \u00e9: \");\n    Serial.println(resultado);\n}\n\nvoid setup() {\n    Serial.begin(9600);\n    imprimirSoma(5, 7);\n}\n\nvoid loop() {\n    // N\u00e3o h\u00e1 c\u00f3digo no loop\n}\n</code></pre> <p>Explica\u00e7\u00e3o:</p> <ul> <li>A fun\u00e7\u00e3o <code>calcularSoma</code> realiza o c\u00e1lculo da soma.</li> <li>A fun\u00e7\u00e3o <code>imprimirSoma</code> gerencia a impress\u00e3o do resultado.</li> <li>Isso separa as responsabilidades, tornando o c\u00f3digo mais organizado.</li> </ul> <p>Exemplo 2: Controle de LEDs com Fun\u00e7\u00f5es</p> <pre><code>const int ledVerde = 9;\nconst int ledVermelho = 10;\n\nvoid ligarLedVerde() {\n    digitalWrite(ledVerde, HIGH);\n}\n\nvoid desligarLedVerde() {\n    digitalWrite(ledVerde, LOW);\n}\n\nvoid ligarLedVermelho() {\n    digitalWrite(ledVermelho, HIGH);\n}\n\nvoid desligarLedVermelho() {\n    digitalWrite(ledVermelho, LOW);\n}\n\nvoid setup() {\n    pinMode(ledVerde, OUTPUT);\n    pinMode(ledVermelho, OUTPUT);\n}\n\nvoid loop() {\n    ligarLedVerde();\n    delay(1000);\n    desligarLedVerde();\n    ligarLedVermelho();\n    delay(1000);\n    desligarLedVermelho();\n}\n</code></pre> <p>Explica\u00e7\u00e3o:</p> <ul> <li>Fun\u00e7\u00f5es espec\u00edficas para ligar e desligar LEDs verde e vermelho.</li> <li>Facilita a manipula\u00e7\u00e3o dos LEDs sem repetir o c\u00f3digo.</li> </ul>"},{"location":"aulas/iot/modulos/modulo4.html#6-exemplos-praticos","title":"6. Exemplos Pr\u00e1ticos","text":""},{"location":"aulas/iot/modulos/modulo4.html#61-funcao-para-calcular-fatorial","title":"6.1 Fun\u00e7\u00e3o para Calcular Fatorial","text":"<pre><code>long calcularFatorial(int numero) {\n    if (numero &lt; 0) return -1; // Retorna -1 para n\u00fameros negativos\n    long fatorial = 1;\n    for (int i = 1; i &lt;= numero; i++) {\n        fatorial *= i;\n    }\n    return fatorial;\n}\n\nvoid setup() {\n    Serial.begin(9600);\n    int num = 5;\n    long resultado = calcularFatorial(num);\n    if (resultado != -1) {\n        Serial.print(\"Fatorial de \");\n        Serial.print(num);\n        Serial.print(\" \u00e9 \");\n        Serial.println(resultado);\n    } else {\n        Serial.println(\"Erro: Fatorial de n\u00famero negativo n\u00e3o existe.\");\n    }\n}\n\nvoid loop() {\n    // N\u00e3o h\u00e1 c\u00f3digo no loop\n}\n</code></pre> <p>Explica\u00e7\u00e3o:</p> <ul> <li>A fun\u00e7\u00e3o <code>calcularFatorial</code> retorna o fatorial de um n\u00famero.</li> <li>Verifica se o n\u00famero \u00e9 negativo e retorna erro se for.</li> <li>O resultado \u00e9 impresso no Monitor Serial.</li> </ul>"},{"location":"aulas/iot/modulos/modulo4.html#62-funcao-para-verificar-palindromo","title":"6.2 Fun\u00e7\u00e3o para Verificar Pal\u00edndromo","text":"<pre><code>bool ehPalindromo(String palavra) {\n    int inicio = 0;\n    int fim = palavra.length() - 1;\n    while (inicio &lt; fim) {\n        if (tolower(palavra[inicio]) != tolower(palavra[fim])) {\n            return false;\n        }\n        inicio++;\n        fim--;\n    }\n    return true;\n}\n\nvoid setup() {\n    Serial.begin(9600);\n    String palavra = \"Radar\";\n    if (ehPalindromo(palavra)) {\n        Serial.println(palavra + \" \u00e9 um pal\u00edndromo.\");\n    } else {\n        Serial.println(palavra + \" n\u00e3o \u00e9 um pal\u00edndromo.\");\n    }\n}\n\nvoid loop() {\n    // N\u00e3o h\u00e1 c\u00f3digo no loop\n}\n</code></pre> <p>Explica\u00e7\u00e3o:</p> <ul> <li>A fun\u00e7\u00e3o <code>ehPalindromo</code> verifica se uma palavra \u00e9 um pal\u00edndromo.</li> <li>Compara caracteres do in\u00edcio e fim da string.</li> <li>Ignora diferen\u00e7as de mai\u00fasculas e min\u00fasculas.</li> </ul>"},{"location":"aulas/iot/modulos/modulo4.html#63-funcao-para-converter-celsius-em-fahrenheit","title":"6.3 Fun\u00e7\u00e3o para Converter Celsius em Fahrenheit","text":"<pre><code>float celsiusParaFahrenheit(float celsius) {\n    return (celsius * 9.0 / 5.0) + 32.0;\n}\n\nvoid setup() {\n    Serial.begin(9600);\n    float tempC = 25.0;\n    float tempF = celsiusParaFahrenheit(tempC);\n    Serial.print(tempC);\n    Serial.print(\"\u00b0C \u00e9 igual a \");\n    Serial.print(tempF);\n    Serial.println(\"\u00b0F.\");\n}\n\nvoid loop() {\n    // N\u00e3o h\u00e1 c\u00f3digo no loop\n}\n</code></pre> <p>Explica\u00e7\u00e3o:</p> <ul> <li>A fun\u00e7\u00e3o <code>celsiusParaFahrenheit</code> converte uma temperatura de Celsius para Fahrenheit.</li> <li>O resultado \u00e9 impresso no Monitor Serial.</li> </ul>"},{"location":"aulas/iot/modulos/modulo4.html#7-exercicios-praticos","title":"7. Exerc\u00edcios Pr\u00e1ticos","text":""},{"location":"aulas/iot/modulos/modulo4.html#exercicio-1-funcao-para-calcular-media","title":"Exerc\u00edcio 1: Fun\u00e7\u00e3o para Calcular M\u00e9dia","text":"<ul> <li> <p>Tarefa: Crie uma fun\u00e7\u00e3o que calcula a m\u00e9dia de tr\u00eas n\u00fameros fornecidos pelo usu\u00e1rio e imprime o resultado.</p> </li> <li> <p>Dicas:</p> </li> <li> <p>Utilize uma fun\u00e7\u00e3o que recebe tr\u00eas par\u00e2metros e retorna a m\u00e9dia.</p> </li> </ul> <pre><code>float calcularMedia(float a, float b, float c) {\n    return (a + b + c) / 3.0;\n}\n\nvoid setup() {\n    Serial.begin(9600);\n    float num1 = 7.5;\n    float num2 = 8.0;\n    float num3 = 9.5;\n    float media = calcularMedia(num1, num2, num3);\n    Serial.print(\"A m\u00e9dia \u00e9: \");\n    Serial.println(media);\n}\n\nvoid loop() {\n    // N\u00e3o h\u00e1 c\u00f3digo no loop\n}\n</code></pre>"},{"location":"aulas/iot/modulos/modulo4.html#exercicio-2-funcao-para-determinar-o-maior-numero","title":"Exerc\u00edcio 2: Fun\u00e7\u00e3o para Determinar o Maior N\u00famero","text":"<ul> <li> <p>Tarefa: Escreva uma fun\u00e7\u00e3o que recebe dois n\u00fameros e retorna o maior deles. Use essa fun\u00e7\u00e3o no seu programa para comparar dois n\u00fameros fornecidos pelo usu\u00e1rio.</p> </li> <li> <p>Exemplo de C\u00f3digo:</p> </li> </ul> <pre><code>int encontrarMaior(int a, int b) {\n    if (a &gt; b) {\n        return a;\n    } else {\n        return b;\n    }\n}\n\nvoid setup() {\n    Serial.begin(9600);\n    int num1 = 15;\n    int num2 = 20;\n    int maior = encontrarMaior(num1, num2);\n    Serial.print(\"O maior n\u00famero \u00e9: \");\n    Serial.println(maior);\n}\n\nvoid loop() {\n    // N\u00e3o h\u00e1 c\u00f3digo no loop\n}\n</code></pre>"},{"location":"aulas/iot/modulos/modulo4.html#exercicio-3-funcao-para-verificar-numero-par-ou-impar","title":"Exerc\u00edcio 3: Fun\u00e7\u00e3o para Verificar N\u00famero Par ou \u00cdmpar","text":"<ul> <li> <p>Tarefa: Desenvolva uma fun\u00e7\u00e3o que recebe um n\u00famero inteiro e retorna <code>true</code> se o n\u00famero for par ou <code>false</code> se for \u00edmpar. Utilize essa fun\u00e7\u00e3o para verificar a paridade de um n\u00famero fornecido pelo usu\u00e1rio.</p> </li> <li> <p>Exemplo de C\u00f3digo:</p> </li> </ul> <pre><code>bool ehPar(int numero) {\n    return (numero % 2 == 0);\n}\n\nvoid setup() {\n    Serial.begin(9600);\n    int num = 7;\n    if (ehPar(num)) {\n        Serial.println(\"O n\u00famero \u00e9 par.\");\n    } else {\n        Serial.println(\"O n\u00famero \u00e9 \u00edmpar.\");\n    }\n}\n\nvoid loop() {\n    // N\u00e3o h\u00e1 c\u00f3digo no loop\n}\n</code></pre>"},{"location":"aulas/iot/modulos/modulo4.html#8-conceitos-importantes","title":"8. Conceitos Importantes","text":""},{"location":"aulas/iot/modulos/modulo4.html#81-recursao","title":"8.1 Recurs\u00e3o","text":"<p>A recurs\u00e3o ocorre quando uma fun\u00e7\u00e3o chama a si mesma para resolver um problema. \u00c9 uma t\u00e9cnica poderosa, mas deve ser usada com cuidado para evitar loops infinitos.</p> <p>Exemplo de Fun\u00e7\u00e3o Recursiva para Calcular Fatorial:</p> <pre><code>long fatorialRecursivo(int numero) {\n    if (numero &lt;= 1) {\n        return 1;\n    } else {\n        return numero * fatorialRecursivo(numero - 1);\n    }\n}\n\nvoid setup() {\n    Serial.begin(9600);\n    int num = 5;\n    long resultado = fatorialRecursivo(num);\n    Serial.print(\"Fatorial de \");\n    Serial.print(num);\n    Serial.print(\" \u00e9 \");\n    Serial.println(resultado);\n}\n\nvoid loop() {\n    // N\u00e3o h\u00e1 c\u00f3digo no loop\n}\n</code></pre> <p>Explica\u00e7\u00e3o:</p> <ul> <li>A fun\u00e7\u00e3o <code>fatorialRecursivo</code> chama a si mesma at\u00e9 que a condi\u00e7\u00e3o base seja atingida (<code>numero &lt;= 1</code>).</li> <li>Calcula o fatorial de forma recursiva.</li> </ul>"},{"location":"aulas/iot/modulos/modulo4.html#82-funcoes-inline","title":"8.2 Fun\u00e7\u00f5es Inline","text":"<p>Fun\u00e7\u00f5es inline s\u00e3o sugest\u00f5es ao compilador para inserir o corpo da fun\u00e7\u00e3o no ponto de chamada, reduzindo a sobrecarga de chamadas de fun\u00e7\u00e3o.</p> <p>Exemplo:</p> <pre><code>inline int quadrado(int x) {\n    return x * x;\n}\n\nvoid setup() {\n    Serial.begin(9600);\n    int num = 4;\n    int q = quadrado(num);\n    Serial.print(\"Quadrado de \");\n    Serial.print(num);\n    Serial.print(\" \u00e9 \");\n    Serial.println(q);\n}\n\nvoid loop() {\n    // N\u00e3o h\u00e1 c\u00f3digo no loop\n}\n</code></pre> <p>Explica\u00e7\u00e3o:</p> <ul> <li>A fun\u00e7\u00e3o <code>quadrado</code> \u00e9 definida como <code>inline</code>, sugerindo ao compilador para otimizar a chamada da fun\u00e7\u00e3o.</li> </ul>"},{"location":"aulas/iot/modulos/modulo4.html#83-sobrecarga-de-funcoes","title":"8.3 Sobrecarga de Fun\u00e7\u00f5es","text":"<p>Sobrecarga permite definir m\u00faltiplas fun\u00e7\u00f5es com o mesmo nome, mas com diferentes par\u00e2metros.</p> <p>Exemplo:</p> <pre><code>int soma(int a, int b) {\n    return a + b;\n}\n\nfloat soma(float a, float b) {\n    return a + b;\n}\n\nvoid setup() {\n    Serial.begin(9600);\n    Serial.print(\"Soma de 5 e 3: \");\n    Serial.println(soma(5, 3));\n    Serial.print(\"Soma de 5.5 e 3.2: \");\n    Serial.println(soma(5.5, 3.2));\n}\n\nvoid loop() {\n    // N\u00e3o h\u00e1 c\u00f3digo no loop\n}\n</code></pre> <p>Explica\u00e7\u00e3o:</p> <ul> <li>Duas fun\u00e7\u00f5es <code>soma</code> s\u00e3o definidas, uma para inteiros e outra para floats.</li> <li>O compilador decide qual fun\u00e7\u00e3o chamar com base nos argumentos fornecidos.</li> </ul>"},{"location":"aulas/iot/modulos/modulo5.html","title":"M\u00f3dulo 5: Arrays e Manipula\u00e7\u00e3o de Dados","text":"<p>Bem-vindo ao M\u00f3dulo 5 do curso \"Programa\u00e7\u00e3o em Arduino: Conceitos Fundamentais sem Hardware\". Neste m\u00f3dulo, voc\u00ea ir\u00e1 aprender sobre arrays e manipula\u00e7\u00e3o de dados na linguagem de programa\u00e7\u00e3o Arduino (C/C++). Arrays s\u00e3o estruturas de dados que armazenam m\u00faltiplos valores do mesmo tipo, permitindo o gerenciamento eficiente de cole\u00e7\u00f5es de dados.</p>"},{"location":"aulas/iot/modulos/modulo5.html#objetivos-do-modulo","title":"Objetivos do M\u00f3dulo","text":"<ul> <li>Compreender o conceito de arrays e sua import\u00e2ncia na programa\u00e7\u00e3o.</li> <li>Aprender a declarar, inicializar e acessar elementos de arrays.</li> <li>Trabalhar com arrays multidimensionais.</li> <li>Aplicar loops para manipular dados em arrays.</li> <li>Implementar fun\u00e7\u00f5es que utilizam arrays como par\u00e2metros.</li> <li>Realizar opera\u00e7\u00f5es de busca e ordena\u00e7\u00e3o em arrays.</li> <li>Resolver exerc\u00edcios pr\u00e1ticos para consolidar o conhecimento sobre arrays e manipula\u00e7\u00e3o de dados.</li> </ul>"},{"location":"aulas/iot/modulos/modulo5.html#1-introducao-aos-arrays","title":"1. Introdu\u00e7\u00e3o aos Arrays","text":""},{"location":"aulas/iot/modulos/modulo5.html#11-o-que-sao-arrays","title":"1.1 O que s\u00e3o Arrays?","text":"<p>Um array \u00e9 uma estrutura de dados que armazena uma cole\u00e7\u00e3o de elementos do mesmo tipo em posi\u00e7\u00f5es cont\u00edguas de mem\u00f3ria. Cada elemento em um array \u00e9 identificado por um \u00edndice, permitindo o acesso r\u00e1pido e eficiente aos dados.</p>"},{"location":"aulas/iot/modulos/modulo5.html#12-beneficios-do-uso-de-arrays","title":"1.2 Benef\u00edcios do Uso de Arrays","text":"<ul> <li>Organiza\u00e7\u00e3o: Permite armazenar m\u00faltiplos valores relacionados de forma organizada.</li> <li>Efici\u00eancia: Facilita o processamento de grandes conjuntos de dados.</li> <li>Facilidade de Acesso: Permite acessar elementos individuais usando \u00edndices.</li> <li>Redu\u00e7\u00e3o de Repeti\u00e7\u00e3o: Evita a necessidade de declarar m\u00faltiplas vari\u00e1veis para armazenar dados semelhantes.</li> </ul>"},{"location":"aulas/iot/modulos/modulo5.html#2-declaracao-e-inicializacao-de-arrays","title":"2. Declara\u00e7\u00e3o e Inicializa\u00e7\u00e3o de Arrays","text":""},{"location":"aulas/iot/modulos/modulo5.html#21-declaracao-de-arrays","title":"2.1 Declara\u00e7\u00e3o de Arrays","text":"<p>Para declarar um array, voc\u00ea especifica o tipo de dados dos elementos e o n\u00famero de elementos que o array ir\u00e1 conter.</p> <p>Sintaxe:</p> <pre><code>tipo nome_array[tamanho];\n</code></pre> <p>Exemplo:</p> <pre><code>int notas[5];\n</code></pre>"},{"location":"aulas/iot/modulos/modulo5.html#22-inicializacao-de-arrays","title":"2.2 Inicializa\u00e7\u00e3o de Arrays","text":"<p>Voc\u00ea pode inicializar um array no momento da declara\u00e7\u00e3o ou atribuir valores individualmente.</p> <p>Inicializa\u00e7\u00e3o na Declara\u00e7\u00e3o:</p> <pre><code>int notas[5] = {85, 90, 78, 92, 88};\n</code></pre> <p>Atribui\u00e7\u00e3o Individual:</p> <pre><code>int notas[5];\nnotas[0] = 85;\nnotas[1] = 90;\nnotas[2] = 78;\nnotas[3] = 92;\nnotas[4] = 88;\n</code></pre>"},{"location":"aulas/iot/modulos/modulo5.html#23-acesso-aos-elementos-do-array","title":"2.3 Acesso aos Elementos do Array","text":"<p>Os elementos de um array s\u00e3o acessados usando \u00edndices, que come\u00e7am em 0.</p> <p>Exemplo:</p> <pre><code>int primeiraNota = notas[0]; // Acessa o primeiro elemento\nint terceiraNota = notas[2]; // Acessa o terceiro elemento\n</code></pre> <p>Imprimindo Elementos no Monitor Serial:</p> <pre><code>void setup() {\n    Serial.begin(9600);\n    Serial.println(notas[0]); // Imprime 85\n    Serial.println(notas[2]); // Imprime 78\n}\n\nvoid loop() {\n    // N\u00e3o h\u00e1 c\u00f3digo no loop\n}\n</code></pre>"},{"location":"aulas/iot/modulos/modulo5.html#3-arrays-multidimensionais","title":"3. Arrays Multidimensionais","text":""},{"location":"aulas/iot/modulos/modulo5.html#31-declaracao-de-arrays-2d","title":"3.1 Declara\u00e7\u00e3o de Arrays 2D","text":"<p>Arrays multidimensionais permitem armazenar dados em uma grade ou tabela.</p> <p>Sintaxe:</p> <pre><code>tipo nome_array[linha][coluna];\n</code></pre> <p>Exemplo:</p> <pre><code>int matriz[3][4];\n</code></pre>"},{"location":"aulas/iot/modulos/modulo5.html#32-inicializacao-de-arrays-2d","title":"3.2 Inicializa\u00e7\u00e3o de Arrays 2D","text":"<pre><code>int matriz[2][3] = {\n    {1, 2, 3},\n    {4, 5, 6}\n};\n</code></pre>"},{"location":"aulas/iot/modulos/modulo5.html#33-acesso-aos-elementos-de-arrays-2d","title":"3.3 Acesso aos Elementos de Arrays 2D","text":"<pre><code>int valor = matriz[1][2]; // Acessa o elemento na segunda linha, terceira coluna (valor = 6)\n</code></pre> <p>Imprimindo uma Matriz no Monitor Serial:</p> <pre><code>void setup() {\n    Serial.begin(9600);\n\n    for(int i = 0; i &lt; 2; i++) { // Percorre as linhas\n        for(int j = 0; j &lt; 3; j++) { // Percorre as colunas\n            Serial.print(matriz[i][j]);\n            Serial.print(\" \");\n        }\n        Serial.println();\n    }\n}\n\nvoid loop() {\n    // N\u00e3o h\u00e1 c\u00f3digo no loop\n}\n</code></pre>"},{"location":"aulas/iot/modulos/modulo5.html#4-manipulacao-de-arrays-com-loops","title":"4. Manipula\u00e7\u00e3o de Arrays com Loops","text":""},{"location":"aulas/iot/modulos/modulo5.html#41-uso-de-for-para-iterar-sobre-arrays","title":"4.1 Uso de <code>for</code> para Iterar sobre Arrays","text":"<pre><code>void setup() {\n    Serial.begin(9600);\n\n    for(int i = 0; i &lt; 5; i++) {\n        Serial.print(\"Nota \");\n        Serial.print(i + 1);\n        Serial.print(\": \");\n        Serial.println(notas[i]);\n    }\n}\n\nvoid loop() {\n    // N\u00e3o h\u00e1 c\u00f3digo no loop\n}\n</code></pre>"},{"location":"aulas/iot/modulos/modulo5.html#42-uso-de-while-para-iterar-sobre-arrays","title":"4.2 Uso de <code>while</code> para Iterar sobre Arrays","text":"<pre><code>void setup() {\n    Serial.begin(9600);\n    int i = 0;\n\n    while(i &lt; 5) {\n        Serial.print(\"Nota \");\n        Serial.print(i + 1);\n        Serial.print(\": \");\n        Serial.println(notas[i]);\n        i++;\n    }\n}\n\nvoid loop() {\n    // N\u00e3o h\u00e1 c\u00f3digo no loop\n}\n</code></pre>"},{"location":"aulas/iot/modulos/modulo5.html#43-uso-de-do-while-para-iterar-sobre-arrays","title":"4.3 Uso de <code>do-while</code> para Iterar sobre Arrays","text":"<pre><code>void setup() {\n    Serial.begin(9600);\n    int i = 0;\n\n    do {\n        Serial.print(\"Nota \");\n        Serial.print(i + 1);\n        Serial.print(\": \");\n        Serial.println(notas[i]);\n        i++;\n    } while(i &lt; 5);\n}\n\nvoid loop() {\n    // N\u00e3o h\u00e1 c\u00f3digo no loop\n}\n</code></pre>"},{"location":"aulas/iot/modulos/modulo5.html#5-funcoes-com-arrays","title":"5. Fun\u00e7\u00f5es com Arrays","text":""},{"location":"aulas/iot/modulos/modulo5.html#51-passando-arrays-como-parametros","title":"5.1 Passando Arrays como Par\u00e2metros","text":"<pre><code>void imprimirNotas(int arr[], int tamanho) {\n    for(int i = 0; i &lt; tamanho; i++) {\n        Serial.print(\"Nota \");\n        Serial.print(i + 1);\n        Serial.print(\": \");\n        Serial.println(arr[i]);\n    }\n}\n\nvoid setup() {\n    Serial.begin(9600);\n    imprimirNotas(notas, 5);\n}\n\nvoid loop() {\n    // N\u00e3o h\u00e1 c\u00f3digo no loop\n}\n</code></pre>"},{"location":"aulas/iot/modulos/modulo5.html#52-funcoes-que-retornam-arrays","title":"5.2 Fun\u00e7\u00f5es que Retornam Arrays","text":"<p>Em C/C++, fun\u00e7\u00f5es n\u00e3o podem retornar arrays diretamente, mas podem retornar ponteiros para arrays ou utilizar estruturas de dados alternativas como <code>std::vector</code> (n\u00e3o muito comum no Arduino devido a limita\u00e7\u00f5es de mem\u00f3ria).</p> <p>Exemplo de Retorno de Ponteiro para Array:</p> <pre><code>int* retornarNotas() {\n    static int notasRetornadas[5] = {85, 90, 78, 92, 88};\n    return notasRetornadas;\n}\n\nvoid setup() {\n    Serial.begin(9600);\n    int* notas = retornarNotas();\n\n    for(int i = 0; i &lt; 5; i++) {\n        Serial.print(\"Nota \");\n        Serial.print(i + 1);\n        Serial.print(\": \");\n        Serial.println(notas[i]);\n    }\n}\n\nvoid loop() {\n    // N\u00e3o h\u00e1 c\u00f3digo no loop\n}\n</code></pre> <p>Explica\u00e7\u00e3o:</p> <ul> <li>A fun\u00e7\u00e3o <code>retornarNotas</code> retorna um ponteiro para o array est\u00e1tico <code>notasRetornadas</code>.</li> <li>O array \u00e9 est\u00e1tico para evitar que seja destru\u00eddo ao sair da fun\u00e7\u00e3o.</li> </ul>"},{"location":"aulas/iot/modulos/modulo5.html#6-operacoes-com-arrays","title":"6. Opera\u00e7\u00f5es com Arrays","text":""},{"location":"aulas/iot/modulos/modulo5.html#61-busca-em-arrays","title":"6.1 Busca em Arrays","text":"<pre><code>int buscarNota(int arr[], int tamanho, int valorBuscado) {\n    for(int i = 0; i &lt; tamanho; i++) {\n        if(arr[i] == valorBuscado) {\n            return i; // Retorna o \u00edndice onde o valor foi encontrado\n        }\n    }\n    return -1; // Retorna -1 se o valor n\u00e3o for encontrado\n}\n\nvoid setup() {\n    Serial.begin(9600);\n    int valor = 90;\n    int indice = buscarNota(notas, 5, valor);\n\n    if(indice != -1) {\n        Serial.print(\"Valor \");\n        Serial.print(valor);\n        Serial.print(\" encontrado no \u00edndice \");\n        Serial.println(indice);\n    } else {\n        Serial.print(\"Valor \");\n        Serial.print(valor);\n        Serial.println(\" n\u00e3o encontrado.\");\n    }\n}\n\nvoid loop() {\n    // N\u00e3o h\u00e1 c\u00f3digo no loop\n}\n</code></pre>"},{"location":"aulas/iot/modulos/modulo5.html#62-ordenacao-de-arrays","title":"6.2 Ordena\u00e7\u00e3o de Arrays","text":""},{"location":"aulas/iot/modulos/modulo5.html#621-ordenacao-bubble-sort","title":"6.2.1 Ordena\u00e7\u00e3o Bubble Sort","text":"<pre><code>void bubbleSort(int arr[], int tamanho) {\n    for(int i = 0; i &lt; tamanho - 1; i++) {\n        for(int j = 0; j &lt; tamanho - i - 1; j++) {\n            if(arr[j] &gt; arr[j + 1]) {\n                // Troca arr[j] e arr[j + 1]\n                int temp = arr[j];\n                arr[j] = arr[j + 1];\n                arr[j + 1] = temp;\n            }\n        }\n    }\n}\n\nvoid setup() {\n    Serial.begin(9600);\n    Serial.println(\"Notas antes da ordena\u00e7\u00e3o:\");\n    imprimirNotas(notas, 5);\n\n    bubbleSort(notas, 5);\n\n    Serial.println(\"Notas ap\u00f3s a ordena\u00e7\u00e3o:\");\n    imprimirNotas(notas, 5);\n}\n\nvoid loop() {\n    // N\u00e3o h\u00e1 c\u00f3digo no loop\n}\n</code></pre> <p>Explica\u00e7\u00e3o:</p> <ul> <li>O algoritmo Bubble Sort compara pares de elementos adjacentes e os troca se estiverem na ordem errada.</li> <li>Este processo \u00e9 repetido at\u00e9 que o array esteja ordenado.</li> </ul>"},{"location":"aulas/iot/modulos/modulo5.html#622-ordenacao-selection-sort","title":"6.2.2 Ordena\u00e7\u00e3o Selection Sort","text":"<pre><code>void selectionSort(int arr[], int tamanho) {\n    for(int i = 0; i &lt; tamanho - 1; i++) {\n        int minIndex = i;\n        for(int j = i + 1; j &lt; tamanho; j++) {\n            if(arr[j] &lt; arr[minIndex]) {\n                minIndex = j;\n            }\n        }\n        // Troca arr[i] e arr[minIndex]\n        int temp = arr[i];\n        arr[i] = arr[minIndex];\n        arr[minIndex] = temp;\n    }\n}\n\nvoid setup() {\n    Serial.begin(9600);\n    Serial.println(\"Notas antes da ordena\u00e7\u00e3o:\");\n    imprimirNotas(notas, 5);\n\n    selectionSort(notas, 5);\n\n    Serial.println(\"Notas ap\u00f3s a ordena\u00e7\u00e3o:\");\n    imprimirNotas(notas, 5);\n}\n\nvoid loop() {\n    // N\u00e3o h\u00e1 c\u00f3digo no loop\n}\n</code></pre> <p>Explica\u00e7\u00e3o:</p> <ul> <li>O algoritmo Selection Sort seleciona o menor elemento do array e o coloca na posi\u00e7\u00e3o correta.</li> <li>Este processo \u00e9 repetido para cada posi\u00e7\u00e3o do array.</li> </ul>"},{"location":"aulas/iot/modulos/modulo5.html#63-media-e-mediana","title":"6.3 M\u00e9dia e Mediana","text":"<pre><code>float calcularMedia(int arr[], int tamanho) {\n    int soma = 0;\n    for(int i = 0; i &lt; tamanho; i++) {\n        soma += arr[i];\n    }\n    return (float)soma / tamanho;\n}\n\nfloat calcularMediana(int arr[], int tamanho) {\n    // Primeiro, ordenar o array\n    bubbleSort(arr, tamanho);\n\n    if(tamanho % 2 == 0) {\n        return (arr[tamanho / 2 - 1] + arr[tamanho / 2]) / 2.0;\n    } else {\n        return arr[tamanho / 2];\n    }\n}\n\nvoid setup() {\n    Serial.begin(9600);\n\n    // Exibir array ordenado\n    bubbleSort(notas, 5);\n    Serial.println(\"Notas ordenadas:\");\n    imprimirNotas(notas, 5);\n\n    float media = calcularMedia(notas, 5);\n    float mediana = calcularMediana(notas, 5);\n\n    Serial.print(\"M\u00e9dia das notas: \");\n    Serial.println(media);\n\n    Serial.print(\"Mediana das notas: \");\n    Serial.println(mediana);\n}\n\nvoid loop() {\n    // N\u00e3o h\u00e1 c\u00f3digo no loop\n}\n</code></pre> <p>Explica\u00e7\u00e3o:</p> <ul> <li>A fun\u00e7\u00e3o <code>calcularMedia</code> soma todos os elementos do array e divide pelo n\u00famero de elementos.</li> <li>A fun\u00e7\u00e3o <code>calcularMediana</code> ordena o array e retorna o valor do meio ou a m\u00e9dia dos dois valores centrais.</li> </ul>"},{"location":"aulas/iot/modulos/modulo5.html#7-exercicios-praticos","title":"7. Exerc\u00edcios Pr\u00e1ticos","text":""},{"location":"aulas/iot/modulos/modulo5.html#exercicio-1-busca-sequencial","title":"Exerc\u00edcio 1: Busca Sequencial","text":"<ul> <li> <p>Tarefa: Crie uma fun\u00e7\u00e3o que realiza busca sequencial em um array de inteiros. A fun\u00e7\u00e3o deve retornar o \u00edndice do elemento buscado ou -1 se n\u00e3o encontrado.</p> </li> <li> <p>Exemplo de C\u00f3digo:</p> </li> </ul> <pre><code>int buscaSequencial(int arr[], int tamanho, int valorBuscado) {\n    for(int i = 0; i &lt; tamanho; i++) {\n        if(arr[i] == valorBuscado) {\n            return i;\n        }\n    }\n    return -1;\n}\n\nvoid setup() {\n    Serial.begin(9600);\n    int valor = 78;\n    int indice = buscaSequencial(notas, 5, valor);\n\n    if(indice != -1) {\n        Serial.print(\"Valor \");\n        Serial.print(valor);\n        Serial.print(\" encontrado no \u00edndice \");\n        Serial.println(indice);\n    } else {\n        Serial.print(\"Valor \");\n        Serial.print(valor);\n        Serial.println(\" n\u00e3o encontrado.\");\n    }\n}\n\nvoid loop() {\n    // N\u00e3o h\u00e1 c\u00f3digo no loop\n}\n</code></pre>"},{"location":"aulas/iot/modulos/modulo5.html#exercicio-2-ordenacao-descrescente","title":"Exerc\u00edcio 2: Ordena\u00e7\u00e3o Descrescente","text":"<ul> <li> <p>Tarefa: Modifique a fun\u00e7\u00e3o de ordena\u00e7\u00e3o Bubble Sort para ordenar o array em ordem decrescente.</p> </li> <li> <p>Exemplo de C\u00f3digo:</p> </li> </ul> <pre><code>void bubbleSortDesc(int arr[], int tamanho) {\n    for(int i = 0; i &lt; tamanho - 1; i++) {\n        for(int j = 0; j &lt; tamanho - i - 1; j++) {\n            if(arr[j] &lt; arr[j + 1]) {\n                // Troca arr[j] e arr[j + 1]\n                int temp = arr[j];\n                arr[j] = arr[j + 1];\n                arr[j + 1] = temp;\n            }\n        }\n    }\n}\n\nvoid setup() {\n    Serial.begin(9600);\n    Serial.println(\"Notas antes da ordena\u00e7\u00e3o decrescente:\");\n    imprimirNotas(notas, 5);\n\n    bubbleSortDesc(notas, 5);\n\n    Serial.println(\"Notas ap\u00f3s a ordena\u00e7\u00e3o decrescente:\");\n    imprimirNotas(notas, 5);\n}\n\nvoid loop() {\n    // N\u00e3o h\u00e1 c\u00f3digo no loop\n}\n</code></pre>"},{"location":"aulas/iot/modulos/modulo5.html#exercicio-3-funcao-para-encontrar-o-maior-e-menor-elemento","title":"Exerc\u00edcio 3: Fun\u00e7\u00e3o para Encontrar o Maior e Menor Elemento","text":"<ul> <li> <p>Tarefa: Crie duas fun\u00e7\u00f5es: uma que retorna o maior elemento em um array e outra que retorna o menor elemento.</p> </li> <li> <p>Exemplo de C\u00f3digo:</p> </li> </ul> <pre><code>int encontrarMaior(int arr[], int tamanho) {\n    int maior = arr[0];\n    for(int i = 1; i &lt; tamanho; i++) {\n        if(arr[i] &gt; maior) {\n            maior = arr[i];\n        }\n    }\n    return maior;\n}\n\nint encontrarMenor(int arr[], int tamanho) {\n    int menor = arr[0];\n    for(int i = 1; i &lt; tamanho; i++) {\n        if(arr[i] &lt; menor) {\n            menor = arr[i];\n        }\n    }\n    return menor;\n}\n\nvoid setup() {\n    Serial.begin(9600);\n    int maior = encontrarMaior(notas, 5);\n    int menor = encontrarMenor(notas, 5);\n\n    Serial.print(\"Maior nota: \");\n    Serial.println(maior);\n\n    Serial.print(\"Menor nota: \");\n    Serial.println(menor);\n}\n\nvoid loop() {\n    // N\u00e3o h\u00e1 c\u00f3digo no loop\n}\n</code></pre>"},{"location":"aulas/iot/modulos/modulo5.html#8-conceitos-importantes","title":"8. Conceitos Importantes","text":""},{"location":"aulas/iot/modulos/modulo5.html#81-vetores-vs-arrays","title":"8.1 Vetores vs. Arrays","text":"<p>Em C/C++, os termos \"vetor\" e \"array\" s\u00e3o frequentemente usados de forma intercambi\u00e1vel para se referirem a estruturas de dados que armazenam m\u00faltiplos elementos do mesmo tipo.</p>"},{"location":"aulas/iot/modulos/modulo5.html#82-limitacoes-dos-arrays-em-arduino","title":"8.2 Limita\u00e7\u00f5es dos Arrays em Arduino","text":"<ul> <li>Tamanho Fixos: Arrays em C/C++ t\u00eam tamanho fixo que deve ser conhecido em tempo de compila\u00e7\u00e3o.</li> <li>Uso de Mem\u00f3ria: Arrays grandes podem consumir significativamente a mem\u00f3ria dispon\u00edvel, especialmente em placas com recursos limitados como o Arduino Uno.</li> <li>Falta de Funcionalidades Avan\u00e7adas: Diferente de linguagens mais modernas, C/C++ n\u00e3o oferece m\u00e9todos avan\u00e7ados para manipula\u00e7\u00e3o de arrays (como inser\u00e7\u00e3o din\u00e2mica).</li> </ul>"},{"location":"aulas/iot/modulos/modulo5.html#83-alternativas-aos-arrays","title":"8.3 Alternativas aos Arrays","text":"<ul> <li>Estruturas (<code>struct</code>): Permitem agrupar diferentes tipos de dados.</li> <li>Listas Ligadas e Outras Estruturas de Dados Din\u00e2micas: Oferecem flexibilidade no gerenciamento de dados, mas s\u00e3o mais complexas para implementar em C/C++ no Arduino.</li> <li>Bibliotecas: Existem bibliotecas que facilitam o uso de arrays din\u00e2micos ou outros tipos de cole\u00e7\u00f5es de dados, mas seu uso deve ser cuidadoso devido \u00e0s limita\u00e7\u00f5es de mem\u00f3ria.</li> </ul>"},{"location":"aulas/iot/modulos/modulo5.html#84-dicas-para-trabalhar-com-arrays","title":"8.4 Dicas para Trabalhar com Arrays","text":"<ul> <li>Sempre Inicialize Arrays: Para evitar valores indeterminados.</li> <li>Evite Acessar \u00cdndices Fora dos Limites: Pode causar comportamentos inesperados ou erros de execu\u00e7\u00e3o.</li> <li>Utilize Constantes para Tamanhos: Facilita a manuten\u00e7\u00e3o do c\u00f3digo.</li> </ul>"},{"location":"aulas/iot/modulos/modulo6.html","title":"M\u00f3dulo 6: Strings e Opera\u00e7\u00f5es com Texto","text":"<p>Bem-vindo ao M\u00f3dulo 6 do curso \"Programa\u00e7\u00e3o em Arduino: Conceitos Fundamentais sem Hardware\". Neste m\u00f3dulo, voc\u00ea ir\u00e1 explorar o uso de strings e opera\u00e7\u00f5es com texto na linguagem de programa\u00e7\u00e3o Arduino (C/C++). Manipular strings \u00e9 essencial para lidar com entradas e sa\u00eddas de texto, especialmente ao interagir com o Monitor Serial.</p>"},{"location":"aulas/iot/modulos/modulo6.html#objetivos-do-modulo","title":"Objetivos do M\u00f3dulo","text":"<ul> <li>Compreender o conceito de strings em Arduino e como utiliz\u00e1-las.</li> <li>Aprender a declarar, inicializar e manipular strings.</li> <li>Trabalhar com fun\u00e7\u00f5es de manipula\u00e7\u00e3o de strings como <code>length()</code>, <code>concat()</code>, <code>substring()</code>, <code>indexOf()</code>, <code>replace()</code>, entre outras.</li> <li>Realizar opera\u00e7\u00f5es de compara\u00e7\u00e3o e busca em strings.</li> <li>Implementar fun\u00e7\u00f5es que utilizam strings como par\u00e2metros e retornos.</li> <li>Entender o gerenciamento de mem\u00f3ria ao trabalhar com strings.</li> <li>Resolver exerc\u00edcios pr\u00e1ticos para consolidar o conhecimento sobre strings e opera\u00e7\u00f5es com texto.</li> </ul>"},{"location":"aulas/iot/modulos/modulo6.html#1-introducao-as-strings","title":"1. Introdu\u00e7\u00e3o \u00e0s Strings","text":""},{"location":"aulas/iot/modulos/modulo6.html#11-o-que-sao-strings","title":"1.1 O que s\u00e3o Strings?","text":"<p>Em C/C++, uma string \u00e9 uma sequ\u00eancia de caracteres terminada por um caractere nulo (<code>'\\0'</code>). No Arduino, as strings podem ser manipuladas de duas formas principais:</p> <ul> <li>Strings em C: Usam arrays de caracteres (<code>char</code>).</li> <li>Classe <code>String</code>: Uma classe que encapsula strings e oferece m\u00e9todos para manipula\u00e7\u00e3o mais f\u00e1cil.</li> </ul>"},{"location":"aulas/iot/modulos/modulo6.html#12-diferencas-entre-strings-em-c-e-a-classe-string","title":"1.2 Diferen\u00e7as entre Strings em C e a Classe <code>String</code>","text":"<ul> <li>Strings em C:</li> <li>Mais eficientes em termos de mem\u00f3ria.</li> <li>Menos seguros, pois requerem cuidado com o gerenciamento de mem\u00f3ria.</li> <li> <p>Manipula\u00e7\u00e3o mais complexa.</p> </li> <li> <p>Classe <code>String</code>:</p> </li> <li>Mais f\u00e1cil de usar com m\u00e9todos integrados para manipula\u00e7\u00e3o.</li> <li>Menos eficiente em termos de mem\u00f3ria, podendo levar a fragmenta\u00e7\u00e3o.</li> <li>Conveniente para iniciantes.</li> </ul>"},{"location":"aulas/iot/modulos/modulo6.html#2-trabalhando-com-a-classe-string","title":"2. Trabalhando com a Classe <code>String</code>","text":""},{"location":"aulas/iot/modulos/modulo6.html#21-declaracao-e-inicializacao","title":"2.1 Declara\u00e7\u00e3o e Inicializa\u00e7\u00e3o","text":"<p>Declarando uma String:</p> <pre><code>String mensagem;\n</code></pre> <p>Inicializando uma String:</p> <pre><code>String mensagem = \"Ol\u00e1, Arduino!\";\n</code></pre>"},{"location":"aulas/iot/modulos/modulo6.html#22-concatenando-strings","title":"2.2 Concatenando Strings","text":"<p>Voc\u00ea pode concatenar strings usando o operador <code>+</code> ou o m\u00e9todo <code>concat()</code>.</p> <p>Usando o Operador <code>+</code>:</p> <pre><code>String saudacao = \"Ol\u00e1\";\nString nome = \"Maria\";\nString mensagem = saudacao + \", \" + nome + \"!\";\n</code></pre> <p>Usando o M\u00e9todo <code>concat()</code>:</p> <pre><code>String mensagem = \"Ol\u00e1\";\nmensagem.concat(\", Maria!\");\n</code></pre>"},{"location":"aulas/iot/modulos/modulo6.html#23-acessando-caracteres-individuais","title":"2.3 Acessando Caracteres Individuais","text":"<p>Voc\u00ea pode acessar caracteres individuais de uma string usando a nota\u00e7\u00e3o de colchetes <code>[]</code>.</p> <pre><code>String palavra = \"Arduino\";\nchar primeiraLetra = palavra[0]; // 'A'\nchar ultimaLetra = palavra[6];    // 'o'\n</code></pre>"},{"location":"aulas/iot/modulos/modulo6.html#24-metodos-comuns-da-classe-string","title":"2.4 M\u00e9todos Comuns da Classe <code>String</code>","text":"<ul> <li><code>length()</code>: Retorna o tamanho da string.</li> </ul> <pre><code>int tamanho = mensagem.length();\n</code></pre> <ul> <li><code>substring()</code>: Retorna uma substring de uma string.</li> </ul> <pre><code>String sub = mensagem.substring(0, 4); // \"Ol\u00e1,\"\n</code></pre> <ul> <li><code>indexOf()</code>: Retorna o \u00edndice da primeira ocorr\u00eancia de um caractere ou substring.</li> </ul> <pre><code>int pos = mensagem.indexOf(\"Maria\"); // 5\n</code></pre> <ul> <li><code>replace()</code>: Substitui todas as ocorr\u00eancias de uma substring por outra.</li> </ul> <pre><code>mensagem.replace(\"Maria\", \"Jo\u00e3o\"); // \"Ol\u00e1, Jo\u00e3o!\"\n</code></pre> <ul> <li><code>toLowerCase()</code> e <code>toUpperCase()</code>: Convertem a string para min\u00fasculas ou mai\u00fasculas.</li> </ul> <pre><code>mensagem.toLowerCase(); // \"ol\u00e1, jo\u00e3o!\"\nmensagem.toUpperCase(); // \"OL\u00c1, JO\u00c3O!\"\n</code></pre>"},{"location":"aulas/iot/modulos/modulo6.html#3-manipulacao-de-strings-com-arrays-de-caracteres","title":"3. Manipula\u00e7\u00e3o de Strings com Arrays de Caracteres","text":""},{"location":"aulas/iot/modulos/modulo6.html#31-declarando-e-inicializando-arrays-de-caracteres","title":"3.1 Declarando e Inicializando Arrays de Caracteres","text":"<pre><code>char mensagem[] = \"Ol\u00e1, Arduino!\";\n</code></pre>"},{"location":"aulas/iot/modulos/modulo6.html#32-funcoes-de-manipulacao-de-strings-em-c","title":"3.2 Fun\u00e7\u00f5es de Manipula\u00e7\u00e3o de Strings em C","text":"<ul> <li><code>strlen()</code>: Retorna o comprimento da string.</li> </ul> <pre><code>int tamanho = strlen(mensagem);\n</code></pre> <ul> <li><code>strcpy()</code>: Copia uma string para outra.</li> </ul> <pre><code>char copia[20];\nstrcpy(copia, mensagem);\n</code></pre> <ul> <li><code>strcat()</code>: Concatena duas strings.</li> </ul> <pre><code>char saudacao[20] = \"Bem-vindo \";\nstrcat(saudacao, \"ao Arduino!\");\n</code></pre> <ul> <li><code>strcmp()</code>: Compara duas strings.</li> </ul> <pre><code>if(strcmp(mensagem, copia) == 0) {\n    // Strings s\u00e3o iguais\n}\n</code></pre>"},{"location":"aulas/iot/modulos/modulo6.html#4-entrada-e-saida-de-strings-com-o-monitor-serial","title":"4. Entrada e Sa\u00edda de Strings com o Monitor Serial","text":""},{"location":"aulas/iot/modulos/modulo6.html#41-enviando-strings-para-o-monitor-serial","title":"4.1 Enviando Strings para o Monitor Serial","text":"<pre><code>void setup() {\n    Serial.begin(9600);\n    String mensagem = \"Ol\u00e1, Mundo!\";\n    Serial.println(mensagem);\n}\n\nvoid loop() {\n    // N\u00e3o h\u00e1 c\u00f3digo no loop\n}\n</code></pre>"},{"location":"aulas/iot/modulos/modulo6.html#42-recebendo-strings-do-monitor-serial","title":"4.2 Recebendo Strings do Monitor Serial","text":"<pre><code>String entrada = \"\";\n\nvoid setup() {\n    Serial.begin(9600);\n    Serial.println(\"Digite uma mensagem:\");\n}\n\nvoid loop() {\n    if(Serial.available() &gt; 0) {\n        entrada = Serial.readString();\n        Serial.print(\"Voc\u00ea digitou: \");\n        Serial.println(entrada);\n        Serial.println(\"Digite outra mensagem:\");\n    }\n}\n</code></pre> <p>Explica\u00e7\u00e3o:</p> <ul> <li>O programa solicita que o usu\u00e1rio digite uma mensagem.</li> <li>Usa <code>Serial.readString()</code> para ler a entrada do usu\u00e1rio.</li> <li>Imprime a mensagem recebida no Monitor Serial.</li> </ul>"},{"location":"aulas/iot/modulos/modulo6.html#5-funcoes-com-strings","title":"5. Fun\u00e7\u00f5es com Strings","text":""},{"location":"aulas/iot/modulos/modulo6.html#51-passando-strings-como-parametros","title":"5.1 Passando Strings como Par\u00e2metros","text":"<pre><code>void imprimirMensagem(String msg) {\n    Serial.println(msg);\n}\n\nvoid setup() {\n    Serial.begin(9600);\n    imprimirMensagem(\"Bem-vindo ao M\u00f3dulo 6!\");\n}\n\nvoid loop() {\n    // N\u00e3o h\u00e1 c\u00f3digo no loop\n}\n</code></pre>"},{"location":"aulas/iot/modulos/modulo6.html#52-funcoes-que-retornam-strings","title":"5.2 Fun\u00e7\u00f5es que Retornam Strings","text":"<pre><code>String obterSaudacao() {\n    return \"Ol\u00e1, estudante!\";\n}\n\nvoid setup() {\n    Serial.begin(9600);\n    String saudacao = obterSaudacao();\n    Serial.println(saudacao);\n}\n\nvoid loop() {\n    // N\u00e3o h\u00e1 c\u00f3digo no loop\n}\n</code></pre> <p>Explica\u00e7\u00e3o:</p> <ul> <li>A fun\u00e7\u00e3o <code>obterSaudacao</code> retorna uma string.</li> <li>A string retornada \u00e9 armazenada na vari\u00e1vel <code>saudacao</code> e impressa no Monitor Serial.</li> </ul>"},{"location":"aulas/iot/modulos/modulo6.html#6-gerenciamento-de-memoria-com-strings","title":"6. Gerenciamento de Mem\u00f3ria com Strings","text":""},{"location":"aulas/iot/modulos/modulo6.html#61-uso-de-strings-vs-arrays-de-caracteres","title":"6.1 Uso de Strings vs. Arrays de Caracteres","text":"<ul> <li>Strings da Classe <code>String</code>:</li> <li>Mais f\u00e1ceis de usar.</li> <li> <p>Podem causar fragmenta\u00e7\u00e3o de mem\u00f3ria em sistemas com recursos limitados.</p> </li> <li> <p>Arrays de Caracteres:</p> </li> <li>Mais eficientes em termos de mem\u00f3ria.</li> <li>Requerem mais cuidado na manipula\u00e7\u00e3o.</li> </ul>"},{"location":"aulas/iot/modulos/modulo6.html#62-evitando-fragmentacao-de-memoria","title":"6.2 Evitando Fragmenta\u00e7\u00e3o de Mem\u00f3ria","text":"<ul> <li>Evitar Muitas Opera\u00e7\u00f5es de Concatena\u00e7\u00e3o:</li> <li> <p>Opera\u00e7\u00f5es frequentes de <code>concat</code> podem fragmentar a mem\u00f3ria.</p> </li> <li> <p>Usar Strings de Forma Constante:</p> </li> <li>Declarar strings como constantes (<code>const char*</code>) sempre que poss\u00edvel.</li> </ul> <pre><code>const char* mensagem = \"Bem-vindo!\";\n</code></pre> <ul> <li>Gerenciar o Tamanho dos Arrays:</li> <li>Certifique-se de que os arrays de caracteres sejam grandes o suficiente para armazenar as strings e o caractere nulo.</li> </ul> <pre><code>char mensagem[20] = \"Este \u00e9 um exemplo seguro.\";\n</code></pre>"},{"location":"aulas/iot/modulos/modulo6.html#7-exemplos-praticos","title":"7. Exemplos Pr\u00e1ticos","text":""},{"location":"aulas/iot/modulos/modulo6.html#71-criando-um-sistema-de-mensagens","title":"7.1 Criando um Sistema de Mensagens","text":"<pre><code>String mensagens[] = {\"Mensagem 1\", \"Mensagem 2\", \"Mensagem 3\"};\nint totalMensagens = 3;\n\nvoid setup() {\n    Serial.begin(9600);\n    for(int i = 0; i &lt; totalMensagens; i++) {\n        Serial.println(mensagens[i]);\n    }\n}\n\nvoid loop() {\n    // N\u00e3o h\u00e1 c\u00f3digo no loop\n}\n</code></pre> <p>Explica\u00e7\u00e3o:</p> <ul> <li>Armazena m\u00faltiplas mensagens em um array de strings.</li> <li>Imprime cada mensagem no Monitor Serial usando um la\u00e7o <code>for</code>.</li> </ul>"},{"location":"aulas/iot/modulos/modulo6.html#72-manipulando-nomes-de-usuarios","title":"7.2 Manipulando Nomes de Usu\u00e1rios","text":"<pre><code>String nome = \"\";\nString saudacao = \"\";\n\nvoid setup() {\n    Serial.begin(9600);\n    Serial.println(\"Digite seu nome:\");\n}\n\nvoid loop() {\n    if(Serial.available() &gt; 0) {\n        nome = Serial.readString();\n        saudacao = \"Ol\u00e1, \" + nome + \"!\";\n        Serial.println(saudacao);\n        Serial.println(\"Digite seu nome novamente ou reinicie o Arduino para sair.\");\n    }\n}\n</code></pre> <p>Explica\u00e7\u00e3o:</p> <ul> <li>Recebe o nome do usu\u00e1rio via Monitor Serial.</li> <li>Concatena a sauda\u00e7\u00e3o com o nome fornecido.</li> <li>Imprime a sauda\u00e7\u00e3o personalizada.</li> </ul>"},{"location":"aulas/iot/modulos/modulo6.html#73-processando-dados-de-sensor-com-strings","title":"7.3 Processando Dados de Sensor com Strings","text":"<pre><code>float temperatura = 23.5;\nfloat umidade = 60.0;\n\nvoid setup() {\n    Serial.begin(9600);\n\n    String dados = \"Temperatura: \" + String(temperatura) + \"\u00b0C, Umidade: \" + String(umidade) + \"%\";\n    Serial.println(dados);\n}\n\nvoid loop() {\n    // N\u00e3o h\u00e1 c\u00f3digo no loop\n}\n</code></pre> <p>Explica\u00e7\u00e3o:</p> <ul> <li>Simula a leitura de dados de sensores.</li> <li>Concatena os valores em uma string formatada.</li> <li>Imprime os dados no Monitor Serial.</li> </ul>"},{"location":"aulas/iot/modulos/modulo6.html#8-exercicios-praticos","title":"8. Exerc\u00edcios Pr\u00e1ticos","text":""},{"location":"aulas/iot/modulos/modulo6.html#exercicio-1-conversor-de-temperatura","title":"Exerc\u00edcio 1: Conversor de Temperatura","text":"<ul> <li> <p>Tarefa: Crie um programa que recebe uma temperatura em Celsius do usu\u00e1rio e converte para Fahrenheit, exibindo o resultado no Monitor Serial.</p> </li> <li> <p>Exemplo de C\u00f3digo:</p> </li> </ul> <pre><code>float celsius = 0.0;\nfloat fahrenheit = 0.0;\n\nvoid setup() {\n    Serial.begin(9600);\n    Serial.println(\"Digite a temperatura em Celsius:\");\n}\n\nvoid loop() {\n    if(Serial.available() &gt; 0) {\n        celsius = Serial.parseFloat();\n        fahrenheit = (celsius * 9.0 / 5.0) + 32.0;\n        Serial.print(celsius);\n        Serial.print(\"\u00b0C \u00e9 igual a \");\n        Serial.print(fahrenheit);\n        Serial.println(\"\u00b0F.\");\n        Serial.println(\"Digite outra temperatura ou reinicie o Arduino para sair.\");\n    }\n}\n</code></pre>"},{"location":"aulas/iot/modulos/modulo6.html#exercicio-2-verificacao-de-palindromo","title":"Exerc\u00edcio 2: Verifica\u00e7\u00e3o de Pal\u00edndromo","text":"<ul> <li> <p>Tarefa: Desenvolva um programa que recebe uma palavra do usu\u00e1rio e verifica se \u00e9 um pal\u00edndromo (mesmo de tr\u00e1s para frente).</p> </li> <li> <p>Exemplo de C\u00f3digo:</p> </li> </ul> <pre><code>String palavra = \"\";\nbool ehPalindromo = true;\n\nbool verificarPalindromo(String str) {\n    int inicio = 0;\n    int fim = str.length() - 1;\n\n    while(inicio &lt; fim) {\n        if(tolower(str[inicio]) != tolower(str[fim])) {\n            return false;\n        }\n        inicio++;\n        fim--;\n    }\n    return true;\n}\n\nvoid setup() {\n    Serial.begin(9600);\n    Serial.println(\"Digite uma palavra para verificar se \u00e9 um pal\u00edndromo:\");\n}\n\nvoid loop() {\n    if(Serial.available() &gt; 0) {\n        palavra = Serial.readString();\n        ehPalindromo = verificarPalindromo(palavra);\n\n        if(ehPalindromo) {\n            Serial.print(palavra);\n            Serial.println(\" \u00e9 um pal\u00edndromo.\");\n        } else {\n            Serial.print(palavra);\n            Serial.println(\" n\u00e3o \u00e9 um pal\u00edndromo.\");\n        }\n\n        Serial.println(\"Digite outra palavra ou reinicie o Arduino para sair.\");\n    }\n}\n</code></pre>"},{"location":"aulas/iot/modulos/modulo6.html#exercicio-3-contador-de-vogais","title":"Exerc\u00edcio 3: Contador de Vogais","text":"<ul> <li> <p>Tarefa: Escreva um programa que recebe uma frase do usu\u00e1rio e conta o n\u00famero de vogais presentes nela.</p> </li> <li> <p>Exemplo de C\u00f3digo:</p> </li> </ul> <pre><code>String frase = \"\";\nint contadorVogais = 0;\n\nint contarVogais(String str) {\n    int count = 0;\n    for(int i = 0; i &lt; str.length(); i++) {\n        char c = tolower(str[i]);\n        if(c == 'a' || c == 'e' || c == 'i' || c == 'o' || c == 'u') {\n            count++;\n        }\n    }\n    return count;\n}\n\nvoid setup() {\n    Serial.begin(9600);\n    Serial.println(\"Digite uma frase para contar as vogais:\");\n}\n\nvoid loop() {\n    if(Serial.available() &gt; 0) {\n        frase = Serial.readString();\n        contadorVogais = contarVogais(frase);\n        Serial.print(\"N\u00famero de vogais: \");\n        Serial.println(contadorVogais);\n        Serial.println(\"Digite outra frase ou reinicie o Arduino para sair.\");\n    }\n}\n</code></pre>"},{"location":"aulas/iot/modulos/modulo6.html#9-conceitos-importantes","title":"9. Conceitos Importantes","text":""},{"location":"aulas/iot/modulos/modulo6.html#91-vetores-vs-arrays","title":"9.1 Vetores vs. Arrays","text":"<p>Em C/C++, os termos \"vetor\" e \"array\" s\u00e3o frequentemente usados de forma intercambi\u00e1vel para se referirem a estruturas de dados que armazenam m\u00faltiplos elementos do mesmo tipo.</p>"},{"location":"aulas/iot/modulos/modulo6.html#92-operacoes-com-strings","title":"9.2 Opera\u00e7\u00f5es com Strings","text":"<ul> <li>Concatena\u00e7\u00e3o:</li> <li> <p>Combine duas ou mais strings em uma \u00fanica string.</p> </li> <li> <p>Compara\u00e7\u00e3o:</p> </li> <li> <p>Verifique se duas strings s\u00e3o iguais ou diferentes.</p> </li> <li> <p>Busca:</p> </li> <li> <p>Encontre a posi\u00e7\u00e3o de uma substring ou caractere dentro de uma string.</p> </li> <li> <p>Substitui\u00e7\u00e3o:</p> </li> <li>Substitua partes de uma string por outras strings.</li> </ul>"},{"location":"aulas/iot/modulos/modulo6.html#93-gerenciamento-de-memoria-com-strings","title":"9.3 Gerenciamento de Mem\u00f3ria com Strings","text":"<ul> <li>Uso de <code>const char*</code>: Para strings que n\u00e3o ser\u00e3o modificadas, use ponteiros para constantes de caracteres.</li> </ul> <pre><code>const char* saudacao = \"Bem-vindo ao Arduino!\";\n</code></pre> <ul> <li>Evitar Repeti\u00e7\u00e3o de Opera\u00e7\u00f5es de Concatena\u00e7\u00e3o: Minimize o uso de opera\u00e7\u00f5es que alteram a string constantemente para reduzir a fragmenta\u00e7\u00e3o de mem\u00f3ria.</li> </ul> <pre><code>char mensagem[50];\nstrcpy(mensagem, \"Este \u00e9 um exemplo seguro.\");\n</code></pre> <ul> <li>Gerenciar o Tamanho dos Arrays: Certifique-se de que os arrays de caracteres s\u00e3o suficientemente grandes para armazenar as strings e o caractere nulo.</li> </ul> <pre><code>char mensagem[50] = \"Este \u00e9 um exemplo seguro.\";\n</code></pre>"},{"location":"aulas/iot/modulos/modulo6.html#94-boas-praticas-com-strings","title":"9.4 Boas Pr\u00e1ticas com Strings","text":"<ul> <li> <p>Evitar Uso Excessivo da Classe <code>String</code>: Em sistemas com mem\u00f3ria limitada, prefira arrays de caracteres para evitar fragmenta\u00e7\u00e3o.</p> </li> <li> <p>Sempre Verificar o Tamanho dos Arrays: Evite overflow garantindo que os arrays s\u00e3o grandes o suficiente para armazenar as strings e o caractere nulo.</p> </li> </ul> <pre><code>char mensagem[50];\nstrcpy(mensagem, \"Este \u00e9 um exemplo seguro.\");\n</code></pre> <ul> <li>Usar Fun\u00e7\u00f5es de Manipula\u00e7\u00e3o de Strings com Cuidado: Certifique-se de que as fun\u00e7\u00f5es utilizadas n\u00e3o ultrapassem os limites dos arrays.</li> </ul>"},{"location":"aulas/iot/modulos/modulo7.html","title":"M\u00f3dulo 7: Ponteiros e Refer\u00eancias","text":"<p>Bem-vindo ao M\u00f3dulo 7 do curso \"Programa\u00e7\u00e3o em Arduino: Conceitos Fundamentais sem Hardware\". Neste m\u00f3dulo, voc\u00ea ir\u00e1 explorar o uso de ponteiros e refer\u00eancias na linguagem de programa\u00e7\u00e3o Arduino (C/C++). Ponteiros s\u00e3o ferramentas poderosas que permitem o acesso direto \u00e0 mem\u00f3ria e a manipula\u00e7\u00e3o eficiente de dados, enquanto refer\u00eancias oferecem uma maneira segura e conveniente de acessar vari\u00e1veis.</p>"},{"location":"aulas/iot/modulos/modulo7.html#objetivos-do-modulo","title":"Objetivos do M\u00f3dulo","text":"<ul> <li>Compreender o conceito de ponteiros e refer\u00eancias e sua import\u00e2ncia na programa\u00e7\u00e3o.</li> <li>Aprender a declarar, inicializar e utilizar ponteiros.</li> <li>Entender a aritm\u00e9tica de ponteiros e como navegar por arrays utilizando ponteiros.</li> <li>Trabalhar com refer\u00eancias e diferenciar entre ponteiros e refer\u00eancias.</li> <li>Utilizar ponteiros em fun\u00e7\u00f5es para manipula\u00e7\u00e3o eficiente de dados.</li> <li>Implementar aloca\u00e7\u00e3o din\u00e2mica de mem\u00f3ria com ponteiros.</li> <li>Resolver exerc\u00edcios pr\u00e1ticos para consolidar o conhecimento sobre ponteiros e refer\u00eancias.</li> </ul>"},{"location":"aulas/iot/modulos/modulo7.html#1-introducao-a-ponteiros-e-referencias","title":"1. Introdu\u00e7\u00e3o a Ponteiros e Refer\u00eancias","text":""},{"location":"aulas/iot/modulos/modulo7.html#11-o-que-sao-ponteiros","title":"1.1 O que s\u00e3o Ponteiros?","text":"<p>Um ponteiro \u00e9 uma vari\u00e1vel que armazena o endere\u00e7o de mem\u00f3ria de outra vari\u00e1vel. Eles s\u00e3o fundamentais para a manipula\u00e7\u00e3o eficiente de dados, permitindo o acesso direto e a modifica\u00e7\u00e3o de vari\u00e1veis em diferentes partes do programa.</p>"},{"location":"aulas/iot/modulos/modulo7.html#12-o-que-sao-referencias","title":"1.2 O que s\u00e3o Refer\u00eancias?","text":"<p>Uma refer\u00eancia \u00e9 um alias para outra vari\u00e1vel. Diferentemente dos ponteiros, refer\u00eancias n\u00e3o podem ser alteradas para apontar para diferentes vari\u00e1veis ap\u00f3s sua inicializa\u00e7\u00e3o e n\u00e3o envolvem opera\u00e7\u00f5es de aritm\u00e9tica de ponteiros.</p>"},{"location":"aulas/iot/modulos/modulo7.html#13-diferencas-entre-ponteiros-e-referencias","title":"1.3 Diferen\u00e7as entre Ponteiros e Refer\u00eancias","text":"<ul> <li>Ponteiros:</li> <li>Podem ser reatribu\u00eddos para apontar para diferentes vari\u00e1veis.</li> <li>Suportam aritm\u00e9tica de ponteiros.</li> <li> <p>Podem ter um valor nulo (<code>NULL</code>).</p> </li> <li> <p>Refer\u00eancias:</p> </li> <li>Devem ser inicializadas no momento da declara\u00e7\u00e3o.</li> <li>N\u00e3o suportam aritm\u00e9tica de ponteiros.</li> <li>N\u00e3o podem ser nulas.</li> </ul>"},{"location":"aulas/iot/modulos/modulo7.html#2-trabalhando-com-ponteiros","title":"2. Trabalhando com Ponteiros","text":""},{"location":"aulas/iot/modulos/modulo7.html#21-declaracao-e-inicializacao-de-ponteiros","title":"2.1 Declara\u00e7\u00e3o e Inicializa\u00e7\u00e3o de Ponteiros","text":"<p>Sintaxe:</p> <pre><code>tipo *nome_ponteiro;\n</code></pre> <p>Exemplo:</p> <pre><code>int *ptr;\nint valor = 10;\nptr = &amp;valor; // ptr aponta para o endere\u00e7o de mem\u00f3ria de 'valor'\n</code></pre>"},{"location":"aulas/iot/modulos/modulo7.html#22-acessando-o-valor-apontado-por-um-ponteiro","title":"2.2 Acessando o Valor Apontado por um Ponteiro","text":"<p>Operador de Desreferencia\u00e7\u00e3o (<code>*</code>):</p> <pre><code>int numero = 20;\nint *ponteiro = &amp;numero;\nSerial.println(*ponteiro); // Imprime 20\n</code></pre> <p>Explica\u00e7\u00e3o:</p> <ul> <li><code>*ponteiro</code> acessa o valor armazenado no endere\u00e7o de mem\u00f3ria para o qual <code>ponteiro</code> aponta.</li> </ul>"},{"location":"aulas/iot/modulos/modulo7.html#23-aritmetica-de-ponteiros","title":"2.3 Aritm\u00e9tica de Ponteiros","text":"<p>Ponteiros podem ser incrementados ou decrementados para navegar por arrays ou estruturas de dados.</p> <p>Exemplo:</p> <pre><code>int arr[3] = {10, 20, 30};\nint *ptr = arr; // Aponta para arr[0]\n\nSerial.println(*ptr); // Imprime 10\nptr++; // Agora aponta para arr[1]\nSerial.println(*ptr); // Imprime 20\nptr++; // Agora aponta para arr[2]\nSerial.println(*ptr); // Imprime 30\n</code></pre> <p>Explica\u00e7\u00e3o:</p> <ul> <li>Incrementar um ponteiro (<code>ptr++</code>) faz com que ele aponte para o pr\u00f3ximo elemento do array.</li> </ul>"},{"location":"aulas/iot/modulos/modulo7.html#24-ponteiros-para-tipos-de-dados-diferentes","title":"2.4 Ponteiros para Tipos de Dados Diferentes","text":"<p>Ponteiros podem apontar para qualquer tipo de dado, incluindo estruturas e outras fun\u00e7\u00f5es.</p> <p>Exemplo com Struct:</p> <pre><code>struct Sensor {\n    int id;\n    float valor;\n};\n\nSensor sensor1 = {1, 23.5};\nSensor *ptrSensor = &amp;sensor1;\n\nSerial.println(ptrSensor-&gt;id);    // Imprime 1\nSerial.println(ptrSensor-&gt;valor); // Imprime 23.5\n</code></pre> <p>Explica\u00e7\u00e3o:</p> <ul> <li>Utiliza-se o operador <code>-&gt;</code> para acessar membros de uma estrutura atrav\u00e9s de um ponteiro.</li> </ul>"},{"location":"aulas/iot/modulos/modulo7.html#3-trabalhando-com-referencias","title":"3. Trabalhando com Refer\u00eancias","text":""},{"location":"aulas/iot/modulos/modulo7.html#31-declaracao-e-inicializacao-de-referencias","title":"3.1 Declara\u00e7\u00e3o e Inicializa\u00e7\u00e3o de Refer\u00eancias","text":"<p>Sintaxe:</p> <pre><code>tipo &amp;nome_referencia = variavel;\n</code></pre> <p>Exemplo:</p> <pre><code>int numero = 50;\nint &amp;ref = numero; // 'ref' \u00e9 uma refer\u00eancia para 'numero'\n\nSerial.println(ref); // Imprime 50\nref = 100;\nSerial.println(numero); // Imprime 100\n</code></pre> <p>Explica\u00e7\u00e3o:</p> <ul> <li>Alterar <code>ref</code> tamb\u00e9m altera <code>numero</code>, j\u00e1 que <code>ref</code> \u00e9 apenas um alias para <code>numero</code>.</li> </ul>"},{"location":"aulas/iot/modulos/modulo7.html#32-passando-referencias-para-funcoes","title":"3.2 Passando Refer\u00eancias para Fun\u00e7\u00f5es","text":"<p>Passar vari\u00e1veis por refer\u00eancia permite que a fun\u00e7\u00e3o modifique o valor original da vari\u00e1vel.</p> <p>Exemplo:</p> <pre><code>void incrementar(int &amp;n) {\n    n += 1;\n}\n\nvoid setup() {\n    Serial.begin(9600);\n    int valor = 5;\n    Serial.println(valor); // Imprime 5\n    incrementar(valor);\n    Serial.println(valor); // Imprime 6\n}\n\nvoid loop() {\n    // N\u00e3o h\u00e1 c\u00f3digo no loop\n}\n</code></pre> <p>Explica\u00e7\u00e3o:</p> <ul> <li>A fun\u00e7\u00e3o <code>incrementar</code> recebe <code>n</code> por refer\u00eancia, permitindo modificar o valor original de <code>valor</code>.</li> </ul>"},{"location":"aulas/iot/modulos/modulo7.html#4-ponteiros-em-funcoes","title":"4. Ponteiros em Fun\u00e7\u00f5es","text":""},{"location":"aulas/iot/modulos/modulo7.html#41-passando-ponteiros-para-funcoes","title":"4.1 Passando Ponteiros para Fun\u00e7\u00f5es","text":"<p>Ponteiros podem ser passados para fun\u00e7\u00f5es para permitir a manipula\u00e7\u00e3o direta das vari\u00e1veis originais.</p> <p>Exemplo:</p> <pre><code>void trocar(int *a, int *b) {\n    int temp = *a;\n    *a = *b;\n    *b = temp;\n}\n\nvoid setup() {\n    Serial.begin(9600);\n    int x = 10;\n    int y = 20;\n    Serial.print(\"Antes: x = \");\n    Serial.print(x);\n    Serial.print(\", y = \");\n    Serial.println(y);\n\n    trocar(&amp;x, &amp;y);\n\n    Serial.print(\"Depois: x = \");\n    Serial.print(x);\n    Serial.print(\", y = \");\n    Serial.println(y);\n}\n\nvoid loop() {\n    // N\u00e3o h\u00e1 c\u00f3digo no loop\n}\n</code></pre> <p>Explica\u00e7\u00e3o:</p> <ul> <li>A fun\u00e7\u00e3o <code>trocar</code> utiliza ponteiros para trocar os valores de <code>x</code> e <code>y</code>.</li> </ul>"},{"location":"aulas/iot/modulos/modulo7.html#42-retornando-ponteiros-de-funcoes","title":"4.2 Retornando Ponteiros de Fun\u00e7\u00f5es","text":"<p>Fun\u00e7\u00f5es podem retornar ponteiros para permitir o acesso a vari\u00e1veis alocadas dinamicamente ou outras estruturas de dados.</p> <p>Exemplo:</p> <pre><code>int* criarArray(int tamanho) {\n    int *arr = new int[tamanho];\n    for(int i = 0; i &lt; tamanho; i++) {\n        arr[i] = i * 2;\n    }\n    return arr;\n}\n\nvoid setup() {\n    Serial.begin(9600);\n    int *meuArray = criarArray(5);\n    for(int i = 0; i &lt; 5; i++) {\n        Serial.println(meuArray[i]);\n    }\n    delete[] meuArray; // Libera a mem\u00f3ria alocada\n}\n\nvoid loop() {\n    // N\u00e3o h\u00e1 c\u00f3digo no loop\n}\n</code></pre> <p>Explica\u00e7\u00e3o:</p> <ul> <li>A fun\u00e7\u00e3o <code>criarArray</code> aloca dinamicamente um array e retorna o ponteiro para ele.</li> <li>\u00c9 importante liberar a mem\u00f3ria alocada com <code>delete[]</code> para evitar vazamentos de mem\u00f3ria.</li> </ul>"},{"location":"aulas/iot/modulos/modulo7.html#5-alocacao-dinamica-de-memoria","title":"5. Aloca\u00e7\u00e3o Din\u00e2mica de Mem\u00f3ria","text":""},{"location":"aulas/iot/modulos/modulo7.html#51-usando-new-e-delete","title":"5.1 Usando <code>new</code> e <code>delete</code>","text":"<p>Ponteiros permitem a aloca\u00e7\u00e3o din\u00e2mica de mem\u00f3ria, onde o tamanho da mem\u00f3ria necess\u00e1ria n\u00e3o \u00e9 conhecido em tempo de compila\u00e7\u00e3o.</p> <p>Exemplo:</p> <pre><code>int *alocarInteiro() {\n    int *ptr = new int;\n    *ptr = 100;\n    return ptr;\n}\n\nvoid setup() {\n    Serial.begin(9600);\n    int *meuInt = alocarInteiro();\n    Serial.println(*meuInt); // Imprime 100\n    delete meuInt; // Libera a mem\u00f3ria alocada\n}\n\nvoid loop() {\n    // N\u00e3o h\u00e1 c\u00f3digo no loop\n}\n</code></pre> <p>Explica\u00e7\u00e3o:</p> <ul> <li>A fun\u00e7\u00e3o <code>alocarInteiro</code> aloca mem\u00f3ria para um inteiro, atribui o valor 100 e retorna o ponteiro.</li> <li>A mem\u00f3ria \u00e9 liberada com <code>delete</code> ap\u00f3s o uso.</li> </ul>"},{"location":"aulas/iot/modulos/modulo7.html#52-alocacao-de-arrays-dinamicos","title":"5.2 Aloca\u00e7\u00e3o de Arrays Din\u00e2micos","text":"<pre><code>int* alocarArray(int tamanho) {\n    int *arr = new int[tamanho];\n    for(int i = 0; i &lt; tamanho; i++) {\n        arr[i] = i + 1;\n    }\n    return arr;\n}\n\nvoid setup() {\n    Serial.begin(9600);\n    int *meuArray = alocarArray(5);\n    for(int i = 0; i &lt; 5; i++) {\n        Serial.println(meuArray[i]);\n    }\n    delete[] meuArray; // Libera a mem\u00f3ria alocada\n}\n\nvoid loop() {\n    // N\u00e3o h\u00e1 c\u00f3digo no loop\n}\n</code></pre> <p>Explica\u00e7\u00e3o:</p> <ul> <li>A fun\u00e7\u00e3o <code>alocarArray</code> aloca dinamicamente um array de inteiros e inicializa os valores.</li> <li>A mem\u00f3ria \u00e9 liberada com <code>delete[]</code> ap\u00f3s o uso.</li> </ul>"},{"location":"aulas/iot/modulos/modulo7.html#6-ponteiros-para-ponteiros","title":"6. Ponteiros para Ponteiros","text":""},{"location":"aulas/iot/modulos/modulo7.html#61-declaracao-e-uso","title":"6.1 Declara\u00e7\u00e3o e Uso","text":"<p>Ponteiros para ponteiros s\u00e3o usados para manipular ponteiros de forma indireta, permitindo m\u00faltiplos n\u00edveis de indire\u00e7\u00e3o.</p> <p>Exemplo:</p> <pre><code>int valor = 50;\nint *ptr = &amp;valor;\nint **ptrPtr = &amp;ptr;\n\nSerial.println(*ptr);    // Imprime 50\nSerial.println(**ptrPtr); // Imprime 50\n</code></pre> <p>Explica\u00e7\u00e3o:</p> <ul> <li><code>ptr</code> \u00e9 um ponteiro para <code>valor</code>.</li> <li><code>ptrPtr</code> \u00e9 um ponteiro para <code>ptr</code>, permitindo acesso indireto ao valor original.</li> </ul>"},{"location":"aulas/iot/modulos/modulo7.html#62-aplicacoes-praticas","title":"6.2 Aplica\u00e7\u00f5es Pr\u00e1ticas","text":"<p>Ponteiros para ponteiros s\u00e3o \u00fateis em situa\u00e7\u00f5es como:</p> <ul> <li>Manipula\u00e7\u00e3o de arrays de ponteiros.</li> <li>Passagem de ponteiros para fun\u00e7\u00f5es que precisam modificar o ponteiro original.</li> <li>Implementa\u00e7\u00e3o de estruturas de dados complexas como listas ligadas.</li> </ul> <p>Exemplo:</p> <pre><code>void modificarPonteiro(int **pptr) {\n    static int novoValor = 200;\n    *pptr = &amp;novoValor;\n}\n\nvoid setup() {\n    Serial.begin(9600);\n    int valor = 100;\n    int *ptr = &amp;valor;\n\n    Serial.println(*ptr); // Imprime 100\n\n    modificarPonteiro(&amp;ptr);\n\n    Serial.println(*ptr); // Imprime 200\n}\n\nvoid loop() {\n    // N\u00e3o h\u00e1 c\u00f3digo no loop\n}\n</code></pre> <p>Explica\u00e7\u00e3o:</p> <ul> <li>A fun\u00e7\u00e3o <code>modificarPonteiro</code> altera o ponteiro original para apontar para <code>novoValor</code>.</li> </ul>"},{"location":"aulas/iot/modulos/modulo7.html#7-exemplos-praticos","title":"7. Exemplos Pr\u00e1ticos","text":""},{"location":"aulas/iot/modulos/modulo7.html#71-manipulando-arrays-com-ponteiros","title":"7.1 Manipulando Arrays com Ponteiros","text":"<pre><code>void imprimirArray(int *arr, int tamanho) {\n    for(int i = 0; i &lt; tamanho; i++) {\n        Serial.println(*(arr + i));\n    }\n}\n\nvoid setup() {\n    Serial.begin(9600);\n    int arr[5] = {10, 20, 30, 40, 50};\n    imprimirArray(arr, 5);\n}\n\nvoid loop() {\n    // N\u00e3o h\u00e1 c\u00f3digo no loop\n}\n</code></pre> <p>Explica\u00e7\u00e3o:</p> <ul> <li>A fun\u00e7\u00e3o <code>imprimirArray</code> usa aritm\u00e9tica de ponteiros para acessar e imprimir os elementos do array.</li> </ul>"},{"location":"aulas/iot/modulos/modulo7.html#72-troca-de-valores-usando-ponteiros","title":"7.2 Troca de Valores Usando Ponteiros","text":"<pre><code>void trocarValores(int *a, int *b) {\n    int temp = *a;\n    *a = *b;\n    *b = temp;\n}\n\nvoid setup() {\n    Serial.begin(9600);\n    int x = 15;\n    int y = 25;\n\n    Serial.print(\"Antes da troca: x = \");\n    Serial.print(x);\n    Serial.print(\", y = \");\n    Serial.println(y);\n\n    trocarValores(&amp;x, &amp;y);\n\n    Serial.print(\"Depois da troca: x = \");\n    Serial.print(x);\n    Serial.print(\", y = \");\n    Serial.println(y);\n}\n\nvoid loop() {\n    // N\u00e3o h\u00e1 c\u00f3digo no loop\n}\n</code></pre> <p>Explica\u00e7\u00e3o:</p> <ul> <li>A fun\u00e7\u00e3o <code>trocarValores</code> troca os valores de <code>x</code> e <code>y</code> usando ponteiros.</li> </ul>"},{"location":"aulas/iot/modulos/modulo7.html#73-alocacao-dinamica-e-liberacao-de-memoria","title":"7.3 Aloca\u00e7\u00e3o Din\u00e2mica e Libera\u00e7\u00e3o de Mem\u00f3ria","text":"<pre><code>int* criarArrayDinamico(int tamanho) {\n    int *arr = new int[tamanho];\n    for(int i = 0; i &lt; tamanho; i++) {\n        arr[i] = i * 10;\n    }\n    return arr;\n}\n\nvoid setup() {\n    Serial.begin(9600);\n    int *meuArray = criarArrayDinamico(4);\n\n    for(int i = 0; i &lt; 4; i++) {\n        Serial.println(meuArray[i]);\n    }\n\n    delete[] meuArray; // Libera a mem\u00f3ria alocada\n}\n\nvoid loop() {\n    // N\u00e3o h\u00e1 c\u00f3digo no loop\n}\n</code></pre> <p>Explica\u00e7\u00e3o:</p> <ul> <li>A fun\u00e7\u00e3o <code>criarArrayDinamico</code> aloca dinamicamente um array e inicializa seus valores.</li> <li>A mem\u00f3ria \u00e9 liberada ap\u00f3s o uso para evitar vazamentos.</li> </ul>"},{"location":"aulas/iot/modulos/modulo7.html#8-exercicios-praticos","title":"8. Exerc\u00edcios Pr\u00e1ticos","text":""},{"location":"aulas/iot/modulos/modulo7.html#exercicio-1-funcao-para-somar-elementos-de-um-array-usando-ponteiros","title":"Exerc\u00edcio 1: Fun\u00e7\u00e3o para Somar Elementos de um Array Usando Ponteiros","text":"<ul> <li> <p>Tarefa: Crie uma fun\u00e7\u00e3o que recebe um array de inteiros e seu tamanho usando ponteiros, e retorna a soma de todos os elementos.</p> </li> <li> <p>Exemplo de C\u00f3digo:</p> </li> </ul> <pre><code>int somarArray(int *arr, int tamanho) {\n    int soma = 0;\n    for(int i = 0; i &lt; tamanho; i++) {\n        soma += *(arr + i);\n    }\n    return soma;\n}\n\nvoid setup() {\n    Serial.begin(9600);\n    int arr[5] = {5, 10, 15, 20, 25};\n    int resultado = somarArray(arr, 5);\n    Serial.print(\"Soma dos elementos: \");\n    Serial.println(resultado); // Imprime 75\n}\n\nvoid loop() {\n    // N\u00e3o h\u00e1 c\u00f3digo no loop\n}\n</code></pre>"},{"location":"aulas/iot/modulos/modulo7.html#exercicio-2-implementar-uma-funcao-que-troca-dois-valores-usando-referencias","title":"Exerc\u00edcio 2: Implementar uma Fun\u00e7\u00e3o que Troca Dois Valores Usando Refer\u00eancias","text":"<ul> <li> <p>Tarefa: Escreva uma fun\u00e7\u00e3o que recebe duas vari\u00e1veis inteiras por refer\u00eancia e troca seus valores.</p> </li> <li> <p>Exemplo de C\u00f3digo:</p> </li> </ul> <pre><code>void trocar(int &amp;a, int &amp;b) {\n    int temp = a;\n    a = b;\n    b = temp;\n}\n\nvoid setup() {\n    Serial.begin(9600);\n    int x = 50;\n    int y = 100;\n\n    Serial.print(\"Antes da troca: x = \");\n    Serial.print(x);\n    Serial.print(\", y = \");\n    Serial.println(y);\n\n    trocar(x, y);\n\n    Serial.print(\"Depois da troca: x = \");\n    Serial.print(x);\n    Serial.print(\", y = \");\n    Serial.println(y);\n}\n\nvoid loop() {\n    // N\u00e3o h\u00e1 c\u00f3digo no loop\n}\n</code></pre>"},{"location":"aulas/iot/modulos/modulo7.html#exercicio-3-criar-uma-funcao-recursiva-para-calcular-o-n-esimo-numero-da-sequencia-de-fibonacci","title":"Exerc\u00edcio 3: Criar uma Fun\u00e7\u00e3o Recursiva para Calcular o N-\u00e9simo N\u00famero da Sequ\u00eancia de Fibonacci","text":"<ul> <li> <p>Tarefa: Desenvolva uma fun\u00e7\u00e3o recursiva que calcula e retorna o N-\u00e9simo n\u00famero da sequ\u00eancia de Fibonacci.</p> </li> <li> <p>Exemplo de C\u00f3digo:</p> </li> </ul> <pre><code>long fibonacci(int n) {\n    if(n &lt;= 1)\n        return n;\n    else\n        return fibonacci(n - 1) + fibonacci(n - 2);\n}\n\nvoid setup() {\n    Serial.begin(9600);\n    int termo = 10;\n    long resultado = fibonacci(termo);\n    Serial.print(\"O \");\n    Serial.print(termo);\n    Serial.print(\"\u00ba termo da sequ\u00eancia de Fibonacci \u00e9: \");\n    Serial.println(resultado); // Imprime 55\n}\n\nvoid loop() {\n    // N\u00e3o h\u00e1 c\u00f3digo no loop\n}\n</code></pre>"},{"location":"aulas/iot/modulos/modulo7.html#9-conceitos-importantes","title":"9. Conceitos Importantes","text":""},{"location":"aulas/iot/modulos/modulo7.html#91-seguranca-com-ponteiros","title":"9.1 Seguran\u00e7a com Ponteiros","text":"<ul> <li>Inicializa\u00e7\u00e3o: Sempre inicialize ponteiros. Ponteiros n\u00e3o inicializados podem levar a comportamentos indefinidos.</li> </ul> <pre><code>int *ptr = nullptr; // Inicializado como nulo\n</code></pre> <ul> <li>Verifica\u00e7\u00e3o de Nulos: Antes de desreferenciar um ponteiro, verifique se ele n\u00e3o \u00e9 nulo.</li> </ul> <pre><code>if(ptr != nullptr) {\n    Serial.println(*ptr);\n}\n</code></pre>"},{"location":"aulas/iot/modulos/modulo7.html#92-gerenciamento-de-memoria","title":"9.2 Gerenciamento de Mem\u00f3ria","text":"<ul> <li>Aloca\u00e7\u00e3o Din\u00e2mica: Sempre libere a mem\u00f3ria alocada dinamicamente usando <code>delete</code> ou <code>delete[]</code> para evitar vazamentos de mem\u00f3ria.</li> </ul> <pre><code>int *arr = new int[10];\n// Uso do array\ndelete[] arr; // Libera a mem\u00f3ria\n</code></pre> <ul> <li>Evitar Ponteiros Vazios: Evite ponteiros que apontam para endere\u00e7os inv\u00e1lidos ou que foram liberados.</li> </ul>"},{"location":"aulas/iot/modulos/modulo7.html#93-ponteiros-constantes","title":"9.3 Ponteiros Constantes","text":"<ul> <li>Ponteiro para Constante: O valor apontado n\u00e3o pode ser alterado atrav\u00e9s do ponteiro.</li> </ul> <pre><code>const int *ptr = &amp;valor;\n</code></pre> <ul> <li>Ponteiro Constante: O pr\u00f3prio ponteiro n\u00e3o pode apontar para outro endere\u00e7o.</li> </ul> <pre><code>int * const ptr = &amp;valor;\n</code></pre> <ul> <li>Ponteiro para Constante Constante: Nem o valor apontado nem o ponteiro podem ser alterados.</li> </ul> <pre><code>const int * const ptr = &amp;valor;\n</code></pre>"},{"location":"aulas/iot/modulos/modulo7.html#94-boas-praticas-com-ponteiros-e-referencias","title":"9.4 Boas Pr\u00e1ticas com Ponteiros e Refer\u00eancias","text":"<ul> <li> <p>Evitar Uso Excessivo de Ponteiros: Use refer\u00eancias quando poss\u00edvel para evitar complexidade desnecess\u00e1ria.</p> </li> <li> <p>Documenta\u00e7\u00e3o: Comente o uso de ponteiros para facilitar a compreens\u00e3o do c\u00f3digo.</p> </li> <li> <p>Valida\u00e7\u00e3o: Sempre valide ponteiros antes de us\u00e1-los para evitar erros de execu\u00e7\u00e3o.</p> </li> </ul>"},{"location":"aulas/iot/modulos/modulo8.html","title":"M\u00f3dulo 8: Estruturas (Structs) e Classes","text":"<p>Bem-vindo ao M\u00f3dulo 8 do curso \"Programa\u00e7\u00e3o em Arduino: Conceitos Fundamentais sem Hardware\". Neste m\u00f3dulo, voc\u00ea ir\u00e1 aprofundar seu conhecimento sobre estruturas (<code>structs</code>) e classes na linguagem de programa\u00e7\u00e3o Arduino (C/C++). Estruturas e classes s\u00e3o fundamentais para a programa\u00e7\u00e3o orientada a objetos, permitindo a cria\u00e7\u00e3o de tipos de dados personalizados e a organiza\u00e7\u00e3o eficiente do c\u00f3digo.</p>"},{"location":"aulas/iot/modulos/modulo8.html#objetivos-do-modulo","title":"Objetivos do M\u00f3dulo","text":"<ul> <li>Compreender o conceito de estruturas (<code>structs</code>) e classes na programa\u00e7\u00e3o.</li> <li>Aprender a declarar e utilizar estruturas em Arduino.</li> <li>Introduzir conceitos b\u00e1sicos de programa\u00e7\u00e3o orientada a objetos (POO) com classes.</li> <li>Trabalhar com atributos e m\u00e9todos dentro de classes.</li> <li>Entender o conceito de encapsulamento, heran\u00e7a e polimorfismo.</li> <li>Implementar construtores e destrutores em classes.</li> <li>Resolver exerc\u00edcios pr\u00e1ticos para consolidar o conhecimento sobre estruturas e classes.</li> </ul>"},{"location":"aulas/iot/modulos/modulo8.html#1-introducao-as-estruturas-structs-e-classes","title":"1. Introdu\u00e7\u00e3o \u00e0s Estruturas (<code>Structs</code>) e Classes","text":""},{"location":"aulas/iot/modulos/modulo8.html#11-o-que-sao-estruturas-structs","title":"1.1 O que s\u00e3o Estruturas (<code>Structs</code>)?","text":"<p>Uma estrutura (<code>struct</code>) \u00e9 uma cole\u00e7\u00e3o de vari\u00e1veis agrupadas sob um \u00fanico nome para representar uma entidade mais complexa. Cada vari\u00e1vel dentro de uma estrutura \u00e9 chamada de membro ou campo da estrutura.</p>"},{"location":"aulas/iot/modulos/modulo8.html#12-o-que-sao-classes","title":"1.2 O que s\u00e3o Classes?","text":"<p>Uma classe \u00e9 uma extens\u00e3o das estruturas, incorporando n\u00e3o apenas dados (atributos) mas tamb\u00e9m fun\u00e7\u00f5es (m\u00e9todos) que operam sobre esses dados. Classes s\u00e3o a base da programa\u00e7\u00e3o orientada a objetos (POO), permitindo a cria\u00e7\u00e3o de objetos que possuem propriedades e comportamentos.</p>"},{"location":"aulas/iot/modulos/modulo8.html#13-diferencas-entre-struct-e-class","title":"1.3 Diferen\u00e7as entre <code>struct</code> e <code>class</code>","text":"<ul> <li>Acesso Padr\u00e3o:</li> <li>Em <code>structs</code>, os membros s\u00e3o p\u00fablicos por padr\u00e3o.</li> <li> <p>Em <code>classes</code>, os membros s\u00e3o privados por padr\u00e3o.</p> </li> <li> <p>Funcionalidades:</p> </li> <li><code>Structs</code> s\u00e3o adequadas para agrupamentos simples de dados.</li> <li><code>Classes</code> suportam POO completa, incluindo encapsulamento, heran\u00e7a e polimorfismo.</li> </ul>"},{"location":"aulas/iot/modulos/modulo8.html#2-trabalhando-com-estruturas-structs","title":"2. Trabalhando com Estruturas (<code>Structs</code>)","text":""},{"location":"aulas/iot/modulos/modulo8.html#21-declaracao-e-inicializacao-de-structs","title":"2.1 Declara\u00e7\u00e3o e Inicializa\u00e7\u00e3o de <code>Structs</code>","text":"<p>Sintaxe:</p> <pre><code>struct NomeEstrutura {\n    tipo membro1;\n    tipo membro2;\n    // ...\n};\n</code></pre> <p>Exemplo:</p> <pre><code>struct Sensor {\n    int id;\n    float valor;\n};\n</code></pre>"},{"location":"aulas/iot/modulos/modulo8.html#22-utilizando-structs-no-arduino","title":"2.2 Utilizando <code>Structs</code> no Arduino","text":"<p>Exemplo Pr\u00e1tico:</p> <pre><code>struct Sensor {\n    int id;\n    float valor;\n};\n\nSensor sensor1;\nSensor sensor2;\n\nvoid setup() {\n    Serial.begin(9600);\n\n    sensor1.id = 1;\n    sensor1.valor = 23.5;\n\n    sensor2.id = 2;\n    sensor2.valor = 47.8;\n\n    Serial.print(\"Sensor \");\n    Serial.print(sensor1.id);\n    Serial.print(\": \");\n    Serial.println(sensor1.valor);\n\n    Serial.print(\"Sensor \");\n    Serial.print(sensor2.id);\n    Serial.print(\": \");\n    Serial.println(sensor2.valor);\n}\n\nvoid loop() {\n    // N\u00e3o h\u00e1 c\u00f3digo no loop\n}\n</code></pre> <p>Explica\u00e7\u00e3o:</p> <ul> <li>Define uma estrutura <code>Sensor</code> com membros <code>id</code> e <code>valor</code>.</li> <li>Declara duas vari\u00e1veis <code>sensor1</code> e <code>sensor2</code> do tipo <code>Sensor</code>.</li> <li>Inicializa os membros e imprime os valores no Monitor Serial.</li> </ul>"},{"location":"aulas/iot/modulos/modulo8.html#3-introducao-a-programacao-orientada-a-objetos-poo-com-classes","title":"3. Introdu\u00e7\u00e3o \u00e0 Programa\u00e7\u00e3o Orientada a Objetos (POO) com Classes","text":""},{"location":"aulas/iot/modulos/modulo8.html#31-conceitos-basicos-de-poo","title":"3.1 Conceitos B\u00e1sicos de POO","text":"<ul> <li>Objeto: Uma inst\u00e2ncia de uma classe que possui estado e comportamento.</li> <li>Classe: Um molde para criar objetos, definindo atributos e m\u00e9todos.</li> <li>Encapsulamento: O ato de esconder os detalhes internos de uma classe e expor apenas o necess\u00e1rio.</li> <li>Heran\u00e7a: Permite que uma classe herde atributos e m\u00e9todos de outra.</li> <li>Polimorfismo: Permite que objetos de diferentes classes sejam tratados de forma uniforme.</li> </ul>"},{"location":"aulas/iot/modulos/modulo8.html#32-beneficios-da-poo","title":"3.2 Benef\u00edcios da POO","text":"<ul> <li>Reutiliza\u00e7\u00e3o de C\u00f3digo: Cria\u00e7\u00e3o de classes reutiliz\u00e1veis.</li> <li>Organiza\u00e7\u00e3o: Estrutura\u00e7\u00e3o l\u00f3gica do c\u00f3digo.</li> <li>Manuten\u00e7\u00e3o: Facilita a atualiza\u00e7\u00e3o e corre\u00e7\u00e3o de c\u00f3digo.</li> <li>Escalabilidade: Permite o crescimento do projeto de forma ordenada.</li> </ul>"},{"location":"aulas/iot/modulos/modulo8.html#4-declaracao-e-uso-de-classes","title":"4. Declara\u00e7\u00e3o e Uso de Classes","text":""},{"location":"aulas/iot/modulos/modulo8.html#41-declaracao-de-uma-classe","title":"4.1 Declara\u00e7\u00e3o de uma Classe","text":"<p>Sintaxe:</p> <pre><code>class NomeClasse {\npublic:\n    // Atributos\n    tipo atributo1;\n    tipo atributo2;\n\n    // M\u00e9todos\n    void metodo1();\n    tipo metodo2();\n};\n</code></pre> <p>Exemplo:</p> <pre><code>class Motor {\npublic:\n    int rpm;\n    float temperatura;\n\n    void ligar() {\n        Serial.println(\"Motor ligado.\");\n    }\n\n    void desligar() {\n        Serial.println(\"Motor desligado.\");\n    }\n\n    float lerTemperatura() {\n        return temperatura;\n    }\n};\n</code></pre>"},{"location":"aulas/iot/modulos/modulo8.html#42-utilizando-classes-no-arduino","title":"4.2 Utilizando Classes no Arduino","text":"<p>Exemplo Pr\u00e1tico:</p> <pre><code>class Motor {\npublic:\n    int rpm;\n    float temperatura;\n\n    void ligar() {\n        Serial.println(\"Motor ligado.\");\n    }\n\n    void desligar() {\n        Serial.println(\"Motor desligado.\");\n    }\n\n    float lerTemperatura() {\n        return temperatura;\n    }\n};\n\nMotor motor1;\n\nvoid setup() {\n    Serial.begin(9600);\n\n    motor1.rpm = 1500;\n    motor1.temperatura = 75.0;\n\n    motor1.ligar();\n    Serial.print(\"RPM: \");\n    Serial.println(motor1.rpm);\n    Serial.print(\"Temperatura: \");\n    Serial.println(motor1.lerTemperatura());\n}\n\nvoid loop() {\n    // N\u00e3o h\u00e1 c\u00f3digo no loop\n}\n</code></pre> <p>Explica\u00e7\u00e3o:</p> <ul> <li>Define uma classe <code>Motor</code> com atributos <code>rpm</code> e <code>temperatura</code> e m\u00e9todos <code>ligar</code>, <code>desligar</code> e <code>lerTemperatura</code>.</li> <li>Cria um objeto <code>motor1</code> da classe <code>Motor</code>.</li> <li>Inicializa os atributos e chama os m\u00e9todos para ligar o motor e imprimir os valores no Monitor Serial.</li> </ul>"},{"location":"aulas/iot/modulos/modulo8.html#5-construtores-e-destrutores","title":"5. Construtores e Destrutores","text":""},{"location":"aulas/iot/modulos/modulo8.html#51-construtores","title":"5.1 Construtores","text":"<p>Um construtor \u00e9 um m\u00e9todo especial que \u00e9 chamado automaticamente quando um objeto \u00e9 criado. Ele \u00e9 usado para inicializar os atributos do objeto.</p> <p>Sintaxe:</p> <pre><code>class NomeClasse {\npublic:\n    NomeClasse() {\n        // C\u00f3digo de inicializa\u00e7\u00e3o\n    }\n};\n</code></pre> <p>Exemplo:</p> <pre><code>class Sensor {\npublic:\n    int id;\n    float valor;\n\n    // Construtor\n    Sensor(int sensorId, float sensorValor) {\n        id = sensorId;\n        valor = sensorValor;\n    }\n\n    void imprimirDados() {\n        Serial.print(\"Sensor \");\n        Serial.print(id);\n        Serial.print(\": \");\n        Serial.println(valor);\n    }\n};\n\nvoid setup() {\n    Serial.begin(9600);\n\n    Sensor sensor1(1, 23.5);\n    Sensor sensor2(2, 47.8);\n\n    sensor1.imprimirDados();\n    sensor2.imprimirDados();\n}\n\nvoid loop() {\n    // N\u00e3o h\u00e1 c\u00f3digo no loop\n}\n</code></pre> <p>Explica\u00e7\u00e3o:</p> <ul> <li>A classe <code>Sensor</code> possui um construtor que inicializa os atributos <code>id</code> e <code>valor</code>.</li> <li>Cria dois objetos <code>sensor1</code> e <code>sensor2</code> com valores iniciais.</li> <li>Chama o m\u00e9todo <code>imprimirDados</code> para exibir os dados no Monitor Serial.</li> </ul>"},{"location":"aulas/iot/modulos/modulo8.html#52-destrutores","title":"5.2 Destrutores","text":"<p>Um destruidor \u00e9 um m\u00e9todo especial que \u00e9 chamado automaticamente quando um objeto \u00e9 destru\u00eddo ou sai de escopo. \u00c9 usado para liberar recursos ou realizar tarefas de limpeza.</p> <p>Sintaxe:</p> <pre><code>class NomeClasse {\npublic:\n    ~NomeClasse() {\n        // C\u00f3digo de limpeza\n    }\n};\n</code></pre> <p>Exemplo:</p> <pre><code>class Motor {\npublic:\n    Motor() {\n        Serial.println(\"Motor criado.\");\n    }\n\n    ~Motor() {\n        Serial.println(\"Motor destru\u00eddo.\");\n    }\n\n    void ligar() {\n        Serial.println(\"Motor ligado.\");\n    }\n};\n\nvoid setup() {\n    Serial.begin(9600);\n    {\n        Motor motor1;\n        motor1.ligar();\n    } // motor1 \u00e9 destru\u00eddo aqui\n}\n\nvoid loop() {\n    // N\u00e3o h\u00e1 c\u00f3digo no loop\n}\n</code></pre> <p>Explica\u00e7\u00e3o:</p> <ul> <li>A classe <code>Motor</code> possui um construtor que imprime uma mensagem ao ser criado e um destruidor que imprime uma mensagem ao ser destru\u00eddo.</li> <li>O objeto <code>motor1</code> \u00e9 criado dentro de um bloco de c\u00f3digo <code>{}</code> e \u00e9 destru\u00eddo ao final do bloco.</li> </ul>"},{"location":"aulas/iot/modulos/modulo8.html#6-encapsulamento-heranca-e-polimorfismo","title":"6. Encapsulamento, Heran\u00e7a e Polimorfismo","text":""},{"location":"aulas/iot/modulos/modulo8.html#61-encapsulamento","title":"6.1 Encapsulamento","text":"<p>Encapsulamento \u00e9 o conceito de esconder os detalhes internos de uma classe e expor apenas o necess\u00e1rio atrav\u00e9s de m\u00e9todos p\u00fablicos.</p> <p>Exemplo:</p> <pre><code>class ContaBancaria {\nprivate:\n    float saldo;\n\npublic:\n    ContaBancaria(float saldoInicial) {\n        saldo = saldoInicial;\n    }\n\n    void depositar(float valor) {\n        saldo += valor;\n    }\n\n    void sacar(float valor) {\n        if(valor &lt;= saldo) {\n            saldo -= valor;\n        } else {\n            Serial.println(\"Saldo insuficiente.\");\n        }\n    }\n\n    float getSaldo() {\n        return saldo;\n    }\n};\n\nvoid setup() {\n    Serial.begin(9600);\n    ContaBancaria minhaConta(1000.0);\n\n    minhaConta.depositar(500.0);\n    minhaConta.sacar(200.0);\n\n    Serial.print(\"Saldo Atual: \");\n    Serial.println(minhaConta.getSaldo());\n}\n\nvoid loop() {\n    // N\u00e3o h\u00e1 c\u00f3digo no loop\n}\n</code></pre> <p>Explica\u00e7\u00e3o:</p> <ul> <li>A classe <code>ContaBancaria</code> encapsula o atributo <code>saldo</code> como privado.</li> <li>M\u00e9todos p\u00fablicos <code>depositar</code>, <code>sacar</code> e <code>getSaldo</code> permitem a manipula\u00e7\u00e3o segura do saldo.</li> </ul>"},{"location":"aulas/iot/modulos/modulo8.html#62-heranca","title":"6.2 Heran\u00e7a","text":"<p>Heran\u00e7a permite que uma classe (classe derivada) herde atributos e m\u00e9todos de outra classe (classe base), promovendo a reutiliza\u00e7\u00e3o de c\u00f3digo.</p> <p>Exemplo:</p> <pre><code>class Veiculo {\npublic:\n    int rodas;\n\n    void mover() {\n        Serial.println(\"Ve\u00edculo em movimento.\");\n    }\n};\n\nclass Carro : public Veiculo {\npublic:\n    string modelo;\n\n    void buzinar() {\n        Serial.println(\"Buzinando!\");\n    }\n};\n\nvoid setup() {\n    Serial.begin(9600);\n    Carro meuCarro;\n    meuCarro.rodas = 4;\n    meuCarro.modelo = \"Sedan\";\n\n    Serial.print(\"Modelo: \");\n    Serial.println(meuCarro.modelo.c_str());\n    Serial.print(\"Rodas: \");\n    Serial.println(meuCarro.rodas);\n\n    meuCarro.mover();\n    meuCarro.buzinar();\n}\n\nvoid loop() {\n    // N\u00e3o h\u00e1 c\u00f3digo no loop\n}\n</code></pre> <p>Explica\u00e7\u00e3o:</p> <ul> <li>A classe <code>Carro</code> herda da classe <code>Veiculo</code>, recebendo o atributo <code>rodas</code> e o m\u00e9todo <code>mover</code>.</li> <li>Adiciona o atributo <code>modelo</code> e o m\u00e9todo <code>buzinar</code>.</li> </ul>"},{"location":"aulas/iot/modulos/modulo8.html#63-polimorfismo","title":"6.3 Polimorfismo","text":"<p>Polimorfismo permite que objetos de diferentes classes sejam tratados de forma uniforme atrav\u00e9s de interfaces comuns.</p> <p>Exemplo:</p> <pre><code>class Forma {\npublic:\n    virtual void desenhar() {\n        Serial.println(\"Desenhando uma forma gen\u00e9rica.\");\n    }\n};\n\nclass Circulo : public Forma {\npublic:\n    void desenhar() override {\n        Serial.println(\"Desenhando um c\u00edrculo.\");\n    }\n};\n\nclass Retangulo : public Forma {\npublic:\n    void desenhar() override {\n        Serial.println(\"Desenhando um ret\u00e2ngulo.\");\n    }\n};\n\nvoid setup() {\n    Serial.begin(9600);\n\n    Forma *formas[2];\n    formas[0] = new Circulo();\n    formas[1] = new Retangulo();\n\n    for(int i = 0; i &lt; 2; i++) {\n        formas[i]-&gt;desenhar();\n    }\n\n    // Libera\u00e7\u00e3o de mem\u00f3ria\n    for(int i = 0; i &lt; 2; i++) {\n        delete formas[i];\n    }\n}\n\nvoid loop() {\n    // N\u00e3o h\u00e1 c\u00f3digo no loop\n}\n</code></pre> <p>Explica\u00e7\u00e3o:</p> <ul> <li>Define uma classe base <code>Forma</code> com um m\u00e9todo virtual <code>desenhar</code>.</li> <li>As classes <code>Circulo</code> e <code>Retangulo</code> sobrescrevem o m\u00e9todo <code>desenhar</code>.</li> <li>Permite que diferentes objetos sejam chamados de forma polim\u00f3rfica atrav\u00e9s de ponteiros da classe base.</li> </ul>"},{"location":"aulas/iot/modulos/modulo8.html#7-exemplos-praticos","title":"7. Exemplos Pr\u00e1ticos","text":""},{"location":"aulas/iot/modulos/modulo8.html#71-criando-uma-classe-para-representar-um-sensor","title":"7.1 Criando uma Classe para Representar um Sensor","text":"<pre><code>class Sensor {\nprivate:\n    int id;\n    float valor;\n\npublic:\n    // Construtor\n    Sensor(int sensorId, float sensorValor) {\n        id = sensorId;\n        valor = sensorValor;\n    }\n\n    // M\u00e9todos para acessar e modificar os atributos\n    int getId() {\n        return id;\n    }\n\n    float getValor() {\n        return valor;\n    }\n\n    void setValor(float novoValor) {\n        valor = novoValor;\n    }\n\n    void imprimirDados() {\n        Serial.print(\"Sensor \");\n        Serial.print(id);\n        Serial.print(\": \");\n        Serial.println(valor);\n    }\n};\n\nvoid setup() {\n    Serial.begin(9600);\n\n    Sensor sensor1(1, 23.5);\n    Sensor sensor2(2, 47.8);\n\n    sensor1.imprimirDados();\n    sensor2.imprimirDados();\n\n    // Atualizando o valor do sensor1\n    sensor1.setValor(25.0);\n    Serial.println(\"Ap\u00f3s atualiza\u00e7\u00e3o:\");\n    sensor1.imprimirDados();\n}\n\nvoid loop() {\n    // N\u00e3o h\u00e1 c\u00f3digo no loop\n}\n</code></pre> <p>Explica\u00e7\u00e3o:</p> <ul> <li>Define a classe <code>Sensor</code> com atributos privados <code>id</code> e <code>valor</code>.</li> <li>Inclui m\u00e9todos p\u00fablicos para acessar e modificar esses atributos.</li> <li>No <code>setup</code>, cria dois objetos <code>sensor1</code> e <code>sensor2</code>, imprime seus dados e atualiza o valor de <code>sensor1</code>.</li> </ul>"},{"location":"aulas/iot/modulos/modulo8.html#72-implementando-uma-classe-de-led-com-metodos-para-ligar-e-desligar","title":"7.2 Implementando uma Classe de LED com M\u00e9todos para Ligar e Desligar","text":"<pre><code>class LED {\nprivate:\n    int pin;\n\npublic:\n    // Construtor\n    LED(int ledPin) {\n        pin = ledPin;\n        pinMode(pin, OUTPUT);\n    }\n\n    // M\u00e9todo para ligar o LED\n    void ligar() {\n        digitalWrite(pin, HIGH);\n    }\n\n    // M\u00e9todo para desligar o LED\n    void desligar() {\n        digitalWrite(pin, LOW);\n    }\n\n    // M\u00e9todo para alternar o estado do LED\n    void alternar() {\n        int estado = digitalRead(pin);\n        digitalWrite(pin, !estado);\n    }\n};\n\nLED meuLED(13); // LED conectado ao pino 13\n\nvoid setup() {\n    Serial.begin(9600);\n    Serial.println(\"Controlando o LED.\");\n\n    meuLED.ligar();\n    delay(1000);\n    meuLED.desligar();\n    delay(1000);\n}\n\nvoid loop() {\n    meuLED.alternar();\n    delay(500);\n}\n</code></pre> <p>Explica\u00e7\u00e3o:</p> <ul> <li>Define a classe <code>LED</code> com um atributo privado <code>pin</code>.</li> <li>Inclui m\u00e9todos para ligar, desligar e alternar o estado do LED.</li> <li>No <code>setup</code>, liga e desliga o LED uma vez.</li> <li>No <code>loop</code>, alterna o estado do LED a cada meio segundo.</li> </ul>"},{"location":"aulas/iot/modulos/modulo8.html#73-criando-uma-classe-para-gerenciar-um-array-de-sensores","title":"7.3 Criando uma Classe para Gerenciar um Array de Sensores","text":"<pre><code>class GerenciadorSensores {\nprivate:\n    Sensor sensores[5];\n    int quantidade;\n\npublic:\n    // Construtor\n    GerenciadorSensores() : sensores{Sensor(1, 23.5), Sensor(2, 47.8), Sensor(3, 30.2), Sensor(4, 50.0), Sensor(5, 25.5)} {\n        quantidade = 5;\n    }\n\n    // M\u00e9todo para imprimir todos os sensores\n    void imprimirTodos() {\n        for(int i = 0; i &lt; quantidade; i++) {\n            sensores[i].imprimirDados();\n        }\n    }\n\n    // M\u00e9todo para atualizar o valor de um sensor espec\u00edfico\n    void atualizarSensor(int id, float novoValor) {\n        for(int i = 0; i &lt; quantidade; i++) {\n            if(sensores[i].getId() == id) {\n                sensores[i].setValor(novoValor);\n                Serial.print(\"Sensor \");\n                Serial.print(id);\n                Serial.println(\" atualizado.\");\n                return;\n            }\n        }\n        Serial.println(\"Sensor n\u00e3o encontrado.\");\n    }\n};\n\nGerenciadorSensores gerenciador;\n\nvoid setup() {\n    Serial.begin(9600);\n    Serial.println(\"Gerenciador de Sensores:\");\n\n    gerenciador.imprimirTodos();\n\n    // Atualizando o valor do sensor 3\n    gerenciador.atualizarSensor(3, 35.0);\n\n    Serial.println(\"Ap\u00f3s atualiza\u00e7\u00e3o:\");\n    gerenciador.imprimirTodos();\n}\n\nvoid loop() {\n    // N\u00e3o h\u00e1 c\u00f3digo no loop\n}\n</code></pre> <p>Explica\u00e7\u00e3o:</p> <ul> <li>Define a classe <code>GerenciadorSensores</code> que gerencia um array de 5 objetos <code>Sensor</code>.</li> <li>Inclui m\u00e9todos para imprimir todos os sensores e atualizar o valor de um sensor espec\u00edfico.</li> <li>No <code>setup</code>, imprime todos os sensores, atualiza o sensor com <code>id</code> 3 e imprime novamente.</li> </ul>"},{"location":"aulas/iot/modulos/modulo8.html#8-exercicios-praticos","title":"8. Exerc\u00edcios Pr\u00e1ticos","text":""},{"location":"aulas/iot/modulos/modulo8.html#exercicio-1-criar-uma-classe-para-representar-um-veiculo","title":"Exerc\u00edcio 1: Criar uma Classe para Representar um Ve\u00edculo","text":"<ul> <li> <p>Tarefa: Desenvolva uma classe <code>Veiculo</code> que possui atributos como <code>marca</code>, <code>modelo</code> e <code>ano</code>. Inclua m\u00e9todos para ligar, desligar e exibir as informa\u00e7\u00f5es do ve\u00edculo.</p> </li> <li> <p>Exemplo de C\u00f3digo:</p> </li> </ul> <pre><code>class Veiculo {\nprivate:\n    String marca;\n    String modelo;\n    int ano;\n    bool ligado;\n\npublic:\n    // Construtor\n    Veiculo(String m, String mo, int a) : marca(m), modelo(mo), ano(a), ligado(false) {}\n\n    // M\u00e9todos\n    void ligar() {\n        if(!ligado) {\n            ligado = true;\n            Serial.println(\"Ve\u00edculo ligado.\");\n        } else {\n            Serial.println(\"Ve\u00edculo j\u00e1 est\u00e1 ligado.\");\n        }\n    }\n\n    void desligar() {\n        if(ligado) {\n            ligado = false;\n            Serial.println(\"Ve\u00edculo desligado.\");\n        } else {\n            Serial.println(\"Ve\u00edculo j\u00e1 est\u00e1 desligado.\");\n        }\n    }\n\n    void exibirInfo() {\n        Serial.print(\"Marca: \");\n        Serial.println(marca);\n        Serial.print(\"Modelo: \");\n        Serial.println(modelo);\n        Serial.print(\"Ano: \");\n        Serial.println(ano);\n        Serial.print(\"Estado: \");\n        Serial.println(ligado ? \"Ligado\" : \"Desligado\");\n    }\n};\n\nVeiculo meuCarro(\"Toyota\", \"Corolla\", 2020);\n\nvoid setup() {\n    Serial.begin(9600);\n    meuCarro.exibirInfo();\n    meuCarro.ligar();\n    meuCarro.exibirInfo();\n    meuCarro.desligar();\n    meuCarro.exibirInfo();\n}\n\nvoid loop() {\n    // N\u00e3o h\u00e1 c\u00f3digo no loop\n}\n</code></pre>"},{"location":"aulas/iot/modulos/modulo8.html#exercicio-2-implementar-heranca-com-classes-animal-e-cachorro","title":"Exerc\u00edcio 2: Implementar Heran\u00e7a com Classes <code>Animal</code> e <code>Cachorro</code>","text":"<ul> <li> <p>Tarefa: Crie uma classe base <code>Animal</code> com atributos e m\u00e9todos gerais, e uma classe derivada <code>Cachorro</code> que herda de <code>Animal</code> e adiciona comportamentos espec\u00edficos.</p> </li> <li> <p>Exemplo de C\u00f3digo:</p> </li> </ul> <pre><code>class Animal {\nprotected:\n    String nome;\n    int idade;\n\npublic:\n    // Construtor\n    Animal(String n, int i) : nome(n), idade(i) {}\n\n    // M\u00e9todo para exibir informa\u00e7\u00f5es\n    void exibirInfo() {\n        Serial.print(\"Nome: \");\n        Serial.println(nome);\n        Serial.print(\"Idade: \");\n        Serial.println(idade);\n    }\n\n    // M\u00e9todo virtual\n    virtual void emitirSom() {\n        Serial.println(\"Animal emite som.\");\n    }\n};\n\nclass Cachorro : public Animal {\npublic:\n    // Construtor\n    Cachorro(String n, int i) : Animal(n, i) {}\n\n    // Sobrescreve o m\u00e9todo emitirSom\n    void emitirSom() override {\n        Serial.println(\"Cachorro diz: Au Au!\");\n    }\n};\n\nvoid setup() {\n    Serial.begin(9600);\n\n    Animal meuAnimal(\"Gen\u00e9rico\", 5);\n    Cachorro meuCachorro(\"Rex\", 3);\n\n    Serial.println(\"Informa\u00e7\u00f5es do Animal:\");\n    meuAnimal.exibirInfo();\n    meuAnimal.emitirSom();\n\n    Serial.println(\"\\nInforma\u00e7\u00f5es do Cachorro:\");\n    meuCachorro.exibirInfo();\n    meuCachorro.emitirSom();\n}\n\nvoid loop() {\n    // N\u00e3o h\u00e1 c\u00f3digo no loop\n}\n</code></pre> <p>Explica\u00e7\u00e3o:</p> <ul> <li>A classe <code>Animal</code> possui atributos <code>nome</code> e <code>idade</code>, e m\u00e9todos para exibir informa\u00e7\u00f5es e emitir som.</li> <li>A classe <code>Cachorro</code> herda de <code>Animal</code> e sobrescreve o m\u00e9todo <code>emitirSom</code> para emitir um som espec\u00edfico.</li> <li>No <code>setup</code>, cria objetos <code>meuAnimal</code> e <code>meuCachorro</code> e chama seus m\u00e9todos.</li> </ul>"},{"location":"aulas/iot/modulos/modulo8.html#exercicio-3-implementar-encapsulamento-com-a-classe-lampada","title":"Exerc\u00edcio 3: Implementar Encapsulamento com a Classe <code>Lampada</code>","text":"<ul> <li> <p>Tarefa: Crie uma classe <code>Lampada</code> que possui atributos privados <code>estado</code> (ligada/desligada) e <code>intensidade</code>. Inclua m\u00e9todos p\u00fablicos para ligar, desligar, aumentar e diminuir a intensidade, e exibir o estado atual.</p> </li> <li> <p>Exemplo de C\u00f3digo:</p> </li> </ul> <pre><code>class Lampada {\nprivate:\n    bool ligada;\n    int intensidade; // De 0 a 100\n\npublic:\n    // Construtor\n    Lampada() : ligada(false), intensidade(0) {}\n\n    // M\u00e9todos\n    void ligar() {\n        ligada = true;\n        Serial.println(\"L\u00e2mpada ligada.\");\n    }\n\n    void desligar() {\n        ligada = false;\n        intensidade = 0;\n        Serial.println(\"L\u00e2mpada desligada.\");\n    }\n\n    void aumentarIntensidade(int valor) {\n        if(ligada) {\n            intensidade += valor;\n            if(intensidade &gt; 100) intensidade = 100;\n            Serial.print(\"Intensidade aumentada para: \");\n            Serial.println(intensidade);\n        } else {\n            Serial.println(\"L\u00e2mpada est\u00e1 desligada. N\u00e3o \u00e9 poss\u00edvel aumentar a intensidade.\");\n        }\n    }\n\n    void diminuirIntensidade(int valor) {\n        if(ligada) {\n            intensidade -= valor;\n            if(intensidade &lt; 0) intensidade = 0;\n            Serial.print(\"Intensidade diminu\u00edda para: \");\n            Serial.println(intensidade);\n        } else {\n            Serial.println(\"L\u00e2mpada est\u00e1 desligada. N\u00e3o \u00e9 poss\u00edvel diminuir a intensidade.\");\n        }\n    }\n\n    void exibirEstado() {\n        Serial.print(\"Estado da L\u00e2mpada: \");\n        Serial.println(ligada ? \"Ligada\" : \"Desligada\");\n        Serial.print(\"Intensidade: \");\n        Serial.println(intensidade);\n    }\n};\n\nLampada minhaLampada;\n\nvoid setup() {\n    Serial.begin(9600);\n    minhaLampada.exibirEstado();\n\n    minhaLampada.ligar();\n    minhaLampada.aumentarIntensidade(30);\n    minhaLampada.aumentarIntensidade(50);\n    minhaLampada.diminuirIntensidade(20);\n    minhaLampada.exibirEstado();\n\n    minhaLampada.desligar();\n    minhaLampada.exibirEstado();\n}\n\nvoid loop() {\n    // N\u00e3o h\u00e1 c\u00f3digo no loop\n}\n</code></pre> <p>Explica\u00e7\u00e3o:</p> <ul> <li>A classe <code>Lampada</code> encapsula os atributos <code>ligada</code> e <code>intensidade</code> como privados.</li> <li>Inclui m\u00e9todos p\u00fablicos para manipular o estado e a intensidade da l\u00e2mpada.</li> <li>No <code>setup</code>, demonstra o uso dos m\u00e9todos da classe <code>Lampada</code>.</li> </ul>"},{"location":"aulas/iot/modulos/modulo8.html#9-conceitos-importantes","title":"9. Conceitos Importantes","text":""},{"location":"aulas/iot/modulos/modulo8.html#91-encapsulamento","title":"9.1 Encapsulamento","text":"<ul> <li>Defini\u00e7\u00e3o: Esconder os detalhes internos de uma classe e expor apenas os necess\u00e1rios atrav\u00e9s de m\u00e9todos p\u00fablicos.</li> <li>Benef\u00edcios:</li> <li>Seguran\u00e7a: Protege os dados contra acessos indevidos.</li> <li>Manuten\u00e7\u00e3o: Facilita a altera\u00e7\u00e3o interna sem afetar o c\u00f3digo externo.</li> </ul>"},{"location":"aulas/iot/modulos/modulo8.html#92-heranca","title":"9.2 Heran\u00e7a","text":"<ul> <li>Defini\u00e7\u00e3o: Permite que uma classe derive atributos e m\u00e9todos de outra classe.</li> <li>Tipos de Heran\u00e7a:</li> <li>P\u00fablica (<code>public</code>): Os membros p\u00fablicos e protegidos da classe base permanecem p\u00fablicos e protegidos na classe derivada.</li> <li>Privada (<code>private</code>): Todos os membros herdados se tornam privados na classe derivada.</li> </ul>"},{"location":"aulas/iot/modulos/modulo8.html#93-polimorfismo","title":"9.3 Polimorfismo","text":"<ul> <li>Defini\u00e7\u00e3o: Permite que objetos de diferentes classes sejam tratados de forma uniforme atrav\u00e9s de interfaces comuns.</li> <li>M\u00e9todos Virtuais: Facilita o polimorfismo, permitindo que m\u00e9todos sejam sobrescritos em classes derivadas.</li> </ul>"},{"location":"aulas/iot/modulos/modulo8.html#94-gerenciamento-de-memoria","title":"9.4 Gerenciamento de Mem\u00f3ria","text":"<ul> <li>Import\u00e2ncia: Classes e objetos podem consumir mem\u00f3ria significativa, especialmente em microcontroladores com recursos limitados.</li> <li>Boas Pr\u00e1ticas:</li> <li>Evitar Aloca\u00e7\u00e3o Din\u00e2mica Desnecess\u00e1ria: Use objetos est\u00e1ticos sempre que poss\u00edvel.</li> <li>Liberar Mem\u00f3ria Alocada Dinamicamente: Utilize <code>delete</code> e <code>delete[]</code> apropriadamente.</li> </ul>"},{"location":"aulas/iot/modulos/modulo8.html#95-boas-praticas-de-programacao-orientada-a-objetos","title":"9.5 Boas Pr\u00e1ticas de Programa\u00e7\u00e3o Orientada a Objetos","text":"<ul> <li>Nomea\u00e7\u00e3o Clara: Use nomes significativos para classes, m\u00e9todos e atributos.</li> <li>Responsabilidade \u00danica: Cada classe deve ter uma \u00fanica responsabilidade ou funcionalidade.</li> <li>Modulariza\u00e7\u00e3o: Divida o c\u00f3digo em m\u00f3dulos e classes que representam entidades do mundo real ou conceitos l\u00f3gicos.</li> <li>Reutiliza\u00e7\u00e3o de C\u00f3digo: Utilize heran\u00e7a e composi\u00e7\u00e3o para reutilizar c\u00f3digo de forma eficiente.</li> </ul>"},{"location":"aulas/iot/modulos/modulo9.html","title":"M\u00f3dulo 9: Interrup\u00e7\u00f5es e Timers","text":"<p>Bem-vindo ao M\u00f3dulo 9 do curso \"Programa\u00e7\u00e3o em Arduino: Conceitos Fundamentais sem Hardware\". Neste m\u00f3dulo, voc\u00ea ir\u00e1 explorar as interrup\u00e7\u00f5es e timers na linguagem de programa\u00e7\u00e3o Arduino (C/C++). Esses conceitos s\u00e3o essenciais para criar programas responsivos e eficientes, capazes de lidar com eventos ass\u00edncronos e temporiza\u00e7\u00f5es precisas.</p>"},{"location":"aulas/iot/modulos/modulo9.html#objetivos-do-modulo","title":"Objetivos do M\u00f3dulo","text":"<ul> <li>Compreender o conceito de interrup\u00e7\u00f5es e sua import\u00e2ncia na programa\u00e7\u00e3o Arduino.</li> <li>Aprender a configurar e utilizar interrup\u00e7\u00f5es externas e internas.</li> <li>Entender o funcionamento dos timers e como utiliz\u00e1-los para gerar eventos temporizados.</li> <li>Implementar aplica\u00e7\u00f5es que utilizam interrup\u00e7\u00f5es e timers para melhorar a efici\u00eancia e a responsividade do programa.</li> <li>Resolver exerc\u00edcios pr\u00e1ticos para consolidar o conhecimento sobre interrup\u00e7\u00f5es e timers.</li> </ul>"},{"location":"aulas/iot/modulos/modulo9.html#1-introducao-a-interrupcoes-e-timers","title":"1. Introdu\u00e7\u00e3o a Interrup\u00e7\u00f5es e Timers","text":""},{"location":"aulas/iot/modulos/modulo9.html#11-o-que-sao-interrupcoes","title":"1.1 O que s\u00e3o Interrup\u00e7\u00f5es?","text":"<p>Interrup\u00e7\u00f5es s\u00e3o sinais que indicam a ocorr\u00eancia de um evento que requer aten\u00e7\u00e3o imediata do processador. Quando uma interrup\u00e7\u00e3o ocorre, o fluxo normal do programa \u00e9 temporariamente interrompido para executar uma rotina de tratamento espec\u00edfica, conhecida como ISR (Interrupt Service Routine). Ap\u00f3s a execu\u00e7\u00e3o da ISR, o programa retorna ao ponto onde foi interrompido.</p>"},{"location":"aulas/iot/modulos/modulo9.html#12-por-que-usar-interrupcoes","title":"1.2 Por que Usar Interrup\u00e7\u00f5es?","text":"<ul> <li>Responsividade: Permite que o microcontrolador reaja rapidamente a eventos externos sem a necessidade de verificar constantemente o estado de entradas.</li> <li>Efici\u00eancia: Reduz o consumo de CPU, j\u00e1 que o processador pode executar outras tarefas enquanto espera por eventos.</li> <li>Precis\u00e3o: Garante que eventos cr\u00edticos sejam tratados imediatamente, aumentando a precis\u00e3o das opera\u00e7\u00f5es temporizadas.</li> </ul>"},{"location":"aulas/iot/modulos/modulo9.html#13-o-que-sao-timers","title":"1.3 O que s\u00e3o Timers?","text":"<p>Timers s\u00e3o m\u00f3dulos internos que contam ciclos de clock e geram eventos ap\u00f3s um determinado per\u00edodo. Eles s\u00e3o usados para criar temporiza\u00e7\u00f5es precisas, gerar sinais PWM, ou criar delays sem bloquear a execu\u00e7\u00e3o do programa principal.</p>"},{"location":"aulas/iot/modulos/modulo9.html#2-trabalhando-com-interrupcoes","title":"2. Trabalhando com Interrup\u00e7\u00f5es","text":""},{"location":"aulas/iot/modulos/modulo9.html#21-tipos-de-interrupcoes-no-arduino","title":"2.1 Tipos de Interrup\u00e7\u00f5es no Arduino","text":"<ul> <li>Interrup\u00e7\u00f5es Externas: Disparadas por sinais em pinos espec\u00edficos (por exemplo, bot\u00f5es ou sensores).</li> <li>Interrup\u00e7\u00f5es Internas: Disparadas por eventos internos, como overflow de timers ou comunica\u00e7\u00e3o serial.</li> </ul>"},{"location":"aulas/iot/modulos/modulo9.html#22-configuracao-de-interrupcoes-externas","title":"2.2 Configura\u00e7\u00e3o de Interrup\u00e7\u00f5es Externas","text":"<p>Os Arduinos possuem pinos espec\u00edficos que suportam interrup\u00e7\u00f5es externas. Por exemplo, no Arduino Uno, os pinos 2 e 3 s\u00e3o comumente usados para esse prop\u00f3sito.</p> <p>Sintaxe:</p> <pre><code>attachInterrupt(digitalPinToInterrupt(pino), nomeISR, modo);\n</code></pre> <ul> <li>pino: N\u00famero do pino que receber\u00e1 a interrup\u00e7\u00e3o.</li> <li>nomeISR: Nome da fun\u00e7\u00e3o que ser\u00e1 chamada quando a interrup\u00e7\u00e3o ocorrer.</li> <li>modo: Condi\u00e7\u00e3o que dispara a interrup\u00e7\u00e3o (<code>LOW</code>, <code>CHANGE</code>, <code>RISING</code>, <code>FALLING</code>).</li> </ul> <p>Exemplo Pr\u00e1tico:</p> <pre><code>volatile bool botaoPressionado = false;\n\nvoid botaoISR() {\n    botaoPressionado = true;\n}\n\nvoid setup() {\n    Serial.begin(9600);\n    pinMode(2, INPUT_PULLUP); // Bot\u00e3o conectado ao pino 2\n    attachInterrupt(digitalPinToInterrupt(2), botaoISR, FALLING);\n}\n\nvoid loop() {\n    if(botaoPressionado) {\n        Serial.println(\"Bot\u00e3o pressionado!\");\n        botaoPressionado = false;\n    }\n}\n</code></pre> <p>Explica\u00e7\u00e3o:</p> <ul> <li><code>volatile</code>: Indica que a vari\u00e1vel pode ser alterada por uma ISR, evitando otimiza\u00e7\u00f5es que poderiam ignorar mudan\u00e7as.</li> <li><code>botaoISR</code>: ISR que altera o estado da vari\u00e1vel <code>botaoPressionado</code> quando o bot\u00e3o \u00e9 pressionado.</li> <li><code>attachInterrupt</code>: Configura a interrup\u00e7\u00e3o no pino 2 para detectar bordas de descida (<code>FALLING</code>).</li> </ul>"},{"location":"aulas/iot/modulos/modulo9.html#23-boas-praticas-com-isrs","title":"2.3 Boas Pr\u00e1ticas com ISRs","text":"<ul> <li>Mantenha as ISRs Curtas: Execute apenas o necess\u00e1rio dentro da ISR para evitar atrasos no processamento.</li> <li>Use Vari\u00e1veis Vol\u00e1teis: Vari\u00e1veis compartilhadas entre a ISR e o loop principal devem ser declaradas como <code>volatile</code>.</li> <li>Evite Fun\u00e7\u00f5es Complexas: Evite chamadas a fun\u00e7\u00f5es que dependem de interrup\u00e7\u00f5es, como <code>Serial.print()</code>, dentro da ISR.</li> </ul>"},{"location":"aulas/iot/modulos/modulo9.html#3-trabalhando-com-timers","title":"3. Trabalhando com Timers","text":""},{"location":"aulas/iot/modulos/modulo9.html#31-tipos-de-timers-no-arduino","title":"3.1 Tipos de Timers no Arduino","text":"<ul> <li>Timer0: Usado pelo <code>millis()</code> e <code>delay()</code>. N\u00e3o deve ser alterado para evitar conflitos.</li> <li>Timer1: Um timer de 16 bits, ideal para aplica\u00e7\u00f5es que requerem precis\u00e3o.</li> <li>Timer2: Um timer de 8 bits, \u00fatil para tarefas menos precisas.</li> </ul>"},{"location":"aulas/iot/modulos/modulo9.html#32-configuracao-de-timer1-para-gerar-uma-interrupcao","title":"3.2 Configura\u00e7\u00e3o de Timer1 para Gerar uma Interrup\u00e7\u00e3o","text":"<p>Exemplo Pr\u00e1tico:</p> <pre><code>volatile unsigned long contador = 0;\n\nISR(TIMER1_COMPA_vect) {\n    contador++;\n}\n\nvoid setup() {\n    Serial.begin(9600);\n\n    // Configura Timer1 para CTC mode (Clear Timer on Compare Match)\n    TCCR1A = 0;\n    TCCR1B = 0;\n    TCCR1B |= (1 &lt;&lt; WGM12);\n\n    // Define valor de compara\u00e7\u00e3o para gerar interrup\u00e7\u00e3o a cada 1 segundo\n    OCR1A = 15624; // (16MHz / (Prescaler * Desired Frequency)) - 1\n    TCCR1B |= (1 &lt;&lt; CS12) | (1 &lt;&lt; CS10); // Prescaler = 1024\n    TIMSK1 |= (1 &lt;&lt; OCIE1A); // Habilita interrup\u00e7\u00e3o por compara\u00e7\u00e3o\n\n    sei(); // Habilita interrup\u00e7\u00f5es globais\n}\n\nvoid loop() {\n    if(contador &gt;= 5) { // Ap\u00f3s 5 segundos\n        Serial.println(\"5 segundos se passaram!\");\n        contador = 0;\n    }\n}\n</code></pre> <p>Explica\u00e7\u00e3o:</p> <ul> <li>CTC Mode: Configura o timer para limpar o contador quando atingir o valor de compara\u00e7\u00e3o.</li> <li>OCR1A: Define o valor de compara\u00e7\u00e3o para gerar uma interrup\u00e7\u00e3o a cada segundo.</li> <li>Prescaler: Reduz a frequ\u00eancia do clock do timer para atingir a temporiza\u00e7\u00e3o desejada.</li> <li><code>sei()</code>: Habilita interrup\u00e7\u00f5es globais.</li> <li><code>ISR(TIMER1_COMPA_vect)</code>: ISR chamada a cada vez que o timer atinge o valor de compara\u00e7\u00e3o, incrementando o contador.</li> </ul>"},{"location":"aulas/iot/modulos/modulo9.html#33-gerando-pwm-com-timers","title":"3.3 Gerando PWM com Timers","text":"<p>Os timers tamb\u00e9m podem ser usados para gerar sinais PWM (Pulse Width Modulation) com maior precis\u00e3o ou em pinos espec\u00edficos.</p> <p>Exemplo Pr\u00e1tico:</p> <pre><code>void setup() {\n    // Configura o pino 9 como sa\u00edda (usado pelo Timer1)\n    pinMode(9, OUTPUT);\n\n    // Configura Timer1 para Fast PWM mode\n    TCCR1A |= (1 &lt;&lt; COM1A1) | (1 &lt;&lt; WGM11);\n    TCCR1B |= (1 &lt;&lt; WGM13) | (1 &lt;&lt; WGM12) | (1 &lt;&lt; CS10); // Prescaler = 1\n    ICR1 = 19999; // Define frequ\u00eancia de 50Hz (usando 16MHz)\n\n    // Define o ciclo de trabalho (Duty Cycle) para 7.5% (posi\u00e7\u00e3o neutra)\n    OCR1A = 1500; // 1.5ms pulse width\n}\n\nvoid loop() {\n    // Pode ajustar OCR1A para alterar o ciclo de trabalho\n}\n</code></pre> <p>Explica\u00e7\u00e3o:</p> <ul> <li>Fast PWM Mode: Configura o timer para modo de PWM r\u00e1pido, permitindo uma frequ\u00eancia est\u00e1vel.</li> <li>ICR1: Define o per\u00edodo do PWM (por exemplo, 20ms para 50Hz).</li> <li>OCR1A: Define a largura do pulso, controlando o ciclo de trabalho.</li> <li>PWM Aplica\u00e7\u00e3o: Comumente usado para controlar servos ou LEDs com brilho ajust\u00e1vel.</li> </ul>"},{"location":"aulas/iot/modulos/modulo9.html#4-exemplos-praticos","title":"4. Exemplos Pr\u00e1ticos","text":""},{"location":"aulas/iot/modulos/modulo9.html#41-monitorando-um-sensor-com-interrupcao","title":"4.1 Monitorando um Sensor com Interrup\u00e7\u00e3o","text":"<pre><code>volatile float leituraSensor = 0.0;\n\nvoid sensorISR() {\n    leituraSensor = analogRead(A0);\n}\n\nvoid setup() {\n    Serial.begin(9600);\n    pinMode(2, INPUT_PULLUP); // Sensor conectado ao pino 2\n\n    attachInterrupt(digitalPinToInterrupt(2), sensorISR, FALLING);\n}\n\nvoid loop() {\n    if(leituraSensor &gt; 0) {\n        Serial.print(\"Leitura do Sensor: \");\n        Serial.println(leituraSensor);\n        leituraSensor = 0.0;\n    }\n}\n</code></pre> <p>Explica\u00e7\u00e3o:</p> <ul> <li><code>sensorISR</code>: ISR que l\u00ea o valor anal\u00f3gico do sensor quando ocorre uma interrup\u00e7\u00e3o no pino 2.</li> <li>Loop Principal: Verifica se uma nova leitura est\u00e1 dispon\u00edvel e a imprime no Monitor Serial.</li> </ul>"},{"location":"aulas/iot/modulos/modulo9.html#42-blink-com-timer1","title":"4.2 Blink com Timer1","text":"<pre><code>volatile bool toggle = false;\n\nISR(TIMER1_COMPA_vect) {\n    toggle = !toggle;\n}\n\nvoid setup() {\n    pinMode(13, OUTPUT);\n\n    // Configura Timer1 para CTC mode\n    TCCR1A = 0;\n    TCCR1B = 0;\n    TCCR1B |= (1 &lt;&lt; WGM12);\n\n    // Define valor de compara\u00e7\u00e3o para 1Hz\n    OCR1A = 15624;\n    TCCR1B |= (1 &lt;&lt; CS12) | (1 &lt;&lt; CS10); // Prescaler = 1024\n    TIMSK1 |= (1 &lt;&lt; OCIE1A); // Habilita interrup\u00e7\u00e3o\n\n    sei(); // Habilita interrup\u00e7\u00f5es globais\n}\n\nvoid loop() {\n    if(toggle) {\n        digitalWrite(13, HIGH);\n    } else {\n        digitalWrite(13, LOW);\n    }\n}\n</code></pre> <p>Explica\u00e7\u00e3o:</p> <ul> <li>ISR <code>TIMER1_COMPA_vect</code>: Alterna o estado da vari\u00e1vel <code>toggle</code> a cada segundo.</li> <li>Loop Principal: Liga ou desliga o LED conectado ao pino 13 com base no estado de <code>toggle</code>.</li> </ul>"},{"location":"aulas/iot/modulos/modulo9.html#5-exercicios-praticos","title":"5. Exerc\u00edcios Pr\u00e1ticos","text":""},{"location":"aulas/iot/modulos/modulo9.html#exercicio-1-contador-de-pulsos-com-interrupcao","title":"Exerc\u00edcio 1: Contador de Pulsos com Interrup\u00e7\u00e3o","text":"<ul> <li> <p>Tarefa: Crie um programa que conta o n\u00famero de pulsos recebidos em um pino espec\u00edfico usando interrup\u00e7\u00f5es e exibe o contador no Monitor Serial a cada segundo.</p> </li> <li> <p>Dicas:</p> </li> <li>Use Timer1 para criar uma interrup\u00e7\u00e3o a cada segundo.</li> <li> <p>Use uma ISR externa para contar os pulsos.</p> </li> <li> <p>Exemplo de C\u00f3digo:</p> </li> </ul> <pre><code>volatile unsigned int contadorPulsos = 0;\nvolatile bool atualizarDisplay = false;\n\n// ISR para contar pulsos no pino 2\nvoid pulseISR() {\n    contadorPulsos++;\n}\n\n// ISR para Timer1 a cada segundo\nISR(TIMER1_COMPA_vect) {\n    atualizarDisplay = true;\n}\n\nvoid setup() {\n    Serial.begin(9600);\n    pinMode(2, INPUT_PULLUP); // Pino de entrada para pulsos\n    attachInterrupt(digitalPinToInterrupt(2), pulseISR, RISING);\n\n    // Configura Timer1 para CTC mode\n    TCCR1A = 0;\n    TCCR1B = 0;\n    TCCR1B |= (1 &lt;&lt; WGM12);\n\n    OCR1A = 15624; // Para 1 segundo\n    TCCR1B |= (1 &lt;&lt; CS12) | (1 &lt;&lt; CS10); // Prescaler = 1024\n    TIMSK1 |= (1 &lt;&lt; OCIE1A); // Habilita interrup\u00e7\u00e3o por compara\u00e7\u00e3o\n\n    sei(); // Habilita interrup\u00e7\u00f5es globais\n}\n\nvoid loop() {\n    if(atualizarDisplay) {\n        Serial.print(\"Pulsos por segundo: \");\n        Serial.println(contadorPulsos);\n        contadorPulsos = 0;\n        atualizarDisplay = false;\n    }\n}\n</code></pre>"},{"location":"aulas/iot/modulos/modulo9.html#exercicio-2-pwm-controlado-por-timer","title":"Exerc\u00edcio 2: PWM Controlado por Timer","text":"<ul> <li> <p>Tarefa: Desenvolva um programa que ajusta a intensidade de um LED usando PWM controlado por Timer1, permitindo aumentar e diminuir o brilho a cada 500ms.</p> </li> <li> <p>Dicas:</p> </li> <li>Configure Timer1 para gerar PWM em um pino espec\u00edfico.</li> <li> <p>Use uma ISR para alterar o ciclo de trabalho periodicamente.</p> </li> <li> <p>Exemplo de C\u00f3digo:</p> </li> </ul> <pre><code>volatile int cicloTrabalho = 128; // Valor inicial (50%)\n\nISR(TIMER1_COMPA_vect) {\n    cicloTrabalho += 32;\n    if(cicloTrabalho &gt; 255) {\n        cicloTrabalho = 0;\n    }\n    OCR1A = cicloTrabalho;\n}\n\nvoid setup() {\n    pinMode(9, OUTPUT); // LED conectado ao pino 9\n\n    // Configura Timer1 para Fast PWM mode\n    TCCR1A |= (1 &lt;&lt; COM1A1) | (1 &lt;&lt; WGM11);\n    TCCR1B |= (1 &lt;&lt; WGM13) | (1 &lt;&lt; WGM12) | (1 &lt;&lt; CS12); // Prescaler = 256\n    ICR1 = 4999; // Define per\u00edodo para 500ms (supondo 16MHz)\n\n    OCR1A = cicloTrabalho; // Define ciclo de trabalho inicial\n\n    // Configura interrup\u00e7\u00e3o para alterar ciclo de trabalho\n    TIMSK1 |= (1 &lt;&lt; OCIE1A);\n    sei(); // Habilita interrup\u00e7\u00f5es globais\n}\n\nvoid loop() {\n    // N\u00e3o h\u00e1 c\u00f3digo no loop\n}\n</code></pre> <p>Explica\u00e7\u00e3o:</p> <ul> <li>ISR <code>TIMER1_COMPA_vect</code>: Incrementa o ciclo de trabalho do PWM a cada 500ms, alterando o brilho do LED.</li> <li>PWM no Pino 9: Controla a intensidade do LED usando PWM gerado pelo Timer1.</li> </ul>"},{"location":"aulas/iot/modulos/modulo9.html#exercicio-3-debounce-de-botao-com-interrupcao","title":"Exerc\u00edcio 3: Debounce de Bot\u00e3o com Interrup\u00e7\u00e3o","text":"<ul> <li> <p>Tarefa: Implemente um sistema que detecta pressionamentos de bot\u00e3o usando interrup\u00e7\u00f5es, com debounce para evitar m\u00faltiplas detec\u00e7\u00f5es indesejadas.</p> </li> <li> <p>Dicas:</p> </li> <li>Use uma vari\u00e1vel para armazenar o \u00faltimo tempo de interrup\u00e7\u00e3o.</li> <li> <p>Ignore interrup\u00e7\u00f5es que ocorram muito pr\u00f3ximas umas das outras.</p> </li> <li> <p>Exemplo de C\u00f3digo:</p> </li> </ul> <pre><code>volatile bool botaoPressionado = false;\nunsigned long ultimoTempo = 0;\nconst unsigned long debounceDelay = 200; // 200ms\n\nvoid botaoISR() {\n    unsigned long tempoAtual = millis();\n    if (tempoAtual - ultimoTempo &gt; debounceDelay) {\n        botaoPressionado = true;\n        ultimoTempo = tempoAtual;\n    }\n}\n\nvoid setup() {\n    Serial.begin(9600);\n    pinMode(2, INPUT_PULLUP); // Bot\u00e3o conectado ao pino 2\n    attachInterrupt(digitalPinToInterrupt(2), botaoISR, FALLING);\n}\n\nvoid loop() {\n    if(botaoPressionado) {\n        Serial.println(\"Bot\u00e3o pressionado!\");\n        botaoPressionado = false;\n    }\n}\n</code></pre> <p>Explica\u00e7\u00e3o:</p> <ul> <li>Debounce: Garante que apenas press\u00f5es de bot\u00e3o com intervalo maior que <code>debounceDelay</code> sejam consideradas v\u00e1lidas.</li> <li>ISR <code>botaoISR</code>: Marca que o bot\u00e3o foi pressionado se o debounce permitir.</li> </ul>"},{"location":"aulas/iot/modulos/modulo9.html#6-conceitos-importantes","title":"6. Conceitos Importantes","text":""},{"location":"aulas/iot/modulos/modulo9.html#61-isr-interrupt-service-routine","title":"6.1 ISR (Interrupt Service Routine)","text":"<ul> <li>Defini\u00e7\u00e3o: Fun\u00e7\u00f5es que s\u00e3o chamadas automaticamente em resposta a interrup\u00e7\u00f5es.</li> <li>Caracter\u00edsticas:</li> <li>N\u00e3o podem retornar valores.</li> <li>Devem ser r\u00e1pidas e eficientes.</li> <li>Devem evitar o uso de fun\u00e7\u00f5es que dependem de interrup\u00e7\u00f5es, como <code>Serial.print()</code>.</li> </ul>"},{"location":"aulas/iot/modulos/modulo9.html#62-aritmetica-de-ponteiros-e-timers","title":"6.2 Aritm\u00e9tica de Ponteiros e Timers","text":"<ul> <li>Aritm\u00e9tica de Ponteiros: Permite navegar por arrays e estruturas de dados de forma eficiente.</li> <li>Timers: Facilitam a cria\u00e7\u00e3o de temporiza\u00e7\u00f5es precisas e a gera\u00e7\u00e3o de sinais PWM.</li> </ul>"},{"location":"aulas/iot/modulos/modulo9.html#63-gerenciamento-de-tempo","title":"6.3 Gerenciamento de Tempo","text":"<ul> <li>Uso de Timers e <code>millis()</code>: Evita o bloqueio do loop principal, permitindo a execu\u00e7\u00e3o de m\u00faltiplas tarefas simultaneamente.</li> <li>Compara\u00e7\u00e3o com <code>delay()</code>: <code>delay()</code> bloqueia a execu\u00e7\u00e3o, enquanto timers e interrup\u00e7\u00f5es permitem um controle mais granular e eficiente.</li> </ul>"},{"location":"aulas/iot/modulos/modulo9.html#64-boas-praticas-com-interrupcoes-e-timers","title":"6.4 Boas Pr\u00e1ticas com Interrup\u00e7\u00f5es e Timers","text":"<ul> <li>Minimize o C\u00f3digo nas ISRs: Execute apenas o essencial dentro das ISRs para evitar atrasos no processamento.</li> <li>Evite Vari\u00e1veis Complexas: Use vari\u00e1veis simples e do tipo <code>volatile</code> para comunica\u00e7\u00e3o entre ISRs e o loop principal.</li> <li>Gerencie a Mem\u00f3ria dos Timers: Configure corretamente os timers para evitar conflitos e sobrecargas.</li> </ul>"},{"location":"aulas/iot/modulos/modulo9.html#7-recursos-adicionais","title":"7. Recursos Adicionais","text":"<ul> <li> <p>Documenta\u00e7\u00e3o Oficial do Arduino:</p> </li> <li> <p>Interrup\u00e7\u00f5es</p> </li> <li> <p>Timers</p> </li> <li> <p>Tutoriais e Guias:</p> </li> <li> <p>Guia Completo de Interrup\u00e7\u00f5es no Arduino</p> </li> <li> <p>Manipula\u00e7\u00e3o Avan\u00e7ada de Timers</p> </li> <li> <p>V\u00eddeos Educacionais:</p> </li> <li> <p>Entendendo Interrup\u00e7\u00f5es no Arduino</p> </li> <li>Timers e PWM Avan\u00e7ados</li> </ul>"},{"location":"aulas/iot/modulos/modulo9.html#8-exercicios-praticos","title":"8. Exerc\u00edcios Pr\u00e1ticos","text":""},{"location":"aulas/iot/modulos/modulo9.html#exercicio-1-led-pisca-com-timer-e-interrupcao","title":"Exerc\u00edcio 1: LED Pisca com Timer e Interrup\u00e7\u00e3o","text":"<ul> <li> <p>Tarefa: Crie um programa que faz um LED piscar a cada 250ms usando Timer1 e uma interrup\u00e7\u00e3o.</p> </li> <li> <p>Dicas:</p> </li> <li>Configure Timer1 para gerar interrup\u00e7\u00f5es a cada 250ms.</li> <li> <p>Use uma ISR para alternar o estado do LED.</p> </li> <li> <p>Exemplo de C\u00f3digo:</p> </li> </ul> <pre><code>volatile bool ledEstado = false;\n\nISR(TIMER1_COMPA_vect) {\n    ledEstado = !ledEstado;\n}\n\nvoid setup() {\n    pinMode(13, OUTPUT);\n    // Configura Timer1 para CTC mode\n    TCCR1A = 0;\n    TCCR1B = 0;\n    TCCR1B |= (1 &lt;&lt; WGM12);\n\n    OCR1A = 3906; // Para 250ms (16MHz / (Prescaler * Desired Frequency)) - 1\n    TCCR1B |= (1 &lt;&lt; CS12) | (1 &lt;&lt; CS10); // Prescaler = 1024\n    TIMSK1 |= (1 &lt;&lt; OCIE1A); // Habilita interrup\u00e7\u00e3o por compara\u00e7\u00e3o\n\n    sei(); // Habilita interrup\u00e7\u00f5es globais\n}\n\nvoid loop() {\n    digitalWrite(13, ledEstado ? HIGH : LOW);\n}\n</code></pre>"},{"location":"aulas/iot/modulos/modulo9.html#exercicio-2-leitura-de-sensor-com-interrupcao","title":"Exerc\u00edcio 2: Leitura de Sensor com Interrup\u00e7\u00e3o","text":"<ul> <li> <p>Tarefa: Desenvolva um programa que l\u00ea um valor de sensor sempre que um bot\u00e3o \u00e9 pressionado, usando interrup\u00e7\u00f5es para detectar o pressionamento.</p> </li> <li> <p>Dicas:</p> </li> <li>Use uma ISR externa para detectar o bot\u00e3o.</li> <li> <p>Armazene o valor do sensor em uma vari\u00e1vel <code>volatile</code>.</p> </li> <li> <p>Exemplo de C\u00f3digo:</p> </li> </ul> <pre><code>volatile bool lerSensor = false;\nvolatile int valorSensor = 0;\n\nvoid botaoISR() {\n    lerSensor = true;\n}\n\nvoid setup() {\n    Serial.begin(9600);\n    pinMode(2, INPUT_PULLUP); // Bot\u00e3o conectado ao pino 2\n    attachInterrupt(digitalPinToInterrupt(2), botaoISR, FALLING);\n}\n\nvoid loop() {\n    if(lerSensor) {\n        valorSensor = analogRead(A0);\n        Serial.print(\"Valor do Sensor: \");\n        Serial.println(valorSensor);\n        lerSensor = false;\n    }\n}\n</code></pre>"},{"location":"aulas/iot/modulos/modulo9.html#exercicio-3-controlar-servo-com-timer-e-interrupcao","title":"Exerc\u00edcio 3: Controlar Servo com Timer e Interrup\u00e7\u00e3o","text":"<ul> <li> <p>Tarefa: Implemente um sistema que controla a posi\u00e7\u00e3o de um servo motor utilizando Timer1 e interrup\u00e7\u00f5es para ajustar a posi\u00e7\u00e3o a cada 500ms.</p> </li> <li> <p>Dicas:</p> </li> <li>Use uma ISR para alterar o \u00e2ngulo do servo.</li> <li> <p>Utilize a biblioteca <code>Servo</code> para facilitar o controle do servo.</p> </li> <li> <p>Exemplo de C\u00f3digo:</p> </li> </ul> <pre><code>#include &lt;Servo.h&gt;\n\nServo meuServo;\nvolatile int angulo = 0;\n\nISR(TIMER1_COMPA_vect) {\n    angulo += 10;\n    if(angulo &gt; 180) {\n        angulo = 0;\n    }\n    meuServo.write(angulo);\n}\n\nvoid setup() {\n    meuServo.attach(9); // Servo conectado ao pino 9\n    meuServo.write(angulo);\n\n    // Configura Timer1 para CTC mode\n    TCCR1A = 0;\n    TCCR1B = 0;\n    TCCR1B |= (1 &lt;&lt; WGM12);\n\n    OCR1A = 15624; // Para 1 segundo\n    TCCR1B |= (1 &lt;&lt; CS12) | (1 &lt;&lt; CS10); // Prescaler = 1024\n    TIMSK1 |= (1 &lt;&lt; OCIE1A); // Habilita interrup\u00e7\u00e3o por compara\u00e7\u00e3o\n\n    sei(); // Habilita interrup\u00e7\u00f5es globais\n}\n\nvoid loop() {\n    // N\u00e3o h\u00e1 c\u00f3digo no loop\n}\n</code></pre>"},{"location":"aulas/iot/modulos/modulo9.html#9-conceitos-importantes","title":"9. Conceitos Importantes","text":""},{"location":"aulas/iot/modulos/modulo9.html#91-variaveis-volateis","title":"9.1 Vari\u00e1veis Vol\u00e1teis","text":"<ul> <li>Defini\u00e7\u00e3o: Vari\u00e1veis declaradas como <code>volatile</code> informam ao compilador que seu valor pode mudar a qualquer momento, prevenindo otimiza\u00e7\u00f5es que poderiam ignorar atualiza\u00e7\u00f5es provenientes de ISRs.</li> </ul> <pre><code>volatile int contador = 0;\n</code></pre>"},{"location":"aulas/iot/modulos/modulo9.html#92-prioridade-de-interrupcoes","title":"9.2 Prioridade de Interrup\u00e7\u00f5es","text":"<ul> <li>Defini\u00e7\u00e3o: Em sistemas com m\u00faltiplas interrup\u00e7\u00f5es, a prioridade determina qual ISR ser\u00e1 executada primeiro.</li> <li>Considera\u00e7\u00f5es:</li> <li>No Arduino, todas as interrup\u00e7\u00f5es t\u00eam a mesma prioridade.</li> <li>Planeje o uso de interrup\u00e7\u00f5es de forma que n\u00e3o haja conflito entre diferentes ISRs.</li> </ul>"},{"location":"aulas/iot/modulos/modulo9.html#93-uso-de-funcoes-nas-isrs","title":"9.3 Uso de Fun\u00e7\u00f5es nas ISRs","text":"<ul> <li>Limita\u00e7\u00f5es: Evite usar fun\u00e7\u00f5es que n\u00e3o sejam seguras para serem chamadas dentro de uma ISR, como <code>Serial.print()</code>.</li> <li>Alternativas: Utilize flags (<code>bool</code>) para indicar ao loop principal que uma a\u00e7\u00e3o deve ser executada.</li> </ul>"},{"location":"aulas/iot/modulos/modulo9.html#94-configuracao-correta-dos-timers","title":"9.4 Configura\u00e7\u00e3o Correta dos Timers","text":"<ul> <li>Import\u00e2ncia: Configura\u00e7\u00f5es incorretas dos timers podem levar a temporiza\u00e7\u00f5es erradas ou ao n\u00e3o funcionamento das interrup\u00e7\u00f5es.</li> <li>Verifique:</li> <li>Modo de opera\u00e7\u00e3o (CTC, Fast PWM, etc.).</li> <li>Prescaler adequado para a temporiza\u00e7\u00e3o desejada.</li> <li>Valores de compara\u00e7\u00e3o (<code>OCRnA</code>).</li> </ul>"},{"location":"aulas/iot/modulos/modulo9.html#95-boas-praticas-com-interrupcoes-e-timers","title":"9.5 Boas Pr\u00e1ticas com Interrup\u00e7\u00f5es e Timers","text":"<ul> <li>Evite Loops Longos nas ISRs: Mantenha as ISRs curtas e r\u00e1pidas.</li> <li>Use Vari\u00e1veis Vol\u00e1teis para Comunica\u00e7\u00e3o: Utilize vari\u00e1veis <code>volatile</code> para comunicar eventos entre ISRs e o loop principal.</li> <li>Gerencie a Prioridade e Frequ\u00eancia de Interrup\u00e7\u00f5es: Planeje a frequ\u00eancia de interrup\u00e7\u00f5es para evitar sobrecarga no processador.</li> </ul>"},{"location":"aulas/iot/modulos/modulo9.html#10-recursos-adicionais","title":"10. Recursos Adicionais","text":"<ul> <li> <p>Documenta\u00e7\u00e3o Oficial do Arduino:</p> </li> <li> <p>Interrup\u00e7\u00f5es</p> </li> <li> <p>Timers</p> </li> <li> <p>Tutoriais e Guias:</p> </li> <li> <p>Guia Completo de Interrup\u00e7\u00f5es no Arduino</p> </li> <li> <p>Manipula\u00e7\u00e3o Avan\u00e7ada de Timers</p> </li> <li> <p>V\u00eddeos Educacionais:</p> </li> <li> <p>Entendendo Interrup\u00e7\u00f5es no Arduino</p> </li> <li>Timers e PWM Avan\u00e7ados</li> </ul>"},{"location":"aulas/iot/modulos/modulo9.html#11-conclusao-do-modulo","title":"11. Conclus\u00e3o do M\u00f3dulo","text":"<p>Neste m\u00f3dulo, voc\u00ea aprendeu:</p> <ul> <li>O que s\u00e3o interrup\u00e7\u00f5es e timers e sua import\u00e2ncia na programa\u00e7\u00e3o Arduino.</li> <li>Como configurar e utilizar interrup\u00e7\u00f5es externas para reagir a eventos ass\u00edncronos.</li> <li>Como configurar e utilizar timers para criar temporiza\u00e7\u00f5es precisas e gerar sinais PWM.</li> <li>Boas pr\u00e1ticas para implementar ISRs eficientes e seguras.</li> <li>Como integrar interrup\u00e7\u00f5es e timers em projetos reais para melhorar a responsividade e efici\u00eancia.</li> <li>Praticou com exemplos e exerc\u00edcios que refor\u00e7am o entendimento das interrup\u00e7\u00f5es e timers.</li> </ul> <p>Voc\u00ea est\u00e1 agora preparado para avan\u00e7ar para o pr\u00f3ximo m\u00f3dulo, onde exploraremos Comunica\u00e7\u00e3o Serial Avan\u00e7ada, aprofundando seu conhecimento em protocolos de comunica\u00e7\u00e3o e troca de dados entre dispositivos Arduino e computadores.</p>"},{"location":"aulas/iot/modulos/modulo9.html#12-proximos-passos","title":"12. Pr\u00f3ximos Passos","text":"<ul> <li>Revisar o conte\u00fado deste m\u00f3dulo e certificar-se de que compreendeu os conceitos apresentados.</li> <li>Completar os exerc\u00edcios propostos para consolidar o aprendizado.</li> <li>Preparar-se para o M\u00f3dulo 10: Comunica\u00e7\u00e3o Serial Avan\u00e7ada.</li> </ul> <p>Se tiver d\u00favidas ou precisar de assist\u00eancia, n\u00e3o hesite em procurar recursos adicionais ou participar de comunidades de aprendizagem para obter suporte.</p> <p>Bom trabalho e continue assim!</p>"},{"location":"aulas/iot/modulos/modulos.html","title":"Modulos","text":""},{"location":"aulas/iot/modulos/modulos.html#programacao-em-arduino-conceitos-fundamentais","title":"Programa\u00e7\u00e3o em Arduino - Conceitos Fundamentais","text":"<p>Este curso b\u00e1sico de Programa\u00e7\u00e3o em Arduino focado nos conceitos da programa\u00e7\u00e3o C/C++.</p> <p>N\u00e3o \u00e9 necess\u00e1rio placa Arduino, utilize o simulador www.wokwi.com para realizar exercicios dos m\u00f3dulos.</p> <p>O curso est\u00e1 dividido em m\u00f3dulos que apresentam conceitos da linguagem C/C++ e sua aplica\u00e7\u00e3o na programa\u00e7\u00e3o Arduino.</p>"},{"location":"aulas/iot/modulos/modulos.html#sumario-do-curso","title":"Sum\u00e1rio do Curso","text":"<ul> <li>M\u00f3dulo 1: Introdu\u00e7\u00e3o ao Arduino</li> <li>M\u00f3dulo 2: Operadores e Express\u00f5es</li> <li>M\u00f3dulo 3: Estruturas de Controle de Fluxo</li> <li>M\u00f3dulo 4: Fun\u00e7\u00f5es e Modulariza\u00e7\u00e3o</li> <li>M\u00f3dulo 5: Arrays e Manipula\u00e7\u00e3o de Dados</li> <li>M\u00f3dulo 6: Strings e Opera\u00e7\u00f5es com Texto</li> <li>M\u00f3dulo 7: Ponteiros e Refer\u00eancias</li> <li>M\u00f3dulo 8: Estruturas (Structs) e Classes</li> </ul>"},{"location":"checkpoint/index.html","title":"CHECKPOINTS","text":""},{"location":"checkpoint/index.html#atencao","title":"Aten\u00e7\u00e3o","text":"<ul> <li> <p>Cuidado com a desonestidade intelectual;</p> </li> <li> <p>AUTO AVALIA\u00c7\u00c3O: Uma auto avalia\u00e7\u00e3o n\u00e3o compat\u00edvel com o material entregue ser\u00e1 interpretada como desonestidade intelectual;</p> </li> <li> <p>PL\u00c1GIO: Atividades que envolvem pesquisas na Internet podem ser enriquecidas com cita\u00e7\u00f5es de v\u00e1rias fontes. No entanto, sempre que utilizar textos ou mesmo imagens que n\u00e3o sejam seus, seu trabalho deve ser acompanhado com um trecho de \u201crefer\u00eancias\u201d. Bastam os hiperlinks utilizados;</p> </li> <li> <p>COLA DE TRABALHOS: N\u00e3o \u00e9 permitida a troca de trabalhos entre os grupos, cada grupo \u00e9 respons\u00e1vel pelo desenvolvimento intelectual do projeto. N\u00e3o copie e entregue o trabalho de outro colega e n\u00e3o permita ser copiado. Atividades duplicadas resultar\u00e3o na anula\u00e7\u00e3o de ambas.</p> </li> </ul>"},{"location":"checkpoint/index.html#como-funcionam-os-checkpoints","title":"COMO FUNCIONAM OS CHECKPOINTS","text":"<p>Leia com aten\u00e7\u00e3o as orienta\u00e7\u00f5es gerais sobre os checkponts</p>"},{"location":"checkpoint/index.html#o-que-e","title":"O que \u00e9:","text":"<p>Os Checkpoints da disciplina s\u00e3o baseados em pequenos projetos com o objetivo de avaliar os conceitos adquiridos dos conte\u00fados ministrados em aula. </p>"},{"location":"checkpoint/index.html#quando-sera","title":"Quando ser\u00e1:","text":"<p>Os checkpoints s\u00e3o sempre divulgados/publicados com anteced\u00eancia (ver agenda das aulas) nesta p\u00e1gina e devem ser realizadas fora do hor\u00e1rio de aula.</p>"},{"location":"checkpoint/index.html#onde-sera","title":"Onde ser\u00e1:","text":"<p>O projeto ser\u00e1 feito no github classroom. O estudante ir\u00e1 receber um link para um reposit\u00f3rio privado no github, \u00e9 neste reposit\u00f3rio que o estudante dever\u00e1 fazer os commits com o desenvolvimento do projeto. </p>"},{"location":"checkpoint/index.html#como-desenvolver-o-projeto","title":"Como desenvolver o projeto:","text":"<p>Existe uma rubrica de nota definida pelo professor e publicada junto com o desafio que o estudante deve seguir. Esta rubrica foi pensada para guiar o desenvolvimento do estudante.</p>"},{"location":"checkpoint/index.html#hora-de-entregar-checkpoint","title":"Hora de entregar checkpoint:","text":"<p>O checkpoint n\u00e3o \u00e9 realizado em sala de aula.</p> <p>O estudante deve realizar a entrega ANTES da data definida para avalia\u00e7\u00e3o do checkpoint.</p> <p>No momento da entrega, o estudante ir\u00e1 responder um question\u00e1rio (google forms) de auto-avalia\u00e7\u00e3o destacando o que foi implementado.</p>"},{"location":"checkpoint/index.html#como-sera-avaliado","title":"Como ser\u00e1 avaliado:","text":"<p>A avalia\u00e7\u00e3o do checkpoint ser\u00e1 feita em sala de aula na data definida na agenda e de forma individual (professor e 1 estudante por vez) onde cada estudante dever\u00e1 demonstrar a evolu\u00e7\u00e3o do seu projeto do github, o question\u00e1rio de auto-avalia\u00e7\u00e3o respondido pelo aluno ser\u00e1 utilizado pelo professor.</p>"},{"location":"checkpoint/index.html#o-que-devo-fazer-agora","title":"O que devo fazer agora??","text":"<p>Aguarde a libera\u00e7\u00e3o do CHECKPOINT...</p>"},{"location":"checkpoint/cp-ml.html","title":"Cp ml","text":"<p>CheckPonint - Estudo de Caso</p>"},{"location":"checkpoint/cp-ml.html#desafio-4-si","title":"Desafio 4 SI","text":"<p>Desenvolver uma solu\u00e7\u00e3o ao desafio proposto.  </p> <ul> <li>Material dispon\u00edvel pelo TEAMS nos arquivo <code>solicitacoescredito.csv</code>. e <code>CP-4SI-24.pdf</code> </li> </ul>"},{"location":"checkpoint/cp-ml.html#dinamicas-das-proximas-aulas","title":"Din\u00e2micas das pr\u00f3ximas aulas","text":"<ul> <li>Aula:<ul> <li>Teoria: Abordando os conceitos </li> <li>Pr\u00e1tica: Exerc\u00edcios de fixa\u00e7\u00e3o</li> <li>Estudio: Est\u00fadio para desenvolvimento do projeto.</li> </ul> </li> </ul>"},{"location":"checkpoint/cp-ml.html#feedback","title":"Feedback","text":"<p>Os grupos que quiserem podem solicitar feedback de acompanhamento do projeto.</p>"},{"location":"checkpoint/cp-ml.html#composicao-da-nota-final","title":"Composi\u00e7\u00e3o da nota final","text":"Data Crit\u00e9rio Nota Aprsenta\u00e7\u00e3o Apresenta\u00e7\u00e3o (at\u00e9 2 pontos) e argui\u00e7\u00e3o (individual at\u00e9 3 pontos) 0 - 5 pontos Aprsenta\u00e7\u00e3o Avalia\u00e7\u00e3o da Documenta\u00e7\u00e3o t\u00e9cnica do projeto  (Qualidade t\u00e9cnica de c\u00f3digo e organiza\u00e7\u00e3o do reposit\u00f3rio github) 0 - 5 pontos <ul> <li>A nota \u00e9 composta de <code>Apresenta\u00e7\u00e3o e argui\u00e7\u00e3o do projeto</code> + <code>valida\u00e7\u00e3o da Documenta\u00e7\u00e3o t\u00e9cnica do projeto</code>.</li> </ul>"},{"location":"checkpoint/cp.html","title":"CHECKPOINT 5","text":"<ul> <li>O objetivo do checkpoint \u00e9 avaliar a compreens\u00e3o dos estudantes em rela\u00e7\u00e3o ao conte\u00fado ministrado pela disciplina.</li> </ul> <p>Obrigat\u00f3rio utilizar como base o c\u00f3digo de exemplo do jogo da mem\u00f3ria dispon\u00edvel:</p> <ul> <li>C\u00f3digo base Jogo da Mem\u00f3ria</li> <li>Wokwi Jogo da Mem\u00f3ria</li> </ul> <p>Materiais Necess\u00e1rios:</p> <ul> <li>\u25b6\ufe0f Arduino UNO</li> <li>\u25b6\ufe0f LEDs</li> <li>\u25b6\ufe0f Bot\u00f5es</li> <li>\u25b6\ufe0f Buzzer</li> <li>\u25b6\ufe0f Resistores, jumpers e protoboard</li> </ul>"},{"location":"checkpoint/cp.html#ideia-geral","title":"Ideia Geral","text":"<p>Neste checkpoint, o desafio \u00e9 desenvolver o prot\u00f3tipo do jogo da mem\u00f3ria \"Genius\" com Arduino, com as seguintes caracter\u00edsticas:</p> <ul> <li>4 (ou mais) LEDs de cores diferentes</li> <li>4 (ou mais) Bot\u00f5es</li> <li>1 Buzzer</li> <li>Possuir Interface de comunica\u00e7\u00e3o serial</li> </ul> <p>Vamos explorar mais detalhadamente o funcionamento do prot\u00f3tipo e os crit\u00e9rios de avalia\u00e7\u00e3o.</p>"},{"location":"checkpoint/cp.html#genius-arduino","title":"Genius Arduino","text":"<p>O jogo tem a din\u00e2mica padr\u00e3o de qualquer outro jogo da mem\u00f3ria: Inicia-se o game, os LEDs piscam em sequ\u00eancia aleat\u00f3ria, e o jogador precisa reproduzir essa sequ\u00eancia pressionando os bot\u00f5es correspondentes. Acertando, avan\u00e7a para o pr\u00f3ximo n\u00edvel; errando, \u00e9 o fim do jogo.</p>"},{"location":"checkpoint/cp.html#atencao-aos-requisitos-funcionais","title":"Aten\u00e7\u00e3o aos requisitos funcionais","text":"<p>Requisitos Funcionais B\u00e1sicos:</p> <ul> <li>LEDs: O jogo deve possuir 4 LEDs de cores diferentes.</li> <li>Bot\u00f5es: O jogo deve possuir 4 bot\u00f5es, cada bot\u00e3o corresponde a um LED.</li> <li> <p>Buzzer: O jogo deve possuir 1 Buzzer que deve emitir uma frequ\u00eancia espec\u00edfica (nota musical) para cada cor de LED, tanto na sequ\u00eancia aleat\u00f3ria quanto ao pressionar das teclas.</p> </li> <li> <p>FASES DO JOGO: O jogo deve possuir 4 fases.</p> </li> <li>Monitor Serial: O jogo deve possuir permitir ao usu\u00e1rio jogar tanto pelos bot\u00f5es f\u00edsicos quanto pelo monitor serial do Arduino.</li> </ul> <p>Requisitos Funcionais Avan\u00e7ados:</p> <ul> <li>FASES DO JOGO: O jogo deve possuir uma quantidade \"infinita\" de niveis de dificuldade.</li> <li>Nivel de dificuldade Crie a fun\u00e7\u00e3o <code>nivelDificuldade</code> que implementa a sele\u00e7\u00e3o de dificuldade do jogo em iniciante, m\u00e9dio e hard. Essa fun\u00e7\u00e3o altera a velocidade com que os leds piscam.</li> <li>Salvar Pontua\u00e7\u00f5es Usar uma mem\u00f3ria EEPROM no Arduino para salvar as pontua\u00e7\u00f5es mais altas, permitindo que os jogadores vejam e tentem superar seus recordes anteriores.</li> <li>Comunica\u00e7\u00e3o Bluetooth: Fa\u00e7a a comunica\u00e7\u00e3o via bluetooth com o notebook ou celular para jogar o jogo.</li> <li>Interface persolnalizada O jogo possui uma interface GUI personalizada que substitui o monitor serial da IDE do Arduino. Pode usar bibliotecas em Python (Tkinter, Streamlit, Flet) ou desenvolver em outra linguagem (C++, C#, Dart, Java, etc.).</li> <li>Comando de Voz: Atrav\u00e9s de um script em Python, ao receber a informa\u00e7\u00e3o da cor, o computador anuncia em voz alta a cor acionada.</li> <li>Vis\u00e3o Computacional: Atrav\u00e9s de um script em Python, utiliza o opencv para jogar com a webcam.</li> <li>Modo Multiplayer Implementar um modo de jogo para dois ou mais jogadores, onde eles se revezam e competem por pontua\u00e7\u00f5es mais altas.</li> <li>Feedback Sonoro Avan\u00e7ado Implementar melodias ou sons mais complexos para feedback ao jogador.</li> <li>OUTRAS FEATURES: O grupo pode propor outras features avan\u00e7adas, mas deve ser aprovado pelo professor.</li> </ul> <p>"},{"location":"checkpoint/cp.html#construindo-uma-caixa-personalizada","title":"Construindo uma Caixa Personalizada:","text":"<ul> <li>Caixa: Utilize o site https://www.festi.info/boxes.py/ para criar uma caixa personalizada para o seu prot\u00f3tipo, de forma simples, online e gratuita.</li> </ul> <p>Links \u00fateis para criar seu case:</p> <ul> <li>Manual do Mundo</li> <li>Angelo Conti</li> <li>Maker Space 307</li> <li>Smoke &amp; Mirrors</li> </ul> <ul> <li>Especifica\u00e7\u00f5es para M\u00e1quina CNC: Selecione a espessura de 3mm para o MDF.</li> </ul> <p></p>"},{"location":"checkpoint/cp.html#rubrica","title":"Rubrica:","text":"Nota Itens 4 Atende aos requisitos funcionais b\u00e1sicos 6 Atende aos requisitos funcionais b\u00e1sicos + caixa personalizada + implementa 1 requisito funcional avan\u00e7ado 7 Atende aos requisitos funcionais b\u00e1sicos  + caixa personalizada + implementa 2 requisitos funcionais avan\u00e7ados 8 Atende aos requisitos funcionais b\u00e1sicos  + caixa personalizada + implementa 3 requisitos funcionais avan\u00e7ados 9 Atende aos requisitos funcionais b\u00e1sicos  + caixa personalizada + implementa 4 requisitos funcionais avan\u00e7ados 10 Atende aos requisitos funcionais b\u00e1sicos + implementa 5 ou mais requisitos funcionais avan\u00e7ados"},{"location":"checkpoint/cp1.html","title":"CHECKPOINT 1","text":"<ul> <li>Leia com aten\u00e7\u00e3o as instru\u00e7\u00f5es gerais sobre checkpoint;</li> <li>clique aqui no link para criar uma c\u00f3pia do repo. do CP em seu github;</li> <li>Leia com aten\u00e7\u00e3o as intru\u00e7\u00f5es do CP e desenvolva o projeto;</li> <li>O estudante deve realizar a entrega ANTES da data definida para avalia\u00e7\u00e3o do checkpoint;</li> <li>O CP \u00e9 em dupla. O primeiro estudante cria o grupo e o segundo estudante acessa o grupo criado.</li> </ul> CP1 link Reposit\u00f3rio https://classroom.github.com/a/4x4sqhyD"},{"location":"checkpoint/cp2.html","title":"Cp2","text":""},{"location":"checkpoint/cp2.html#desafio-de-visao-computacional","title":"Desafio de Vis\u00e3o Computacional","text":"<p>Mini Projeto de Vis\u00e3o Computacional aplicado.</p>"},{"location":"checkpoint/cp2.html#atualizacao-da-data-de-apresentacao","title":"ATUALIZA\u00c7\u00c3O DA DATA DE APRESENTA\u00c7\u00c3O","text":""},{"location":"checkpoint/cp2.html#considerar-a-data-de-apresentacao-do-projeto-dia-2305","title":"CONSIDERAR A DATA DE APRESENTA\u00c7\u00c3O DO PROJETO DIA <code>23/05</code>.","text":""},{"location":"checkpoint/cp2.html#objetivo-do-projeto","title":"Objetivo do Projeto:","text":"<p>Desenvolver uma aplica\u00e7\u00e3o pr\u00e1tica e inovadora de vis\u00e3o computacional que possa ser aplicada em v\u00eddeos em tempo real.  A aplica\u00e7\u00e3o deve abordar um problema relevante em uma das seguintes \u00e1reas: jogos, entretenimento, sa\u00fade, bem-estar, agricultura ou  seguran\u00e7a p\u00fablica.</p>"},{"location":"checkpoint/cp2.html#requisitos","title":"Requisitos:","text":"<ul> <li> <p>A solu\u00e7\u00e3o deve ser <code>original e n\u00e3o trivial</code>, demonstrando um entendimento profundo e uma aplica\u00e7\u00e3o criativa das t\u00e9cnicas de vis\u00e3o computacional.</p> </li> <li> <p>Implementa\u00e7\u00e3o em Python e seus frameworks como OpenCV, Tensorflow entre outros.</p> </li> <li> <p>Espera-se que os grupos:</p> <ul> <li>Desenvolvam uma abordagem \u00fanica para o problema escolhido, n\u00e3o pode ser c\u00f3pia direta de solu\u00e7\u00f5es existentes.</li> <li>Mostrem capacidade de integrar e adaptar conceitos de vis\u00e3o computacional para atender \u00e0s necessidades espec\u00edficas do projeto.</li> <li>Demonstrem habilidade em inovar e pensar criticamente sobre como as t\u00e9cnicas de vis\u00e3o computacional podem ser aplicadas de maneiras novas e eficazes.</li> </ul> </li> <li> <p><code>Importante</code>: N\u00e3o ser\u00e1 aceita a simples replica\u00e7\u00e3o de projetos prontos, incluindo o uso de prompts de GPT e outras intelig\u00eancias artificiais generativas sem adapta\u00e7\u00e3o significativa e contribui\u00e7\u00e3o pr\u00f3pria. </p> </li> <li> <p>A aplica\u00e7\u00e3o deve ser capaz de processar v\u00eddeos em tempo real, e/ou usando uma webcam.</p> </li> </ul>"},{"location":"checkpoint/cp2.html#criterios-de-avaliacao","title":"Crit\u00e9rios de Avalia\u00e7\u00e3o:","text":"<ul> <li>Inova\u00e7\u00e3o e criatividade na escolha e abordagem do problema.</li> <li>Efici\u00eancia e precis\u00e3o da solu\u00e7\u00e3o de vis\u00e3o computacional em tempo real.</li> <li>Qualidade t\u00e9cnica de documenta\u00e7\u00e3o e c\u00f3digo e funcionalidade do projeto.</li> <li>Apresenta\u00e7\u00e3o e comunica\u00e7\u00e3o das ideias e resultados.</li> </ul>"},{"location":"checkpoint/cp2.html#dinamicas-das-proximas-aulas","title":"Dinamicas das pr\u00f3ximas aulas:","text":"<ul> <li> <p>1a aula: Demonstra\u00e7\u00e3o de novas t\u00e9cnicas de Vis\u00e3o Computacional, baseada nos laborat\u00f3rios da disciplina.</p> <ul> <li>Os laborat\u00f3rios continuam com as entregas semanais e valer\u00e3o nota <code>B\u00f4nus</code> de participa\u00e7\u00e3o para quem fizer e entregar via atividade do Teams.</li> </ul> </li> <li> <p>2a aula: Aula est\u00fadio para desenvolvimento do projeto.</p> <ul> <li>Entregas de acompanhamento semanal com feedback do projeto, via github.</li> </ul> </li> </ul>"},{"location":"checkpoint/cp2.html#feedback-continuo","title":"Feedback Cont\u00ednuo:","text":"<p>Os grupos receber\u00e3o feedback ap\u00f3s cada atualiza\u00e7\u00e3o do GitHub por meio de issues que ser\u00e3o abertas, e que valer\u00e3o parte da nota final a cada semana,  para garantir que estejam no caminho certo e para ajudar na resolu\u00e7\u00e3o de quaisquer problemas t\u00e9cnicos ou conceituais.</p>"},{"location":"checkpoint/cp2.html#acompanhamento-semanal","title":"Acompanhamento semanal","text":"Data Atividade Nota parcial 11/04 Reposit\u00f3rio GitHub: Inclui README claro, defini\u00e7\u00e3o de projeto bem articulada, <code>rubrica de avalia\u00e7\u00e3o</code> realista e desafiadora, algum c\u00f3digo base organizado. 0 - 2 pontos 18/04 Atualiza\u00e7\u00f5es do GitHub: Progresso documentado e c\u00f3digo atualizado, mostrando implementa\u00e7\u00e3o aproximada de <code>20%</code>. 0 - 2 pontos 25/04 Atualiza\u00e7\u00f5es do GitHub: Progresso documentado e c\u00f3digo atualizado, mostrando implementa\u00e7\u00e3o aproximada de <code>50%</code>. 0 - 2 pontos 02/05 Atualiza\u00e7\u00f5es do GitHub: Progresso documentado e c\u00f3digo atualizado, mostrando implementa\u00e7\u00e3o aproximada de <code>80%</code>. 0 - 2 pontos 09/05 Atualiza\u00e7\u00f5es do GitHub: Progresso documentado e c\u00f3digo atualizado, mostrando implementa\u00e7\u00e3o aproximada de <code>100%</code>. 0 - 2 pontos"},{"location":"checkpoint/cp2.html#composicao-da-nota-final","title":"Composi\u00e7\u00e3o da nota final","text":"Data Crit\u00e9rio Nota 16/05 Apresenta\u00e7\u00e3o e argui\u00e7\u00e3o do projeto 0 - 5 pontos 16/05 Avalia\u00e7\u00e3o da Documenta\u00e7\u00e3o t\u00e9cnica do projeto 0 - 5 pontos De 11/04 at\u00e9 09/05 Acompanhamento semanal (para os grupos que participarem) 0 - 10 pontos <ul> <li> <p>CP2:</p> <ul> <li>Dia 16/05, composta de <code>Apresenta\u00e7\u00e3o e argui\u00e7\u00e3o do projeto</code> + <code>valia\u00e7\u00e3o da Documenta\u00e7\u00e3o t\u00e9cnica do projeto</code>.</li> </ul> </li> <li> <p>CP3:</p> <ul> <li>Os grupos que realizarem o acompanhamento semanal ter\u00e1 a somat\u00f3ria do <code>acompanhamento semanal</code> convertida nota de CP3.</li> <li>Os grupos que <code>n\u00e3o participarem</code> do acompanhamento semanal <code>n\u00e3o ganham nota</code> e podem fazer o CP3 dia 23/05. O <code>CP3 Ser\u00e1 uma avalia\u00e7\u00e3o individual e presencial durante o periodo da aula</code>.  </li> </ul> </li> </ul>"},{"location":"checkpoint/cp3.html","title":"CHECKPOINT 3","text":"<p>Leia com aten\u00e7\u00e3o as instru\u00e7\u00f5es gerais sobre checkpoint;</p> <p>O checkpoint3 \u00e9 a cereja do bolo antes das f\u00e9rias e ser\u00e1 sobre comunica\u00e7\u00e3o entre sistemas, no nosso caso Arduino e vis\u00e3o computacional.</p>"},{"location":"checkpoint/cp3.html#descricao-do-problema","title":"Descri\u00e7\u00e3o do problema:","text":"<p>O objetivo deste desafio \u00e9 criar um sistema que utilize vis\u00e3o computacional em Python e um Arduino para realizar diferentes tarefas de acordo com o objetivo escolhido pelo grupo.</p> <p>O grupo pode escolher entre tr\u00eas alternativas de objetivos: <code>classifica\u00e7\u00e3o de cores, detec\u00e7\u00e3o de m\u00e3os ou detec\u00e7\u00e3o de faces</code>. O sistema deve capturar imagens utilizando uma c\u00e2mera e process\u00e1-las usando a biblioteca OpenCV e/ou Mediapipe. O sistema deve ent\u00e3o comunicar-se com um Arduino via comunica\u00e7\u00e3o serial para realizar tarefas espec\u00edficas com base no objetivo escolhido.</p>"},{"location":"checkpoint/cp3.html#alternativas-de-objetivos","title":"Alternativas de objetivos:","text":"<ul> <li><code>Classifica\u00e7\u00e3o de cores</code>: O sistema dever\u00e1 identificar e classificar objetos de diferentes cores e realizar a\u00e7\u00f5es espec\u00edficas com base na cor identificada.</li> <li><code>Detec\u00e7\u00e3o de m\u00e3os com Mediapipe</code>: O sistema dever\u00e1 detectar m\u00e3os em tempo real e identificar gestos espec\u00edficos, realizando a\u00e7\u00f5es espec\u00edficas com base nos gestos identificados.</li> <li><code>Detec\u00e7\u00e3o de faces</code>: O sistema dever\u00e1 detectar faces em tempo real e realizar a\u00e7\u00f5es espec\u00edficas com base na quantidade de faces detectadas ou nas caracter\u00edsticas faciais (olho aberto/fechado, sorrindo..).</li> </ul>"},{"location":"checkpoint/cp3.html#requisitos-tecnicos","title":"Requisitos t\u00e9cnicos:","text":"<ol> <li>Utiliza\u00e7\u00e3o da linguagem Python para desenvolver a parte de vis\u00e3o computacional.</li> <li>Utiliza\u00e7\u00e3o da biblioteca OpenCV para processar e analisar as imagens.</li> <li>Comunica\u00e7\u00e3o serial entre o sistema de vis\u00e3o computacional em Python e o Arduino.</li> <li>Implementa\u00e7\u00e3o de tarefas espec\u00edficas no Arduino com base na cor do objeto detectado.</li> <li>Documenta\u00e7\u00e3o em reposit\u00f3rio github de forma clara e completa do projeto, incluindo instru\u00e7\u00f5es para replicar o sistema e testes realizados.</li> </ol>"},{"location":"checkpoint/cp3.html#rubrica-de-avaliacao","title":"Rubrica de avalia\u00e7\u00e3o:","text":""},{"location":"checkpoint/cp3.html#funcionalidade-ate-5-pontos","title":"Funcionalidade (at\u00e9 5 pontos)","text":"<ul> <li>O sistema consegue capturar e processar imagens adequadamente.</li> <li>A comunica\u00e7\u00e3o serial entre o Python e o Arduino \u00e9 estabelecida e funciona corretamente.</li> <li>O Arduino realiza as tarefas espec\u00edficas de acordo com o objeto desejado.</li> </ul>"},{"location":"checkpoint/cp3.html#qualidade-do-codigo-ate-2-pontos","title":"Qualidade do c\u00f3digo (at\u00e9 2 pontos)","text":"<ul> <li>O c\u00f3digo \u00e9 bem estruturado e f\u00e1cil de entender.</li> <li>Boas pr\u00e1ticas de programa\u00e7\u00e3o s\u00e3o utilizadas, incluindo coment\u00e1rios, nomes de vari\u00e1veis e fun\u00e7\u00f5es apropriados, facilitando a manuten\u00e7\u00e3o e a compreens\u00e3o.</li> </ul>"},{"location":"checkpoint/cp3.html#documentacao-ate-3-pontos","title":"Documenta\u00e7\u00e3o (at\u00e9 3 pontos)","text":"<ul> <li>A documenta\u00e7\u00e3o do projeto em reposit\u00f3rio github de forma clara e completa, incluindo instru\u00e7\u00f5es para replicar o sistema.</li> <li>Video demonstrando o funcionamento do projeto de forma clara e completa.</li> </ul>"},{"location":"checkpoint/cp4.html","title":"CHECKPOINT 4","text":"<p>Leia com aten\u00e7\u00e3o as instru\u00e7\u00f5es gerais sobre o checkpoint.</p> <ul> <li>O objetivo do checkpoint \u00e9 avaliar sua compreens\u00e3o acerca do conte\u00fado ministrado pela disciplina.</li> </ul>"},{"location":"checkpoint/cp4.html#grupos-e-apresentacao","title":"Grupos e Apresenta\u00e7\u00e3o","text":"<ul> <li>O projeto pode ser realizado individualmente ou por grupos no m\u00e1ximo 5 alunos.</li> <li>A apresenta\u00e7\u00e3o do projeto deve ser realizada no dia program\u00e1tico, ver agenda.</li> </ul>"},{"location":"checkpoint/cp4.html#ideia-geral","title":"Ideia geral","text":""},{"location":"checkpoint/cp4.html#sistema-de-acesso-inteligente-para-ambientes-controlados","title":"Sistema de Acesso Inteligente para Ambientes Controlados","text":"<p>Desenvolver um sistema que controle o acesso a uma \u00e1rea espec\u00edfica (por exemplo, um laborat\u00f3rio, uma sala de servidores ou um armaz\u00e9m) usando RFID para autentica\u00e7\u00e3o e um atuador para liberar ou bloquear a entrada.</p>"},{"location":"checkpoint/cp4.html#funcionamento","title":"Funcionamento:","text":"<ul> <li>O usu\u00e1rio aproxima seu cart\u00e3o RFID do sensor.</li> <li>O Arduino l\u00ea o ID do cart\u00e3o e envia para o Node-RED.</li> <li>O Node-RED verifica em sua base de dados se aquele ID est\u00e1 autorizado a acessar o ambiente.</li> <li>Se autorizado, o Node-RED envia um comando ao Arduino para acionar o atuador, liberando - o acesso. Caso contr\u00e1rio, pode acionar um alarme ou simplesmente negar o acesso.</li> <li>O dashboard mostra em tempo real todas as tentativas de acesso, sejam elas bem-sucedidas ou n\u00e3o. Al\u00e9m disso, permite que um administrador controle manualmente o atuador.</li> </ul> <p>Neste checkpoint, voc\u00eas ir\u00e3o desenvolver o prot\u00f3tipo deste sistema de identifica\u00e7\u00e3o IoT, que em linhas gerais possuir\u00e1 as seguintes interfaces:</p> <p></p>"},{"location":"checkpoint/cp4.html#rubrica","title":"Rubrica","text":"<p>(R1 - NOTA 6) Os requisitos funcionais m\u00ednimos do sistema devem seguir a arquitetura abaixo:</p> <p></p> <p>Para atender a esta rubrica, o sistema est\u00e1 dividido em 2 fluxos: </p> <p>Fluxo 1: Deve ser capaz de coletar a identifica\u00e7\u00e3o da TAG RFID com o Arduino (ARDUINO1) e enviar, utilizando formato JSON, para um fluxo Node-Red que realiza duas fun\u00e7\u00f5es:</p> <ul> <li>Publica em um t\u00f3pico utilizando o protocolo MQTT;</li> <li>Notifica o usu\u00e1rio via outro canal de comunica\u00e7\u00e3o (E-mail, Telegram, Whatsapp, etc...).</li> </ul> <p>Fluxo 2: O fluxo do Node-Red subscreve o t\u00f3pico e exibe o valor da TAG em um DASHBOARD.</p> <ul> <li>Desenvolver um dashboard intuitivo e com boa usabilidade;</li> <li>Exibir em tempo real todas as tentativas de acesso, sejam elas bem-sucedidas ou n\u00e3o.</li> </ul> <p>(R2 - NOTA 7) Os requisitos funcionais m\u00ednimos do sistema devem seguir a imagem abaixo:</p> <p></p> <p>Para atender a esta rubrica, implemente a rubrica R1, e fa\u00e7a a atualiza\u00e7\u00e3o necess\u00e1ria onde o sistema deve se comunicar com o segundo Arduino (ARDUINO2) no formato JSON para realizar o controle de posi\u00e7\u00e3o do servo motor.</p> <ul> <li>A posi\u00e7\u00e3o do servo motor \u00e9 controlada pelo DASHBOARD, ou seja, um administrador controla manualmente o atuador.</li> </ul> <p>(R3 - NOTA 8) Os requisitos funcionais m\u00ednimos do sistema devem seguir a imagem abaixo:</p> <p></p> <ul> <li>Para atender a esta rubrica, implemente a rubrica R2, e o sistema do servidor Node-Red deve estar embarcado na Raspberry PI, sendo capaz de coletar dados do sensor DTH11 (Temperatura e Umidade) a cada 30s. </li> <li>As informa\u00e7\u00f5es do sensor s\u00e3o sempre atualizadas pelo Dashboard e enviadas para o usu\u00e1rio apenas se a umidade estiver abaixo de 50% ou a temperatura estiver acima de 30\u00b0C. Os setpoints de temperatura e umidade s\u00e3o configurados pelo administrador, ou seja, n\u00e3o s\u00e3o <code>hardcode</code>.</li> </ul> <p>(R4 - NOTA 10) Os requisitos funcionais m\u00ednimos do sistema devem seguir a imagem abaixo:</p> <p></p> <p>Para atender a esta rubrica, implemente a rubrica R3, e adicione a integra\u00e7\u00e3o com algum banco de dados e implementa\u00e7\u00e3o mobile (o grupo define a linguagem de programa\u00e7\u00e3o).</p> <p>(BONUS - 2 pontos ) MVP do projeto:</p> <p>Desenvolva uma caixa para acomodar os hardware do projeto, que pode ser desenvolvida pelo MakerLab utilizando a impressora 3D ou MDF cortado no laser.</p> <p></p> <ul> <li>Caixa: Utilize o site https://www.festi.info/boxes.py/ para criar uma caixa personalizada para o seu prot\u00f3tipo, de forma simples, online e gratuita.</li> </ul> <p>Links \u00fateis para criar seu case:</p> <ul> <li>Manual do Mundo</li> <li>Angelo Conti</li> <li>Maker Space 307</li> <li>Smoke &amp; Mirrors</li> </ul> <ul> <li>Especifica\u00e7\u00f5es para M\u00e1quina CNC: Selecione a espessura de 3mm para o MDF.</li> </ul>"},{"location":"checkpoint/cp5-arduino.html","title":"CHECKPOINT 4","text":"<ul> <li>O CP ser\u00e1 realizado em aula, de forma individual. </li> <li>A data de aplica\u00e7\u00e3o est\u00e1 dispon\u00edvel no site, em agenda.</li> </ul>"},{"location":"checkpoint/cp5-arduino.html#conteudo-do-cp","title":"Conte\u00fado do CP","text":"<ul> <li>Conceitos de Programa\u00e7\u00e3o C para arduino</li> <li>Conceitos de Eletrica e Eletr\u00f4nica</li> </ul>"},{"location":"checkpoint/cp6.html","title":"CHECKPOINT 6","text":""},{"location":"checkpoint/cp6.html#cp6-em-breve","title":"CP6 - Em breve","text":"<p>Individual em aula.</p> <p>4SIA - 06/11 4SIR - 07/11</p>"},{"location":"instalacao/index.html","title":"Instru\u00e7\u00f5es para a instala\u00e7\u00e3o da infraestrutura","text":""},{"location":"instalacao/index.html#arduino-ide-winlinuxmac","title":"Arduino IDE (Win/Linux/MAC)","text":"<ul> <li>Fazer o download e instalar a ide do arduino pelo site oficial - https://www.arduino.cc</li> </ul>"},{"location":"instalacao/index.html#simulador-de-arduino-online-nao-vamos-usar-em-aula","title":"Simulador de Arduino online (n\u00e3o vamos usar em aula)","text":"<ul> <li> <p>Tinkercad - https://www.tinkercad.com/</p> </li> <li> <p>Wokwi - https://wokwi.com/</p> </li> <li> <p>SimulIDE - https://www.simulide.com/p/home.html</p> </li> </ul>"},{"location":"instalacao/index.html#instalacao-python-3x","title":"Instala\u00e7\u00e3o Python 3.x","text":"<ul> <li> <p>Windows:</p> <ul> <li> <p>Fazer o download do python no site oficial:</p> </li> <li> <p>https://www.python.org/downloads/ * selecionar a op\u00e7\u00e3o: <code>adicionar o Python ao PATH</code></p> </li> </ul> </li> <li> <p>Linux/mac:</p> <ul> <li>S\u00f3 precisa executar \u201cpip3 install pacote\u201d no terminal.</li> </ul> </li> <li> <p>Alternativa: N\u00e3o \u00e9 necess\u00e1rio, masssss\u2026 quem preferir, pode usar o <code>anaconda</code> e criar uma virtual env para instalar a infra</p> <ul> <li>Instala\u00e7\u00e3o ANACONDA - https://www.anaconda.com/download/</li> </ul> </li> <li> <p>Com o Python instalado, abra o terminal/cmd e instale os pacotes abaixo:</p> <pre><code>* pip install matplotlib\n* pip install opencv-python\n* pip install notebook\n* pip install pyserial\n* pip install mediapipe\n</code></pre> </li> </ul>"},{"location":"instalacao/index.html#vm-virtual-box-alternativa","title":"VM - Virtual box (Alternativa)","text":"<p>Tem uma VM (M\u00e1quina Virtual) pronta para usar com tudo instalado e configurado, basta instalar o VirtualBox e os extension pack:</p> <ul> <li>https://www.virtualbox.org/wiki/Downloads - s\u00e3o 2 arquivos para fazer o download.</li> <li> <p>Fazer o download do arquivo iot.ova que est\u00e1 no google drive <code>Clique aqui para fazer o download</code></p> </li> <li> <p>Usu\u00e1rio: iot</p> </li> <li>Senha: iot</li> <li><code>sugest\u00e3o:</code> rodar com pelo menos 2 CPU\u2019s e 4G de Ram</li> </ul>"}]}