{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"index.html","title":"Bem vindo disciplina de AI Engineering, Cognitive and Semantics Computing &amp; IoT","text":"<p>Ol\u00e1 pessoal, bem vindos!! Nesta p\u00e1gina voc\u00ea ir\u00e1 encontrar os conte\u00fados ministrados em sala de aula assim como dicas,atividades, labor\u00f3rios e muito mais. </p> <ul> <li>Curso: Sistemas da Informa\u00e7\u00e3o</li> <li>Disciplina: AI Engineering, Cognitive and Semantics Computing &amp; IoT</li> <li>Turmas 2025: 4SIPF, 4SIR</li> <li>Reposit\u00f3rio com todos os arquivos est\u00e1 disponivel em: https://github.com/arnaldojr/cognitivecomputing/</li> </ul> <p>Prof. Arnaldo Viana</p>"},{"location":"index.html#objetivos","title":"Objetivos","text":"<p>Nosso curso est\u00e1 dividido em IA e IoT, ao final da disciplina o estudante ser\u00e1 capaz de:</p> <ul> <li>Compreender o conceitos de Processamento digital de imagens </li> <li>Conhecer as principais tecnicas para detec\u00e7\u00e3o e segmenta\u00e7\u00e3o de objetos</li> <li>Conhecer e aplicar tecnicas de vis\u00e3o computacional</li> <li>Compreender os conceitos de An\u00e1lise de dados, Machine Learning (ML) e Deep Learning (DL)</li> <li>Aplicar conceitos e t\u00e9cnicas de DL</li> <li>Desenvolver pequenos projetos envolvendo IA.</li> <li>Compreender o conceitos de sistemas baseados em IoT (Internet das Coisas)</li> <li>Conhecer as principais tecnologias habilitadoras da IoT</li> <li>Programar e desenvolver pequenos projetos de IoT</li> </ul>"},{"location":"index.html#o-que-preciso-tersaber-para-acompanhar-esse-curso","title":"O que preciso ter/saber para acompanhar esse curso?","text":"<ul> <li>L\u00f3gica de programa\u00e7\u00e3o</li> <li>Python b\u00e1sico</li> <li>Algebra linear</li> <li>Dedica\u00e7\u00e3o</li> </ul>"},{"location":"index.html#dinamica-das-aulas","title":"Din\u00e2mica das aulas:","text":"<p>O curso \u00e9 baseadas em desafios (exercicios, atividades, pesquisa e etc.) que abordam teoria e pr\u00e1tica.</p> <p>Por essa raz\u00e3o as aulas est\u00e3o divididas em pequenos laborat\u00f3rios, cada laborat\u00f3rio possui os seus objetivos especificos. </p> <p></p>"},{"location":"index.html#quais-software-preciso-instalar-para-acompanhar-esse-curso","title":"Quais software preciso instalar para acompanhar esse curso?","text":"<p>Basicamente, vamos trabalhar com scripts em python e algumas bibliotecas que podem ser executados localmente ou em nuvem. </p> <p>Como sugest\u00e3o de instala\u00e7\u00e3o local:</p> <ul> <li>Python 3.x.</li> <li>Jupyter Notebook.</li> <li>Anaconda.</li> </ul> <p>Em nuvem:</p> <ul> <li>Google Colab.</li> <li> <p>Kaggle.</p> </li> <li> <p>Quer detalhes de como instalar a infra necess\u00e1ria para o curso? Da uma olhadinha na aba instala\u00e7\u00e3o.</p> </li> </ul>"},{"location":"index.html#ideias-de-projetos","title":"Id\u00e9ias de projetos","text":"<p>As aplica\u00e7\u00f5es s\u00e3o vastas e diversas... Para ajudar a despertar a curiosidade, pense de que forma podemos utilizar ML para resolver um problema do nosso dia a dia.</p>"},{"location":"index.html#bibliografia","title":"Bibliografia","text":"<ul> <li>Stewart Russel e Peter Norvig . Intelig\u00eancia artificial. 3\u00aa. Ed., Rio de Janeiro: Campus, 2012.</li> <li>George F. Luger . Intelig\u00eancia Artificial, 6\u00aa ed. S\u00e3o Paulo: Pearson Education do Brasil, 2013 (biblioteca virtual)</li> <li>Aur\u00e9lien Geron. 2019. Hands-On Machine Learning with Scikit-Learn, Keras, and Tensorflow: Concepts, Tools, and Techniques to Build Intelligent Systems</li> </ul>"},{"location":"agenda/agenda.html","title":"Agenda","text":""},{"location":"agenda/agenda.html#agenda","title":"Agenda","text":""},{"location":"agenda/agenda.html#cronograma-2o-semestre-2025","title":"Cronograma 2\u00ba Semestre - 2025","text":"Semana Segundo Semestre - Conte\u00fado 4SIRQuarta-Feira 1 Apresenta\u00e7\u00e3o do semestre, datas importantes (CP, GS)Explora\u00e7\u00e3o de dados 07/08/2025 2 ML Supervisionado - Classifica\u00e7\u00e3o 14/08/2025 3 ML Supervisionado - Regress\u00e3o 21/08/2025 4 CP1 \u2013 Avalia\u00e7\u00e3oCP1 - ML Conceitos e aplica\u00e7\u00e3o 28/08/2025 5 Introdu\u00e7\u00e3o ao Deep Learning, Perceptron, MLP 04/09/2025 6 CNN 11/09/2025 7 CNN Continua\u00e7\u00e3o 18/09/2025 8 Aplica\u00e7\u00e3o de DL (batalha das redes) 25/09/2025 9 Avalia\u00e7\u00e3o Projeto challenge Santander 02/10/2025 10 CP2 \u2013 Avalia\u00e7\u00e3oCP2 - Redes Neurais conceitos e aplica\u00e7\u00e3o 09/10/2025 11 Transfer Learning, lan\u00e7amento CP3 16/10/2025 12 Redes modernas, aplica\u00e7\u00f5es com DL 23/10/2025 13 Aplica\u00e7\u00f5es com Yolo e deploy de aplica\u00e7\u00f5es. 30/10/2025 14 CP3 \u2013 Apresenta\u00e7\u00e3o Final CP3CP3 - Sistema de VC com Deploy em Aplica\u00e7\u00e3o Web 06/11/2025 15 GS - Avalia\u00e7\u00e3o Global Solution segundo semestre  13/11/2025"},{"location":"aulas/IA/batalharedes/batalha_das_redes.html","title":"BATALHA DAS REDES","text":"In\u00a0[\u00a0]: Copied! <pre>## importa dataset\nfrom sklearn.datasets import load_iris\nfrom sklearn.model_selection import train_test_split\n\ndef iris():\n    iris = load_iris()\n    X, y = iris.data, iris.target\n    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n    return X_train, X_test, y_train, y_test\n</pre> ## importa dataset from sklearn.datasets import load_iris from sklearn.model_selection import train_test_split  def iris():     iris = load_iris()     X, y = iris.data, iris.target     X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)      return X_train, X_test, y_train, y_test  In\u00a0[\u00a0]: Copied! <pre>import pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\n\ndef heart():\n    url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/heart-disease/processed.cleveland.data\"\n    columns = ['age', 'sex', 'cp', 'trestbps', 'chol', 'fbs', 'restecg', 'thalach', 'exang', 'oldpeak', 'slope', 'ca', 'thal', 'target']\n\n    heart_disease_data = pd.read_csv(url, header=None, names=columns, na_values=\"?\")\n    #valores ausentes (NaN), substitue pela m\u00e9dia da coluna\n    heart_disease_data.fillna(heart_disease_data.mean(), inplace=True)\n\n    X = heart_disease_data.drop('target', axis=1)\n    y = heart_disease_data[\"target\"].values\n    # Converta os valores de r\u00f3tulo 1-4 em 1\n    y = np.where(y &gt; 0, 1, 0)\n\n\n    scaler = StandardScaler()\n    X_scaled = scaler.fit_transform(X)\n\n\n    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n    return X_train, X_test, y_train, y_test\n</pre> import pandas as pd from sklearn.model_selection import train_test_split from sklearn.preprocessing import StandardScaler  def heart():     url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/heart-disease/processed.cleveland.data\"     columns = ['age', 'sex', 'cp', 'trestbps', 'chol', 'fbs', 'restecg', 'thalach', 'exang', 'oldpeak', 'slope', 'ca', 'thal', 'target']      heart_disease_data = pd.read_csv(url, header=None, names=columns, na_values=\"?\")     #valores ausentes (NaN), substitue pela m\u00e9dia da coluna     heart_disease_data.fillna(heart_disease_data.mean(), inplace=True)      X = heart_disease_data.drop('target', axis=1)     y = heart_disease_data[\"target\"].values     # Converta os valores de r\u00f3tulo 1-4 em 1     y = np.where(y &gt; 0, 1, 0)       scaler = StandardScaler()     X_scaled = scaler.fit_transform(X)       X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)      return X_train, X_test, y_train, y_test In\u00a0[\u00a0]: Copied! <pre>import tensorflow as tf\n\ndef cifar():\n    (X_train, y_train), (X_test, y_test) = tf.keras.datasets.cifar10.load_data()\n\n    X_train = X_train.astype('float32')\n    X_test = X_test.astype('float32')\n    #normaliza os dados para o pixel ficar com valores entre 0 e 1\n    X_train = X_train / 255.0\n    X_test = X_test / 255.0\n\n    print('shape original')\n    print('X_train: {}, X_test: {}, y_train:{}, y_test:{}'.format(X_train.shape, X_test.shape, y_train.shape, y_test.shape))\n    print('shape redimensionado, flatten')\n    X_train = X_train.reshape(X_train.shape[0], -1)\n    X_test = X_test.reshape(X_test.shape[0], -1)\n\n    return X_train, X_test, y_train, y_test\n</pre> import tensorflow as tf  def cifar():     (X_train, y_train), (X_test, y_test) = tf.keras.datasets.cifar10.load_data()      X_train = X_train.astype('float32')     X_test = X_test.astype('float32')     #normaliza os dados para o pixel ficar com valores entre 0 e 1     X_train = X_train / 255.0     X_test = X_test / 255.0      print('shape original')     print('X_train: {}, X_test: {}, y_train:{}, y_test:{}'.format(X_train.shape, X_test.shape, y_train.shape, y_test.shape))     print('shape redimensionado, flatten')     X_train = X_train.reshape(X_train.shape[0], -1)     X_test = X_test.reshape(X_test.shape[0], -1)      return X_train, X_test, y_train, y_test In\u00a0[\u00a0]: Copied! <pre># Importa\u00e7\u00e3o das bibliotecas necess\u00e1rias\nimport numpy as np\nimport pandas as pd\nimport tensorflow as tf\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense\nfrom tensorflow.keras.layers import Dropout\nfrom tensorflow.keras.layers import BatchNormalization\nfrom keras.utils.np_utils import to_categorical\n\n# importa as m\u00e9tricas de avalia\u00e7\u00e3o\nfrom sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n</pre> # Importa\u00e7\u00e3o das bibliotecas necess\u00e1rias import numpy as np import pandas as pd import tensorflow as tf from tensorflow.keras.models import Sequential from tensorflow.keras.layers import Dense from tensorflow.keras.layers import Dropout from tensorflow.keras.layers import BatchNormalization from keras.utils.np_utils import to_categorical  # importa as m\u00e9tricas de avalia\u00e7\u00e3o from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score  In\u00a0[\u00a0]: Copied! <pre>### dataset da rodada, basta descomentar uma das linhas abaixo\n\n#dataset = 'rodada1'\n#dataset = 'rodada2'\ndataset = 'rodada3'\n\n\n\n# Fun\u00e7\u00e3o para carregar e preprocessar o dataset\ndef load_and_preprocess_data(dataset):\n    if dataset == \"rodada1\":\n        X_train, X_test, y_train, y_test = iris()\n\n    elif dataset == \"rodada2\":\n        X_train, X_test, y_train, y_test = heart()\n\n    else:\n        X_train, X_test, y_train, y_test = cifar()\n\n    return X_train, X_test, y_train, y_test\n\n# Carregue e preprocess os dados\nX_train, X_test, y_train, y_test = load_and_preprocess_data(dataset)\n\nprint(\"\\n---------LEIA COM ATEN\u00c7\u00c3O--------------------------\")\nprint('\\nX_train: {}, X_test: {}\\ny_train: {}, y_test: {}'.format(X_train.shape, X_test.shape, y_train.shape, y_test.shape))\n</pre> ### dataset da rodada, basta descomentar uma das linhas abaixo  #dataset = 'rodada1' #dataset = 'rodada2' dataset = 'rodada3'    # Fun\u00e7\u00e3o para carregar e preprocessar o dataset def load_and_preprocess_data(dataset):     if dataset == \"rodada1\":         X_train, X_test, y_train, y_test = iris()      elif dataset == \"rodada2\":         X_train, X_test, y_train, y_test = heart()      else:         X_train, X_test, y_train, y_test = cifar()      return X_train, X_test, y_train, y_test  # Carregue e preprocess os dados X_train, X_test, y_train, y_test = load_and_preprocess_data(dataset)  print(\"\\n---------LEIA COM ATEN\u00c7\u00c3O--------------------------\") print('\\nX_train: {}, X_test: {}\\ny_train: {}, y_test: {}'.format(X_train.shape, X_test.shape, y_train.shape, y_test.shape)) In\u00a0[\u00a0]: Copied! <pre># Fun\u00e7\u00e3o para criar o modelo MLP\ndef create_model(dataset):\n    model = Sequential()\n    # Adicione as camadas aqui\n\n\n\n\n\n    # Compile o modelo N\u00e3o altera aqui, por enquanto.\n    if dataset == 'rodada2': model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n    else: model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n\n    return model\n\n# Crie o modelo\nprint(dataset)\nmodel = create_model(dataset)\n\nmodel.summary()\nprint(\"Loss function:\", model.loss)\nprint(\"Optimizer name:\", model.optimizer.get_config()[\"name\"])\n</pre> # Fun\u00e7\u00e3o para criar o modelo MLP def create_model(dataset):     model = Sequential()     # Adicione as camadas aqui          # Compile o modelo N\u00e3o altera aqui, por enquanto.     if dataset == 'rodada2': model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])     else: model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])      return model  # Crie o modelo print(dataset) model = create_model(dataset)  model.summary() print(\"Loss function:\", model.loss) print(\"Optimizer name:\", model.optimizer.get_config()[\"name\"])  In\u00a0[\u00a0]: Copied! <pre># Treine o modelo\nhistory = model.fit(X_train, y_train, epochs=10, validation_split=0.2)\n\n#Validad\u00e7\u00e3o\ntrain_loss, train_acc = model.evaluate(X_train,  y_train, verbose=2)\ntest_loss, test_acc = model.evaluate(X_test,  y_test, verbose=2)\n</pre> # Treine o modelo history = model.fit(X_train, y_train, epochs=10, validation_split=0.2)  #Validad\u00e7\u00e3o train_loss, train_acc = model.evaluate(X_train,  y_train, verbose=2) test_loss, test_acc = model.evaluate(X_test,  y_test, verbose=2) In\u00a0[\u00a0]: Copied! <pre>## exibe os graficos da fun\u00e7\u00e3o loss e acuracia\n\nhistory_df = pd.DataFrame(history.history)\n\nhistory_df[['loss','val_loss']].plot();\nhistory_df[['accuracy','val_accuracy']].plot();\n</pre> ## exibe os graficos da fun\u00e7\u00e3o loss e acuracia  history_df = pd.DataFrame(history.history)  history_df[['loss','val_loss']].plot(); history_df[['accuracy','val_accuracy']].plot();  In\u00a0[\u00a0]: Copied! <pre># Fun\u00e7\u00e3o para avaliar o modelo\ndef train_and_evaluate_model(model, dataset, X_train, X_test, y_train, y_test):\n\n    # Fa\u00e7a previs\u00f5es no conjunto de teste\n    if dataset =='rodada2':\n      y_pred = np.round(model.predict(X_test))\n    else:\n      y_pred = np.argmax(model.predict(X_test), axis=-1)\n\n    # Converta os r\u00f3tulos para inteiros\n    y_test = y_test.astype(int)\n    y_pred = y_pred.astype(int)\n\n\n    # Calcule as m\u00e9tricas de avalia\u00e7\u00e3o\n    accuracy = accuracy_score(y_test, y_pred)\n    precision = precision_score(y_test, y_pred, average='weighted')\n    recall = recall_score(y_test, y_pred, average='weighted')\n    f1 = f1_score(y_test, y_pred, average='weighted')\n\n    return accuracy, precision, recall, f1\n\n# Treine e avalie o modelo\naccuracy, precision, recall, f1 = train_and_evaluate_model(model,dataset, X_train, X_test, y_train, y_test)\n\n# Exiba os resultados\nprint(\"Acur\u00e1cia:\", accuracy)\nprint(\"Precis\u00e3o:\", precision)\nprint(\"Revoca\u00e7\u00e3o:\", recall)\nprint(\"F1-Score:\", f1)\n</pre> # Fun\u00e7\u00e3o para avaliar o modelo def train_and_evaluate_model(model, dataset, X_train, X_test, y_train, y_test):      # Fa\u00e7a previs\u00f5es no conjunto de teste     if dataset =='rodada2':       y_pred = np.round(model.predict(X_test))     else:       y_pred = np.argmax(model.predict(X_test), axis=-1)      # Converta os r\u00f3tulos para inteiros     y_test = y_test.astype(int)     y_pred = y_pred.astype(int)       # Calcule as m\u00e9tricas de avalia\u00e7\u00e3o     accuracy = accuracy_score(y_test, y_pred)     precision = precision_score(y_test, y_pred, average='weighted')     recall = recall_score(y_test, y_pred, average='weighted')     f1 = f1_score(y_test, y_pred, average='weighted')      return accuracy, precision, recall, f1  # Treine e avalie o modelo accuracy, precision, recall, f1 = train_and_evaluate_model(model,dataset, X_train, X_test, y_train, y_test)  # Exiba os resultados print(\"Acur\u00e1cia:\", accuracy) print(\"Precis\u00e3o:\", precision) print(\"Revoca\u00e7\u00e3o:\", recall) print(\"F1-Score:\", f1)  In\u00a0[\u00a0]: Copied! <pre>\n</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre>"},{"location":"aulas/IA/batalharedes/batalha_das_redes.html#2-redes-neurais","title":"2. Redes Neurais\u00b6","text":""},{"location":"aulas/IA/batalharedes/batalha_das_redes.html#objetivos","title":"Objetivos\u00b6","text":"<ul> <li>Conhecer e praticar Redes Neurais MLP</li> </ul>"},{"location":"aulas/IA/batalharedes/batalha_das_redes.html#batalha-das-redes","title":"Batalha das redes\u00b6","text":"<p>Bem-vindos \u00e0 nossa emocionante competi\u00e7\u00e3o de Redes Neurais Multilayer Perceptron (MLP)! Hoje, voc\u00eas participar\u00e3o de uma competi\u00e7\u00e3o estilo Kaggle simplificada, projetada para colocar suas habilidades \u00e0 prova e acelerar sua aprendizagem em um ambiente divertido e colaborativo.</p> <p>Ao longo desta aula, voc\u00eas enfrentar\u00e3o tr\u00eas rodadas de desafios, cada uma com um dataset de dificuldade crescente. O objetivo \u00e9 criar e otimizar modelos de redes neurais MLP para resolver problemas de classifica\u00e7\u00e3o. Voc\u00eas trabalhar\u00e3o em duplas para desenvolver as melhores solu\u00e7\u00f5es poss\u00edveis, competindo uns contra os outros para ver quem alcan\u00e7a o melhor desempenho.</p> <p>A competi\u00e7\u00e3o \u00e9 estruturada da seguinte maneira:</p> <ul> <li>Primeira rodada: Dataset f\u00e1cil para que todos possam se familiarizar com o processo e come\u00e7ar a se aquecer.</li> <li>Segunda rodada: Dataset de dificuldade m\u00e9dia para desafiar suas habilidades e encoraj\u00e1-los a explorar t\u00e9cnicas avan\u00e7adas de otimiza\u00e7\u00e3o.</li> <li>Terceira rodada: Dataset dif\u00edcil, onde voc\u00eas colocar\u00e3o \u00e0 prova tudo o que aprenderam, desenvolvendo solu\u00e7\u00f5es para problemas complexos e realistas.</li> </ul> <p>Voc\u00eas ser\u00e3o avaliados com base no desempenho de suas redes neurais e em crit\u00e9rios relacionados \u00e0 arquitetura e complexidade da rede. Isso inclui m\u00e9tricas como acur\u00e1cia, F1-Score e o n\u00famero de neur\u00f4nios usados no modelo. O objetivo \u00e9 incentivar a cria\u00e7\u00e3o de solu\u00e7\u00f5es eficientes e de alto desempenho.</p> <p>Preparem-se para mergulhar no mundo das redes neurais e aprender atrav\u00e9s da experi\u00eancia pr\u00e1tica. A competi\u00e7\u00e3o ser\u00e1 acirrada, mas, no final, todos sair\u00e3o ganhando com o conhecimento e as habilidades adquiridas.</p> <p>Boa sorte a todos e que ven\u00e7a a melhor solu\u00e7\u00e3o!</p>"},{"location":"aulas/IA/batalharedes/batalha_das_redes.html#descricao-dos-datasets-para-as-rodadas-de-competicao","title":"Descri\u00e7\u00e3o dos Datasets para as Rodadas de Competi\u00e7\u00e3o\u00b6","text":"<p>Ao longo desta competi\u00e7\u00e3o, voc\u00eas enfrentar\u00e3o tr\u00eas rodadas de desafios, cada uma com um dataset de dificuldade crescente. Abaixo est\u00e3o as descri\u00e7\u00f5es dos datasets selecionados para cada rodada:</p>"},{"location":"aulas/IA/batalharedes/batalha_das_redes.html#primeira-rodada-dataset-facil-iris-dataset","title":"Primeira rodada - Dataset f\u00e1cil: Iris Dataset\u00b6","text":"<p>O <code>Iris dataset</code> voc\u00ea j\u00e1 conhece, \u00e9 um conjunto cl\u00e1ssico de dados usado para problemas de classifica\u00e7\u00e3o. Ele cont\u00e9m 150 amostras de flores de \u00edris, divididas em 3 classes, cada uma representando um tipo de \u00edris (Setosa, Versicolour e Virginica). Para cada amostra, h\u00e1 quatro caracter\u00edsticas: comprimento e largura das s\u00e9palas e p\u00e9talas.</p> <p>O objetivo \u00e9 criar um modelo MLP para classificar corretamente o tipo de \u00edris com base nessas caracter\u00edsticas.</p> <p>Para carregar o Iris dataset:</p>"},{"location":"aulas/IA/batalharedes/batalha_das_redes.html#segunda-rodada-dataset-medio-heart-disease-uci-dataset","title":"Segunda rodada - Dataset m\u00e9dio: Heart Disease UCI Dataset\u00b6","text":"<p>O <code>Heart Disease UCI dataset</code> \u00e9 um conjunto de dados m\u00e9dicos que cont\u00e9m informa\u00e7\u00f5es sobre pacientes e a presen\u00e7a de doen\u00e7as card\u00edacas. S\u00e3o 303 amostras com 13 caracter\u00edsticas, incluindo idade, sexo, press\u00e3o arterial em repouso e n\u00edveis de colesterol.</p> <p>O objetivo \u00e9 classificar as amostras em duas classes: presen\u00e7a ou aus\u00eancia de doen\u00e7a card\u00edaca.</p> <p>Para carregar o Heart Disease UCI dataset:</p>"},{"location":"aulas/IA/batalharedes/batalha_das_redes.html#terceira-rodada-dataset-dificil-cifar10-dataset","title":"Terceira rodada - Dataset dif\u00edcil: Cifar10 Dataset\u00b6","text":"<p>O <code>cifar10</code> \u00e9 um conjunto de dados mais desafiador, contendo mais de 60.000 imagens em cores de 32x32 pixels, representando 10 classes de objetos capturados em imagens reais.</p> <p>link: https://www.cs.toronto.edu/~kriz/cifar.html</p> <p>O objetivo \u00e9 criar um modelo MLP capaz de classificar corretamente cada imagem em seu respectivo d\u00edgito.</p> <p>Para carregar o SVHN dataset:</p>"},{"location":"aulas/IA/batalharedes/batalha_das_redes.html#codigo-base","title":"C\u00f3digo base\u00b6","text":"<p>O seu objetivo \u00e9 a cria\u00e7\u00e3o da rede MLP mais eficiente, este co\u00f3digo base te auxilia no restante.</p> <p>Para rodar, execute as celulas de c\u00f3digo abaixo e fa\u00e7a as altera\u00e7\u00f5es onde for solicitado:</p>"},{"location":"aulas/IA/batalharedes/batalha_das_redes.html#primeiro-passo","title":"Primeiro passo\u00b6","text":"<p>Aqui voc\u00ea deve escolhar do dataset.</p> <p>Defina o dataset de acordo com rodada da competi\u00e7\u00e3o.</p> <ul> <li>dataset = 'rodada1'   --&gt; primeira rodada</li> <li>dataset = 'rodada2'   --&gt; primeira rodada</li> <li>dataset = 'rodada3'   --&gt; primeira rodada</li> </ul>"},{"location":"aulas/IA/batalharedes/batalha_das_redes.html#segundo-passo","title":"Segundo passo\u00b6","text":"<p>Crie sua rede neural MLP dentro da fun\u00e7\u00e3o create_model().</p> <p>\u00c9 aqui que voc\u00ea vai trabalhar! Use a fun\u00e7\u00e3o create_model() para definir a arquitetura da sua rede neural MLP.</p>"},{"location":"aulas/IA/batalharedes/batalha_das_redes.html#dicas","title":"Dicas\u00b6","text":"<ul> <li>Adicione as camadas Densas, Dropout, etc.</li> <li>Adicione/altere quantidade de neuronios.</li> <li>Adicione/altere fun\u00e7\u00e3o de ativa\u00e7\u00e3o ('relu','softmax','sigmoid')</li> </ul> <p>Exemplos:</p> <ul> <li>model.add(Dense(18, activation='relu', input_shape=(4,)))</li> <li>model.add(Dropout(rate=0.5))</li> <li>model.add(BatchNormalization())</li> </ul>"},{"location":"aulas/IA/batalharedes/batalha_das_redes.html#terceiro-passo","title":"Terceiro passo\u00b6","text":"<p>Treine o seu modelo, aqui voce deve trabalhar para definir os parametros de treinamento da rede neural.</p>"},{"location":"aulas/IA/batalharedes/batalha_das_redes.html#dicas","title":"Dicas\u00b6","text":"<ul> <li>Altere quantidade de epocas, batch_size e validation_split</li> </ul>"},{"location":"aulas/IA/batalharedes/batalha_das_redes.html#quarto-passo","title":"Quarto passo\u00b6","text":"<p>Avalia\u00e7\u00e3o do modelo treinado</p>"},{"location":"aulas/IA/batalharedes/batalha_das_redes.html#pontuacao","title":"Pontua\u00e7\u00e3o\u00b6","text":"<p>Para computar seus pontos anote os resultados obtidos</p> <ul> <li>Acur\u00e1cia</li> <li>Quantidade de camadas</li> </ul>"},{"location":"aulas/IA/batalharedes/batalha_das_redes.html#se-der-empate","title":"se der empate\u00b6","text":"<ul> <li>F1-Scores</li> <li>Quantidade de parametros trein\u00e1veis</li> </ul>"},{"location":"aulas/IA/conceitos/eda.html","title":"An\u00e1lise Explorat\u00f3ria de Dados (EDA)","text":""},{"location":"aulas/IA/conceitos/eda.html#introducao","title":"Introdu\u00e7\u00e3o","text":"<p>A An\u00e1lise Explorat\u00f3ria de Dados (EDA - Exploratory Data Analysis) \u00e9 um processo cr\u00edtico em ci\u00eancia de dados que envolve a investiga\u00e7\u00e3o sistem\u00e1tica de conjuntos de dados para descobrir padr\u00f5es, detectar anomalias, testar hip\u00f3teses e verificar suposi\u00e7\u00f5es atrav\u00e9s de estat\u00edsticas descritivas e representa\u00e7\u00f5es gr\u00e1ficas.</p> <p>\"Far better an approximate answer to the right question, which is often vague, than an exact answer to the wrong question, which can always be made precise.\" - John Tukey</p>"},{"location":"aulas/IA/conceitos/eda.html#objetivos-da-eda","title":"Objetivos da EDA","text":""},{"location":"aulas/IA/conceitos/eda.html#1-compreensao-dos-dados","title":"1. Compreens\u00e3o dos Dados","text":"<ul> <li>Entender a estrutura e caracter\u00edsticas dos dados</li> <li>Identificar tipos de vari\u00e1veis (num\u00e9ricas, categ\u00f3ricas, temporais)</li> <li>Verificar qualidade e integridade dos dados</li> </ul>"},{"location":"aulas/IA/conceitos/eda.html#2-deteccao-de-padroes","title":"2. Detec\u00e7\u00e3o de Padr\u00f5es","text":"<ul> <li>Identificar tend\u00eancias, sazonalidades e ciclos</li> <li>Descobrir relacionamentos entre vari\u00e1veis</li> <li>Encontrar grupos ou clusters naturais nos dados</li> </ul>"},{"location":"aulas/IA/conceitos/eda.html#3-identificacao-de-anomalias","title":"3. Identifica\u00e7\u00e3o de Anomalias","text":"<ul> <li>Detectar outliers e valores at\u00edpicos</li> <li>Identificar inconsist\u00eancias e erros nos dados</li> <li>Verificar distribui\u00e7\u00f5es incomuns</li> </ul>"},{"location":"aulas/IA/conceitos/eda.html#4-formulacao-de-hipoteses","title":"4. Formula\u00e7\u00e3o de Hip\u00f3teses","text":"<ul> <li>Gerar quest\u00f5es de pesquisa baseadas nos dados</li> <li>Definir dire\u00e7\u00f5es para an\u00e1lises mais profundas</li> <li>Validar ou refutar suposi\u00e7\u00f5es iniciais</li> </ul>"},{"location":"aulas/IA/conceitos/eda.html#etapas-da-eda","title":"Etapas da EDA","text":""},{"location":"aulas/IA/conceitos/eda.html#fase-1-conhecimento-inicial-dos-dados","title":"Fase 1: Conhecimento Inicial dos Dados","text":""},{"location":"aulas/IA/conceitos/eda.html#visao-geral","title":"Vis\u00e3o Geral","text":"<pre><code>import pandas as pd\nimport numpy as np\n\n# Carregar dados\ndf = pd.read_csv('dataset.csv')\n\n# Informa\u00e7\u00f5es b\u00e1sicas\nprint(f\"Dimens\u00f5es: {df.shape}\")\nprint(f\"Colunas: {list(df.columns)}\")\nprint(f\"Tipos de dados:\\n{df.dtypes}\")\nprint(f\"Mem\u00f3ria utilizada: {df.memory_usage(deep=True).sum() / 1024**2:.2f} MB\")\n</code></pre>"},{"location":"aulas/IA/conceitos/eda.html#primeiras-impressoes","title":"Primeiras Impress\u00f5es","text":"<pre><code># Primeiras e \u00faltimas linhas\nprint(\"Primeiras 5 linhas:\")\nprint(df.head())\n\nprint(\"\\n\u00daltimas 5 linhas:\")\nprint(df.tail())\n\n# Amostra aleat\u00f3ria\nprint(\"\\nAmostra aleat\u00f3ria:\")\nprint(df.sample(5))\n</code></pre>"},{"location":"aulas/IA/conceitos/eda.html#fase-2-analise-da-qualidade-dos-dados","title":"Fase 2: An\u00e1lise da Qualidade dos Dados","text":""},{"location":"aulas/IA/conceitos/eda.html#valores-ausentes","title":"Valores Ausentes","text":"<pre><code># An\u00e1lise de valores ausentes\nmissing_data = df.isnull().sum()\nmissing_percent = (missing_data / len(df)) * 100\nmissing_summary = pd.DataFrame({\n    'Coluna': missing_data.index,\n    'Valores_Ausentes': missing_data.values,\n    'Porcentagem': missing_percent.values\n}).sort_values('Porcentagem', ascending=False)\n\nprint(missing_summary[missing_summary['Valores_Ausentes'] &gt; 0])\n</code></pre>"},{"location":"aulas/IA/conceitos/eda.html#duplicatas-e-inconsistencias","title":"Duplicatas e Inconsist\u00eancias","text":"<pre><code># Verificar duplicatas\nprint(f\"Linhas duplicadas: {df.duplicated().sum()}\")\n\n# Verificar inconsist\u00eancias em dados categ\u00f3ricos\nfor col in df.select_dtypes(include=['object']).columns:\n    unique_values = df[col].unique()\n    print(f\"\\n{col}: {len(unique_values)} valores \u00fanicos\")\n    if len(unique_values) &lt; 20:  # Mostrar apenas se poucos valores\n        print(f\"Valores: {unique_values}\")\n</code></pre>"},{"location":"aulas/IA/conceitos/eda.html#outliers-univariados","title":"Outliers Univariados","text":"<pre><code>def detect_outliers_iqr(df, column):\n    \"\"\"Detecta outliers usando m\u00e9todo IQR\"\"\"\n    Q1 = df[column].quantile(0.25)\n    Q3 = df[column].quantile(0.75)\n    IQR = Q3 - Q1\n    lower_bound = Q1 - 1.5 * IQR\n    upper_bound = Q3 + 1.5 * IQR\n\n    outliers = df[(df[column] &lt; lower_bound) | (df[column] &gt; upper_bound)]\n    return outliers, lower_bound, upper_bound\n\n# Aplicar para colunas num\u00e9ricas\nnumeric_columns = df.select_dtypes(include=[np.number]).columns\nfor col in numeric_columns:\n    outliers, lower, upper = detect_outliers_iqr(df, col)\n    print(f\"{col}: {len(outliers)} outliers ({len(outliers)/len(df)*100:.2f}%)\")\n</code></pre>"},{"location":"aulas/IA/conceitos/eda.html#fase-3-analise-univariada","title":"Fase 3: An\u00e1lise Univariada","text":""},{"location":"aulas/IA/conceitos/eda.html#variaveis-numericas","title":"Vari\u00e1veis Num\u00e9ricas","text":"<pre><code># Estat\u00edsticas descritivas detalhadas\ndesc_stats = df.describe(include='all').T\ndesc_stats['missing'] = df.isnull().sum()\ndesc_stats['missing_pct'] = (desc_stats['missing'] / len(df)) * 100\nprint(desc_stats)\n\n# Estat\u00edsticas adicionais\nfor col in numeric_columns:\n    data = df[col].dropna()\n    print(f\"\\n{col}:\")\n    print(f\"  Assimetria (Skewness): {data.skew():.3f}\")\n    print(f\"  Curtose (Kurtosis): {data.kurtosis():.3f}\")\n    print(f\"  Coeficiente de Varia\u00e7\u00e3o: {(data.std() / data.mean()):.3f}\")\n</code></pre>"},{"location":"aulas/IA/conceitos/eda.html#variaveis-categoricas","title":"Vari\u00e1veis Categ\u00f3ricas","text":"<pre><code># An\u00e1lise de frequ\u00eancias\ncategorical_columns = df.select_dtypes(include=['object', 'category']).columns\n\nfor col in categorical_columns:\n    print(f\"\\n=== {col} ===\")\n    freq_table = df[col].value_counts()\n    freq_percent = df[col].value_counts(normalize=True) * 100\n\n    freq_summary = pd.DataFrame({\n        'Frequ\u00eancia': freq_table,\n        'Porcentagem': freq_percent\n    })\n    print(freq_summary.head(10))\n\n    # Verificar cardinalidade\n    cardinality = df[col].nunique()\n    print(f\"Cardinalidade: {cardinality}\")\n    if cardinality &gt; 50:\n        print(\"\u26a0\ufe0f Alta cardinalidade - considere agrupamento\")\n</code></pre>"},{"location":"aulas/IA/conceitos/eda.html#fase-4-analise-bivariada","title":"Fase 4: An\u00e1lise Bivariada","text":""},{"location":"aulas/IA/conceitos/eda.html#correlacoes","title":"Correla\u00e7\u00f5es","text":"<pre><code>import matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Matriz de correla\u00e7\u00e3o\ncorrelation_matrix = df[numeric_columns].corr()\n\n# Identificar correla\u00e7\u00f5es fortes\ndef find_strong_correlations(corr_matrix, threshold=0.7):\n    \"\"\"Encontra pares de vari\u00e1veis com correla\u00e7\u00e3o forte\"\"\"\n    strong_corr = []\n    for i in range(len(corr_matrix.columns)):\n        for j in range(i+1, len(corr_matrix.columns)):\n            corr_value = abs(corr_matrix.iloc[i, j])\n            if corr_value &gt; threshold:\n                strong_corr.append({\n                    'var1': corr_matrix.columns[i],\n                    'var2': corr_matrix.columns[j],\n                    'correlation': corr_matrix.iloc[i, j]\n                })\n    return pd.DataFrame(strong_corr).sort_values('correlation', key=abs, ascending=False)\n\nstrong_correlations = find_strong_correlations(correlation_matrix)\nprint(\"Correla\u00e7\u00f5es fortes (|r| &gt; 0.7):\")\nprint(strong_correlations)\n</code></pre>"},{"location":"aulas/IA/conceitos/eda.html#analise-por-grupos","title":"An\u00e1lise por Grupos","text":"<pre><code># Se houver vari\u00e1vel target categ\u00f3rica\nif 'target' in df.columns:\n    target_col = 'target'\n\n    # Estat\u00edsticas por grupo\n    for col in numeric_columns:\n        if col != target_col:\n            group_stats = df.groupby(target_col)[col].describe()\n            print(f\"\\n{col} por {target_col}:\")\n            print(group_stats)\n\n    # Teste estat\u00edstico (exemplo: ANOVA)\n    from scipy import stats\n\n    for col in numeric_columns:\n        if col != target_col:\n            groups = [group[col].dropna() for name, group in df.groupby(target_col)]\n            if len(groups) &gt; 1:\n                f_stat, p_value = stats.f_oneway(*groups)\n                print(f\"\\n{col} - ANOVA: F={f_stat:.3f}, p={p_value:.3f}\")\n</code></pre>"},{"location":"aulas/IA/conceitos/eda.html#fase-5-analise-multivariada","title":"Fase 5: An\u00e1lise Multivariada","text":""},{"location":"aulas/IA/conceitos/eda.html#analise-de-componentes-principais-pca","title":"An\u00e1lise de Componentes Principais (PCA)","text":"<pre><code>from sklearn.decomposition import PCA\nfrom sklearn.preprocessing import StandardScaler\n\n# Preparar dados para PCA\nnumeric_data = df[numeric_columns].dropna()\nscaler = StandardScaler()\nscaled_data = scaler.fit_transform(numeric_data)\n\n# Aplicar PCA\npca = PCA()\npca_result = pca.fit_transform(scaled_data)\n\n# Vari\u00e2ncia explicada\nexplained_variance = pca.explained_variance_ratio_\ncumulative_variance = np.cumsum(explained_variance)\n\nprint(\"Vari\u00e2ncia explicada por componente:\")\nfor i, (individual, cumulative) in enumerate(zip(explained_variance, cumulative_variance)):\n    print(f\"PC{i+1}: {individual:.3f} (Cumulativa: {cumulative:.3f})\")\n\n# N\u00famero de componentes para 90% da vari\u00e2ncia\nn_components_90 = np.argmax(cumulative_variance &gt;= 0.9) + 1\nprint(f\"\\nComponentes necess\u00e1rios para 90% da vari\u00e2ncia: {n_components_90}\")\n</code></pre>"},{"location":"aulas/IA/conceitos/eda.html#padroes-comuns-e-red-flags","title":"Padr\u00f5es Comuns e Red Flags","text":""},{"location":"aulas/IA/conceitos/eda.html#distribuicoes-problematicas","title":"Distribui\u00e7\u00f5es Problem\u00e1ticas","text":""},{"location":"aulas/IA/conceitos/eda.html#alta-assimetria","title":"Alta Assimetria","text":"<pre><code>def analyze_skewness(df, threshold=2):\n    \"\"\"Analisa assimetria das vari\u00e1veis num\u00e9ricas\"\"\"\n    skewed_features = []\n    for col in df.select_dtypes(include=[np.number]).columns:\n        skew_value = df[col].skew()\n        if abs(skew_value) &gt; threshold:\n            skewed_features.append({\n                'feature': col,\n                'skewness': skew_value,\n                'interpretation': 'Positiva' if skew_value &gt; 0 else 'Negativa'\n            })\n    return pd.DataFrame(skewed_features)\n\nskewed_analysis = analyze_skewness(df)\nprint(\"Vari\u00e1veis com alta assimetria:\")\nprint(skewed_analysis)\n</code></pre>"},{"location":"aulas/IA/conceitos/eda.html#transformacoes-sugeridas","title":"Transforma\u00e7\u00f5es Sugeridas","text":"<pre><code># Sugest\u00f5es de transforma\u00e7\u00e3o baseadas na assimetria\ndef suggest_transformations(skewness):\n    \"\"\"Sugere transforma\u00e7\u00f5es baseadas na assimetria\"\"\"\n    abs_skew = abs(skewness)\n    if abs_skew &lt; 0.5:\n        return \"Normal - sem transforma\u00e7\u00e3o necess\u00e1ria\"\n    elif abs_skew &lt; 1:\n        return \"Ligeiramente assim\u00e9trica - considere sqrt ou log\"\n    elif abs_skew &lt; 2:\n        return \"Moderadamente assim\u00e9trica - use log ou Box-Cox\"\n    else:\n        return \"Altamente assim\u00e9trica - use log, Box-Cox ou Yeo-Johnson\"\n\nfor _, row in skewed_analysis.iterrows():\n    suggestion = suggest_transformations(row['skewness'])\n    print(f\"{row['feature']}: {suggestion}\")\n</code></pre>"},{"location":"aulas/IA/conceitos/eda.html#deteccao-de-padroes-temporais","title":"Detec\u00e7\u00e3o de Padr\u00f5es Temporais","text":"<pre><code># Se houver coluna de data\ndef analyze_temporal_patterns(df, date_col, value_col):\n    \"\"\"Analisa padr\u00f5es temporais nos dados\"\"\"\n    df_temp = df.copy()\n    df_temp[date_col] = pd.to_datetime(df_temp[date_col])\n    df_temp = df_temp.sort_values(date_col)\n\n    # Extrair componentes temporais\n    df_temp['year'] = df_temp[date_col].dt.year\n    df_temp['month'] = df_temp[date_col].dt.month\n    df_temp['day_of_week'] = df_temp[date_col].dt.day_of_week\n    df_temp['hour'] = df_temp[date_col].dt.hour\n\n    # An\u00e1lise por per\u00edodo\n    patterns = {}\n    patterns['yearly'] = df_temp.groupby('year')[value_col].mean()\n    patterns['monthly'] = df_temp.groupby('month')[value_col].mean()\n    patterns['weekly'] = df_temp.groupby('day_of_week')[value_col].mean()\n\n    return patterns\n\n# Exemplo de uso\n# if 'date' in df.columns and 'sales' in df.columns:\n#     temporal_patterns = analyze_temporal_patterns(df, 'date', 'sales')\n</code></pre>"},{"location":"aulas/IA/conceitos/eda.html#checklist-de-eda","title":"Checklist de EDA","text":""},{"location":"aulas/IA/conceitos/eda.html#checklist-basico","title":"\u2705 Checklist B\u00e1sico","text":"<ol> <li>Conhecimento dos Dados</li> <li> Dimens\u00f5es do dataset</li> <li> Tipos de vari\u00e1veis</li> <li> <p> Primeiras observa\u00e7\u00f5es</p> </li> <li> <p>Qualidade dos Dados</p> </li> <li> Valores ausentes identificados</li> <li> Duplicatas verificadas</li> <li> Inconsist\u00eancias analisadas</li> <li> <p> Outliers detectados</p> </li> <li> <p>An\u00e1lise Univariada</p> </li> <li> Estat\u00edsticas descritivas calculadas</li> <li> Distribui\u00e7\u00f5es analisadas</li> <li> <p> Frequ\u00eancias de categorias verificadas</p> </li> <li> <p>An\u00e1lise Bivariada</p> </li> <li> Correla\u00e7\u00f5es calculadas</li> <li> Relacionamentos principais identificados</li> <li> <p> An\u00e1lise por grupos realizada</p> </li> <li> <p>Insights e Pr\u00f3ximos Passos</p> </li> <li> Padr\u00f5es principais documentados</li> <li> Hip\u00f3teses formuladas</li> <li> Estrat\u00e9gias de tratamento definidas</li> </ol>"},{"location":"aulas/IA/conceitos/eda.html#perguntas-chave-para-cada-etapa","title":"\ud83c\udfaf Perguntas-Chave para Cada Etapa","text":""},{"location":"aulas/IA/conceitos/eda.html#conhecimento-inicial","title":"Conhecimento Inicial","text":"<ul> <li>Qual \u00e9 o tamanho do dataset?</li> <li>Que tipos de vari\u00e1veis temos?</li> <li>Os dados fazem sentido do ponto de vista do neg\u00f3cio?</li> </ul>"},{"location":"aulas/IA/conceitos/eda.html#qualidade","title":"Qualidade","text":"<ul> <li>H\u00e1 valores ausentes significativos?</li> <li>Existem inconsist\u00eancias \u00f3bvias?</li> <li>Os outliers s\u00e3o erros ou casos extremos v\u00e1lidos?</li> </ul>"},{"location":"aulas/IA/conceitos/eda.html#padroes","title":"Padr\u00f5es","text":"<ul> <li>Quais vari\u00e1veis s\u00e3o mais importantes?</li> <li>Existem grupos naturais nos dados?</li> <li>H\u00e1 relacionamentos n\u00e3o-lineares?</li> </ul>"},{"location":"aulas/IA/conceitos/eda.html#acao","title":"A\u00e7\u00e3o","text":"<ul> <li>Que transforma\u00e7\u00f5es s\u00e3o necess\u00e1rias?</li> <li>Quais vari\u00e1veis podem ser removidas?</li> <li>Que an\u00e1lises adicionais s\u00e3o recomendadas?</li> </ul>"},{"location":"aulas/IA/conceitos/eda.html#ferramentas-automatizadas-de-eda","title":"Ferramentas Automatizadas de EDA","text":""},{"location":"aulas/IA/conceitos/eda.html#pandas-profiling","title":"Pandas Profiling","text":"<pre><code># pip install pandas-profiling\nfrom pandas_profiling import ProfileReport\n\n# Gerar relat\u00f3rio autom\u00e1tico\nprofile = ProfileReport(df, title=\"EDA Autom\u00e1tica\", explorative=True)\nprofile.to_file(\"eda_report.html\")\n</code></pre>"},{"location":"aulas/IA/conceitos/eda.html#sweetviz","title":"Sweetviz","text":"<pre><code># pip install sweetviz\nimport sweetviz as sv\n\n# An\u00e1lise completa\nreport = sv.analyze(df)\nreport.show_html(\"sweetviz_report.html\")\n\n# Compara\u00e7\u00e3o entre datasets\n# report = sv.compare([df_train, \"Treino\"], [df_test, \"Teste\"])\n</code></pre>"},{"location":"aulas/IA/conceitos/eda.html#autoviz","title":"AutoViz","text":"<pre><code># pip install autoviz\nfrom autoviz.AutoViz_Class import AutoViz_Class\n\nAV = AutoViz_Class()\ndft = AV.AutoViz(\"dataset.csv\")\n</code></pre>"},{"location":"aulas/IA/conceitos/eda.html#documentacao-e-comunicacao","title":"Documenta\u00e7\u00e3o e Comunica\u00e7\u00e3o","text":""},{"location":"aulas/IA/conceitos/eda.html#template-de-relatorio-eda","title":"Template de Relat\u00f3rio EDA","text":"<pre><code># Relat\u00f3rio de An\u00e1lise Explorat\u00f3ria de Dados\n\n## 1. Resumo Executivo\n- Principais descobertas\n- Recomenda\u00e7\u00f5es imediatas\n- Pr\u00f3ximos passos\n\n## 2. Vis\u00e3o Geral dos Dados\n- Fonte e contexto\n- Dimens\u00f5es e estrutura\n- Qualidade geral\n\n## 3. An\u00e1lise Detalhada\n- Distribui\u00e7\u00f5es das vari\u00e1veis\n- Relacionamentos identificados\n- Padr\u00f5es e anomalias\n\n## 4. Insights de Neg\u00f3cio\n- Implica\u00e7\u00f5es pr\u00e1ticas\n- Oportunidades identificadas\n- Riscos e limita\u00e7\u00f5es\n\n## 5. Recomenda\u00e7\u00f5es T\u00e9cnicas\n- Tratamentos necess\u00e1rios\n- Vari\u00e1veis para feature engineering\n- Estrat\u00e9gias de modelagem\n</code></pre>"},{"location":"aulas/IA/conceitos/eda.html#boas-praticas-de-comunicacao","title":"Boas Pr\u00e1ticas de Comunica\u00e7\u00e3o","text":"<ol> <li>Use Visualiza\u00e7\u00f5es Efetivas</li> <li>Escolha o gr\u00e1fico certo para cada tipo de dado</li> <li>Mantenha simplicidade e clareza</li> <li> <p>Adicione contexto e interpreta\u00e7\u00e3o</p> </li> <li> <p>Conte uma Hist\u00f3ria</p> </li> <li>Organize insights de forma l\u00f3gica</li> <li>Conecte descobertas com objetivos de neg\u00f3cio</li> <li> <p>Use linguagem acess\u00edvel ao p\u00fablico-alvo</p> </li> <li> <p>Seja Honesto sobre Limita\u00e7\u00f5es</p> </li> <li>Mencione dados ausentes significativos</li> <li>Identifique potenciais vieses</li> <li>Sugira valida\u00e7\u00f5es adicionais</li> </ol> <p>A EDA \u00e9 uma arte que combina t\u00e9cnica estat\u00edstica, intui\u00e7\u00e3o de neg\u00f3cio e pensamento cr\u00edtico. Quanto mais voc\u00ea pratica, mais eficiente se torna em extrair insights valiosos dos dados.</p>"},{"location":"aulas/IA/conceitos/matplotlib.html","title":"Matplotlib: Visualiza\u00e7\u00e3o de Dados em Python","text":""},{"location":"aulas/IA/conceitos/matplotlib.html#introducao","title":"Introdu\u00e7\u00e3o","text":"<p>Matplotlib \u00e9 a biblioteca de visualiza\u00e7\u00e3o de dados mais fundamental em Python. \u00c9 a base para muitas outras bibliotecas de plotagem (como Seaborn) e oferece controle completo sobre todos os aspectos de uma figura, desde elementos b\u00e1sicos at\u00e9 customiza\u00e7\u00f5es avan\u00e7adas.</p>"},{"location":"aulas/IA/conceitos/matplotlib.html#arquitetura-do-matplotlib","title":"Arquitetura do Matplotlib","text":""},{"location":"aulas/IA/conceitos/matplotlib.html#componentes-principais","title":"Componentes Principais","text":"<pre><code>import matplotlib.pyplot as plt\nimport numpy as np\n\n# Figura e Eixos - conceitos fundamentais\nfig, ax = plt.subplots()  # Cria figura e eixo\nax.plot([1, 2, 3, 4], [1, 4, 9, 16])  # Plota no eixo\nplt.show()  # Exibe a figura\n</code></pre>"},{"location":"aulas/IA/conceitos/matplotlib.html#hierarquia-de-objetos","title":"Hierarquia de Objetos","text":"<ul> <li>Figure: Container de n\u00edvel mais alto</li> <li>Axes: \u00c1rea de plotagem (eixos x, y)</li> <li>Axis: Eixos individuais (x ou y)</li> <li>Artist: Todos os elementos visuais</li> </ul>"},{"location":"aulas/IA/conceitos/matplotlib.html#interfaces-do-matplotlib","title":"Interfaces do Matplotlib","text":""},{"location":"aulas/IA/conceitos/matplotlib.html#1-interface-pyplot-matlab-style","title":"1. Interface pyplot (MATLAB-style)","text":"<pre><code>import matplotlib.pyplot as plt\n\n# Estilo MATLAB - mais simples para plots r\u00e1pidos\nplt.plot([1, 2, 3, 4], [1, 4, 9, 16])\nplt.title('Meu Primeiro Gr\u00e1fico')\nplt.xlabel('X')\nplt.ylabel('Y')\nplt.show()\n</code></pre>"},{"location":"aulas/IA/conceitos/matplotlib.html#2-interface-orientada-a-objetos","title":"2. Interface Orientada a Objetos","text":"<pre><code># Mais controle e flexibilidade\nfig, ax = plt.subplots(figsize=(8, 6))\nax.plot([1, 2, 3, 4], [1, 4, 9, 16], marker='o')\nax.set_title('Gr\u00e1fico com OO Interface')\nax.set_xlabel('X')\nax.set_ylabel('Y')\nplt.show()\n</code></pre>"},{"location":"aulas/IA/conceitos/matplotlib.html#tipos-de-graficos","title":"Tipos de Gr\u00e1ficos","text":""},{"location":"aulas/IA/conceitos/matplotlib.html#graficos-de-linha","title":"Gr\u00e1ficos de Linha","text":"<pre><code># Dados de exemplo\nx = np.linspace(0, 10, 100)\ny1 = np.sin(x)\ny2 = np.cos(x)\n\n# Gr\u00e1fico b\u00e1sico\nplt.figure(figsize=(10, 6))\nplt.plot(x, y1, label='sen(x)', color='blue', linewidth=2)\nplt.plot(x, y2, label='cos(x)', color='red', linestyle='--')\nplt.title('Fun\u00e7\u00f5es Trigonom\u00e9tricas')\nplt.xlabel('x')\nplt.ylabel('y')\nplt.legend()\nplt.grid(True, alpha=0.3)\nplt.show()\n</code></pre>"},{"location":"aulas/IA/conceitos/matplotlib.html#customizacao-de-linhas","title":"Customiza\u00e7\u00e3o de Linhas","text":"<pre><code># Estilos de linha\nline_styles = ['-', '--', '-.', ':']\ncolors = ['b', 'g', 'r', 'c', 'm', 'y', 'k']\nmarkers = ['o', 's', '^', 'v', '&lt;', '&gt;', 'D']\n\nfig, ax = plt.subplots(figsize=(12, 8))\n\nfor i, (style, color, marker) in enumerate(zip(line_styles, colors, markers)):\n    y = np.sin(x + i * 0.5)\n    ax.plot(x, y, \n            linestyle=style, \n            color=color, \n            marker=marker,\n            markersize=8,\n            markevery=10,  # Marcador a cada 10 pontos\n            label=f'Linha {i+1}')\n\nax.legend()\nax.set_title('Estilos de Linha Customizados')\nplt.show()\n</code></pre>"},{"location":"aulas/IA/conceitos/matplotlib.html#graficos-de-barras","title":"Gr\u00e1ficos de Barras","text":"<pre><code># Dados categ\u00f3ricos\ncategorias = ['A', 'B', 'C', 'D', 'E']\nvalores = [23, 45, 56, 78, 32]\n\n# Gr\u00e1fico de barras vertical\nfig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 5))\n\n# Barras verticais\nbars1 = ax1.bar(categorias, valores, color=['red', 'green', 'blue', 'orange', 'purple'])\nax1.set_title('Gr\u00e1fico de Barras Vertical')\nax1.set_ylabel('Valores')\n\n# Adicionar valores nas barras\nfor bar in bars1:\n    height = bar.get_height()\n    ax1.text(bar.get_x() + bar.get_width()/2., height,\n             f'{height}', ha='center', va='bottom')\n\n# Barras horizontais\nbars2 = ax2.barh(categorias, valores, color='skyblue')\nax2.set_title('Gr\u00e1fico de Barras Horizontal')\nax2.set_xlabel('Valores')\n\nplt.tight_layout()\nplt.show()\n</code></pre>"},{"location":"aulas/IA/conceitos/matplotlib.html#barras-agrupadas-e-empilhadas","title":"Barras Agrupadas e Empilhadas","text":"<pre><code># Dados para m\u00faltiplas s\u00e9ries\ngrupos = ['Grupo 1', 'Grupo 2', 'Grupo 3', 'Grupo 4']\nvalores_serie1 = [20, 35, 30, 35]\nvalores_serie2 = [25, 30, 15, 30]\nvalores_serie3 = [15, 25, 25, 15]\n\nx = np.arange(len(grupos))  # Posi\u00e7\u00f5es dos grupos\nwidth = 0.25  # Largura das barras\n\nfig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n\n# Barras agrupadas\nbars1 = ax1.bar(x - width, valores_serie1, width, label='S\u00e9rie 1', color='lightcoral')\nbars2 = ax1.bar(x, valores_serie2, width, label='S\u00e9rie 2', color='lightskyblue')\nbars3 = ax1.bar(x + width, valores_serie3, width, label='S\u00e9rie 3', color='lightgreen')\n\nax1.set_xlabel('Grupos')\nax1.set_ylabel('Valores')\nax1.set_title('Barras Agrupadas')\nax1.set_xticks(x)\nax1.set_xticklabels(grupos)\nax1.legend()\n\n# Barras empilhadas\nax2.bar(grupos, valores_serie1, label='S\u00e9rie 1', color='lightcoral')\nax2.bar(grupos, valores_serie2, bottom=valores_serie1, label='S\u00e9rie 2', color='lightskyblue')\nax2.bar(grupos, valores_serie3, \n        bottom=np.array(valores_serie1) + np.array(valores_serie2), \n        label='S\u00e9rie 3', color='lightgreen')\n\nax2.set_ylabel('Valores')\nax2.set_title('Barras Empilhadas')\nax2.legend()\n\nplt.tight_layout()\nplt.show()\n</code></pre>"},{"location":"aulas/IA/conceitos/matplotlib.html#histogramas","title":"Histogramas","text":"<pre><code># Dados para histograma\nnp.random.seed(42)\ndados = np.random.normal(100, 15, 1000)  # Distribui\u00e7\u00e3o normal\n\nfig, axes = plt.subplots(2, 2, figsize=(12, 10))\n\n# Histograma b\u00e1sico\naxes[0,0].hist(dados, bins=30, color='skyblue', alpha=0.7, edgecolor='black')\naxes[0,0].set_title('Histograma B\u00e1sico')\naxes[0,0].set_xlabel('Valores')\naxes[0,0].set_ylabel('Frequ\u00eancia')\n\n# Histograma com densidade\naxes[0,1].hist(dados, bins=30, density=True, color='lightgreen', alpha=0.7)\naxes[0,1].set_title('Histograma com Densidade')\naxes[0,1].set_xlabel('Valores')\naxes[0,1].set_ylabel('Densidade')\n\n# Histograma com m\u00faltiplas s\u00e9ries\ndados2 = np.random.normal(110, 20, 1000)\naxes[1,0].hist([dados, dados2], bins=30, label=['S\u00e9rie 1', 'S\u00e9rie 2'], \n               color=['skyblue', 'lightcoral'], alpha=0.7)\naxes[1,0].set_title('M\u00faltiplas S\u00e9ries')\naxes[1,0].legend()\n\n# Histograma cumulativo\naxes[1,1].hist(dados, bins=30, cumulative=True, color='orange', alpha=0.7)\naxes[1,1].set_title('Histograma Cumulativo')\naxes[1,1].set_xlabel('Valores')\naxes[1,1].set_ylabel('Frequ\u00eancia Cumulativa')\n\nplt.tight_layout()\nplt.show()\n</code></pre>"},{"location":"aulas/IA/conceitos/matplotlib.html#graficos-de-dispersao","title":"Gr\u00e1ficos de Dispers\u00e3o","text":"<pre><code># Dados para scatter plot\nnp.random.seed(42)\nn = 200\nx = np.random.randn(n)\ny = 2 * x + np.random.randn(n) * 0.5\ncolors = np.random.rand(n)\nsizes = 1000 * np.random.rand(n)\n\nfig, axes = plt.subplots(2, 2, figsize=(12, 10))\n\n# Scatter b\u00e1sico\naxes[0,0].scatter(x, y, alpha=0.6)\naxes[0,0].set_title('Scatter Plot B\u00e1sico')\naxes[0,0].set_xlabel('X')\naxes[0,0].set_ylabel('Y')\n\n# Scatter com cores\nscatter = axes[0,1].scatter(x, y, c=colors, alpha=0.6, cmap='viridis')\naxes[0,1].set_title('Scatter com Cores')\nplt.colorbar(scatter, ax=axes[0,1])\n\n# Scatter com tamanhos vari\u00e1veis\naxes[1,0].scatter(x, y, s=sizes, alpha=0.6, c='red')\naxes[1,0].set_title('Scatter com Tamanhos Vari\u00e1veis')\n\n# Scatter com linha de regress\u00e3o\naxes[1,1].scatter(x, y, alpha=0.6)\n# Adicionar linha de regress\u00e3o\nz = np.polyfit(x, y, 1)\np = np.poly1d(z)\naxes[1,1].plot(x, p(x), \"r--\", alpha=0.8)\naxes[1,1].set_title('Scatter com Linha de Regress\u00e3o')\n\nplt.tight_layout()\nplt.show()\n</code></pre>"},{"location":"aulas/IA/conceitos/matplotlib.html#box-plots","title":"Box Plots","text":"<pre><code># Dados para box plots\nnp.random.seed(42)\ndata_to_plot = [np.random.normal(0, std, 100) for std in range(1, 4)]\n\nfig, axes = plt.subplots(1, 3, figsize=(15, 5))\n\n# Box plot b\u00e1sico\nbp1 = axes[0].boxplot(data_to_plot, labels=['Grupo 1', 'Grupo 2', 'Grupo 3'])\naxes[0].set_title('Box Plot B\u00e1sico')\n\n# Box plot customizado\nbp2 = axes[1].boxplot(data_to_plot, \n                      labels=['Grupo 1', 'Grupo 2', 'Grupo 3'],\n                      patch_artist=True,  # Permite colorir\n                      notch=True,         # Mostra intervalo de confian\u00e7a\n                      showmeans=True)     # Mostra m\u00e9dia\n\n# Colorir os boxes\ncolors = ['lightblue', 'lightgreen', 'lightcoral']\nfor patch, color in zip(bp2['boxes'], colors):\n    patch.set_facecolor(color)\n\naxes[1].set_title('Box Plot Customizado')\n\n# Box plot horizontal\nbp3 = axes[2].boxplot(data_to_plot, \n                      labels=['Grupo 1', 'Grupo 2', 'Grupo 3'],\n                      vert=False,  # Horizontal\n                      patch_artist=True)\n\nfor patch, color in zip(bp3['boxes'], colors):\n    patch.set_facecolor(color)\n\naxes[2].set_title('Box Plot Horizontal')\n\nplt.tight_layout()\nplt.show()\n</code></pre>"},{"location":"aulas/IA/conceitos/matplotlib.html#graficos-de-pizza","title":"Gr\u00e1ficos de Pizza","text":"<pre><code># Dados para gr\u00e1fico de pizza\nlabels = ['Python', 'Java', 'JavaScript', 'C++', 'C#']\nsizes = [30, 25, 20, 15, 10]\nexplode = (0.1, 0, 0, 0, 0)  # \"Explodir\" primeira fatia\ncolors = ['gold', 'yellowgreen', 'lightcoral', 'lightskyblue', 'lightpink']\n\nfig, axes = plt.subplots(1, 2, figsize=(12, 6))\n\n# Pizza b\u00e1sica\naxes[0].pie(sizes, labels=labels, autopct='%1.1f%%', startangle=90)\naxes[0].set_title('Distribui\u00e7\u00e3o de Linguagens de Programa\u00e7\u00e3o')\n\n# Pizza customizada\naxes[1].pie(sizes, \n            labels=labels, \n            explode=explode,\n            colors=colors,\n            autopct='%1.1f%%', \n            shadow=True, \n            startangle=90)\naxes[1].set_title('Pizza Customizada')\n\nplt.tight_layout()\nplt.show()\n</code></pre>"},{"location":"aulas/IA/conceitos/matplotlib.html#subplots-e-layouts","title":"Subplots e Layouts","text":""},{"location":"aulas/IA/conceitos/matplotlib.html#subplots-basicos","title":"Subplots B\u00e1sicos","text":"<pre><code># Criando m\u00faltiplos subplots\nfig, axes = plt.subplots(2, 3, figsize=(15, 10))\n\n# Dados de exemplo\nx = np.linspace(0, 2*np.pi, 100)\n\n# Plotar em cada subplot\nplots_data = [\n    (np.sin(x), 'sin(x)', 'blue'),\n    (np.cos(x), 'cos(x)', 'red'),\n    (np.tan(x), 'tan(x)', 'green'),\n    (np.sinh(x), 'sinh(x)', 'orange'),\n    (np.cosh(x), 'cosh(x)', 'purple'),\n    (np.tanh(x), 'tanh(x)', 'brown')\n]\n\nfor i, (y_data, title, color) in enumerate(plots_data):\n    row = i // 3\n    col = i % 3\n    axes[row, col].plot(x, y_data, color=color)\n    axes[row, col].set_title(title)\n    axes[row, col].grid(True, alpha=0.3)\n\nplt.tight_layout()\nplt.show()\n</code></pre>"},{"location":"aulas/IA/conceitos/matplotlib.html#gridspec-para-layouts-complexos","title":"GridSpec para Layouts Complexos","text":"<pre><code>import matplotlib.gridspec as gridspec\n\n# Layout complexo com GridSpec\nfig = plt.figure(figsize=(12, 10))\ngs = gridspec.GridSpec(3, 3, hspace=0.3, wspace=0.3)\n\n# Plot principal (2x2)\nax1 = fig.add_subplot(gs[0:2, 0:2])\nax1.plot(x, np.sin(x), 'b-', linewidth=2)\nax1.set_title('Plot Principal')\n\n# Plot superior direito\nax2 = fig.add_subplot(gs[0, 2])\nax2.hist(np.random.randn(1000), bins=30, color='red', alpha=0.7)\nax2.set_title('Histograma')\n\n# Plot do meio direito\nax3 = fig.add_subplot(gs[1, 2])\nax3.scatter(np.random.randn(100), np.random.randn(100), alpha=0.6)\nax3.set_title('Scatter')\n\n# Plot inferior (span 3 colunas)\nax4 = fig.add_subplot(gs[2, :])\nax4.bar(['A', 'B', 'C', 'D'], [1, 3, 2, 4], color='green', alpha=0.7)\nax4.set_title('Barras (Span 3 colunas)')\n\nplt.show()\n</code></pre>"},{"location":"aulas/IA/conceitos/matplotlib.html#customizacao-avancada","title":"Customiza\u00e7\u00e3o Avan\u00e7ada","text":""},{"location":"aulas/IA/conceitos/matplotlib.html#cores-e-estilos","title":"Cores e Estilos","text":"<pre><code># Definir esquemas de cores\nfrom matplotlib import cm\nimport matplotlib.colors as mcolors\n\nfig, axes = plt.subplots(2, 2, figsize=(12, 10))\n\n# Cores b\u00e1sicas\nx = np.linspace(0, 10, 100)\ncolors_basic = ['red', 'green', 'blue', 'orange', 'purple']\n\nfor i, color in enumerate(colors_basic):\n    y = np.sin(x + i * 0.5)\n    axes[0,0].plot(x, y, color=color, label=f'Linha {i+1}')\naxes[0,0].set_title('Cores B\u00e1sicas')\naxes[0,0].legend()\n\n# Colormap\ncolormap = cm.get_cmap('viridis')\nfor i in range(5):\n    y = np.sin(x + i * 0.5)\n    color = colormap(i / 4)  # Normalizar entre 0 e 1\n    axes[0,1].plot(x, y, color=color, label=f'Linha {i+1}')\naxes[0,1].set_title('Usando Colormap')\naxes[0,1].legend()\n\n# Cores hexadecimais\nhex_colors = ['#FF6B6B', '#4ECDC4', '#45B7D1', '#FFA07A', '#98D8C8']\nfor i, color in enumerate(hex_colors):\n    y = np.sin(x + i * 0.5)\n    axes[1,0].plot(x, y, color=color, label=f'Linha {i+1}')\naxes[1,0].set_title('Cores Hexadecimais')\naxes[1,0].legend()\n\n# Transpar\u00eancia (alpha)\nfor i in range(5):\n    y = np.sin(x + i * 0.5)\n    alpha = 0.2 + (i * 0.2)  # Alpha de 0.2 a 1.0\n    axes[1,1].plot(x, y, color='blue', alpha=alpha, \n                   linewidth=3, label=f'Alpha {alpha:.1f}')\naxes[1,1].set_title('Transpar\u00eancia (Alpha)')\naxes[1,1].legend()\n\nplt.tight_layout()\nplt.show()\n</code></pre>"},{"location":"aulas/IA/conceitos/matplotlib.html#anotacoes-e-texto","title":"Anota\u00e7\u00f5es e Texto","text":"<pre><code>fig, ax = plt.subplots(figsize=(10, 8))\n\n# Dados\nx = np.linspace(0, 10, 100)\ny = np.sin(x)\n\nax.plot(x, y, 'b-', linewidth=2)\n\n# T\u00edtulo e labels\nax.set_title('Exemplo de Anota\u00e7\u00f5es e Texto', fontsize=16, fontweight='bold')\nax.set_xlabel('Eixo X', fontsize=12)\nax.set_ylabel('sin(x)', fontsize=12)\n\n# Anota\u00e7\u00f5es com setas\nax.annotate('M\u00e1ximo local', \n            xy=(np.pi/2, 1), xytext=(2, 1.2),\n            arrowprops=dict(arrowstyle='-&gt;', color='red', lw=2),\n            fontsize=12, color='red')\n\nax.annotate('M\u00ednimo local', \n            xy=(3*np.pi/2, -1), xytext=(5, -1.2),\n            arrowprops=dict(arrowstyle='-&gt;', color='green', lw=2),\n            fontsize=12, color='green')\n\n# Texto simples\nax.text(7, 0.5, 'Fun\u00e7\u00e3o Seno', fontsize=14, \n        bbox=dict(boxstyle=\"round,pad=0.3\", facecolor=\"yellow\", alpha=0.7))\n\n# Linha vertical e horizontal de refer\u00eancia\nax.axvline(x=np.pi, color='gray', linestyle='--', alpha=0.7, label='\u03c0')\nax.axhline(y=0, color='black', linestyle='-', alpha=0.3)\n\nax.legend()\nax.grid(True, alpha=0.3)\nplt.show()\n</code></pre>"},{"location":"aulas/IA/conceitos/matplotlib.html#estilos-e-temas","title":"Estilos e Temas","text":"<pre><code># Estilos dispon\u00edveis\nprint(\"Estilos dispon\u00edveis:\")\nprint(plt.style.available)\n\n# Aplicar diferentes estilos\nstyles = ['default', 'seaborn-v0_8', 'ggplot', 'classic']\nfig, axes = plt.subplots(2, 2, figsize=(12, 10))\n\nx = np.linspace(0, 10, 100)\ny = np.sin(x)\n\nfor i, style in enumerate(styles):\n    with plt.style.context(style):\n        row = i // 2\n        col = i % 2\n        axes[row, col].plot(x, y, linewidth=2)\n        axes[row, col].set_title(f'Estilo: {style}')\n        axes[row, col].grid(True)\n\nplt.tight_layout()\nplt.show()\n</code></pre>"},{"location":"aulas/IA/conceitos/matplotlib.html#integracao-com-pandas","title":"Integra\u00e7\u00e3o com Pandas","text":""},{"location":"aulas/IA/conceitos/matplotlib.html#plotting-direto-do-dataframe","title":"Plotting Direto do DataFrame","text":"<pre><code>import pandas as pd\n\n# Criar dados de exemplo\nnp.random.seed(42)\ndates = pd.date_range('2023-01-01', periods=100)\ndf = pd.DataFrame({\n    'vendas': np.random.randint(50, 200, 100),\n    'lucro': np.random.randint(10, 50, 100),\n    'despesas': np.random.randint(20, 80, 100)\n}, index=dates)\n\n# Matplotlib com Pandas\nfig, axes = plt.subplots(2, 2, figsize=(15, 10))\n\n# Plot direto do DataFrame\ndf.plot(ax=axes[0,0], title='S\u00e9rie Temporal')\n\n# Plot espec\u00edfico\ndf['vendas'].plot(ax=axes[0,1], kind='line', color='blue', title='Vendas')\n\n# Histograma\ndf['vendas'].plot(ax=axes[1,0], kind='hist', bins=20, alpha=0.7, title='Distribui\u00e7\u00e3o Vendas')\n\n# Box plot\ndf.plot(ax=axes[1,1], kind='box', title='Box Plot')\n\nplt.tight_layout()\nplt.show()\n</code></pre>"},{"location":"aulas/IA/conceitos/matplotlib.html#salvando-figuras","title":"Salvando Figuras","text":""},{"location":"aulas/IA/conceitos/matplotlib.html#diferentes-formatos","title":"Diferentes Formatos","text":"<pre><code># Criar uma figura\nfig, ax = plt.subplots(figsize=(8, 6))\nx = np.linspace(0, 10, 100)\ny = np.sin(x)\nax.plot(x, y, linewidth=2)\nax.set_title('Exemplo para Salvar')\n\n# Salvar em diferentes formatos\n# PNG (bitmap - boa qualidade, arquivo maior)\nplt.savefig('grafico.png', dpi=300, bbox_inches='tight')\n\n# PDF (vetor - excelente para publica\u00e7\u00f5es)\nplt.savefig('grafico.pdf', bbox_inches='tight')\n\n# SVG (vetor - bom para web)\nplt.savefig('grafico.svg', bbox_inches='tight')\n\n# JPG (compress\u00e3o - arquivo menor)\nplt.savefig('grafico.jpg', dpi=150, bbox_inches='tight', quality=95)\n\nplt.show()\n</code></pre>"},{"location":"aulas/IA/conceitos/matplotlib.html#configuracoes-avancadas-de-salvamento","title":"Configura\u00e7\u00f5es Avan\u00e7adas de Salvamento","text":"<pre><code># Configura\u00e7\u00f5es detalhadas\nplt.savefig('grafico_config.png',\n            dpi=300,                    # Resolu\u00e7\u00e3o\n            bbox_inches='tight',        # Remove espa\u00e7os em branco\n            pad_inches=0.1,            # Padding ao redor\n            facecolor='white',         # Cor de fundo\n            edgecolor='none',          # Cor da borda\n            transparent=False,         # Fundo transparente\n            orientation='landscape')   # Orienta\u00e7\u00e3o\n\nplt.show()\n</code></pre>"},{"location":"aulas/IA/conceitos/matplotlib.html#performance-e-boas-praticas","title":"Performance e Boas Pr\u00e1ticas","text":""},{"location":"aulas/IA/conceitos/matplotlib.html#otimizacao-para-grandes-datasets","title":"Otimiza\u00e7\u00e3o para Grandes Datasets","text":"<pre><code># Para muitos dados, usar rasteriza\u00e7\u00e3o\nfig, ax = plt.subplots()\n\n# Muitos pontos - usar rasterized=True\nx = np.random.randn(100000)\ny = np.random.randn(100000)\nax.scatter(x, y, alpha=0.5, rasterized=True)  # Converte para bitmap\n\nplt.savefig('scatter_otimizado.pdf', dpi=150)\nplt.show()\n</code></pre>"},{"location":"aulas/IA/conceitos/matplotlib.html#gestao-de-memoria","title":"Gest\u00e3o de Mem\u00f3ria","text":"<pre><code># Fechar figuras para liberar mem\u00f3ria\nplt.figure()\nplt.plot([1, 2, 3], [1, 4, 9])\nplt.close()  # Fecha a figura atual\n\n# Limpar todas as figuras\nplt.clf()   # Clear figure\nplt.cla()   # Clear axes\nplt.close('all')  # Fecha todas as figuras\n</code></pre>"},{"location":"aulas/IA/conceitos/matplotlib.html#resolucao-de-problemas-comuns","title":"Resolu\u00e7\u00e3o de Problemas Comuns","text":""},{"location":"aulas/IA/conceitos/matplotlib.html#backend-e-display","title":"Backend e Display","text":"<pre><code># Verificar backend atual\nprint(f\"Backend atual: {plt.get_backend()}\")\n\n# Configurar backend (se necess\u00e1rio)\nimport matplotlib\nmatplotlib.use('Agg')  # Para salvar sem exibir\n# matplotlib.use('TkAgg')  # Para exibi\u00e7\u00e3o interativa\n</code></pre>"},{"location":"aulas/IA/conceitos/matplotlib.html#configuracoes-globais","title":"Configura\u00e7\u00f5es Globais","text":"<pre><code># Configurar fonte padr\u00e3o\nplt.rcParams['font.size'] = 12\nplt.rcParams['font.family'] = 'serif'\n\n# Configurar figura padr\u00e3o\nplt.rcParams['figure.figsize'] = (10, 6)\nplt.rcParams['figure.dpi'] = 100\n\n# Resetar configura\u00e7\u00f5es\nplt.rcdefaults()\n</code></pre>"},{"location":"aulas/IA/conceitos/matplotlib.html#dicas-de-visualizacao-efetiva","title":"Dicas de Visualiza\u00e7\u00e3o Efetiva","text":""},{"location":"aulas/IA/conceitos/matplotlib.html#escolha-do-grafico-correto","title":"Escolha do Gr\u00e1fico Correto","text":"<pre><code># Diretrizes para escolha de gr\u00e1ficos:\nguia_graficos = {\n    'Comparar categorias': 'Barras verticais/horizontais',\n    'Distribui\u00e7\u00e3o de dados': 'Histograma, Box plot, Violin plot',\n    'Rela\u00e7\u00e3o entre vari\u00e1veis': 'Scatter plot',\n    'Tend\u00eancia temporal': 'Linha',\n    'Composi\u00e7\u00e3o/propor\u00e7\u00e3o': 'Pizza, Barras empilhadas',\n    'M\u00faltiplas vari\u00e1veis': 'Scatter matrix, Parallel coordinates'\n}\n\nfor uso, grafico in guia_graficos.items():\n    print(f\"{uso}: {grafico}\")\n</code></pre>"},{"location":"aulas/IA/conceitos/matplotlib.html#principios-de-design","title":"Princ\u00edpios de Design","text":"<pre><code># Exemplo de gr\u00e1fico bem formatado\nfig, ax = plt.subplots(figsize=(10, 6))\n\n# Dados\ncategories = ['Produto A', 'Produto B', 'Produto C', 'Produto D']\nvalues = [23, 45, 56, 78]\n\n# Barras com cores consistentes\nbars = ax.bar(categories, values, color='steelblue', alpha=0.8)\n\n# Adicionar valores nas barras\nfor bar in bars:\n    height = bar.get_height()\n    ax.text(bar.get_x() + bar.get_width()/2., height + 1,\n            f'{height}', ha='center', va='bottom', fontsize=12)\n\n# Formata\u00e7\u00e3o limpa\nax.set_title('Vendas por Produto - Q1 2024', fontsize=16, fontweight='bold', pad=20)\nax.set_ylabel('Vendas (milhares)', fontsize=12)\nax.set_xlabel('Produtos', fontsize=12)\n\n# Grade sutil\nax.grid(axis='y', alpha=0.3, linestyle='-', linewidth=0.5)\nax.set_axisbelow(True)\n\n# Remover bordas desnecess\u00e1rias\nax.spines['top'].set_visible(False)\nax.spines['right'].set_visible(False)\n\n# Ajustar layout\nplt.tight_layout()\nplt.show()\n</code></pre>"},{"location":"aulas/IA/conceitos/matplotlib.html#exercicios-praticos","title":"Exerc\u00edcios Pr\u00e1ticos","text":""},{"location":"aulas/IA/conceitos/matplotlib.html#exercicio-1-grafico-de-linha-multiplas","title":"Exerc\u00edcio 1: Gr\u00e1fico de Linha M\u00faltiplas","text":"<p>Crie um gr\u00e1fico que mostra a evolu\u00e7\u00e3o de vendas de 3 produtos ao longo de 12 meses com: - Cores distintas para cada produto - Marcadores diferentes - Legenda posicionada fora da \u00e1rea do gr\u00e1fico - Grid suave - Anota\u00e7\u00e3o do ponto m\u00e1ximo</p>"},{"location":"aulas/IA/conceitos/matplotlib.html#exercicio-2-dashboard-simples","title":"Exerc\u00edcio 2: Dashboard Simples","text":"<p>Crie um dashboard 2x2 com: - Gr\u00e1fico de barras (top-left) - Histograma (top-right) - Scatter plot (bottom-left) - Box plot (bottom-right)</p>"},{"location":"aulas/IA/conceitos/matplotlib.html#exercicio-3-visualizacao-de-correlacao","title":"Exerc\u00edcio 3: Visualiza\u00e7\u00e3o de Correla\u00e7\u00e3o","text":"<ul> <li>Carregue um dataset com m\u00faltiplas vari\u00e1veis num\u00e9ricas</li> <li>Crie uma matriz de correla\u00e7\u00e3o visual usando <code>imshow</code></li> <li>Adicione anota\u00e7\u00f5es com os valores de correla\u00e7\u00e3o</li> <li>Use uma paleta de cores divergente</li> </ul> <p>O Matplotlib \u00e9 uma ferramenta extremamente poderosa e flex\u00edvel. Embora tenha uma curva de aprendizado inicial, dominar seus conceitos fundamentais permitir\u00e1 criar visualiza\u00e7\u00f5es de qualidade profissional para qualquer tipo de an\u00e1lise de dados.</p>"},{"location":"aulas/IA/conceitos/pandas.html","title":"Pandas: Manipula\u00e7\u00e3o e An\u00e1lise de Dados em Python","text":""},{"location":"aulas/IA/conceitos/pandas.html#introducao","title":"Introdu\u00e7\u00e3o","text":"<p>O Pandas \u00e9 uma biblioteca fundamental para ci\u00eancia de dados em Python, fornecendo estruturas de dados de alto desempenho e ferramentas de an\u00e1lise de dados. \u00c9 constru\u00eddo sobre NumPy e oferece estruturas de dados flex\u00edveis para trabalhar com dados estruturados e heterog\u00eaneos.</p>"},{"location":"aulas/IA/conceitos/pandas.html#principais-estruturas-de-dados","title":"Principais Estruturas de Dados","text":""},{"location":"aulas/IA/conceitos/pandas.html#series","title":"Series","text":"<p>Uma Series \u00e9 uma estrutura de dados unidimensional que pode armazenar qualquer tipo de dados (inteiros, strings, floats, objetos Python, etc.).</p> <pre><code>import pandas as pd\nimport numpy as np\n\n# Criando uma Series\ns = pd.Series([1, 3, 5, np.nan, 6, 8])\nprint(s)\n</code></pre>"},{"location":"aulas/IA/conceitos/pandas.html#dataframe","title":"DataFrame","text":"<p>Um DataFrame \u00e9 uma estrutura de dados bidimensional com eixos rotulados (linhas e colunas). \u00c9 similar a uma planilha Excel ou tabela SQL.</p> <pre><code># Criando um DataFrame\ndata = {\n    'Nome': ['Ana', 'Carlos', 'Maria', 'Jo\u00e3o'],\n    'Idade': [25, 30, 35, 28],\n    'Cidade': ['S\u00e3o Paulo', 'Rio de Janeiro', 'Bras\u00edlia', 'Salvador']\n}\ndf = pd.DataFrame(data)\n</code></pre>"},{"location":"aulas/IA/conceitos/pandas.html#carregamento-de-dados","title":"Carregamento de Dados","text":""},{"location":"aulas/IA/conceitos/pandas.html#principais-formatos-suportados","title":"Principais Formatos Suportados","text":""},{"location":"aulas/IA/conceitos/pandas.html#csv-comma-separated-values","title":"CSV (Comma Separated Values)","text":"<pre><code># Carregando dados de um arquivo CSV\ndf = pd.read_csv('arquivo.csv')\n\n# Com par\u00e2metros personalizados\ndf = pd.read_csv('arquivo.csv', \n                 delimiter=';',           # Separador personalizado\n                 header=0,               # Linha do cabe\u00e7alho\n                 names=['col1', 'col2'], # Nomes das colunas\n                 encoding='utf-8')       # Codifica\u00e7\u00e3o\n</code></pre>"},{"location":"aulas/IA/conceitos/pandas.html#outros-formatos","title":"Outros Formatos","text":"<pre><code># Excel\ndf = pd.read_excel('arquivo.xlsx', sheet_name='Planilha1')\n\n# JSON\ndf = pd.read_json('arquivo.json')\n\n# SQL\nimport sqlite3\nconn = sqlite3.connect('database.db')\ndf = pd.read_sql_query(\"SELECT * FROM tabela\", conn)\n\n# URLs diretas\nurl = \"https://example.com/data.csv\"\ndf = pd.read_csv(url)\n</code></pre>"},{"location":"aulas/IA/conceitos/pandas.html#exploracao-inicial-dos-dados","title":"Explora\u00e7\u00e3o Inicial dos Dados","text":""},{"location":"aulas/IA/conceitos/pandas.html#informacoes-basicas","title":"Informa\u00e7\u00f5es B\u00e1sicas","text":"<pre><code># Primeiras linhas\ndf.head()          # 5 primeiras linhas (padr\u00e3o)\ndf.head(10)        # 10 primeiras linhas\n\n# \u00daltimas linhas\ndf.tail()          # 5 \u00faltimas linhas\n\n# Informa\u00e7\u00f5es gerais do DataFrame\ndf.info()          # Tipos de dados, valores n\u00e3o-nulos, uso de mem\u00f3ria\n\n# Dimens\u00f5es\ndf.shape           # (linhas, colunas)\n\n# Nomes das colunas\ndf.columns         # Lista das colunas\n\n# Tipos de dados\ndf.dtypes          # Tipo de cada coluna\n\n# \u00cdndice\ndf.index           # Informa\u00e7\u00f5es sobre o \u00edndice\n</code></pre>"},{"location":"aulas/IA/conceitos/pandas.html#estatisticas-descritivas","title":"Estat\u00edsticas Descritivas","text":"<pre><code># Resumo estat\u00edstico para colunas num\u00e9ricas\ndf.describe()\n\n# Incluindo colunas categ\u00f3ricas\ndf.describe(include='all')\n\n# Estat\u00edsticas espec\u00edficas\ndf.mean()          # M\u00e9dia\ndf.median()        # Mediana\ndf.std()           # Desvio padr\u00e3o\ndf.var()           # Vari\u00e2ncia\ndf.min()           # Valor m\u00ednimo\ndf.max()           # Valor m\u00e1ximo\ndf.count()         # Contagem de valores n\u00e3o-nulos\n</code></pre>"},{"location":"aulas/IA/conceitos/pandas.html#selecao-e-indexacao-de-dados","title":"Sele\u00e7\u00e3o e Indexa\u00e7\u00e3o de Dados","text":""},{"location":"aulas/IA/conceitos/pandas.html#selecao-de-colunas","title":"Sele\u00e7\u00e3o de Colunas","text":"<pre><code># Uma coluna (retorna Series)\ndf['nome_coluna']\ndf.nome_coluna     # Nota\u00e7\u00e3o de atributo (se o nome for v\u00e1lido)\n\n# M\u00faltiplas colunas (retorna DataFrame)\ndf[['coluna1', 'coluna2']]\n\n# Sele\u00e7\u00e3o por \u00edndice posicional\ndf.iloc[:, 0]      # Primeira coluna\ndf.iloc[:, 0:3]    # Primeiras tr\u00eas colunas\n</code></pre>"},{"location":"aulas/IA/conceitos/pandas.html#selecao-de-linhas","title":"Sele\u00e7\u00e3o de Linhas","text":"<pre><code># Por \u00edndice posicional\ndf.iloc[0]         # Primeira linha\ndf.iloc[0:5]       # Primeiras 5 linhas\ndf.iloc[-1]        # \u00daltima linha\n\n# Por r\u00f3tulo do \u00edndice\ndf.loc[0]          # Linha com \u00edndice 0\ndf.loc[0:4]        # Linhas do \u00edndice 0 ao 4 (inclusivo)\n\n# Por condi\u00e7\u00e3o\ndf[df['idade'] &gt; 25]                    # Linhas onde idade &gt; 25\ndf[df['nome'].str.contains('Ana')]      # Linhas onde nome cont\u00e9m 'Ana'\ndf[(df['idade'] &gt; 25) &amp; (df['salario'] &lt; 5000)]  # M\u00faltiplas condi\u00e7\u00f5es\n</code></pre>"},{"location":"aulas/IA/conceitos/pandas.html#selecao-combinada","title":"Sele\u00e7\u00e3o Combinada","text":"<pre><code># loc[linhas, colunas]\ndf.loc[0:5, 'nome':'idade']           # Linhas 0-5, colunas 'nome' at\u00e9 'idade'\ndf.loc[df['idade'] &gt; 25, ['nome', 'salario']]  # Linhas filtradas, colunas espec\u00edficas\n\n# iloc[linhas, colunas]\ndf.iloc[0:5, 0:3]                     # Primeiras 5 linhas, 3 primeiras colunas\n</code></pre>"},{"location":"aulas/IA/conceitos/pandas.html#limpeza-e-tratamento-de-dados","title":"Limpeza e Tratamento de Dados","text":""},{"location":"aulas/IA/conceitos/pandas.html#valores-ausentes-missing-values","title":"Valores Ausentes (Missing Values)","text":"<pre><code># Identificar valores ausentes\ndf.isnull()        # DataFrame booleano\ndf.isnull().sum()  # Contagem por coluna\ndf.isna()          # Sin\u00f4nimo de isnull()\n\n# Verificar se h\u00e1 valores ausentes\ndf.isnull().any()  # True se h\u00e1 algum valor ausente por coluna\ndf.isnull().all()  # True se todos os valores s\u00e3o ausentes por coluna\n\n# Remover valores ausentes\ndf.dropna()                    # Remove linhas com qualquer valor ausente\ndf.dropna(axis=1)             # Remove colunas com qualquer valor ausente\ndf.dropna(subset=['coluna'])   # Remove linhas com valores ausentes em 'coluna'\ndf.dropna(thresh=2)           # Manter linhas com pelo menos 2 valores n\u00e3o-nulos\n\n# Preencher valores ausentes\ndf.fillna(0)                  # Preencher com 0\ndf.fillna(df.mean())          # Preencher com a m\u00e9dia\ndf.fillna(method='ffill')     # Forward fill (propagar \u00faltimo valor v\u00e1lido)\ndf.fillna(method='bfill')     # Backward fill (propagar pr\u00f3ximo valor v\u00e1lido)\n\n# Preencher por coluna\ndf['coluna'].fillna(df['coluna'].mean(), inplace=True)\n</code></pre>"},{"location":"aulas/IA/conceitos/pandas.html#duplicatas","title":"Duplicatas","text":"<pre><code># Identificar duplicatas\ndf.duplicated()              # S\u00e9rie booleana\ndf.duplicated().sum()        # N\u00famero de duplicatas\n\n# Remover duplicatas\ndf.drop_duplicates()         # Remove duplicatas\ndf.drop_duplicates(subset=['coluna'])  # Baseado em colunas espec\u00edficas\ndf.drop_duplicates(keep='first')       # Manter primeira ocorr\u00eancia\ndf.drop_duplicates(keep='last')        # Manter \u00faltima ocorr\u00eancia\n</code></pre>"},{"location":"aulas/IA/conceitos/pandas.html#conversao-de-tipos","title":"Convers\u00e3o de Tipos","text":"<pre><code># Converter tipos de dados\ndf['coluna'] = df['coluna'].astype('float64')\ndf['coluna'] = df['coluna'].astype('category')\ndf['data'] = pd.to_datetime(df['data'])\ndf['numero'] = pd.to_numeric(df['numero'], errors='coerce')  # Erros viram NaN\n</code></pre>"},{"location":"aulas/IA/conceitos/pandas.html#transformacao-de-dados","title":"Transforma\u00e7\u00e3o de Dados","text":""},{"location":"aulas/IA/conceitos/pandas.html#criacao-de-novas-colunas","title":"Cria\u00e7\u00e3o de Novas Colunas","text":"<pre><code># Opera\u00e7\u00f5es aritm\u00e9ticas\ndf['nova_coluna'] = df['coluna1'] + df['coluna2']\ndf['area'] = df['comprimento'] * df['largura']\n\n# Opera\u00e7\u00f5es condicionais\ndf['categoria'] = df['idade'].apply(lambda x: 'Jovem' if x &lt; 30 else 'Adulto')\n\n# Usando np.where (mais eficiente para condi\u00e7\u00f5es simples)\nimport numpy as np\ndf['categoria'] = np.where(df['idade'] &lt; 30, 'Jovem', 'Adulto')\n\n# M\u00faltiplas condi\u00e7\u00f5es\nconditions = [\n    df['idade'] &lt; 18,\n    (df['idade'] &gt;= 18) &amp; (df['idade'] &lt; 60),\n    df['idade'] &gt;= 60\n]\nchoices = ['Menor', 'Adulto', 'Idoso']\ndf['faixa_etaria'] = np.select(conditions, choices, default='Indefinido')\n</code></pre>"},{"location":"aulas/IA/conceitos/pandas.html#aplicacao-de-funcoes","title":"Aplica\u00e7\u00e3o de Fun\u00e7\u00f5es","text":"<pre><code># apply() para aplicar fun\u00e7\u00f5es\ndf['coluna_upper'] = df['coluna'].apply(str.upper)\ndf['coluna_transformada'] = df['coluna'].apply(lambda x: x * 2)\n\n# map() para mapeamentos\nmapeamento = {'A': 1, 'B': 2, 'C': 3}\ndf['nova_coluna'] = df['categoria'].map(mapeamento)\n\n# transform() para transforma\u00e7\u00f5es que mant\u00eam o \u00edndice original\ndf['coluna_normalizada'] = df.groupby('grupo')['valor'].transform(lambda x: (x - x.mean()) / x.std())\n</code></pre>"},{"location":"aulas/IA/conceitos/pandas.html#manipulacao-de-strings","title":"Manipula\u00e7\u00e3o de Strings","text":"<pre><code># Acessar m\u00e9todos de string com .str\ndf['nome'].str.upper()           # Mai\u00fasculas\ndf['nome'].str.lower()           # Min\u00fasculas\ndf['nome'].str.len()             # Comprimento\ndf['nome'].str.contains('Ana')   # Cont\u00e9m substring\ndf['nome'].str.startswith('A')   # Come\u00e7a com\ndf['nome'].str.endswith('a')     # Termina com\ndf['nome'].str.replace('a', 'e') # Substituir caracteres\n\n# Dividir strings\ndf['nome'].str.split(' ')        # Dividir por espa\u00e7o\ndf[['primeiro_nome', 'sobrenome']] = df['nome'].str.split(' ', expand=True)\n</code></pre>"},{"location":"aulas/IA/conceitos/pandas.html#agrupamento-e-agregacao","title":"Agrupamento e Agrega\u00e7\u00e3o","text":""},{"location":"aulas/IA/conceitos/pandas.html#groupby-basico","title":"GroupBy B\u00e1sico","text":"<pre><code># Agrupar por uma coluna\ngrouped = df.groupby('categoria')\n\n# Opera\u00e7\u00f5es de agrega\u00e7\u00e3o\ngrouped.mean()                   # M\u00e9dia por grupo\ngrouped.sum()                    # Soma por grupo\ngrouped.count()                  # Contagem por grupo\ngrouped.size()                   # Tamanho do grupo\ngrouped.std()                    # Desvio padr\u00e3o por grupo\n\n# M\u00faltiplas agrega\u00e7\u00f5es\ngrouped.agg({\n    'valor': ['mean', 'sum', 'count'],\n    'preco': ['min', 'max']\n})\n</code></pre>"},{"location":"aulas/IA/conceitos/pandas.html#agrupamento-avancado","title":"Agrupamento Avan\u00e7ado","text":"<pre><code># Agrupar por m\u00faltiplas colunas\ndf.groupby(['categoria', 'subcategoria']).mean()\n\n# Aplicar fun\u00e7\u00e3o customizada\ndef custom_agg(x):\n    return {\n        'min': x.min(),\n        'max': x.max(),\n        'mean': x.mean(),\n        'range': x.max() - x.min()\n    }\n\ngrouped.apply(custom_agg)\n\n# Filtrar grupos\ngrouped.filter(lambda x: len(x) &gt; 5)  # Grupos com mais de 5 elementos\n</code></pre>"},{"location":"aulas/IA/conceitos/pandas.html#juncao-e-combinacao-de-dataframes","title":"Jun\u00e7\u00e3o e Combina\u00e7\u00e3o de DataFrames","text":""},{"location":"aulas/IA/conceitos/pandas.html#concatenacao","title":"Concatena\u00e7\u00e3o","text":"<pre><code># Concatenar verticalmente (empilhar)\ndf_combined = pd.concat([df1, df2], axis=0)\n\n# Concatenar horizontalmente (lado a lado)\ndf_combined = pd.concat([df1, df2], axis=1)\n\n# Com chaves para identificar origem\ndf_combined = pd.concat([df1, df2], keys=['dados1', 'dados2'])\n</code></pre>"},{"location":"aulas/IA/conceitos/pandas.html#merge-juncoes-tipo-sql","title":"Merge (Jun\u00e7\u00f5es tipo SQL)","text":"<pre><code># Inner join (padr\u00e3o)\nmerged = pd.merge(df1, df2, on='chave')\n\n# Left join\nmerged = pd.merge(df1, df2, on='chave', how='left')\n\n# Right join\nmerged = pd.merge(df1, df2, on='chave', how='right')\n\n# Outer join\nmerged = pd.merge(df1, df2, on='chave', how='outer')\n\n# Merge com colunas de nomes diferentes\nmerged = pd.merge(df1, df2, left_on='id1', right_on='id2')\n\n# Merge com m\u00faltiplas chaves\nmerged = pd.merge(df1, df2, on=['chave1', 'chave2'])\n</code></pre>"},{"location":"aulas/IA/conceitos/pandas.html#ordenacao-e-ranking","title":"Ordena\u00e7\u00e3o e Ranking","text":""},{"location":"aulas/IA/conceitos/pandas.html#ordenacao","title":"Ordena\u00e7\u00e3o","text":"<pre><code># Ordenar por uma coluna\ndf.sort_values('coluna')                    # Crescente\ndf.sort_values('coluna', ascending=False)   # Decrescente\n\n# Ordenar por m\u00faltiplas colunas\ndf.sort_values(['coluna1', 'coluna2'], ascending=[True, False])\n\n# Ordenar pelo \u00edndice\ndf.sort_index()\n</code></pre>"},{"location":"aulas/IA/conceitos/pandas.html#ranking","title":"Ranking","text":"<pre><code># Criar ranking\ndf['rank'] = df['valor'].rank()                    # Ranking padr\u00e3o\ndf['rank'] = df['valor'].rank(method='dense')      # Ranking denso\ndf['rank'] = df['valor'].rank(ascending=False)     # Ranking decrescente\n</code></pre>"},{"location":"aulas/IA/conceitos/pandas.html#reshaping-de-dados","title":"Reshaping de Dados","text":""},{"location":"aulas/IA/conceitos/pandas.html#pivot","title":"Pivot","text":"<pre><code># Pivot table\npivot_df = df.pivot_table(\n    values='valor',\n    index='categoria',\n    columns='mes',\n    aggfunc='mean'\n)\n</code></pre>"},{"location":"aulas/IA/conceitos/pandas.html#melt-wide-to-long","title":"Melt (Wide to Long)","text":"<pre><code># Transformar colunas em linhas\nmelted_df = pd.melt(\n    df,\n    id_vars=['id', 'nome'],\n    value_vars=['jan', 'fev', 'mar'],\n    var_name='mes',\n    value_name='valor'\n)\n</code></pre>"},{"location":"aulas/IA/conceitos/pandas.html#trabalhando-com-datas","title":"Trabalhando com Datas","text":""},{"location":"aulas/IA/conceitos/pandas.html#conversao-e-criacao","title":"Convers\u00e3o e Cria\u00e7\u00e3o","text":"<pre><code># Converter para datetime\ndf['data'] = pd.to_datetime(df['data'])\ndf['data'] = pd.to_datetime(df['data'], format='%Y-%m-%d')\n\n# Criar range de datas\ndates = pd.date_range('2023-01-01', '2023-12-31', freq='D')\n\n# Extrair componentes de data\ndf['ano'] = df['data'].dt.year\ndf['mes'] = df['data'].dt.month\ndf['dia'] = df['data'].dt.day\ndf['dia_semana'] = df['data'].dt.day_name()\n</code></pre>"},{"location":"aulas/IA/conceitos/pandas.html#operacoes-com-datas","title":"Opera\u00e7\u00f5es com Datas","text":"<pre><code># Filtrar por per\u00edodo\ndf[df['data'] &gt; '2023-01-01']\ndf[df['data'].between('2023-01-01', '2023-06-30')]\n\n# Resample (agrega\u00e7\u00e3o temporal)\ndf.set_index('data').resample('M').mean()  # M\u00e9dia mensal\ndf.set_index('data').resample('Q').sum()   # Soma trimestral\n</code></pre>"},{"location":"aulas/IA/conceitos/pandas.html#performance-e-boas-praticas","title":"Performance e Boas Pr\u00e1ticas","text":""},{"location":"aulas/IA/conceitos/pandas.html#otimizacao-de-memoria","title":"Otimiza\u00e7\u00e3o de Mem\u00f3ria","text":"<pre><code># Verificar uso de mem\u00f3ria\ndf.memory_usage(deep=True)\n\n# Otimizar tipos de dados\ndf['categoria'] = df['categoria'].astype('category')\ndf['inteiro'] = pd.to_numeric(df['inteiro'], downcast='integer')\ndf['float'] = pd.to_numeric(df['float'], downcast='float')\n</code></pre>"},{"location":"aulas/IA/conceitos/pandas.html#operacoes-vetorizadas","title":"Opera\u00e7\u00f5es Vetorizadas","text":"<pre><code># Evitar loops expl\u00edcitos\n# \u274c Ineficiente\nfor i in range(len(df)):\n    df.loc[i, 'nova_coluna'] = df.loc[i, 'coluna1'] * 2\n\n# \u2705 Eficiente\ndf['nova_coluna'] = df['coluna1'] * 2\n</code></pre>"},{"location":"aulas/IA/conceitos/pandas.html#chaining-de-operacoes","title":"Chaining de Opera\u00e7\u00f5es","text":"<pre><code># Encadear opera\u00e7\u00f5es para c\u00f3digo mais limpo\nresultado = (df\n             .dropna()\n             .groupby('categoria')\n             .agg({'valor': 'mean'})\n             .reset_index()\n             .sort_values('valor', ascending=False)\n             .head(10))\n</code></pre>"},{"location":"aulas/IA/conceitos/pandas.html#dicas-e-truques-avancados","title":"Dicas e Truques Avan\u00e7ados","text":""},{"location":"aulas/IA/conceitos/pandas.html#configuracoes-do-pandas","title":"Configura\u00e7\u00f5es do Pandas","text":"<pre><code># Configura\u00e7\u00f5es de exibi\u00e7\u00e3o\npd.set_option('display.max_columns', None)     # Mostrar todas as colunas\npd.set_option('display.max_rows', 100)        # Mostrar at\u00e9 100 linhas\npd.set_option('display.precision', 2)         # Precis\u00e3o decimal\npd.set_option('display.float_format', '{:.2f}'.format)\n\n# Resetar configura\u00e7\u00f5es\npd.reset_option('all')\n</code></pre>"},{"location":"aulas/IA/conceitos/pandas.html#operacoes-condicionais-avancadas","title":"Opera\u00e7\u00f5es Condicionais Avan\u00e7adas","text":"<pre><code># Query method (mais leg\u00edvel para filtros complexos)\ndf.query('idade &gt; 25 and salario &lt; 5000')\ndf.query('categoria in [\"A\", \"B\"]')\n\n# Where com multiple conditions\ndf.where(df['valor'] &gt; df['valor'].mean(), other=np.nan)\n</code></pre>"},{"location":"aulas/IA/conceitos/pandas.html#sampling","title":"Sampling","text":"<pre><code># Amostragem aleat\u00f3ria\ndf.sample(n=100)              # 100 linhas aleat\u00f3rias\ndf.sample(frac=0.1)           # 10% das linhas\ndf.sample(n=10, random_state=42)  # Amostra reproduz\u00edvel\n</code></pre>"},{"location":"aulas/IA/conceitos/pandas.html#exercicios-praticos","title":"Exerc\u00edcios Pr\u00e1ticos","text":"<ol> <li>Carregamento e Explora\u00e7\u00e3o:</li> <li>Carregue um dataset CSV</li> <li>Explore suas dimens\u00f5es, tipos de dados e valores ausentes</li> <li> <p>Gere estat\u00edsticas descritivas</p> </li> <li> <p>Limpeza de Dados:</p> </li> <li>Identifique e trate valores ausentes</li> <li>Remova duplicatas</li> <li> <p>Converta tipos de dados quando necess\u00e1rio</p> </li> <li> <p>Transforma\u00e7\u00e3o:</p> </li> <li>Crie novas colunas baseadas em opera\u00e7\u00f5es matem\u00e1ticas</li> <li>Aplique transforma\u00e7\u00f5es condicionais</li> <li> <p>Normalize ou padronize valores num\u00e9ricos</p> </li> <li> <p>Agrupamento e An\u00e1lise:</p> </li> <li>Agrupe dados por categorias</li> <li>Calcule estat\u00edsticas por grupo</li> <li>Identifique padr\u00f5es e outliers</li> </ol> <p>O Pandas \u00e9 uma ferramenta poderosa que se torna mais intuitiva com a pr\u00e1tica. Comece com opera\u00e7\u00f5es simples e gradualmente incorpore t\u00e9cnicas mais avan\u00e7adas conforme sua familiaridade com a biblioteca cresce.</p>"},{"location":"aulas/IA/intro/index.html","title":"Introdu\u00e7\u00e3o \u00e0 Ci\u00eancia de Dados e Intelig\u00eancia Artificial","text":"<p>Fa\u00e7a o download do pdf de Introdu\u00e7\u00e3o.</p> <ul> <li>arquivo pdf: Introdu\u00e7\u00e3o</li> </ul> <p></p>"},{"location":"aulas/IA/intro/index.html#o-que-e-ciencia-de-dados","title":"O que \u00e9 Ci\u00eancia de Dados?","text":"<p>Voc\u00ea j\u00e1 se perguntou como a Netflix sempre sabe qual filme voc\u00ea vai querer assistir? Ou como o seu banco detecta uma compra suspeita no seu cart\u00e3o em segundos? A resposta est\u00e1 na Ci\u00eancia de Dados!</p> <p>A Ci\u00eancia de Dados \u00e9 um campo interdisciplinar que utiliza m\u00e9todos cient\u00edficos, processos, algoritmos e sistemas para <code>extrair conhecimento</code> e insights valiosos de dados estruturados e n\u00e3o estruturados. \u00c9 evolu\u00e7\u00e3o natural da estat\u00edstica tradicional, s\u00f3 que com programa\u00e7\u00e3o, matem\u00e1tica e conhecimento espec\u00edfico para resolver problemas complexos do mundo real.</p> <p>Tip</p> <p>\"Ci\u00eancia de Dados \u00e9 o campo que combina estat\u00edstica, an\u00e1lise de dados, machine learning e m\u00e9todos relacionados para entender e analisar fen\u00f4menos reais atrav\u00e9s de dados.\" https://dl.acm.org/doi/pdf/10.1145/2500499 Dhar, 2013</p>"},{"location":"aulas/IA/intro/index.html#componentes-fundamentais-da-ciencia-de-dados","title":"Componentes Fundamentais da Ci\u00eancia de DadosPor que a Ci\u00eancia de Dados precisa dos tr\u00eas componentes (programa\u00e7\u00e3o, matem\u00e1tica e conhecimento de dom\u00ednio)?","text":"<p>A Ci\u00eancia de Dados pode ser compreendida como a converg\u00eancia de tr\u00eas conjuntos de compet\u00eancias essenciais, cuja integra\u00e7\u00e3o \u00e9 indispens\u00e1vel para a pr\u00e1tica profissional eficaz:</p> <p></p> <ol> <li>Habilidades de Programa\u00e7\u00e3o Compet\u00eancia para manipula\u00e7\u00e3o, processamento e an\u00e1lise de dados por meio de linguagens e ferramentas computacionais, possibilitando a implementa\u00e7\u00e3o de algoritmos e a automa\u00e7\u00e3o de tarefas anal\u00edticas.</li> <li>Conhecimento Matem\u00e1tico e Estat\u00edstico Fundamenta\u00e7\u00e3o te\u00f3rica para modelagem, infer\u00eancia e interpreta\u00e7\u00e3o de dados, abrangendo conceitos como probabilidade, estat\u00edstica descritiva e inferencial, \u00e1lgebra linear e an\u00e1lise de algoritmos.</li> <li>Expertise de Dom\u00ednio Compreens\u00e3o aprofundada do contexto espec\u00edfico em que o problema est\u00e1 inserido, permitindo a formula\u00e7\u00e3o de hip\u00f3teses realistas, a correta interpreta\u00e7\u00e3o dos resultados e a tomada de decis\u00f5es embasadas.</li> </ol> <p>Tip</p> <p>Dica importante: Embora n\u00e3o seja necess\u00e1rio dominar todas as \u00e1reas desde o in\u00edcio, a atua\u00e7\u00e3o consistente em Ci\u00eancia de Dados requer o desenvolvimento progressivo e equilibrado dessas compet\u00eancias, com aprofundamento gradual de acordo com o foco profissional ou acad\u00eamico.</p> Para impressionar os chefes com termos t\u00e9cnicosPorque cada um resolve uma parte espec\u00edfica do problema de forma complementarPorque assim o sal\u00e1rio fica mais altoNa verdade, s\u00f3 a programa\u00e7\u00e3o \u00e9 importanteSubmit Exato! Programa\u00e7\u00e3o te d\u00e1 as ferramentas, matem\u00e1tica/estat\u00edstica te d\u00e1 os m\u00e9todos corretos, e conhecimento de dom\u00ednio garante que voc\u00ea est\u00e1 resolvendo o problema certo da forma certa. \u00c9 como um trip\u00e9 - tire uma perna e tudo desaba!"},{"location":"aulas/IA/intro/index.html#historia-e-evolucao-da-ciencia-de-dados","title":"Hist\u00f3ria e Evolu\u00e7\u00e3o da Ci\u00eancia de Dados","text":"<p>A Ci\u00eancia de Dados \u00e9 resultado de um processo evolutivo que integra estat\u00edstica, ci\u00eancia da computa\u00e7\u00e3o e conhecimento de dom\u00ednio, impulsionado por avan\u00e7os tecnol\u00f3gicos e pela crescente disponibilidade de dados em larga escala.</p>"},{"location":"aulas/IA/intro/index.html#marcos-historicos","title":"Marcos Hist\u00f3ricosO que diferencia a Ci\u00eancia de Dados da Estat\u00edstica tradicional?","text":"<ul> <li> <p>1962: O estat\u00edstico John W. Tukey, em seu artigo \"The Future of Data Analysis\", prop\u00f4s uma abordagem mais abrangente para a an\u00e1lise de dados, antecipando a integra\u00e7\u00e3o entre estat\u00edstica e m\u00e9todos computacionais. Embora n\u00e3o tenha utilizado diretamente o termo Data Science, sua vis\u00e3o foi precursora.</p> </li> <li> <p>1970s-1980s: A cria\u00e7\u00e3o do modelo relacional por Edgar F. Codd (1970) e a populariza\u00e7\u00e3o dos sistemas de gerenciamento de bancos de dados relacionais (SGBDR) transformaram a forma de armazenar e consultar dados.</p> </li> <li>1990s: O termo Data Mining ganhou destaque, descrevendo t\u00e9cnicas para extra\u00e7\u00e3o de padr\u00f5es de grandes conjuntos de dados. Paralelamente, algoritmos de aprendizado de m\u00e1quina, como \u00e1rvores de decis\u00e3o, redes neurais artificiais e m\u00e9todos de vizinhan\u00e7a, come\u00e7aram a ser aplicados de forma mais ampla (essas t\u00e9cnicas j\u00e1 existiam antes) em cen\u00e1rios comerciais.</li> <li>2001: William S. Cleveland em seu trabalho \"Data Science: An Action Plan for Expanding the Technical Areas of the Field of Statistics\", prop\u00f4s ampliar o escopo da estat\u00edstica para incluir computa\u00e7\u00e3o, visualiza\u00e7\u00e3o de dados e aplica\u00e7\u00f5es multidisciplinares, formalizando parte da base conceitual da Ci\u00eancia de Dados.</li> <li>2008: DJ Patil (LinkedIn) e Jeff Hammerbacher (Facebook) s\u00e3o frequentemente creditados por popularizar o termo Data Scientist para descrever um profissional com compet\u00eancias em programa\u00e7\u00e3o, estat\u00edstica e entendimento de neg\u00f3cios.</li> <li>2010s: Explos\u00e3o do Big Data! Com o crescimento exponencial da gera\u00e7\u00e3o de dados, tecnologias como Hadoop e Spark possibilitaram o processamento distribu\u00eddo em larga escala. A quantidade de dados gerada globalmente passou a crescer de forma acelerada, superando rapidamente a capacidade de armazenamento e processamento tradicionais.</li> <li>2020s: Democratiza\u00e7\u00e3o da IA e MLOps com ferramentas de intelig\u00eancia artificial de c\u00f3digo aberto e servi\u00e7os baseados em nuvem tornaram o acesso \u00e0 IA mais acess\u00edvel. O MLOps consolidou-se como disciplina para integrar modelos de machine learning ao ciclo de desenvolvimento e opera\u00e7\u00e3o de sistemas.</li> </ul> Ci\u00eancia de Dados usa apenas dados digitaisEstat\u00edstica n\u00e3o usa computadoresCi\u00eancia de Dados combina programa\u00e7\u00e3o, estat\u00edstica e conhecimento de dom\u00ednio para trabalhar com big dataN\u00e3o h\u00e1 diferen\u00e7a entre elasSubmit A Ci\u00eancia de Dados \u00e9 interdisciplinar, combinando estat\u00edstica com programa\u00e7\u00e3o e conhecimento espec\u00edfico do dom\u00ednio para extrair insights de grandes volumes de dados estruturados e n\u00e3o estruturados."},{"location":"aulas/IA/intro/index.html#tipos-de-dados-em-ciencia-de-dados","title":"Tipos de Dados em Ci\u00eancia de Dados","text":"<p>Nem todo dado \u00e9 igual! Cada tipo tem suas caracter\u00edsticas e requer t\u00e9cnicas espec\u00edficas de prepara\u00e7\u00e3o. Vamos conhecer os tr\u00eas principais:</p>"},{"location":"aulas/IA/intro/index.html#1-dados-estruturados","title":"1. Dados Estruturados","text":"<p>S\u00e3o os \"certinhos\" da turma! Organizados em formato tabular com linhas e colunas bem definidas, como uma planilha Excel bem organizada.</p> <p>Exemplos pr\u00e1ticos: - Planilhas Excel (vendas mensais, cadastro de clientes) - Bancos de dados relacionais (SQL) - como o sistema de uma loja online - Arquivos CSV - formato universal de troca de dados - Dados de sensores IoT com schema fixo (temperatura, umidade, press\u00e3o)</p> <p>Vantagem: F\u00e1ceis de analisar e processar Desvantagem: Representam apenas uma pequena parte dos dados do mundo real (cerca de 20%)</p>"},{"location":"aulas/IA/intro/index.html#2-dados-semi-estruturados","title":"2. Dados Semi-estruturados","text":"<p>Os \"meio organizados\"! N\u00e3o seguem um formato r\u00edgido de tabela, mas possuem alguma organiza\u00e7\u00e3o que podemos aproveitar.</p> <p>Exemplos pr\u00e1ticos: - JSON (JavaScript Object Notation) - usado em APIs web - XML (eXtensible Markup Language) - comum em sistemas antigos - Logs de sistemas - rastros digitais de aplica\u00e7\u00f5es - Emails com metadados (remetente, data, assunto)</p> <p>Vantagem: Mais flex\u00edveis que dados estruturados Desvantagem: Precisam de algum processamento antes da an\u00e1lise</p>"},{"location":"aulas/IA/intro/index.html#3-dados-nao-estruturados","title":"3. Dados N\u00e3o-estruturadosQual tipo de dados requer maior processamento para an\u00e1lise?","text":"<p>Os \"brabosssss\"! Sem organiza\u00e7\u00e3o predefinida que requerem t\u00e9cnicas especiais de processamento. S\u00e3o a maioria absoluta dos dados no mundo digital!</p> <p>Exemplos pr\u00e1ticos: - Textos livres (artigos, posts no Twitter, reviews de produtos) - Imagens e v\u00eddeos (fotos do Instagram, v\u00eddeos do YouTube) - \u00c1udios e podcasts (grava\u00e7\u00f5es de call center, m\u00fasica) - Documentos PDF (contratos, relat\u00f3rios, livros)</p> <p>Vantagem: Cont\u00eam informa\u00e7\u00f5es riqu\u00edssimas e insights \u00fanicos Desvantagem: Requerem t\u00e9cnicas avan\u00e7adas (NLP, Computer Vision) para an\u00e1lise</p> Dados estruturadosDados semi-estruturadosDados n\u00e3o-estruturadosTodos requerem o mesmo n\u00edvel de processamentoSubmit Dados n\u00e3o-estruturados como textos, imagens e \u00e1udios requerem t\u00e9cnicas especiais de processamento (NLP, Computer Vision, etc.) antes de poderem ser analisados, ao contr\u00e1rio de dados estruturados que j\u00e1 est\u00e3o em formato tabular."},{"location":"aulas/IA/intro/index2.html","title":"Descoberta do Conhecimento","text":""},{"location":"aulas/IA/intro/index2.html#descoberta-do-conhecimento","title":"Descoberta do conhecimento","text":"<p>Imagine que voc\u00ea tem uma montanha de dados na sua empresa e precisa transform\u00e1-los em decis\u00f5es inteligentes. Como fazer isso de forma organizada e eficiente? \u00c9 exatamente isso que vamos descobrir!</p> <p>Vamos come\u00e7ar essa etapa do nosso curso explorando o ciclo de vida de dados em projetos de ci\u00eancia de dados - um roteiro que todo cientista de dados segue para extrair conhecimento valioso dos dados.</p> <p>Info</p> <p>A descoberta do conhecimento \u00e9 um conjunto estruturado de etapas que nos permite transformar grandes volumes de dados brutos em informa\u00e7\u00f5es \u00fateis e compreens\u00edveis.</p>"},{"location":"aulas/IA/intro/index2.html#introducao-ao-crisp-dm","title":"Introdu\u00e7\u00e3o ao CRISP-DMPor que o CRISP-DM \u00e9 representado como um processo c\u00edclico e n\u00e3o linear?","text":"<p>O CRISP-DM (Cross-Industry Standard Process for Data Mining) \u00e9 uma ferramenta amplamente utilizada na ind\u00fastria para projetos de ci\u00eancia de dados.</p> <p></p> <p>Repare que o processo \u00e9 c\u00edclico - isso significa que podemos voltar a etapas anteriores conforme descobrimos novos <code>insights</code>!</p> Porque os dados sempre mudam com o tempoPorque podemos descobrir novos insights que nos fazem repensar etapas anterioresPorque \u00e9 mais bonito visualmentePorque sempre precisamos come\u00e7ar do zeroSubmit Exato! O processo \u00e9 iterativo porque conforme avan\u00e7amos, podemos descobrir que precisamos coletar mais dados, redefinir o problema ou ajustar nossa abordagem. \u00c9 um processo de aprendizado cont\u00ednuo!"},{"location":"aulas/IA/intro/index2.html#1-entendimento-do-negocio","title":"1. Entendimento do Neg\u00f3cio","text":"<p>Tip</p> <p>\"Antes de resolver um problema, certifique-se de que est\u00e1 resolvendo o problema certo!\"</p> <p>O primeiro passo \u00e9 como ser um detetive: voc\u00ea precisa investigar e entender completamente o \"crime\" (problema) que precisa resolver. Muitos projetos falham porque pulam esta etapa crucial!</p> <p>Imagine que voc\u00ea trabalha em uma loja online e o gerente diz: \"Queremos usar IA para aumentar as vendas\". Parece claro, n\u00e9? Mas n\u00e3o \u00e9! Voc\u00ea precisa descobrir: - As vendas est\u00e3o baixas em quais produtos espec\u00edficos? - O problema \u00e9 atrair novos clientes ou fazer os existentes comprarem mais? - Qual \u00e9 o or\u00e7amento dispon\u00edvel? - Em quanto tempo precisam ver resultados?</p>"},{"location":"aulas/IA/intro/index2.html#perguntas-chave-desta-fase","title":"Perguntas-Chave desta Fase","text":"<ul> <li>Qual \u00e9 o problema de neg\u00f3cio que estamos tentando resolver?</li> <li>Como o sucesso ser\u00e1 medido?</li> <li>Quais s\u00e3o as restri\u00e7\u00f5es de tempo, or\u00e7amento e recursos?</li> <li>Como os resultados ser\u00e3o implementados?</li> </ul> Um gerente pede para \"usar machine learning para melhorar o atendimento ao cliente\". O que voc\u00ea deveria perguntar primeiro?Quais algoritmos ele prefere usarQuantos dados hist\u00f3ricos temos dispon\u00edveisComo exatamente ele define \"melhorar o atendimento\" e como vamos medir essa melhoriaQual \u00e9 o or\u00e7amento do projetoSubmit Perfeito! Sem definir claramente o que significa \"melhorar\" e como medir isso, voc\u00ea pode acabar resolvendo o problema errado. Pode ser reduzir tempo de espera, aumentar satisfa\u00e7\u00e3o, reduzir reclama\u00e7\u00f5es... cada um requer uma abordagem diferente!"},{"location":"aulas/IA/intro/index2.html#ferramentas-e-tecnicas","title":"Ferramentas e T\u00e9cnicas","text":"<ul> <li>Entrevistas e Workshops: Para coletar informa\u00e7\u00f5es dos stakeholders e especialistas</li> <li>Mapas Mentais: Para visualizar o problema e suas poss\u00edveis solu\u00e7\u00f5es</li> <li>5W2H: Framework para definir escopo (What, Why, Who, When, Where, How, How much)</li> </ul>"},{"location":"aulas/IA/intro/index2.html#2-entendimento-dos-dados","title":"2. Entendimento dos Dados","text":"<p>Agora que voc\u00ea sabe qual problema resolver, \u00e9 hora de conhecer seus os dados! Esta fase \u00e9 como explorar uma nova cidade: voc\u00ea precisa conhecer o territ\u00f3rio antes de planejar seu roteiro.</p> <p>Tip</p> <p>Dados ruins produzem modelos ruins, n\u00e3o importa qu\u00e3o sofisticado seja seu algoritmo! \u00c9 como tentar fazer um bolo delicioso com ingredientes estragados.</p>"},{"location":"aulas/IA/intro/index2.html#atividades-principais","title":"Atividades Principais","text":"<ul> <li>Coleta Inicial: Reunir todos os dados dispon\u00edveis (como fazer um invent\u00e1rio da sua cozinha)</li> <li>Descri\u00e7\u00e3o dos Dados: Documentar estrutura, formato e significado (criar um cat\u00e1logo dos ingredientes)</li> <li>Explora\u00e7\u00e3o: An\u00e1lise estat\u00edstica descritiva inicial (provar os ingredientes)</li> <li>Verifica\u00e7\u00e3o de Qualidade: Identificar problemas nos dados (verificar se est\u00e3o frescos)</li> </ul>"},{"location":"aulas/IA/intro/index2.html#ferramentas-e-tecnicas_1","title":"Ferramentas e T\u00e9cnicas","text":"<ul> <li>SQL e NoSQL: Para coleta de dados de bases estruturadas e n\u00e3o estruturadas</li> <li>Explora\u00e7\u00e3o de Dados: Usando pandas, matplotlib e seaborn para an\u00e1lise explorat\u00f3ria (EDA)</li> <li>An\u00e1lise de Qualidade: Verifica\u00e7\u00e3o de inconsist\u00eancias, valores ausentes e outliers</li> <li>Profiling de Dados: Ferramentas automatizadas para gerar relat\u00f3rios de qualidade</li> </ul> Durante a explora\u00e7\u00e3o inicial dos dados de vendas de uma empresa, voc\u00ea descobre que 30% dos registros t\u00eam valores ausentes na coluna \"idade do cliente\". Qual deve ser sua primeira a\u00e7\u00e3o?Excluir imediatamente todos os registros com dados ausentesPreencher com a m\u00e9dia de idade de todos os clientesInvestigar por que esses dados est\u00e3o ausentes e se h\u00e1 um padr\u00e3oIgnorar a coluna idade completamenteSubmit Correto! Primeiro voc\u00ea precisa entender o \"porqu\u00ea\" dos dados ausentes. Talvez clientes de certas regi\u00f5es n\u00e3o informem idade, ou o sistema teve problemas em per\u00edodos espec\u00edficos. Essa investiga\u00e7\u00e3o pode revelar insights importantes!"},{"location":"aulas/IA/intro/index2.html#3-preparacao-dos-dados","title":"3. Prepara\u00e7\u00e3o dos Dados","text":"<p>Chegamos \u00e0 fase que consome 70-80% do tempo de qualquer projeto de ci\u00eancia de dados! \u00c9 trabalhoso, mas essencial para o sucesso.</p> <p>Realidade check: Se voc\u00ea acha que ci\u00eancia de dados \u00e9 s\u00f3 treinar modelos sofisticados, prepare-se para uma surpresa! A maior parte do tempo voc\u00ea ser\u00e1 um \"faxineiro de dados\" - e isso \u00e9 perfeitamente normal e necess\u00e1rio.</p>"},{"location":"aulas/IA/intro/index2.html#atividades-detalhadas","title":"Atividades Detalhadas","text":"<ul> <li>Limpeza: Remo\u00e7\u00e3o de duplicatas, corre\u00e7\u00e3o de inconsist\u00eancias</li> <li>Integra\u00e7\u00e3o: Combina\u00e7\u00e3o de dados de m\u00faltiplas fontes (como juntar ingredientes de fornecedores diferentes)</li> <li>Transforma\u00e7\u00e3o: Normaliza\u00e7\u00e3o, padroniza\u00e7\u00e3o, discretiza\u00e7\u00e3o</li> <li>Redu\u00e7\u00e3o: Sele\u00e7\u00e3o de features e redu\u00e7\u00e3o de dimensionalidade</li> <li>Constru\u00e7\u00e3o: Feature engineering - criar novas vari\u00e1veis que ajudem o modelo</li> </ul>"},{"location":"aulas/IA/intro/index2.html#ferramentas-e-tecnicas_2","title":"Ferramentas e T\u00e9cnicas","text":"<ul> <li>Pandas e NumPy: Para manipula\u00e7\u00e3o e transforma\u00e7\u00e3o de dados</li> <li>Scikit-learn: Para pr\u00e9-processamento como normaliza\u00e7\u00e3o e codifica\u00e7\u00e3o</li> <li>Feature Engineering: Cria\u00e7\u00e3o de novas features (a parte mais criativa!)</li> <li>Pipelines: Automatiza\u00e7\u00e3o do processo de prepara\u00e7\u00e3o</li> </ul>"},{"location":"aulas/IA/intro/index2.html#4-modelagem","title":"4. Modelagem","text":"<p>Aqui \u00e9 onde a m\u00e1gica acontece e voc\u00ea aplica algoritmos de machine learning aos seus dados preparados.</p> <p>Tip</p> <p>Importante: N\u00e3o existe um algoritmo <code>melhor</code> para todos os problemas. \u00c9 como escolher uma ferramenta, voc\u00ea usaria um martelo para apertar um parafuso?</p>"},{"location":"aulas/IA/intro/index2.html#tipos-de-problemas-e-tecnicas","title":"Tipos de Problemas e T\u00e9cnicas","text":"<p>Problemas Supervisionados (quando voc\u00ea tem as \"respostas corretas\" para treinar): - Classifica\u00e7\u00e3o: Prever categorias (spam ou n\u00e3o spam, gato ou cachorro)   - \u00c1rvores de Decis\u00e3o, Random Forest, SVM, Redes Neurais - Regress\u00e3o: Prever valores num\u00e9ricos (pre\u00e7o de casa, vendas do pr\u00f3ximo m\u00eas)   - Regress\u00e3o Linear, Ridge, Lasso, XGBoost</p> <p>Problemas N\u00e3o-Supervisionados (quando voc\u00ea explora sem \"respostas\" pr\u00e9-definidas): - Clustering: Agrupar dados similares (segmentar clientes)   - K-Means, Hierarchical Clustering, DBSCAN - Redu\u00e7\u00e3o de Dimensionalidade: Simplificar dados complexos   - PCA, t-SNE, UMAP</p> <p></p> Voc\u00ea precisa prever se um e-mail \u00e9 spam ou n\u00e3o. Que tipo de problema \u00e9 este?Regress\u00e3o, porque queremos um valor num\u00e9ricoClassifica\u00e7\u00e3o, porque queremos categorizar em duas classesClustering, porque queremos agrupar e-mails similaresRedu\u00e7\u00e3o de dimensionalidade, porque temos muitas palavrasSubmit Perfeito! \u00c9 um problema de classifica\u00e7\u00e3o bin\u00e1ria pois queremos classificar cada e-mail em uma de duas categorias: spam ou n\u00e3o spam. O resultado \u00e9 uma categoria, n\u00e3o um valor num\u00e9rico."},{"location":"aulas/IA/intro/index2.html#ferramentas-e-tecnicas_3","title":"Ferramentas e T\u00e9cnicas","text":"<ul> <li>Scikit-learn: Para algoritmos tradicionais de machine learning</li> <li>TensorFlow/Keras e PyTorch: Para redes neurais profundas</li> <li>Cross-validation: Para avaliar modelos de forma robusta</li> <li>Grid Search: Para encontrar os melhores par\u00e2metros</li> </ul>"},{"location":"aulas/IA/intro/index2.html#5-avaliacao","title":"5. Avalia\u00e7\u00e3o","text":"<p>Tip</p> <p>\"Um modelo que parece bom no papel pode ser um desastre na vida real!\"</p> <p>\u00c9 importante validar se o modelo realmente resolve o problema de neg\u00f3cio. Esta fase de avalia\u00e7\u00e3o vai al\u00e9m de olhar m\u00e9tricas t\u00e9cnicas.</p>"},{"location":"aulas/IA/intro/index2.html#metricas-de-avaliacao-por-tipo-de-problema","title":"M\u00e9tricas de Avalia\u00e7\u00e3o por Tipo de Problema","text":"<p>Classifica\u00e7\u00e3o: - Accuracy: Quantos acertei do total (cuidado com dados desbalanceados!) - Precision: Dos que previ como positivos, quantos realmente eram? - Recall: Dos positivos reais, quantos consegui encontrar? - F1-Score: Harmonia entre precision e recall</p> <p>Regress\u00e3o: - RMSE: Qu\u00e3o longe, em m\u00e9dia, minhas previs\u00f5es est\u00e3o da realidade? - MAE: Erro m\u00e9dio absoluto (mais f\u00e1cil de interpretar) - R\u00b2: Quanto da varia\u00e7\u00e3o consigo explicar? (0-100%)</p> Voc\u00ea criou um modelo para detectar fraudes banc\u00e1rias. O modelo tem 99% de accuracy, mas detecta apenas 10% das fraudes reais. Qual \u00e9 o problema principal?O modelo est\u00e1 overfittadoPrecisamos de mais dados de treinoO modelo tem baixo recall - est\u00e1 perdendo muitas fraudes reaisA accuracy est\u00e1 muito alta, deve estar erradoSubmit Exato! Com dados desbalanceados (poucas fraudes), alta accuracy pode ser enganosa. Se apenas 1% das transa\u00e7\u00f5es s\u00e3o fraudes, um modelo que sempre diz \"n\u00e3o \u00e9 fraude\" teria 99% accuracy, mas seria in\u00fatil! O recall baixo indica que estamos perdendo fraudes reais."},{"location":"aulas/IA/intro/index2.html#ferramentas-e-tecnicas_4","title":"Ferramentas e T\u00e9cnicas","text":"<ul> <li>M\u00e9tricas de Avalia\u00e7\u00e3o: Precision, recall, F1-score, AUC-ROC</li> <li>Confusion Matrix: Para an\u00e1lise visual detalhada</li> <li>ROC Curves: Para avaliar trade-offs entre sensibilidade e especificidade</li> <li>A/B Testing: Para valida\u00e7\u00e3o no mundo real</li> <li>An\u00e1lise de Bias: Verifica\u00e7\u00e3o de vieses e fairness</li> </ul>"},{"location":"aulas/IA/intro/index2.html#6-implantacao","title":"6. Implanta\u00e7\u00e3o","text":"<p>Tip</p> <p>\"Um modelo que n\u00e3o vai para produ\u00e7\u00e3o \u00e9 apenas um hobby caro!\"</p> <p>Aqui \u00e9 onde seu modelo sai do laborat\u00f3rio e entra no mundo real.</p>"},{"location":"aulas/IA/intro/index2.html#ferramentas-e-tecnicas_5","title":"Ferramentas e T\u00e9cnicas","text":"<ul> <li>Flask e FastAPI: Para criar APIs web</li> <li>Docker e Kubernetes: Para containeriza\u00e7\u00e3o e escalabilidade</li> <li>MLflow: Para versionar e rastrear modelos</li> <li>Monitoramento: Prometheus e Grafana para acompanhar performance</li> <li>CI/CD: Deploy automatizado e seguro</li> </ul> Seu modelo de recomenda\u00e7\u00e3o est\u00e1 em produ\u00e7\u00e3o h\u00e1 3 meses e a performance come\u00e7ou a cair. Qual \u00e9 a causa mais prov\u00e1vel?O c\u00f3digo do modelo foi corrompidoOs servidores est\u00e3o sobrecarregadosOs dados mudaram e o modelo precisa ser retreinadoOs usu\u00e1rios pararam de usar o sistemaSubmit Correto! Este \u00e9 um fen\u00f4meno comum chamado \"model drift\". Com o tempo, os padr\u00f5es nos dados mudam (novos produtos, mudan\u00e7as no comportamento do usu\u00e1rio), e o modelo fica \"desatualizado\". \u00c9 por isso que monitoramento e retreinamento s\u00e3o essenciais!"},{"location":"aulas/IA/intro/index2.html#outras-estrategias","title":"Outras estrat\u00e9giasQual \u00e9 a primeira fase do CRISP-DM e por que ela \u00e9 crucial?Uma empresa de e-commerce quer implementar um sistema de recomenda\u00e7\u00e3o de produtos. Ordene as fases do CRISP-DM que seriam seguidas.Voc\u00ea est\u00e1 trabalhando em um projeto de ci\u00eancia de dados e percebe que est\u00e1 gastando mais tempo preparando dados do que criando modelos. Isso \u00e9:","text":"<p>Embora o CRISP-DM seja o mais popular, existem outras metodologias interessantes:</p> <ul> <li>KDD (Knowledge Discovery in Databases) - O \"av\u00f4\" do CRISP-DM, mais acad\u00eamico</li> </ul> <p></p> <ul> <li>SEMMA (Sample, Explore, Modify, Model, Assess) - Criado pela SAS, focado nas ferramentas</li> </ul> <p></p> <ul> <li>MLOps (Machine Learning Operations) - A evolu\u00e7\u00e3o moderna, focada em automa\u00e7\u00e3o e DevOps</li> </ul> <p></p> Prepara\u00e7\u00e3o dos Dados - porque dados limpos s\u00e3o essenciaisEntendimento do Neg\u00f3cio - porque define objetivos e crit\u00e9rios de sucessoModelagem - porque \u00e9 onde a IA aconteceColeta de Dados - porque precisamos de dados para come\u00e7arSubmit O entendimento do neg\u00f3cio \u00e9 fundamental porque estabelece o que realmente precisa ser resolvido, como o sucesso ser\u00e1 medido e garante que o projeto esteja alinhado com os objetivos organizacionais. Entendimento do Neg\u00f3cio \u2192 Entendimento dos Dados \u2192 Prepara\u00e7\u00e3o dos Dados \u2192 Modelagem \u2192 Avalia\u00e7\u00e3o \u2192 Implanta\u00e7\u00e3oPrepara\u00e7\u00e3o dos Dados \u2192 Modelagem \u2192 Entendimento do Neg\u00f3cio \u2192 Avalia\u00e7\u00e3o \u2192 Entendimento dos Dados \u2192 Implanta\u00e7\u00e3oModelagem \u2192 Entendimento do Neg\u00f3cio \u2192 Prepara\u00e7\u00e3o dos Dados \u2192 Avalia\u00e7\u00e3o \u2192 Implanta\u00e7\u00e3o \u2192 Entendimento dos DadosEntendimento dos Dados \u2192 Modelagem \u2192 Prepara\u00e7\u00e3o dos Dados \u2192 Avalia\u00e7\u00e3o \u2192 Entendimento do Neg\u00f3cio \u2192 Implanta\u00e7\u00e3oSubmit Correto! Entendimento do Neg\u00f3cio \u2192 Entendimento dos Dados \u2192 Prepara\u00e7\u00e3o dos Dados \u2192 Modelagem \u2192 Avalia\u00e7\u00e3o \u2192 Implanta\u00e7\u00e3o Um sinal de que voc\u00ea est\u00e1 fazendo algo erradoMotivo para pular algumas etapas de limpezaCompletamente normal - prepara\u00e7\u00e3o de dados consome 70-80% do tempoIndica\u00e7\u00e3o de que os dados s\u00e3o de baixa qualidadeSubmit Isso \u00e9 absolutamente normal! A prepara\u00e7\u00e3o de dados \u00e9 a parte mais trabalhosa, mas tamb\u00e9m mais importante de qualquer projeto. Dados bem preparados s\u00e3o a base para modelos de sucesso. Como dizem: \"Garbage in, garbage out!\""},{"location":"aulas/IA/lab-01/aula5-parte2.html","title":"lab2","text":"In\u00a0[1]: Copied! <pre>#Importe das libs\nimport pandas as pd\n\nfrom sklearn.cluster import KMeans, DBSCAN\nfrom sklearn.mixture import GaussianMixture\n\nimport matplotlib.pyplot as plt\n</pre> #Importe das libs import pandas as pd  from sklearn.cluster import KMeans, DBSCAN from sklearn.mixture import GaussianMixture  import matplotlib.pyplot as plt In\u00a0[2]: Copied! <pre>url_db = 'https://raw.githubusercontent.com/reisanar/datasets/master/moons.csv'\nmoons = pd.read_csv(url_db)\n</pre> url_db = 'https://raw.githubusercontent.com/reisanar/datasets/master/moons.csv' moons = pd.read_csv(url_db) In\u00a0[3]: Copied! <pre>moons.head()\n</pre> moons.head() Out[3]: X Y 0 -0.415208 1.035735 1 0.058781 0.304334 2 1.109379 -0.509738 3 1.540948 -0.427550 4 0.929095 -0.532388 In\u00a0[4]: Copied! <pre>plt.scatter(x=moons['X'], y=moons['Y'])\n</pre> plt.scatter(x=moons['X'], y=moons['Y']) Out[4]: <pre>&lt;matplotlib.collections.PathCollection at 0x16a43b1c0&gt;</pre> In\u00a0[5]: Copied! <pre># Modelos de agrupamento\n\nrandom_state = 42\n\n#k-means\nkm = KMeans(n_clusters=4, random_state=random_state) # k=4\n#Gaussian Mixture\ngm = GaussianMixture(n_components=4, random_state=random_state) #k=4\n#DBScan\ndb = DBSCAN(eps=0.4)\n</pre> # Modelos de agrupamento  random_state = 42  #k-means km = KMeans(n_clusters=4, random_state=random_state) # k=4 #Gaussian Mixture gm = GaussianMixture(n_components=4, random_state=random_state) #k=4 #DBScan db = DBSCAN(eps=0.4) In\u00a0[6]: Copied! <pre>#aplica o algoritimo e armazena o cluster de cada dado\n\nkm_c = km.fit_predict(moons)\ngm_c = gm.fit_predict(moons)\ndb_c = db.fit_predict(moons)\n</pre> #aplica o algoritimo e armazena o cluster de cada dado  km_c = km.fit_predict(moons) gm_c = gm.fit_predict(moons) db_c = db.fit_predict(moons) In\u00a0[7]: Copied! <pre>fig = plt.figure(figsize = (12,8), dpi=80)\nplt.subplot(2,2,1)\nplt.scatter(x=moons['X'],y=moons['Y'])\nplt.title('Original')\nplt.subplot(2,2,2)\nplt.scatter(x=moons['X'],y=moons['Y'], c=km_c)\nplt.title('KMeans')\nplt.subplot(2,2,3)\nplt.scatter(x=moons['X'],y=moons['Y'], c=gm_c)\nplt.title('GaussianMixture')\nplt.subplot(2,2,4)\nplt.scatter(x=moons['X'],y=moons['Y'], c=db_c)\nplt.title('DBScan')\n</pre> fig = plt.figure(figsize = (12,8), dpi=80) plt.subplot(2,2,1) plt.scatter(x=moons['X'],y=moons['Y']) plt.title('Original') plt.subplot(2,2,2) plt.scatter(x=moons['X'],y=moons['Y'], c=km_c) plt.title('KMeans') plt.subplot(2,2,3) plt.scatter(x=moons['X'],y=moons['Y'], c=gm_c) plt.title('GaussianMixture') plt.subplot(2,2,4) plt.scatter(x=moons['X'],y=moons['Y'], c=db_c) plt.title('DBScan') Out[7]: <pre>Text(0.5, 1.0, 'DBScan')</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre>"},{"location":"aulas/IA/lab-01/aula5-parte2.html#2-aprendizagem-de-maquina","title":"2. Aprendizagem de m\u00e1quina\u00b6","text":""},{"location":"aulas/IA/lab-01/aula5-parte2.html#objetivos","title":"Objetivos\u00b6","text":"<ul> <li>Apresentar e praticar conceitos de aprendizado n\u00e3o supervisionado</li> <li>Compreender o conceito de cluster</li> <li>Apresentar os algoritimos KMeans, DBScan e GaussianMixture</li> </ul>"},{"location":"aulas/IA/lab-01/aula5-parte2.html#e-se-os-dados-nao-forem-volumetricos-ou-globulares-o-k-means-consegue-clusterizar","title":"E se os dados n\u00e3o forem volum\u00e9tricos ou globulares?  o K-Means consegue clusterizar?\u00b6","text":""},{"location":"aulas/IA/lab-01/aula5-parte2.html#aplicando-gmm-e-dbscan","title":"Aplicando GMM e DBSCAN\u00b6","text":"<ul> <li><p><code>Gaussian Mixture Models</code> \u00e9 uma abordagem probabil\u00edstica para o agrupamento, que tenta modelar cada cluster como uma distribui\u00e7\u00e3o gaussiana (normal).</p> </li> <li><p><code>DBSCAN (Density-Based Spatial Clustering of Applications with Noise)</code> \u00e9 um algoritmo de clustering baseado na densidade dos pontos. Ele \u00e9 capaz de identificar clusters de formas arbitr\u00e1rias e tratar pontos ruidosos (outliers) de maneira eficiente.</p> <ul> <li><p>O DBSCAN possui dois principais par\u00e2metros:</p> <ul> <li><code>eps</code>: A dist\u00e2ncia m\u00e1xima entre dois pontos para que sejam considerados vizinhos.</li> <li><code>min_samples</code>: O n\u00famero m\u00ednimo de pontos vizinhos para que um ponto seja considerado parte de um cluster.</li> </ul> </li> </ul> </li> </ul>"},{"location":"aulas/IA/lab-01/aula5-parte2.html#carregando-os-dados","title":"Carregando os dados\u00b6","text":""},{"location":"aulas/IA/lab-01/aula5-parte2.html#criacao-de-modelos-de-agrupamento","title":"Cria\u00e7\u00e3o de modelos de Agrupamento\u00b6","text":""},{"location":"aulas/IA/lab-01/aula5.html","title":"lab1","text":"<p>Uma das t\u00e9cnicas de aprendizagem n\u00e3o supervisionada \u00e9 o agrupamento autom\u00e1tico de dados ou clusteriza\u00e7\u00e3o.</p> <p>Lembre-se: Em aprendizagem n\u00e3o supervissionada, o nosso conjunto de dados para treino n\u00e3o possui label.</p> <p>Essa t\u00e9cnica classifica os dados em conjuntos que apresentam alguma similaridade (dist\u00e2ncia das observa\u00e7\u00f5es). Os grupos gerados nesse processo s\u00e3o chamados de <code>clusters</code>.</p> In\u00a0[2]: Copied! <pre>%matplotlib inline\nimport matplotlib.pyplot as plt\nimport seaborn as sns; sns.set()  # for plot styling\nimport numpy as np\n</pre> %matplotlib inline import matplotlib.pyplot as plt import seaborn as sns; sns.set()  # for plot styling import numpy as np In\u00a0[3]: Copied! <pre>from sklearn.datasets import make_blobs\n\nX, y_true = make_blobs(n_samples=300, centers=4,\n                       cluster_std=0.60, random_state=0)\nplt.scatter(X[:, 0], X[:, 1], s=50);\n</pre> from sklearn.datasets import make_blobs  X, y_true = make_blobs(n_samples=300, centers=4,                        cluster_std=0.60, random_state=0) plt.scatter(X[:, 0], X[:, 1], s=50); In\u00a0[4]: Copied! <pre>from sklearn.cluster import KMeans\nkmeans = KMeans(n_clusters=4)\nkmeans.fit(X)\ny_kmeans = kmeans.predict(X)\n</pre> from sklearn.cluster import KMeans kmeans = KMeans(n_clusters=4) kmeans.fit(X) y_kmeans = kmeans.predict(X) In\u00a0[5]: Copied! <pre>plt.scatter(X[:, 0], X[:, 1], c=y_kmeans, s=50, cmap='viridis')\n\ncenters = kmeans.cluster_centers_\nplt.scatter(centers[:, 0], centers[:, 1], c='black', s=200, alpha=0.5);\n</pre> plt.scatter(X[:, 0], X[:, 1], c=y_kmeans, s=50, cmap='viridis')  centers = kmeans.cluster_centers_ plt.scatter(centers[:, 0], centers[:, 1], c='black', s=200, alpha=0.5); In\u00a0[\u00a0]: Copied! <pre>## sua resposta...\n</pre> ## sua resposta... In\u00a0[6]: Copied! <pre>inertias = []\nK = range(1, 10)\n\nfor k in K:\n    kmeans = KMeans(n_clusters=k, random_state=42)\n    kmeans.fit(X)\n    inertias.append(kmeans.inertia_)\n\n# Plotando o gr\u00e1fico\nplt.plot(K, inertias, 'bo-')\nplt.xlabel('N\u00famero de clusters, K')\nplt.ylabel('In\u00e9rcia')\nplt.title('M\u00e9todo do Cotovelo para Escolher K')\nplt.show()\n</pre> inertias = [] K = range(1, 10)  for k in K:     kmeans = KMeans(n_clusters=k, random_state=42)     kmeans.fit(X)     inertias.append(kmeans.inertia_)  # Plotando o gr\u00e1fico plt.plot(K, inertias, 'bo-') plt.xlabel('N\u00famero de clusters, K') plt.ylabel('In\u00e9rcia') plt.title('M\u00e9todo do Cotovelo para Escolher K') plt.show()  In\u00a0[14]: Copied! <pre>import pandas as pd\n\nfrom sklearn.cluster import KMeans\n\nk_otimo = 4 # Definindo o n\u00famero \u00f3timo de clusters\n\nkmeans = KMeans(n_clusters=k_otimo)\n\nkmeans.fit(X)\ny_kmeans = kmeans.predict(X)\n\n# Criando um DataFrame a partir dos dados gerados\ndf = pd.DataFrame(X, columns=['Feature 1', 'Feature 2'])\n\n# Adicionando a coluna de clusters ao DataFrame\ndf['Cluster'] = y_kmeans\n\n# Exibindo as primeiras linhas do DataFrame para visualiza\u00e7\u00e3o\ndf.head()\n</pre> import pandas as pd  from sklearn.cluster import KMeans  k_otimo = 4 # Definindo o n\u00famero \u00f3timo de clusters  kmeans = KMeans(n_clusters=k_otimo)  kmeans.fit(X) y_kmeans = kmeans.predict(X)  # Criando um DataFrame a partir dos dados gerados df = pd.DataFrame(X, columns=['Feature 1', 'Feature 2'])  # Adicionando a coluna de clusters ao DataFrame df['Cluster'] = y_kmeans  # Exibindo as primeiras linhas do DataFrame para visualiza\u00e7\u00e3o df.head()  Out[14]: Feature 1 Feature 2 Cluster 0 0.836857 2.136359 0 1 -1.413658 7.409623 2 2 1.155213 5.099619 1 3 -1.018616 7.814915 2 4 1.271351 1.892542 0"},{"location":"aulas/IA/lab-01/aula5.html#2-aprendizagem-de-maquina","title":"2. Aprendizagem de m\u00e1quina\u00b6","text":""},{"location":"aulas/IA/lab-01/aula5.html#objetivos","title":"Objetivos\u00b6","text":"<ul> <li>Apresentar e praticar conceitos de aprendizado n\u00e3o supervisionado</li> <li>Compreender o conceito de cluster</li> <li>Apresentar os algoritimos KMeans, DBScan e GaussianMixture</li> </ul>"},{"location":"aulas/IA/lab-01/aula5.html#metodos-de-agrupamento","title":"M\u00e9todos de agrupamento\u00b6","text":""},{"location":"aulas/IA/lab-01/aula5.html#desafio-1","title":"Desafio 1\u00b6","text":"<p>Acesse o link e realize o cadastro com email <code>FIAP</code> e bora fazer a atividade: https://miro.com/app/board/o9J_l2e1B1U=/</p>"},{"location":"aulas/IA/lab-01/aula5.html#k-means","title":"K-Means\u00b6","text":"<p>O K-Means \u00e9 SIMPLE por isso \u00e9 um dos metodos de clusteriza\u00e7\u00e3o mais \"cl\u00e1sicos\" e recebe esse nome pois encontra uma quantidade <code>K de clusters</code>, sendo K um par\u00e2metro para o modelo e para cada cluster \u00e9 atribu\u00eddo um centro chamado de <code>centroide</code>. Tambem conhecido m\u00e9todo de parti\u00e7\u00e3o sem sobreposi\u00e7\u00e3o.</p>"},{"location":"aulas/IA/lab-01/aula5.html#curiosidades","title":"Curiosidades\u00b6","text":"<p>Esse algoritimo est\u00e1 entre os top 10 algoritimos de minera\u00e7\u00e3o de dados (data mining)</p> <p>\u00c9 um algoritimo utilizado a mais de 70 anos, existe papers das decadas de 50 e 60 que falam sobre ele.</p>"},{"location":"aulas/IA/lab-01/aula5.html#algoritmo-k-means","title":"Algoritmo K-Means\u00b6","text":"<p>O algoritimo K-Means trata-se de um m\u00e9todo iterativo e pode ser definido em 4 etapas, s\u00e3o elas:</p> <ol> <li><p>Escolher aleatoriamente k prot\u00f3tipos (centros) para os clusters</p> </li> <li><p>Atribuir cada objeto para o cluster de centro mais pr\u00f3ximo (segundo alguma dist\u00e2ncia, e.g. Euclidiana)</p> </li> <li><p>Mover cada centro para a m\u00e9dia (centr\u00f3ide) dos objetos do cluster correspondente</p> </li> <li><p>Repetir os passos 2 e 3 at\u00e9 que algum crit\u00e9rio de converg\u00eancia seja obtido:</p> </li> </ol> <ul> <li>n\u00famero m\u00e1ximo de itera\u00e7\u00f5es</li> <li>limiar m\u00ednimo de mudan\u00e7as nos centr\u00f3ides</li> </ul>"},{"location":"aulas/IA/lab-01/aula5.html#vantagens-e-desvantagens","title":"Vantagens e Desvantagens\u00b6","text":""},{"location":"aulas/IA/lab-01/aula5.html#vantagens","title":"Vantagens\u00b6","text":"<ul> <li>Simples e intuitivo</li> <li>Complexidade computacional linear em todas as vari\u00e1veis cr\u00edticas</li> <li>Eficaz em muitos cen\u00e1rios de aplica\u00e7\u00e3o e produz resultados de interpreta\u00e7\u00e3o simples</li> </ul>"},{"location":"aulas/IA/lab-01/aula5.html#desvantagens","title":"Desvantagens\u00b6","text":"<ul> <li>k = ?</li> <li>Sens\u00edvel \u00e0 inicializa\u00e7\u00e3o dos prot\u00f3tipos (m\u00ednimos locais)</li> <li>Limita-se a encontrar clusters volum\u00e9tricos / globulares</li> <li>Cada item deve pertencer a um \u00fanico cluster (parti\u00e7\u00e3o r\u00edgida, ou seja, sem sobreposi\u00e7\u00e3o)</li> <li>Limitado a atributos num\u00e9ricos</li> <li>Sens\u00edvel a outliers</li> </ul>"},{"location":"aulas/IA/lab-01/aula5.html#desafio-2","title":"Desafio 2\u00b6","text":"<p>Pergunta: E como descobrir o n\u00famero de k?</p> <p>dica: Busque por refer\u00eancias como o m\u00e9todo do cotovelo ou elbow...</p>"},{"location":"aulas/IA/lab-01/aula5.html#selecionando-o-numero-otimo-de-clusters-com-o-metodo-do-cotovelo","title":"Selecionando o N\u00famero \u00d3timo de Clusters com o M\u00e9todo do Cotovelo\u00b6","text":"<p>O m\u00e9todo do cotovelo ajuda a escolher o n\u00famero ideal de clusters, plotando a in\u00e9rcia contra o n\u00famero de clusters. Quando o gr\u00e1fico come\u00e7a a \"dobrar\", \u00e9 um bom indicativo de que o n\u00famero de clusters adequado foi atingido.</p>"},{"location":"aulas/IA/lab-01/aula5.html#adicionar-os-clusters-ao-dataset","title":"Adicionar os Clusters ao Dataset\u00b6","text":"<p>Para adicionar os clusters encontrados pelo algoritmo K-means como uma nova coluna no dataset, podemos usar o pacote Pandas para manipular os dados de forma organizada.</p> <p>Passos para Adicionar os Clusters ao Dataset:</p> <ul> <li>Usaremos Pandas para criar um DataFrame com os dados originais.</li> <li>Adicionaremos a coluna clusters com os valores gerados pelo K-means.</li> </ul>"},{"location":"aulas/IA/lab-02/aula6.html","title":"lab2","text":"In\u00a0[1]: Copied! <pre>%matplotlib inline\n\n# O scipy \u00e9 bastante utilizada para Data Science\nfrom scipy.cluster.hierarchy import dendrogram, linkage\n\nfrom sklearn.cluster import AgglomerativeClustering\nimport matplotlib.pyplot as plt\nimport pandas as pd\nimport numpy as np\n</pre> %matplotlib inline  # O scipy \u00e9 bastante utilizada para Data Science from scipy.cluster.hierarchy import dendrogram, linkage  from sklearn.cluster import AgglomerativeClustering import matplotlib.pyplot as plt import pandas as pd import numpy as np In\u00a0[2]: Copied! <pre>url_db= 'https://stackabuse.s3.amazonaws.com/files/hierarchical-clustering-with-python-and-scikit-learn-shopping-data.csv'\ndf = pd.read_csv(url_db)\n\n#renomeando o nome das colunas para tirar espa\u00e7o\ndf.columns = ['CustomerID', 'Genre', 'Age', 'Annual_Income_k','Spending_Score_1_100']\ndf.head()\n</pre> url_db= 'https://stackabuse.s3.amazonaws.com/files/hierarchical-clustering-with-python-and-scikit-learn-shopping-data.csv' df = pd.read_csv(url_db)  #renomeando o nome das colunas para tirar espa\u00e7o df.columns = ['CustomerID', 'Genre', 'Age', 'Annual_Income_k','Spending_Score_1_100'] df.head() Out[2]: CustomerID Genre Age Annual_Income_k Spending_Score_1_100 0 1 Male 19 15 39 1 2 Male 21 15 81 2 3 Female 20 16 6 3 4 Female 23 16 77 4 5 Female 31 17 40 <p>Descri\u00e7\u00e3o das colunas do dataset:</p> <pre><code>            CustomerID = Identifica\u00e7\u00e3o do usuario\n                Genre  = Genero\n                Age    = Idade\n    Annual Income (k$) = Rendimento anual em k$\t\nSpending Score (1-100) = Indice de \"vontade de gastar no shooping\"</code></pre> In\u00a0[4]: Copied! <pre>data = df.iloc[:,[3,4]].values;\ndata\n</pre> data = df.iloc[:,[3,4]].values; data Out[4]: <pre>array([[ 15,  39],\n       [ 15,  81],\n       [ 16,   6],\n       [ 16,  77],\n       [ 17,  40],\n       [ 17,  76],\n       [ 18,   6],\n       [ 18,  94],\n       [ 19,   3],\n       [ 19,  72],\n       [ 19,  14],\n       [ 19,  99],\n       [ 20,  15],\n       [ 20,  77],\n       [ 20,  13],\n       [ 20,  79],\n       [ 21,  35],\n       [ 21,  66],\n       [ 23,  29],\n       [ 23,  98],\n       [ 24,  35],\n       [ 24,  73],\n       [ 25,   5],\n       [ 25,  73],\n       [ 28,  14],\n       [ 28,  82],\n       [ 28,  32],\n       [ 28,  61],\n       [ 29,  31],\n       [ 29,  87],\n       [ 30,   4],\n       [ 30,  73],\n       [ 33,   4],\n       [ 33,  92],\n       [ 33,  14],\n       [ 33,  81],\n       [ 34,  17],\n       [ 34,  73],\n       [ 37,  26],\n       [ 37,  75],\n       [ 38,  35],\n       [ 38,  92],\n       [ 39,  36],\n       [ 39,  61],\n       [ 39,  28],\n       [ 39,  65],\n       [ 40,  55],\n       [ 40,  47],\n       [ 40,  42],\n       [ 40,  42],\n       [ 42,  52],\n       [ 42,  60],\n       [ 43,  54],\n       [ 43,  60],\n       [ 43,  45],\n       [ 43,  41],\n       [ 44,  50],\n       [ 44,  46],\n       [ 46,  51],\n       [ 46,  46],\n       [ 46,  56],\n       [ 46,  55],\n       [ 47,  52],\n       [ 47,  59],\n       [ 48,  51],\n       [ 48,  59],\n       [ 48,  50],\n       [ 48,  48],\n       [ 48,  59],\n       [ 48,  47],\n       [ 49,  55],\n       [ 49,  42],\n       [ 50,  49],\n       [ 50,  56],\n       [ 54,  47],\n       [ 54,  54],\n       [ 54,  53],\n       [ 54,  48],\n       [ 54,  52],\n       [ 54,  42],\n       [ 54,  51],\n       [ 54,  55],\n       [ 54,  41],\n       [ 54,  44],\n       [ 54,  57],\n       [ 54,  46],\n       [ 57,  58],\n       [ 57,  55],\n       [ 58,  60],\n       [ 58,  46],\n       [ 59,  55],\n       [ 59,  41],\n       [ 60,  49],\n       [ 60,  40],\n       [ 60,  42],\n       [ 60,  52],\n       [ 60,  47],\n       [ 60,  50],\n       [ 61,  42],\n       [ 61,  49],\n       [ 62,  41],\n       [ 62,  48],\n       [ 62,  59],\n       [ 62,  55],\n       [ 62,  56],\n       [ 62,  42],\n       [ 63,  50],\n       [ 63,  46],\n       [ 63,  43],\n       [ 63,  48],\n       [ 63,  52],\n       [ 63,  54],\n       [ 64,  42],\n       [ 64,  46],\n       [ 65,  48],\n       [ 65,  50],\n       [ 65,  43],\n       [ 65,  59],\n       [ 67,  43],\n       [ 67,  57],\n       [ 67,  56],\n       [ 67,  40],\n       [ 69,  58],\n       [ 69,  91],\n       [ 70,  29],\n       [ 70,  77],\n       [ 71,  35],\n       [ 71,  95],\n       [ 71,  11],\n       [ 71,  75],\n       [ 71,   9],\n       [ 71,  75],\n       [ 72,  34],\n       [ 72,  71],\n       [ 73,   5],\n       [ 73,  88],\n       [ 73,   7],\n       [ 73,  73],\n       [ 74,  10],\n       [ 74,  72],\n       [ 75,   5],\n       [ 75,  93],\n       [ 76,  40],\n       [ 76,  87],\n       [ 77,  12],\n       [ 77,  97],\n       [ 77,  36],\n       [ 77,  74],\n       [ 78,  22],\n       [ 78,  90],\n       [ 78,  17],\n       [ 78,  88],\n       [ 78,  20],\n       [ 78,  76],\n       [ 78,  16],\n       [ 78,  89],\n       [ 78,   1],\n       [ 78,  78],\n       [ 78,   1],\n       [ 78,  73],\n       [ 79,  35],\n       [ 79,  83],\n       [ 81,   5],\n       [ 81,  93],\n       [ 85,  26],\n       [ 85,  75],\n       [ 86,  20],\n       [ 86,  95],\n       [ 87,  27],\n       [ 87,  63],\n       [ 87,  13],\n       [ 87,  75],\n       [ 87,  10],\n       [ 87,  92],\n       [ 88,  13],\n       [ 88,  86],\n       [ 88,  15],\n       [ 88,  69],\n       [ 93,  14],\n       [ 93,  90],\n       [ 97,  32],\n       [ 97,  86],\n       [ 98,  15],\n       [ 98,  88],\n       [ 99,  39],\n       [ 99,  97],\n       [101,  24],\n       [101,  68],\n       [103,  17],\n       [103,  85],\n       [103,  23],\n       [103,  69],\n       [113,   8],\n       [113,  91],\n       [120,  16],\n       [120,  79],\n       [126,  28],\n       [126,  74],\n       [137,  18],\n       [137,  83]])</pre> In\u00a0[7]: Copied! <pre>plt.figure(figsize=(10,7))\nplt.scatter(data[:, 0], data[:, 1])\n</pre> plt.figure(figsize=(10,7)) plt.scatter(data[:, 0], data[:, 1])  Out[7]: <pre>&lt;matplotlib.collections.PathCollection at 0x1483ec7f0&gt;</pre> In\u00a0[8]: Copied! <pre>plt.figure(figsize=(10,10))\nden = dendrogram(linkage(data, method='average'))\n#plt.axhline(y=30)\n</pre> plt.figure(figsize=(10,10)) den = dendrogram(linkage(data, method='average')) #plt.axhline(y=30) In\u00a0[29]: Copied! <pre>## sua resposta aqui.....\n</pre> ## sua resposta aqui.....         In\u00a0[9]: Copied! <pre>cluster = AgglomerativeClustering(n_clusters=5, affinity=\"euclidean\", linkage=\"ward\")\ncluster.fit_predict(data)\n</pre> cluster = AgglomerativeClustering(n_clusters=5, affinity=\"euclidean\", linkage=\"ward\") cluster.fit_predict(data) <pre>\n---------------------------------------------------------------------------\nTypeError                                 Traceback (most recent call last)\nCell In[9], line 1\n----&gt; 1 cluster = AgglomerativeClustering(n_clusters=5, affinity=\"euclidean\", linkage=\"ward\")\n      2 cluster.fit_predict(data)\n\nTypeError: __init__() got an unexpected keyword argument 'affinity'</pre> In\u00a0[35]: Copied! <pre>cluster.labels_\n</pre> cluster.labels_ Out[35]: <pre>array([4, 3, 4, 3, 4, 3, 4, 3, 4, 3, 4, 3, 4, 3, 4, 3, 4, 3, 4, 3, 4, 3,\n       4, 3, 4, 3, 4, 3, 4, 3, 4, 3, 4, 3, 4, 3, 4, 3, 4, 3, 4, 3, 4, 1,\n       4, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 2, 1, 2, 0, 2, 0, 2,\n       1, 2, 0, 2, 0, 2, 0, 2, 0, 2, 1, 2, 0, 2, 1, 2, 0, 2, 0, 2, 0, 2,\n       0, 2, 0, 2, 0, 2, 1, 2, 0, 2, 0, 2, 0, 2, 0, 2, 0, 2, 0, 2, 0, 2,\n       0, 2, 0, 2, 0, 2, 0, 2, 0, 2, 0, 2, 0, 2, 0, 2, 0, 2, 0, 2, 0, 2,\n       0, 2])</pre> In\u00a0[10]: Copied! <pre>plt.figure(figsize=(10,7))\nplt.scatter(data[:,0],data[:,1], c=cluster.labels_, cmap=\"rainbow\")\n</pre> plt.figure(figsize=(10,7)) plt.scatter(data[:,0],data[:,1], c=cluster.labels_, cmap=\"rainbow\") <pre>\n---------------------------------------------------------------------------\nNameError                                 Traceback (most recent call last)\nCell In[10], line 2\n      1 plt.figure(figsize=(10,7))\n----&gt; 2 plt.scatter(data[:,0],data[:,1], c=cluster.labels_, cmap=\"rainbow\")\n\nNameError: name 'cluster' is not defined</pre> <pre>&lt;Figure size 1000x700 with 0 Axes&gt;</pre> In\u00a0[38]: Copied! <pre>## implemente sua resposta\n</pre> ## implemente sua resposta"},{"location":"aulas/IA/lab-02/aula6.html#2-aprendizagem-de-maquina","title":"2. Aprendizagem de m\u00e1quina\u00b6","text":""},{"location":"aulas/IA/lab-02/aula6.html#objetivos","title":"Objetivos\u00b6","text":"<ul> <li>continua\u00e7\u00e3o de aprendizado n\u00e3o supervisionado</li> <li>Apresentar uma intui\u00e7\u00e3o dos algoritimos de agupamento por densidade - DBScan</li> <li>Apresentar uma intui\u00e7\u00e3o e praticar o algoritimo de agrupamento hierarquico - AGNES</li> </ul>"},{"location":"aulas/IA/lab-02/aula6.html#metodos-de-agrupamento","title":"M\u00e9todos de agrupamento\u00b6","text":""},{"location":"aulas/IA/lab-02/aula6.html#de-forma-geral-as-estrategias-de-agrupamento-sao","title":"De forma geral as estrat\u00e9gias de agrupamento s\u00e3o:\u00b6","text":"<ul> <li>Parti\u00e7\u00e3o: exemplo KMeans</li> <li>Densidade: exemplo DBSCAN</li> <li>Hierarquicas: exemplo AGNES</li> </ul> <p>Utilizamos a ferramenta <code>orange-canvas</code> para obter uma intui\u00e7\u00e3o sobre esses algoritimos al\u00e9m de compreender suas principais diferen\u00e7a.</p>"},{"location":"aulas/IA/lab-02/aula6.html#desafio-1-sugestao","title":"Desafio 1 (Sugest\u00e3o)\u00b6","text":"<p>Fa\u00e7a a instala\u00e7\u00e3o do <code>orange-canvas</code> em sua maquina e realize os exemplos dados em sala de aula.</p> <p>Para usuarios linux o site oficial https://orangedatamining.com/ recomenda o uso de virutal env, eu uso direto sem virtual env:</p> <p>Instala\u00e7\u00e3o:</p> <pre><code>sudo apt install python3-pyqt5.*\npip install --upgrade --user pyqtwebengine==5.12\npip install --upgrade --user pyqt5==5.12\npip3 install orange3 --user\npip install orange3-educational</code></pre> <p>Execute:</p> <pre><code>python3 -m Orange.canvas\nou\norange-canvas</code></pre>"},{"location":"aulas/IA/lab-02/aula6.html#agrupamento-por-estrategia-hierarquica","title":"Agrupamento por estrat\u00e9gia Hierarquica\u00b6","text":""},{"location":"aulas/IA/lab-02/aula6.html#introducao-ao-problema-segmentacao-de-clientes","title":"Introdu\u00e7\u00e3o ao Problema: Segmenta\u00e7\u00e3o de Clientes\u00b6","text":"<p>Voc\u00ea \u00e9 um analista de dados contratado por um grande shopping center. O shopping quer melhorar suas campanhas de marketing e otimizar o atendimento aos clientes. Atualmente, eles possuem uma vasta quantidade de dados sobre seus clientes, mas enfrentam um desafio: Como identificar grupos de clientes que compartilham caracter\u00edsticas semelhantes para criar estrat\u00e9gias de marketing mais eficazes?</p>"},{"location":"aulas/IA/lab-02/aula6.html#descricao-do-problema","title":"Descri\u00e7\u00e3o do Problema\u00b6","text":"<p>Voc\u00ea recebeu um dataset contendo informa\u00e7\u00f5es sobre os clientes do shopping. Este dataset inclui vari\u00e1veis como a idade dos clientes, sua renda anual, e uma pontua\u00e7\u00e3o de gastos, que representa o quanto esses clientes tendem a gastar. Com base nesses dados, sua tarefa \u00e9 identificar grupos distintos de clientes que possam ser tratados de forma diferente pelo shopping.</p> <p>Por exemplo, pode haver um grupo de clientes jovens com alta renda que gasta muito, ou outro grupo de clientes mais velhos com uma renda menor, mas que s\u00e3o clientes fi\u00e9is e regulares. Entender essas segmenta\u00e7\u00f5es pode ajudar o shopping a personalizar ofertas, melhorar a satisfa\u00e7\u00e3o do cliente e, consequentemente, aumentar as vendas.</p>"},{"location":"aulas/IA/lab-02/aula6.html#reflexao-inicial","title":"Reflex\u00e3o Inicial\u00b6","text":"<p>Antes de mergulharmos nas t\u00e9cnicas de clustering, pense nas seguintes quest\u00f5es:</p> <ul> <li><p>Quais caracter\u00edsticas dos clientes s\u00e3o mais importantes para identificar padr\u00f5es de comportamento?</p> </li> <li><p>Como voc\u00ea definiria um \"grupo\" de clientes em termos de caracter\u00edsticas como idade, renda e pontua\u00e7\u00e3o de gastos?</p> </li> <li><p>O que voc\u00ea esperaria encontrar ap\u00f3s agrupar os clientes? Quais tipos de grupos ou segmentos voc\u00ea acha que poderiam surgir?</p> </li> <li><p>Como voc\u00ea pode preparar os dados para que sejam adequados para an\u00e1lise de clustering?</p> </li> <li><p>Qual t\u00e9cnica de clustering voc\u00ea escolheria para este problema e por qu\u00ea?</p> </li> <li><p>Como voc\u00ea pode avaliar se os grupos identificados realmente fazem sentido?</p> </li> </ul>"},{"location":"aulas/IA/lab-02/aula6.html#importa-libs","title":"Importa libs\u00b6","text":""},{"location":"aulas/IA/lab-02/aula6.html#importa-dataset","title":"Importa dataset\u00b6","text":""},{"location":"aulas/IA/lab-02/aula6.html#criando-um-subset","title":"Criando um subset\u00b6","text":""},{"location":"aulas/IA/lab-02/aula6.html#visualizacao-no-espaco-2d","title":"Visualiza\u00e7\u00e3o no espa\u00e7o 2D\u00b6","text":""},{"location":"aulas/IA/lab-02/aula6.html#desafio-2","title":"Desafio 2\u00b6","text":"<p>Realize uma an\u00e1lise visual e determine uma quantidade de cluster.</p> <pre><code>[ ] - 2 clusters\n[ ] - 3 clusters\n[ ] - 4 clusters\n[ ] - 5 clusters\n[ ] - 6 clusters\n[ ] - 7 clusters\n[ ] - 8 clusters    </code></pre>"},{"location":"aulas/IA/lab-02/aula6.html#dendrograma","title":"Dendrograma\u00b6","text":"<p>O dendrograma \u00e9 uma forma grafica de visualizar o agrupamentos de objetos.</p> <p>O agrupamento (<code>linkage</code>) \u00e9 feito de forma iterativa: No inicio, cada objeto \u00e9 um cluster e no fim, todos os objetos fazem parte do mesmo cluster.</p>"},{"location":"aulas/IA/lab-02/aula6.html#desafio-2","title":"Desafio 2\u00b6","text":"<p>Visualmente, com base no dendrograma acima, qual seria o melhor corte para realizar a clusteriza\u00e7\u00e3o hierarquica?</p> <pre><code>[ ] - 2 clusters\n[ ] - 3 clusters\n[ ] - 4 clusters\n[ ] - 5 clusters\n[ ] - 6 clusters\n[ ] - 7 clusters\n[ ] - 8 clusters </code></pre>"},{"location":"aulas/IA/lab-02/aula6.html#desafio-3","title":"Desafio 3\u00b6","text":"<p>O agrupameno dos dados foi realizado a partir do calculo da m\u00e9dia (average). Realize um estudo para comparar com outros linkage methtods.</p> <pre><code>single\ncomplete\naverage\nweighted\ncentroid\nmedian\nward</code></pre> <p>Compare os resultados de pelo menos 3 m\u00e9todos: single, average e ward</p> <p>Refer\u00eancia: Leia a documenta\u00e7\u00e3o oficial https://docs.scipy.org/doc/scipy/reference/generated/scipy.cluster.hierarchy.linkage.html#scipy.cluster.hierarchy.linkage</p>"},{"location":"aulas/IA/lab-02/aula6.html#agnes","title":"AGNES\u00b6","text":"<p>AGNES (AgglomerativeClustering) \u00e9 uma estrat\u00e9gia de agrupamento de dados do tipo botton-top.</p> <p>Como parametros deve ser passado o numero de cluster que foi encontrado no dendrograma e os metodos utilizados affinity e linkage.</p>"},{"location":"aulas/IA/lab-02/aula6.html#desafio-4","title":"Desafio 4\u00b6","text":"<p>Utilizando este dataset compare com os resultados para KMeans e DBSCAN</p>"},{"location":"aulas/IA/lab-03/aula7.html","title":"lab3","text":"In\u00a0[1]: Copied! <pre>%matplotlib inline\n\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom sklearn.cluster import KMeans\nfrom sklearn.preprocessing import StandardScaler\n</pre> %matplotlib inline  import pandas as pd import matplotlib.pyplot as plt from sklearn.cluster import KMeans from sklearn.preprocessing import StandardScaler In\u00a0[7]: Copied! <pre>url_db = 'default of credit card clients.csv'\ndf = pd.read_csv(url_db, sep=';', header=1)  # Definindo o delimitador como ponto e v\u00edrgula\ndf.head()\n</pre> url_db = 'default of credit card clients.csv' df = pd.read_csv(url_db, sep=';', header=1)  # Definindo o delimitador como ponto e v\u00edrgula df.head()  Out[7]: ID LIMIT_BAL SEX EDUCATION MARRIAGE AGE PAY_0 PAY_2 PAY_3 PAY_4 ... BILL_AMT4 BILL_AMT5 BILL_AMT6 PAY_AMT1 PAY_AMT2 PAY_AMT3 PAY_AMT4 PAY_AMT5 PAY_AMT6 default payment next month 0 1 20000 2 2 1 24 2 2 -1 -1 ... 0 0 0 0 689 0 0 0 0 1 1 2 120000 2 2 2 26 -1 2 0 0 ... 3272 3455 3261 0 1000 1000 1000 0 2000 1 2 3 90000 2 2 2 34 0 0 0 0 ... 14331 14948 15549 1518 1500 1000 1000 1000 5000 0 3 4 50000 2 2 1 37 0 0 0 0 ... 28314 28959 29547 2000 2019 1200 1100 1069 1000 0 4 5 50000 1 2 1 57 -1 0 -1 0 ... 20940 19146 19131 2000 36681 10000 9000 689 679 0 <p>5 rows \u00d7 25 columns</p> In\u00a0[18]: Copied! <pre>## Analise se o dataset possui dados faltantes, se sim, fa\u00e7a o drop dessas entradas\n\n## Seu c\u00f3digo aqui.....\n</pre> ## Analise se o dataset possui dados faltantes, se sim, fa\u00e7a o drop dessas entradas  ## Seu c\u00f3digo aqui.....   <p>Descri\u00e7\u00e3o das colunas Principais:</p> <ul> <li><code>ID</code>: Identifica\u00e7\u00e3o \u00fanica de cada cliente.</li> <li><code>LIMIT_BAL</code>: Limite de cr\u00e9dito concedido ao cliente (em d\u00f3lares).</li> <li><code>SEX</code>: G\u00eanero do cliente (1 = Masculino, 2 = Feminino).</li> <li><code>EDUCATION</code>: N\u00edvel educacional do cliente (1 = P\u00f3s-gradua\u00e7\u00e3o, 2 = Gradua\u00e7\u00e3o, 3 = Ensino M\u00e9dio, 4 = Outros).</li> <li><code>MARRIAGE</code>: Estado civil do cliente (1 = Casado, 2 = Solteiro, 3 = Outros).</li> <li><code>AGE</code>: Idade do cliente.</li> <li><code>PAY_0 a PAY_6</code>: Status de pagamento dos \u00faltimos 6 meses (0 = Pago na data, -1 = Pagamento adiantado, 1 = Atraso de 1 m\u00eas, etc.).</li> <li><code>BILL_AMT1 a BILL_AMT6</code>: Valor da fatura (em d\u00f3lares) nos \u00faltimos 6 meses.</li> <li><code>PAY_AMT1 a PAY_AMT6</code>: Pagamento realizado (em d\u00f3lares) nos \u00faltimos 6 meses.</li> <li><code>Y (default payment next month)</code>: Indicador de inadimpl\u00eancia no pr\u00f3ximo m\u00eas (1 = Inadimplente, 0 = N\u00e3o inadimplente).</li> </ul> <p>ref: https://archive.ics.uci.edu/dataset/350/default+of+credit+card+clients</p> In\u00a0[\u00a0]: Copied! <pre>## Crie uma nova coluna que soma todas as colunas de d\u00edvidas \n\n## Seu c\u00f3digo aqui.....\n</pre> ## Crie uma nova coluna que soma todas as colunas de d\u00edvidas   ## Seu c\u00f3digo aqui.....      In\u00a0[\u00a0]: Copied! <pre>## Selecione as colunas de limite de cr\u00e9dito e divida total \n\n#data = df.iloc[:,[,]].values\n#data;\n</pre> ## Selecione as colunas de limite de cr\u00e9dito e divida total   #data = df.iloc[:,[,]].values #data; In\u00a0[21]: Copied! <pre>## Como estamos trabalhos com algoritmos de dist\u00e2ncia, \u00e9 importante e recomendavel que os dados sejam normalizados\n## seu c\u00f3digo de normaliza\u00e7\u00e3o...\n</pre> ## Como estamos trabalhos com algoritmos de dist\u00e2ncia, \u00e9 importante e recomendavel que os dados sejam normalizados ## seu c\u00f3digo de normaliza\u00e7\u00e3o...   In\u00a0[19]: Copied! <pre>## Seu c\u00f3digo aqui......\n</pre> ## Seu c\u00f3digo aqui......     In\u00a0[20]: Copied! <pre>## Sua resposta aqui.....\n</pre> ## Sua resposta aqui.....     In\u00a0[23]: Copied! <pre>## Fa\u00e7a uma breve descri\u00e7\u00e3o de cada cluster obtido, o que eles indicam?\n</pre> ## Fa\u00e7a uma breve descri\u00e7\u00e3o de cada cluster obtido, o que eles indicam?"},{"location":"aulas/IA/lab-03/aula7.html#2-aprendizagem-de-maquina","title":"2. Aprendizagem de m\u00e1quina\u00b6","text":""},{"location":"aulas/IA/lab-03/aula7.html#objetivos","title":"Objetivos\u00b6","text":"<ul> <li>Praticar os algoritmos de clusteriza\u00e7\u00e3o</li> </ul>"},{"location":"aulas/IA/lab-03/aula7.html#analise-de-credito-do-cartao-de-credito","title":"An\u00e1lise de cr\u00e9dito do cart\u00e3o de credito\u00b6","text":"<p>Realizar uma an\u00e1lise explorat\u00f3ria na base de dados de clientes afim de categorizar a quantidade de perfis</p>"},{"location":"aulas/IA/lab-03/aula7.html#importa-libs","title":"Importa libs\u00b6","text":""},{"location":"aulas/IA/lab-03/aula7.html#importa-dataset","title":"Importa dataset\u00b6","text":"<p>link para download: https://drive.google.com/file/d/1jhWFqkYWtyhJhvpMtu5xX0EHsQjUOlw0/view?usp=sharing</p>"},{"location":"aulas/IA/lab-03/aula7.html#criando-um-subset","title":"Criando um subset\u00b6","text":""},{"location":"aulas/IA/lab-03/aula7.html#quantidade-de-k-cluster","title":"Quantidade de k cluster\u00b6","text":"<p>Escolha uma t\u00e9cnica dada em aula para inicializar o Kmeans. Poder ser a t\u00e9cnica <code>Elbow</code> ou <code>dendrograma</code>.</p> <p>wcss = within-cluster sum of squares = soma dos quadrados intra-clusters</p> <pre>wcss = []\nK = range(1,12)\n\nfor k in K:\n  km = KMeans(n_clusters=k)\n  km = km.fit(data_treino)\n  wcss.append(km.inertia_)\n  \n\nplt.plot(K, wcss, \"bx-\", color = \"grey\")\nplt.xlabel(\"k\")\nplt.ylabel(\"WCSS\")\nplt.title(\"M\u00e9todo do Cotovelo para k Otimizado\");\n</pre>"},{"location":"aulas/IA/lab-03/aula7.html#agrupando-dados","title":"Agrupando dados\u00b6","text":"<p>Realize o agrupamento utilizando <code>Kmeans e Agnes</code> e compare os resultados obtidos.</p>"},{"location":"aulas/IA/lab01/dataframe%20copy.html","title":"Dataframe copy","text":"<p>Para instalar</p> <ul> <li>pandas: <code>pip install pandas</code></li> </ul> <p>LEIA A DOCUMENTA\u00c7\u00c3O: https://pandas.pydata.org/docs/index.html</p> In\u00a0[\u00a0]: Copied! <pre>import pandas as pd\n</pre> import pandas as pd In\u00a0[\u00a0]: Copied! <pre># Caminho do arquivo\nurl = \"https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data\"\n\n# L\u00ea e carrega o arquivo para a mem\u00f3ria\ndf = pd.read_csv(url)\n</pre> # Caminho do arquivo url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data\"  # L\u00ea e carrega o arquivo para a mem\u00f3ria df = pd.read_csv(url) In\u00a0[\u00a0]: Copied! <pre>df.head()\n</pre> df.head() Out[\u00a0]: 5.1 3.5 1.4 0.2 Iris-setosa 0 4.9 3.0 1.4 0.2 Iris-setosa 1 4.7 3.2 1.3 0.2 Iris-setosa 2 4.6 3.1 1.5 0.2 Iris-setosa 3 5.0 3.6 1.4 0.2 Iris-setosa 4 5.4 3.9 1.7 0.4 Iris-setosa <p>Note que a primeira linha n\u00e3o contem os nomes das colunas ou <code>atributos</code>(variaveis) e sim, dados (valores).</p> <p>Dependendo da base dados utilizada e como voc\u00ea carrega no pandas, os dados da primeira linha s\u00e3o importados como atributos.</p> <p>Vamos adicionar um cabe\u00e7ario ao nosso dataframe. Mas o que podemos adicionar???</p> <p>Vamos dar uma olhada no reposit\u00f3rio oficial onde dadas informa\u00e7\u00f5es sobre o dataset e \u00e9 dito que as variaveis s\u00e3o:</p> <pre><code>Attribute Information:\n\n1. sepal length in cm\n2. sepal width in cm\n3. petal length in cm\n4. petal width in cm\n5. class:\n-- Iris Setosa\n-- Iris Versicolour\n-- Iris Virginica\n</code></pre> In\u00a0[\u00a0]: Copied! <pre># Define o nome das colunas\nheader = ['sepal_length', 'sepal_width', 'petal_length', 'petal_width', 'species']\n# L\u00ea e carrega o arquivo para a mem\u00f3ria\ndf = pd.read_csv(url, header=None, names=header)\n</pre> # Define o nome das colunas header = ['sepal_length', 'sepal_width', 'petal_length', 'petal_width', 'species'] # L\u00ea e carrega o arquivo para a mem\u00f3ria df = pd.read_csv(url, header=None, names=header) In\u00a0[\u00a0]: Copied! <pre># Retorna um trecho com as 5 primeiras linhas do dataframe\ndf.head()\n</pre> # Retorna um trecho com as 5 primeiras linhas do dataframe df.head() Out[\u00a0]: sepal_length sepal_width petal_length petal_width species 0 5.1 3.5 1.4 0.2 Iris-setosa 1 4.9 3.0 1.4 0.2 Iris-setosa 2 4.7 3.2 1.3 0.2 Iris-setosa 3 4.6 3.1 1.5 0.2 Iris-setosa 4 5.0 3.6 1.4 0.2 Iris-setosa In\u00a0[\u00a0]: Copied! <pre># Mostra informa\u00e7\u00f5es sobre o dataframe em si\ndf.info()\n</pre> # Mostra informa\u00e7\u00f5es sobre o dataframe em si df.info() <pre>&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 150 entries, 0 to 149\nData columns (total 5 columns):\n #   Column        Non-Null Count  Dtype  \n---  ------        --------------  -----  \n 0   sepal_length  150 non-null    float64\n 1   sepal_width   150 non-null    float64\n 2   petal_length  150 non-null    float64\n 3   petal_width   150 non-null    float64\n 4   species       150 non-null    object \ndtypes: float64(4), object(1)\nmemory usage: 6.0+ KB\n</pre> In\u00a0[\u00a0]: Copied! <pre># exibe o shape (dimenso\u1ebds) do dataframe\ndf.shape\n</pre> # exibe o shape (dimenso\u1ebds) do dataframe df.shape Out[\u00a0]: <pre>(150, 5)</pre> In\u00a0[\u00a0]: Copied! <pre>## Suas respostas....\n</pre> ## Suas respostas....       <p>S\u00e3o 150 exemplares de flor de \u00edris, pertencentes a tr\u00eas esp\u00e9cies diferentes: setosa, versicolor e virginica, sendo 50 amostras de cada esp\u00e9cie.</p> <p>Os atributos de <code>largura e comprimento de s\u00e9pala</code> e <code>largura e comprimento de p\u00e9tala</code> de cada flor fooram medidos manualmente.</p> In\u00a0[\u00a0]: Copied! <pre>df.describe()\n</pre> df.describe() Out[\u00a0]: sepal_length sepal_width petal_length petal_width count 150.000000 150.000000 150.000000 150.000000 mean 5.843333 3.054000 3.758667 1.198667 std 0.828066 0.433594 1.764420 0.763161 min 4.300000 2.000000 1.000000 0.100000 25% 5.100000 2.800000 1.600000 0.300000 50% 5.800000 3.000000 4.350000 1.300000 75% 6.400000 3.300000 5.100000 1.800000 max 7.900000 4.400000 6.900000 2.500000 <p>Note que o m\u00e9todo describe() n\u00e3o exibe a coluna species, pois se trata de uma coluna n\u00e3o-num\u00e9rica.</p> <p>Apenas as colunas num\u00e9ricas est\u00e3o presentes, o atributo species indica r\u00f3tulos - trata-se de dados categ\u00f3ricos.</p> In\u00a0[\u00a0]: Copied! <pre># retorna a quantiade de classes da coluna\n\ndf.species.unique()\n</pre> # retorna a quantiade de classes da coluna  df.species.unique() Out[\u00a0]: <pre>array(['Iris-setosa', 'Iris-versicolor', 'Iris-virginica'], dtype=object)</pre> In\u00a0[\u00a0]: Copied! <pre># agrupamento por m\u00e9dia\n\ndf.groupby('species').mean()\n</pre> # agrupamento por m\u00e9dia  df.groupby('species').mean() Out[\u00a0]: sepal_length sepal_width petal_length petal_width species Iris-setosa 5.006 3.418 1.464 0.244 Iris-versicolor 5.936 2.770 4.260 1.326 Iris-virginica 6.588 2.974 5.552 2.026 In\u00a0[\u00a0]: Copied! <pre>#  Quantidade de cada categoria\ndf.groupby('species').size()\n</pre> #  Quantidade de cada categoria df.groupby('species').size() Out[\u00a0]: <pre>species\nIris-setosa        50\nIris-versicolor    50\nIris-virginica     50\ndtype: int64</pre> In\u00a0[\u00a0]: Copied! <pre>import numpy as np\n\n# c\u00f3pia de df\ndf_iris = df\n\n# Gera dados faltante no dataset\nfor col in df_iris.columns[:-1]:\n    df_iris.loc[np.random.choice(df_iris.index, 5), col] = np.nan\n</pre> import numpy as np  # c\u00f3pia de df df_iris = df  # Gera dados faltante no dataset for col in df_iris.columns[:-1]:     df_iris.loc[np.random.choice(df_iris.index, 5), col] = np.nan  In\u00a0[\u00a0]: Copied! <pre>df_iris.info()\n</pre> df_iris.info() <pre>&lt;class 'pandas.core.frame.DataFrame'&gt;\nInt64Index: 131 entries, 0 to 149\nData columns (total 5 columns):\n #   Column        Non-Null Count  Dtype  \n---  ------        --------------  -----  \n 0   sepal_length  121 non-null    float64\n 1   sepal_width   121 non-null    float64\n 2   petal_length  122 non-null    float64\n 3   petal_width   121 non-null    float64\n 4   species       131 non-null    object \ndtypes: float64(4), object(1)\nmemory usage: 10.2+ KB\n</pre> In\u00a0[\u00a0]: Copied! <pre># Verifica os valores ausentes\n\ndf_iris.isnull().sum()\n</pre> # Verifica os valores ausentes  df_iris.isnull().sum()  Out[\u00a0]: <pre>sepal_length    10\nsepal_width     10\npetal_length     9\npetal_width     10\nspecies          0\ndtype: int64</pre> In\u00a0[\u00a0]: Copied! <pre>df_iris.dropna(axis=0, inplace=True)\n</pre> df_iris.dropna(axis=0, inplace=True) In\u00a0[\u00a0]: Copied! <pre># Tratamento de valores faltantes: imputa\u00e7\u00e3o m\u00e9dia\n\nfor col in df_iris.columns[:-1]:  # a coluna de especie n\u00e3o entra\n    mean_val = df_iris[col].mean()\n    df_iris[col].fillna(mean_val, inplace=True)\n</pre> # Tratamento de valores faltantes: imputa\u00e7\u00e3o m\u00e9dia  for col in df_iris.columns[:-1]:  # a coluna de especie n\u00e3o entra     mean_val = df_iris[col].mean()     df_iris[col].fillna(mean_val, inplace=True) In\u00a0[\u00a0]: Copied! <pre>df_iris.info()\n</pre> df_iris.info()  <pre>&lt;class 'pandas.core.frame.DataFrame'&gt;\nInt64Index: 131 entries, 0 to 149\nData columns (total 5 columns):\n #   Column        Non-Null Count  Dtype  \n---  ------        --------------  -----  \n 0   sepal_length  131 non-null    float64\n 1   sepal_width   131 non-null    float64\n 2   petal_length  131 non-null    float64\n 3   petal_width   131 non-null    float64\n 4   species       131 non-null    object \ndtypes: float64(4), object(1)\nmemory usage: 10.2+ KB\n</pre> In\u00a0[\u00a0]: Copied! <pre>import matplotlib.pyplot as plt\nimport seaborn as sns\n</pre> import matplotlib.pyplot as plt import seaborn as sns In\u00a0[\u00a0]: Copied! <pre># Gr\u00e1fico de linha para a m\u00e9dia do comprimento da s\u00e9pala de cada esp\u00e9cie\n\ngrouped = df_iris.groupby('species')['sepal_length'].mean()\ngrouped.plot(kind='line', marker='o')\n\n\nplt.title('M\u00e9dia do Comprimento da S\u00e9pala por Esp\u00e9cie')\nplt.ylabel('Comprimento da S\u00e9pala (cm)')\nplt.grid(True)\nplt.show()\n</pre> # Gr\u00e1fico de linha para a m\u00e9dia do comprimento da s\u00e9pala de cada esp\u00e9cie  grouped = df_iris.groupby('species')['sepal_length'].mean() grouped.plot(kind='line', marker='o')   plt.title('M\u00e9dia do Comprimento da S\u00e9pala por Esp\u00e9cie') plt.ylabel('Comprimento da S\u00e9pala (cm)') plt.grid(True) plt.show()  In\u00a0[\u00a0]: Copied! <pre># Gr\u00e1fico de Barras\n\nspecies_count = df['species'].value_counts()\nspecies_count.plot(kind='bar')\n\nplt.title('Contagem de Esp\u00e9cies')\nplt.xlabel('Esp\u00e9cie')\nplt.ylabel('Contagem')\nplt.show()\n</pre> # Gr\u00e1fico de Barras  species_count = df['species'].value_counts() species_count.plot(kind='bar')  plt.title('Contagem de Esp\u00e9cies') plt.xlabel('Esp\u00e9cie') plt.ylabel('Contagem') plt.show()  In\u00a0[\u00a0]: Copied! <pre># Lembra de histograma, que exibe uma gr\u00e1fico de frequ\u00eancia.\ndf.hist(bins=100, figsize=(15, 15))\nplt.show()\n</pre> # Lembra de histograma, que exibe uma gr\u00e1fico de frequ\u00eancia. df.hist(bins=100, figsize=(15, 15)) plt.show() In\u00a0[\u00a0]: Copied! <pre># Histograma apenas de um atributo\n\nplt.hist(df['sepal_length'], bins=100)\n\n\nplt.title('Histograma de Sepal Length')\nplt.xlabel('Sepal Length')\nplt.ylabel('Contagem')\nplt.show()\n</pre> # Histograma apenas de um atributo  plt.hist(df['sepal_length'], bins=100)   plt.title('Histograma de Sepal Length') plt.xlabel('Sepal Length') plt.ylabel('Contagem') plt.show()  In\u00a0[\u00a0]: Copied! <pre># box plot\ndf.plot(kind='box', subplots=True, layout=(2,2), sharex=False, sharey=False, figsize=(15, 15))\nplt.show()\n</pre> # box plot df.plot(kind='box', subplots=True, layout=(2,2), sharex=False, sharey=False, figsize=(15, 15)) plt.show() In\u00a0[\u00a0]: Copied! <pre># Grafico de dispers\u00e3o\n\nplt.scatter(df_iris['sepal_length'], df_iris['petal_length'])\n\nplt.title('Sepal Length vs Petal Length')\nplt.xlabel('Sepal Length (cm)')\nplt.ylabel('Petal Length (cm)')\nplt.show()\n</pre> # Grafico de dispers\u00e3o  plt.scatter(df_iris['sepal_length'], df_iris['petal_length'])  plt.title('Sepal Length vs Petal Length') plt.xlabel('Sepal Length (cm)') plt.ylabel('Petal Length (cm)') plt.show() In\u00a0[\u00a0]: Copied! <pre># Os mesmos dados mas agora cada classe de uma cor diferente\n\ncolors = {'Iris-setosa':'red', 'Iris-versicolor':'blue', 'Iris-virginica':'green'}\n\nplt.scatter(df['sepal_length'], df['petal_length'], c=df['species'].map(colors), label=colors)\n\nplt.title('Sepal Length vs Petal Length')\nplt.xlabel('Sepal Length (cm)')\nplt.ylabel('Petal Length (cm)')\nplt.legend(handles=[plt.Line2D([0], [0], marker='o', color='w', markerfacecolor=color, markersize=10) for color in colors.values()], labels=colors.keys())\nplt.show()\n</pre> # Os mesmos dados mas agora cada classe de uma cor diferente  colors = {'Iris-setosa':'red', 'Iris-versicolor':'blue', 'Iris-virginica':'green'}  plt.scatter(df['sepal_length'], df['petal_length'], c=df['species'].map(colors), label=colors)  plt.title('Sepal Length vs Petal Length') plt.xlabel('Sepal Length (cm)') plt.ylabel('Petal Length (cm)') plt.legend(handles=[plt.Line2D([0], [0], marker='o', color='w', markerfacecolor=color, markersize=10) for color in colors.values()], labels=colors.keys()) plt.show() In\u00a0[\u00a0]: Copied! <pre># scatter plot matrix\n# tudo junto e misturado\n\nfrom pandas.plotting import scatter_matrix\n\nscatter_matrix(df,figsize=(15, 15))\n\nplt.show()\n</pre> # scatter plot matrix # tudo junto e misturado  from pandas.plotting import scatter_matrix  scatter_matrix(df,figsize=(15, 15))  plt.show() <p>Vamos utilizar o <code>seaborn</code> para visualizar gr\u00e1ficos mais bonitos</p> In\u00a0[\u00a0]: Copied! <pre>import seaborn as sns\n\n# A cor vem do campo `species` do dataframe\n\nsns.pairplot(df, hue='species', height=5)\n\nplt.show()\n</pre> import seaborn as sns  # A cor vem do campo `species` do dataframe  sns.pairplot(df, hue='species', height=5)  plt.show() <p>O Violin plot \u00e9 similar ao box plot, exibe a distribui\u00e7\u00e3o de variaveis num\u00e9ricas em niveis, pode ser configurada de muitas formas e \u00e9 uma forma de visualiza\u00e7\u00e3o interessante de dados.</p> <p>Saiba mais em: https://seaborn.pydata.org/generated/seaborn.violinplot.html</p> In\u00a0[\u00a0]: Copied! <pre># Violin plot\ng = sns.violinplot(y='species', x='sepal_length', data=df, inner='quartile')\nplt.show()\ng = sns.violinplot(y='species', x='sepal_width', data=df, inner='quartile')\nplt.show()\ng = sns.violinplot(y='species', x='petal_length', data=df, inner='quartile')\nplt.show()\ng = sns.violinplot(y='species', x='petal_width', data=df, inner='quartile')\nplt.show()\n</pre> # Violin plot g = sns.violinplot(y='species', x='sepal_length', data=df, inner='quartile') plt.show() g = sns.violinplot(y='species', x='sepal_width', data=df, inner='quartile') plt.show() g = sns.violinplot(y='species', x='petal_length', data=df, inner='quartile') plt.show() g = sns.violinplot(y='species', x='petal_width', data=df, inner='quartile') plt.show() In\u00a0[\u00a0]: Copied! <pre>cols = ['sepal_length', 'sepal_width', 'petal_length','petal_width']\ncorr_matx = df[cols].corr()\n\nheatmap = sns.heatmap(corr_matx,cbar=True,annot=True,square=True,fmt='.2f',annot_kws={'size': 15},yticklabels=cols,xticklabels=cols,cmap='Dark2')\n</pre> cols = ['sepal_length', 'sepal_width', 'petal_length','petal_width'] corr_matx = df[cols].corr()  heatmap = sns.heatmap(corr_matx,cbar=True,annot=True,square=True,fmt='.2f',annot_kws={'size': 15},yticklabels=cols,xticklabels=cols,cmap='Dark2') In\u00a0[\u00a0]: Copied! <pre>### Implemente sua solu\u00e7\u00e3o e apresente sua an\u00e1lise....\n</pre> ### Implemente sua solu\u00e7\u00e3o e apresente sua an\u00e1lise....     In\u00a0[\u00a0]: Copied! <pre>df['petal_length'].head()\n</pre> df['petal_length'].head() Out[\u00a0]: <pre>0    1.4\n1    1.4\n2    1.3\n3    1.5\n4    1.4\nName: petal_length, dtype: float64</pre> <p>Por outro lado, se dentro dos colchetes passamos uma lista de nomes de coluna, o reultado \u00e9 outro <code>DataFrame</code> contendo aquelas colunas. Isso vale inclusive para uma coluna simples:</p> In\u00a0[\u00a0]: Copied! <pre># Mostra apenas a coluna petal_len\ndf[['petal_length']].head()\n</pre> # Mostra apenas a coluna petal_len df[['petal_length']].head() Out[\u00a0]: petal_length 0 1.4 1 1.4 2 1.3 3 1.5 4 1.4 In\u00a0[\u00a0]: Copied! <pre># Mostra as colunas petal_length e petal_width\ndf[['petal_length', 'petal_width']].head()\n</pre> # Mostra as colunas petal_length e petal_width df[['petal_length', 'petal_width']].head() Out[\u00a0]: petal_length petal_width 0 1.4 0.2 1 1.4 0.2 2 1.3 0.2 3 1.5 0.2 4 1.4 0.2 In\u00a0[\u00a0]: Copied! <pre># Criando uma nova caracter\u00edstica: \u00e1rea da s\u00e9pala\n\ndf['sepal_area'] = df['sepal_length'] * df['sepal_width']\n\ndf.head()\n</pre> # Criando uma nova caracter\u00edstica: \u00e1rea da s\u00e9pala  df['sepal_area'] = df['sepal_length'] * df['sepal_width']  df.head()  Out[\u00a0]: sepal_length sepal_width petal_length petal_width species sepal_area 0 5.1 3.5 1.4 0.2 Iris-setosa 17.85 1 4.9 3.0 1.4 0.2 Iris-setosa 14.70 2 4.7 3.2 1.3 0.2 Iris-setosa 15.04 3 4.6 3.1 1.5 0.2 Iris-setosa 14.26 4 5.0 3.6 1.4 0.2 Iris-setosa 18.00 In\u00a0[\u00a0]: Copied! <pre>## suas respostas aqui.....\n</pre> ## suas respostas aqui.....      In\u00a0[\u00a0]: Copied! <pre>### Implemente sua sua solu\u00e7\u00e3o e an\u00e1lise de dados. :)\n</pre> ### Implemente sua sua solu\u00e7\u00e3o e an\u00e1lise de dados. :)"},{"location":"aulas/IA/lab01/dataframe%20copy.html#objetivos","title":"Objetivos\u00b6","text":"<ul> <li>Apresentar e utilizar o pacote pandas</li> <li>Como carregar uma base dados</li> <li>Como visualizar os dados</li> <li>Intui\u00e7\u00e3o de an\u00e1lise explorat\u00f3ria de dados</li> </ul>"},{"location":"aulas/IA/lab01/dataframe%20copy.html#introducao-a-analise-de-dados-usando-pandas","title":"Introdu\u00e7\u00e3o a an\u00e1lise de dados usando Pandas\u00b6","text":"<p>Vamos come\u00e7ar pelo come\u00e7o! Vamos escolher um dataset (conjunto de dados) para analisar.</p> <p>Vamos utilizar um pacote do python capaz de trabalhar com tabelas de dados chamada pandas, para essas tabelas chamamos de dataframe.</p> <p>Veja mais em: https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.html</p>"},{"location":"aulas/IA/lab01/dataframe%20copy.html#hello-world-do-mundo-dos-dados","title":"Hello World! do mundo dos dados\u00b6","text":""},{"location":"aulas/IA/lab01/dataframe%20copy.html#conjunto-de-dados-dataset","title":"Conjunto de dados <code>Dataset</code>\u00b6","text":"<p>Para trabalhar com an\u00e1lise de dados precisamos de.... <code>DADOS</code>.</p> <p>Podemos escolher qualquer base de dados disponivel na internet, ou at\u00e9 mesmo criar nosso proprio dataset.</p> <p>Vamos simplificar essa etapa e come\u00e7ar analisando uma base pequena e muito famosa chamada iris que esta disponivel em:</p> <p>ref: https://archive.ics.uci.edu/ml/datasets/Iris</p> <p>Conhe\u00e7a outros datasets: https://archive.ics.uci.edu/ml/datasets.php</p>"},{"location":"aulas/IA/lab01/dataframe%20copy.html#conhecendo-os-dados","title":"Conhecendo os dados\u00b6","text":"<p>Essa etapa \u00e9 muito importante, CONHECER OS DADOS!</p> <p>Quanto mais voc\u00ea conhece a base de DADOS maior a possibilidade de extrair INFORMA\u00c7\u00d5ES \u00fateis para tomada de decis\u00e3o.</p>"},{"location":"aulas/IA/lab01/dataframe%20copy.html#analisando-o-dataset","title":"an\u00e1lisando o dataset\u00b6","text":"<p>Agora que j\u00e1 carregamos o dataset corretamente, vamos come\u00e7ar a analisa-lo. o m\u00e9todo <code>info()</code> \u00e9 um bom ponto de partida para isso.</p>"},{"location":"aulas/IA/lab01/dataframe%20copy.html#desafio-1","title":"Desafio 1\u00b6","text":"<p>Analisando as informa\u00e7\u00f5es do dataset iris, responda:</p> <ol> <li><p>Quantos dados existem nesse dataset?</p> </li> <li><p>Qual a quantidade de atributos?</p> </li> <li><p>Existe valores faltantes?</p> </li> <li><p>De que tipo s\u00e3o os dados (dtype)?</p> </li> </ol>"},{"location":"aulas/IA/lab01/dataframe%20copy.html#analisando-os-dados-mais-a-fundo","title":"An\u00e1lisando os dados mais a fundo\u00b6","text":""},{"location":"aulas/IA/lab01/dataframe%20copy.html#resumo-estatistico","title":"Resumo estat\u00edstico\u00b6","text":"<p>O m\u00e9todo <code>describe()</code> gera um resumo estat\u00edstico dos dados contidos em um DataFrame ou Series.</p> <p>Retorna estat\u00edsticas descritivas como <code>m\u00e9dia, desvio padr\u00e3o, valor m\u00ednimo, quartis e valor m\u00e1ximo</code> para as colunas num\u00e9ricas do DataFrame</p>"},{"location":"aulas/IA/lab01/dataframe%20copy.html#agrupando-dados","title":"Agrupando dados\u00b6","text":"<p>O m\u00e9todo <code>groupby</code> \u00e9 usada para agrupar dados com base em valores espec\u00edficos de uma ou mais colunas.</p> <p>Permite realizar opera\u00e7\u00f5es em grupos de dados e \u00e9 muito \u00fatil e versatil para an\u00e1lise e agrega\u00e7\u00e3o de dado.</p>"},{"location":"aulas/IA/lab01/dataframe%20copy.html#limpeza-de-dados","title":"Limpeza de Dados\u00b6","text":"<p>Base de dados do mundo real podem conter diversos problemas, \u00e9 muito comum o lidar com valores faltantes em um dataset.</p> <p>Como exemplo, vamos usar o conjunto de dados Iris, mas introduzimos algumas 'imperfei\u00e7\u00f5es' para fins de demonstra\u00e7\u00e3o.</p> <p>Para introduzir valores faltantes, podemos usar o seguinte c\u00f3digo:</p> <pre>## Gera dados faltante no dataset\nfor col in df_iris.columns[:-1]:\n    df_iris.loc[np.random.choice(df_iris.index, 5), col] = np.nan\n</pre>"},{"location":"aulas/IA/lab01/dataframe%20copy.html#excluindo-linhas","title":"Excluindo linhas\u00b6","text":"<p>Podemos simplismente excluir as linhas ou colunas que contenham dados faltantes, basta usar a fun\u00e7\u00e3o dropna pandas, utilizando como par\u00e2metros o axis = 1 para dizer que queremos deletar a coluna ou axis = 0 para linha e inplace = True para aplicarmos no dataset e n\u00e3o criarmos uma c\u00f3pia deste:</p> <ul> <li><code>axis=0</code> --&gt; exclui linha</li> <li><code>axis=1</code> --&gt; exclui coluna</li> </ul> <p><code>Pense bemmmm!!!!</code> A decis\u00e3o por qual vai excluir depende do problema que voc\u00ea est\u00e1 atacando...</p>"},{"location":"aulas/IA/lab01/dataframe%20copy.html#preenchimento-com-valores","title":"Preenchimento com valores\u00b6","text":"<p>Voc\u00ea pode preencher os valores faltantes com m\u00e9dias, medianas, modas ou outros valores relevantes.</p> <p>Isso ajuda a manter o tamanho do conjunto de dados, mas pode introduzir vi\u00e9s nos resultados.</p> <p><code>Pense bemmmm!!!!</code> A decis\u00e3o por qual valor preencher depende do problema que voc\u00ea est\u00e1 atacando...</p>"},{"location":"aulas/IA/lab01/dataframe%20copy.html#analisando-informacoes-em-graficos","title":"Analisando informa\u00e7\u00f5es em gr\u00e1ficos\u00b6","text":"<p>Uma an\u00e1lise gr\u00e1fica pode ajudar a compreeder melhor os dados que estamos trabalhando....</p> <p>Vamos explorar diferentes tipos de visualiza\u00e7\u00f5es que podem nos ajudar a entender melhor nossos dados.</p> <p>Vamos usar o <code>matplotlib</code> e o  <code>seaborn</code> para nos ajudar.</p> <p>Se precisar instalar:</p> <ul> <li>pip install matplotlib seaborn</li> </ul>"},{"location":"aulas/IA/lab01/dataframe%20copy.html#correlacao-entre-atributos","title":"Correla\u00e7\u00e3o entre atributos\u00b6","text":"<p>A matriz de correla\u00e7\u00e3o  avalia a rela\u00e7\u00e3o entre duas ou mais variaveis (correla\u00e7\u00e3o).</p> <p>valores:</p> <ul> <li>0.9 a 1 positivo ou negativo indica uma correla\u00e7\u00e3o muito forte.</li> <li>0.7 a 0.9 positivo ou negativo indica uma correla\u00e7\u00e3o forte.</li> <li>0.5 a 0.7 positivo ou negativo indica uma correla\u00e7\u00e3o moderada.</li> <li>0.3 a 0.5 positivo ou negativo indica uma correla\u00e7\u00e3o fraca.</li> <li>0 a 0.3 positivo ou negativo indica uma correla\u00e7\u00e3o desprez\u00edvel.</li> </ul> <p>lembre-se que: alta correla\u00e7\u00e3o n\u00e3o implica em causa. (causa e consequ\u00eancia). Para entender melhor vale a pena dar uma olhada nesse site que mostra correla\u00e7\u00f5es absurdas...'spurious correlations'</p>"},{"location":"aulas/IA/lab01/dataframe%20copy.html#desafio-2","title":"Desafio 2\u00b6","text":"<p>Analise os gr\u00e1ficos gerados at\u00e9 o momento para responder as quest\u00f5es abaixo:</p> <ol> <li><p>A especie que possui na m\u00e9dia a menor sepala \u00e9 a mesma que possui a menor petala?</p> </li> <li><p>Existe sobreposi\u00e7\u00e3o entre as medi\u00e7\u00f5es, ou seja, uma petala de tamanho x pode ser tanto da especie versicolor ou da virginica?</p> </li> <li><p>\u00c9 possivel classificar as especies de iris com base apenas em suas dimens\u00f5es?</p> </li> </ol>"},{"location":"aulas/IA/lab01/dataframe%20copy.html#acessando-dados-de-um-dataframe","title":"Acessando dados de um Dataframe\u00b6","text":"<p>H\u00e1 v\u00e1rias maneiras de acessar o conte\u00fado de um <code>DataFrame</code>. Os mais simples s\u00e3o aqueles que usam a nota\u00e7\u00e3o de colchetes. Primeiramente, podemos acessar uma coluna atrav\u00e9s do seu \u00edndice, retornando uma <code>Series</code>, ou seja, uma coluna do dataframe.</p>"},{"location":"aulas/IA/lab01/dataframe%20copy.html#desafios-3","title":"Desafios 3\u00b6","text":"<ol> <li>Limpeza de Dados: Introduza valores faltantes no dataset Iris. Tente usar diferentes m\u00e9todos para tratar essas imperfei\u00e7\u00f5es e compare os resultados.</li> <li>Manipula\u00e7\u00e3o de Dados: Use as fun\u00e7\u00f5es do pandas para responder \u00e0s seguintes perguntas sobre o dataset Iris:<ul> <li>Qual \u00e9 a m\u00e9dia da largura da s\u00e9pala para cada esp\u00e9cie?</li> <li>Quantas flores t\u00eam uma \u00e1rea da s\u00e9pala maior que 20 cm^2?</li> </ul> </li> <li>feature engineering: Pense em outras caracter\u00edsticas que podem ser criadas a partir do dataset Iris. Por exemplo, uma caracter\u00edstica que represente a propor\u00e7\u00e3o entre a largura e o comprimento da s\u00e9pala.</li> </ol>"},{"location":"aulas/IA/lab01/dataframe%20copy.html#desafio-4","title":"Desafio 4\u00b6","text":"<p>Fa\u00e7a agora uma explora\u00e7\u00e3o de dados em outra base, conhe\u00e7a a base, e crie hipoteses de teste.</p> <ol> <li>Importar os dados do dataset <code>Breast Cancer Data Set</code> acesse o site:<code>https://archive.ics.uci.edu/ml/datasets/breast+cancer</code></li> <li>Nomear as colunas de acordo com o arquivo <code>breast-cancer.names</code></li> <li>Ralizar a An\u00e1lise Explorat\u00f3ria de Dados (EDA):</li> <li>Visualize a distribui\u00e7\u00e3o de cada caracter\u00edstica do conjunto de dados.</li> <li>Determine quais caracter\u00edsticas t\u00eam maior correla\u00e7\u00e3o com a classifica\u00e7\u00e3o de malignidade.</li> <li>Crie novas caracter\u00edsticas a partir das existentes.</li> <li>Crie representa\u00e7\u00e3oes gr\u00e1ficas do dataset para contribuir para sua an\u00e1lise</li> </ol>"},{"location":"aulas/IA/lab01/dataframe.html","title":"Dataframe","text":"<p>Para instalar</p> <ul> <li>pandas: <code>pip install pandas</code></li> </ul> <p>LEIA A DOCUMENTA\u00c7\u00c3O: https://pandas.pydata.org/docs/index.html</p> In\u00a0[\u00a0]: Copied! <pre>import pandas as pd\n</pre> import pandas as pd In\u00a0[\u00a0]: Copied! <pre># Caminho do arquivo\nurl = \"https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data\"\n\n# L\u00ea e carrega o arquivo para a mem\u00f3ria\ndf = pd.read_csv(url)\n</pre> # Caminho do arquivo url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data\"  # L\u00ea e carrega o arquivo para a mem\u00f3ria df = pd.read_csv(url) In\u00a0[\u00a0]: Copied! <pre>df.head()\n</pre> df.head() Out[\u00a0]: 5.1 3.5 1.4 0.2 Iris-setosa 0 4.9 3.0 1.4 0.2 Iris-setosa 1 4.7 3.2 1.3 0.2 Iris-setosa 2 4.6 3.1 1.5 0.2 Iris-setosa 3 5.0 3.6 1.4 0.2 Iris-setosa 4 5.4 3.9 1.7 0.4 Iris-setosa <p>Note que a primeira linha n\u00e3o contem os nomes das colunas ou <code>atributos</code>(variaveis) e sim, dados (valores).</p> <p>Dependendo da base dados utilizada e como voc\u00ea carrega no pandas, os dados da primeira linha s\u00e3o importados como atributos.</p> <p>Vamos adicionar um cabe\u00e7ario ao nosso dataframe. Mas o que podemos adicionar???</p> <p>Vamos dar uma olhada no reposit\u00f3rio oficial onde dadas informa\u00e7\u00f5es sobre o dataset e \u00e9 dito que as variaveis s\u00e3o:</p> <pre><code>Attribute Information:\n\n1. sepal length in cm\n2. sepal width in cm\n3. petal length in cm\n4. petal width in cm\n5. class:\n-- Iris Setosa\n-- Iris Versicolour\n-- Iris Virginica\n</code></pre> In\u00a0[\u00a0]: Copied! <pre># Define o nome das colunas\nheader = ['sepal_length', 'sepal_width', 'petal_length', 'petal_width', 'species']\n# L\u00ea e carrega o arquivo para a mem\u00f3ria\ndf = pd.read_csv(url, header=None, names=header)\n</pre> # Define o nome das colunas header = ['sepal_length', 'sepal_width', 'petal_length', 'petal_width', 'species'] # L\u00ea e carrega o arquivo para a mem\u00f3ria df = pd.read_csv(url, header=None, names=header) In\u00a0[\u00a0]: Copied! <pre># Retorna um trecho com as 5 primeiras linhas do dataframe\ndf.head()\n</pre> # Retorna um trecho com as 5 primeiras linhas do dataframe df.head() Out[\u00a0]: sepal_length sepal_width petal_length petal_width species 0 5.1 3.5 1.4 0.2 Iris-setosa 1 4.9 3.0 1.4 0.2 Iris-setosa 2 4.7 3.2 1.3 0.2 Iris-setosa 3 4.6 3.1 1.5 0.2 Iris-setosa 4 5.0 3.6 1.4 0.2 Iris-setosa In\u00a0[\u00a0]: Copied! <pre># Mostra informa\u00e7\u00f5es sobre o dataframe em si\ndf.info()\n</pre> # Mostra informa\u00e7\u00f5es sobre o dataframe em si df.info() <pre>&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 150 entries, 0 to 149\nData columns (total 5 columns):\n #   Column        Non-Null Count  Dtype  \n---  ------        --------------  -----  \n 0   sepal_length  150 non-null    float64\n 1   sepal_width   150 non-null    float64\n 2   petal_length  150 non-null    float64\n 3   petal_width   150 non-null    float64\n 4   species       150 non-null    object \ndtypes: float64(4), object(1)\nmemory usage: 6.0+ KB\n</pre> In\u00a0[\u00a0]: Copied! <pre># exibe o shape (dimenso\u1ebds) do dataframe\ndf.shape\n</pre> # exibe o shape (dimenso\u1ebds) do dataframe df.shape Out[\u00a0]: <pre>(150, 5)</pre> In\u00a0[\u00a0]: Copied! <pre>## Suas respostas....\n</pre> ## Suas respostas....       <p>S\u00e3o 150 exemplares de flor de \u00edris, pertencentes a tr\u00eas esp\u00e9cies diferentes: setosa, versicolor e virginica, sendo 50 amostras de cada esp\u00e9cie.</p> <p>Os atributos de <code>largura e comprimento de s\u00e9pala</code> e <code>largura e comprimento de p\u00e9tala</code> de cada flor fooram medidos manualmente.</p> In\u00a0[\u00a0]: Copied! <pre>df.describe()\n</pre> df.describe() Out[\u00a0]: sepal_length sepal_width petal_length petal_width count 150.000000 150.000000 150.000000 150.000000 mean 5.843333 3.054000 3.758667 1.198667 std 0.828066 0.433594 1.764420 0.763161 min 4.300000 2.000000 1.000000 0.100000 25% 5.100000 2.800000 1.600000 0.300000 50% 5.800000 3.000000 4.350000 1.300000 75% 6.400000 3.300000 5.100000 1.800000 max 7.900000 4.400000 6.900000 2.500000 <p>Note que o m\u00e9todo describe() n\u00e3o exibe a coluna species, pois se trata de uma coluna n\u00e3o-num\u00e9rica.</p> <p>Apenas as colunas num\u00e9ricas est\u00e3o presentes, o atributo species indica r\u00f3tulos - trata-se de dados categ\u00f3ricos.</p> In\u00a0[\u00a0]: Copied! <pre># retorna a quantiade de classes da coluna\n\ndf.species.unique()\n</pre> # retorna a quantiade de classes da coluna  df.species.unique() Out[\u00a0]: <pre>array(['Iris-setosa', 'Iris-versicolor', 'Iris-virginica'], dtype=object)</pre> In\u00a0[\u00a0]: Copied! <pre># agrupamento por m\u00e9dia\n\ndf.groupby('species').mean()\n</pre> # agrupamento por m\u00e9dia  df.groupby('species').mean() Out[\u00a0]: sepal_length sepal_width petal_length petal_width species Iris-setosa 5.006 3.418 1.464 0.244 Iris-versicolor 5.936 2.770 4.260 1.326 Iris-virginica 6.588 2.974 5.552 2.026 In\u00a0[\u00a0]: Copied! <pre>#  Quantidade de cada categoria\ndf.groupby('species').size()\n</pre> #  Quantidade de cada categoria df.groupby('species').size() Out[\u00a0]: <pre>species\nIris-setosa        50\nIris-versicolor    50\nIris-virginica     50\ndtype: int64</pre> In\u00a0[\u00a0]: Copied! <pre>import numpy as np\n\n# c\u00f3pia de df\ndf_iris = df\n\n# Gera dados faltante no dataset\nfor col in df_iris.columns[:-1]:\n    df_iris.loc[np.random.choice(df_iris.index, 5), col] = np.nan\n</pre> import numpy as np  # c\u00f3pia de df df_iris = df  # Gera dados faltante no dataset for col in df_iris.columns[:-1]:     df_iris.loc[np.random.choice(df_iris.index, 5), col] = np.nan  In\u00a0[\u00a0]: Copied! <pre>df_iris.info()\n</pre> df_iris.info() <pre>&lt;class 'pandas.core.frame.DataFrame'&gt;\nInt64Index: 131 entries, 0 to 149\nData columns (total 5 columns):\n #   Column        Non-Null Count  Dtype  \n---  ------        --------------  -----  \n 0   sepal_length  121 non-null    float64\n 1   sepal_width   121 non-null    float64\n 2   petal_length  122 non-null    float64\n 3   petal_width   121 non-null    float64\n 4   species       131 non-null    object \ndtypes: float64(4), object(1)\nmemory usage: 10.2+ KB\n</pre> In\u00a0[\u00a0]: Copied! <pre># Verifica os valores ausentes\n\ndf_iris.isnull().sum()\n</pre> # Verifica os valores ausentes  df_iris.isnull().sum()  Out[\u00a0]: <pre>sepal_length    10\nsepal_width     10\npetal_length     9\npetal_width     10\nspecies          0\ndtype: int64</pre> In\u00a0[\u00a0]: Copied! <pre>df_iris.dropna(axis=0, inplace=True)\n</pre> df_iris.dropna(axis=0, inplace=True) In\u00a0[\u00a0]: Copied! <pre># Tratamento de valores faltantes: imputa\u00e7\u00e3o m\u00e9dia\n\nfor col in df_iris.columns[:-1]:  # a coluna de especie n\u00e3o entra\n    mean_val = df_iris[col].mean()\n    df_iris[col].fillna(mean_val, inplace=True)\n</pre> # Tratamento de valores faltantes: imputa\u00e7\u00e3o m\u00e9dia  for col in df_iris.columns[:-1]:  # a coluna de especie n\u00e3o entra     mean_val = df_iris[col].mean()     df_iris[col].fillna(mean_val, inplace=True) In\u00a0[\u00a0]: Copied! <pre>df_iris.info()\n</pre> df_iris.info()  <pre>&lt;class 'pandas.core.frame.DataFrame'&gt;\nInt64Index: 131 entries, 0 to 149\nData columns (total 5 columns):\n #   Column        Non-Null Count  Dtype  \n---  ------        --------------  -----  \n 0   sepal_length  131 non-null    float64\n 1   sepal_width   131 non-null    float64\n 2   petal_length  131 non-null    float64\n 3   petal_width   131 non-null    float64\n 4   species       131 non-null    object \ndtypes: float64(4), object(1)\nmemory usage: 10.2+ KB\n</pre> In\u00a0[\u00a0]: Copied! <pre>import matplotlib.pyplot as plt\nimport seaborn as sns\n</pre> import matplotlib.pyplot as plt import seaborn as sns In\u00a0[\u00a0]: Copied! <pre># Gr\u00e1fico de linha para a m\u00e9dia do comprimento da s\u00e9pala de cada esp\u00e9cie\n\ngrouped = df_iris.groupby('species')['sepal_length'].mean()\ngrouped.plot(kind='line', marker='o')\n\n\nplt.title('M\u00e9dia do Comprimento da S\u00e9pala por Esp\u00e9cie')\nplt.ylabel('Comprimento da S\u00e9pala (cm)')\nplt.grid(True)\nplt.show()\n</pre> # Gr\u00e1fico de linha para a m\u00e9dia do comprimento da s\u00e9pala de cada esp\u00e9cie  grouped = df_iris.groupby('species')['sepal_length'].mean() grouped.plot(kind='line', marker='o')   plt.title('M\u00e9dia do Comprimento da S\u00e9pala por Esp\u00e9cie') plt.ylabel('Comprimento da S\u00e9pala (cm)') plt.grid(True) plt.show()  In\u00a0[\u00a0]: Copied! <pre># Gr\u00e1fico de Barras\n\nspecies_count = df['species'].value_counts()\nspecies_count.plot(kind='bar')\n\nplt.title('Contagem de Esp\u00e9cies')\nplt.xlabel('Esp\u00e9cie')\nplt.ylabel('Contagem')\nplt.show()\n</pre> # Gr\u00e1fico de Barras  species_count = df['species'].value_counts() species_count.plot(kind='bar')  plt.title('Contagem de Esp\u00e9cies') plt.xlabel('Esp\u00e9cie') plt.ylabel('Contagem') plt.show()  In\u00a0[\u00a0]: Copied! <pre># Lembra de histograma, que exibe uma gr\u00e1fico de frequ\u00eancia.\ndf.hist(bins=100, figsize=(15, 15))\nplt.show()\n</pre> # Lembra de histograma, que exibe uma gr\u00e1fico de frequ\u00eancia. df.hist(bins=100, figsize=(15, 15)) plt.show() In\u00a0[\u00a0]: Copied! <pre># Histograma apenas de um atributo\n\nplt.hist(df['sepal_length'], bins=100)\n\n\nplt.title('Histograma de Sepal Length')\nplt.xlabel('Sepal Length')\nplt.ylabel('Contagem')\nplt.show()\n</pre> # Histograma apenas de um atributo  plt.hist(df['sepal_length'], bins=100)   plt.title('Histograma de Sepal Length') plt.xlabel('Sepal Length') plt.ylabel('Contagem') plt.show()  In\u00a0[\u00a0]: Copied! <pre># box plot\ndf.plot(kind='box', subplots=True, layout=(2,2), sharex=False, sharey=False, figsize=(15, 15))\nplt.show()\n</pre> # box plot df.plot(kind='box', subplots=True, layout=(2,2), sharex=False, sharey=False, figsize=(15, 15)) plt.show() In\u00a0[\u00a0]: Copied! <pre># Grafico de dispers\u00e3o\n\nplt.scatter(df_iris['sepal_length'], df_iris['petal_length'])\n\nplt.title('Sepal Length vs Petal Length')\nplt.xlabel('Sepal Length (cm)')\nplt.ylabel('Petal Length (cm)')\nplt.show()\n</pre> # Grafico de dispers\u00e3o  plt.scatter(df_iris['sepal_length'], df_iris['petal_length'])  plt.title('Sepal Length vs Petal Length') plt.xlabel('Sepal Length (cm)') plt.ylabel('Petal Length (cm)') plt.show() In\u00a0[\u00a0]: Copied! <pre># Os mesmos dados mas agora cada classe de uma cor diferente\n\ncolors = {'Iris-setosa':'red', 'Iris-versicolor':'blue', 'Iris-virginica':'green'}\n\nplt.scatter(df['sepal_length'], df['petal_length'], c=df['species'].map(colors), label=colors)\n\nplt.title('Sepal Length vs Petal Length')\nplt.xlabel('Sepal Length (cm)')\nplt.ylabel('Petal Length (cm)')\nplt.legend(handles=[plt.Line2D([0], [0], marker='o', color='w', markerfacecolor=color, markersize=10) for color in colors.values()], labels=colors.keys())\nplt.show()\n</pre> # Os mesmos dados mas agora cada classe de uma cor diferente  colors = {'Iris-setosa':'red', 'Iris-versicolor':'blue', 'Iris-virginica':'green'}  plt.scatter(df['sepal_length'], df['petal_length'], c=df['species'].map(colors), label=colors)  plt.title('Sepal Length vs Petal Length') plt.xlabel('Sepal Length (cm)') plt.ylabel('Petal Length (cm)') plt.legend(handles=[plt.Line2D([0], [0], marker='o', color='w', markerfacecolor=color, markersize=10) for color in colors.values()], labels=colors.keys()) plt.show() In\u00a0[\u00a0]: Copied! <pre># scatter plot matrix\n# tudo junto e misturado\n\nfrom pandas.plotting import scatter_matrix\n\nscatter_matrix(df,figsize=(15, 15))\n\nplt.show()\n</pre> # scatter plot matrix # tudo junto e misturado  from pandas.plotting import scatter_matrix  scatter_matrix(df,figsize=(15, 15))  plt.show() <p>Vamos utilizar o <code>seaborn</code> para visualizar gr\u00e1ficos mais bonitos</p> In\u00a0[\u00a0]: Copied! <pre>import seaborn as sns\n\n# A cor vem do campo `species` do dataframe\n\nsns.pairplot(df, hue='species', height=5)\n\nplt.show()\n</pre> import seaborn as sns  # A cor vem do campo `species` do dataframe  sns.pairplot(df, hue='species', height=5)  plt.show() <p>O Violin plot \u00e9 similar ao box plot, exibe a distribui\u00e7\u00e3o de variaveis num\u00e9ricas em niveis, pode ser configurada de muitas formas e \u00e9 uma forma de visualiza\u00e7\u00e3o interessante de dados.</p> <p>Saiba mais em: https://seaborn.pydata.org/generated/seaborn.violinplot.html</p> In\u00a0[\u00a0]: Copied! <pre># Violin plot\ng = sns.violinplot(y='species', x='sepal_length', data=df, inner='quartile')\nplt.show()\ng = sns.violinplot(y='species', x='sepal_width', data=df, inner='quartile')\nplt.show()\ng = sns.violinplot(y='species', x='petal_length', data=df, inner='quartile')\nplt.show()\ng = sns.violinplot(y='species', x='petal_width', data=df, inner='quartile')\nplt.show()\n</pre> # Violin plot g = sns.violinplot(y='species', x='sepal_length', data=df, inner='quartile') plt.show() g = sns.violinplot(y='species', x='sepal_width', data=df, inner='quartile') plt.show() g = sns.violinplot(y='species', x='petal_length', data=df, inner='quartile') plt.show() g = sns.violinplot(y='species', x='petal_width', data=df, inner='quartile') plt.show() In\u00a0[\u00a0]: Copied! <pre>cols = ['sepal_length', 'sepal_width', 'petal_length','petal_width']\ncorr_matx = df[cols].corr()\n\nheatmap = sns.heatmap(corr_matx,cbar=True,annot=True,square=True,fmt='.2f',annot_kws={'size': 15},yticklabels=cols,xticklabels=cols,cmap='Dark2')\n</pre> cols = ['sepal_length', 'sepal_width', 'petal_length','petal_width'] corr_matx = df[cols].corr()  heatmap = sns.heatmap(corr_matx,cbar=True,annot=True,square=True,fmt='.2f',annot_kws={'size': 15},yticklabels=cols,xticklabels=cols,cmap='Dark2') In\u00a0[\u00a0]: Copied! <pre>### Implemente sua solu\u00e7\u00e3o e apresente sua an\u00e1lise....\n</pre> ### Implemente sua solu\u00e7\u00e3o e apresente sua an\u00e1lise....     In\u00a0[\u00a0]: Copied! <pre>df['petal_length'].head()\n</pre> df['petal_length'].head() Out[\u00a0]: <pre>0    1.4\n1    1.4\n2    1.3\n3    1.5\n4    1.4\nName: petal_length, dtype: float64</pre> <p>Por outro lado, se dentro dos colchetes passamos uma lista de nomes de coluna, o reultado \u00e9 outro <code>DataFrame</code> contendo aquelas colunas. Isso vale inclusive para uma coluna simples:</p> In\u00a0[\u00a0]: Copied! <pre># Mostra apenas a coluna petal_len\ndf[['petal_length']].head()\n</pre> # Mostra apenas a coluna petal_len df[['petal_length']].head() Out[\u00a0]: petal_length 0 1.4 1 1.4 2 1.3 3 1.5 4 1.4 In\u00a0[\u00a0]: Copied! <pre># Mostra as colunas petal_length e petal_width\ndf[['petal_length', 'petal_width']].head()\n</pre> # Mostra as colunas petal_length e petal_width df[['petal_length', 'petal_width']].head() Out[\u00a0]: petal_length petal_width 0 1.4 0.2 1 1.4 0.2 2 1.3 0.2 3 1.5 0.2 4 1.4 0.2 In\u00a0[\u00a0]: Copied! <pre># Criando uma nova caracter\u00edstica: \u00e1rea da s\u00e9pala\n\ndf['sepal_area'] = df['sepal_length'] * df['sepal_width']\n\ndf.head()\n</pre> # Criando uma nova caracter\u00edstica: \u00e1rea da s\u00e9pala  df['sepal_area'] = df['sepal_length'] * df['sepal_width']  df.head()  Out[\u00a0]: sepal_length sepal_width petal_length petal_width species sepal_area 0 5.1 3.5 1.4 0.2 Iris-setosa 17.85 1 4.9 3.0 1.4 0.2 Iris-setosa 14.70 2 4.7 3.2 1.3 0.2 Iris-setosa 15.04 3 4.6 3.1 1.5 0.2 Iris-setosa 14.26 4 5.0 3.6 1.4 0.2 Iris-setosa 18.00 In\u00a0[\u00a0]: Copied! <pre>## suas respostas aqui.....\n</pre> ## suas respostas aqui.....      In\u00a0[\u00a0]: Copied! <pre>### Implemente sua sua solu\u00e7\u00e3o e an\u00e1lise de dados. :)\n</pre> ### Implemente sua sua solu\u00e7\u00e3o e an\u00e1lise de dados. :)"},{"location":"aulas/IA/lab01/dataframe.html#objetivos","title":"Objetivos\u00b6","text":"<ul> <li>Apresentar e utilizar o pacote pandas</li> <li>Como carregar uma base dados</li> <li>Como visualizar os dados</li> <li>Intui\u00e7\u00e3o de an\u00e1lise explorat\u00f3ria de dados</li> </ul>"},{"location":"aulas/IA/lab01/dataframe.html#introducao-a-analise-de-dados-usando-pandas","title":"Introdu\u00e7\u00e3o a an\u00e1lise de dados usando Pandas\u00b6","text":"<p>Vamos come\u00e7ar pelo come\u00e7o! Vamos escolher um dataset (conjunto de dados) para analisar.</p> <p>Vamos utilizar um pacote do python capaz de trabalhar com tabelas de dados chamada pandas, para essas tabelas chamamos de dataframe.</p> <p>Veja mais em: https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.html</p>"},{"location":"aulas/IA/lab01/dataframe.html#hello-world-do-mundo-dos-dados","title":"Hello World! do mundo dos dados\u00b6","text":""},{"location":"aulas/IA/lab01/dataframe.html#conjunto-de-dados-dataset","title":"Conjunto de dados <code>Dataset</code>\u00b6","text":"<p>Para trabalhar com an\u00e1lise de dados precisamos de.... <code>DADOS</code>.</p> <p>Podemos escolher qualquer base de dados disponivel na internet, ou at\u00e9 mesmo criar nosso proprio dataset.</p> <p>Vamos simplificar essa etapa e come\u00e7ar analisando uma base pequena e muito famosa chamada iris que esta disponivel em:</p> <p>ref: https://archive.ics.uci.edu/ml/datasets/Iris</p> <p>Conhe\u00e7a outros datasets: https://archive.ics.uci.edu/ml/datasets.php</p>"},{"location":"aulas/IA/lab01/dataframe.html#conhecendo-os-dados","title":"Conhecendo os dados\u00b6","text":"<p>Essa etapa \u00e9 muito importante, CONHECER OS DADOS!</p> <p>Quanto mais voc\u00ea conhece a base de DADOS maior a possibilidade de extrair INFORMA\u00c7\u00d5ES \u00fateis para tomada de decis\u00e3o.</p>"},{"location":"aulas/IA/lab01/dataframe.html#analisando-o-dataset","title":"an\u00e1lisando o dataset\u00b6","text":"<p>Agora que j\u00e1 carregamos o dataset corretamente, vamos come\u00e7ar a analisa-lo. o m\u00e9todo <code>info()</code> \u00e9 um bom ponto de partida para isso.</p>"},{"location":"aulas/IA/lab01/dataframe.html#desafio-1","title":"Desafio 1\u00b6","text":"<p>Analisando as informa\u00e7\u00f5es do dataset iris, responda:</p> <ol> <li><p>Quantos dados existem nesse dataset?</p> </li> <li><p>Qual a quantidade de atributos?</p> </li> <li><p>Existe valores faltantes?</p> </li> <li><p>De que tipo s\u00e3o os dados (dtype)?</p> </li> </ol>"},{"location":"aulas/IA/lab01/dataframe.html#analisando-os-dados-mais-a-fundo","title":"An\u00e1lisando os dados mais a fundo\u00b6","text":""},{"location":"aulas/IA/lab01/dataframe.html#resumo-estatistico","title":"Resumo estat\u00edstico\u00b6","text":"<p>O m\u00e9todo <code>describe()</code> gera um resumo estat\u00edstico dos dados contidos em um DataFrame ou Series.</p> <p>Retorna estat\u00edsticas descritivas como <code>m\u00e9dia, desvio padr\u00e3o, valor m\u00ednimo, quartis e valor m\u00e1ximo</code> para as colunas num\u00e9ricas do DataFrame</p>"},{"location":"aulas/IA/lab01/dataframe.html#agrupando-dados","title":"Agrupando dados\u00b6","text":"<p>O m\u00e9todo <code>groupby</code> \u00e9 usada para agrupar dados com base em valores espec\u00edficos de uma ou mais colunas.</p> <p>Permite realizar opera\u00e7\u00f5es em grupos de dados e \u00e9 muito \u00fatil e versatil para an\u00e1lise e agrega\u00e7\u00e3o de dado.</p>"},{"location":"aulas/IA/lab01/dataframe.html#limpeza-de-dados","title":"Limpeza de Dados\u00b6","text":"<p>Base de dados do mundo real podem conter diversos problemas, \u00e9 muito comum o lidar com valores faltantes em um dataset.</p> <p>Como exemplo, vamos usar o conjunto de dados Iris, mas introduzimos algumas 'imperfei\u00e7\u00f5es' para fins de demonstra\u00e7\u00e3o.</p> <p>Para introduzir valores faltantes, podemos usar o seguinte c\u00f3digo:</p> <pre>## Gera dados faltante no dataset\nfor col in df_iris.columns[:-1]:\n    df_iris.loc[np.random.choice(df_iris.index, 5), col] = np.nan\n</pre>"},{"location":"aulas/IA/lab01/dataframe.html#excluindo-linhas","title":"Excluindo linhas\u00b6","text":"<p>Podemos simplismente excluir as linhas ou colunas que contenham dados faltantes, basta usar a fun\u00e7\u00e3o dropna pandas, utilizando como par\u00e2metros o axis = 1 para dizer que queremos deletar a coluna ou axis = 0 para linha e inplace = True para aplicarmos no dataset e n\u00e3o criarmos uma c\u00f3pia deste:</p> <ul> <li><code>axis=0</code> --&gt; exclui linha</li> <li><code>axis=1</code> --&gt; exclui coluna</li> </ul> <p><code>Pense bemmmm!!!!</code> A decis\u00e3o por qual vai excluir depende do problema que voc\u00ea est\u00e1 atacando...</p>"},{"location":"aulas/IA/lab01/dataframe.html#preenchimento-com-valores","title":"Preenchimento com valores\u00b6","text":"<p>Voc\u00ea pode preencher os valores faltantes com m\u00e9dias, medianas, modas ou outros valores relevantes.</p> <p>Isso ajuda a manter o tamanho do conjunto de dados, mas pode introduzir vi\u00e9s nos resultados.</p> <p><code>Pense bemmmm!!!!</code> A decis\u00e3o por qual valor preencher depende do problema que voc\u00ea est\u00e1 atacando...</p>"},{"location":"aulas/IA/lab01/dataframe.html#analisando-informacoes-em-graficos","title":"Analisando informa\u00e7\u00f5es em gr\u00e1ficos\u00b6","text":"<p>Uma an\u00e1lise gr\u00e1fica pode ajudar a compreeder melhor os dados que estamos trabalhando....</p> <p>Vamos explorar diferentes tipos de visualiza\u00e7\u00f5es que podem nos ajudar a entender melhor nossos dados.</p> <p>Vamos usar o <code>matplotlib</code> e o  <code>seaborn</code> para nos ajudar.</p> <p>Se precisar instalar:</p> <ul> <li>pip install matplotlib seaborn</li> </ul>"},{"location":"aulas/IA/lab01/dataframe.html#correlacao-entre-atributos","title":"Correla\u00e7\u00e3o entre atributos\u00b6","text":"<p>A matriz de correla\u00e7\u00e3o  avalia a rela\u00e7\u00e3o entre duas ou mais variaveis (correla\u00e7\u00e3o).</p> <p>valores:</p> <ul> <li>0.9 a 1 positivo ou negativo indica uma correla\u00e7\u00e3o muito forte.</li> <li>0.7 a 0.9 positivo ou negativo indica uma correla\u00e7\u00e3o forte.</li> <li>0.5 a 0.7 positivo ou negativo indica uma correla\u00e7\u00e3o moderada.</li> <li>0.3 a 0.5 positivo ou negativo indica uma correla\u00e7\u00e3o fraca.</li> <li>0 a 0.3 positivo ou negativo indica uma correla\u00e7\u00e3o desprez\u00edvel.</li> </ul> <p>lembre-se que: alta correla\u00e7\u00e3o n\u00e3o implica em causa. (causa e consequ\u00eancia). Para entender melhor vale a pena dar uma olhada nesse site que mostra correla\u00e7\u00f5es absurdas...'spurious correlations'</p>"},{"location":"aulas/IA/lab01/dataframe.html#desafio-2","title":"Desafio 2\u00b6","text":"<p>Analise os gr\u00e1ficos gerados at\u00e9 o momento para responder as quest\u00f5es abaixo:</p> <ol> <li><p>A especie que possui na m\u00e9dia a menor sepala \u00e9 a mesma que possui a menor petala?</p> </li> <li><p>Existe sobreposi\u00e7\u00e3o entre as medi\u00e7\u00f5es, ou seja, uma petala de tamanho x pode ser tanto da especie versicolor ou da virginica?</p> </li> <li><p>\u00c9 possivel classificar as especies de iris com base apenas em suas dimens\u00f5es?</p> </li> </ol>"},{"location":"aulas/IA/lab01/dataframe.html#acessando-dados-de-um-dataframe","title":"Acessando dados de um Dataframe\u00b6","text":"<p>H\u00e1 v\u00e1rias maneiras de acessar o conte\u00fado de um <code>DataFrame</code>. Os mais simples s\u00e3o aqueles que usam a nota\u00e7\u00e3o de colchetes. Primeiramente, podemos acessar uma coluna atrav\u00e9s do seu \u00edndice, retornando uma <code>Series</code>, ou seja, uma coluna do dataframe.</p>"},{"location":"aulas/IA/lab01/dataframe.html#desafios-3","title":"Desafios 3\u00b6","text":"<ol> <li>Limpeza de Dados: Introduza valores faltantes no dataset Iris. Tente usar diferentes m\u00e9todos para tratar essas imperfei\u00e7\u00f5es e compare os resultados.</li> <li>Manipula\u00e7\u00e3o de Dados: Use as fun\u00e7\u00f5es do pandas para responder \u00e0s seguintes perguntas sobre o dataset Iris:<ul> <li>Qual \u00e9 a m\u00e9dia da largura da s\u00e9pala para cada esp\u00e9cie?</li> <li>Quantas flores t\u00eam uma \u00e1rea da s\u00e9pala maior que 20 cm^2?</li> </ul> </li> <li>feature engineering: Pense em outras caracter\u00edsticas que podem ser criadas a partir do dataset Iris. Por exemplo, uma caracter\u00edstica que represente a propor\u00e7\u00e3o entre a largura e o comprimento da s\u00e9pala.</li> </ol>"},{"location":"aulas/IA/lab01/dataframe.html#desafio-4","title":"Desafio 4\u00b6","text":"<p>Fa\u00e7a agora uma explora\u00e7\u00e3o de dados em outra base, conhe\u00e7a a base, e crie hipoteses de teste.</p> <ol> <li>Importar os dados do dataset <code>Breast Cancer Data Set</code> acesse o site:<code>https://archive.ics.uci.edu/ml/datasets/breast+cancer</code></li> <li>Nomear as colunas de acordo com o arquivo <code>breast-cancer.names</code></li> <li>Ralizar a An\u00e1lise Explorat\u00f3ria de Dados (EDA):</li> <li>Visualize a distribui\u00e7\u00e3o de cada caracter\u00edstica do conjunto de dados.</li> <li>Determine quais caracter\u00edsticas t\u00eam maior correla\u00e7\u00e3o com a classifica\u00e7\u00e3o de malignidade.</li> <li>Crie novas caracter\u00edsticas a partir das existentes.</li> <li>Crie representa\u00e7\u00e3oes gr\u00e1ficas do dataset para contribuir para sua an\u00e1lise</li> </ol>"},{"location":"aulas/IA/lab01/dataframeold.html","title":"Dataframeold","text":"In\u00a0[\u00a0]: Copied! <pre>import pandas as pd\n\n# Cria uma dataframe\ndata = {\n  \"Nome\": [\"Riu\", \"M\u00e1rio\", \"Gogu\"],\n  \"Idade\": [50, 40, 45]\n}\n\n# Carrega o dataframe\ndf = pd.DataFrame(data)\n\nprint(df) \n</pre> import pandas as pd  # Cria uma dataframe data = {   \"Nome\": [\"Riu\", \"M\u00e1rio\", \"Gogu\"],   \"Idade\": [50, 40, 45] }  # Carrega o dataframe df = pd.DataFrame(data)  print(df)     <pre>    Nome  Idade\n0    Riu     50\n1  M\u00e1rio     40\n2   Gogu     45\n</pre> In\u00a0[\u00a0]: Copied! <pre>import pandas as pd\n\n# Cria uma dataframe\ndata = [[\"Riu\", 50],[\"Gogu\",15],[\"M\u00e1rio\",80]]\n\n# Carrega o dataframe\ndf = pd.DataFrame(data)\n\nprint(df)\n</pre> import pandas as pd  # Cria uma dataframe data = [[\"Riu\", 50],[\"Gogu\",15],[\"M\u00e1rio\",80]]  # Carrega o dataframe df = pd.DataFrame(data)  print(df) <pre>       0   1\n0    Riu  50\n1   Gogu  15\n2  M\u00e1rio  80\n</pre> <p>Para instalar</p> <ul> <li>pandas: <code>pip install pandas</code></li> </ul> <p>LEIA A DOCUMENTA\u00c7\u00c3O: https://pandas.pydata.org/docs/index.html</p> In\u00a0[\u00a0]: Copied! <pre># Inicializ\u00e7\u00e3o das bibliotecas\n%matplotlib inline\n\nimport pandas as pd\nimport matplotlib.pyplot as plt\n</pre> # Inicializ\u00e7\u00e3o das bibliotecas %matplotlib inline  import pandas as pd import matplotlib.pyplot as plt  In\u00a0[\u00a0]: Copied! <pre># Caminho do arquivo\nurl = \"https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data\"\n\n# L\u00ea e carrega o arquivo para a mem\u00f3ria\ndf = pd.read_csv(url)\n</pre> # Caminho do arquivo url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data\"  # L\u00ea e carrega o arquivo para a mem\u00f3ria df = pd.read_csv(url) In\u00a0[\u00a0]: Copied! <pre>df.head()\n</pre> df.head() Out[\u00a0]: 5.1 3.5 1.4 0.2 Iris-setosa 0 4.9 3.0 1.4 0.2 Iris-setosa 1 4.7 3.2 1.3 0.2 Iris-setosa 2 4.6 3.1 1.5 0.2 Iris-setosa 3 5.0 3.6 1.4 0.2 Iris-setosa 4 5.4 3.9 1.7 0.4 Iris-setosa <p>Note que a primeira linha n\u00e3o \u00e9 com os nomes das colunas ou atributos(variaveis) e sim de dados (valores). Por padr\u00e3o os dados da primeira linha s\u00e3o importados como atributos.</p> <p>Vamos adicionar um cabe\u00e7ario ao nosso dataframe. No reposit\u00f3rio oficial \u00e9 dito que as variaveis s\u00e3o:</p> <pre><code>Attribute Information:\n\n1. sepal length in cm\n2. sepal width in cm\n3. petal length in cm\n4. petal width in cm\n5. class:\n-- Iris Setosa\n-- Iris Versicolour\n-- Iris Virginica\n</code></pre> In\u00a0[\u00a0]: Copied! <pre># Define o nome das colunas\nheader = ['sepal_length', 'sepal_width', 'petal_length', 'petal_width', 'species']\n# L\u00ea e carrega o arquivo para a mem\u00f3ria\ndf = pd.read_csv(url, header=None, names=header)\n</pre> # Define o nome das colunas header = ['sepal_length', 'sepal_width', 'petal_length', 'petal_width', 'species'] # L\u00ea e carrega o arquivo para a mem\u00f3ria df = pd.read_csv(url, header=None, names=header) In\u00a0[\u00a0]: Copied! <pre># Retorna um trecho com as 5 primeiras linhas do dataframe\ndf.head()\n</pre> # Retorna um trecho com as 5 primeiras linhas do dataframe df.head() Out[\u00a0]: sepal_length sepal_width petal_length petal_width species 0 5.1 3.5 1.4 0.2 Iris-setosa 1 4.9 3.0 1.4 0.2 Iris-setosa 2 4.7 3.2 1.3 0.2 Iris-setosa 3 4.6 3.1 1.5 0.2 Iris-setosa 4 5.0 3.6 1.4 0.2 Iris-setosa In\u00a0[\u00a0]: Copied! <pre># Mostra informa\u00e7\u00f5es sobre o dataframe em si\ndf.info()\n</pre> # Mostra informa\u00e7\u00f5es sobre o dataframe em si df.info() <pre>&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 150 entries, 0 to 149\nData columns (total 5 columns):\n #   Column        Non-Null Count  Dtype  \n---  ------        --------------  -----  \n 0   sepal_length  150 non-null    float64\n 1   sepal_width   150 non-null    float64\n 2   petal_length  150 non-null    float64\n 3   petal_width   150 non-null    float64\n 4   species       150 non-null    object \ndtypes: float64(4), object(1)\nmemory usage: 6.0+ KB\n</pre> In\u00a0[\u00a0]: Copied! <pre># exibe o shape (dimenso\u1ebds) do dataframe\ndf.shape\n</pre> # exibe o shape (dimenso\u1ebds) do dataframe df.shape Out[\u00a0]: <pre>(150, 5)</pre> In\u00a0[\u00a0]: Copied! <pre># class distribution\nprint(df.groupby('species').size())\n</pre> # class distribution print(df.groupby('species').size()) <pre>species\nIris-setosa        50\nIris-versicolor    50\nIris-virginica     50\ndtype: int64\n</pre> In\u00a0[\u00a0]: Copied! <pre>## Suas respostas....\n</pre> ## Suas respostas....       <p>S\u00e3o 150 exemplares de flor de \u00edris, pertencentes a tr\u00eas esp\u00e9cies diferentes: setosa, versicolor e virginica, sendo 50 amostras de cada esp\u00e9cie. Os atributos de largura e comprimento de s\u00e9pala e largura e comprimento de p\u00e9tala de cada flor fooram medidos manualmente.</p> In\u00a0[\u00a0]: Copied! <pre>df.describe()\n</pre> df.describe() Out[\u00a0]: sepal_length sepal_width petal_length petal_width count 150.000000 150.000000 150.000000 150.000000 mean 5.843333 3.054000 3.758667 1.198667 std 0.828066 0.433594 1.764420 0.763161 min 4.300000 2.000000 1.000000 0.100000 25% 5.100000 2.800000 1.600000 0.300000 50% 5.800000 3.000000 4.350000 1.300000 75% 6.400000 3.300000 5.100000 1.800000 max 7.900000 4.400000 6.900000 2.500000 <p>Note que o m\u00e9todo describe() n\u00e3o exibe a coluna species, pois se trata de uma coluna n\u00e3o-num\u00e9rica. Apenas as colunas num\u00e9ricas est\u00e3o presentes, e a coluna *species** indica r\u00f3tulos - trata-se de dados categ\u00f3ricos.</p> In\u00a0[\u00a0]: Copied! <pre>df.species.unique()\n</pre> df.species.unique() Out[\u00a0]: <pre>array(['Iris-setosa', 'Iris-versicolor', 'Iris-virginica'], dtype=object)</pre> In\u00a0[\u00a0]: Copied! <pre># box and whisker plots\ndf.plot(kind='box', subplots=True, layout=(2,2), sharex=False, sharey=False, figsize=(15, 15))\nplt.show()\n</pre> # box and whisker plots df.plot(kind='box', subplots=True, layout=(2,2), sharex=False, sharey=False, figsize=(15, 15)) plt.show() In\u00a0[\u00a0]: Copied! <pre># Lembra de histograma, que exibe uma gr\u00e1fico de frequ\u00eancia.\ndf.hist(bins=100, figsize=(15, 15))\nplt.show()\n</pre> # Lembra de histograma, que exibe uma gr\u00e1fico de frequ\u00eancia. df.hist(bins=100, figsize=(15, 15)) plt.show() In\u00a0[\u00a0]: Copied! <pre># scatter plot matrix\nfrom pandas.plotting import scatter_matrix\nscatter_matrix(df,figsize=(15, 15))\nplt.show()\n</pre> # scatter plot matrix from pandas.plotting import scatter_matrix scatter_matrix(df,figsize=(15, 15)) plt.show() <p>Vamos instalar o pacote seaborn para visualizar gr\u00e1ficos de dispers\u00e3o entre todos os campos da tabela</p> <ul> <li>seaborn: <code>pip3 install seaborn</code></li> </ul> In\u00a0[\u00a0]: Copied! <pre>import matplotlib.pyplot as plt\nimport seaborn as sns\n\n# A cor vem do campo `species` do dataframe\nsns.pairplot(df, hue='species', height=5)\nplt.show()\n</pre> import matplotlib.pyplot as plt import seaborn as sns  # A cor vem do campo `species` do dataframe sns.pairplot(df, hue='species', height=5) plt.show() <p>O Violin plot \u00e9 similar ao box plot, exibe a distribui\u00e7\u00e3o de variaveis num\u00e9ricas em niveis, pode ser configurada de muitas formas e \u00e9 uma forma de visualiza\u00e7\u00e3o interessante de dados.</p> <p>Saiba mais em: https://seaborn.pydata.org/generated/seaborn.violinplot.html</p> In\u00a0[\u00a0]: Copied! <pre># Violin plot\ng = sns.violinplot(y='species', x='sepal_length', data=df, inner='quartile')\nplt.show()\ng = sns.violinplot(y='species', x='sepal_width', data=df, inner='quartile')\nplt.show()\ng = sns.violinplot(y='species', x='petal_length', data=df, inner='quartile')\nplt.show()\ng = sns.violinplot(y='species', x='petal_width', data=df, inner='quartile')\nplt.show()\n</pre> # Violin plot g = sns.violinplot(y='species', x='sepal_length', data=df, inner='quartile') plt.show() g = sns.violinplot(y='species', x='sepal_width', data=df, inner='quartile') plt.show() g = sns.violinplot(y='species', x='petal_length', data=df, inner='quartile') plt.show() g = sns.violinplot(y='species', x='petal_width', data=df, inner='quartile') plt.show() In\u00a0[\u00a0]: Copied! <pre>cols = ['sepal_length', 'sepal_width', 'petal_length','petal_width']\ncorr_matx = df[cols].corr()\nheatmap = sns.heatmap(corr_matx,cbar=True,annot=True,square=True,fmt='.2f',annot_kws={'size': 15},yticklabels=cols,xticklabels=cols,cmap='Dark2')\n</pre> cols = ['sepal_length', 'sepal_width', 'petal_length','petal_width'] corr_matx = df[cols].corr() heatmap = sns.heatmap(corr_matx,cbar=True,annot=True,square=True,fmt='.2f',annot_kws={'size': 15},yticklabels=cols,xticklabels=cols,cmap='Dark2') In\u00a0[\u00a0]: Copied! <pre>### Implemente sua solu\u00e7\u00e3o e apresente sua an\u00e1lise....\n</pre> ### Implemente sua solu\u00e7\u00e3o e apresente sua an\u00e1lise....     In\u00a0[\u00a0]: Copied! <pre>df['petal_length'].head()\n</pre> df['petal_length'].head() Out[\u00a0]: <pre>0    1.4\n1    1.4\n2    1.3\n3    1.5\n4    1.4\nName: petal_length, dtype: float64</pre> <p>Por outro lado, se dentro dos colchetes passamos uma lista de nomes de coluna, o reultado \u00e9 outro <code>DataFrame</code> contendo aquelas colunas. Isso vale inclusive para uma coluna simples:</p> In\u00a0[\u00a0]: Copied! <pre># Mostra apenas a coluna petal_len\ndf[['petal_length']].head()\n</pre> # Mostra apenas a coluna petal_len df[['petal_length']].head() Out[\u00a0]: petal_length 0 1.4 1 1.4 2 1.3 3 1.5 4 1.4 In\u00a0[\u00a0]: Copied! <pre># Mostra as colunas petal_length e petal_width\ndf[['petal_length', 'petal_width']].head()\n</pre> # Mostra as colunas petal_length e petal_width df[['petal_length', 'petal_width']].head() Out[\u00a0]: petal_length petal_width 0 1.4 0.2 1 1.4 0.2 2 1.3 0.2 3 1.5 0.2 4 1.4 0.2 In\u00a0[\u00a0]: Copied! <pre>### Implemente sua sua solu\u00e7\u00e3o e an\u00e1lise de dados. :)\n</pre> ### Implemente sua sua solu\u00e7\u00e3o e an\u00e1lise de dados. :)"},{"location":"aulas/IA/lab01/dataframeold.html#objetivos","title":"Objetivos\u00b6","text":"<ul> <li>Apresentar e utilizar o pacote pandas</li> <li>Como carregar uma base dados</li> <li>Como visualizar os dados</li> <li>Intui\u00e7\u00e3o de an\u00e1lise explorat\u00f3ria de dados</li> </ul>"},{"location":"aulas/IA/lab01/dataframeold.html#introducao","title":"Introdu\u00e7\u00e3o\u00b6","text":"<p>Vamos come\u00e7ar pelo come\u00e7o! Vamos escolher um dataset (conjunto de dados) para analisar.</p> <p>Vamos utilizar um pacote do python capaz de trabalhar com tabelas de dados chamada pandas, para essas tabelas chamamos de dataframe.</p> <p>Veja mais em: https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.html</p>"},{"location":"aulas/IA/lab01/dataframeold.html#dataset","title":"Dataset\u00b6","text":"<p>Podemos escolher qualquer base de dados disponivel na internet, ou at\u00e9 mesmo criar nosso proprio dataset.</p> <p>Vamos simplificar essa etapa e come\u00e7ar analisando uma base pequena e muito famosa chamada iris que esta disponivel em:</p> <p>ref: https://archive.ics.uci.edu/ml/datasets/Iris</p> <p>Conhe\u00e7a outros datasets: https://archive.ics.uci.edu/ml/datasets.php</p>"},{"location":"aulas/IA/lab01/dataframeold.html#conhecendo-os-dados","title":"Conhecendo os dados\u00b6","text":"<p>Essa etapa \u00e9 muito importante, CONHECER OS DADOS!</p> <p>Quanto mais voc\u00ea conhece a base de DADOS maior a possibilidade de extrair INFORMA\u00c7\u00d5ES \u00fateis para tomada de decis\u00e3o.</p>"},{"location":"aulas/IA/lab01/dataframeold.html#desafio-1","title":"Desafio 1\u00b6","text":"<ol> <li><p>Analisando as informa\u00e7\u00f5es do df e no repositorio do dataset, responda:</p> </li> <li><p>Quantos dados existem nesse dataset?</p> </li> <li><p>Qual a quantidade de atributos?</p> </li> <li><p>Existe valores faltantes?</p> </li> <li><p>De que tipo s\u00e3o os dados (dtype)?</p> </li> </ol>"},{"location":"aulas/IA/lab01/dataframeold.html#analisando-dos-dados-mais-a-fundo","title":"An\u00e1lisando dos dados mais a fundo\u00b6","text":""},{"location":"aulas/IA/lab01/dataframeold.html#analisando-informacoes-em-graficos","title":"Analisando informa\u00e7\u00f5es em gr\u00e1ficos\u00b6","text":"<p>Uma an\u00e1lise gr\u00e1fica pode ajudar a compreeder melhor os dados que estamos trabalhando....</p>"},{"location":"aulas/IA/lab01/dataframeold.html#correlacao-entre-atributos","title":"Correla\u00e7\u00e3o entre atributos\u00b6","text":"<p>A matriz de correla\u00e7\u00e3o  avalia a rela\u00e7\u00e3o entre duas ou mais variaveis (correla\u00e7\u00e3o).</p> <p>valores:</p> <ul> <li>0.9 a 1 positivo ou negativo indica uma correla\u00e7\u00e3o muito forte.</li> <li>0.7 a 0.9 positivo ou negativo indica uma correla\u00e7\u00e3o forte.</li> <li>0.5 a 0.7 positivo ou negativo indica uma correla\u00e7\u00e3o moderada.</li> <li>0.3 a 0.5 positivo ou negativo indica uma correla\u00e7\u00e3o fraca.</li> <li>0 a 0.3 positivo ou negativo indica uma correla\u00e7\u00e3o desprez\u00edvel.</li> </ul> <p>lembre-se que: alta correla\u00e7\u00e3o n\u00e3o implica em causa. (causa e consequ\u00eancia). Para entender melhor vale a pena dar uma olhada nesse site que mostra correla\u00e7\u00f5es absurdas...'spurious correlations'</p>"},{"location":"aulas/IA/lab01/dataframeold.html#desafio-2","title":"Desafio 2\u00b6","text":"<p>Analise os gr\u00e1ficos gerados at\u00e9 o momento para responder as quest\u00f5es abaixo:</p> <ol> <li><p>A especie que possui na m\u00e9dia a menor sepala \u00e9 a mesma que possui a menor petala?</p> </li> <li><p>Existe sobreposi\u00e7\u00e3o entre as medi\u00e7\u00f5es, ou seja, uma petala de tamanho x pode ser tanto da especie versicolor ou da virginica?</p> </li> <li><p>\u00c9 possivel classificar as especies de iris com base apenas em suas dimens\u00f5es?</p> </li> </ol>"},{"location":"aulas/IA/lab01/dataframeold.html#acessando-dados-de-um-dataframe","title":"Acessando dados de um Dataframe\u00b6","text":"<p>H\u00e1 v\u00e1rias maneiras de acessar o conte\u00fado de um <code>DataFrame</code>. Os mais simples s\u00e3o aqueles que usam a nota\u00e7\u00e3o de colchetes. Primeiramente, podemos acessar uma coluna atrav\u00e9s do seu \u00edndice, retornando uma <code>Series</code>, ou seja, uma coluna do dataframe.</p>"},{"location":"aulas/IA/lab01/dataframeold.html#desafio-3","title":"Desafio 3\u00b6","text":"<p>Fa\u00e7a agora uma explora\u00e7\u00e3o de dados em outra base, conhe\u00e7a a base, e crie hipoteses de teste.</p> <ol> <li>Importar os dados do dataset Breast Cancer Data Set: <code>https://archive.ics.uci.edu/ml/datasets/breast+cancer</code></li> <li>Nomear as colunas de acordo com o arquivo <code>breast-cancer.names</code></li> <li>Criar um subdataframe contendo apenas o conte\u00fado das colunas <code>Class</code>, <code>age</code>, <code>menopause</code> e <code>tumor-size</code></li> <li>Visualizar os dados usando pelo menos <code>head()</code> e <code>pairplot()</code></li> </ol>"},{"location":"aulas/IA/lab02/classificacao-ml-completa-old.html","title":"Classifica\u00e7\u00e3o em Machine Learning","text":""},{"location":"aulas/IA/lab02/classificacao-ml-completa-old.html#objetivos-de-aprendizagem","title":"Objetivos de aprendizagem","text":"<ul> <li>Entender tipos de problemas de classifica\u00e7\u00e3o (bin\u00e1ria, multiclasses, multilabel).</li> <li>Conhecer m\u00e9tricas apropriadas e interpretar confus\u00e3o/confid\u00eancias.</li> <li>Montar pipelines reprodut\u00edveis com pr\u00e9-processamento, valida\u00e7\u00e3o e busca de hiperpar\u00e2metros.</li> <li>Tratar desequil\u00edbrio de classes, evitar vazamento de dados e aplicar calibra\u00e7\u00e3o.</li> <li>Usar t\u00e9cnicas de interpreta\u00e7\u00e3o (coeficientes, odds ratios, import\u00e2ncia, SHAP).</li> </ul>"},{"location":"aulas/IA/lab02/classificacao-ml-completa-old.html#atividades-praticas","title":"Atividades Pr\u00e1ticas","text":"<p>As seguintes atividades foram preparadas para refor\u00e7ar os conceitos abordados:</p>"},{"location":"aulas/IA/lab02/classificacao-ml-completa-old.html#datasets","title":"Datasets","text":"<p>Os laborat\u00f3rios utilizam os seguintes conjuntos de dados:</p>"},{"location":"aulas/IA/lab02/classificacao-ml-completa-old.html#1-tipos-de-problemas","title":"1. Tipos de problemas","text":"<ul> <li>Bin\u00e1ria: dois r\u00f3tulos (0/1). Ex.: detec\u00e7\u00e3o de fraude.</li> <li>Multiclasse: mais de duas classes mutuamente exclusivas. Ex.: classifica\u00e7\u00e3o de esp\u00e9cies.</li> <li>Multilabel: cada exemplo pode ter m\u00faltiplos r\u00f3tulos simult\u00e2neos. Ex.: tags em artigos.</li> </ul> Qual tipo de problema permite m\u00faltiplos r\u00f3tulos por exemplo?Bin\u00e1riaMulticlasseMultilabelRegress\u00e3oSubmit Multilabel permite que um mesmo exemplo perten\u00e7a a v\u00e1rias classes ao mesmo tempo (por exemplo, um artigo pode ser \"ci\u00eancia\" e \"educa\u00e7\u00e3o\")."},{"location":"aulas/IA/lab02/classificacao-ml-completa-old.html#2-representacao-do-problema-probabilistica-vs-deterministica","title":"2. Representa\u00e7\u00e3o do problema: probabil\u00edstica vs determin\u00edstica","text":"<ul> <li>Modelos probabil\u00edsticos retornam P(y|x) (ex.: LogisticRegression, Naive Bayes).</li> <li>Modelos determin\u00edsticos entregam um r\u00f3tulo diretamente (ex.: alguns trees sem probabilidade bem calibrada).</li> </ul> <p>Probabilidades permitem ajustar limiares e tomar decis\u00f5es custo-sensitivas.</p> Por que probabilidades preditas s\u00e3o \u00fateis em vez de r\u00f3tulos diretos?Porque s\u00e3o mais r\u00e1pidas de computarPorque permitem ajustar limiares e tomar decis\u00f5es custo-sensitivasPorque evitam overfittingPorque convertem modelos em regress\u00e3oSubmit Probabilidades possibilitam escolher thresholds diferentes para otimizar precis\u00e3o, recall ou custo esperado; tamb\u00e9m s\u00e3o essenciais para calibra\u00e7\u00e3o."},{"location":"aulas/IA/lab02/classificacao-ml-completa-old.html#3-metricas-e-interpretacao-da-matriz-de-confusao","title":"3. M\u00e9tricas e interpreta\u00e7\u00e3o da matriz de confus\u00e3o","text":"<p>Confusion matrix (bin\u00e1ria):</p> <ul> <li>True Positive (TP)</li> <li>False Positive (FP)</li> <li>True Negative (TN)</li> <li>False Negative (FN)</li> </ul> <p>Deixando claro:</p> <ul> <li>Acur\u00e1cia = (TP + TN) / total</li> <li>Precis\u00e3o = TP / (TP + FP)</li> <li>Recall (sensibilidade) = TP / (TP + FN)</li> <li>Especificidade = TN / (TN + FP)</li> </ul> <p>F1 = 2 * (precis\u00e3o * recall) / (precis\u00e3o + recall) \u2014 \u00fatil com classes desbalanceadas.</p> <p>ROC e AUC: curva entre True Positive Rate vs False Positive Rate para v\u00e1rios thresholds.</p> <p>Precision-Recall curve: mais informativa quando as classes s\u00e3o desbalanceadas.</p> <p>Log loss (cross-entropy): penaliza previs\u00f5es probabil\u00edsticas erradas \u2014 \u00fatil para modelos calibrados.</p> Em cen\u00e1rio com classes muito desbalanceadas, qual curva tende a ser mais informativa?ROCPrecision-RecallCurva de calibra\u00e7\u00e3oCurva de aprendizagemSubmit Quando a classe positiva \u00e9 rara, PRC destaca o trade-off entre precis\u00e3o e recall sem ser influenciada pelo grande n\u00famero de verdadeiros negativos."},{"location":"aulas/IA/lab02/classificacao-ml-completa-old.html#4-pre-processamento-e-engenharia-de-features","title":"4. Pr\u00e9-processamento e engenharia de features","text":"<ul> <li>Escalonamento: padronizar ou normalizar \u00e9 importante para KNN, SVM, regress\u00e3o log\u00edstica com regulariza\u00e7\u00e3o.</li> <li>Codifica\u00e7\u00e3o categ\u00f3rica: One-Hot, Ordinal, Target Encoding (com cuidado para evitar vazamento).</li> <li>Dados faltantes: imputa\u00e7\u00e3o (median, mean, model-based).</li> <li>Extra\u00e7\u00e3o de features: intera\u00e7\u00f5es, polin\u00f4mios (com parcim\u00f4nia), embeddings para texto/categ\u00f3ricos.</li> </ul> <p>Boas pr\u00e1ticas:</p> <ul> <li>Encapsular transforma\u00e7\u00f5es em um Pipeline \u2014 evita vazamento de informa\u00e7\u00e3o.</li> <li>Aplicar transforma\u00e7\u00e3o apenas no conjunto de treino durante valida\u00e7\u00e3o cruzada.</li> </ul> Por que usar `Pipeline` do scikit-learn?Para treinar m\u00faltiplos modelos sequenciaisPara encapsular pr\u00e9-processamento e estimador evitando vazamento durante valida\u00e7\u00e3oPara paralelizar o treinamento em GPUPara converter regress\u00e3o em classifica\u00e7\u00e3oSubmit Pipeline garante que as transforma\u00e7\u00f5es (fit/transform) sejam aplicadas corretamente apenas com dados de treino em cada fold, mantendo reprodutibilidade."},{"location":"aulas/IA/lab02/classificacao-ml-completa-old.html#5-estrategias-de-validacao","title":"5. Estrat\u00e9gias de valida\u00e7\u00e3o","text":"<ul> <li>Holdout simples: r\u00e1pido, mas vari\u00e1vel.</li> <li>Stratified K-Fold: preserva propor\u00e7\u00e3o das classes em cada fold \u2014 padr\u00e3o para classifica\u00e7\u00e3o.</li> <li>GroupKFold: quando h\u00e1 depend\u00eancias por grupo (ex.: pacientes).</li> <li>Nested CV: para estimates de generaliza\u00e7\u00e3o honestos ao ajustar hiperpar\u00e2metros.</li> </ul> <p>Exemplo r\u00e1pido: StratifiedKFold para compara\u00e7\u00e3o entre modelos.</p>"},{"location":"aulas/IA/lab02/classificacao-ml-completa-old.html#6-desequilibrio-de-classes","title":"6. Desequil\u00edbrio de classes","text":"<p>Problema comum em detec\u00e7\u00e3o de anomalias, fraude, medicina.</p> <p>Abordagens:</p> <ul> <li>Alterar m\u00e9trica (usar F1, PR AUC)</li> <li>Penaliza\u00e7\u00e3o/weights no treino (class_weight) \u2014 simples e eficaz</li> <li>Reamostragem: oversampling (SMOTE), undersampling, combina\u00e7\u00e3o</li> <li>Algoritmos especializados: anomaly detection, one-class SVM</li> </ul> O que o SMOTE faz?Remove amostras da classe majorit\u00e1riaGera novas amostras sint\u00e9ticas da classe minorit\u00e1riaAjusta pesos de classe automaticamenteAplica regulariza\u00e7\u00e3o L1 nas featuresSubmit SMOTE cria novos pontos sint\u00e9ticos interpolando entre exemplos minorit\u00e1rios \u2014 ajuda a fornecer mais variedade para o modelo aprender."},{"location":"aulas/IA/lab02/classificacao-ml-completa-old.html#7-modelos-e-regularizacao","title":"7. Modelos e regulariza\u00e7\u00e3o","text":"<ul> <li>Regress\u00e3o Log\u00edstica: linear, probabil\u00edstica, interpret\u00e1vel; regulariza\u00e7\u00e3o L2 (por padr\u00e3o) ou L1 para sele\u00e7\u00e3o de features.</li> <li>SVM: margens \u00f3timas; escolha de kernel permite separar dados n\u00e3o lineares; sens\u00edvel \u00e0 escala e custo computacional.</li> <li>\u00c1rvores/Ensembles: RandomForest, GradientBoosting \u2014 robustos, pouco pr\u00e9-processamento, poderosos em tabulares.</li> </ul> <p>Regulariza\u00e7\u00e3o controla complexidade e previne overfitting. L1 promove sparsity; L2 encolhe coeficientes.</p>"},{"location":"aulas/IA/lab02/classificacao-ml-completa-old.html#8-calibracao-de-probabilidades","title":"8. Calibra\u00e7\u00e3o de probabilidades","text":"<p>Nem todo modelo produz probabilidades bem calibradas. T\u00e9cnicas:</p> <ul> <li>Platt scaling (sigmoide) \u2014 usa uma regress\u00e3o log\u00edstica nos scores do modelo.</li> <li>Isotonic regression \u2014 n\u00e3o param\u00e9trico, precisa de mais dados.</li> </ul> <p>Calibra\u00e7\u00e3o \u00e9 importante quando probabilidades s\u00e3o usadas em decis\u00f5es custo-sensitivas.</p> Qual t\u00e9cnica de calibra\u00e7\u00e3o \u00e9 n\u00e3o-param\u00e9trica?Platt scalingIsotonic regressionRegulariza\u00e7\u00e3o L2MinMax scalingSubmit Isotonic regression ajusta uma fun\u00e7\u00e3o monot\u00f4nica n\u00e3o-param\u00e9trica entre scores e probabilidades observadas; \u00e9 flex\u00edvel, mas requer dados."},{"location":"aulas/IA/lab02/classificacao-ml-completa-old.html#9-estrategias-de-thresholding-e-custo","title":"9. Estrat\u00e9gias de thresholding e custo","text":"<ul> <li>Ajuste do limiar padr\u00e3o (0.5) pode melhorar performance segundo custos reais.</li> <li>Em problemas com custos assim\u00e9tricos (FP mais caro que FN), otimize uma m\u00e9trica ponderada ou minimize custo esperado.</li> </ul>"},{"location":"aulas/IA/lab02/classificacao-ml-completa-old.html#10-multiclass-estrategias","title":"10. Multiclass: estrat\u00e9gias","text":"<ul> <li>One-vs-Rest (OvR): treina um classificador por classe contra as demais.</li> <li>One-vs-One (OvO): treina classificador por par de classes.</li> <li>Classificadores nativos multiclasses: \u00e1rvores, RandomForest, softmax em regress\u00e3o log\u00edstica multinomial.</li> </ul>"},{"location":"aulas/IA/lab02/classificacao-ml-completa-old.html#11-interpretacao-e-explicabilidade","title":"11. Interpreta\u00e7\u00e3o e explicabilidade","text":"<ul> <li>Coeficientes e odds ratios (em modelos lineares) \u2014 cuidado com escala das features.</li> <li>Import\u00e2ncias de features em \u00e1rvores \u2014 olhar com parcim\u00f4nia (bias para categ\u00f3ricos com muitas categorias).</li> <li>SHAP/LIME: explica\u00e7\u00f5es locais e globais; SHAP tem fundamento te\u00f3rico (valores de Shapley) e \u00e9 robusto.</li> </ul> Qual m\u00e9todo gera explica\u00e7\u00f5es locais e tem base em teoria dos valores de Shapley?LIMESHAPPCAt-SNESubmit SHAP explica contribui\u00e7\u00e3o de cada feature para uma predi\u00e7\u00e3o espec\u00edfica com base em jogos cooperativos (Shapley values)."},{"location":"aulas/IA/lab02/classificacao-ml-completa-old.html#12-pipelines-reproduziveis-e-hiperparametrizacao","title":"12. Pipelines reproduz\u00edveis e hiperparametriza\u00e7\u00e3o","text":"<p>Exemplo de Pipeline com busca por hiperpar\u00e2metros (GridSearchCV) e valida\u00e7\u00e3o estratificada:</p> <pre><code>from sklearn.pipeline import Pipeline\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import StratifiedKFold, GridSearchCV\n\npipe = Pipeline([\n    ('scaler', StandardScaler()),\n    ('clf', LogisticRegression(solver='saga', max_iter=2000))\n])\n\nparam_grid = {\n    'clf__C': [0.01, 0.1, 1, 10],\n    'clf__penalty': ['l1', 'l2']\n}\n\ncv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\nsearch = GridSearchCV(pipe, param_grid, scoring='f1', cv=cv, n_jobs=-1)\nsearch.fit(X_train, y_train)\nprint(search.best_params_)\n</code></pre> <p>Use RandomizedSearchCV ou otimiza\u00e7\u00e3o bayesiana para espa\u00e7os grandes.</p>"},{"location":"aulas/IA/lab02/classificacao-ml-completa-old.html#13-exemplo-pratico-comparacao-rapida-logistic-vs-randomforest","title":"13. Exemplo pr\u00e1tico: compara\u00e7\u00e3o r\u00e1pida (Logistic vs RandomForest)","text":"<pre><code>from sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import precision_recall_fscore_support, roc_auc_score\n\nmodels = {\n    'logreg': LogisticRegression(max_iter=2000, class_weight='balanced'),\n    'rf': RandomForestClassifier(n_estimators=200, class_weight='balanced', n_jobs=-1)\n}\n\nfor name, m in models.items():\n    m.fit(X_train, y_train)\n    probs = m.predict_proba(X_test)[:, 1]\n    preds = m.predict(X_test)\n    p, r, f, _ = precision_recall_fscore_support(y_test, preds, average='binary')\n    auc = roc_auc_score(y_test, probs)\n    print(name, f\"P={p:.3f} R={r:.3f} F1={f:.3f} AUC={auc:.3f}\")\n</code></pre>"},{"location":"aulas/IA/lab02/classificacao-ml-completa-old.html#14-avoiding-data-leakage","title":"14. Avoiding data leakage","text":"<ul> <li>Nunca ajuste o scaler, encoder ou selecionador de features com dados que incluam o conjunto de teste.</li> <li>Fa\u00e7a toda transforma\u00e7\u00e3o dentro do Pipeline ou dentro do loop de CV.</li> </ul>"},{"location":"aulas/IA/lab02/classificacao-ml-completa-old.html#15-deploy-e-monitoramento","title":"15. Deploy e monitoramento","text":"<ul> <li>Monitorar drift de dados e performance (alertas quando m\u00e9tricas ca\u00edrem).</li> <li>Registrar modelos, vers\u00f5es e datestamps (MLflow, DVC).</li> <li>Testes em produ\u00e7\u00e3o: A/B testing, canary releases, thresholds de rollback.</li> </ul>"},{"location":"aulas/IA/lab02/classificacao-ml-completa-old.html#16-questoes-avancadas-leitura-adicional","title":"16. Quest\u00f5es avan\u00e7adas (leitura adicional)","text":"<ul> <li>Aprendizado ativo (active learning) para reduzir r\u00f3tulos necess\u00e1rios.</li> <li>Aprendizado custo-sensitivo e otimiza\u00e7\u00e3o direta de m\u00e9tricas n\u00e3o diferenci\u00e1veis.</li> <li>M\u00e9todos bayesianos para classifica\u00e7\u00e3o e quantifica\u00e7\u00e3o de incerteza.</li> </ul>"},{"location":"aulas/IA/lab02/classificacao-ml-completa-old.html#exercicios-praticos-sugeridos","title":"Exerc\u00edcios pr\u00e1ticos sugeridos","text":"<ol> <li>Implementar Pipeline com StratifiedKFold e GridSearch para LogisticRegression e RandomForest. Compare F1 e PR AUC.</li> <li>Em um dataset desbalanceado, compare class_weight vs SMOTE vs combina\u00e7\u00e3o e relate tempo de treino e performance.</li> <li>Calibrar probabilidades de um classificador (Platt e Isotonic) e comparar Brier score antes/depois.</li> </ol>"},{"location":"aulas/IA/lab02/classificacao-ml-completa-old.html#quizzes-sumario","title":"Quizzes (sum\u00e1rio)","text":"Em problemas de classifica\u00e7\u00e3o, qual \u00e9 o objetivo principal?Estimar um valor num\u00e9rico cont\u00ednuoAtribuir um r\u00f3tulo ou categoria a cada exemploReduzir a dimensionalidade dos dadosGerar novas amostras sint\u00e9ticasSubmit Classifica\u00e7\u00e3o mapeia entradas para classes discretas; regress\u00e3o mapeia para valores cont\u00ednuos. Em valida\u00e7\u00e3o cruzada para classifica\u00e7\u00e3o, qual t\u00e9cnica preserva a propor\u00e7\u00e3o das classes em cada fold?KFold simplesStratifiedKFoldLeaveOneOutTimeSeriesSplitSubmit StratifiedKFold garante que cada fold mantenha a propor\u00e7\u00e3o de classes observada no conjunto completo. O que significa calibrar um modelo de classifica\u00e7\u00e3o?Ajustar o hiperpar\u00e2metro C na regress\u00e3o log\u00edsticaRemover features com baixa import\u00e2nciaAjustar as probabilidades preditas para que representem verdadeiras frequ\u00eanciasAumentar o n\u00famero de \u00e1rvores na florestaSubmit Calibra\u00e7\u00e3o transforma scores do modelo em probabilidades que correspondam \u00e0s frequ\u00eancias observadas (p.ex., 0.8 significa ~80% de chance). O que \u00e9 Nested Cross-Validation usado para?Acelerar o treinamento de modelosObter estimativas de generaliza\u00e7\u00e3o honestas ao ajustar hiperpar\u00e2metrosCalcular probabilidades calibradasBalancear classes automaticamenteSubmit Nested CV envolve uma CV externa para avalia\u00e7\u00e3o e uma CV interna para busca de hiperpar\u00e2metros, evitando vi\u00e9s de otimiza\u00e7\u00e3o. Qual m\u00e9trica \u00e9 mais indicada quando voc\u00ea tem custo alto para falsos positivos e quer controlar a propor\u00e7\u00e3o de previs\u00f5es positivas corretas?RecallPrecis\u00e3oAcur\u00e1ciaROC AUCSubmit Precis\u00e3o (precision) mede a propor\u00e7\u00e3o das previs\u00f5es positivas que s\u00e3o corretas \u2014 \u00fatil quando FP s\u00e3o caros."},{"location":"aulas/IA/lab02/classificacao-ml-completa.html","title":"Classifica\u00e7\u00e3o em Machine Learning","text":"<p>Nesta aula, vamos aprender a treinar modelos de machine learning para problemas de classifica\u00e7\u00e3o, passando por casos bin\u00e1rios, m\u00faltiplas classes e m\u00faltiplos r\u00f3tulos. Tamb\u00e9m vamos entender como selecionar e interpretar as m\u00e9tricas mais adequadas, analisando a matriz de confus\u00e3o e os n\u00edveis de confian\u00e7a das previs\u00f5es.</p>"},{"location":"aulas/IA/lab02/classificacao-ml-completa.html#atividades-praticas","title":"Atividades Pr\u00e1ticas","text":"<p>As seguintes atividades foram preparadas para refor\u00e7ar os conceitos abordados:</p> <ul> <li>Lab 1: Flores Iris   Uma introdu\u00e7\u00e3o aos conceitos b\u00e1sicos de classifica\u00e7\u00e3o, utilizando o famoso dataset Iris para prever a esp\u00e9cie de uma flor.</li> <li>Lab 2: Classifica\u00e7\u00e3o digitos   Uma explora\u00e7\u00e3o mais aprofundada, com foco em problemas multiclasses. O objetivo \u00e9 criar um modelo para identificar d\u00edgitos manuscritos (de 0 a 9) a partir de imagens.</li> <li>Lab 3: classifica\u00e7\u00e3o de renda   Um desafio de classifica\u00e7\u00e3o bin\u00e1ria, onde treinamos um modelo para prever se a renda de uma pessoa \u00e9 superior ou inferior a 50 mil d\u00f3lares por ano, com base em suas caracter\u00edsticas demogr\u00e1ficas.</li> </ul>"},{"location":"aulas/IA/lab02/classificacao-ml-completa.html#datasets","title":"Datasets","text":"<p>Os laborat\u00f3rios utilizam os seguintes conjuntos de dados: - renda: Dataset de caracter\u00edsticas demogr\u00e1ficas, utilizado no Lab 3 para o problema de classifica\u00e7\u00e3o de renda.</p>"},{"location":"aulas/IA/lab02/classificacao-ml-completa.html#o-que-e-classificacao","title":"O que \u00e9 Classifica\u00e7\u00e3o?","text":"<p>A classifica\u00e7\u00e3o em Machine Learning \u00e9 uma tarefa em que o objetivo do modelo \u00e9 prever a qual categoria ou classe um determinado exemplo pertence, a partir de suas caracter\u00edsticas (tamb\u00e9m chamadas de features).</p> <p>Pense nela como um processo de tomada de decis\u00e3o automatizada: o modelo analisa padr\u00f5es nos dados de treinamento e aprende regras internas que o ajudam a classificar novos exemplos corretamente.</p>"},{"location":"aulas/IA/lab02/classificacao-ml-completa.html#tipos-de-problemas-de-classificacao","title":"Tipos de Problemas de Classifica\u00e7\u00e3o","text":"<ol> <li> <p>Classifica\u00e7\u00e3o bin\u00e1ria \u2013 Quando existem apenas duas classes poss\u00edveis. Exemplo: detectar se um e-mail \u00e9 \u201cspam\u201d ou \u201cn\u00e3o spam\u201d.</p> </li> <li> <p>Classifica\u00e7\u00e3o multiclasses \u2013 Quando h\u00e1 mais de duas classes e cada exemplo pertence a apenas uma delas. Exemplo: identificar o g\u00eanero de um filme como \u201ccom\u00e9dia\u201d, \u201cdrama\u201d ou \u201ca\u00e7\u00e3o\u201d.</p> </li> </ol> <p>A classifica\u00e7\u00e3o pode ser aplicada em diversas \u00e1reas, como:</p> <ul> <li>Sa\u00fade (diagn\u00f3stico de doen\u00e7as)</li> <li>Ind\u00fastria (detec\u00e7\u00e3o de falhas)</li> <li>Finan\u00e7as (an\u00e1lise de risco)</li> <li>Reconhecimento de imagens</li> <li>Processamento de linguagem natural</li> </ul>"},{"location":"aulas/IA/lab02/classificacao-ml-completa.html#como-funciona-o-treinamento","title":"Como Funciona o Treinamento","text":"<p>No aprendizado supervisionado de um modelo de classifica\u00e7\u00e3o, trabalhamos com dois conjuntos de dados:</p> <ul> <li>Conjunto de Treinamento: \u00c9 o conjunto de dados rotulados (com as respostas corretas) que usamos para ensinar o modelo a reconhecer padr\u00f5es. O modelo \"aprende\" a mapear as caracter\u00edsticas de entrada para suas respectivas classes de sa\u00edda.</li> </ul> <p>--Conjunto de Teste: \u00c9 um conjunto de dados completamente novo, n\u00e3o utilizado durante o treinamento. Ele serve para avaliar se o modelo aprendeu bem e consegue generalizar para dados que ele nunca viu antes, simulando o uso no mundo re</p>"},{"location":"aulas/IA/lab02/classificacao-ml-completa.html#principais-algoritimos-de-classificacao","title":"Principais algoritimos de classifica\u00e7\u00e3o","text":"<p>Existem diferentes tipos de algoritimos para classifica\u00e7\u00e3o, entre os mais usados, temos:</p> <ul> <li>K-Nearest Neighbors (KNN) \u2192 Baseado em proximidade no espa\u00e7o das features.</li> <li>\u00c1rvores de Decis\u00e3o e Random Forests \u2192 Divis\u00e3o hier\u00e1rquica de dados com regras.</li> <li>Naive Bayes \u2192 Baseado em probabilidade condicional.</li> <li>Regress\u00e3o Log\u00edstica \u2192 Modelo estat\u00edstico para classifica\u00e7\u00e3o bin\u00e1ria.</li> <li>Support Vector Machines (SVM) \u2192 Cria hiperplanos separadores.</li> <li>Redes Neurais \u2192 Aprendem representa\u00e7\u00f5es complexas.</li> </ul>"},{"location":"aulas/IA/lab02/classificacao-ml-completa.html#exemplo-em-python","title":"Exemplo em Python","text":"<pre><code>from sklearn.datasets import load_iris\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.tree import DecisionTreeClassifier\n\n# Carregar dataset\ndata = load_iris()\nX_train, X_test, y_train, y_test = train_test_split(\n    data.data, data.target, test_size=0.3, random_state=42\n)\n\n# Treinar modelo\nmodel = DecisionTreeClassifier()\nmodel.fit(X_train, y_train)\n\n# Fazer previs\u00f5es\ny_pred = model.predict(X_test)\n\n# Avaliar resultados\nprint(f\"A classe predita \u00e9: {y_pred}\")\n</code></pre>"},{"location":"aulas/IA/lab02/classificacao-ml-completa.html#metricas-de-avaliacao","title":"M\u00e9tricas de avalia\u00e7\u00e3o","text":"<p>Para saber se o nosso modelo \u00e9 bom, precisamos avaliar o seu desempenho. A forma mais comum de fazer isso \u00e9 usando m\u00e9tricas de avalia\u00e7\u00e3o, que nos ajudam a entender n\u00e3o apenas quantos acertos o modelo teve, mas tamb\u00e9m os tipos de erros que ele cometeu.</p>"},{"location":"aulas/IA/lab02/classificacao-ml-completa.html#matriz-de-confusao","title":"Matriz de Confus\u00e3o","text":"<p>A matriz de confus\u00e3o \u00e9 uma ferramenta fundamental para visualizar o desempenho de um classificador. Ela resume os resultados do modelo em uma tabela, comparando as previs\u00f5es com os valores reais. Para problemas bin\u00e1rios, a matriz tem a seguinte estrutura:</p> Predi\u00e7\u00e3o: Positivo Predi\u00e7\u00e3o: Negativo Real: Positivo Verdadeiro Positivo (VP) Falso Negativo (FN) Real: Negativo Falso Positivo (FP) Verdadeiro Negativo (VN) <p>onde: </p> <ul> <li>Verdadeiro Positivo (VP): O modelo previu a classe positiva e a classe real era positiva. (Acerto)</li> <li>Verdadeiro Negativo (VN): O modelo previu a classe negativa e a classe real era negativa. (Acerto)</li> <li>Falso Positivo (FP): O modelo previu a classe positiva, mas a classe real era negativa. (Erro tipo I)</li> <li>Falso Negativo (FN): O modelo previu a classe negativa, mas a classe real era positiva. (Erro tipo II)</li> </ul> <p>A partir da matriz de confus\u00e3o, podemos calcular as m\u00e9tricas mais comuns:</p>"},{"location":"aulas/IA/lab02/classificacao-ml-completa.html#1-acuracia-accuracy","title":"1. Acur\u00e1cia (Accuracy)","text":"<p>Mede a propor\u00e7\u00e3o total de previs\u00f5es corretas. \u00c9 a m\u00e9trica mais simples, mas pode ser enganosa em datasets desbalanceados.</p>  \\text{Acur\u00e1cia} = \\frac{VP + VN}{VP + VN + FP + FN}"},{"location":"aulas/IA/lab02/classificacao-ml-completa.html#2-precisao-precision","title":"2. Precis\u00e3o (Precision)","text":"<p>Mede a propor\u00e7\u00e3o de previs\u00f5es positivas que foram realmente corretas. \u00c9 importante quando o custo de um falso positivo \u00e9 alto.</p>  \\text{Precis\u00e3o} = \\frac{VP}{VP + FP}"},{"location":"aulas/IA/lab02/classificacao-ml-completa.html#3-revocacao-recall-sensibilidade-sensitivity","title":"3. Revoca\u00e7\u00e3o (Recall) / Sensibilidade (Sensitivity)","text":"<p>Mede a propor\u00e7\u00e3o de casos positivos reais que o modelo conseguiu identificar corretamente. \u00c9 importante quando o custo de um falso negativo \u00e9 alto.</p>  \\text{Revoca\u00e7\u00e3o} = \\frac{VP}{VP + FN}"},{"location":"aulas/IA/lab02/classificacao-ml-completa.html#4-f1-score","title":"4. F1-Score","text":"<p>\u00c9 a m\u00e9dia harm\u00f4nica entre precis\u00e3o e revoca\u00e7\u00e3o. \u00c9 \u00fatil quando queremos um equil\u00edbrio entre as duas m\u00e9tricas, especialmente em datasets desbalanceados.</p>  \\text{F1-Score} = 2 \\times \\frac{\\text{Precis\u00e3o} \\times \\text{Revoca\u00e7\u00e3o}}{\\text{Precis\u00e3o} + \\text{Revoca\u00e7\u00e3o}}"},{"location":"aulas/IA/lab02/classificacao-ml-completa.html#exemplo-em-python_1","title":"Exemplo em PythonClassifica\u00e7\u00e3o KNN \u2014 ajuste k e explore a fronteira de decis\u00e3oClassifica\u00e7\u00e3o \u2014 Regress\u00e3o Log\u00edstica","text":"<pre><code>from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n\n# --------------------------------------------\n# Supondo que o modelo j\u00e1 foi treinado\n# e que temos:\n# y_test -&gt; classes reais (valores corretos)\n# y_pred -&gt; classes previstas pelo modelo\n# --------------------------------------------\n\n# 1. Calcular a Matriz de Confus\u00e3o\n# Mostra a contagem de acertos e erros para cada classe\nconf_matrix = confusion_matrix(y_test, y_pred)\n\n# 2. Gerar o Relat\u00f3rio de Classifica\u00e7\u00e3o\n# Inclui m\u00e9tricas por classe: Precis\u00e3o, Revoca\u00e7\u00e3o e F1-Score\nreport = classification_report(y_test, y_pred)\n\n# 3. Calcular a Acur\u00e1cia Global\n# Mede a propor\u00e7\u00e3o de previs\u00f5es corretas em rela\u00e7\u00e3o ao total\nacuracia = accuracy_score(y_test, y_pred)\n\n# 4. Exibir os resultados\nprint(\"=== Matriz de Confus\u00e3o ===\")\nprint(conf_matrix)\nprint(\"\\n=== Relat\u00f3rio de Classifica\u00e7\u00e3o ===\")\nprint(report)\nprint(f\"Acur\u00e1cia m\u00e9dia de classifica\u00e7\u00e3o: {acuracia:.2f}\")\n</code></pre> <p>knn</p> <code>k</code>: 5 (\u00edmpares recomendados) ru\u00eddo (dispers\u00e3o): 1.00  ponderar por dist\u00e2ncia (1/d)         mostrar regi\u00e3o de decis\u00e3o        Acur\u00e1cia: \u2014 Regerar dataset Reset x\u2081, x\u2082 no quadrado [0,10] \u00d7 [0,10] \u2022 azul = classe 0 \u2022 vermelho = classe 1 Como funciona <p>       O KNN prev\u00ea a classe de um ponto pela maioria entre seus k vizinhos mais pr\u00f3ximos. A op\u00e7\u00e3o \u201cponderar por dist\u00e2ncia\u201d d\u00e1 mais peso aos vizinhos mais pr\u00f3ximos.       A regi\u00e3o colorida mostra a previs\u00e3o do classificador; os pontos s\u00e3o os dados reais. Ajuste k e o ru\u00eddo para observar overfitting (k pequeno) vs underfitting (k grande).     </p> <p>Regress\u00e3o logistica</p> w\u2081: -1.00 w\u2082: 1.00 b: 0.00 Acur\u00e1cia: \u2014  mostrar regi\u00e3o de probabilidade        Auto-ajustar (gradiente) Reset        x\u2081, x\u2082 em [0,10] \u00d7 [0,10] \u2022 azul = classe 0 \u2022 vermelho = classe 1 \u2022 contorno preto = fronteira p=0.5"},{"location":"aulas/IA/lab02/classificador-knn-old.html","title":"Classificador knn old","text":"<p>S\u00e3o 150 exemplares de flor de \u00edris, pertencentes a tr\u00eas esp\u00e9cies diferentes: setosa, versicolor e virginica, sendo 50 amostras de cada esp\u00e9cie. Os atributos de largura e comprimento de s\u00e9pala e largura e comprimento de p\u00e9tala de cada flor fooram medidos manualmente.</p> In\u00a0[\u00a0]: Copied! <pre>### Sua resposta.....\n</pre> ### Sua resposta.....   In\u00a0[\u00a0]: Copied! <pre># Inicializ\u00e7\u00e3o das bibliotecas\n%matplotlib inline\n\nimport pandas as pd\nimport matplotlib.pyplot as plt\n</pre> # Inicializ\u00e7\u00e3o das bibliotecas %matplotlib inline  import pandas as pd import matplotlib.pyplot as plt  In\u00a0[\u00a0]: Copied! <pre># Caminho do arquivo\nurl = \"https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data\"\n# Define o nome das colunas\nheader = ['sepal_length', 'sepal_width', 'petal_length', 'petal_width', 'species']\n# L\u00ea e carrega o arquivo para a mem\u00f3ria\ndf = pd.read_csv(url, header=None, names=header)\n</pre> # Caminho do arquivo url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data\" # Define o nome das colunas header = ['sepal_length', 'sepal_width', 'petal_length', 'petal_width', 'species'] # L\u00ea e carrega o arquivo para a mem\u00f3ria df = pd.read_csv(url, header=None, names=header) In\u00a0[\u00a0]: Copied! <pre># Retorna um trecho com as 5 primeiras linhas do dataframe\ndf.head()\n</pre> # Retorna um trecho com as 5 primeiras linhas do dataframe df.head() Out[\u00a0]: sepal_length sepal_width petal_length petal_width species 0 5.1 3.5 1.4 0.2 Iris-setosa 1 4.9 3.0 1.4 0.2 Iris-setosa 2 4.7 3.2 1.3 0.2 Iris-setosa 3 4.6 3.1 1.5 0.2 Iris-setosa 4 5.0 3.6 1.4 0.2 Iris-setosa In\u00a0[\u00a0]: Copied! <pre>df.tail()\n</pre> df.tail() Out[\u00a0]: sepal_length sepal_width petal_length petal_width species 145 6.7 3.0 5.2 2.3 Iris-virginica 146 6.3 2.5 5.0 1.9 Iris-virginica 147 6.5 3.0 5.2 2.0 Iris-virginica 148 6.2 3.4 5.4 2.3 Iris-virginica 149 5.9 3.0 5.1 1.8 Iris-virginica In\u00a0[\u00a0]: Copied! <pre># Mostra informa\u00e7\u00f5es sobre o dataframe em si\ndf.info()\n</pre> # Mostra informa\u00e7\u00f5es sobre o dataframe em si df.info() <pre>&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 150 entries, 0 to 149\nData columns (total 5 columns):\n #   Column        Non-Null Count  Dtype  \n---  ------        --------------  -----  \n 0   sepal_length  150 non-null    float64\n 1   sepal_width   150 non-null    float64\n 2   petal_length  150 non-null    float64\n 3   petal_width   150 non-null    float64\n 4   species       150 non-null    object \ndtypes: float64(4), object(1)\nmemory usage: 6.0+ KB\n</pre> In\u00a0[\u00a0]: Copied! <pre># class distribution\nprint(df.groupby('species').size())\n</pre> # class distribution print(df.groupby('species').size()) <pre>species\nIris-setosa        50\nIris-versicolor    50\nIris-virginica     50\ndtype: int64\n</pre> In\u00a0[\u00a0]: Copied! <pre>## Sua resposta e seus gr\u00e1ficos para an\u00e1lisar..\n</pre> ## Sua resposta e seus gr\u00e1ficos para an\u00e1lisar..       In\u00a0[\u00a0]: Copied! <pre># Selecionando um sub-dataframe com os campos petal_length e petal_width, \n# e outro com a vari\u00e1vel de classes\nentradas = df[['petal_length', 'petal_width']]\nclasses = df['species']\nprint(f\"Formato das tabelas de dados {entradas.shape} e classes {classes.shape}\")\n</pre> # Selecionando um sub-dataframe com os campos petal_length e petal_width,  # e outro com a vari\u00e1vel de classes entradas = df[['petal_length', 'petal_width']] classes = df['species'] print(f\"Formato das tabelas de dados {entradas.shape} e classes {classes.shape}\") <pre>Formato das tabelas de dados (150, 2) e classes (150,)\n</pre> In\u00a0[\u00a0]: Copied! <pre># Separamos 20% para o teste\nfrom sklearn.model_selection import train_test_split\n\nentradas_treino, entradas_teste, classes_treino, classes_teste = train_test_split(entradas, classes, test_size=0.2)\n\nprint(f\"Formato das tabelas de dados de treino {entradas_treino.shape} e teste {entradas_teste.shape}\")\n</pre> # Separamos 20% para o teste from sklearn.model_selection import train_test_split  entradas_treino, entradas_teste, classes_treino, classes_teste = train_test_split(entradas, classes, test_size=0.2)  print(f\"Formato das tabelas de dados de treino {entradas_treino.shape} e teste {entradas_teste.shape}\") <pre>Formato das tabelas de dados de treino (120, 2) e teste (30, 2)\n</pre> In\u00a0[\u00a0]: Copied! <pre>#Primeiras linhas do dataframe \nentradas_treino.head()\n</pre> #Primeiras linhas do dataframe  entradas_treino.head() Out[\u00a0]: petal_length petal_width 31 1.5 0.4 120 5.7 2.3 93 3.3 1.0 5 1.7 0.4 102 5.9 2.1 In\u00a0[\u00a0]: Copied! <pre>classes_treino.head()\n</pre> classes_treino.head() Out[\u00a0]: <pre>31         Iris-setosa\n120     Iris-virginica\n93     Iris-versicolor\n5          Iris-setosa\n102     Iris-virginica\nName: species, dtype: object</pre> In\u00a0[\u00a0]: Copied! <pre># Importa a biblioteca\nfrom sklearn.neighbors import KNeighborsClassifier\n\n# Cria o classificar KNN\nk = 9\nmodelo = KNeighborsClassifier(n_neighbors=k)\n\n# Cria o modelo de machine learning\nmodelo.fit(entradas_treino, classes_treino)\n</pre> # Importa a biblioteca from sklearn.neighbors import KNeighborsClassifier  # Cria o classificar KNN k = 9 modelo = KNeighborsClassifier(n_neighbors=k)  # Cria o modelo de machine learning modelo.fit(entradas_treino, classes_treino)    Out[\u00a0]: <pre>KNeighborsClassifier(n_neighbors=9)</pre> <p>Pronto!! bora testar se esta funcionando....</p> In\u00a0[\u00a0]: Copied! <pre># Para obter as previs\u00f5es, basta chamar o m\u00e9todo predict()\nclasses_encontradas = modelo.predict(entradas_teste)\nprint(\"Predi\u00e7\u00e3o: {}\".format(classes_encontradas))\n</pre> # Para obter as previs\u00f5es, basta chamar o m\u00e9todo predict() classes_encontradas = modelo.predict(entradas_teste) print(\"Predi\u00e7\u00e3o: {}\".format(classes_encontradas)) <pre>Predi\u00e7\u00e3o: ['Iris-virginica' 'Iris-virginica' 'Iris-virginica' 'Iris-virginica'\n 'Iris-virginica' 'Iris-virginica' 'Iris-versicolor' 'Iris-virginica'\n 'Iris-versicolor' 'Iris-versicolor' 'Iris-versicolor' 'Iris-versicolor'\n 'Iris-virginica' 'Iris-setosa' 'Iris-versicolor' 'Iris-setosa'\n 'Iris-versicolor' 'Iris-setosa' 'Iris-virginica' 'Iris-setosa'\n 'Iris-virginica' 'Iris-setosa' 'Iris-versicolor' 'Iris-versicolor'\n 'Iris-setosa' 'Iris-virginica' 'Iris-versicolor' 'Iris-virginica'\n 'Iris-versicolor' 'Iris-virginica']\n</pre> In\u00a0[\u00a0]: Copied! <pre># Para determinar a quantidade de acertos (acuracia)\n\nfrom sklearn.metrics import accuracy_score\nacertos = accuracy_score(classes_teste, classes_encontradas)\nprint(\"Acerto m\u00e9dio de classifica\u00e7\u00e3o: \", acertos)\n</pre> # Para determinar a quantidade de acertos (acuracia)  from sklearn.metrics import accuracy_score acertos = accuracy_score(classes_teste, classes_encontradas) print(\"Acerto m\u00e9dio de classifica\u00e7\u00e3o: \", acertos) <pre>Acerto m\u00e9dio de classifica\u00e7\u00e3o:  0.9666666666666667\n</pre> In\u00a0[\u00a0]: Copied! <pre># Criamos um modelo utilizando duas entradas e uma saida, logo temos que passar duas entradas para o modelo fa\u00e7a a predi\u00e7\u00e3o. \n\nmodelo.predict([[3.3, 3.2]])\n</pre> # Criamos um modelo utilizando duas entradas e uma saida, logo temos que passar duas entradas para o modelo fa\u00e7a a predi\u00e7\u00e3o.   modelo.predict([[3.3, 3.2]]) Out[\u00a0]: <pre>array(['Iris-versicolor'], dtype=object)</pre> In\u00a0[\u00a0]: Copied! <pre># Unificamos os dados de entrada e as classes de treino e teste em um daframe cada\ndf_treino = pd.concat((entradas_treino, classes_treino), axis=1)\n\nnovas_classes = pd.Series(classes_encontradas, name=\"species\", index=entradas_teste.index)\ndf_teste = pd.concat((entradas_teste, novas_classes), axis=1)\n</pre> # Unificamos os dados de entrada e as classes de treino e teste em um daframe cada df_treino = pd.concat((entradas_treino, classes_treino), axis=1)  novas_classes = pd.Series(classes_encontradas, name=\"species\", index=entradas_teste.index) df_teste = pd.concat((entradas_teste, novas_classes), axis=1) In\u00a0[\u00a0]: Copied! <pre>import seaborn as sns\n## Unificamos os dataframes de treinamento e teste em um novo DataFrame\n# indicando a origem dos dados\nnovo_df = pd.concat((df_treino, df_teste), keys=['train', 'test'])\nnovo_df['origin'] = ''\nnovo_df.loc['train','origin'] = 'Treino'\nnovo_df.loc['test','origin'] = 'Teste'\n\n# Usamos o scatterplot do seaborn, informando mudando o marcador de acordo com a origem do dado\nsns.scatterplot('petal_length', 'petal_width', hue='species', style='origin', data=novo_df)\n\nplt.show()\n</pre> import seaborn as sns ## Unificamos os dataframes de treinamento e teste em um novo DataFrame # indicando a origem dos dados novo_df = pd.concat((df_treino, df_teste), keys=['train', 'test']) novo_df['origin'] = '' novo_df.loc['train','origin'] = 'Treino' novo_df.loc['test','origin'] = 'Teste'  # Usamos o scatterplot do seaborn, informando mudando o marcador de acordo com a origem do dado sns.scatterplot('petal_length', 'petal_width', hue='species', style='origin', data=novo_df)  plt.show() <pre>c:\\Users\\junior\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\seaborn\\_decorators.py:36: FutureWarning: Pass the following variables as keyword args: x, y. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n  warnings.warn(\n</pre> In\u00a0[\u00a0]: Copied! <pre>### Implemente sua sua solu\u00e7\u00e3o.....\n</pre> ### Implemente sua sua solu\u00e7\u00e3o.....       In\u00a0[\u00a0]: Copied! <pre>#### Resposta loop for para diferntes k\nk_range = list(range(1,26))\nacertos = []\nfor k in k_range:\n    modelo = KNeighborsClassifier(n_neighbors=k)\n    modelo.fit(entradas_treino, classes_treino)\n    classes_encontradas = modelo.predict(entradas_teste)\n    acertos.append(accuracy_score(classes_teste, classes_encontradas))\n  \n  \nplt.plot(k_range, acertos)\nplt.xlabel('Valor de k do KNN')\nplt.ylabel('Taxa de acertos')\nplt.title('Taxa de acertos x valor de k do KNN')\nplt.show()\n</pre> #### Resposta loop for para diferntes k k_range = list(range(1,26)) acertos = [] for k in k_range:     modelo = KNeighborsClassifier(n_neighbors=k)     modelo.fit(entradas_treino, classes_treino)     classes_encontradas = modelo.predict(entradas_teste)     acertos.append(accuracy_score(classes_teste, classes_encontradas))       plt.plot(k_range, acertos) plt.xlabel('Valor de k do KNN') plt.ylabel('Taxa de acertos') plt.title('Taxa de acertos x valor de k do KNN') plt.show()  In\u00a0[\u00a0]: Copied! <pre>## implemente sua sua solu\u00e7\u00e3o....\n</pre> ## implemente sua sua solu\u00e7\u00e3o....     In\u00a0[\u00a0]: Copied! <pre># implemente sua solu\u00e7\u00e3o......\n</pre> # implemente sua solu\u00e7\u00e3o......"},{"location":"aulas/IA/lab02/classificador-knn-old.html#objetivos","title":"Objetivos\u00b6","text":"<ul> <li>Apresentar e utilizar o classificador k-nearest neighbours (kNN)</li> <li>Apresentar a t\u00e9cnica de separa\u00e7\u00e3o de dados (treino e teste)</li> <li>Avaliar Aprendizagem do modelo</li> </ul>"},{"location":"aulas/IA/lab02/classificador-knn-old.html#comecando","title":"Come\u00e7ando\u00b6","text":"<p>Vamos dar continuidade ao nosso estudo de aprendizagem de m\u00e1quina, j\u00e1 vimos:</p> <ul> <li>Tudo come\u00e7a, conhecendo os dados dispon\u00edveis.</li> <li>Como carregar um data frame</li> <li>Como visualizar os dados em gr\u00e1ficos (histograma, box plot, violin plot, matriz de confus\u00e3o)</li> <li>Fizemos uma breve introdu\u00e7\u00e3o sobre an\u00e1lise explorat\u00f3ria buscando correlacionar os dados para gerar informa\u00e7\u00f5es.</li> </ul> <p>Hoje, vamos seguir nossa jornada e finalizar nosso estudo aplicando a t\u00e9cnica de KNN.</p>"},{"location":"aulas/IA/lab02/classificador-knn-old.html#k-nearest-neighbors","title":"k-Nearest Neighbors\u00b6","text":"<p>O KNN(K vizinhos mais pr\u00f3ximos) \u00e9 considerado um dos algoritmos mais simples dentro da categoria de aprendizagem supervisionada sendo muito utilizado para problemas de classifica\u00e7\u00e3o, por\u00e9m tamb\u00e9m pode ser utilizado em problemas de regress\u00e3o.</p> <p>Problemas de classifica\u00e7\u00e3o = Vale lembrar que em problemas de classifica\u00e7\u00e3o n\u00e3o estamos interessados em valores exatos, queremos apenas saber se um dado pertence ou n\u00e3o a uma dada classe.</p>"},{"location":"aulas/IA/lab02/classificador-knn-old.html#uma-intuicao-sobre-o-metodo","title":"Uma intui\u00e7\u00e3o sobre o m\u00e9todo\u00b6","text":"<p>Para realizar a classifica\u00e7\u00e3o o KNN calcula a dist\u00e2ncia objeto desconhecido (target) para todos os outros elementos, encontra os mais K vizinhos mais pr\u00f3ximos faz uma contagem dos r\u00f3tulos e considera que o objeto desconhecido pertence ao r\u00f3tulo de maior contagem.</p> <p>A imagem abaixo exemplifica o funcionamento, mas se ficou um pouco complicado de entender, rode o script python iknn.py e fa\u00e7a algumas simula\u00e7\u00f5es para compreender.</p> <p> </p>"},{"location":"aulas/IA/lab02/classificador-knn-old.html#bora-la","title":"Bora l\u00e1!!\u00b6","text":"<p>Vamos juntos realizar nosso primeiro projeto, do come\u00e7o ao fim, de aprendizagem de m\u00e1quina.</p>"},{"location":"aulas/IA/lab02/classificador-knn-old.html#definicao-do-problema","title":"Defini\u00e7\u00e3o do problema\u00b6","text":"<p>A primeira coisa que precisamos fazer \u00e9 a defini\u00e7\u00e3o do problema. Neste primeiro caso vamos trabalhar com o mesmo dataset da \u00faltima aula, dataset iris. Vamos desenvolver um sistema de machine learning capaz de classificar sua esp\u00e9cie com base nos dimensionais da p\u00e9tala.</p>"},{"location":"aulas/IA/lab02/classificador-knn-old.html#desafio-1","title":"Desafio 1\u00b6","text":"<p>Do ponto de vista de machine learning, que problema \u00e9 esse:</p> <pre><code>Aprendizado supervisionado ou n\u00e3o-supervisionado?</code></pre> <p>R:</p> <pre><code>Classifica\u00e7\u00e3o ou regress\u00e3o?</code></pre> <p>R:</p>"},{"location":"aulas/IA/lab02/classificador-knn-old.html#desafio-2","title":"Desafio 2\u00b6","text":"<p>Aplique os m\u00e9todos que achar conveniente (vimos algumas op\u00e7\u00f5es na \u00faltima aula) para visualizar os dados de forma gr\u00e1fica.</p>"},{"location":"aulas/IA/lab02/classificador-knn-old.html#pare","title":"PARE!!!\u00b6","text":"<p>A an\u00e1lise feita no desafio 2 \u00e9 uma das etapas mais importantes. Caso voc\u00ea tenha pulado essa etapa, volte e fa\u00e7a suas an\u00e1lises.</p> <p>Com essa etapa conclu\u00edda, vamos criar um sub-dataset com os atributos que ser\u00e3o utilizados.</p>"},{"location":"aulas/IA/lab02/classificador-knn-old.html#dividindo-os-dados-em-conjunto-de-treinamento-e-de-testes","title":"Dividindo os dados em conjunto de treinamento e de testes\u00b6","text":"<p>Dividir nosso dataset em dois conjuntos de dados.</p> <pre><code>Treinamento - Representa 80% das amostras do conjunto de dados original,\nTeste - com 20% das amostras</code></pre> <p>Vamos escolher aleatoriamente algumas amostras do conjunto original. Isto pode ser feito com Scikit-Learn usando a fun\u00e7\u00e3o train_test_split()</p> <p>scikit-learn: pip3 install scikit-learn</p>"},{"location":"aulas/IA/lab02/classificador-knn-old.html#chegou-a-hora-de-aplicar-o-modelo-preditivo","title":"Chegou a hora de aplicar o modelo preditivo\u00b6","text":"<p>Treinar um modelo no python \u00e9 simples se usar o Scikit-Learn. Treinar um modelo no Scikit-Learn \u00e9 simples: basta criar o classificador, e chamar o m\u00e9todo fit().</p> <p>Uma observa\u00e7\u00e3o sobre a sintaxe dos classificadores do <code>scikit-learn</code></p> <ul> <li>O m\u00e9todo <code>fit(X,Y)</code> recebe uma matriz ou dataframe X onde cada linha \u00e9 uma amostra de aprendizado, e um array Y contendo as sa\u00eddas esperadas do classificador, seja na forma de texto ou de inteiros</li> <li>O m\u00e9todo <code>predict(X)</code> recebe uma matriz ou dataframe X onde cada linha \u00e9 uma amostra de teste, retornando um array de classes</li> </ul>"},{"location":"aulas/IA/lab02/classificador-knn-old.html#utilizando-o-modelo-treinado-com-amostras-fora-do-dataset","title":"Utilizando o modelo treinado com amostras fora do dataset\u00b6","text":"<p>Vamos colocar alguns valores e ver a predi\u00e7\u00e3o do classificador.</p>"},{"location":"aulas/IA/lab02/classificador-knn-old.html#visualizando-o-modelo-de-forma-grafica","title":"Visualizando o modelo de forma gr\u00e1fica\u00b6","text":""},{"location":"aulas/IA/lab02/classificador-knn-old.html#desafio-3","title":"Desafio 3\u00b6","text":"<p>Fizemos o treinamento para k=3, mude o valor de k e an\u00e1lise a acur\u00e1cia do modelo.</p> <p>Dica: Fa\u00e7a um loop for que varre um range de k, a sa\u00edda pode ser armazenada em uma lista. No final do loop exiba em um gr\u00e1fico.</p>"},{"location":"aulas/IA/lab02/classificador-knn-old.html#desafio-4","title":"Desafio 4\u00b6","text":"<p>Refa\u00e7a os notebook substituindo as entradas (variaveis independentes) e analise se o modelo obtido ficou melhor ou pior.</p>"},{"location":"aulas/IA/lab02/classificador-knn-old.html#desafio-5","title":"Desafio 5\u00b6","text":"<p>Lembra o dataset 'breast_cancer', fa\u00e7a um modelo de predi\u00e7\u00e3o que informa se o c\u00e2ncer \u00e9 maligno ou n\u00e3o.</p>"},{"location":"aulas/IA/lab02/classificador_knn.html","title":"Classificador knn","text":"<p>S\u00e3o 150 exemplares de flor de \u00edris, pertencentes a tr\u00eas esp\u00e9cies diferentes: setosa, versicolor e virginica, sendo 50 amostras de cada esp\u00e9cie. Os atributos de largura e comprimento de s\u00e9pala e largura e comprimento de p\u00e9tala de cada flor fooram medidos manualmente.</p> In\u00a0[\u00a0]: Copied! <pre>### Sua resposta.....\n</pre> ### Sua resposta.....   In\u00a0[\u00a0]: Copied! <pre># Inicializ\u00e7\u00e3o das bibliotecas\n%matplotlib inline\n\nimport pandas as pd\nimport matplotlib.pyplot as plt\n</pre> # Inicializ\u00e7\u00e3o das bibliotecas %matplotlib inline  import pandas as pd import matplotlib.pyplot as plt  In\u00a0[\u00a0]: Copied! <pre># Caminho do arquivo\nurl = \"https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data\"\n# Define o nome das colunas\nheader = ['sepal_length', 'sepal_width', 'petal_length', 'petal_width', 'species']\n# L\u00ea e carrega o arquivo para a mem\u00f3ria\ndf = pd.read_csv(url, header=None, names=header)\n</pre> # Caminho do arquivo url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data\" # Define o nome das colunas header = ['sepal_length', 'sepal_width', 'petal_length', 'petal_width', 'species'] # L\u00ea e carrega o arquivo para a mem\u00f3ria df = pd.read_csv(url, header=None, names=header) In\u00a0[\u00a0]: Copied! <pre># Retorna um trecho com as 5 primeiras linhas do dataframe\ndf.head()\n</pre> # Retorna um trecho com as 5 primeiras linhas do dataframe df.head() Out[\u00a0]: sepal_length sepal_width petal_length petal_width species 0 5.1 3.5 1.4 0.2 Iris-setosa 1 4.9 3.0 1.4 0.2 Iris-setosa 2 4.7 3.2 1.3 0.2 Iris-setosa 3 4.6 3.1 1.5 0.2 Iris-setosa 4 5.0 3.6 1.4 0.2 Iris-setosa In\u00a0[\u00a0]: Copied! <pre>df.tail()\n</pre> df.tail() Out[\u00a0]: sepal_length sepal_width petal_length petal_width species 145 6.7 3.0 5.2 2.3 Iris-virginica 146 6.3 2.5 5.0 1.9 Iris-virginica 147 6.5 3.0 5.2 2.0 Iris-virginica 148 6.2 3.4 5.4 2.3 Iris-virginica 149 5.9 3.0 5.1 1.8 Iris-virginica In\u00a0[\u00a0]: Copied! <pre># Mostra informa\u00e7\u00f5es sobre o dataframe em si\ndf.info()\n</pre> # Mostra informa\u00e7\u00f5es sobre o dataframe em si df.info() <pre>&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 150 entries, 0 to 149\nData columns (total 5 columns):\n #   Column        Non-Null Count  Dtype  \n---  ------        --------------  -----  \n 0   sepal_length  150 non-null    float64\n 1   sepal_width   150 non-null    float64\n 2   petal_length  150 non-null    float64\n 3   petal_width   150 non-null    float64\n 4   species       150 non-null    object \ndtypes: float64(4), object(1)\nmemory usage: 6.0+ KB\n</pre> In\u00a0[\u00a0]: Copied! <pre># class distribution\nprint(df.groupby('species').size())\n</pre> # class distribution print(df.groupby('species').size()) <pre>species\nIris-setosa        50\nIris-versicolor    50\nIris-virginica     50\ndtype: int64\n</pre> In\u00a0[\u00a0]: Copied! <pre>## Sua resposta e seus gr\u00e1ficos para an\u00e1lisar..\n</pre> ## Sua resposta e seus gr\u00e1ficos para an\u00e1lisar..       In\u00a0[\u00a0]: Copied! <pre># Selecionando um sub-dataframe com os campos petal_length e petal_width,\n# e outro com a vari\u00e1vel de classes\nentradas = df[['petal_length', 'petal_width']]\nclasses = df['species']\nprint(f\"Formato das tabelas de dados {entradas.shape} e classes {classes.shape}\")\n</pre> # Selecionando um sub-dataframe com os campos petal_length e petal_width, # e outro com a vari\u00e1vel de classes entradas = df[['petal_length', 'petal_width']] classes = df['species'] print(f\"Formato das tabelas de dados {entradas.shape} e classes {classes.shape}\") <pre>Formato das tabelas de dados (150, 2) e classes (150,)\n</pre> In\u00a0[\u00a0]: Copied! <pre># Separamos 20% para o teste\nfrom sklearn.model_selection import train_test_split\n\nentradas_treino, entradas_teste, classes_treino, classes_teste = train_test_split(entradas, classes, test_size=0.2)\n\nprint(f\"Formato das tabelas de dados de treino {entradas_treino.shape} e teste {entradas_teste.shape}\")\n</pre> # Separamos 20% para o teste from sklearn.model_selection import train_test_split  entradas_treino, entradas_teste, classes_treino, classes_teste = train_test_split(entradas, classes, test_size=0.2)  print(f\"Formato das tabelas de dados de treino {entradas_treino.shape} e teste {entradas_teste.shape}\") <pre>Formato das tabelas de dados de treino (120, 2) e teste (30, 2)\n</pre> In\u00a0[\u00a0]: Copied! <pre>#Primeiras linhas do dataframe\nentradas_treino.head()\n</pre> #Primeiras linhas do dataframe entradas_treino.head() Out[\u00a0]: petal_length petal_width 71 4.0 1.3 78 4.5 1.5 129 5.8 1.6 48 1.5 0.2 148 5.4 2.3 In\u00a0[\u00a0]: Copied! <pre>classes_treino.head()\n</pre> classes_treino.head() Out[\u00a0]: species 71 Iris-versicolor 78 Iris-versicolor 129 Iris-virginica 48 Iris-setosa 148 Iris-virginica dtype: object In\u00a0[\u00a0]: Copied! <pre># Importa a biblioteca\nfrom sklearn.neighbors import KNeighborsClassifier\n\n# Cria o classificar KNN\nk = 9\nmodelo = KNeighborsClassifier(n_neighbors=k)\n\n# Cria o modelo de machine learning\nmodelo.fit(entradas_treino, classes_treino)\n</pre> # Importa a biblioteca from sklearn.neighbors import KNeighborsClassifier  # Cria o classificar KNN k = 9 modelo = KNeighborsClassifier(n_neighbors=k)  # Cria o modelo de machine learning modelo.fit(entradas_treino, classes_treino)    Out[\u00a0]: <pre>KNeighborsClassifier(n_neighbors=9)</pre>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.KNeighborsClassifier<pre>KNeighborsClassifier(n_neighbors=9)</pre> <p>Pronto!! bora testar se esta funcionando....</p> In\u00a0[\u00a0]: Copied! <pre># Para obter as previs\u00f5es, basta chamar o m\u00e9todo predict()\nclasses_encontradas = modelo.predict(entradas_teste)\nprint(\"Predi\u00e7\u00e3o: {}\".format(classes_encontradas))\n</pre> # Para obter as previs\u00f5es, basta chamar o m\u00e9todo predict() classes_encontradas = modelo.predict(entradas_teste) print(\"Predi\u00e7\u00e3o: {}\".format(classes_encontradas)) <pre>Predi\u00e7\u00e3o: ['Iris-setosa' 'Iris-versicolor' 'Iris-setosa' 'Iris-setosa'\n 'Iris-versicolor' 'Iris-versicolor' 'Iris-versicolor' 'Iris-versicolor'\n 'Iris-setosa' 'Iris-setosa' 'Iris-versicolor' 'Iris-versicolor'\n 'Iris-virginica' 'Iris-setosa' 'Iris-versicolor' 'Iris-setosa'\n 'Iris-versicolor' 'Iris-versicolor' 'Iris-virginica' 'Iris-setosa'\n 'Iris-versicolor' 'Iris-virginica' 'Iris-versicolor' 'Iris-versicolor'\n 'Iris-setosa' 'Iris-virginica' 'Iris-setosa' 'Iris-versicolor'\n 'Iris-virginica' 'Iris-setosa']\n</pre> In\u00a0[\u00a0]: Copied! <pre># Para determinar a quantidade de acertos (acuracia)\n\nfrom sklearn.metrics import accuracy_score\nacertos = accuracy_score(classes_teste, classes_encontradas)\nprint(\"Acerto m\u00e9dio de classifica\u00e7\u00e3o: \", acertos)\n</pre> # Para determinar a quantidade de acertos (acuracia)  from sklearn.metrics import accuracy_score acertos = accuracy_score(classes_teste, classes_encontradas) print(\"Acerto m\u00e9dio de classifica\u00e7\u00e3o: \", acertos) <pre>Acerto m\u00e9dio de classifica\u00e7\u00e3o:  0.9333333333333333\n</pre> In\u00a0[\u00a0]: Copied! <pre># Criamos um modelo utilizando duas entradas e uma saida, logo temos que passar duas entradas para o modelo fa\u00e7a a predi\u00e7\u00e3o.\n\nmodelo.predict([[3.3, 3.2]])\n</pre> # Criamos um modelo utilizando duas entradas e uma saida, logo temos que passar duas entradas para o modelo fa\u00e7a a predi\u00e7\u00e3o.  modelo.predict([[3.3, 3.2]]) <pre>/usr/local/lib/python3.10/dist-packages/sklearn/base.py:465: UserWarning: X does not have valid feature names, but KNeighborsClassifier was fitted with feature names\n  warnings.warn(\n</pre> Out[\u00a0]: <pre>array(['Iris-versicolor'], dtype=object)</pre> In\u00a0[\u00a0]: Copied! <pre># Unificamos os dados de entrada e as classes de treino e teste em um daframe cada\ndf_treino = pd.concat((entradas_treino, classes_treino), axis=1)\n\nnovas_classes = pd.Series(classes_encontradas, name=\"species\", index=entradas_teste.index)\ndf_teste = pd.concat((entradas_teste, novas_classes), axis=1)\n</pre> # Unificamos os dados de entrada e as classes de treino e teste em um daframe cada df_treino = pd.concat((entradas_treino, classes_treino), axis=1)  novas_classes = pd.Series(classes_encontradas, name=\"species\", index=entradas_teste.index) df_teste = pd.concat((entradas_teste, novas_classes), axis=1) In\u00a0[\u00a0]: Copied! <pre>import seaborn as sns\n## Unificamos os dataframes de treinamento e teste em um novo DataFrame\n# indicando a origem dos dados\nnovo_df = pd.concat((df_treino, df_teste), keys=['train', 'test'])\nnovo_df['origin'] = ''\nnovo_df.loc['train','origin'] = 'Treino'\nnovo_df.loc['test','origin'] = 'Teste'\n\n# Usamos o scatterplot do seaborn, informando mudando o marcador de acordo com a origem do dado\nsns.scatterplot(x='petal_length', y='petal_width', hue='species', style='origin', data=novo_df)\n\nplt.show()\n</pre> import seaborn as sns ## Unificamos os dataframes de treinamento e teste em um novo DataFrame # indicando a origem dos dados novo_df = pd.concat((df_treino, df_teste), keys=['train', 'test']) novo_df['origin'] = '' novo_df.loc['train','origin'] = 'Treino' novo_df.loc['test','origin'] = 'Teste'  # Usamos o scatterplot do seaborn, informando mudando o marcador de acordo com a origem do dado sns.scatterplot(x='petal_length', y='petal_width', hue='species', style='origin', data=novo_df)  plt.show() In\u00a0[\u00a0]: Copied! <pre>### Implemente sua sua solu\u00e7\u00e3o.....\n</pre> ### Implemente sua sua solu\u00e7\u00e3o.....       In\u00a0[\u00a0]: Copied! <pre>#### Resposta loop for para diferntes k\nk_range = list(range(1,26))\nacertos = []\nfor k in k_range:\n    modelo = KNeighborsClassifier(n_neighbors=k)\n    modelo.fit(entradas_treino, classes_treino)\n    classes_encontradas = modelo.predict(entradas_teste)\n    acertos.append(accuracy_score(classes_teste, classes_encontradas))\n\n\nplt.plot(k_range, acertos)\nplt.xlabel('Valor de k do KNN')\nplt.ylabel('Taxa de acertos')\nplt.title('Taxa de acertos x valor de k do KNN')\nplt.show()\n</pre> #### Resposta loop for para diferntes k k_range = list(range(1,26)) acertos = [] for k in k_range:     modelo = KNeighborsClassifier(n_neighbors=k)     modelo.fit(entradas_treino, classes_treino)     classes_encontradas = modelo.predict(entradas_teste)     acertos.append(accuracy_score(classes_teste, classes_encontradas))   plt.plot(k_range, acertos) plt.xlabel('Valor de k do KNN') plt.ylabel('Taxa de acertos') plt.title('Taxa de acertos x valor de k do KNN') plt.show()  In\u00a0[\u00a0]: Copied! <pre>## implemente sua sua solu\u00e7\u00e3o....\n</pre> ## implemente sua sua solu\u00e7\u00e3o....     In\u00a0[\u00a0]: Copied! <pre># implemente sua solu\u00e7\u00e3o......\n</pre> # implemente sua solu\u00e7\u00e3o......    In\u00a0[\u00a0]: Copied! <pre>### uma solu\u00e7\u00e3o possivel usando o Arvore de decis\u00e3o.\n\nfrom sklearn.tree import DecisionTreeClassifier, plot_tree\n\n# Criando o modelo de \u00e1rvore de decis\u00e3o\ntree_classifier = DecisionTreeClassifier(max_depth=3)\ntree_classifier.fit(entradas_treino, classes_treino)\n\n# Avaliando o modelo\ny_pred = tree_classifier.predict(entradas_teste)\naccuracy = accuracy_score(classes_teste, y_pred)\nprint(\"Acur\u00e1cia do modelo:\", accuracy)\n\nfeature_names = ['sepal length (cm)', 'sepal width (cm)', 'petal length (cm)', 'petal width (cm)']\nclass_names = ['setosa', 'versicolor', 'virginica']\n# Visualizando a \u00e1rvore de decis\u00e3o\nplt.figure(figsize=(20,10))\nplot_tree(tree_classifier, filled=True, feature_names=feature_names, class_names=class_names)\nplt.title('Visualiza\u00e7\u00e3o da \u00c1rvore de Decis\u00e3o do Dataset Iris')\nplt.show()\n</pre>   ### uma solu\u00e7\u00e3o possivel usando o Arvore de decis\u00e3o.  from sklearn.tree import DecisionTreeClassifier, plot_tree  # Criando o modelo de \u00e1rvore de decis\u00e3o tree_classifier = DecisionTreeClassifier(max_depth=3) tree_classifier.fit(entradas_treino, classes_treino)  # Avaliando o modelo y_pred = tree_classifier.predict(entradas_teste) accuracy = accuracy_score(classes_teste, y_pred) print(\"Acur\u00e1cia do modelo:\", accuracy)  feature_names = ['sepal length (cm)', 'sepal width (cm)', 'petal length (cm)', 'petal width (cm)'] class_names = ['setosa', 'versicolor', 'virginica'] # Visualizando a \u00e1rvore de decis\u00e3o plt.figure(figsize=(20,10)) plot_tree(tree_classifier, filled=True, feature_names=feature_names, class_names=class_names) plt.title('Visualiza\u00e7\u00e3o da \u00c1rvore de Decis\u00e3o do Dataset Iris') plt.show()  <pre>Acur\u00e1cia do modelo: 0.9\n</pre>"},{"location":"aulas/IA/lab02/classificador_knn.html#objetivos","title":"Objetivos\u00b6","text":"<ul> <li>Apresentar e utilizar o classificador k-nearest neighbours (kNN)</li> <li>Apresentar a t\u00e9cnica de separa\u00e7\u00e3o de dados (treino e teste)</li> <li>Avaliar Aprendizagem do modelo</li> </ul>"},{"location":"aulas/IA/lab02/classificador_knn.html#comecando","title":"Come\u00e7ando\u00b6","text":"<p>Vamos dar continuidade ao nosso estudo de aprendizagem de m\u00e1quina, j\u00e1 vimos:</p> <ul> <li>Tudo come\u00e7a, conhecendo os dados dispon\u00edveis.</li> <li>Como carregar um data frame</li> <li>Como visualizar os dados em gr\u00e1ficos (histograma, box plot, violin plot, matriz de confus\u00e3o)</li> <li>Fizemos uma breve introdu\u00e7\u00e3o sobre an\u00e1lise explorat\u00f3ria buscando correlacionar os dados para gerar informa\u00e7\u00f5es.</li> </ul> <p>Hoje, vamos seguir nossa jornada e finalizar nosso estudo aplicando a t\u00e9cnica de KNN.</p>"},{"location":"aulas/IA/lab02/classificador_knn.html#k-nearest-neighbors","title":"k-Nearest Neighbors\u00b6","text":"<p>O KNN(K vizinhos mais pr\u00f3ximos) \u00e9 considerado um dos algoritmos mais simples dentro da categoria de aprendizagem supervisionada sendo muito utilizado para problemas de classifica\u00e7\u00e3o, por\u00e9m tamb\u00e9m pode ser utilizado em problemas de regress\u00e3o.</p> <p>Problemas de classifica\u00e7\u00e3o = Vale lembrar que em problemas de classifica\u00e7\u00e3o n\u00e3o estamos interessados em valores exatos, queremos apenas saber se um dado pertence ou n\u00e3o a uma dada classe.</p>"},{"location":"aulas/IA/lab02/classificador_knn.html#uma-intuicao-sobre-o-metodo","title":"Uma intui\u00e7\u00e3o sobre o m\u00e9todo\u00b6","text":"<p>Para realizar a classifica\u00e7\u00e3o o KNN calcula a dist\u00e2ncia objeto desconhecido (target) para todos os outros elementos, encontra os mais K vizinhos mais pr\u00f3ximos faz uma contagem dos r\u00f3tulos e considera que o objeto desconhecido pertence ao r\u00f3tulo de maior contagem.</p> <p>A imagem abaixo exemplifica o funcionamento, mas se ficou um pouco complicado de entender, rode o script python iknn.py e fa\u00e7a algumas simula\u00e7\u00f5es para compreender.</p> <p></p>"},{"location":"aulas/IA/lab02/classificador_knn.html#bora-la","title":"Bora l\u00e1!!\u00b6","text":"<p>Vamos juntos realizar nosso primeiro projeto, do come\u00e7o ao fim, de aprendizagem de m\u00e1quina.</p>"},{"location":"aulas/IA/lab02/classificador_knn.html#definicao-do-problema","title":"Defini\u00e7\u00e3o do problema\u00b6","text":"<p>A primeira coisa que precisamos fazer \u00e9 a defini\u00e7\u00e3o do problema. Neste primeiro caso vamos trabalhar com o mesmo dataset da \u00faltima aula, dataset iris. Vamos desenvolver um sistema de machine learning capaz de classificar sua esp\u00e9cie com base nos dimensionais da p\u00e9tala.</p>"},{"location":"aulas/IA/lab02/classificador_knn.html#desafio-1","title":"Desafio 1\u00b6","text":"<p>Do ponto de vista de machine learning, que problema \u00e9 esse:</p> <pre><code>Aprendizado supervisionado ou n\u00e3o-supervisionado?</code></pre> <p>R:</p> <pre><code>Classifica\u00e7\u00e3o ou regress\u00e3o?</code></pre> <p>R:</p>"},{"location":"aulas/IA/lab02/classificador_knn.html#desafio-2","title":"Desafio 2\u00b6","text":"<p>Aplique os m\u00e9todos que achar conveniente (vimos algumas op\u00e7\u00f5es na \u00faltima aula) para visualizar os dados de forma gr\u00e1fica.</p>"},{"location":"aulas/IA/lab02/classificador_knn.html#pare","title":"PARE!!!\u00b6","text":"<p>A an\u00e1lise feita no desafio 2 \u00e9 uma das etapas mais importantes. Caso voc\u00ea tenha pulado essa etapa, volte e fa\u00e7a suas an\u00e1lises.</p> <p>Com essa etapa conclu\u00edda, vamos criar um sub-dataset com os atributos que ser\u00e3o utilizados.</p>"},{"location":"aulas/IA/lab02/classificador_knn.html#dividindo-os-dados-em-conjunto-de-treinamento-e-de-testes","title":"Dividindo os dados em conjunto de treinamento e de testes\u00b6","text":"<p>Dividir nosso dataset em dois conjuntos de dados.</p> <pre><code>Treinamento - Representa 80% das amostras do conjunto de dados original,\nTeste - com 20% das amostras</code></pre> <p>Vamos escolher aleatoriamente algumas amostras do conjunto original. Isto pode ser feito com Scikit-Learn usando a fun\u00e7\u00e3o train_test_split()</p> <p>scikit-learn: pip3 install scikit-learn</p>"},{"location":"aulas/IA/lab02/classificador_knn.html#chegou-a-hora-de-aplicar-o-modelo-preditivo","title":"Chegou a hora de aplicar o modelo preditivo\u00b6","text":"<p>Treinar um modelo no python \u00e9 simples se usar o Scikit-Learn. Treinar um modelo no Scikit-Learn \u00e9 simples: basta criar o classificador, e chamar o m\u00e9todo fit().</p> <p>Uma observa\u00e7\u00e3o sobre a sintaxe dos classificadores do <code>scikit-learn</code></p> <ul> <li>O m\u00e9todo <code>fit(X,Y)</code> recebe uma matriz ou dataframe X onde cada linha \u00e9 uma amostra de aprendizado, e um array Y contendo as sa\u00eddas esperadas do classificador, seja na forma de texto ou de inteiros</li> <li>O m\u00e9todo <code>predict(X)</code> recebe uma matriz ou dataframe X onde cada linha \u00e9 uma amostra de teste, retornando um array de classes</li> </ul>"},{"location":"aulas/IA/lab02/classificador_knn.html#utilizando-o-modelo-treinado-com-amostras-fora-do-dataset","title":"Utilizando o modelo treinado com amostras fora do dataset\u00b6","text":"<p>Vamos colocar alguns valores e ver a predi\u00e7\u00e3o do classificador.</p>"},{"location":"aulas/IA/lab02/classificador_knn.html#visualizando-o-modelo-de-forma-grafica","title":"Visualizando o modelo de forma gr\u00e1fica\u00b6","text":""},{"location":"aulas/IA/lab02/classificador_knn.html#desafio-3","title":"Desafio 3\u00b6","text":"<p>Fizemos o treinamento para k=3, mude o valor de k e an\u00e1lise a acur\u00e1cia do modelo.</p> <p>Dica: Fa\u00e7a um loop for que varre um range de k, a sa\u00edda pode ser armazenada em uma lista. No final do loop exiba em um gr\u00e1fico.</p>"},{"location":"aulas/IA/lab02/classificador_knn.html#desafio-4","title":"Desafio 4\u00b6","text":"<p>Refa\u00e7a os notebook substituindo as entradas (variaveis independentes) e analise se o modelo obtido ficou melhor ou pior.</p>"},{"location":"aulas/IA/lab02/classificador_knn.html#desafio-5","title":"Desafio 5\u00b6","text":"<p>Fa\u00e7a o treinamento utilizando um algoritimo de ML difernte do KNN, ao final compare os resultados e an\u00e1lise qual modelo obteve uma performance melhor.</p>"},{"location":"aulas/IA/lab02/iknn.html","title":"Iknn","text":"In\u00a0[\u00a0]: Copied! <pre># adaptado de: https://pysource.com/2018/05/22/k-nearest-neighbour-classification-opencv-3-4-with-python-3-tutorial-33/\nimport cv2\nimport numpy as np\n</pre> # adaptado de: https://pysource.com/2018/05/22/k-nearest-neighbour-classification-opencv-3-4-with-python-3-tutorial-33/ import cv2 import numpy as np In\u00a0[\u00a0]: Copied! <pre>def mouse_pos(event, x, y, flags, params):\n\tglobal squares, color, new_element\n\n\tif event == cv2.EVENT_LBUTTONDOWN:\n\t\tif color == \"b\":\n\t\t\tblue_squares.append([x, y])\n\t\telif color == \"r\":\n\t\t\tred_squares.append([x, y])\n\t\telse:\n\t\t\tnew_element = [x, y]\n</pre> def mouse_pos(event, x, y, flags, params): \tglobal squares, color, new_element  \tif event == cv2.EVENT_LBUTTONDOWN: \t\tif color == \"b\": \t\t\tblue_squares.append([x, y]) \t\telif color == \"r\": \t\t\tred_squares.append([x, y]) \t\telse: \t\t\tnew_element = [x, y] In\u00a0[\u00a0]: Copied! <pre># Create Window and Set mouse events\ncv2.namedWindow(\"KNN\")\ncv2.setMouseCallback(\"KNN\", mouse_pos)\n</pre> # Create Window and Set mouse events cv2.namedWindow(\"KNN\") cv2.setMouseCallback(\"KNN\", mouse_pos) In\u00a0[\u00a0]: Copied! <pre># Create an empty image\nimg = np.zeros([500, 700, 3], dtype=np.uint8)\nimg[:] = (255, 255, 255)\n</pre> # Create an empty image img = np.zeros([500, 700, 3], dtype=np.uint8) img[:] = (255, 255, 255) In\u00a0[\u00a0]: Copied! <pre># Load KNN algorythm\nknn = cv2.ml.KNearest_create()\n</pre> # Load KNN algorythm knn = cv2.ml.KNearest_create() In\u00a0[\u00a0]: Copied! <pre># Store all the elements\nblue_squares = []\nred_squares = []\nnew_element = []\nnew_comer = False\ncolor = \"b\"\n</pre> # Store all the elements blue_squares = [] red_squares = [] new_element = [] new_comer = False color = \"b\" In\u00a0[\u00a0]: Copied! <pre># Text Data\nfont = cv2.FONT_HERSHEY_SIMPLEX\nresult = \"None\"\nk = 1\nneighbours = \"None\"\ndist = \"None\"\nwhile True:\n\timg[:] = (255, 255, 255)\n    \n\tcv2.line(img, (0, 330),(700, 330),(0, 0, 0),2)\n\n\tcv2.putText(img, \"CALCULO KNN\", (10, 360), font, 1, (0, 0, 0), 2)\n\tcv2.putText(img, \"Resultado: \" + str(result), (10, 400), font, 1, (0, 0, 0), 2)\n\tcv2.putText(img, \"K: \" + str(k), (10, 440), font, 1, (0, 0, 0), 2)\n\tcv2.putText(img, \"Neighbours: \" + str(neighbours), (10, 470), font, 0.5, (0, 0, 0), 1)\n\tcv2.putText(img, \"Distance: \" + str(dist), (10, 490), font, 0.5, (0, 0, 0), 1)\n\n\tcv2.putText(img, \"Manual:\", (440, 350), font, 0.5, (0, 0, 0), 1)\n\tcv2.putText(img, \"B: Ponto AZUL\", (440, 370), font, 0.5, (0, 0, 0), 1)\n\tcv2.putText(img, \"R: Ponto Vermelho\", (440, 390), font, 0.5, (0, 0, 0), 1)\n\tcv2.putText(img, \"G: Ponto Verde\", (440, 410), font, 0.5, (0, 0, 0), 1)\n\tcv2.putText(img, \"1, 3, 5, 7, 9: muda K\", (440, 430), font, 0.5, (0, 0, 0), 1)\n\tcv2.putText(img, \"C: Calcula\", (440, 450), font, 0.5, (0, 0, 0), 1)\n\tcv2.putText(img, \"D: Deleta, limpa\", (440, 470), font, 0.5, (0, 0, 0), 1)\n\n\t# Show the Squares\n\tfor s in blue_squares:\n\t\tcv2.rectangle(img, (s[0] - 5, s[1] - 5), (s[0] + 5, s[1] + 5), (255, 0, 0), -1)\n\tfor s in red_squares:\n\t\tcv2.rectangle(img, (s[0] - 5, s[1] - 5), (s[0] + 5, s[1] + 5), (0, 0, 255), -1)\n\tif new_element != []:\n\t\tcv2.rectangle(img, (new_element[0] - 5, new_element[1] - 5),\n\t\t(new_element[0] + 5, new_element[1] + 5), (0, 255, 0), -1)\n\n\t# Create element to show\n\n\tcv2.imshow(\"KNN\", img)\n\n\t# Key events to break the loop and to select the color of the squares\n\tkey = cv2.waitKey(25)\n\tif key == 27 or key == ord(\"q\") :\n\t\tbreak\n\telif key == ord(\"b\"):\n\t\tcolor = \"b\"\n\telif key == ord(\"r\"):\n\t\tcolor = \"r\"\n\telif key == ord(\"g\"):\n\t\tcolor = \"g\"\n\t\tnew_comer = True\n\telif key == ord(\"1\"):\n\t\tk = 1\n\telif key == ord(\"2\"):\n\t\tk = 2\n\telif key == ord(\"3\"):\n\t\tk = 3\n\telif key == ord(\"4\"):\n\t\tk = 4\n\telif key == ord(\"5\"):\n\t\tk = 5\n\telif key == ord(\"6\"):\n\t\tk = 6\n\telif key == ord(\"7\"):\n\t\tk = 7\n\telif key == ord(\"8\"):\n\t\tk = 8\n\telif key == ord(\"9\"):\n\t\tk = 9\n\telif key == ord(\"d\"):\n\t\tblue_squares = []\n\t\tred_squares = []\n\t\tnew_element = []\n\telif key == ord(\"c\"):\n\t\ttraindata = np.array(blue_squares + red_squares, dtype=np.float32)\n\t\tblue_responses = np.zeros(len(blue_squares), dtype=np.float32)\n\t\tred_resposnes = np.ones(len(red_squares), dtype=np.float32)\n\t\tresponses = np.concatenate((blue_responses, red_resposnes))\n\n\t\tknn.train(traindata, cv2.ml.ROW_SAMPLE, responses)\n\t\tif new_comer:\n\t\t\tgreen_square = np.array([new_element], dtype=np.float32)\n\n\t\t\tret, results, neighbours, dist = knn.findNearest(green_square, k)\n\n\t\t\tprint(results[0][0])\n\t\t\tprint (results)\n\n\t\t\tif results[0][0] &gt; 0:\n\t\t\t\tresult = \"Red\"\n\t\t\telse:\n\t\t\t\tresult = \"Blue\"\n</pre> # Text Data font = cv2.FONT_HERSHEY_SIMPLEX result = \"None\" k = 1 neighbours = \"None\" dist = \"None\" while True: \timg[:] = (255, 255, 255)      \tcv2.line(img, (0, 330),(700, 330),(0, 0, 0),2)  \tcv2.putText(img, \"CALCULO KNN\", (10, 360), font, 1, (0, 0, 0), 2) \tcv2.putText(img, \"Resultado: \" + str(result), (10, 400), font, 1, (0, 0, 0), 2) \tcv2.putText(img, \"K: \" + str(k), (10, 440), font, 1, (0, 0, 0), 2) \tcv2.putText(img, \"Neighbours: \" + str(neighbours), (10, 470), font, 0.5, (0, 0, 0), 1) \tcv2.putText(img, \"Distance: \" + str(dist), (10, 490), font, 0.5, (0, 0, 0), 1)  \tcv2.putText(img, \"Manual:\", (440, 350), font, 0.5, (0, 0, 0), 1) \tcv2.putText(img, \"B: Ponto AZUL\", (440, 370), font, 0.5, (0, 0, 0), 1) \tcv2.putText(img, \"R: Ponto Vermelho\", (440, 390), font, 0.5, (0, 0, 0), 1) \tcv2.putText(img, \"G: Ponto Verde\", (440, 410), font, 0.5, (0, 0, 0), 1) \tcv2.putText(img, \"1, 3, 5, 7, 9: muda K\", (440, 430), font, 0.5, (0, 0, 0), 1) \tcv2.putText(img, \"C: Calcula\", (440, 450), font, 0.5, (0, 0, 0), 1) \tcv2.putText(img, \"D: Deleta, limpa\", (440, 470), font, 0.5, (0, 0, 0), 1)  \t# Show the Squares \tfor s in blue_squares: \t\tcv2.rectangle(img, (s[0] - 5, s[1] - 5), (s[0] + 5, s[1] + 5), (255, 0, 0), -1) \tfor s in red_squares: \t\tcv2.rectangle(img, (s[0] - 5, s[1] - 5), (s[0] + 5, s[1] + 5), (0, 0, 255), -1) \tif new_element != []: \t\tcv2.rectangle(img, (new_element[0] - 5, new_element[1] - 5), \t\t(new_element[0] + 5, new_element[1] + 5), (0, 255, 0), -1)  \t# Create element to show  \tcv2.imshow(\"KNN\", img)  \t# Key events to break the loop and to select the color of the squares \tkey = cv2.waitKey(25) \tif key == 27 or key == ord(\"q\") : \t\tbreak \telif key == ord(\"b\"): \t\tcolor = \"b\" \telif key == ord(\"r\"): \t\tcolor = \"r\" \telif key == ord(\"g\"): \t\tcolor = \"g\" \t\tnew_comer = True \telif key == ord(\"1\"): \t\tk = 1 \telif key == ord(\"2\"): \t\tk = 2 \telif key == ord(\"3\"): \t\tk = 3 \telif key == ord(\"4\"): \t\tk = 4 \telif key == ord(\"5\"): \t\tk = 5 \telif key == ord(\"6\"): \t\tk = 6 \telif key == ord(\"7\"): \t\tk = 7 \telif key == ord(\"8\"): \t\tk = 8 \telif key == ord(\"9\"): \t\tk = 9 \telif key == ord(\"d\"): \t\tblue_squares = [] \t\tred_squares = [] \t\tnew_element = [] \telif key == ord(\"c\"): \t\ttraindata = np.array(blue_squares + red_squares, dtype=np.float32) \t\tblue_responses = np.zeros(len(blue_squares), dtype=np.float32) \t\tred_resposnes = np.ones(len(red_squares), dtype=np.float32) \t\tresponses = np.concatenate((blue_responses, red_resposnes))  \t\tknn.train(traindata, cv2.ml.ROW_SAMPLE, responses) \t\tif new_comer: \t\t\tgreen_square = np.array([new_element], dtype=np.float32)  \t\t\tret, results, neighbours, dist = knn.findNearest(green_square, k)  \t\t\tprint(results[0][0]) \t\t\tprint (results)  \t\t\tif results[0][0] &gt; 0: \t\t\t\tresult = \"Red\" \t\t\telse: \t\t\t\tresult = \"Blue\" In\u00a0[\u00a0]: Copied! <pre>cv2.destroyAllWindows()\n</pre> cv2.destroyAllWindows()"},{"location":"aulas/IA/lab02/ml-classificador-digito.html","title":"lab2","text":"In\u00a0[1]: Copied! <pre>from sklearn.datasets import load_digits\n\ndigits = load_digits()\n\nprint(digits)\n</pre> from sklearn.datasets import load_digits  digits = load_digits()  print(digits) <pre>{'data': array([[ 0.,  0.,  5., ...,  0.,  0.,  0.],\n       [ 0.,  0.,  0., ..., 10.,  0.,  0.],\n       [ 0.,  0.,  0., ..., 16.,  9.,  0.],\n       ...,\n       [ 0.,  0.,  1., ...,  6.,  0.,  0.],\n       [ 0.,  0.,  2., ..., 12.,  0.,  0.],\n       [ 0.,  0., 10., ..., 12.,  1.,  0.]], shape=(1797, 64)), 'target': array([0, 1, 2, ..., 8, 9, 8], shape=(1797,)), 'frame': None, 'feature_names': ['pixel_0_0', 'pixel_0_1', 'pixel_0_2', 'pixel_0_3', 'pixel_0_4', 'pixel_0_5', 'pixel_0_6', 'pixel_0_7', 'pixel_1_0', 'pixel_1_1', 'pixel_1_2', 'pixel_1_3', 'pixel_1_4', 'pixel_1_5', 'pixel_1_6', 'pixel_1_7', 'pixel_2_0', 'pixel_2_1', 'pixel_2_2', 'pixel_2_3', 'pixel_2_4', 'pixel_2_5', 'pixel_2_6', 'pixel_2_7', 'pixel_3_0', 'pixel_3_1', 'pixel_3_2', 'pixel_3_3', 'pixel_3_4', 'pixel_3_5', 'pixel_3_6', 'pixel_3_7', 'pixel_4_0', 'pixel_4_1', 'pixel_4_2', 'pixel_4_3', 'pixel_4_4', 'pixel_4_5', 'pixel_4_6', 'pixel_4_7', 'pixel_5_0', 'pixel_5_1', 'pixel_5_2', 'pixel_5_3', 'pixel_5_4', 'pixel_5_5', 'pixel_5_6', 'pixel_5_7', 'pixel_6_0', 'pixel_6_1', 'pixel_6_2', 'pixel_6_3', 'pixel_6_4', 'pixel_6_5', 'pixel_6_6', 'pixel_6_7', 'pixel_7_0', 'pixel_7_1', 'pixel_7_2', 'pixel_7_3', 'pixel_7_4', 'pixel_7_5', 'pixel_7_6', 'pixel_7_7'], 'target_names': array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]), 'images': array([[[ 0.,  0.,  5., ...,  1.,  0.,  0.],\n        [ 0.,  0., 13., ..., 15.,  5.,  0.],\n        [ 0.,  3., 15., ..., 11.,  8.,  0.],\n        ...,\n        [ 0.,  4., 11., ..., 12.,  7.,  0.],\n        [ 0.,  2., 14., ..., 12.,  0.,  0.],\n        [ 0.,  0.,  6., ...,  0.,  0.,  0.]],\n\n       [[ 0.,  0.,  0., ...,  5.,  0.,  0.],\n        [ 0.,  0.,  0., ...,  9.,  0.,  0.],\n        [ 0.,  0.,  3., ...,  6.,  0.,  0.],\n        ...,\n        [ 0.,  0.,  1., ...,  6.,  0.,  0.],\n        [ 0.,  0.,  1., ...,  6.,  0.,  0.],\n        [ 0.,  0.,  0., ..., 10.,  0.,  0.]],\n\n       [[ 0.,  0.,  0., ..., 12.,  0.,  0.],\n        [ 0.,  0.,  3., ..., 14.,  0.,  0.],\n        [ 0.,  0.,  8., ..., 16.,  0.,  0.],\n        ...,\n        [ 0.,  9., 16., ...,  0.,  0.,  0.],\n        [ 0.,  3., 13., ..., 11.,  5.,  0.],\n        [ 0.,  0.,  0., ..., 16.,  9.,  0.]],\n\n       ...,\n\n       [[ 0.,  0.,  1., ...,  1.,  0.,  0.],\n        [ 0.,  0., 13., ...,  2.,  1.,  0.],\n        [ 0.,  0., 16., ..., 16.,  5.,  0.],\n        ...,\n        [ 0.,  0., 16., ..., 15.,  0.,  0.],\n        [ 0.,  0., 15., ..., 16.,  0.,  0.],\n        [ 0.,  0.,  2., ...,  6.,  0.,  0.]],\n\n       [[ 0.,  0.,  2., ...,  0.,  0.,  0.],\n        [ 0.,  0., 14., ..., 15.,  1.,  0.],\n        [ 0.,  4., 16., ..., 16.,  7.,  0.],\n        ...,\n        [ 0.,  0.,  0., ..., 16.,  2.,  0.],\n        [ 0.,  0.,  4., ..., 16.,  2.,  0.],\n        [ 0.,  0.,  5., ..., 12.,  0.,  0.]],\n\n       [[ 0.,  0., 10., ...,  1.,  0.,  0.],\n        [ 0.,  2., 16., ...,  1.,  0.,  0.],\n        [ 0.,  0., 15., ..., 15.,  0.,  0.],\n        ...,\n        [ 0.,  4., 16., ..., 16.,  6.,  0.],\n        [ 0.,  8., 16., ..., 16.,  8.,  0.],\n        [ 0.,  1.,  8., ..., 12.,  1.,  0.]]], shape=(1797, 8, 8)), 'DESCR': \".. _digits_dataset:\\n\\nOptical recognition of handwritten digits dataset\\n--------------------------------------------------\\n\\n**Data Set Characteristics:**\\n\\n:Number of Instances: 1797\\n:Number of Attributes: 64\\n:Attribute Information: 8x8 image of integer pixels in the range 0..16.\\n:Missing Attribute Values: None\\n:Creator: E. Alpaydin (alpaydin '@' boun.edu.tr)\\n:Date: July; 1998\\n\\nThis is a copy of the test set of the UCI ML hand-written digits datasets\\nhttps://archive.ics.uci.edu/ml/datasets/Optical+Recognition+of+Handwritten+Digits\\n\\nThe data set contains images of hand-written digits: 10 classes where\\neach class refers to a digit.\\n\\nPreprocessing programs made available by NIST were used to extract\\nnormalized bitmaps of handwritten digits from a preprinted form. From a\\ntotal of 43 people, 30 contributed to the training set and different 13\\nto the test set. 32x32 bitmaps are divided into nonoverlapping blocks of\\n4x4 and the number of on pixels are counted in each block. This generates\\nan input matrix of 8x8 where each element is an integer in the range\\n0..16. This reduces dimensionality and gives invariance to small\\ndistortions.\\n\\nFor info on NIST preprocessing routines, see M. D. Garris, J. L. Blue, G.\\nT. Candela, D. L. Dimmick, J. Geist, P. J. Grother, S. A. Janet, and C.\\nL. Wilson, NIST Form-Based Handprint Recognition System, NISTIR 5469,\\n1994.\\n\\n.. dropdown:: References\\n\\n  - C. Kaynak (1995) Methods of Combining Multiple Classifiers and Their\\n    Applications to Handwritten Digit Recognition, MSc Thesis, Institute of\\n    Graduate Studies in Science and Engineering, Bogazici University.\\n  - E. Alpaydin, C. Kaynak (1998) Cascading Classifiers, Kybernetika.\\n  - Ken Tang and Ponnuthurai N. Suganthan and Xi Yao and A. Kai Qin.\\n    Linear dimensionalityreduction using relevance weighted LDA. School of\\n    Electrical and Electronic Engineering Nanyang Technological University.\\n    2005.\\n  - Claudio Gentile. A New Approximate Maximal Margin Classification\\n    Algorithm. NIPS. 2000.\\n\"}\n</pre> In\u00a0[2]: Copied! <pre># conhecendo todos os atributos carregados em digits\ndigits.keys()\n</pre> # conhecendo todos os atributos carregados em digits digits.keys() Out[2]: <pre>dict_keys(['data', 'target', 'frame', 'feature_names', 'target_names', 'images', 'DESCR'])</pre> In\u00a0[3]: Copied! <pre># definindo X e y \nX = digits.data\ny =  digits.target\n</pre> # definindo X e y  X = digits.data y =  digits.target In\u00a0[4]: Copied! <pre>digits.target\n</pre> digits.target  Out[4]: <pre>array([0, 1, 2, ..., 8, 9, 8], shape=(1797,))</pre> In\u00a0[5]: Copied! <pre># Visualizando os primeiros 10 d\u00edgitos do dataset\nimport matplotlib.pyplot as plt\n\n\nfig, axes = plt.subplots(1, 10, figsize=(10,3))\n\nfor i, ax in enumerate(axes):\n    ax.imshow(digits.images[i], cmap='gray')\n    ax.set_title(digits.target[i])\n</pre> # Visualizando os primeiros 10 d\u00edgitos do dataset import matplotlib.pyplot as plt   fig, axes = plt.subplots(1, 10, figsize=(10,3))  for i, ax in enumerate(axes):     ax.imshow(digits.images[i], cmap='gray')     ax.set_title(digits.target[i])  In\u00a0[6]: Copied! <pre>from sklearn.model_selection import train_test_split\n# Separando os dados em conjunto de treinamento e teste\nX_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.2, random_state=42)\n\nprint(f\"Formato das tabelas de dados de treino {X_train.shape} e teste {y_train.shape}\")\n</pre> from sklearn.model_selection import train_test_split # Separando os dados em conjunto de treinamento e teste X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.2, random_state=42)  print(f\"Formato das tabelas de dados de treino {X_train.shape} e teste {y_train.shape}\") <pre>Formato das tabelas de dados de treino (1437, 64) e teste (1437,)\n</pre> In\u00a0[8]: Copied! <pre>from sklearn.svm import SVC\nfrom sklearn.ensemble import RandomForestClassifier\n\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n\n# Criando os modelos\nsvm = SVC()\nrf = RandomForestClassifier()\n\n# Ajustando os modelos com os dados de treinamento\nsvm.fit(X_train, y_train)\nrf.fit(X_train, y_train)\n\n# Realizando previs\u00f5es e avaliando os modelos com os dados de teste\nsvm_pred = svm.predict(X_test)\nrf_pred = rf.predict(X_test)\n\nprint(\"SVM - Acur\u00e1cia: \", accuracy_score(y_test, svm_pred))\nprint(\"SVM - Precis\u00e3o: \", precision_score(y_test, svm_pred, average='macro'))\nprint(\"SVM - Recall: \", recall_score(y_test, svm_pred, average='macro'))\nprint(\"SVM - F1-score: \", f1_score(y_test, svm_pred, average='macro'))\n\nprint(\"Random Forest - Acur\u00e1cia: \", accuracy_score(y_test, rf_pred))\nprint(\"Random Forest - Precis\u00e3o: \", precision_score(y_test, rf_pred, average='macro'))\nprint(\"Random Forest - Recall: \", recall_score(y_test, rf_pred, average='macro'))\nprint(\"Random Forest - F1-score: \", f1_score(y_test, rf_pred, average='macro'))\n</pre> from sklearn.svm import SVC from sklearn.ensemble import RandomForestClassifier  from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score  # Criando os modelos svm = SVC() rf = RandomForestClassifier()  # Ajustando os modelos com os dados de treinamento svm.fit(X_train, y_train) rf.fit(X_train, y_train)  # Realizando previs\u00f5es e avaliando os modelos com os dados de teste svm_pred = svm.predict(X_test) rf_pred = rf.predict(X_test)  print(\"SVM - Acur\u00e1cia: \", accuracy_score(y_test, svm_pred)) print(\"SVM - Precis\u00e3o: \", precision_score(y_test, svm_pred, average='macro')) print(\"SVM - Recall: \", recall_score(y_test, svm_pred, average='macro')) print(\"SVM - F1-score: \", f1_score(y_test, svm_pred, average='macro'))  print(\"Random Forest - Acur\u00e1cia: \", accuracy_score(y_test, rf_pred)) print(\"Random Forest - Precis\u00e3o: \", precision_score(y_test, rf_pred, average='macro')) print(\"Random Forest - Recall: \", recall_score(y_test, rf_pred, average='macro')) print(\"Random Forest - F1-score: \", f1_score(y_test, rf_pred, average='macro'))    <pre>SVM - Acur\u00e1cia:  0.9861111111111112\nSVM - Precis\u00e3o:  0.9871533861771657\nSVM - Recall:  0.9865978306216103\nSVM - F1-score:  0.9868277979964809\nRandom Forest - Acur\u00e1cia:  0.9805555555555555\nRandom Forest - Precis\u00e3o:  0.9821815479795213\nRandom Forest - Recall:  0.9806613651263213\nRandom Forest - F1-score:  0.9812604082871628\n</pre> In\u00a0[9]: Copied! <pre>from sklearn.metrics import classification_report\n\nprint(classification_report(y_test, svm_pred))\nprint(classification_report(y_test, rf_pred))\n</pre> from sklearn.metrics import classification_report  print(classification_report(y_test, svm_pred)) print(classification_report(y_test, rf_pred)) <pre>              precision    recall  f1-score   support\n\n           0       1.00      1.00      1.00        33\n           1       1.00      1.00      1.00        28\n           2       1.00      1.00      1.00        33\n           3       1.00      1.00      1.00        34\n           4       1.00      1.00      1.00        46\n           5       0.98      0.98      0.98        47\n           6       0.97      1.00      0.99        35\n           7       0.97      0.97      0.97        34\n           8       1.00      0.97      0.98        30\n           9       0.95      0.95      0.95        40\n\n    accuracy                           0.99       360\n   macro avg       0.99      0.99      0.99       360\nweighted avg       0.99      0.99      0.99       360\n\n              precision    recall  f1-score   support\n\n           0       1.00      0.97      0.98        33\n           1       1.00      1.00      1.00        28\n           2       1.00      1.00      1.00        33\n           3       1.00      0.94      0.97        34\n           4       0.98      1.00      0.99        46\n           5       0.96      0.98      0.97        47\n           6       0.97      0.97      0.97        35\n           7       0.97      0.97      0.97        34\n           8       0.97      1.00      0.98        30\n           9       0.97      0.97      0.97        40\n\n    accuracy                           0.98       360\n   macro avg       0.98      0.98      0.98       360\nweighted avg       0.98      0.98      0.98       360\n\n</pre> In\u00a0[10]: Copied! <pre>from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n\ncm = confusion_matrix(y_test, svm_pred)\ndisp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=digits.target_names)\ndisp.plot(cmap=plt.cm.Blues)\nplt.title(\"Matriz de Confus\u00e3o - SVM\")\nplt.show()\n\ncm_rf = confusion_matrix(y_test, rf_pred)\ndisp_rf = ConfusionMatrixDisplay(confusion_matrix=cm_rf, display_labels=digits.target_names)\ndisp_rf.plot(cmap=plt.cm.Blues)\nplt.title(\"Matriz de Confus\u00e3o - Random Forest\")\nplt.show()\n</pre> from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay  cm = confusion_matrix(y_test, svm_pred) disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=digits.target_names) disp.plot(cmap=plt.cm.Blues) plt.title(\"Matriz de Confus\u00e3o - SVM\") plt.show()  cm_rf = confusion_matrix(y_test, rf_pred) disp_rf = ConfusionMatrixDisplay(confusion_matrix=cm_rf, display_labels=digits.target_names) disp_rf.plot(cmap=plt.cm.Blues) plt.title(\"Matriz de Confus\u00e3o - Random Forest\") plt.show() In\u00a0[11]: Copied! <pre># Salvando os modelos treinados para uso futuro\nimport joblib\njoblib.dump(svm, 'svm_model_digito.pkl')\njoblib.dump(rf, 'rf_model_digito.pkl')\n</pre> # Salvando os modelos treinados para uso futuro import joblib joblib.dump(svm, 'svm_model_digito.pkl') joblib.dump(rf, 'rf_model_digito.pkl') Out[11]: <pre>['rf_model_digito.pkl']</pre> In\u00a0[11]: Copied! <pre># sua resposta aqui...\n</pre> # sua resposta aqui...    In\u00a0[12]: Copied! <pre># sua resposta aqui...\n</pre> # sua resposta aqui..."},{"location":"aulas/IA/lab02/ml-classificador-digito.html#objetivos","title":"Objetivos\u00b6","text":"<ul> <li>Conhecer algoritmos de classifica\u00e7\u00e3o, SVM e Randon Forest;</li> </ul>"},{"location":"aulas/IA/lab02/ml-classificador-digito.html#classificacao-de-digitos-0-9","title":"Classifica\u00e7\u00e3o de digitos 0-9\u00b6","text":"<p>Agora aplicamos os modelos a um dataset mais complexo: reconhecimento de d\u00edgitos manuscritos (0-9), com 1797 amostras e 64 features (pixels 8x8).</p> <p></p>"},{"location":"aulas/IA/lab02/ml-classificador-digito.html#treinamento-do-modelo","title":"Treinamento do modelo\u00b6","text":"Algoritmo Aplica\u00e7\u00e3o Vantagens Desvantagens Contexto de uso Support Vector Machine (SVM) Classifica\u00e7\u00e3o/Regress\u00e3o Eficiente em espa\u00e7os de alta dimensionalidade, robusto a overfitting com kernel adequado, bom para margens de separa\u00e7\u00e3o claras Pode ser lento em grandes datasets, escolha do kernel e par\u00e2metros pode ser complexa Problemas de classifica\u00e7\u00e3o bin\u00e1ria ou multiclasse com margens bem definidas; \u00fatil em textos, imagens e bioinform\u00e1tica Random Forest Classifica\u00e7\u00e3o/Regress\u00e3o Reduz overfitting combinando v\u00e1rias \u00e1rvores, lida bem com dados heterog\u00eaneos, fornece import\u00e2ncia das vari\u00e1veis Modelo mais pesado, menos interpret\u00e1vel que uma \u00fanica \u00e1rvore, pode ser lento com muitas \u00e1rvores Problemas complexos com dados mistos, alto n\u00famero de vari\u00e1veis e rela\u00e7\u00f5es n\u00e3o lineares; bom desempenho geral"},{"location":"aulas/IA/lab02/ml-classificador-digito.html#salvando-os-modelos-treinados-para-uso-futuro","title":"Salvando os modelos treinados para uso futuro\u00b6","text":"<p>Ap\u00f3s a avalia\u00e7\u00e3o, o modelo com melhor desempenho pode ser escolhido para implanta\u00e7\u00e3o em um ambiente de produ\u00e7\u00e3o. Iremos fazer em outro c\u00f3digo (em breve)</p>"},{"location":"aulas/IA/lab02/ml-classificador-digito.html#desafio-1","title":"Desafio 1\u00b6","text":"<p>Tente ajustar os hiperpar\u00e2metros dos modelos para os algoritmos utilizados e aprimore a performance dos modelo.</p>"},{"location":"aulas/IA/lab02/ml-classificador-digito.html#desafio-2","title":"Desafio 2\u00b6","text":"<p>Pesquise sobre outros modelos de classifica\u00e7\u00e3o e compare-os com os utlizados.</p>"},{"location":"aulas/IA/lab02/ml-classificador-iris.html","title":"lab1","text":"In\u00a0[1]: Copied! <pre># Inicializ\u00e7\u00e3o das bibliotecas\n%matplotlib inline\n\nimport pandas as pd\nimport matplotlib.pyplot as plt\n</pre> # Inicializ\u00e7\u00e3o das bibliotecas %matplotlib inline  import pandas as pd import matplotlib.pyplot as plt  In\u00a0[2]: Copied! <pre># Caminho do arquivo\nurl = \"https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data\"\n# Define o nome das colunas\nheader = ['sepal_length', 'sepal_width', 'petal_length', 'petal_width', 'species']\n# L\u00ea e carrega o arquivo para a mem\u00f3ria\ndf = pd.read_csv(url, header=None, names=header)\n</pre> # Caminho do arquivo url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data\" # Define o nome das colunas header = ['sepal_length', 'sepal_width', 'petal_length', 'petal_width', 'species'] # L\u00ea e carrega o arquivo para a mem\u00f3ria df = pd.read_csv(url, header=None, names=header) In\u00a0[3]: Copied! <pre># Retorna um trecho com as 5 primeiras linhas do dataframe\ndf.head()\n</pre> # Retorna um trecho com as 5 primeiras linhas do dataframe df.head() Out[3]: sepal_length sepal_width petal_length petal_width species 0 5.1 3.5 1.4 0.2 Iris-setosa 1 4.9 3.0 1.4 0.2 Iris-setosa 2 4.7 3.2 1.3 0.2 Iris-setosa 3 4.6 3.1 1.5 0.2 Iris-setosa 4 5.0 3.6 1.4 0.2 Iris-setosa In\u00a0[4]: Copied! <pre>df.tail()\n</pre> df.tail() Out[4]: sepal_length sepal_width petal_length petal_width species 145 6.7 3.0 5.2 2.3 Iris-virginica 146 6.3 2.5 5.0 1.9 Iris-virginica 147 6.5 3.0 5.2 2.0 Iris-virginica 148 6.2 3.4 5.4 2.3 Iris-virginica 149 5.9 3.0 5.1 1.8 Iris-virginica In\u00a0[5]: Copied! <pre># Mostra informa\u00e7\u00f5es sobre o dataframe em si\ndf.info()\n</pre> # Mostra informa\u00e7\u00f5es sobre o dataframe em si df.info() <pre>&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 150 entries, 0 to 149\nData columns (total 5 columns):\n #   Column        Non-Null Count  Dtype  \n---  ------        --------------  -----  \n 0   sepal_length  150 non-null    float64\n 1   sepal_width   150 non-null    float64\n 2   petal_length  150 non-null    float64\n 3   petal_width   150 non-null    float64\n 4   species       150 non-null    object \ndtypes: float64(4), object(1)\nmemory usage: 6.0+ KB\n</pre> In\u00a0[6]: Copied! <pre># class distribution\nprint(df.groupby('species').size())\n</pre> # class distribution print(df.groupby('species').size()) <pre>species\nIris-setosa        50\nIris-versicolor    50\nIris-virginica     50\ndtype: int64\n</pre> In\u00a0[7]: Copied! <pre>## Sua resposta e seus gr\u00e1ficos para an\u00e1lisar..\n</pre> ## Sua resposta e seus gr\u00e1ficos para an\u00e1lisar..       In\u00a0[8]: Copied! <pre># instalando a biblioteca scikit-learn\n\n!pip install scikit-learn --quiet\n</pre> # instalando a biblioteca scikit-learn  !pip install scikit-learn --quiet In\u00a0[7]: Copied! <pre># Codificando os r\u00f3tulos de especies\n\nfrom sklearn.preprocessing import LabelEncoder\n\nle = LabelEncoder()\ndf['species'] = le.fit_transform(df['species'])\n</pre> # Codificando os r\u00f3tulos de especies  from sklearn.preprocessing import LabelEncoder  le = LabelEncoder() df['species'] = le.fit_transform(df['species']) In\u00a0[8]: Copied! <pre># Verificando o dataframe ap\u00f3s a codifica\u00e7\u00e3o\ndf.head()\n</pre> # Verificando o dataframe ap\u00f3s a codifica\u00e7\u00e3o df.head() Out[8]: sepal_length sepal_width petal_length petal_width species 0 5.1 3.5 1.4 0.2 0 1 4.9 3.0 1.4 0.2 0 2 4.7 3.2 1.3 0.2 0 3 4.6 3.1 1.5 0.2 0 4 5.0 3.6 1.4 0.2 0 In\u00a0[9]: Copied! <pre>df.groupby('species').size()\n</pre> df.groupby('species').size() Out[9]: <pre>species\n0    50\n1    50\n2    50\ndtype: int64</pre> In\u00a0[10]: Copied! <pre># Separamos 20% para o teste\nfrom sklearn.model_selection import train_test_split\n\n## define entradas de dados e o target\nX = df.iloc[:, :-1]\ny = df['species']\n\n# Separando os dados em conjunto de treinamento e teste\nX_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.2, random_state=42)\n\nprint(f\"Formato das tabelas de dados de treino {X_train.shape} e teste {y_train.shape}\")\n</pre> # Separamos 20% para o teste from sklearn.model_selection import train_test_split  ## define entradas de dados e o target X = df.iloc[:, :-1] y = df['species']  # Separando os dados em conjunto de treinamento e teste X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.2, random_state=42)  print(f\"Formato das tabelas de dados de treino {X_train.shape} e teste {y_train.shape}\") <pre>Formato das tabelas de dados de treino (120, 4) e teste (120,)\n</pre> In\u00a0[11]: Copied! <pre>#Primeiras linhas do dataframe de treino \nX_train.head()\n</pre> #Primeiras linhas do dataframe de treino  X_train.head() Out[11]: sepal_length sepal_width petal_length petal_width 22 4.6 3.6 1.0 0.2 15 5.7 4.4 1.5 0.4 65 6.7 3.1 4.4 1.4 11 4.8 3.4 1.6 0.2 42 4.4 3.2 1.3 0.2 In\u00a0[12]: Copied! <pre>y_train.tail()\n</pre> y_train.tail() Out[12]: <pre>71     1\n106    2\n14     0\n92     1\n102    2\nName: species, dtype: int64</pre> In\u00a0[37]: Copied! <pre># Importa a biblioteca\nfrom sklearn.neighbors import KNeighborsClassifier\n\n# Cria o classificar KNN\nk = 3\nknn = KNeighborsClassifier()\n\n# Cria o modelo de machine learning\nknn.fit(X_train, y_train)\n</pre> # Importa a biblioteca from sklearn.neighbors import KNeighborsClassifier  # Cria o classificar KNN k = 3 knn = KNeighborsClassifier()  # Cria o modelo de machine learning knn.fit(X_train, y_train) Out[37]: <pre>KNeighborsClassifier()</pre>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.KNeighborsClassifier?Documentation for KNeighborsClassifieriFitted Parameters n_neighbors\u00a0 5 weights\u00a0 'uniform' algorithm\u00a0 'auto' leaf_size\u00a0 30 p\u00a0 2 metric\u00a0 'minkowski' metric_params\u00a0 None n_jobs\u00a0 None <p>Pronto!! bora testar se esta funcionando....</p> <p>Vamos fazer predi\u00e7\u00f5es para os dados do conjunto de teste</p> In\u00a0[38]: Copied! <pre># Realizando previs\u00f5es\n\ny_pred = knn.predict(X_test)\n\n# vendo as previs\u00f5es\nprint(y_pred)\n\n# com o r\u00f3tulo original\nprint(\"R\u00f3tulo original:\", le.inverse_transform(y_test))\nprint(\"Nova previs\u00e3o:\", le.inverse_transform(y_pred))\n</pre> # Realizando previs\u00f5es  y_pred = knn.predict(X_test)  # vendo as previs\u00f5es print(y_pred)  # com o r\u00f3tulo original print(\"R\u00f3tulo original:\", le.inverse_transform(y_test)) print(\"Nova previs\u00e3o:\", le.inverse_transform(y_pred))  <pre>[1 0 2 1 1 0 1 2 1 1 2 0 0 0 0 1 2 1 1 2 0 2 0 2 2 2 2 2 0 0]\nR\u00f3tulo original: ['Iris-versicolor' 'Iris-setosa' 'Iris-virginica' 'Iris-versicolor'\n 'Iris-versicolor' 'Iris-setosa' 'Iris-versicolor' 'Iris-virginica'\n 'Iris-versicolor' 'Iris-versicolor' 'Iris-virginica' 'Iris-setosa'\n 'Iris-setosa' 'Iris-setosa' 'Iris-setosa' 'Iris-versicolor'\n 'Iris-virginica' 'Iris-versicolor' 'Iris-versicolor' 'Iris-virginica'\n 'Iris-setosa' 'Iris-virginica' 'Iris-setosa' 'Iris-virginica'\n 'Iris-virginica' 'Iris-virginica' 'Iris-virginica' 'Iris-virginica'\n 'Iris-setosa' 'Iris-setosa']\nNova previs\u00e3o: ['Iris-versicolor' 'Iris-setosa' 'Iris-virginica' 'Iris-versicolor'\n 'Iris-versicolor' 'Iris-setosa' 'Iris-versicolor' 'Iris-virginica'\n 'Iris-versicolor' 'Iris-versicolor' 'Iris-virginica' 'Iris-setosa'\n 'Iris-setosa' 'Iris-setosa' 'Iris-setosa' 'Iris-versicolor'\n 'Iris-virginica' 'Iris-versicolor' 'Iris-versicolor' 'Iris-virginica'\n 'Iris-setosa' 'Iris-virginica' 'Iris-setosa' 'Iris-virginica'\n 'Iris-virginica' 'Iris-virginica' 'Iris-virginica' 'Iris-virginica'\n 'Iris-setosa' 'Iris-setosa']\n</pre> In\u00a0[39]: Copied! <pre># novas previs\u00f5es\nsepal_length = 14.1 # altere esses valores para testar\nsepal_width = 1.5 # altere esses valores para testar\npetal_length = 1.4 # altere esses valores para testar\npetal_width = 2.2 # altere esses valores para testar\n\ndado = pd.DataFrame([[sepal_length, sepal_width, petal_length, petal_width]], columns=X.columns)\n\nnova_previsao = knn.predict(dado)\n\nprint(\"Novas previs\u00f5es:\", nova_previsao)\n\n# com o r\u00f3tulo original\nprint(\"R\u00f3tulo original:\", le.inverse_transform(nova_previsao))  \n</pre> # novas previs\u00f5es sepal_length = 14.1 # altere esses valores para testar sepal_width = 1.5 # altere esses valores para testar petal_length = 1.4 # altere esses valores para testar petal_width = 2.2 # altere esses valores para testar  dado = pd.DataFrame([[sepal_length, sepal_width, petal_length, petal_width]], columns=X.columns)  nova_previsao = knn.predict(dado)  print(\"Novas previs\u00f5es:\", nova_previsao)  # com o r\u00f3tulo original print(\"R\u00f3tulo original:\", le.inverse_transform(nova_previsao))   <pre>Novas previs\u00f5es: [1]\nR\u00f3tulo original: ['Iris-versicolor']\n</pre> In\u00a0[40]: Copied! <pre># a probabilidade da predi\u00e7\u00e3o\nprob = knn.predict_proba(dado)\nprint(\"Probabilidade da predi\u00e7\u00e3o:\", prob)\n</pre> # a probabilidade da predi\u00e7\u00e3o prob = knn.predict_proba(dado) print(\"Probabilidade da predi\u00e7\u00e3o:\", prob) <pre>Probabilidade da predi\u00e7\u00e3o: [[0.  0.8 0.2]]\n</pre> In\u00a0[41]: Copied! <pre># Avaliando o modelo\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n\nprint(\"Acur\u00e1cia: \", accuracy_score(y_test, y_pred))\nprint(\"Precis\u00e3o: \", precision_score(y_test, y_pred, average='macro'))\nprint(\"Recall: \", recall_score(y_test, y_pred, average='macro'))\nprint(\"F1-score: \", f1_score(y_test, y_pred, average='macro'))\n\n## average='macro': m\u00e9trica \u00e9 calculada para cada classe individualmente e, em seguida, a m\u00e9dia n\u00e3o ponderada das m\u00e9tricas de cada classe \u00e9 retornada.\n##  Isso significa que todas as classes t\u00eam a mesma import\u00e2ncia no c\u00e1lculo da m\u00e9trica.\n</pre>  # Avaliando o modelo from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score  print(\"Acur\u00e1cia: \", accuracy_score(y_test, y_pred)) print(\"Precis\u00e3o: \", precision_score(y_test, y_pred, average='macro')) print(\"Recall: \", recall_score(y_test, y_pred, average='macro')) print(\"F1-score: \", f1_score(y_test, y_pred, average='macro'))  ## average='macro': m\u00e9trica \u00e9 calculada para cada classe individualmente e, em seguida, a m\u00e9dia n\u00e3o ponderada das m\u00e9tricas de cada classe \u00e9 retornada. ##  Isso significa que todas as classes t\u00eam a mesma import\u00e2ncia no c\u00e1lculo da m\u00e9trica. <pre>Acur\u00e1cia:  1.0\nPrecis\u00e3o:  1.0\nRecall:  1.0\nF1-score:  1.0\n</pre> In\u00a0[42]: Copied! <pre>from sklearn.tree import DecisionTreeClassifier\n\n# Definindo o modelo de \u00e1rvore de decis\u00e3o com hiperpar\u00e2metros padr\u00e3o\ntree = DecisionTreeClassifier()\ntree.fit(X_train, y_train)\n</pre> from sklearn.tree import DecisionTreeClassifier  # Definindo o modelo de \u00e1rvore de decis\u00e3o com hiperpar\u00e2metros padr\u00e3o tree = DecisionTreeClassifier() tree.fit(X_train, y_train)   Out[42]: <pre>DecisionTreeClassifier()</pre>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.DecisionTreeClassifier?Documentation for DecisionTreeClassifieriFitted Parameters criterion\u00a0 'gini' splitter\u00a0 'best' max_depth\u00a0 None min_samples_split\u00a0 2 min_samples_leaf\u00a0 1 min_weight_fraction_leaf\u00a0 0.0 max_features\u00a0 None random_state\u00a0 None max_leaf_nodes\u00a0 None min_impurity_decrease\u00a0 0.0 class_weight\u00a0 None ccp_alpha\u00a0 0.0 monotonic_cst\u00a0 None In\u00a0[36]: Copied! <pre># Realizando previs\u00f5es e avaliando o modelo\ny_pred = tree.predict(X_test)\n\n# vendo as previs\u00f5es\nprint(\"Acur\u00e1cia: \", accuracy_score(y_test, y_pred))\nprint(\"Precis\u00e3o: \", precision_score(y_test, y_pred, average='macro'))\nprint(\"Recall: \", recall_score(y_test, y_pred, average='macro'))\nprint(\"F1-score: \", f1_score(y_test, y_pred, average='macro'))\n</pre> # Realizando previs\u00f5es e avaliando o modelo y_pred = tree.predict(X_test)  # vendo as previs\u00f5es print(\"Acur\u00e1cia: \", accuracy_score(y_test, y_pred)) print(\"Precis\u00e3o: \", precision_score(y_test, y_pred, average='macro')) print(\"Recall: \", recall_score(y_test, y_pred, average='macro')) print(\"F1-score: \", f1_score(y_test, y_pred, average='macro')) <pre>Acur\u00e1cia:  1.0\nPrecis\u00e3o:  1.0\nRecall:  1.0\nF1-score:  1.0\n</pre> In\u00a0[43]: Copied! <pre>from sklearn.tree import plot_tree\nimport matplotlib.pyplot as plt\n\nplt.figure(figsize=(12,8), dpi=400)\nplot_tree(tree, feature_names=X.columns, class_names=le.classes_, filled=True)\nplt.show()\n</pre> from sklearn.tree import plot_tree import matplotlib.pyplot as plt  plt.figure(figsize=(12,8), dpi=400) plot_tree(tree, feature_names=X.columns, class_names=le.classes_, filled=True) plt.show()  In\u00a0[45]: Copied! <pre># novas previs\u00f5es\nsepal_length = 14.1 # altere esses valores para testar\nsepal_width = 1.5 # altere esses valores para testar\npetal_length = 1.4 # altere esses valores para testar\npetal_width = 2.2 # altere esses valores para testar\n\ndado = pd.DataFrame([[sepal_length, sepal_width, petal_length, petal_width]], columns=X.columns)\n\nnova_previsao = tree.predict(dado)\n\nprint(\"Novas previs\u00f5es:\", nova_previsao)\n\n# com o r\u00f3tulo original\nprint(\"R\u00f3tulo original:\", le.inverse_transform(nova_previsao))  \n</pre> # novas previs\u00f5es sepal_length = 14.1 # altere esses valores para testar sepal_width = 1.5 # altere esses valores para testar petal_length = 1.4 # altere esses valores para testar petal_width = 2.2 # altere esses valores para testar  dado = pd.DataFrame([[sepal_length, sepal_width, petal_length, petal_width]], columns=X.columns)  nova_previsao = tree.predict(dado)  print(\"Novas previs\u00f5es:\", nova_previsao)  # com o r\u00f3tulo original print(\"R\u00f3tulo original:\", le.inverse_transform(nova_previsao))   <pre>Novas previs\u00f5es: [0]\nR\u00f3tulo original: ['Iris-setosa']\n</pre> In\u00a0[46]: Copied! <pre># a probabilidade da predi\u00e7\u00e3o\nprob = tree.predict_proba(dado)\nprint(\"Probabilidade da predi\u00e7\u00e3o:\", prob)\n</pre> # a probabilidade da predi\u00e7\u00e3o prob = tree.predict_proba(dado) print(\"Probabilidade da predi\u00e7\u00e3o:\", prob) <pre>Probabilidade da predi\u00e7\u00e3o: [[1. 0. 0.]]\n</pre> In\u00a0[52]: Copied! <pre>from sklearn.model_selection import GridSearchCV\n\n\n# Definindo os valores para os hiperpar\u00e2metros\nparam_grid = {'n_neighbors': [3, 5, 7, 9], 'weights': ['uniform', 'distance'], 'algorithm': ['ball_tree', 'kd_tree', 'brute'], 'p': [1, 2]}\n\n# Criando o objeto GridSearchCV\ngrid_knn = GridSearchCV(KNeighborsClassifier(), param_grid, verbose=1, cv=5, n_jobs=-1)\n\n# Ajustando o modelo com os dados de treinamento\ngrid_knn.fit(X_train, y_train)\n</pre> from sklearn.model_selection import GridSearchCV   # Definindo os valores para os hiperpar\u00e2metros param_grid = {'n_neighbors': [3, 5, 7, 9], 'weights': ['uniform', 'distance'], 'algorithm': ['ball_tree', 'kd_tree', 'brute'], 'p': [1, 2]}  # Criando o objeto GridSearchCV grid_knn = GridSearchCV(KNeighborsClassifier(), param_grid, verbose=1, cv=5, n_jobs=-1)  # Ajustando o modelo com os dados de treinamento grid_knn.fit(X_train, y_train)   <pre>Fitting 5 folds for each of 48 candidates, totalling 240 fits\n</pre> Out[52]: <pre>GridSearchCV(cv=5, estimator=KNeighborsClassifier(), n_jobs=-1,\n             param_grid={'algorithm': ['ball_tree', 'kd_tree', 'brute'],\n                         'n_neighbors': [3, 5, 7, 9], 'p': [1, 2],\n                         'weights': ['uniform', 'distance']},\n             verbose=1)</pre>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.GridSearchCV?Documentation for GridSearchCViFitted Parameters estimator\u00a0 KNeighborsClassifier() param_grid\u00a0 {'algorithm': ['ball_tree', 'kd_tree', ...], 'n_neighbors': [3, 5, ...], 'p': [1, 2], 'weights': ['uniform', 'distance']} scoring\u00a0 None n_jobs\u00a0 -1 refit\u00a0 True cv\u00a0 5 verbose\u00a0 1 pre_dispatch\u00a0 '2*n_jobs' error_score\u00a0 nan return_train_score\u00a0 False best_estimator_: KNeighborsClassifier<pre>KNeighborsClassifier(algorithm='ball_tree', n_neighbors=3, p=1)</pre>KNeighborsClassifier?Documentation for KNeighborsClassifier Parameters n_neighbors\u00a0 3 weights\u00a0 'uniform' algorithm\u00a0 'ball_tree' leaf_size\u00a0 30 p\u00a0 1 metric\u00a0 'minkowski' metric_params\u00a0 None n_jobs\u00a0 None In\u00a0[53]: Copied! <pre># Imprimindo os melhores hiperpar\u00e2metros encontrados\nprint(\"Melhores hiperpar\u00e2metros: \", grid_knn.best_params_)\n\n# Realizando previs\u00f5es e avaliando o modelo com os melhores hiperpar\u00e2metros\ny_pred = grid_knn.predict(X_test)\nprint(\"Acur\u00e1cia: \", accuracy_score(y_test, y_pred))\nprint(\"Precis\u00e3o: \", precision_score(y_test, y_pred, average='macro'))\nprint(\"Recall: \", recall_score(y_test, y_pred, average='macro'))\nprint(\"F1-score: \", f1_score(y_test, y_pred, average='macro'))\n</pre> # Imprimindo os melhores hiperpar\u00e2metros encontrados print(\"Melhores hiperpar\u00e2metros: \", grid_knn.best_params_)  # Realizando previs\u00f5es e avaliando o modelo com os melhores hiperpar\u00e2metros y_pred = grid_knn.predict(X_test) print(\"Acur\u00e1cia: \", accuracy_score(y_test, y_pred)) print(\"Precis\u00e3o: \", precision_score(y_test, y_pred, average='macro')) print(\"Recall: \", recall_score(y_test, y_pred, average='macro')) print(\"F1-score: \", f1_score(y_test, y_pred, average='macro')) <pre>Melhores hiperpar\u00e2metros:  {'algorithm': 'ball_tree', 'n_neighbors': 3, 'p': 1, 'weights': 'uniform'}\nAcur\u00e1cia:  1.0\nPrecis\u00e3o:  1.0\nRecall:  1.0\nF1-score:  1.0\n</pre> In\u00a0[54]: Copied! <pre># Definindo os valores para os hiperpar\u00e2metros\nparam_grid = {'criterion': ['gini', 'entropy'], 'max_depth': [None, 3, 5, 7], 'min_samples_split': [2, 5, 10], 'min_samples_leaf': [1, 2, 4]}\n\n# Criando o objeto GridSearchCV\ngrid_tree = GridSearchCV(DecisionTreeClassifier(), param_grid, verbose=1, cv=5, n_jobs=-1)\n\n# Ajustando o modelo com os dados de treinamento\ngrid_tree.fit(X_train, y_train)\n</pre> # Definindo os valores para os hiperpar\u00e2metros param_grid = {'criterion': ['gini', 'entropy'], 'max_depth': [None, 3, 5, 7], 'min_samples_split': [2, 5, 10], 'min_samples_leaf': [1, 2, 4]}  # Criando o objeto GridSearchCV grid_tree = GridSearchCV(DecisionTreeClassifier(), param_grid, verbose=1, cv=5, n_jobs=-1)  # Ajustando o modelo com os dados de treinamento grid_tree.fit(X_train, y_train)   <pre>Fitting 5 folds for each of 72 candidates, totalling 360 fits\n</pre> Out[54]: <pre>GridSearchCV(cv=5, estimator=DecisionTreeClassifier(), n_jobs=-1,\n             param_grid={'criterion': ['gini', 'entropy'],\n                         'max_depth': [None, 3, 5, 7],\n                         'min_samples_leaf': [1, 2, 4],\n                         'min_samples_split': [2, 5, 10]},\n             verbose=1)</pre>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.GridSearchCV?Documentation for GridSearchCViFitted Parameters estimator\u00a0 DecisionTreeClassifier() param_grid\u00a0 {'criterion': ['gini', 'entropy'], 'max_depth': [None, 3, ...], 'min_samples_leaf': [1, 2, ...], 'min_samples_split': [2, 5, ...]} scoring\u00a0 None n_jobs\u00a0 -1 refit\u00a0 True cv\u00a0 5 verbose\u00a0 1 pre_dispatch\u00a0 '2*n_jobs' error_score\u00a0 nan return_train_score\u00a0 False best_estimator_: DecisionTreeClassifier<pre>DecisionTreeClassifier(criterion='entropy', min_samples_leaf=4)</pre>DecisionTreeClassifier?Documentation for DecisionTreeClassifier Parameters criterion\u00a0 'entropy' splitter\u00a0 'best' max_depth\u00a0 None min_samples_split\u00a0 2 min_samples_leaf\u00a0 4 min_weight_fraction_leaf\u00a0 0.0 max_features\u00a0 None random_state\u00a0 None max_leaf_nodes\u00a0 None min_impurity_decrease\u00a0 0.0 class_weight\u00a0 None ccp_alpha\u00a0 0.0 monotonic_cst\u00a0 None In\u00a0[56]: Copied! <pre># Imprimindo os melhores hiperpar\u00e2metros encontrados\nprint(\"Melhores hiperpar\u00e2metros: \", grid_tree.best_params_)\n\n# Realizando previs\u00f5es e avaliando o modelo com os melhores hiperpar\u00e2metros\ny_pred = grid_tree.predict(X_test)\nprint(\"Acur\u00e1cia: \", accuracy_score(y_test, y_pred))\nprint(\"Precis\u00e3o: \", precision_score(y_test, y_pred, average='macro'))\nprint(\"Recall: \", recall_score(y_test, y_pred, average='macro'))\nprint(\"F1-score: \", f1_score(y_test, y_pred, average='macro'))\n</pre> # Imprimindo os melhores hiperpar\u00e2metros encontrados print(\"Melhores hiperpar\u00e2metros: \", grid_tree.best_params_)  # Realizando previs\u00f5es e avaliando o modelo com os melhores hiperpar\u00e2metros y_pred = grid_tree.predict(X_test) print(\"Acur\u00e1cia: \", accuracy_score(y_test, y_pred)) print(\"Precis\u00e3o: \", precision_score(y_test, y_pred, average='macro')) print(\"Recall: \", recall_score(y_test, y_pred, average='macro')) print(\"F1-score: \", f1_score(y_test, y_pred, average='macro')) <pre>Melhores hiperpar\u00e2metros:  {'criterion': 'entropy', 'max_depth': None, 'min_samples_leaf': 4, 'min_samples_split': 2}\nAcur\u00e1cia:  1.0\nPrecis\u00e3o:  1.0\nRecall:  1.0\nF1-score:  1.0\n</pre> In\u00a0[59]: Copied! <pre># Criando os modelos ( altere os parametros para os melhores hiperpar\u00e2metros encontrados)\nknn = KNeighborsClassifier(n_neighbors=3, weights='uniform', algorithm='ball_tree', p=1) \ntree = DecisionTreeClassifier(criterion='entropy', max_depth=None, min_samples_split=2, min_samples_leaf=4)\n\n# Ajustando os modelos com os dados de treinamento\nknn.fit(X_train, y_train)\ntree.fit(X_train, y_train)\n\n# Realizando previs\u00f5es e avaliando os modelos com os dados de teste\nknn_pred = knn.predict(X_test)\ntree_pred = tree.predict(X_test)\n\nprint(\"KNN - Acur\u00e1cia: \", accuracy_score(y_test, knn_pred))\nprint(\"KNN - Precis\u00e3o: \", precision_score(y_test, knn_pred, average='macro'))\nprint(\"KNN - Recall: \", recall_score(y_test, knn_pred, average='macro'))\nprint(\"KNN - F1-score: \", f1_score(y_test, knn_pred, average='macro'))\n\nprint(\"\u00c1rvore de Decis\u00e3o - Acur\u00e1cia: \", accuracy_score(y_test, tree_pred))\nprint(\"\u00c1rvore de Decis\u00e3o - Precis\u00e3o: \", precision_score(y_test, tree_pred, average='macro'))\nprint(\"\u00c1rvore de Decis\u00e3o - Recall: \", recall_score(y_test, tree_pred, average='macro'))\nprint(\"\u00c1rvore de Decis\u00e3o - F1-score: \", f1_score(y_test, tree_pred, average='macro'))\n</pre> # Criando os modelos ( altere os parametros para os melhores hiperpar\u00e2metros encontrados) knn = KNeighborsClassifier(n_neighbors=3, weights='uniform', algorithm='ball_tree', p=1)  tree = DecisionTreeClassifier(criterion='entropy', max_depth=None, min_samples_split=2, min_samples_leaf=4)  # Ajustando os modelos com os dados de treinamento knn.fit(X_train, y_train) tree.fit(X_train, y_train)  # Realizando previs\u00f5es e avaliando os modelos com os dados de teste knn_pred = knn.predict(X_test) tree_pred = tree.predict(X_test)  print(\"KNN - Acur\u00e1cia: \", accuracy_score(y_test, knn_pred)) print(\"KNN - Precis\u00e3o: \", precision_score(y_test, knn_pred, average='macro')) print(\"KNN - Recall: \", recall_score(y_test, knn_pred, average='macro')) print(\"KNN - F1-score: \", f1_score(y_test, knn_pred, average='macro'))  print(\"\u00c1rvore de Decis\u00e3o - Acur\u00e1cia: \", accuracy_score(y_test, tree_pred)) print(\"\u00c1rvore de Decis\u00e3o - Precis\u00e3o: \", precision_score(y_test, tree_pred, average='macro')) print(\"\u00c1rvore de Decis\u00e3o - Recall: \", recall_score(y_test, tree_pred, average='macro')) print(\"\u00c1rvore de Decis\u00e3o - F1-score: \", f1_score(y_test, tree_pred, average='macro')) <pre>KNN - Acur\u00e1cia:  1.0\nKNN - Precis\u00e3o:  1.0\nKNN - Recall:  1.0\nKNN - F1-score:  1.0\n\u00c1rvore de Decis\u00e3o - Acur\u00e1cia:  1.0\n\u00c1rvore de Decis\u00e3o - Precis\u00e3o:  1.0\n\u00c1rvore de Decis\u00e3o - Recall:  1.0\n\u00c1rvore de Decis\u00e3o - F1-score:  1.0\n</pre> In\u00a0[60]: Copied! <pre>from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n\ncm = confusion_matrix(y_test, tree_pred)\ndisp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=le.classes_)\ndisp.plot()\nplt.title(\"Matriz de Confus\u00e3o - \u00c1rvore de Decis\u00e3o\")\nplt.show()\n\ncm_knn = confusion_matrix(y_test, knn_pred)\ndisp_knn = ConfusionMatrixDisplay(confusion_matrix=cm_knn, display_labels=le.classes_)\ndisp_knn.plot(cmap=plt.cm.Blues)\nplt.title(\"Matriz de Confus\u00e3o - KNN\")\nplt.show()\n</pre> from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay  cm = confusion_matrix(y_test, tree_pred) disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=le.classes_) disp.plot() plt.title(\"Matriz de Confus\u00e3o - \u00c1rvore de Decis\u00e3o\") plt.show()  cm_knn = confusion_matrix(y_test, knn_pred) disp_knn = ConfusionMatrixDisplay(confusion_matrix=cm_knn, display_labels=le.classes_) disp_knn.plot(cmap=plt.cm.Blues) plt.title(\"Matriz de Confus\u00e3o - KNN\") plt.show()  In\u00a0[62]: Copied! <pre># Salvando os modelos treinados para uso futuro\nimport joblib\njoblib.dump(knn, 'knn_model_iris.pkl')\njoblib.dump(tree, 'tree_model_iris.pkl') \n</pre> # Salvando os modelos treinados para uso futuro import joblib joblib.dump(knn, 'knn_model_iris.pkl') joblib.dump(tree, 'tree_model_iris.pkl')  Out[62]: <pre>['tree_model_iris.pkl']</pre>"},{"location":"aulas/IA/lab02/ml-classificador-iris.html#objetivos","title":"Objetivos\u00b6","text":"<ul> <li>Conhecer a biblioteca Sklearn</li> <li>Conhecer algoritmos de classifica\u00e7\u00e3o, K-Nearest Neighbors (KNN) e \u00c1rvore de Decis\u00e3o;</li> <li>Aplicar o Grid Search para encontrar os melhores par\u00e2metros para esses modelos;</li> <li>Conhecer, Analisar e interpretar m\u00e9tricas de avalia\u00e7\u00e3o (acur\u00e1cia, precis\u00e3o, recall, F1-score) e visualiza\u00e7\u00f5es para entender o desempenho dos modelos.</li> </ul>"},{"location":"aulas/IA/lab02/ml-classificador-iris.html#problemas-de-classicacao","title":"Problemas de classica\u00e7\u00e3o\u00b6","text":"<p>A classifica\u00e7\u00e3o \u00e9 uma das principais tarefas em aprendizado de m\u00e1quina e envolve a atribui\u00e7\u00e3o de um r\u00f3tulo ou categoria a um conjunto de dados. Por exemplo, podemos usar a classifica\u00e7\u00e3o para identificar se um e-mail \u00e9 spam ou n\u00e3o, se uma transa\u00e7\u00e3o financeira \u00e9 fraudulenta ou leg\u00edtima, ou para prever se um paciente desenvolver\u00e1 uma doen\u00e7a com base em seus dados m\u00e9dicos.</p> <p>Existem muitos desafios em problemas de classica\u00e7\u00e3o que o an\u00e1lista de dados deve levar em considera\u00e7\u00e3o, como a escolha do modelo de aprendizado de m\u00e1quina adequado, o ajuste dos hiperpar\u00e2metros do modelo, a sele\u00e7\u00e3o de features relevantes, o tratamento de dados adequado ao problema, o cuidado com overfitting e a avalia\u00e7\u00e3o correta do modelo.</p> <p>Al\u00e9m disso, diferentes modelos de classifica\u00e7\u00e3o t\u00eam seus pr\u00f3prios pontos fortes e fracos, e escolher o modelo certo para um problema espec\u00edfico pode ser dif\u00edcil.</p>"},{"location":"aulas/IA/lab02/ml-classificador-iris.html#resumo-sobre-knn-e-arvore-de-decisao","title":"Resumo sobre KNN e \u00c1rvore de Decis\u00e3o\u00b6","text":"Algoritmo Aplica\u00e7\u00e3o Vantagens Desvantagens Contexto de uso \u00c1rvores de Decis\u00e3o Classifica\u00e7\u00e3o/Regress\u00e3o F\u00e1cil interpretabilidade, lida bem com dados faltantes, captura rela\u00e7\u00f5es n\u00e3o lineares Tend\u00eancia ao overfitting, pode ser sens\u00edvel a ru\u00eddo Problemas de classifica\u00e7\u00e3o/regress\u00e3o com rela\u00e7\u00f5es n\u00e3o lineares K-Nearest Neighbors (KNN) Classifica\u00e7\u00e3o/Regress\u00e3o F\u00e1cil de entender e implementar, lida bem com dados com muitas vari\u00e1veis de entrada Requer muita mem\u00f3ria para grandes conjuntos de dados, sens\u00edvel a outliers Problemas de classifica\u00e7\u00e3o/regress\u00e3o com muitas vari\u00e1veis de entrada e poucas classes poss\u00edveis"},{"location":"aulas/IA/lab02/ml-classificador-iris.html#definicao-do-problema","title":"Defini\u00e7\u00e3o do problema\u00b6","text":"<p>A primeira coisa que precisamos fazer \u00e9 a defini\u00e7\u00e3o do problema. Neste primeiro caso vamos trabalhar com o mesmo dataset da \u00faltima aula, dataset iris. Vamos desenvolver um sistema de machine learning capaz de classificar a especie de flor Iris com base nos dimensionais da p\u00e9tala e sepala.</p>"},{"location":"aulas/IA/lab02/ml-classificador-iris.html#relembrando-o-dataset-iris","title":"Relembrando o dataset Iris\u00b6","text":"<p>Iris \u00e9 um dataset de flor com 150 linhas, divididos em tr\u00eas esp\u00e9cies diferentes: setosa, versicolor e virginica, sendo 50 amostras de cada esp\u00e9cie. Os atributos de largura e comprimento de s\u00e9pala e largura e comprimento de p\u00e9tala de cada flor foram anotados manualmente.</p>"},{"location":"aulas/IA/lab02/ml-classificador-iris.html#desafio-1","title":"Desafio 1\u00b6","text":"<p>Aplique os m\u00e9todos que achar conveniente (vimos algumas op\u00e7\u00f5es na \u00faltima aula) para visualizar os dados de forma gr\u00e1fica.</p>"},{"location":"aulas/IA/lab02/ml-classificador-iris.html#pare","title":"PARE!!!\u00b6","text":"<p>A an\u00e1lise feita no desafio 1 \u00e9 uma das etapas mais importantes. Caso voc\u00ea tenha pulado essa etapa, volte e fa\u00e7a suas an\u00e1lises.</p>"},{"location":"aulas/IA/lab02/ml-classificador-iris.html#scikit-learn","title":"scikit-learn\u00b6","text":"<p>Tamb\u00e9m conhecida como sklearn, \u00e9 uma biblioteca de c\u00f3digo aberto (open source) para a linguagem Python, essa biblioteca fornece uma ampla gama de ferramentas e algoritmos de aprendizado de m\u00e1quina de forma acess\u00edvel e eficiente.</p> <p></p> <p>Podemos dizer que o scikit-learn \u00e9 a ferramenta mais popular e utilizada em aprendizado de m\u00e1quina e existem alguns motivos para isso, tais como:</p> <ul> <li>Simplicidade e Consist\u00eancia: Todos os algoritmos no scikit-learn compartilham uma interface consistente, que segue um padr\u00e3o de m\u00e9todos como fit(), predict(), e transform(). Isso facilita a troca e experimenta\u00e7\u00e3o de diferentes algoritmos, promovendo um ambiente de desenvolvimento r\u00e1pido e eficiente.</li> <li>Compatibilidade e Integra\u00e7\u00e3o: O scikit-learn \u00e9 projetado para interoperabilidade com outras bibliotecas do ecossistema Python, como pandas para manipula\u00e7\u00e3o de dados, numpy para opera\u00e7\u00f5es num\u00e9ricas, e matplotlib para visualiza\u00e7\u00e3o. Essa integra\u00e7\u00e3o permite uma f\u00e1cil manipula\u00e7\u00e3o e transforma\u00e7\u00e3o de dados, bem como a visualiza\u00e7\u00e3o de resultados de modelos.</li> <li>Foco em Performance e Efici\u00eancia Computacional: Embora Python seja uma linguagem interpretada, a scikit-learn faz uso extensivo de opera\u00e7\u00f5es vetorizadas atrav\u00e9s de numpy e implementa\u00e7\u00f5es otimizadas em Cython (que \u00e9 uma linguagem de programa\u00e7\u00e3o que facilita a escrita de extens\u00f5es em C para Python) para acelerar o processamento de dados e a execu\u00e7\u00e3o de algoritmos. Isso proporciona uma execu\u00e7\u00e3o eficiente de tarefas complexas de machine learning, como treinamento de modelos e ajuste de hiperpar\u00e2metros.</li> </ul>"},{"location":"aulas/IA/lab02/ml-classificador-iris.html#instalacao","title":"Instala\u00e7\u00e3o\u00b6","text":"<pre>pip install scikit-learn\n</pre> <p>Saiba mais: site da documenta\u00e7\u00e3o oficial https://scikit-learn.org/stable/</p>"},{"location":"aulas/IA/lab02/ml-classificador-iris.html#codificando-os-dados","title":"Codificando os dados\u00b6","text":"<p>Com essa etapa conclu\u00edda, vamos codificar os r\u00f3tulos de especie para que possam ser usados pelos modelos que vamos treinar.</p>"},{"location":"aulas/IA/lab02/ml-classificador-iris.html#labelencoder","title":"LabelEncoder\u00b6","text":"<ul> <li>LabelEncoder: Converte cada categoria em um valor inteiro \u00fanico. Cada categoria recebe um n\u00famero inteiro diferente, e os valores num\u00e9ricos n\u00e3o t\u00eam rela\u00e7\u00e3o direta entre si al\u00e9m de representar categorias distintas. As categorias s\u00e3o ordenadas alfabeticamente e cada categoria recebe um valor correspondente.</li> </ul>"},{"location":"aulas/IA/lab02/ml-classificador-iris.html#dividindo-os-dados-em-conjunto-de-treinamento-e-de-testes","title":"Dividindo os dados em conjunto de treinamento e de testes\u00b6","text":"<p>Em qualquer projeto de aprendizado de m\u00e1quina, uma pr\u00e1tica essencial \u00e9 <code>separar</code> os dados em conjuntos de <code>treinamento e teste</code>.</p> <p>Isso permite treinar o modelo em um subconjunto dos dados e avali\u00e1-lo em outro subconjunto, garantindo que o modelo n\u00e3o seja avaliado nos mesmos dados em que foi treinado.</p> <p>A fun\u00e7\u00e3o <code>train_test_split</code> facilita esse processo, dividindo os dados em duas ou mais partes de forma aleat\u00f3ria ou estratificada.</p> <p>O par\u00e2metro <code>test_size</code> define a propor\u00e7\u00e3o dos dados reservada para o teste, e o par\u00e2metro <code>random_state</code> garante a reprodutibilidade do processo.</p> <p>Dividir nosso dataset em dois conjuntos de dados.</p> <ul> <li><code>Treinamento</code> - Representa <code>80%</code> das amostras do conjunto de dados original.</li> <li><code>Teste</code> - com <code>20%</code> das amostras</li> </ul>"},{"location":"aulas/IA/lab02/ml-classificador-iris.html#chegou-a-hora-de-treinar-os-modelos","title":"Chegou a hora de treinar os modelos\u00b6","text":"<p>Treinar um modelo no python \u00e9 simples se usar o Scikit-Learn.</p> <p></p> <p>Treinar um modelo no Scikit-Learn \u00e9 simples: basta criar o classificador, e chamar o m\u00e9todo fit().</p> <p>Uma observa\u00e7\u00e3o sobre a sintaxe dos classificadores do <code>scikit-learn</code></p> <ul> <li>O m\u00e9todo <code>fit(X,Y)</code> recebe uma matriz ou dataframe X onde cada linha \u00e9 uma amostra de aprendizado, e um array Y contendo as sa\u00eddas esperadas do classificador, seja na forma de texto ou de inteiros</li> <li>O m\u00e9todo <code>predict(X)</code> recebe uma matriz ou dataframe X onde cada linha \u00e9 uma amostra de teste, retornando um array de classes</li> </ul>"},{"location":"aulas/IA/lab02/ml-classificador-iris.html#treinamento-usando-algoritmo-knn","title":"Treinamento usando algoritmo KNN\u00b6","text":""},{"location":"aulas/IA/lab02/ml-classificador-iris.html#predicao-para-novos-dados","title":"Predi\u00e7\u00e3o para novos dados\u00b6","text":"<p>Vamos fazer a predi\u00e7\u00e3o para uma flor com as seguintes dimens\u00f5es:</p> <ul> <li>sepal_length = 5.1</li> <li>sepal_width = 3.5</li> <li>petal_length = 1.4</li> <li>petal_width = 0.2</li> </ul>"},{"location":"aulas/IA/lab02/ml-classificador-iris.html#avaliacao-do-modelo-treinado","title":"Avalia\u00e7\u00e3o do modelo treinado\u00b6","text":"<p>A avalia\u00e7\u00e3o de modelos \u00e9 uma etapa importante no pipeline de machine learning.</p> <p>Para cada tipo de tarefa (classifica\u00e7\u00e3o, regress\u00e3o ou clusteriza\u00e7\u00e3o), diferentes m\u00e9tricas s\u00e3o usadas para medir o qu\u00e3o bem o modelo est\u00e1 desempenhando. A seguir, exploramos as principais m\u00e9tricas oferecidas pelo scikit-learn.</p>"},{"location":"aulas/IA/lab02/ml-classificador-iris.html#em-resumo-avaliacao-de-modelos","title":"Em resumo: Avalia\u00e7\u00e3o de Modelos\u00b6","text":"<ul> <li>Acur\u00e1cia: Percentual de previs\u00f5es corretas.</li> <li>Precis\u00e3o: Propor\u00e7\u00e3o de previs\u00f5es positivas corretas (evita falsos positivos).</li> <li>Recall: Propor\u00e7\u00e3o de casos positivos identificados (evita falsos negativos).</li> <li>F1-score: M\u00e9dia harm\u00f4nica de precis\u00e3o e recall, utilizado para datasets desbalanceados.</li> </ul>"},{"location":"aulas/IA/lab02/ml-classificador-iris.html#treinamento-usando-algoritmo-arvore-de-decisao","title":"Treinamento usando algoritmo \u00c1rvore de Decis\u00e3o\u00b6","text":""},{"location":"aulas/IA/lab02/ml-classificador-iris.html#visualizacao-da-arvore","title":"Visualiza\u00e7\u00e3o da \u00e1rvore\u00b6","text":""},{"location":"aulas/IA/lab02/ml-classificador-iris.html#predicao-para-novos-dados","title":"Predi\u00e7\u00e3o para novos dados\u00b6","text":"<p>Vamos fazer a predi\u00e7\u00e3o para uma flor com as seguintes dimens\u00f5es:</p> <ul> <li>sepal_length = 5.1</li> <li>sepal_width = 3.5</li> <li>petal_length = 1.4</li> <li>petal_width = 0.2</li> </ul>"},{"location":"aulas/IA/lab02/ml-classificador-iris.html#ajustando-os-hiperparametros-do-modelo-knn","title":"Ajustando os hiperpar\u00e2metros do modelo KNN\u00b6","text":"<p>Ao ajustar esses hiperpar\u00e2metros usando o Grid Search, podemos encontrar a combina\u00e7\u00e3o ideal de hiperpar\u00e2metros que leva \u00e0 melhor performance do modelo em um conjunto de dados espec\u00edfico.</p> <p>Existem v\u00e1rios hiperpar\u00e2metros do modelo K-Nearest Neighbors (KNN) que podem ser ajustados usando o Grid Search. Alguns dos hiperpar\u00e2metros mais comuns s\u00e3o:</p> <ul> <li><p><code>n_neighbors</code>: o n\u00famero de vizinhos mais pr\u00f3ximos a serem considerados no modelo.</p> </li> <li><p><code>weights</code>: como ponderar a contribui\u00e7\u00e3o dos vizinhos mais pr\u00f3ximos. Op\u00e7\u00f5es comuns s\u00e3o <code>uniform</code>, onde todos os vizinhos t\u00eam peso igual, e <code>distance</code>, onde o peso \u00e9 inversamente proporcional \u00e0 dist\u00e2ncia do ponto de consulta aos vizinhos.</p> </li> <li><p><code>p</code>: a m\u00e9trica de dist\u00e2ncia a ser usada. O valor padr\u00e3o \u00e9 <code>p=2</code>, que corresponde \u00e0 dist\u00e2ncia Euclidiana. Outras op\u00e7\u00f5es incluem <code>p=1</code>, que corresponde \u00e0 dist\u00e2ncia de Manhattan, e <code>p=inf</code>, que corresponde \u00e0 dist\u00e2ncia m\u00e1xima.</p> </li> <li><p><code>algorithm</code>: o algoritmo usado para calcular os vizinhos mais pr\u00f3ximos. As op\u00e7\u00f5es comuns s\u00e3o <code>brute</code>, que for\u00e7a uma busca exaustiva sobre todos os pontos de treinamento, e <code>kd_tree</code> e <code>ball_tree</code>, que usam estruturas de dados mais eficientes para acelerar a busca.</p> </li> <li><p><code>leaf_size</code>: o tamanho da folha para a \u00e1rvore de busca, que afeta a efici\u00eancia do algoritmo.</p> </li> </ul>"},{"location":"aulas/IA/lab02/ml-classificador-iris.html#ajustando-os-hiperparametros-do-modelo-de-arvore-de-decisao","title":"Ajustando os hiperpar\u00e2metros do modelo de \u00e1rvore de decis\u00e3o\u00b6","text":"<p>Existem v\u00e1rios hiperpar\u00e2metros da \u00c1rvore de Decis\u00e3o que podem ser ajustados usando o Grid Search. Alguns dos hiperpar\u00e2metros mais comuns s\u00e3o:</p> <ul> <li><p><code>criterion</code>: a fun\u00e7\u00e3o usada para medir a qualidade da divis\u00e3o em cada n\u00f3 da \u00e1rvore. As op\u00e7\u00f5es comuns s\u00e3o <code>gini</code> e <code>entropy</code>.</p> </li> <li><p><code>splitter</code>: a estrat\u00e9gia usada para escolher a vari\u00e1vel que divide o conjunto de dados em cada n\u00f3. As op\u00e7\u00f5es comuns s\u00e3o <code>best</code>, que escolhe a melhor divis\u00e3o poss\u00edvel, e <code>random</code>, que escolhe uma divis\u00e3o aleat\u00f3ria.</p> </li> <li><p><code>max_depth</code>: a profundidade m\u00e1xima da \u00e1rvore. Se definido como <code>None</code>, os n\u00f3s ser\u00e3o expandidos at\u00e9 que todas as folhas contenham menos de min_samples_split amostras ou todas as amostras sejam classificadas.</p> </li> <li><p><code>min_samples_split</code>: o n\u00famero m\u00ednimo de amostras necess\u00e1rias para dividir um n\u00f3 interno.</p> </li> <li><p><code>min_samples_leaf</code>: o n\u00famero m\u00ednimo de amostras necess\u00e1rias para ser uma folha.</p> </li> <li><p><code>max_features</code>: o n\u00famero m\u00e1ximo de recursos que podem ser considerados em cada divis\u00e3o.</p> </li> <li><p><code>max_leaf_nodes</code>: o n\u00famero m\u00e1ximo de folhas permitidas na \u00e1rvore.</p> </li> </ul>"},{"location":"aulas/IA/lab02/ml-classificador-iris.html#comparando-os-melhores-modelos-treinados-de-cada-algoritmo","title":"Comparando os melhores modelos treinados de cada algoritmo\u00b6","text":"<p>Por fim, podemos comparar a performance dos modelos de KNN e \u00e1rvore de decis\u00e3o.</p>"},{"location":"aulas/IA/lab02/ml-classificador-iris.html#salvando-os-modelos-treinados-para-uso-futuro","title":"Salvando os modelos treinados para uso futuro\u00b6","text":"<p>Ap\u00f3s a avalia\u00e7\u00e3o, o modelo com melhor desempenho pode ser escolhido para implanta\u00e7\u00e3o em um ambiente de produ\u00e7\u00e3o. Iremos fazer em outro c\u00f3digo (em breve)</p>"},{"location":"aulas/IA/lab02/ml-classificador-old.html","title":"Ml classificador old","text":"In\u00a0[105]: Copied! <pre># Inicializ\u00e7\u00e3o das bibliotecas\n%matplotlib inline\n\nimport pandas as pd\nimport matplotlib.pyplot as plt\n</pre> # Inicializ\u00e7\u00e3o das bibliotecas %matplotlib inline  import pandas as pd import matplotlib.pyplot as plt  In\u00a0[106]: Copied! <pre># Caminho do arquivo\nurl = \"https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data\"\n# Define o nome das colunas\nheader = ['sepal_length', 'sepal_width', 'petal_length', 'petal_width', 'species']\n# L\u00ea e carrega o arquivo para a mem\u00f3ria\ndf = pd.read_csv(url, header=None, names=header)\n</pre> # Caminho do arquivo url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data\" # Define o nome das colunas header = ['sepal_length', 'sepal_width', 'petal_length', 'petal_width', 'species'] # L\u00ea e carrega o arquivo para a mem\u00f3ria df = pd.read_csv(url, header=None, names=header) In\u00a0[107]: Copied! <pre># Retorna um trecho com as 5 primeiras linhas do dataframe\ndf.head()\n</pre> # Retorna um trecho com as 5 primeiras linhas do dataframe df.head() Out[107]: sepal_length sepal_width petal_length petal_width species 0 5.1 3.5 1.4 0.2 Iris-setosa 1 4.9 3.0 1.4 0.2 Iris-setosa 2 4.7 3.2 1.3 0.2 Iris-setosa 3 4.6 3.1 1.5 0.2 Iris-setosa 4 5.0 3.6 1.4 0.2 Iris-setosa In\u00a0[108]: Copied! <pre>df.tail()\n</pre> df.tail() Out[108]: sepal_length sepal_width petal_length petal_width species 145 6.7 3.0 5.2 2.3 Iris-virginica 146 6.3 2.5 5.0 1.9 Iris-virginica 147 6.5 3.0 5.2 2.0 Iris-virginica 148 6.2 3.4 5.4 2.3 Iris-virginica 149 5.9 3.0 5.1 1.8 Iris-virginica In\u00a0[109]: Copied! <pre># Mostra informa\u00e7\u00f5es sobre o dataframe em si\ndf.info()\n</pre> # Mostra informa\u00e7\u00f5es sobre o dataframe em si df.info() <pre>&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 150 entries, 0 to 149\nData columns (total 5 columns):\n #   Column        Non-Null Count  Dtype  \n---  ------        --------------  -----  \n 0   sepal_length  150 non-null    float64\n 1   sepal_width   150 non-null    float64\n 2   petal_length  150 non-null    float64\n 3   petal_width   150 non-null    float64\n 4   species       150 non-null    object \ndtypes: float64(4), object(1)\nmemory usage: 6.0+ KB\n</pre> In\u00a0[110]: Copied! <pre># class distribution\nprint(df.groupby('species').size())\n</pre> # class distribution print(df.groupby('species').size()) <pre>species\nIris-setosa        50\nIris-versicolor    50\nIris-virginica     50\ndtype: int64\n</pre> In\u00a0[111]: Copied! <pre>## Sua resposta e seus gr\u00e1ficos para an\u00e1lisar..\n</pre> ## Sua resposta e seus gr\u00e1ficos para an\u00e1lisar..       In\u00a0[112]: Copied! <pre># instalando a biblioteca scikit-learn\n\n!pip install scikit-learn --quiet\n</pre> # instalando a biblioteca scikit-learn  !pip install scikit-learn --quiet In\u00a0[113]: Copied! <pre># Codificando os r\u00f3tulos de especies\n\nfrom sklearn.preprocessing import LabelEncoder\n\nle = LabelEncoder()\ndf['species'] = le.fit_transform(df['species'])\n</pre> # Codificando os r\u00f3tulos de especies  from sklearn.preprocessing import LabelEncoder  le = LabelEncoder() df['species'] = le.fit_transform(df['species']) In\u00a0[114]: Copied! <pre># Verificando o dataframe ap\u00f3s a codifica\u00e7\u00e3o\ndf.head()\n</pre> # Verificando o dataframe ap\u00f3s a codifica\u00e7\u00e3o df.head() Out[114]: sepal_length sepal_width petal_length petal_width species 0 5.1 3.5 1.4 0.2 0 1 4.9 3.0 1.4 0.2 0 2 4.7 3.2 1.3 0.2 0 3 4.6 3.1 1.5 0.2 0 4 5.0 3.6 1.4 0.2 0 In\u00a0[115]: Copied! <pre>df.groupby('species').size()\n</pre> df.groupby('species').size() Out[115]: <pre>species\n0    50\n1    50\n2    50\ndtype: int64</pre> In\u00a0[116]: Copied! <pre># Separamos 20% para o teste\nfrom sklearn.model_selection import train_test_split\n\n## define entradas de dados e o target\n\nX = df.iloc[:, :-1]\ny = df['species']\n\n# Separando os dados em conjunto de treinamento e teste\nX_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.2, random_state=42)\n\nprint(f\"Formato das tabelas de dados de treino {X_train.shape} e teste {y_train.shape}\")\n</pre> # Separamos 20% para o teste from sklearn.model_selection import train_test_split  ## define entradas de dados e o target  X = df.iloc[:, :-1] y = df['species']  # Separando os dados em conjunto de treinamento e teste X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.2, random_state=42)  print(f\"Formato das tabelas de dados de treino {X_train.shape} e teste {y_train.shape}\") <pre>Formato das tabelas de dados de treino (120, 4) e teste (120,)\n</pre> In\u00a0[117]: Copied! <pre>#Primeiras linhas do dataframe de treino \nX_train.head()\n</pre> #Primeiras linhas do dataframe de treino  X_train.head() Out[117]: sepal_length sepal_width petal_length petal_width 22 4.6 3.6 1.0 0.2 15 5.7 4.4 1.5 0.4 65 6.7 3.1 4.4 1.4 11 4.8 3.4 1.6 0.2 42 4.4 3.2 1.3 0.2 In\u00a0[118]: Copied! <pre>y_train.tail()\n</pre> y_train.tail() Out[118]: <pre>71     1\n106    2\n14     0\n92     1\n102    2\nName: species, dtype: int64</pre> In\u00a0[119]: Copied! <pre># Importa a biblioteca\nfrom sklearn.neighbors import KNeighborsClassifier\n\n# Cria o classificar KNN\nk = 3\nknn = KNeighborsClassifier(n_neighbors=k)\n\n# Cria o modelo de machine learning\nknn.fit(X_train, y_train)\n</pre> # Importa a biblioteca from sklearn.neighbors import KNeighborsClassifier  # Cria o classificar KNN k = 3 knn = KNeighborsClassifier(n_neighbors=k)  # Cria o modelo de machine learning knn.fit(X_train, y_train) Out[119]: <pre>KNeighborsClassifier(n_neighbors=3)</pre>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.KNeighborsClassifier?Documentation for KNeighborsClassifieriFitted Parameters n_neighbors\u00a0 3 weights\u00a0 'uniform' algorithm\u00a0 'auto' leaf_size\u00a0 30 p\u00a0 2 metric\u00a0 'minkowski' metric_params\u00a0 None n_jobs\u00a0 None <p>Pronto!! bora testar se esta funcionando....</p> <p>Vamos fazer predi\u00e7\u00f5es para os dados do conjunto de teste</p> In\u00a0[120]: Copied! <pre># Realizando previs\u00f5es\n\ny_pred = knn.predict(X_test)\n\n# vendo as previs\u00f5es\nprint(y_pred)\n</pre> # Realizando previs\u00f5es  y_pred = knn.predict(X_test)  # vendo as previs\u00f5es print(y_pred)  <pre>[1 0 2 1 1 0 1 2 1 1 2 0 0 0 0 1 2 1 1 2 0 2 0 2 2 2 2 2 0 0]\n</pre> In\u00a0[121]: Copied! <pre># novas previs\u00f5es\nsepal_length = 5.1\nsepal_width = 3.5\npetal_length = 1.4\npetal_width = 0.2\n\ndado = pd.DataFrame([[sepal_length, sepal_width, petal_length, petal_width]], columns=X.columns)\n\nnova_previsao = knn.predict(dado)\n\nprint(\"Novas previs\u00f5es:\", nova_previsao)\n\n# com o r\u00f3tulo original\nprint(\"R\u00f3tulo original:\", le.inverse_transform(nova_previsao))  \n</pre> # novas previs\u00f5es sepal_length = 5.1 sepal_width = 3.5 petal_length = 1.4 petal_width = 0.2  dado = pd.DataFrame([[sepal_length, sepal_width, petal_length, petal_width]], columns=X.columns)  nova_previsao = knn.predict(dado)  print(\"Novas previs\u00f5es:\", nova_previsao)  # com o r\u00f3tulo original print(\"R\u00f3tulo original:\", le.inverse_transform(nova_previsao))   <pre>Novas previs\u00f5es: [0]\nR\u00f3tulo original: ['Iris-setosa']\n</pre> In\u00a0[122]: Copied! <pre># a probabilidade da predi\u00e7\u00e3o\nprob = knn.predict_proba(dado)\nprint(\"Probabilidade da predi\u00e7\u00e3o:\", prob)\n</pre> # a probabilidade da predi\u00e7\u00e3o prob = knn.predict_proba(dado) print(\"Probabilidade da predi\u00e7\u00e3o:\", prob) <pre>Probabilidade da predi\u00e7\u00e3o: [[1. 0. 0.]]\n</pre> In\u00a0[123]: Copied! <pre># Avaliando o modelo\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n\nprint(\"Acur\u00e1cia: \", accuracy_score(y_test, y_pred))\nprint(\"Precis\u00e3o: \", precision_score(y_test, y_pred, average='macro'))\nprint(\"Recall: \", recall_score(y_test, y_pred, average='macro'))\nprint(\"F1-score: \", f1_score(y_test, y_pred, average='macro'))\n\n## average='macro': m\u00e9trica \u00e9 calculada para cada classe individualmente e, em seguida, a m\u00e9dia n\u00e3o ponderada das m\u00e9tricas de cada classe \u00e9 retornada.\n##  Isso significa que todas as classes t\u00eam a mesma import\u00e2ncia no c\u00e1lculo da m\u00e9trica.\n</pre>  # Avaliando o modelo from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score  print(\"Acur\u00e1cia: \", accuracy_score(y_test, y_pred)) print(\"Precis\u00e3o: \", precision_score(y_test, y_pred, average='macro')) print(\"Recall: \", recall_score(y_test, y_pred, average='macro')) print(\"F1-score: \", f1_score(y_test, y_pred, average='macro'))  ## average='macro': m\u00e9trica \u00e9 calculada para cada classe individualmente e, em seguida, a m\u00e9dia n\u00e3o ponderada das m\u00e9tricas de cada classe \u00e9 retornada. ##  Isso significa que todas as classes t\u00eam a mesma import\u00e2ncia no c\u00e1lculo da m\u00e9trica. <pre>Acur\u00e1cia:  1.0\nPrecis\u00e3o:  1.0\nRecall:  1.0\nF1-score:  1.0\n</pre> In\u00a0[124]: Copied! <pre>from sklearn.model_selection import GridSearchCV\n\n\n# Definindo os valores para os hiperpar\u00e2metros\nparam_grid = {'n_neighbors': [3, 5, 7, 9], 'weights': ['uniform', 'distance'], 'algorithm': ['ball_tree', 'kd_tree', 'brute'], 'p': [1, 2]}\n\n# Criando o objeto GridSearchCV\ngrid = GridSearchCV(KNeighborsClassifier(), param_grid, verbose=1, cv=5, n_jobs=-1)\n\n# Ajustando o modelo com os dados de treinamento\ngrid.fit(X_train, y_train)\n\n# Imprimindo os melhores hiperpar\u00e2metros encontrados\nprint(\"Melhores hiperpar\u00e2metros: \", grid.best_params_)\n\n# Realizando previs\u00f5es e avaliando o modelo com os melhores hiperpar\u00e2metros\ny_pred = grid.predict(X_test)\nprint(\"Acur\u00e1cia: \", accuracy_score(y_test, y_pred))\nprint(\"Precis\u00e3o: \", precision_score(y_test, y_pred, average='macro'))\nprint(\"Recall: \", recall_score(y_test, y_pred, average='macro'))\nprint(\"F1-score: \", f1_score(y_test, y_pred, average='macro'))\n</pre> from sklearn.model_selection import GridSearchCV   # Definindo os valores para os hiperpar\u00e2metros param_grid = {'n_neighbors': [3, 5, 7, 9], 'weights': ['uniform', 'distance'], 'algorithm': ['ball_tree', 'kd_tree', 'brute'], 'p': [1, 2]}  # Criando o objeto GridSearchCV grid = GridSearchCV(KNeighborsClassifier(), param_grid, verbose=1, cv=5, n_jobs=-1)  # Ajustando o modelo com os dados de treinamento grid.fit(X_train, y_train)  # Imprimindo os melhores hiperpar\u00e2metros encontrados print(\"Melhores hiperpar\u00e2metros: \", grid.best_params_)  # Realizando previs\u00f5es e avaliando o modelo com os melhores hiperpar\u00e2metros y_pred = grid.predict(X_test) print(\"Acur\u00e1cia: \", accuracy_score(y_test, y_pred)) print(\"Precis\u00e3o: \", precision_score(y_test, y_pred, average='macro')) print(\"Recall: \", recall_score(y_test, y_pred, average='macro')) print(\"F1-score: \", f1_score(y_test, y_pred, average='macro')) <pre>Fitting 5 folds for each of 48 candidates, totalling 240 fits\nMelhores hiperpar\u00e2metros:  {'algorithm': 'ball_tree', 'n_neighbors': 3, 'p': 1, 'weights': 'uniform'}\nAcur\u00e1cia:  1.0\nPrecis\u00e3o:  1.0\nRecall:  1.0\nF1-score:  1.0\n</pre> In\u00a0[125]: Copied! <pre>from sklearn.tree import DecisionTreeClassifier\n\n# Definindo o modelo de \u00e1rvore de decis\u00e3o com hiperpar\u00e2metros padr\u00e3o\ntree = DecisionTreeClassifier(criterion='gini', max_depth=None, min_samples_split=2, min_samples_leaf=1, random_state=42)\ntree.fit(X_train, y_train)\n\n# Realizando previs\u00f5es e avaliando o modelo\ny_pred = tree.predict(X_test)\nprint(\"Acur\u00e1cia: \", accuracy_score(y_test, y_pred))\nprint(\"Precis\u00e3o: \", precision_score(y_test, y_pred, average='macro'))\nprint(\"Recall: \", recall_score(y_test, y_pred, average='macro'))\nprint(\"F1-score: \", f1_score(y_test, y_pred, average='macro'))\n</pre> from sklearn.tree import DecisionTreeClassifier  # Definindo o modelo de \u00e1rvore de decis\u00e3o com hiperpar\u00e2metros padr\u00e3o tree = DecisionTreeClassifier(criterion='gini', max_depth=None, min_samples_split=2, min_samples_leaf=1, random_state=42) tree.fit(X_train, y_train)  # Realizando previs\u00f5es e avaliando o modelo y_pred = tree.predict(X_test) print(\"Acur\u00e1cia: \", accuracy_score(y_test, y_pred)) print(\"Precis\u00e3o: \", precision_score(y_test, y_pred, average='macro')) print(\"Recall: \", recall_score(y_test, y_pred, average='macro')) print(\"F1-score: \", f1_score(y_test, y_pred, average='macro')) <pre>Acur\u00e1cia:  1.0\nPrecis\u00e3o:  1.0\nRecall:  1.0\nF1-score:  1.0\n</pre> In\u00a0[126]: Copied! <pre>from sklearn.tree import plot_tree\nimport matplotlib.pyplot as plt\n\nplt.figure(figsize=(12,8), dpi=400)\nplot_tree(tree, feature_names=X.columns, class_names=le.classes_, filled=True)\nplt.show()\n</pre> from sklearn.tree import plot_tree import matplotlib.pyplot as plt  plt.figure(figsize=(12,8), dpi=400) plot_tree(tree, feature_names=X.columns, class_names=le.classes_, filled=True) plt.show()  In\u00a0[127]: Copied! <pre># Definindo os valores para os hiperpar\u00e2metros\nparam_grid = {'criterion': ['gini', 'entropy'], 'max_depth': [None, 3, 5, 7], 'min_samples_split': [2, 5, 10], 'min_samples_leaf': [1, 2, 4]}\n\n# Criando o objeto GridSearchCV\ngrid = GridSearchCV(DecisionTreeClassifier(), param_grid, verbose=1, cv=5, n_jobs=-1)\n\n# Ajustando o modelo com os dados de treinamento\ngrid.fit(X_train, y_train)\n\n# Imprimindo os melhores hiperpar\u00e2metros encontrados\nprint(\"Melhores hiperpar\u00e2metros: \", grid.best_params_)\n\n# Realizando previs\u00f5es e avaliando o modelo com os melhores hiperpar\u00e2metros\ny_pred = grid.predict(X_test)\nprint(\"Acur\u00e1cia: \", accuracy_score(y_test, y_pred))\nprint(\"Precis\u00e3o: \", precision_score(y_test, y_pred, average='macro'))\nprint(\"Recall: \", recall_score(y_test, y_pred, average='macro'))\nprint(\"F1-score: \", f1_score(y_test, y_pred, average='macro'))\n</pre> # Definindo os valores para os hiperpar\u00e2metros param_grid = {'criterion': ['gini', 'entropy'], 'max_depth': [None, 3, 5, 7], 'min_samples_split': [2, 5, 10], 'min_samples_leaf': [1, 2, 4]}  # Criando o objeto GridSearchCV grid = GridSearchCV(DecisionTreeClassifier(), param_grid, verbose=1, cv=5, n_jobs=-1)  # Ajustando o modelo com os dados de treinamento grid.fit(X_train, y_train)  # Imprimindo os melhores hiperpar\u00e2metros encontrados print(\"Melhores hiperpar\u00e2metros: \", grid.best_params_)  # Realizando previs\u00f5es e avaliando o modelo com os melhores hiperpar\u00e2metros y_pred = grid.predict(X_test) print(\"Acur\u00e1cia: \", accuracy_score(y_test, y_pred)) print(\"Precis\u00e3o: \", precision_score(y_test, y_pred, average='macro')) print(\"Recall: \", recall_score(y_test, y_pred, average='macro')) print(\"F1-score: \", f1_score(y_test, y_pred, average='macro')) <pre>Fitting 5 folds for each of 72 candidates, totalling 360 fits\nMelhores hiperpar\u00e2metros:  {'criterion': 'entropy', 'max_depth': None, 'min_samples_leaf': 4, 'min_samples_split': 2}\nAcur\u00e1cia:  1.0\nPrecis\u00e3o:  1.0\nRecall:  1.0\nF1-score:  1.0\n</pre> In\u00a0[128]: Copied! <pre># Criando os modelos ( altere os parametros para os melhores hiperpar\u00e2metros encontrados)\nknn = KNeighborsClassifier(n_neighbors=3, weights='uniform', algorithm='ball_tree', p=1) \ntree = DecisionTreeClassifier(criterion='entropy', max_depth=None, min_samples_split=2, min_samples_leaf=4)\n\n# Ajustando os modelos com os dados de treinamento\nknn.fit(X_train, y_train)\ntree.fit(X_train, y_train)\n\n# Realizando previs\u00f5es e avaliando os modelos com os dados de teste\nknn_pred = knn.predict(X_test)\ntree_pred = tree.predict(X_test)\n\nprint(\"KNN - Acur\u00e1cia: \", accuracy_score(y_test, knn_pred))\nprint(\"KNN - Precis\u00e3o: \", precision_score(y_test, knn_pred, average='macro'))\nprint(\"KNN - Recall: \", recall_score(y_test, knn_pred, average='macro'))\nprint(\"KNN - F1-score: \", f1_score(y_test, knn_pred, average='macro'))\n\nprint(\"\u00c1rvore de Decis\u00e3o - Acur\u00e1cia: \", accuracy_score(y_test, tree_pred))\nprint(\"\u00c1rvore de Decis\u00e3o - Precis\u00e3o: \", precision_score(y_test, tree_pred, average='macro'))\nprint(\"\u00c1rvore de Decis\u00e3o - Recall: \", recall_score(y_test, tree_pred, average='macro'))\nprint(\"\u00c1rvore de Decis\u00e3o - F1-score: \", f1_score(y_test, tree_pred, average='macro'))\n</pre> # Criando os modelos ( altere os parametros para os melhores hiperpar\u00e2metros encontrados) knn = KNeighborsClassifier(n_neighbors=3, weights='uniform', algorithm='ball_tree', p=1)  tree = DecisionTreeClassifier(criterion='entropy', max_depth=None, min_samples_split=2, min_samples_leaf=4)  # Ajustando os modelos com os dados de treinamento knn.fit(X_train, y_train) tree.fit(X_train, y_train)  # Realizando previs\u00f5es e avaliando os modelos com os dados de teste knn_pred = knn.predict(X_test) tree_pred = tree.predict(X_test)  print(\"KNN - Acur\u00e1cia: \", accuracy_score(y_test, knn_pred)) print(\"KNN - Precis\u00e3o: \", precision_score(y_test, knn_pred, average='macro')) print(\"KNN - Recall: \", recall_score(y_test, knn_pred, average='macro')) print(\"KNN - F1-score: \", f1_score(y_test, knn_pred, average='macro'))  print(\"\u00c1rvore de Decis\u00e3o - Acur\u00e1cia: \", accuracy_score(y_test, tree_pred)) print(\"\u00c1rvore de Decis\u00e3o - Precis\u00e3o: \", precision_score(y_test, tree_pred, average='macro')) print(\"\u00c1rvore de Decis\u00e3o - Recall: \", recall_score(y_test, tree_pred, average='macro')) print(\"\u00c1rvore de Decis\u00e3o - F1-score: \", f1_score(y_test, tree_pred, average='macro')) <pre>KNN - Acur\u00e1cia:  1.0\nKNN - Precis\u00e3o:  1.0\nKNN - Recall:  1.0\nKNN - F1-score:  1.0\n\u00c1rvore de Decis\u00e3o - Acur\u00e1cia:  1.0\n\u00c1rvore de Decis\u00e3o - Precis\u00e3o:  1.0\n\u00c1rvore de Decis\u00e3o - Recall:  1.0\n\u00c1rvore de Decis\u00e3o - F1-score:  1.0\n</pre> In\u00a0[137]: Copied! <pre>from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n\ncm = confusion_matrix(y_test, tree_pred)\ndisp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=le.classes_)\n\ndisp.plot()\nplt.show()\n</pre> from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay  cm = confusion_matrix(y_test, tree_pred) disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=le.classes_)  disp.plot() plt.show() <pre>\n---------------------------------------------------------------------------\nValueError                                Traceback (most recent call last)\nCell In[137], line 6\n      3 cm = confusion_matrix(y_test, tree_pred)\n      4 disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=le.classes_)\n----&gt; 6 disp.plot()\n      7 plt.show()\n\nFile ~/cognitivecomputing/.venv/lib/python3.12/site-packages/sklearn/metrics/_plot/confusion_matrix.py:188, in ConfusionMatrixDisplay.plot(self, include_values, cmap, xticks_rotation, values_format, ax, colorbar, im_kw, text_kw)\n    186 if colorbar:\n    187     fig.colorbar(self.im_, ax=ax)\n--&gt; 188 ax.set(\n    189     xticks=np.arange(n_classes),\n    190     yticks=np.arange(n_classes),\n    191     xticklabels=display_labels,\n    192     yticklabels=display_labels,\n    193     ylabel=\"True label\",\n    194     xlabel=\"Predicted label\",\n    195 )\n    197 ax.set_ylim((n_classes - 0.5, -0.5))\n    198 plt.setp(ax.get_xticklabels(), rotation=xticks_rotation)\n\nFile ~/cognitivecomputing/.venv/lib/python3.12/site-packages/matplotlib/artist.py:146, in Artist.__init_subclass__.&lt;locals&gt;.&lt;lambda&gt;(self, **kwargs)\n    138 if not hasattr(cls.set, '_autogenerated_signature'):\n    139     # Don't overwrite cls.set if the subclass or one of its parents\n    140     # has defined a set method set itself.\n    141     # If there was no explicit definition, cls.set is inherited from\n    142     # the hierarchy of auto-generated set methods, which hold the\n    143     # flag _autogenerated_signature.\n    144     return\n--&gt; 146 cls.set = lambda self, **kwargs: Artist.set(self, **kwargs)\n    147 cls.set.__name__ = \"set\"\n    148 cls.set.__qualname__ = f\"{cls.__qualname__}.set\"\n\nFile ~/cognitivecomputing/.venv/lib/python3.12/site-packages/matplotlib/artist.py:1241, in Artist.set(self, **kwargs)\n   1237 def set(self, **kwargs):\n   1238     # docstring and signature are auto-generated via\n   1239     # Artist._update_set_signature_and_docstring() at the end of the\n   1240     # module.\n-&gt; 1241     return self._internal_update(cbook.normalize_kwargs(kwargs, self))\n\nFile ~/cognitivecomputing/.venv/lib/python3.12/site-packages/matplotlib/artist.py:1233, in Artist._internal_update(self, kwargs)\n   1226 def _internal_update(self, kwargs):\n   1227     \"\"\"\n   1228     Update artist properties without prenormalizing them, but generating\n   1229     errors as if calling `set`.\n   1230 \n   1231     The lack of prenormalization is to maintain backcompatibility.\n   1232     \"\"\"\n-&gt; 1233     return self._update_props(\n   1234         kwargs, \"{cls.__name__}.set() got an unexpected keyword argument \"\n   1235         \"{prop_name!r}\")\n\nFile ~/cognitivecomputing/.venv/lib/python3.12/site-packages/matplotlib/artist.py:1209, in Artist._update_props(self, props, errfmt)\n   1205             if not callable(func):\n   1206                 raise AttributeError(\n   1207                     errfmt.format(cls=type(self), prop_name=k),\n   1208                     name=k)\n-&gt; 1209             ret.append(func(v))\n   1210 if ret:\n   1211     self.pchanged()\n\nFile ~/cognitivecomputing/.venv/lib/python3.12/site-packages/matplotlib/axes/_base.py:74, in _axis_method_wrapper.__set_name__.&lt;locals&gt;.wrapper(self, *args, **kwargs)\n     73 def wrapper(self, *args, **kwargs):\n---&gt; 74     return get_method(self)(*args, **kwargs)\n\nFile ~/cognitivecomputing/.venv/lib/python3.12/site-packages/matplotlib/axis.py:2106, in Axis.set_ticklabels(self, labels, minor, fontdict, **kwargs)\n   2102 elif isinstance(locator, mticker.FixedLocator):\n   2103     # Passing [] as a list of labels is often used as a way to\n   2104     # remove all tick labels, so only error for &gt; 0 labels\n   2105     if len(locator.locs) != len(labels) and len(labels) != 0:\n-&gt; 2106         raise ValueError(\n   2107             \"The number of FixedLocator locations\"\n   2108             f\" ({len(locator.locs)}), usually from a call to\"\n   2109             \" set_ticks, does not match\"\n   2110             f\" the number of labels ({len(labels)}).\")\n   2111     tickd = {loc: lab for loc, lab in zip(locator.locs, labels)}\n   2112     func = functools.partial(self._format_with_dict, tickd)\n\nValueError: The number of FixedLocator locations (10), usually from a call to set_ticks, does not match the number of labels (3).</pre> In\u00a0[130]: Copied! <pre>from sklearn.datasets import load_digits\n\ndigits = load_digits()\nX, y = digits.data, digits.target\n</pre> from sklearn.datasets import load_digits  digits = load_digits() X, y = digits.data, digits.target  In\u00a0[131]: Copied! <pre># visualizando todos os atributos carregados em digits\ndir(digits)\n</pre> # visualizando todos os atributos carregados em digits dir(digits) Out[131]: <pre>['DESCR', 'data', 'feature_names', 'frame', 'images', 'target', 'target_names']</pre> In\u00a0[132]: Copied! <pre># Visualizando os primeiros 10 d\u00edgitos do dataset\nimport matplotlib.pyplot as plt\n\n\nfig, axes = plt.subplots(1, 10, figsize=(10,3))\n\nfor i, ax in enumerate(axes):\n    ax.imshow(digits.images[i], cmap='gray')\n    ax.set_title(digits.target[i])\n</pre> # Visualizando os primeiros 10 d\u00edgitos do dataset import matplotlib.pyplot as plt   fig, axes = plt.subplots(1, 10, figsize=(10,3))  for i, ax in enumerate(axes):     ax.imshow(digits.images[i], cmap='gray')     ax.set_title(digits.target[i])  In\u00a0[133]: Copied! <pre># Separando os dados em conjunto de treinamento e teste\nX_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.2, random_state=42)\n\nprint(f\"Formato das tabelas de dados de treino {X_train.shape} e teste {y_train.shape}\")\n</pre> # Separando os dados em conjunto de treinamento e teste X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.2, random_state=42)  print(f\"Formato das tabelas de dados de treino {X_train.shape} e teste {y_train.shape}\") <pre>Formato das tabelas de dados de treino (1437, 64) e teste (1437,)\n</pre> In\u00a0[134]: Copied! <pre># Criando os modelos ( altere os parametros para os melhores hiperpar\u00e2metros encontrados)\nknn = KNeighborsClassifier(n_neighbors=3, weights='uniform', algorithm='ball_tree', p=2) \ntree = DecisionTreeClassifier(criterion='entropy', max_depth=None, min_samples_split=2, min_samples_leaf=1)\n\n# Ajustando os modelos com os dados de treinamento\nknn.fit(X_train, y_train)\ntree.fit(X_train, y_train)\n\n# Realizando previs\u00f5es e avaliando os modelos com os dados de teste\nknn_pred = knn.predict(X_test)\ntree_pred = tree.predict(X_test)\n\nprint(\"KNN - Acur\u00e1cia: \", accuracy_score(y_test, knn_pred))\nprint(\"KNN - Precis\u00e3o: \", precision_score(y_test, knn_pred, average='macro'))\nprint(\"KNN - Recall: \", recall_score(y_test, knn_pred, average='macro'))\nprint(\"KNN - F1-score: \", f1_score(y_test, knn_pred, average='macro'))\n\nprint(\"\u00c1rvore de Decis\u00e3o - Acur\u00e1cia: \", accuracy_score(y_test, tree_pred))\nprint(\"\u00c1rvore de Decis\u00e3o - Precis\u00e3o: \", precision_score(y_test, tree_pred, average='macro'))\nprint(\"\u00c1rvore de Decis\u00e3o - Recall: \", recall_score(y_test, tree_pred, average='macro'))\nprint(\"\u00c1rvore de Decis\u00e3o - F1-score: \", f1_score(y_test, tree_pred, average='macro'))\n</pre> # Criando os modelos ( altere os parametros para os melhores hiperpar\u00e2metros encontrados) knn = KNeighborsClassifier(n_neighbors=3, weights='uniform', algorithm='ball_tree', p=2)  tree = DecisionTreeClassifier(criterion='entropy', max_depth=None, min_samples_split=2, min_samples_leaf=1)  # Ajustando os modelos com os dados de treinamento knn.fit(X_train, y_train) tree.fit(X_train, y_train)  # Realizando previs\u00f5es e avaliando os modelos com os dados de teste knn_pred = knn.predict(X_test) tree_pred = tree.predict(X_test)  print(\"KNN - Acur\u00e1cia: \", accuracy_score(y_test, knn_pred)) print(\"KNN - Precis\u00e3o: \", precision_score(y_test, knn_pred, average='macro')) print(\"KNN - Recall: \", recall_score(y_test, knn_pred, average='macro')) print(\"KNN - F1-score: \", f1_score(y_test, knn_pred, average='macro'))  print(\"\u00c1rvore de Decis\u00e3o - Acur\u00e1cia: \", accuracy_score(y_test, tree_pred)) print(\"\u00c1rvore de Decis\u00e3o - Precis\u00e3o: \", precision_score(y_test, tree_pred, average='macro')) print(\"\u00c1rvore de Decis\u00e3o - Recall: \", recall_score(y_test, tree_pred, average='macro')) print(\"\u00c1rvore de Decis\u00e3o - F1-score: \", f1_score(y_test, tree_pred, average='macro'))    <pre>KNN - Acur\u00e1cia:  0.9833333333333333\nKNN - Precis\u00e3o:  0.9840299054067057\nKNN - Recall:  0.9840978306216105\nKNN - F1-score:  0.9838693018809959\n\u00c1rvore de Decis\u00e3o - Acur\u00e1cia:  0.8833333333333333\n\u00c1rvore de Decis\u00e3o - Precis\u00e3o:  0.8835099627511486\n\u00c1rvore de Decis\u00e3o - Recall:  0.8801782843319819\n\u00c1rvore de Decis\u00e3o - F1-score:  0.8813055670013833\n</pre> In\u00a0[135]: Copied! <pre>from sklearn.metrics import classification_report\n\nprint(classification_report(y_test, knn_pred))\nprint(classification_report(y_test, tree_pred))\n</pre> from sklearn.metrics import classification_report  print(classification_report(y_test, knn_pred)) print(classification_report(y_test, tree_pred)) <pre>              precision    recall  f1-score   support\n\n           0       1.00      1.00      1.00        33\n           1       0.97      1.00      0.98        28\n           2       1.00      1.00      1.00        33\n           3       0.97      1.00      0.99        34\n           4       0.98      1.00      0.99        46\n           5       0.98      0.98      0.98        47\n           6       0.97      1.00      0.99        35\n           7       1.00      0.97      0.99        34\n           8       1.00      0.97      0.98        30\n           9       0.97      0.93      0.95        40\n\n    accuracy                           0.98       360\n   macro avg       0.98      0.98      0.98       360\nweighted avg       0.98      0.98      0.98       360\n\n              precision    recall  f1-score   support\n\n           0       0.97      0.91      0.94        33\n           1       0.89      0.86      0.87        28\n           2       0.81      0.79      0.80        33\n           3       0.94      0.88      0.91        34\n           4       0.85      0.87      0.86        46\n           5       0.94      0.96      0.95        47\n           6       0.91      0.91      0.91        35\n           7       0.79      0.88      0.83        34\n           8       0.84      0.87      0.85        30\n           9       0.90      0.88      0.89        40\n\n    accuracy                           0.88       360\n   macro avg       0.88      0.88      0.88       360\nweighted avg       0.89      0.88      0.88       360\n\n</pre> In\u00a0[136]: Copied! <pre># sua resposta aqui...\n</pre> # sua resposta aqui..."},{"location":"aulas/IA/lab02/ml-classificador-old.html#objetivos","title":"Objetivos\u00b6","text":"<ul> <li>Conhecer algoritmos de classifica\u00e7\u00e3o, K-Nearest Neighbors (KNN) e \u00c1rvore de Decis\u00e3o;</li> <li>Como aplicar o Grid Search para encontrar os melhores par\u00e2metros para esses modelos.</li> </ul>"},{"location":"aulas/IA/lab02/ml-classificador-old.html#problemas-de-classicacao","title":"Problemas de classica\u00e7\u00e3o\u00b6","text":"<p>A classifica\u00e7\u00e3o \u00e9 uma das principais tarefas em aprendizado de m\u00e1quina e envolve a atribui\u00e7\u00e3o de um r\u00f3tulo ou categoria a um conjunto de dados. Por exemplo, podemos usar a classifica\u00e7\u00e3o para identificar se um e-mail \u00e9 spam ou n\u00e3o, se uma transa\u00e7\u00e3o financeira \u00e9 fraudulenta ou leg\u00edtima, ou para prever se um paciente desenvolver\u00e1 uma doen\u00e7a com base em seus dados m\u00e9dicos.</p> <p>Existem muitos desafios em problemas de classica\u00e7\u00e3o que o an\u00e1lista de dados deve levar em considera\u00e7\u00e3o, como a escolha do modelo de aprendizado de m\u00e1quina adequado, o ajuste dos hiperpar\u00e2metros do modelo, a sele\u00e7\u00e3o de features relevantes, o tratamento de dados adequado ao problema, o cuidado com overfitting e a avalia\u00e7\u00e3o correta do modelo.</p> <p>Al\u00e9m disso, diferentes modelos de classifica\u00e7\u00e3o t\u00eam seus pr\u00f3prios pontos fortes e fracos, e escolher o modelo certo para um problema espec\u00edfico pode ser dif\u00edcil.</p>"},{"location":"aulas/IA/lab02/ml-classificador-old.html#resumo-sobre-knn-e-arvore-de-decisao","title":"Resumo sobre KNN e \u00c1rvore de Decis\u00e3o\u00b6","text":"Algoritmo Aplica\u00e7\u00e3o Vantagens Desvantagens Contexto de uso \u00c1rvores de Decis\u00e3o Classifica\u00e7\u00e3o/Regress\u00e3o F\u00e1cil interpretabilidade, lida bem com dados faltantes, captura rela\u00e7\u00f5es n\u00e3o lineares Tend\u00eancia ao overfitting, pode ser sens\u00edvel a ru\u00eddo Problemas de classifica\u00e7\u00e3o/regress\u00e3o com rela\u00e7\u00f5es n\u00e3o lineares K-Nearest Neighbors (KNN) Classifica\u00e7\u00e3o/Regress\u00e3o F\u00e1cil de entender e implementar, lida bem com dados com muitas vari\u00e1veis de entrada Requer muita mem\u00f3ria para grandes conjuntos de dados, sens\u00edvel a outliers Problemas de classifica\u00e7\u00e3o/regress\u00e3o com muitas vari\u00e1veis de entrada e poucas classes poss\u00edveis"},{"location":"aulas/IA/lab02/ml-classificador-old.html#definicao-do-problema","title":"Defini\u00e7\u00e3o do problema\u00b6","text":"<p>A primeira coisa que precisamos fazer \u00e9 a defini\u00e7\u00e3o do problema. Neste primeiro caso vamos trabalhar com o mesmo dataset da \u00faltima aula, dataset iris. Vamos desenvolver um sistema de machine learning capaz de classificar a especie de flor Iris com base nos dimensionais da p\u00e9tala e sepala.</p>"},{"location":"aulas/IA/lab02/ml-classificador-old.html#relembrando-o-dataset-iris","title":"Relembrando o dataset Iris\u00b6","text":"<p>Iris \u00e9 um dataset de flor com 150 linhas, divididos em tr\u00eas esp\u00e9cies diferentes: setosa, versicolor e virginica, sendo 50 amostras de cada esp\u00e9cie. Os atributos de largura e comprimento de s\u00e9pala e largura e comprimento de p\u00e9tala de cada flor foram anotados manualmente.</p>"},{"location":"aulas/IA/lab02/ml-classificador-old.html#desafio-1","title":"Desafio 1\u00b6","text":"<p>Aplique os m\u00e9todos que achar conveniente (vimos algumas op\u00e7\u00f5es na \u00faltima aula) para visualizar os dados de forma gr\u00e1fica.</p>"},{"location":"aulas/IA/lab02/ml-classificador-old.html#pare","title":"PARE!!!\u00b6","text":"<p>A an\u00e1lise feita no desafio 1 \u00e9 uma das etapas mais importantes. Caso voc\u00ea tenha pulado essa etapa, volte e fa\u00e7a suas an\u00e1lises.</p>"},{"location":"aulas/IA/lab02/ml-classificador-old.html#scikit-learn","title":"scikit-learn\u00b6","text":"<p>Tamb\u00e9m conhecida como sklearn, \u00e9 uma biblioteca de c\u00f3digo aberto (open source) para a linguagem Python, essa biblioteca fornece uma ampla gama de ferramentas e algoritmos de aprendizado de m\u00e1quina de forma acess\u00edvel e eficiente.</p> <p></p> <p>Podemos dizer que o scikit-learn \u00e9 a ferramenta mais popular e utilizada em aprendizado de m\u00e1quina e existem alguns motivos para isso, tais como:</p> <ul> <li>Simplicidade e Consist\u00eancia: Todos os algoritmos no scikit-learn compartilham uma interface consistente, que segue um padr\u00e3o de m\u00e9todos como fit(), predict(), e transform(). Isso facilita a troca e experimenta\u00e7\u00e3o de diferentes algoritmos, promovendo um ambiente de desenvolvimento r\u00e1pido e eficiente.</li> <li>Compatibilidade e Integra\u00e7\u00e3o: O scikit-learn \u00e9 projetado para interoperabilidade com outras bibliotecas do ecossistema Python, como pandas para manipula\u00e7\u00e3o de dados, numpy para opera\u00e7\u00f5es num\u00e9ricas, e matplotlib para visualiza\u00e7\u00e3o. Essa integra\u00e7\u00e3o permite uma f\u00e1cil manipula\u00e7\u00e3o e transforma\u00e7\u00e3o de dados, bem como a visualiza\u00e7\u00e3o de resultados de modelos.</li> <li>Foco em Performance e Efici\u00eancia Computacional: Embora Python seja uma linguagem interpretada, a scikit-learn faz uso extensivo de opera\u00e7\u00f5es vetorizadas atrav\u00e9s de numpy e implementa\u00e7\u00f5es otimizadas em Cython (que \u00e9 uma linguagem de programa\u00e7\u00e3o que facilita a escrita de extens\u00f5es em C para Python) para acelerar o processamento de dados e a execu\u00e7\u00e3o de algoritmos. Isso proporciona uma execu\u00e7\u00e3o eficiente de tarefas complexas de machine learning, como treinamento de modelos e ajuste de hiperpar\u00e2metros.</li> </ul>"},{"location":"aulas/IA/lab02/ml-classificador-old.html#instalacao","title":"Instala\u00e7\u00e3o\u00b6","text":"<pre>pip install scikit-learn\n</pre> <p>Saiba mais: site da documenta\u00e7\u00e3o oficial https://scikit-learn.org/stable/</p>"},{"location":"aulas/IA/lab02/ml-classificador-old.html#codificando-os-dados","title":"Codificando os dados\u00b6","text":"<p>Com essa etapa conclu\u00edda, vamos codificar os r\u00f3tulos de especie para que possam ser usados pelos modelos que vamos treinar.</p>"},{"location":"aulas/IA/lab02/ml-classificador-old.html#labelencoder","title":"LabelEncoder\u00b6","text":"<ul> <li>LabelEncoder: Converte cada categoria em um valor inteiro \u00fanico. Cada categoria recebe um n\u00famero inteiro diferente, e os valores num\u00e9ricos n\u00e3o t\u00eam rela\u00e7\u00e3o direta entre si al\u00e9m de representar categorias distintas. As categorias s\u00e3o ordenadas alfabeticamente e cada categoria recebe um valor correspondente.</li> </ul>"},{"location":"aulas/IA/lab02/ml-classificador-old.html#dividindo-os-dados-em-conjunto-de-treinamento-e-de-testes","title":"Dividindo os dados em conjunto de treinamento e de testes\u00b6","text":"<p>Em qualquer projeto de aprendizado de m\u00e1quina, uma pr\u00e1tica essencial \u00e9 <code>separar</code> os dados em conjuntos de <code>treinamento e teste</code>. Isso permite treinar o modelo em um subconjunto dos dados e avali\u00e1-lo em outro subconjunto, garantindo que o modelo n\u00e3o seja avaliado nos mesmos dados em que foi treinado. A fun\u00e7\u00e3o train_test_split facilita esse processo, dividindo os dados em duas ou mais partes de forma aleat\u00f3ria ou estratificada. O par\u00e2metro test_size define a propor\u00e7\u00e3o dos dados reservada para o teste, e o par\u00e2metro random_state garante a reprodutibilidade do processo.</p> <p>Dividir nosso dataset em dois conjuntos de dados.</p> <ul> <li><code>Treinamento</code> - Representa <code>80%</code> das amostras do conjunto de dados original.</li> <li><code>Teste</code> - com <code>20%</code> das amostras</li> </ul>"},{"location":"aulas/IA/lab02/ml-classificador-old.html#chegou-a-hora-de-treinar-os-modelos","title":"Chegou a hora de treinar os modelos\u00b6","text":"<p>Treinar um modelo no python \u00e9 simples se usar o Scikit-Learn.</p> <p></p> <p>Treinar um modelo no Scikit-Learn \u00e9 simples: basta criar o classificador, e chamar o m\u00e9todo fit().</p> <p>Uma observa\u00e7\u00e3o sobre a sintaxe dos classificadores do <code>scikit-learn</code></p> <ul> <li>O m\u00e9todo <code>fit(X,Y)</code> recebe uma matriz ou dataframe X onde cada linha \u00e9 uma amostra de aprendizado, e um array Y contendo as sa\u00eddas esperadas do classificador, seja na forma de texto ou de inteiros</li> <li>O m\u00e9todo <code>predict(X)</code> recebe uma matriz ou dataframe X onde cada linha \u00e9 uma amostra de teste, retornando um array de classes</li> </ul>"},{"location":"aulas/IA/lab02/ml-classificador-old.html#treinamento-usando-algoritmo-knn","title":"Treinamento usando algoritmo KNN\u00b6","text":""},{"location":"aulas/IA/lab02/ml-classificador-old.html#predicao-para-novos-dados","title":"Predi\u00e7\u00e3o para novos dados\u00b6","text":"<p>Vamos fazer a predi\u00e7\u00e3o para uma flor com as seguintes dimens\u00f5es:</p> <ul> <li>sepal_length = 5.1</li> <li>sepal_width = 3.5</li> <li>petal_length = 1.4</li> <li>petal_width = 0.2</li> </ul>"},{"location":"aulas/IA/lab02/ml-classificador-old.html#avaliacao-do-modelo-treinado","title":"Avalia\u00e7\u00e3o do modelo treinado\u00b6","text":"<p>A avalia\u00e7\u00e3o de modelos \u00e9 uma etapa importante no pipeline de machine learning.</p> <p>Para cada tipo de tarefa (classifica\u00e7\u00e3o, regress\u00e3o ou clusteriza\u00e7\u00e3o), diferentes m\u00e9tricas s\u00e3o usadas para medir o qu\u00e3o bem o modelo est\u00e1 desempenhando. A seguir, exploramos as principais m\u00e9tricas oferecidas pelo scikit-learn.</p> <p>Acur\u00e1cia ou taxa de acerto \u00e9 a m\u00e9trica bastante popular em problemas de classifica\u00e7\u00e3o pois mede o n\u00famero de acertos do modelo dividido pelo n\u00famero total testado.</p> <p>Por exemplo, se o modelo possui uma acur\u00e1cia de 0.95 (95%) o seu modelo acerta 95 de 100 previs\u00f5es. Trata-se da m\u00e9trica mais simples e usada em datasets onde as classes s\u00e3o balanceadas, ou seja, possu\u00edmos propor\u00e7\u00f5es parecidas de amostras para cada uma das categorias.</p> <p>Em resumo:</p> <ul> <li>Acur\u00e1cia mede acertos totais;</li> <li>Precis\u00e3o foca em falsos positivos;</li> <li>Recall em falsos negativos;</li> <li>F1-score \u00e9 a m\u00e9dia harm\u00f4nica.</li> </ul>"},{"location":"aulas/IA/lab02/ml-classificador-old.html#ajustando-os-hiperparametros-do-modelo-knn","title":"Ajustando os hiperpar\u00e2metros do modelo KNN\u00b6","text":"<p>Ao ajustar esses hiperpar\u00e2metros usando o Grid Search, podemos encontrar a combina\u00e7\u00e3o ideal de hiperpar\u00e2metros que leva \u00e0 melhor performance do modelo em um conjunto de dados espec\u00edfico.</p> <p>Existem v\u00e1rios hiperpar\u00e2metros do modelo K-Nearest Neighbors (KNN) que podem ser ajustados usando o Grid Search. Alguns dos hiperpar\u00e2metros mais comuns s\u00e3o:</p> <ul> <li><p><code>n_neighbors</code>: o n\u00famero de vizinhos mais pr\u00f3ximos a serem considerados no modelo.</p> </li> <li><p><code>weights</code>: como ponderar a contribui\u00e7\u00e3o dos vizinhos mais pr\u00f3ximos. Op\u00e7\u00f5es comuns s\u00e3o <code>uniform</code>, onde todos os vizinhos t\u00eam peso igual, e <code>distance</code>, onde o peso \u00e9 inversamente proporcional \u00e0 dist\u00e2ncia do ponto de consulta aos vizinhos.</p> </li> <li><p><code>p</code>: a m\u00e9trica de dist\u00e2ncia a ser usada. O valor padr\u00e3o \u00e9 <code>p=2</code>, que corresponde \u00e0 dist\u00e2ncia Euclidiana. Outras op\u00e7\u00f5es incluem <code>p=1</code>, que corresponde \u00e0 dist\u00e2ncia de Manhattan, e <code>p=inf</code>, que corresponde \u00e0 dist\u00e2ncia m\u00e1xima.</p> </li> <li><p><code>algorithm</code>: o algoritmo usado para calcular os vizinhos mais pr\u00f3ximos. As op\u00e7\u00f5es comuns s\u00e3o <code>brute</code>, que for\u00e7a uma busca exaustiva sobre todos os pontos de treinamento, e <code>kd_tree</code> e <code>ball_tree</code>, que usam estruturas de dados mais eficientes para acelerar a busca.</p> </li> <li><p><code>leaf_size</code>: o tamanho da folha para a \u00e1rvore de busca, que afeta a efici\u00eancia do algoritmo.</p> </li> </ul>"},{"location":"aulas/IA/lab02/ml-classificador-old.html#treinamento-usando-algoritmo-arvore-de-decisao","title":"Treinamento usando algoritmo \u00c1rvore de Decis\u00e3o\u00b6","text":""},{"location":"aulas/IA/lab02/ml-classificador-old.html#visualizacao-da-arvore","title":"Visualiza\u00e7\u00e3o da \u00e1rvore\u00b6","text":""},{"location":"aulas/IA/lab02/ml-classificador-old.html#ajustando-os-hiperparametros-do-modelo-de-arvore-de-decisao","title":"Ajustando os hiperpar\u00e2metros do modelo de \u00e1rvore de decis\u00e3o\u00b6","text":"<p>Existem v\u00e1rios hiperpar\u00e2metros da \u00c1rvore de Decis\u00e3o que podem ser ajustados usando o Grid Search. Alguns dos hiperpar\u00e2metros mais comuns s\u00e3o:</p> <ul> <li><p><code>criterion</code>: a fun\u00e7\u00e3o usada para medir a qualidade da divis\u00e3o em cada n\u00f3 da \u00e1rvore. As op\u00e7\u00f5es comuns s\u00e3o <code>gini</code> e <code>entropy</code>.</p> </li> <li><p><code>splitter</code>: a estrat\u00e9gia usada para escolher a vari\u00e1vel que divide o conjunto de dados em cada n\u00f3. As op\u00e7\u00f5es comuns s\u00e3o <code>best</code>, que escolhe a melhor divis\u00e3o poss\u00edvel, e <code>random</code>, que escolhe uma divis\u00e3o aleat\u00f3ria.</p> </li> <li><p><code>max_depth</code>: a profundidade m\u00e1xima da \u00e1rvore. Se definido como <code>None</code>, os n\u00f3s ser\u00e3o expandidos at\u00e9 que todas as folhas contenham menos de min_samples_split amostras ou todas as amostras sejam classificadas.</p> </li> <li><p><code>min_samples_split</code>: o n\u00famero m\u00ednimo de amostras necess\u00e1rias para dividir um n\u00f3 interno.</p> </li> <li><p><code>min_samples_leaf</code>: o n\u00famero m\u00ednimo de amostras necess\u00e1rias para ser uma folha.</p> </li> <li><p><code>max_features</code>: o n\u00famero m\u00e1ximo de recursos que podem ser considerados em cada divis\u00e3o.</p> </li> <li><p><code>max_leaf_nodes</code>: o n\u00famero m\u00e1ximo de folhas permitidas na \u00e1rvore.</p> </li> </ul>"},{"location":"aulas/IA/lab02/ml-classificador-old.html#comparando-os-melhores-modelos-treinados-de-cada-algoritmo","title":"Comparando os melhores modelos treinados de cada algoritmo\u00b6","text":"<p>Por fim, podemos comparar a performance dos modelos de KNN e \u00e1rvore de decis\u00e3o.</p>"},{"location":"aulas/IA/lab02/ml-classificador-old.html#classificacao-de-digitos-0-9","title":"Classifica\u00e7\u00e3o de digitos 0-9\u00b6","text":"<p>Agora aplicamos os modelos a um dataset mais complexo: reconhecimento de d\u00edgitos manuscritos (0-9), com 1797 amostras e 64 features (pixels 8x8).</p> <p></p>"},{"location":"aulas/IA/lab02/ml-classificador-old.html#desafio-1","title":"Desafio 1\u00b6","text":"<p>Tente ajustar os hiperpar\u00e2metros dos modelos de KNN e \u00e1rvore de decis\u00e3o para melhorar ainda mais a performance dos modelos.</p>"},{"location":"aulas/IA/lab02/ml-classificador-old.html#desafio-2","title":"Desafio 2\u00b6","text":"<p>Pesquise sobre outros modelos de classifica\u00e7\u00e3o e compare-os com o KNN e \u00e1rvore de decis\u00e3o.</p> <p>Qual modelo \u00e9 o mais adequado para diferentes tipos de problemas de classifica\u00e7\u00e3o?</p>"},{"location":"aulas/IA/lab02/ml-classificador-renda.html","title":"Ml classificador renda","text":"In\u00a0[12]: Copied! <pre>%matplotlib inline\n\nimport pandas as pd\nimport numpy as np \nimport matplotlib.pyplot as plt \nimport seaborn as sns \n</pre> %matplotlib inline  import pandas as pd import numpy as np  import matplotlib.pyplot as plt  import seaborn as sns    In\u00a0[2]: Copied! <pre>df = pd.read_csv('df.csv', header = None)\n\ncolumns_name = ['age', 'workclass', 'fnlwgt', 'education', 'education_num', 'marital_status', 'occupation', 'relationship',\n             'race', 'sex', 'capital_gain', 'capital_loss', 'hours_per_week', 'native_country', 'income']\n\ndf.columns = columns_name\n\ndf.shape\n</pre> df = pd.read_csv('df.csv', header = None)  columns_name = ['age', 'workclass', 'fnlwgt', 'education', 'education_num', 'marital_status', 'occupation', 'relationship',              'race', 'sex', 'capital_gain', 'capital_loss', 'hours_per_week', 'native_country', 'income']  df.columns = columns_name  df.shape Out[2]: <pre>(32561, 15)</pre> <p>Descri\u00e7\u00e3o do dataset:</p> <pre><code>Age \u2013 idade \nWorkclass \u2013 classe de trabalho\nfnlwgt \u2013 n\u00famero de pessoas que amostra representa comparada a popula\u00e7\u00e3o.\nEducation \u2013 educa\u00e7\u00e3o\nEducation_Num \u2013 anos de escolaridade\nMartial_Status \u2013 Estado Civil\nOccupation \u2013 ocupa\u00e7\u00e3o, cargo que ocupa\nRelationship \u2013 parentesco\nRace \u2013 ra\u00e7a\nSex \u2013 sexo\nCapital_Gain \u2013 ganho capital\nCapital_Loss \u2013 perda capital\nHours_per_week \u2013 horas por semana\nCountry \u2013 Nacionalidade\n\nincome \u2013 renda anual</code></pre> In\u00a0[3]: Copied! <pre>df.head()\n</pre> df.head() Out[3]: age workclass fnlwgt education education_num marital_status occupation relationship race sex capital_gain capital_loss hours_per_week native_country income 0 39 State-gov 77516 Bachelors 13 Never-married Adm-clerical Not-in-family White Male 2174 0 40 United-States &lt;=50K 1 50 Self-emp-not-inc 83311 Bachelors 13 Married-civ-spouse Exec-managerial Husband White Male 0 0 13 United-States &lt;=50K 2 38 Private 215646 HS-grad 9 Divorced Handlers-cleaners Not-in-family White Male 0 0 40 United-States &lt;=50K 3 53 Private 234721 11th 7 Married-civ-spouse Handlers-cleaners Husband Black Male 0 0 40 United-States &lt;=50K 4 28 Private 338409 Bachelors 13 Married-civ-spouse Prof-specialty Wife Black Female 0 0 40 Cuba &lt;=50K In\u00a0[11]: Copied! <pre>df.groupby('native_country').size()\n</pre> df.groupby('native_country').size() Out[11]: <pre>native_country\n?                               583\nCambodia                         19\nCanada                          121\nChina                            75\nColumbia                         59\nCuba                             95\nDominican-Republic               70\nEcuador                          28\nEl-Salvador                     106\nEngland                          90\nFrance                           29\nGermany                         137\nGreece                           29\nGuatemala                        64\nHaiti                            44\nHoland-Netherlands                1\nHonduras                         13\nHong                             20\nHungary                          13\nIndia                           100\nIran                             43\nIreland                          24\nItaly                            73\nJamaica                          81\nJapan                            62\nLaos                             18\nMexico                          643\nNicaragua                        34\nOutlying-US(Guam-USVI-etc)       14\nPeru                             31\nPhilippines                     198\nPoland                           60\nPortugal                         37\nPuerto-Rico                     114\nScotland                         12\nSouth                            80\nTaiwan                           51\nThailand                         18\nTrinadad&amp;Tobago                  19\nUnited-States                 29170\nVietnam                          67\nYugoslavia                       16\ndtype: int64</pre> In\u00a0[\u00a0]: Copied! <pre>## verifica as informa\u00e7\u00f5es do dataset\n## Seu c\u00f3digo aqui....\n</pre> ## verifica as informa\u00e7\u00f5es do dataset ## Seu c\u00f3digo aqui....   In\u00a0[4]: Copied! <pre>## Seu c\u00f3digo aqui....\n\ndf.isnull().sum()\n</pre> ## Seu c\u00f3digo aqui....  df.isnull().sum() Out[4]: <pre>age               0\nworkclass         0\nfnlwgt            0\neducation         0\neducation_num     0\nmarital_status    0\noccupation        0\nrelationship      0\nrace              0\nsex               0\ncapital_gain      0\ncapital_loss      0\nhours_per_week    0\nnative_country    0\nincome            0\ndtype: int64</pre> <p>Aparentemente, n\u00e3o possui dados ausente. Vamos visualizar de forma diferente...</p> In\u00a0[5]: Copied! <pre>for v2 in df:\n    print(df[v2].value_counts())\n</pre> for v2 in df:     print(df[v2].value_counts()) <pre>age\n36    898\n31    888\n34    886\n23    877\n35    876\n     ... \n83      6\n88      3\n85      3\n86      1\n87      1\nName: count, Length: 73, dtype: int64\nworkclass\nPrivate             22696\nSelf-emp-not-inc     2541\nLocal-gov            2093\n?                    1836\nState-gov            1298\nSelf-emp-inc         1116\nFederal-gov           960\nWithout-pay            14\nNever-worked            7\nName: count, dtype: int64\nfnlwgt\n164190    13\n203488    13\n123011    13\n148995    12\n121124    12\n          ..\n232784     1\n325573     1\n140176     1\n318264     1\n257302     1\nName: count, Length: 21648, dtype: int64\neducation\nHS-grad         10501\nSome-college     7291\nBachelors        5355\nMasters          1723\nAssoc-voc        1382\n11th             1175\nAssoc-acdm       1067\n10th              933\n7th-8th           646\nProf-school       576\n9th               514\n12th              433\nDoctorate         413\n5th-6th           333\n1st-4th           168\nPreschool          51\nName: count, dtype: int64\neducation_num\n9     10501\n10     7291\n13     5355\n14     1723\n11     1382\n7      1175\n12     1067\n6       933\n4       646\n15      576\n5       514\n8       433\n16      413\n3       333\n2       168\n1        51\nName: count, dtype: int64\nmarital_status\nMarried-civ-spouse       14976\nNever-married            10683\nDivorced                  4443\nSeparated                 1025\nWidowed                    993\nMarried-spouse-absent      418\nMarried-AF-spouse           23\nName: count, dtype: int64\noccupation\nProf-specialty       4140\nCraft-repair         4099\nExec-managerial      4066\nAdm-clerical         3770\nSales                3650\nOther-service        3295\nMachine-op-inspct    2002\n?                    1843\nTransport-moving     1597\nHandlers-cleaners    1370\nFarming-fishing       994\nTech-support          928\nProtective-serv       649\nPriv-house-serv       149\nArmed-Forces            9\nName: count, dtype: int64\nrelationship\nHusband           13193\nNot-in-family      8305\nOwn-child          5068\nUnmarried          3446\nWife               1568\nOther-relative      981\nName: count, dtype: int64\nrace\nWhite                 27816\nBlack                  3124\nAsian-Pac-Islander     1039\nAmer-Indian-Eskimo      311\nOther                   271\nName: count, dtype: int64\nsex\nMale      21790\nFemale    10771\nName: count, dtype: int64\ncapital_gain\n0        29849\n15024      347\n7688       284\n7298       246\n99999      159\n         ...  \n1111         1\n2538         1\n22040        1\n4931         1\n5060         1\nName: count, Length: 119, dtype: int64\ncapital_loss\n0       31042\n1902      202\n1977      168\n1887      159\n1848       51\n        ...  \n2080        1\n1539        1\n1844        1\n2489        1\n1411        1\nName: count, Length: 92, dtype: int64\nhours_per_week\n40    15217\n50     2819\n45     1824\n60     1475\n35     1297\n      ...  \n82        1\n92        1\n87        1\n74        1\n94        1\nName: count, Length: 94, dtype: int64\nnative_country\nUnited-States                 29170\nMexico                          643\n?                               583\nPhilippines                     198\nGermany                         137\nCanada                          121\nPuerto-Rico                     114\nEl-Salvador                     106\nIndia                           100\nCuba                             95\nEngland                          90\nJamaica                          81\nSouth                            80\nChina                            75\nItaly                            73\nDominican-Republic               70\nVietnam                          67\nGuatemala                        64\nJapan                            62\nPoland                           60\nColumbia                         59\nTaiwan                           51\nHaiti                            44\nIran                             43\nPortugal                         37\nNicaragua                        34\nPeru                             31\nFrance                           29\nGreece                           29\nEcuador                          28\nIreland                          24\nHong                             20\nCambodia                         19\nTrinadad&amp;Tobago                  19\nLaos                             18\nThailand                         18\nYugoslavia                       16\nOutlying-US(Guam-USVI-etc)       14\nHonduras                         13\nHungary                          13\nScotland                         12\nHoland-Netherlands                1\nName: count, dtype: int64\nincome\n&lt;=50K    24720\n&gt;50K      7841\nName: count, dtype: int64\n</pre> <p>Fa\u00e7a a interpreta\u00e7\u00e3o das informa\u00e7\u00f5es, observe o caracter <code>?</code>.</p> <p>Em quais colunas ele aparece?</p> <p>Fa\u00e7a o replace dos <code>?</code> por np.NaN.</p> In\u00a0[6]: Copied! <pre>## Seu c\u00f3digo aqui...\n\ndf=df.replace(' ?', np.nan)\n</pre> ## Seu c\u00f3digo aqui...  df=df.replace(' ?', np.nan)  <p>Vamos ver como ficou</p> In\u00a0[7]: Copied! <pre>for v2 in df:\n    print(df[v2].value_counts())\n    \ndf.isnull().sum()\n</pre> for v2 in df:     print(df[v2].value_counts())      df.isnull().sum() <pre>age\n36    898\n31    888\n34    886\n23    877\n35    876\n     ... \n83      6\n88      3\n85      3\n86      1\n87      1\nName: count, Length: 73, dtype: int64\nworkclass\nPrivate             22696\nSelf-emp-not-inc     2541\nLocal-gov            2093\nState-gov            1298\nSelf-emp-inc         1116\nFederal-gov           960\nWithout-pay            14\nNever-worked            7\nName: count, dtype: int64\nfnlwgt\n164190    13\n203488    13\n123011    13\n148995    12\n121124    12\n          ..\n232784     1\n325573     1\n140176     1\n318264     1\n257302     1\nName: count, Length: 21648, dtype: int64\neducation\nHS-grad         10501\nSome-college     7291\nBachelors        5355\nMasters          1723\nAssoc-voc        1382\n11th             1175\nAssoc-acdm       1067\n10th              933\n7th-8th           646\nProf-school       576\n9th               514\n12th              433\nDoctorate         413\n5th-6th           333\n1st-4th           168\nPreschool          51\nName: count, dtype: int64\neducation_num\n9     10501\n10     7291\n13     5355\n14     1723\n11     1382\n7      1175\n12     1067\n6       933\n4       646\n15      576\n5       514\n8       433\n16      413\n3       333\n2       168\n1        51\nName: count, dtype: int64\nmarital_status\nMarried-civ-spouse       14976\nNever-married            10683\nDivorced                  4443\nSeparated                 1025\nWidowed                    993\nMarried-spouse-absent      418\nMarried-AF-spouse           23\nName: count, dtype: int64\noccupation\nProf-specialty       4140\nCraft-repair         4099\nExec-managerial      4066\nAdm-clerical         3770\nSales                3650\nOther-service        3295\nMachine-op-inspct    2002\nTransport-moving     1597\nHandlers-cleaners    1370\nFarming-fishing       994\nTech-support          928\nProtective-serv       649\nPriv-house-serv       149\nArmed-Forces            9\nName: count, dtype: int64\nrelationship\nHusband           13193\nNot-in-family      8305\nOwn-child          5068\nUnmarried          3446\nWife               1568\nOther-relative      981\nName: count, dtype: int64\nrace\nWhite                 27816\nBlack                  3124\nAsian-Pac-Islander     1039\nAmer-Indian-Eskimo      311\nOther                   271\nName: count, dtype: int64\nsex\nMale      21790\nFemale    10771\nName: count, dtype: int64\ncapital_gain\n0        29849\n15024      347\n7688       284\n7298       246\n99999      159\n         ...  \n1111         1\n2538         1\n22040        1\n4931         1\n5060         1\nName: count, Length: 119, dtype: int64\ncapital_loss\n0       31042\n1902      202\n1977      168\n1887      159\n1848       51\n        ...  \n2080        1\n1539        1\n1844        1\n2489        1\n1411        1\nName: count, Length: 92, dtype: int64\nhours_per_week\n40    15217\n50     2819\n45     1824\n60     1475\n35     1297\n      ...  \n82        1\n92        1\n87        1\n74        1\n94        1\nName: count, Length: 94, dtype: int64\nnative_country\nUnited-States                 29170\nMexico                          643\nPhilippines                     198\nGermany                         137\nCanada                          121\nPuerto-Rico                     114\nEl-Salvador                     106\nIndia                           100\nCuba                             95\nEngland                          90\nJamaica                          81\nSouth                            80\nChina                            75\nItaly                            73\nDominican-Republic               70\nVietnam                          67\nGuatemala                        64\nJapan                            62\nPoland                           60\nColumbia                         59\nTaiwan                           51\nHaiti                            44\nIran                             43\nPortugal                         37\nNicaragua                        34\nPeru                             31\nFrance                           29\nGreece                           29\nEcuador                          28\nIreland                          24\nHong                             20\nCambodia                         19\nTrinadad&amp;Tobago                  19\nLaos                             18\nThailand                         18\nYugoslavia                       16\nOutlying-US(Guam-USVI-etc)       14\nHonduras                         13\nHungary                          13\nScotland                         12\nHoland-Netherlands                1\nName: count, dtype: int64\nincome\n&lt;=50K    24720\n&gt;50K      7841\nName: count, dtype: int64\n</pre> Out[7]: <pre>age                  0\nworkclass         1836\nfnlwgt               0\neducation            0\neducation_num        0\nmarital_status       0\noccupation        1843\nrelationship         0\nrace                 0\nsex                  0\ncapital_gain         0\ncapital_loss         0\nhours_per_week       0\nnative_country     583\nincome               0\ndtype: int64</pre> <p>note que agora conseguimos ver que existem dados faltantes no dataset.</p> <p>Use o m\u00e9todo <code>.fillna()</code>, para substituir os nulos (np.nan) por zero.</p> In\u00a0[8]: Copied! <pre>## Seu c\u00f3digo aqui...\n\ndf.fillna(0)\n</pre> ## Seu c\u00f3digo aqui...  df.fillna(0)  Out[8]: age workclass fnlwgt education education_num marital_status occupation relationship race sex capital_gain capital_loss hours_per_week native_country income 0 39 State-gov 77516 Bachelors 13 Never-married Adm-clerical Not-in-family White Male 2174 0 40 United-States &lt;=50K 1 50 Self-emp-not-inc 83311 Bachelors 13 Married-civ-spouse Exec-managerial Husband White Male 0 0 13 United-States &lt;=50K 2 38 Private 215646 HS-grad 9 Divorced Handlers-cleaners Not-in-family White Male 0 0 40 United-States &lt;=50K 3 53 Private 234721 11th 7 Married-civ-spouse Handlers-cleaners Husband Black Male 0 0 40 United-States &lt;=50K 4 28 Private 338409 Bachelors 13 Married-civ-spouse Prof-specialty Wife Black Female 0 0 40 Cuba &lt;=50K ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... 32556 27 Private 257302 Assoc-acdm 12 Married-civ-spouse Tech-support Wife White Female 0 0 38 United-States &lt;=50K 32557 40 Private 154374 HS-grad 9 Married-civ-spouse Machine-op-inspct Husband White Male 0 0 40 United-States &gt;50K 32558 58 Private 151910 HS-grad 9 Widowed Adm-clerical Unmarried White Female 0 0 40 United-States &lt;=50K 32559 22 Private 201490 HS-grad 9 Never-married Adm-clerical Own-child White Male 0 0 20 United-States &lt;=50K 32560 52 Self-emp-inc 287927 HS-grad 9 Married-civ-spouse Exec-managerial Wife White Female 15024 0 40 United-States &gt;50K <p>32561 rows \u00d7 15 columns</p> In\u00a0[9]: Copied! <pre>df['occupation'].value_counts()\n</pre> df['occupation'].value_counts() Out[9]: <pre>occupation\nProf-specialty       4140\nCraft-repair         4099\nExec-managerial      4066\nAdm-clerical         3770\nSales                3650\nOther-service        3295\nMachine-op-inspct    2002\nTransport-moving     1597\nHandlers-cleaners    1370\nFarming-fishing       994\nTech-support          928\nProtective-serv       649\nPriv-house-serv       149\nArmed-Forces            9\nName: count, dtype: int64</pre> <p>Ainda temos um problema, os classificadores que estudamos at\u00e9 agora n\u00e3o se d\u00e3o bem com vari\u00e1veis categ\u00f3ricas.</p> <p>Dentre as diversas formas de se fazer isso.....</p> <p>Vamos utilizar a t\u00e9cnica de OneHotEncoder com a biblioteca <code>category_encoders</code> apenas para economizar tempo.</p> In\u00a0[11]: Copied! <pre>## Se necess\u00e1rio, pip install category_encoders\n\nfrom sklearn.preprocessing import OneHotEncoder\n\nonehot_encoder = OneHotEncoder(sparse_output=False, cols=[\"----Coloque aqui as colunas categoricas para realizar a transforma\u00e7\u00e3o----\"])\n\ndf = onehot_encoder.fit_transform(df)\n</pre> ## Se necess\u00e1rio, pip install category_encoders  from sklearn.preprocessing import OneHotEncoder  onehot_encoder = OneHotEncoder(sparse_output=False, cols=[\"----Coloque aqui as colunas categoricas para realizar a transforma\u00e7\u00e3o----\"])  df = onehot_encoder.fit_transform(df)   <pre>\n---------------------------------------------------------------------------\nTypeError                                 Traceback (most recent call last)\nCell In[11], line 5\n      1 ## Se necess\u00e1rio, pip install category_encoders\n      3 from sklearn.preprocessing import OneHotEncoder\n----&gt; 5 onehot_encoder = OneHotEncoder(sparse_output=False, cols=[\"----Coloque aqui as colunas categoricas para realizar a transforma\u00e7\u00e3o----\"])\n      7 df = onehot_encoder.fit_transform(df)\n\nTypeError: OneHotEncoder.__init__() got an unexpected keyword argument 'cols'</pre> In\u00a0[12]: Copied! <pre>df.head()\n</pre> df.head() Out[12]: age workclass fnlwgt education education_num marital_status occupation relationship race sex capital_gain capital_loss hours_per_week native_country income 0 39 State-gov 77516 Bachelors 13 Never-married Adm-clerical Not-in-family White Male 2174 0 40 United-States &lt;=50K 1 50 Self-emp-not-inc 83311 Bachelors 13 Married-civ-spouse Exec-managerial Husband White Male 0 0 13 United-States &lt;=50K 2 38 Private 215646 HS-grad 9 Divorced Handlers-cleaners Not-in-family White Male 0 0 40 United-States &lt;=50K 3 53 Private 234721 11th 7 Married-civ-spouse Handlers-cleaners Husband Black Male 0 0 40 United-States &lt;=50K 4 28 Private 338409 Bachelors 13 Married-civ-spouse Prof-specialty Wife Black Female 0 0 40 Cuba &lt;=50K <p>Criamos um novo problema, os valores est\u00e3o em escalas muito diferentes, o que pode prejudicar o aprendizado.</p> <p>Podemos tomar algumas desci\u00e7\u00f5es: Vamos normatizar os dados, mas antes, fa\u00e7a o drop da coluna <code>income</code> para n\u00e3o mudar a escala dela; Da um replace na coluna <code>income</code> para 0 ou 1.</p> <p>Variavel independente: --&gt; X Variavel dependente: --&gt; y</p> In\u00a0[\u00a0]: Copied! <pre>#Vamos fazer um drop da coluna de interesse de estudo `income`. (y)\n</pre> #Vamos fazer um drop da coluna de interesse de estudo `income`. (y)   In\u00a0[13]: Copied! <pre>## Fa\u00e7a a normaliza\u00e7\u00e3o dos dados\n## escolha um dos m\u00e9todos....\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.preprocessing import minmax_scale\nfrom sklearn.preprocessing import MaxAbsScaler\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.preprocessing import RobustScaler\nfrom sklearn.preprocessing import Normalizer\nfrom sklearn.preprocessing import QuantileTransformer\nfrom sklearn.preprocessing import PowerTransformer\n\n## seu c\u00f3digo aqui...\n</pre> ## Fa\u00e7a a normaliza\u00e7\u00e3o dos dados ## escolha um dos m\u00e9todos.... from sklearn.preprocessing import MinMaxScaler from sklearn.preprocessing import minmax_scale from sklearn.preprocessing import MaxAbsScaler from sklearn.preprocessing import StandardScaler from sklearn.preprocessing import RobustScaler from sklearn.preprocessing import Normalizer from sklearn.preprocessing import QuantileTransformer from sklearn.preprocessing import PowerTransformer  ## seu c\u00f3digo aqui...   <p>Agora sim! temos uma base limpa e organizada para rodar diversos modelos de ML. onde:</p> <p>X - &gt; possui as variaveis independentes. y - &gt; \u00e9 a nossa variavel de interesse.</p> <p>Separe os dados em treino e teste, qual a propo\u00e7\u00e3o ser\u00e1 utiizada para cada subset??</p> In\u00a0[14]: Copied! <pre>#Separar os dados em treino e teste\nfrom sklearn.model_selection import train_test_split\n</pre> #Separar os dados em treino e teste from sklearn.model_selection import train_test_split   In\u00a0[15]: Copied! <pre>from sklearn.naive_bayes import GaussianNB\n\ngnb = GaussianNB()\n\ngnb.fit(X_train, y_train)\ny_pred = gnb.predict(X_test)\ny_pred\n</pre> from sklearn.naive_bayes import GaussianNB  gnb = GaussianNB()  gnb.fit(X_train, y_train) y_pred = gnb.predict(X_test) y_pred <pre>\n---------------------------------------------------------------------------\nNameError                                 Traceback (most recent call last)\nCell In[15], line 5\n      1 from sklearn.naive_bayes import GaussianNB\n      3 gnb = GaussianNB()\n----&gt; 5 gnb.fit(X_train, y_train)\n      6 y_pred = gnb.predict(X_test)\n      7 y_pred\n\nNameError: name 'X_train' is not defined</pre> In\u00a0[16]: Copied! <pre>from sklearn.metrics import accuracy_score\n\naccuracy_score(y_test, y_pred)\n</pre> from sklearn.metrics import accuracy_score  accuracy_score(y_test, y_pred) <pre>\n---------------------------------------------------------------------------\nNameError                                 Traceback (most recent call last)\nCell In[16], line 3\n      1 from sklearn.metrics import accuracy_score\n----&gt; 3 accuracy_score(y_test, y_pred)\n\nNameError: name 'y_test' is not defined</pre> In\u00a0[17]: Copied! <pre>y_pred_train = gnb.predict(X_train)\ny_pred_train\n</pre> y_pred_train = gnb.predict(X_train) y_pred_train <pre>\n---------------------------------------------------------------------------\nNameError                                 Traceback (most recent call last)\nCell In[17], line 1\n----&gt; 1 y_pred_train = gnb.predict(X_train)\n      2 y_pred_train\n\nNameError: name 'X_train' is not defined</pre> In\u00a0[18]: Copied! <pre>accuracy_score(y_train, y_pred_train)\n</pre> accuracy_score(y_train, y_pred_train) <pre>\n---------------------------------------------------------------------------\nNameError                                 Traceback (most recent call last)\nCell In[18], line 1\n----&gt; 1 accuracy_score(y_train, y_pred_train)\n\nNameError: name 'y_train' is not defined</pre> In\u00a0[\u00a0]: Copied! <pre>### sua resposta aqui....\n</pre> ### sua resposta aqui....    In\u00a0[\u00a0]: Copied! <pre>\n</pre>"},{"location":"aulas/IA/lab02/ml-classificador-renda.html#objetivos","title":"Objetivos\u00b6","text":"<ul> <li>Praticar as etapas de entendimento do problema</li> <li>praticar as etapas de prepara\u00e7\u00e3o dos dados</li> <li>Praticar os algoritmos de aprendizado de maquina e otimiza\u00e7\u00e3o de hiperpar\u00e2metros</li> <li>Praticar as metricas de valida\u00e7\u00e3o dos resultados</li> </ul>"},{"location":"aulas/IA/lab02/ml-classificador-renda.html#classificador-de-renda","title":"Classificador de renda\u00b6","text":"<p>Voc\u00ea foi contratado por uma empresa para prestar um servi\u00e7o de consultor.</p> <p>Nesse sentido a empresa disponibilizou uma base em dados demogr\u00e1ficos e ocupacionais dos seus clientes e gostaria de saber se \u00e9 poss\u00edvel criar um modelo que preve se determinada pessoa ganha mais ou menos de 50k d\u00f3lares por ano.</p> <p>Nosso dataset:http://archive.ics.uci.edu/ml/datasets/Adult</p>"},{"location":"aulas/IA/lab02/ml-classificador-renda.html#importa-as-bibliotecas","title":"Importa as bibliotecas\u00b6","text":""},{"location":"aulas/IA/lab02/ml-classificador-renda.html#carrega-o-dataset","title":"Carrega o dataset\u00b6","text":""},{"location":"aulas/IA/lab02/ml-classificador-renda.html#verificar-se-possui-dados-ausentes","title":"Verificar se possui dados ausentes\u00b6","text":""},{"location":"aulas/IA/lab02/ml-classificador-renda.html#classificadores-naive-bayes","title":"Classificadores Naive Bayes\u00b6","text":"<p>Trata-se de \"classificadores probabil\u00edsticos\" simples, baseados na aplica\u00e7\u00e3o do <code>teorema de Bayes</code> com fortes pressupostos de independ\u00eancia entre os atributos. Eles est\u00e3o entre os modelos de rede bayesianos mais simples.</p> <p>Existem 3 tipos diferentes de Naive Bayes:</p> <pre><code>1.Gaussian Naive Bayes\n\n2.Multinomial Naive Bayes\n\n3.Bernoulli Naive Bayes</code></pre> <p>S\u00e3o muiiiitttooo utilizados em aplica\u00e7\u00f5es com texto e NLP e aplica\u00e7\u00f5es como:</p> <pre><code>[X] Filtro de Spam\n[X] Classifica\u00e7\u00e3o de Texto\n[X] Analise de sentimento\n[X] Sistemas de recomenda\u00e7\u00e3o</code></pre> <p>Para mais refer\u00eancias: https://en.wikipedia.org/wiki/Naive_Bayes_classifier</p>"},{"location":"aulas/IA/lab02/ml-classificador-renda.html#compare-o-resultado-de-acuracia-com-pelo-menos-1-outro-metodo-de-machine-learning","title":"Compare o resultado de acuracia com pelo menos 1 outro m\u00e9todo de machine learning.\u00b6","text":""},{"location":"aulas/IA/lab03/preco-notebook.html","title":"lab3","text":"In\u00a0[62]: Copied! <pre># Inicializ\u00e7\u00e3o das bibliotecas\n%matplotlib inline\n\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n</pre> # Inicializ\u00e7\u00e3o das bibliotecas %matplotlib inline  import pandas as pd import matplotlib.pyplot as plt import seaborn as sns  In\u00a0[63]: Copied! <pre>df = pd.read_csv('laptop_data.csv')\n</pre> df = pd.read_csv('laptop_data.csv') In\u00a0[65]: Copied! <pre># Verifique se o dataset foi carregado corretamente, \n# imprimindo o nome das colunas do dataset e as primeiras linhas do dataset \n# use o comando head() para visualizar as primeiras linhas do dataset\n\ndf.head()\n</pre> # Verifique se o dataset foi carregado corretamente,  # imprimindo o nome das colunas do dataset e as primeiras linhas do dataset  # use o comando head() para visualizar as primeiras linhas do dataset  df.head()      Out[65]: Unnamed: 0 Company TypeName Inches ScreenResolution Cpu Ram Memory Gpu OpSys Weight Price 0 0 Apple Ultrabook 13.3 IPS Panel Retina Display 2560x1600 Intel Core i5 2.3GHz 8GB 128GB SSD Intel Iris Plus Graphics 640 macOS 1.37kg 71378.6832 1 1 Apple Ultrabook 13.3 1440x900 Intel Core i5 1.8GHz 8GB 128GB Flash Storage Intel HD Graphics 6000 macOS 1.34kg 47895.5232 2 2 HP Notebook 15.6 Full HD 1920x1080 Intel Core i5 7200U 2.5GHz 8GB 256GB SSD Intel HD Graphics 620 No OS 1.86kg 30636.0000 3 3 Apple Ultrabook 15.4 IPS Panel Retina Display 2880x1800 Intel Core i7 2.7GHz 16GB 512GB SSD AMD Radeon Pro 455 macOS 1.83kg 135195.3360 4 4 Apple Ultrabook 13.3 IPS Panel Retina Display 2560x1600 Intel Core i5 3.1GHz 8GB 256GB SSD Intel Iris Plus Graphics 650 macOS 1.37kg 96095.8080 In\u00a0[66]: Copied! <pre># verificando se existem valores duplicados \n\ndf.duplicated().sum()\n\n# dropando as linhas duplicadas\n\ndf.drop_duplicates(inplace=True)\n</pre> # verificando se existem valores duplicados   df.duplicated().sum()  # dropando as linhas duplicadas  df.drop_duplicates(inplace=True) In\u00a0[67]: Copied! <pre># drop a coluna Unnamed: 0 do dataset e imprima novamente as primeiras linhas do dataset\n\ndf.drop(columns=['Unnamed: 0'],inplace=True)\n</pre> # drop a coluna Unnamed: 0 do dataset e imprima novamente as primeiras linhas do dataset  df.drop(columns=['Unnamed: 0'],inplace=True) In\u00a0[68]: Copied! <pre># use o comando info() para visualizar as informa\u00e7\u00f5es do dataset\ndf.info()\n</pre> # use o comando info() para visualizar as informa\u00e7\u00f5es do dataset df.info() <pre>&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 1303 entries, 0 to 1302\nData columns (total 11 columns):\n #   Column            Non-Null Count  Dtype  \n---  ------            --------------  -----  \n 0   Company           1303 non-null   object \n 1   TypeName          1303 non-null   object \n 2   Inches            1303 non-null   float64\n 3   ScreenResolution  1303 non-null   object \n 4   Cpu               1303 non-null   object \n 5   Ram               1303 non-null   object \n 6   Memory            1303 non-null   object \n 7   Gpu               1303 non-null   object \n 8   OpSys             1303 non-null   object \n 9   Weight            1303 non-null   object \n 10  Price             1303 non-null   float64\ndtypes: float64(2), object(9)\nmemory usage: 112.1+ KB\n</pre> In\u00a0[69]: Copied! <pre># use o comando describe() para visualizar as estat\u00edsticas do dataset\ndf.describe()\n</pre> # use o comando describe() para visualizar as estat\u00edsticas do dataset df.describe() Out[69]: Inches Price count 1303.000000 1303.000000 mean 15.017191 59870.042910 std 1.426304 37243.201786 min 10.100000 9270.720000 25% 14.000000 31914.720000 50% 15.600000 52054.560000 75% 15.600000 79274.246400 max 18.400000 324954.720000 <p>Dentre outras an\u00e1lises, \u00e9 esperado que voc\u00ea tenha reparado que os atributos <code>Ram</code> e <code>Weight</code> est\u00e3o como object. Como sugest\u00e3o, podemos converter esses atributos para dado num\u00e9rico.</p> In\u00a0[70]: Copied! <pre># usamos o comando str.replace() para remover a unidade de medida dos valores\ndf['Ram'] = df['Ram'].str.replace('GB','')\ndf['Weight'] = df['Weight'].str.replace('kg','')\n\n# usamos o comando astype() para converter os valores para o tipo num\u00e9rico\ndf['Ram'] = df['Ram'].astype('int32')\ndf['Weight'] = df['Weight'].astype('float32')\n</pre> # usamos o comando str.replace() para remover a unidade de medida dos valores df['Ram'] = df['Ram'].str.replace('GB','') df['Weight'] = df['Weight'].str.replace('kg','')  # usamos o comando astype() para converter os valores para o tipo num\u00e9rico df['Ram'] = df['Ram'].astype('int32') df['Weight'] = df['Weight'].astype('float32')  In\u00a0[71]: Copied! <pre># use o comando info() para visualizar as informa\u00e7\u00f5es do dataset ap\u00f3s a convers\u00e3o\ndf.info()\n</pre> # use o comando info() para visualizar as informa\u00e7\u00f5es do dataset ap\u00f3s a convers\u00e3o df.info()    <pre>&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 1303 entries, 0 to 1302\nData columns (total 11 columns):\n #   Column            Non-Null Count  Dtype  \n---  ------            --------------  -----  \n 0   Company           1303 non-null   object \n 1   TypeName          1303 non-null   object \n 2   Inches            1303 non-null   float64\n 3   ScreenResolution  1303 non-null   object \n 4   Cpu               1303 non-null   object \n 5   Ram               1303 non-null   int32  \n 6   Memory            1303 non-null   object \n 7   Gpu               1303 non-null   object \n 8   OpSys             1303 non-null   object \n 9   Weight            1303 non-null   float32\n 10  Price             1303 non-null   float64\ndtypes: float32(1), float64(2), int32(1), object(7)\nmemory usage: 101.9+ KB\n</pre> In\u00a0[72]: Copied! <pre># use o comando describe() para visualizar as estat\u00edsticas do dataset ap\u00f3s a convers\u00e3o \ndf.describe()\n</pre> # use o comando describe() para visualizar as estat\u00edsticas do dataset ap\u00f3s a convers\u00e3o  df.describe()    Out[72]: Inches Ram Weight Price count 1303.000000 1303.000000 1303.000000 1303.000000 mean 15.017191 8.382195 2.038734 59870.042910 std 1.426304 5.084665 0.665475 37243.201786 min 10.100000 2.000000 0.690000 9270.720000 25% 14.000000 4.000000 1.500000 31914.720000 50% 15.600000 8.000000 2.040000 52054.560000 75% 15.600000 8.000000 2.300000 79274.246400 max 18.400000 64.000000 4.700000 324954.720000 In\u00a0[8]: Copied! <pre>## Sua resposta e seus gr\u00e1ficos para an\u00e1lisar..\n</pre> ## Sua resposta e seus gr\u00e1ficos para an\u00e1lisar..       In\u00a0[\u00a0]: Copied! <pre>## Sua resposta e seus gr\u00e1ficos para an\u00e1lisar..\n</pre> ## Sua resposta e seus gr\u00e1ficos para an\u00e1lisar.. In\u00a0[\u00a0]: Copied! <pre>## Sua resposta e seus gr\u00e1ficos para an\u00e1lisar..\n</pre> ## Sua resposta e seus gr\u00e1ficos para an\u00e1lisar.. In\u00a0[\u00a0]: Copied! <pre>## Sua resposta e seus gr\u00e1ficos para an\u00e1lisar..\n</pre> ## Sua resposta e seus gr\u00e1ficos para an\u00e1lisar.. In\u00a0[\u00a0]: Copied! <pre>## Sua resposta e seus gr\u00e1ficos para an\u00e1lisar..\n</pre> ## Sua resposta e seus gr\u00e1ficos para an\u00e1lisar.. In\u00a0[73]: Copied! <pre># vamos explorar o atributo ScreenResolution\n# use o comando value_counts() para visualizar a frequ\u00eancia dos valores do atributo ScreenResolution\n\ndf['ScreenResolution'].value_counts()\n</pre> # vamos explorar o atributo ScreenResolution # use o comando value_counts() para visualizar a frequ\u00eancia dos valores do atributo ScreenResolution  df['ScreenResolution'].value_counts()   Out[73]: <pre>ScreenResolution\nFull HD 1920x1080                                507\n1366x768                                         281\nIPS Panel Full HD 1920x1080                      230\nIPS Panel Full HD / Touchscreen 1920x1080         53\nFull HD / Touchscreen 1920x1080                   47\n1600x900                                          23\nTouchscreen 1366x768                              16\nQuad HD+ / Touchscreen 3200x1800                  15\nIPS Panel 4K Ultra HD 3840x2160                   12\nIPS Panel 4K Ultra HD / Touchscreen 3840x2160     11\n4K Ultra HD / Touchscreen 3840x2160               10\n4K Ultra HD 3840x2160                              7\nTouchscreen 2560x1440                              7\nIPS Panel 1366x768                                 7\nIPS Panel Quad HD+ / Touchscreen 3200x1800         6\nIPS Panel Retina Display 2560x1600                 6\nIPS Panel Retina Display 2304x1440                 6\nTouchscreen 2256x1504                              6\nIPS Panel Touchscreen 2560x1440                    5\nIPS Panel Retina Display 2880x1800                 4\nIPS Panel Touchscreen 1920x1200                    4\n1440x900                                           4\nIPS Panel 2560x1440                                4\nIPS Panel Quad HD+ 2560x1440                       3\nQuad HD+ 3200x1800                                 3\n1920x1080                                          3\nTouchscreen 2400x1600                              3\n2560x1440                                          3\nIPS Panel Touchscreen 1366x768                     3\nIPS Panel Touchscreen / 4K Ultra HD 3840x2160      2\nIPS Panel Full HD 2160x1440                        2\nIPS Panel Quad HD+ 3200x1800                       2\nIPS Panel Retina Display 2736x1824                 1\nIPS Panel Full HD 1920x1200                        1\nIPS Panel Full HD 2560x1440                        1\nIPS Panel Full HD 1366x768                         1\nTouchscreen / Full HD 1920x1080                    1\nTouchscreen / Quad HD+ 3200x1800                   1\nTouchscreen / 4K Ultra HD 3840x2160                1\nIPS Panel Touchscreen 2400x1600                    1\nName: count, dtype: int64</pre> <p>Vamos aplicar uma transforma\u00e7\u00e3o em nossos dados:</p> <ul> <li>Vamos realizar uma transforma\u00e7\u00e3o em nossos dados usando o atributo ScreenResolution.</li> <li>Vamos analisar os valores presentes nessa coluna e verificar se eles cont\u00eam a informa\u00e7\u00e3o sobre a presen\u00e7a de uma tela touchscreen.</li> <li>A partir dessa verifica\u00e7\u00e3o, criaremos uma nova coluna <code>Touchscreen</code> que indicar\u00e1, de forma bin\u00e1ria, se o laptop possui ou n\u00e3o uma tela touchscreen (1 para sim e 0 para n\u00e3o).</li> </ul> In\u00a0[74]: Copied! <pre># Vamos criar uma nova coluna chamada 'Touchscreen' que recebe 1 se o valor da coluna 'ScreenResolution' cont\u00e9m a palavra 'Touchscreen' e 0 caso contr\u00e1rio\ndf['Touchscreen'] = df['ScreenResolution'].apply(lambda x:1 if 'Touchscreen' in x else 0)\n</pre> # Vamos criar uma nova coluna chamada 'Touchscreen' que recebe 1 se o valor da coluna 'ScreenResolution' cont\u00e9m a palavra 'Touchscreen' e 0 caso contr\u00e1rio df['Touchscreen'] = df['ScreenResolution'].apply(lambda x:1 if 'Touchscreen' in x else 0)  In\u00a0[75]: Copied! <pre># podemos visualizar graficamente a quantidade de laptops com e sem touchscreen\ndf['Touchscreen'].value_counts().plot(kind='bar')\n</pre> # podemos visualizar graficamente a quantidade de laptops com e sem touchscreen df['Touchscreen'].value_counts().plot(kind='bar') Out[75]: <pre>&lt;Axes: xlabel='Touchscreen'&gt;</pre> In\u00a0[76]: Copied! <pre># avaliando o pre\u00e7o com e sem touchscreen\nsns.barplot(x=df['Touchscreen'],y=df['Price'])\n</pre> # avaliando o pre\u00e7o com e sem touchscreen sns.barplot(x=df['Touchscreen'],y=df['Price']) Out[76]: <pre>&lt;Axes: xlabel='Touchscreen', ylabel='Price'&gt;</pre> In\u00a0[\u00a0]: Copied! <pre>## Sua resposta aqui\n</pre> ## Sua resposta aqui In\u00a0[\u00a0]: Copied! <pre>## Sua resposta aqui\n</pre> ## Sua resposta aqui In\u00a0[\u00a0]: Copied! <pre>## Sua resposta aqui\n</pre> ## Sua resposta aqui In\u00a0[\u00a0]: Copied! <pre>## Sua resposta aqui\n</pre> ## Sua resposta aqui In\u00a0[77]: Copied! <pre># Vamos explorar o atributo 'OpSys'\ndf['OpSys'].value_counts()\n</pre> # Vamos explorar o atributo 'OpSys' df['OpSys'].value_counts() Out[77]: <pre>OpSys\nWindows 10      1072\nNo OS             66\nLinux             62\nWindows 7         45\nChrome OS         27\nmacOS             13\nMac OS X           8\nWindows 10 S       8\nAndroid            2\nName: count, dtype: int64</pre> In\u00a0[78]: Copied! <pre># podemos visualizar graficamente a quantidade de laptops com cada sistema operacional\nsns.barplot(x=df['OpSys'],y=df['Price'])\nplt.xticks(rotation='vertical')\nplt.show()\n</pre> # podemos visualizar graficamente a quantidade de laptops com cada sistema operacional sns.barplot(x=df['OpSys'],y=df['Price']) plt.xticks(rotation='vertical') plt.show() In\u00a0[79]: Copied! <pre># vamos criar uma nova coluna chamada 'OS' que recebe o valor 'Windows' se o valor da coluna 'OpSys' for 'Windows 10', 'Windows 7' ou 'Windows 10 S', 'Mac' se o valor for 'macOS' ou 'Mac OS X' e 'Others/No OS/Linux' caso contr\u00e1rio\n\ndef cat_os(inp):\n    if inp == 'Windows 10' or inp == 'Windows 7' or inp == 'Windows 10 S':\n        return 'Windows'\n    elif inp == 'macOS' or inp == 'Mac OS X':\n        return 'Mac'\n    else:\n        return 'Others/No OS/Linux'\n\ndf['OS'] = df['OpSys'].apply(cat_os)\n</pre> # vamos criar uma nova coluna chamada 'OS' que recebe o valor 'Windows' se o valor da coluna 'OpSys' for 'Windows 10', 'Windows 7' ou 'Windows 10 S', 'Mac' se o valor for 'macOS' ou 'Mac OS X' e 'Others/No OS/Linux' caso contr\u00e1rio  def cat_os(inp):     if inp == 'Windows 10' or inp == 'Windows 7' or inp == 'Windows 10 S':         return 'Windows'     elif inp == 'macOS' or inp == 'Mac OS X':         return 'Mac'     else:         return 'Others/No OS/Linux'  df['OS'] = df['OpSys'].apply(cat_os) In\u00a0[80]: Copied! <pre># podemos visualizar graficamente a quantidade de laptops com cada sistema operacional\nsns.barplot(x=df['OS'],y=df['Price'])\nplt.xticks(rotation='vertical')\nplt.show()\n</pre> # podemos visualizar graficamente a quantidade de laptops com cada sistema operacional sns.barplot(x=df['OS'],y=df['Price']) plt.xticks(rotation='vertical') plt.show() In\u00a0[81]: Copied! <pre># Vamos explorar o atributo 'OS'\ndf['OS'].value_counts()\n</pre> # Vamos explorar o atributo 'OS' df['OS'].value_counts() Out[81]: <pre>OS\nWindows               1125\nOthers/No OS/Linux     157\nMac                     21\nName: count, dtype: int64</pre> In\u00a0[82]: Copied! <pre>df.head()\n</pre> df.head() Out[82]: Company TypeName Inches ScreenResolution Cpu Ram Memory Gpu OpSys Weight Price Touchscreen OS 0 Apple Ultrabook 13.3 IPS Panel Retina Display 2560x1600 Intel Core i5 2.3GHz 8 128GB SSD Intel Iris Plus Graphics 640 macOS 1.37 71378.6832 0 Mac 1 Apple Ultrabook 13.3 1440x900 Intel Core i5 1.8GHz 8 128GB Flash Storage Intel HD Graphics 6000 macOS 1.34 47895.5232 0 Mac 2 HP Notebook 15.6 Full HD 1920x1080 Intel Core i5 7200U 2.5GHz 8 256GB SSD Intel HD Graphics 620 No OS 1.86 30636.0000 0 Others/No OS/Linux 3 Apple Ultrabook 15.4 IPS Panel Retina Display 2880x1800 Intel Core i7 2.7GHz 16 512GB SSD AMD Radeon Pro 455 macOS 1.83 135195.3360 0 Mac 4 Apple Ultrabook 13.3 IPS Panel Retina Display 2560x1600 Intel Core i5 3.1GHz 8 256GB SSD Intel Iris Plus Graphics 650 macOS 1.37 96095.8080 0 Mac In\u00a0[27]: Copied! <pre>## Sua resposta aqui\n</pre> ## Sua resposta aqui    In\u00a0[83]: Copied! <pre>df.info()\n</pre> df.info() <pre>&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 1303 entries, 0 to 1302\nData columns (total 13 columns):\n #   Column            Non-Null Count  Dtype  \n---  ------            --------------  -----  \n 0   Company           1303 non-null   object \n 1   TypeName          1303 non-null   object \n 2   Inches            1303 non-null   float64\n 3   ScreenResolution  1303 non-null   object \n 4   Cpu               1303 non-null   object \n 5   Ram               1303 non-null   int32  \n 6   Memory            1303 non-null   object \n 7   Gpu               1303 non-null   object \n 8   OpSys             1303 non-null   object \n 9   Weight            1303 non-null   float32\n 10  Price             1303 non-null   float64\n 11  Touchscreen       1303 non-null   int64  \n 12  OS                1303 non-null   object \ndtypes: float32(1), float64(2), int32(1), int64(1), object(8)\nmemory usage: 122.3+ KB\n</pre> In\u00a0[88]: Copied! <pre># exibe a correla\u00e7\u00e3o entre as vari\u00e1veis num\u00e9ricas\n\n# Calcula a matriz de correla\u00e7\u00e3o\ncorrelation_matrix = df[['Inches', 'Ram', 'Weight', 'Price','Touchscreen']].corr()\n\n# exibe a matriz de correla\u00e7\u00e3o\nplt.figure(figsize=(10, 8))\nsns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt=\".2f\", linewidths=.5)\nplt.title('Correlation Matrix')\nplt.show()\n</pre> # exibe a correla\u00e7\u00e3o entre as vari\u00e1veis num\u00e9ricas  # Calcula a matriz de correla\u00e7\u00e3o correlation_matrix = df[['Inches', 'Ram', 'Weight', 'Price','Touchscreen']].corr()  # exibe a matriz de correla\u00e7\u00e3o plt.figure(figsize=(10, 8)) sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt=\".2f\", linewidths=.5) plt.title('Correlation Matrix') plt.show()   In\u00a0[94]: Copied! <pre># Vamos treinar nosso modelo com base no dataset de laptops e prever o pre\u00e7o de um laptop com as seguintes caracter\u00edsticas:\n\n\nX = df[['Inches', 'Ram', 'Weight','Touchscreen']]\n# X = df.drop(['Price'], axis=1)     ### teste com todas as entradas\n\nY = df['Price']             \n\nprint(f\"Formato das tabelas de dados {X.shape} e saidas {Y.shape}\")\n</pre> # Vamos treinar nosso modelo com base no dataset de laptops e prever o pre\u00e7o de um laptop com as seguintes caracter\u00edsticas:   X = df[['Inches', 'Ram', 'Weight','Touchscreen']] # X = df.drop(['Price'], axis=1)     ### teste com todas as entradas  Y = df['Price']               print(f\"Formato das tabelas de dados {X.shape} e saidas {Y.shape}\") <pre>Formato das tabelas de dados (1303, 4) e saidas (1303,)\n</pre> In\u00a0[95]: Copied! <pre># Separamos 20% para o teste\nfrom sklearn.model_selection import train_test_split\n\nX_treino, X_teste, Y_treino, Y_teste = train_test_split(X, Y, test_size=0.2)\n\nprint(X_treino.shape)\nprint(X_teste.shape)\nprint(Y_treino.shape)\nprint(Y_teste.shape)\n</pre> # Separamos 20% para o teste from sklearn.model_selection import train_test_split  X_treino, X_teste, Y_treino, Y_teste = train_test_split(X, Y, test_size=0.2)  print(X_treino.shape) print(X_teste.shape) print(Y_treino.shape) print(Y_teste.shape) <pre>(1042, 4)\n(261, 4)\n(1042,)\n(261,)\n</pre> In\u00a0[96]: Copied! <pre>#Primeiras linhas do dataframe \nX_treino.head()\n</pre> #Primeiras linhas do dataframe  X_treino.head() Out[96]: Inches Ram Weight Touchscreen 119 15.6 8 1.70 0 438 14.0 24 1.32 0 24 15.6 8 1.91 0 1010 15.6 8 2.65 0 631 15.6 16 2.62 0 In\u00a0[97]: Copied! <pre>Y_treino.head()\n</pre> Y_treino.head() Out[97]: <pre>119      59567.04\n438     126912.96\n24       35111.52\n1010     50562.72\n631      78801.12\nName: Price, dtype: float64</pre> In\u00a0[98]: Copied! <pre># Importa a biblioteca\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import mean_squared_error\n\n# Cria o modelo de regress\u00e3o \nlin_model = LinearRegression()\n\n# Cria o modelo de machine learning\nlin_model.fit(X_treino, Y_treino)\n</pre> # Importa a biblioteca from sklearn.linear_model import LinearRegression from sklearn.metrics import mean_squared_error  # Cria o modelo de regress\u00e3o  lin_model = LinearRegression()  # Cria o modelo de machine learning lin_model.fit(X_treino, Y_treino)    Out[98]: <pre>LinearRegression()</pre>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.\u00a0\u00a0LinearRegression?Documentation for LinearRegressioniFitted<pre>LinearRegression()</pre> <p>Pronto!! bora testar se esta funcionando....</p> In\u00a0[99]: Copied! <pre># Para obter as previs\u00f5es, basta chamar o m\u00e9todo predict()\ny_teste_predito = lin_model.predict(X_teste)\nprint(\"Predi\u00e7\u00e3o usando regress\u00e3o, retorna valores continuos: {}\".format(y_teste_predito))\n</pre> # Para obter as previs\u00f5es, basta chamar o m\u00e9todo predict() y_teste_predito = lin_model.predict(X_teste) print(\"Predi\u00e7\u00e3o usando regress\u00e3o, retorna valores continuos: {}\".format(y_teste_predito))  <pre>Predi\u00e7\u00e3o usando regress\u00e3o, retorna valores continuos: [100034.37969786  59932.48674075  28480.27437865  59685.46857027\n  54085.85527543  99275.47252861  43184.31534678  32354.91705733\n  36263.18833347  63602.67213891  64228.45109843  62957.03363296\n  58323.48378503 107077.6245361   50573.50573024  60228.9082705\n  99470.31655009  54448.14840892  32667.80663524  32519.59596852\n  54481.08411263  54514.01981635  54711.63443126  32338.44920547\n  54184.66258289  68103.09397342  57697.70482551  54596.35907564\n  31959.68841644  99458.0040976   60320.1800186   58685.77691852\n  54777.50583869  32848.9533983   21374.17318158  31959.68841644\n  50655.84498953  65771.58264672  54942.18435727  36526.6741595\n  28480.27437865  59932.48674075  50738.18424882  58027.06205897\n  99622.6830088   31959.68841644  37634.10560752  59932.48674075\n  54184.66258289  32354.91705733  54415.2127052   53405.97899809\n  32848.9533983   32190.23853875  36427.86704835 183667.48320055\n  37699.97701495  32354.91705733 109859.23784614  32519.59596852\n  33260.65008736  65969.19706532  32190.23853875  55518.55995753\n  32190.23853875 104612.98499966  59932.48674075  39609.22931373\n  36049.10606301  35686.81292952 107822.0703495   65458.69306881\n  58570.50175921  56424.29259494 100281.39747572  99243.92202346\n  32519.59596852  55106.86326847  98354.65704159  25216.57265767\n  97460.69810117  36954.83870042 104440.77092174  36839.56373741\n  51676.04011968  32519.59596852  32684.2744871   32305.51350175\n  59800.74372958  39609.22931373  65359.88595766  32519.59596852\n  31943.22056458  55271.54178704  36839.56373741  55370.34889819\n  65969.19706532  32354.91705733  32486.66026481  50557.03787839\n  31959.68841644  54942.18435727 103613.29334792  38152.14496708\n 105638.76988583  54942.18435727  41970.54122826  36510.20630764\n  59463.85093677  98218.22007186  66002.13276904  65376.35380952\n  77035.41570886  51298.09199722  57747.10838109  99622.6830088\n  55419.75245376  51726.25653814  32848.9533983   32437.25670924\n  32848.9533983   77051.88356072  32354.91705733  32519.59596852\n  32519.59596852  99787.36152738  31490.67596647  97559.50521232\n  58586.96961106  60064.22955561  42561.67150314 102542.88179931\n  54250.53399032  32585.46737595 109760.43053868  31959.68841644\n  54925.71650541  54777.50583869  98218.22007186  60261.84397421\n  32354.91705733  60344.18342981  58685.77691852  43632.08305175\n 102822.83567351  60261.84397421  99935.57219409  32042.02767572\n  55469.15600933  50738.18424882  96867.85504168 100956.58018713\n  53954.11246057  32848.9533983   94595.28952223  54826.90939427\n  54612.82692749  58521.09820363  32568.9995241   98634.61071948\n  54530.48766821  54448.14840892  67297.55364572  95418.68290035\n  62561.80479576 109974.51280914  38069.80570779  55106.86326847\n  32289.0456499  100940.11233527  54514.01981635  77200.09422744\n  28480.27437865  50573.50573024  55436.22030562  32190.23853875\n  54777.50583869  31860.88110898  32684.2744871   43813.22942218\n  99293.32557903  59767.80802587  43236.85421455  32025.55982386\n  94644.6930778   60163.03686307  32848.9533983  100582.59609492\n  55271.54178704  36164.38102601  54217.5982866   58323.48378503\n  43648.55090361  67495.16806432  32256.10994618  54777.50583869\n  55271.54178704  57747.10838109  60080.69740747  54744.57013498\n  32354.91705733  54448.14840892  65936.26136161  54777.50583869\n  36839.56373741  54991.58791284  99293.32557903  65244.61079835\n  58586.96961106  54777.50583869  35999.70250744  31959.68841644\n  54448.14840892 101121.2587057   95418.68290035  59892.01547769\n  97230.14817517  96159.73662656  54217.5982866  104201.2883106\n  54448.14840892  98766.35373065  54777.50583869  50573.50573024\n  42751.37391273  97822.99162729  54365.80914963  65326.95025395\n  71060.38425964  58422.29089618  51298.09199722  32519.59596852\n  54826.90939427  43977.90833338  54777.50583869  32042.02767572\n  99787.36152738 104925.87457758  28809.63180842  65376.35380952\n  36329.0597409   58768.11617781  65590.43607998  97724.18451614\n  32009.09197201  60410.05483724  59924.9511814   37921.59484476\n  31860.88110898  60410.05483724 102279.39597328  36786.33236852\n  62561.80479576  95138.72902615 100034.37969786  54942.18435727\n  99787.36152738  50458.23076724 193472.41040241  32025.55982386\n  32717.21019081]\n</pre> In\u00a0[100]: Copied! <pre>from sklearn.metrics import r2_score, mean_squared_error,mean_absolute_error\nimport numpy as np\n\nprint(\"Soma dos Erros ao Quadrado (SSE): %2.f \" % np.sum((y_teste_predito - Y_teste)**2))\nprint(\"Erro Quadr\u00e1tico M\u00e9dio (MSE): %.2f\" % mean_squared_error(Y_teste, y_teste_predito))\nprint(\"Erro M\u00e9dio Absoluto (MAE): %.2f\" % mean_absolute_error(Y_teste, y_teste_predito))\nprint (\"Raiz do Erro Quadr\u00e1tico M\u00e9dio (RMSE): %.2f \" % np.sqrt(mean_squared_error(Y_teste, y_teste_predito)))\nprint(\"R2-score: %.2f\" % r2_score(y_teste_predito , Y_teste) )\n</pre> from sklearn.metrics import r2_score, mean_squared_error,mean_absolute_error import numpy as np  print(\"Soma dos Erros ao Quadrado (SSE): %2.f \" % np.sum((y_teste_predito - Y_teste)**2)) print(\"Erro Quadr\u00e1tico M\u00e9dio (MSE): %.2f\" % mean_squared_error(Y_teste, y_teste_predito)) print(\"Erro M\u00e9dio Absoluto (MAE): %.2f\" % mean_absolute_error(Y_teste, y_teste_predito)) print (\"Raiz do Erro Quadr\u00e1tico M\u00e9dio (RMSE): %.2f \" % np.sqrt(mean_squared_error(Y_teste, y_teste_predito))) print(\"R2-score: %.2f\" % r2_score(y_teste_predito , Y_teste) ) <pre>Soma dos Erros ao Quadrado (SSE): 177032003697 \nErro Quadr\u00e1tico M\u00e9dio (MSE): 678283539.07\nErro M\u00e9dio Absoluto (MAE): 19312.26\nRaiz do Erro Quadr\u00e1tico M\u00e9dio (RMSE): 26043.88 \nR2-score: 0.02\n</pre> In\u00a0[21]: Copied! <pre>## implemente sua sua solu\u00e7\u00e3o....\n</pre> ## implemente sua sua solu\u00e7\u00e3o....    In\u00a0[101]: Copied! <pre>import joblib\n\n# Supondo que seu modelo treinado seja armazenado na vari\u00e1vel `model`\njoblib.dump(lin_model, 'modelo_treinado.joblib')\n</pre> import joblib  # Supondo que seu modelo treinado seja armazenado na vari\u00e1vel `model` joblib.dump(lin_model, 'modelo_treinado.joblib')  Out[101]: <pre>['modelo_treinado.joblib']</pre> In\u00a0[102]: Copied! <pre># Para carregar o modelo posteriormente\n\nmodel = joblib.load('modelo_treinado.joblib')\n</pre> # Para carregar o modelo posteriormente  model = joblib.load('modelo_treinado.joblib')"},{"location":"aulas/IA/lab03/preco-notebook.html#objetivos","title":"Objetivos\u00b6","text":"<ul> <li>Vamos desenvolver um projeto completo de regress\u00e3o, desde a explora\u00e7\u00e3o inicial dos dados at\u00e9 a constru\u00e7\u00e3o e avalia\u00e7\u00e3o do modelo final.</li> </ul>"},{"location":"aulas/IA/lab03/preco-notebook.html#definicao-do-problema","title":"Defini\u00e7\u00e3o do problema\u00b6","text":""},{"location":"aulas/IA/lab03/preco-notebook.html#faca-o-download-do-dataset-aqui-httpsdrivegooglecomfiled1pqtec5sx9zz4qi2q3zp2k-gi2pjclgj9viewuspsharing","title":"Fa\u00e7a o download do dataset aqui: https://drive.google.com/file/d/1pqtEc5sx9Zz4QI2Q3zP2k-Gi2PJClGJ9/view?usp=sharing\u00b6","text":"<p>Vamos explorar um dataset que cont\u00e9m informa\u00e7\u00f5es detalhadas sobre 1303 modelos de notebooks. Este dataset foi compilado para nos ajudar a entender as caracter\u00edsticas t\u00e9cnicas e de mercado.</p> <p>Informa\u00e7\u00f5es importantes sobre o significado de cada um dos atributos</p> <ul> <li><p>O dataset \"laptop_data.csv\" cont\u00e9m 1303 entradas e 12 colunas.</p> </li> <li><p>As colunas incluem:</p> <ul> <li>Unnamed: 0: Um \u00edndice ou identificador num\u00e9rico para cada entrada.</li> <li>Company: A marca ou fabricante do laptop.</li> <li>TypeName: O tipo ou categoria do laptop (por exemplo, Notebook, Ultrabook, etc.).</li> <li>Inches: O tamanho da tela do laptop em polegadas.</li> <li>ScreenResolution: A resolu\u00e7\u00e3o da tela do laptop.</li> <li>Cpu: O modelo e a especifica\u00e7\u00e3o da CPU do laptop.</li> <li>Ram: A quantidade de RAM no laptop.</li> <li>Memory: O tipo e a capacidade de armazenamento (por exemplo, HDD, SSD).</li> <li>Gpu: A unidade de processamento gr\u00e1fico (GPU) do laptop.</li> <li>OpSys: O sistema operacional instalado no laptop.</li> <li>Weight: O peso do laptop.</li> <li>Price: O pre\u00e7o do laptop.</li> </ul> </li> </ul>"},{"location":"aulas/IA/lab03/preco-notebook.html#objetivo","title":"Objetivo\u00b6","text":"<p><code>Queremos desenvolver um modelo capaz de predizer o valor de um notebook.</code></p>"},{"location":"aulas/IA/lab03/preco-notebook.html#desafio-1","title":"Desafio 1\u00b6","text":"<p>Do ponto de vista de machine learning, que problema \u00e9 esse:</p> <pre><code>Aprendizado supervisionado, n\u00e3o-supervisionado ou aprendizado por refor\u00e7o?</code></pre> <p>R:</p> <pre><code>Classifica\u00e7\u00e3o, regress\u00e3o ou clusteriza\u00e7\u00e3o?</code></pre> <p>R:</p>"},{"location":"aulas/IA/lab03/preco-notebook.html#desafio-2","title":"Desafio 2\u00b6","text":"<p>Use os metodos info() e describe() para exibir as informa\u00e7\u00f5es do dataframe e responda:</p> <p>Existe dados faltantes?</p> <p>Qual o tipo de dados dos atributos, isso faz sentido?</p>"},{"location":"aulas/IA/lab03/preco-notebook.html#explorando-os-dados-visualmente","title":"Explorando os Dados Visualmente\u00b6","text":"<p>Agora, vamos mergulhar nos dados para descobrir padr\u00f5es, tend\u00eancias e insights que s\u00f3 podem ser revelados por uma an\u00e1lise visual. Elabore an\u00e1lises para tentar responder algumas das seguintes perguntas:</p> <ul> <li>Como o tamanho da tela influencia o pre\u00e7o?</li> <li>Qual a marca de notebook que mais vende?</li> <li>A marca que mais vende \u00e9 a que possui os maiores pre\u00e7os?</li> <li>Existe uma correla\u00e7\u00e3o entre a marca do laptop e o tipo de GPU utilizado?</li> <li>Quais s\u00e3o as faixas de pre\u00e7os mais comuns? Certos tipos de laptops dominam o mercado?</li> <li>Ser\u00e1 que a distribui\u00e7\u00e3o de pre\u00e7os varia muito entre diferentes marcas? E entre diferentes tipos de mem\u00f3ria?</li> <li>Existem laptops com pre\u00e7os ou especifica\u00e7\u00f5es muito fora do comum?</li> </ul> <p>Aplique os m\u00e9todos que achar conveniente (j\u00e1 vimos algumas op\u00e7\u00f5es em aula) para visualizar os dados de forma gr\u00e1fica. Use esses gr\u00e1ficos para identificar padr\u00f5es e rela\u00e7\u00f5es que podem ser explorados em an\u00e1lises mais profundas.</p>"},{"location":"aulas/IA/lab03/preco-notebook.html#pre-processamento-de-dados","title":"Pr\u00e9-processamento de dados\u00b6","text":"<p>Vamos imaginar que estamos interessados em saber se a presen\u00e7a de uma tela touchscreen influencia o pre\u00e7o de um laptop.</p> <ul> <li><code>Como voc\u00ea extrairia informa\u00e7\u00e3o dos dados que temos em formato de texto e a transformaria em algo que possa ser visualizado ou modelado?</code></li> </ul>"},{"location":"aulas/IA/lab03/preco-notebook.html#desafio-3","title":"Desafio 3\u00b6","text":"<p>Implemente as seguintes transforma\u00e7\u00f5es nos dados:</p> <ul> <li>criar uma nova coluna chamada 'Ips' que recebe 1 se o valor da coluna 'ScreenResolution' cont\u00e9m a palavra 'IPS' e 0 caso contr\u00e1rio.</li> </ul>"},{"location":"aulas/IA/lab03/preco-notebook.html#desafio-4","title":"Desafio 4\u00b6","text":"<ul> <li>criar uma nova coluna chamada 'Cpu Name' que recebe da coluna 'Cpu' o nome do fabricante da cpu, Intel, AMD e outros...</li> </ul>"},{"location":"aulas/IA/lab03/preco-notebook.html#desafio-5","title":"Desafio 5\u00b6","text":"<ul> <li>criar uma nova coluna chamada 'Cpu Name' que recebe da coluna 'Cpu' o nome do fabricante da cpu, Intel, AMD e outros...</li> </ul>"},{"location":"aulas/IA/lab03/preco-notebook.html#desafio-6","title":"Desafio 6\u00b6","text":"<ul> <li>criar uma nova coluna chamada 'Gpu Name' que recebe da coluna 'Gpu' o nome do fabricante da cpu, Nvidia, Intel e AMD.</li> </ul>"},{"location":"aulas/IA/lab03/preco-notebook.html#desafio-resolvido","title":"Desafio resolvido\u00b6","text":"<ul> <li>criar uma nova coluna chamada 'os' que recebe da coluna 'OpSys' o nome do fabricante do sistema operacional: Windows, MAC, Linux.</li> </ul>"},{"location":"aulas/IA/lab03/preco-notebook.html#desafio-7","title":"Desafio 7\u00b6","text":"<ul> <li><p>An\u00e1lise o atributo <code>Memory</code>, visualize os tipos de memoria existentes: \u00c9 espeperado que voc\u00ea consiga observar 4 tipos de memoria, s\u00e3o elas:</p> <ul> <li>HDD</li> <li>SSD</li> <li>Hybrid</li> <li>Flash_Storage</li> </ul> </li> <li><p>Fa\u00e7a a convers\u00e3o de unidade: Note que a capacidade de armazenamento variam bastante e devem ser padronizadas em GB, os valores em TB devem ser convertidos para GB, ou seja 1TB = 1000GB.</p> </li> <li><p>Crie novas colunas chamadas 'SSD', 'HDD', 'Hybrid' e 'Flash_Storage' que recebe da coluna 'Memory' o valor da capacidade de memoria.</p> </li> <li><p>Note que em alguns casos uma entrada de dados possui mais de um tipo de memoria '512GB SSD +  2TB HDD' e nesse caso deve ser alocado o valor correto nas duas colunas.</p> </li> </ul>"},{"location":"aulas/IA/lab03/preco-notebook.html#avaliacao-de-correlacao","title":"Avalia\u00e7\u00e3o de correla\u00e7\u00e3o\u00b6","text":"<p>Vamos explorar a correla\u00e7\u00e3o entre os atributos num\u00e9ricos</p>"},{"location":"aulas/IA/lab03/preco-notebook.html#desafio-8","title":"Desafio 8\u00b6","text":"<p>Analisando a matriz de correla\u00e7\u00e3o acima responda:</p> <p>Qual(is) feature possue a maior correla\u00e7\u00e3o com o target?</p> <p>Qual(is) feature n\u00e3o possue correla\u00e7\u00e3o com o target?</p>"},{"location":"aulas/IA/lab03/preco-notebook.html#pare","title":"PARE!!!\u00b6","text":"<p>Podemos pensar em outras diversas transforma\u00e7\u00f5es em nossos dados, por hora j\u00e1 est\u00e1 bom. Vamos avan\u00e7ar e criar um sub-dataset com os atributos que ser\u00e3o utilizados para treinar nosso modelo de Machine Learning.</p>"},{"location":"aulas/IA/lab03/preco-notebook.html#desafio-9","title":"Desafio 9\u00b6","text":"<ul> <li>Identifica\u00e7\u00e3o do Atributo Alvo: Qual \u00e9 o atributo que queremos prever ou analisar como nossa vari\u00e1vel de interesse principal neste conjunto de dados?</li> </ul>"},{"location":"aulas/IA/lab03/preco-notebook.html#dividindo-os-dados-em-conjunto-de-treinamento-e-de-testes","title":"Dividindo os dados em conjunto de treinamento e de testes\u00b6","text":"<p>Dividir nosso dataset em dois conjuntos de dados.</p> <pre><code>Treinamento - Representa 80% das amostras do conjunto de dados original,\nTeste - com 20% das amostras</code></pre> <p>Vamos escolher aleatoriamente algumas amostras do conjunto original. Isto pode ser feito com Scikit-Learn usando a fun\u00e7\u00e3o train_test_split()</p> <p>scikit-learn Caso ainda n\u00e3o tenha instalado, no terminal digite:</p> <ul> <li>pip install scikit-learn</li> </ul>"},{"location":"aulas/IA/lab03/preco-notebook.html#chegou-a-hora-de-aplicar-o-modelo-preditivo","title":"Chegou a hora de aplicar o modelo preditivo\u00b6","text":"<p>Treinar um modelo no python \u00e9 simples se usar o Scikit-Learn. Treinar um modelo no Scikit-Learn \u00e9 simples: basta criar o regressor, e chamar o m\u00e9todo fit().</p> <p>Uma observa\u00e7\u00e3o sobre a sintaxe dos classificadores do <code>scikit-learn</code></p> <ul> <li>O m\u00e9todo <code>fit(X,Y)</code> recebe uma matriz ou dataframe X onde cada linha \u00e9 uma amostra de aprendizado, e um array Y contendo as sa\u00eddas esperadas do classificador, seja na forma de texto ou de inteiros</li> <li>O m\u00e9todo <code>predict(X)</code> recebe uma matriz ou dataframe X onde cada linha \u00e9 uma amostra de teste, retornando um array de classes</li> </ul>"},{"location":"aulas/IA/lab03/preco-notebook.html#avaliando-o-modelo-treinado","title":"Avaliando o modelo treinado\u00b6","text":"<p>Vamos colocar alguns valores e ver a predi\u00e7\u00e3o do classificador.</p>"},{"location":"aulas/IA/lab03/preco-notebook.html#desafio-10","title":"Desafio 10\u00b6","text":"<p>Refa\u00e7a o notebook substituindo o algoritmo de regress\u00e3o linear por outro algoritmo de regress\u00e3o e compare os resultados obtidos.</p> <p>Sugest\u00e3o de alguns algoritmos de ML para problemas de regress\u00e3o:</p> Nome Vantagem Desvantagem Exemplo sklearn Regress\u00e3o Linear F\u00e1cil de entender e implementar Pode n\u00e3o ser adequado para problemas mais complexos from sklearn.linear_model import LinearRegressionmodel = LinearRegression()model.fit(X, y)prediction = model.predict([X_teste]) \u00c1rvores de decis\u00e3o F\u00e1cil de entender e visualizar Pode levar a overfitting se a \u00e1rvore for muito grande from sklearn.tree import DecisionTreeRegressormodel = DecisionTreeRegressor()model.fit(X, y)prediction = model.predict([X_teste]) Random Forest Mais robusto e geralmente mais preciso do que uma \u00fanica \u00e1rvore de decis\u00e3o Pode ser mais lento e mais dif\u00edcil de ajustar from sklearn.ensemble import RandomForestRegressormodel = RandomForestRegressor(n_estimators=100)model.fit(X, y)prediction = model.predict([X_teste]) Support Vector Regression (SVR) Lida bem com dados multidimensionais e n\u00e3o lineares Pode ser dif\u00edcil de escolher o kernel correto e ajustar os hiperpar\u00e2metros from sklearn.svm import SVRmodel = SVR(kernel='rbf')model.fit(X, y)prediction = model.predict([X_teste]) Gradient Boosting Preciso e lida bem com dados multidimensionais e n\u00e3o lineares Pode ser mais lento e mais dif\u00edcil de ajustar from sklearn.ensemble import GradientBoostingRegressormodel = GradientBoostingRegressor(n_estimators=100)model.fit(X, y)prediction = model.predict([X_teste])"},{"location":"aulas/IA/lab03/preco-notebook.html#exportando-o-modelo","title":"Exportando o Modelo\u00b6","text":"<p>Agora que conclu\u00edmos o treinamento do nosso modelo, \u00e9 hora de salv\u00e1-lo para que possamos reutiliz\u00e1-lo posteriormente. Isso nos permitir\u00e1 aplicar o modelo a novos dados sem precisar trein\u00e1-lo novamente, economizando tempo e recursos.</p>"},{"location":"aulas/IA/lab03/regressao-ml-completa.html","title":"Regress\u00e3o em Machine Learning","text":"<p>Nesta aula, vamos explorar os fundamentos de problemas de regress\u00e3o, entender como modelar rela\u00e7\u00f5es entre vari\u00e1veis e aplicar esses conceitos em atividades pr\u00e1ticas. Nosso objetivo \u00e9 aprender a entender o problema a ser resolvido e treinar modelos de forma precisa e eficiente.</p>"},{"location":"aulas/IA/lab03/regressao-ml-completa.html#atividades-praticas","title":"Atividades Pr\u00e1ticas","text":"<p>As seguintes atividades foram preparadas para refor\u00e7ar os conceitos abordados:</p> <ul> <li>Lab 1: Regress\u00e3o Simples   Introdu\u00e7\u00e3o aos conceitos b\u00e1sicos de regress\u00e3o, com aplica\u00e7\u00e3o pr\u00e1tica na predi\u00e7\u00e3o de pre\u00e7os de casas na Calif\u00f3rnia.</li> <li>Lab 2: T\u00e9cnicas Avan\u00e7adas   Explora\u00e7\u00e3o de m\u00e9todos como regress\u00e3o polinomial e XGBoost para modelagem mais robusta.</li> <li>Lab 3: Predi\u00e7\u00e3o de Pre\u00e7os de Notebooks   Treinamento de um modelo para prever o valor de notebooks com base em suas caracter\u00edsticas.</li> </ul>"},{"location":"aulas/IA/lab03/regressao-ml-completa.html#datasets","title":"Datasets","text":"<p>Os laborat\u00f3rios utilizam os seguintes conjuntos de dados: - Housing: Informa\u00e7\u00f5es sobre casas na Calif\u00f3rnia, usado no Lab 1. - Laptop Data: Dados de notebooks, usado no Lab 3.</p>"},{"location":"aulas/IA/lab03/regressao-ml-completa.html#o-que-e-regressao","title":"O que \u00e9 regress\u00e3o?","text":"<p>A regress\u00e3o \u00e9 uma t\u00e9cnica de aprendizado supervisionado usada para prever valores num\u00e9ricos cont\u00ednuos a partir de vari\u00e1veis de entrada (features). Em vez de atribuir classes, buscamos estimar quantidades \u2014 por exemplo, o pre\u00e7o de um im\u00f3vel ou a temperatura amanh\u00e3.</p>"},{"location":"aulas/IA/lab03/regressao-ml-completa.html#classificacao-vs-regressao","title":"Classifica\u00e7\u00e3o vs Regress\u00e3oQual \u00e9 a principal diferen\u00e7a entre regress\u00e3o e classifica\u00e7\u00e3o?","text":"Aspecto Classifica\u00e7\u00e3o Regress\u00e3o Sa\u00edda Categ\u00f3rica / Discreta Num\u00e9rica / Cont\u00ednua Exemplos Spam / Sentimento / Tipo de flor Pre\u00e7o / Temperatura / Altura M\u00e9tricas Acur\u00e1cia, Precis\u00e3o, Recall MAE, MSE, RMSE, R\u00b2 Exemplos de algoritmos KNN, SVM, Random Forest (class.) Regress\u00e3o Linear, Ridge, Lasso, SVR, \u00c1rvores/Boosting Regress\u00e3o prediz categorias; Classifica\u00e7\u00e3o prediz n\u00famerosAmbas s\u00f3 funcionam com dados categ\u00f3ricosRegress\u00e3o prediz n\u00fameros; Classifica\u00e7\u00e3o prediz categoriasClassifica\u00e7\u00e3o \u00e9 sempre n\u00e3o supervisionadaSubmit Regress\u00e3o estima valores num\u00e9ricos cont\u00ednuos (por exemplo, pre\u00e7o), enquanto classifica\u00e7\u00e3o atribui uma categoria ou r\u00f3tulo (por exemplo, spam ou n\u00e3o-spam)."},{"location":"aulas/IA/lab03/regressao-ml-completa.html#ideia-matematica","title":"Ideia matem\u00e1tica","text":"<p>Procuramos uma fun\u00e7\u00e3o f que aproxime a rela\u00e7\u00e3o entre entradas X e alvo y:</p> <pre><code>y = f(X) + \u03b5\n</code></pre> <p>\u03b5 representa o ru\u00eddo \u2014 sempre haver\u00e1 alguma incerteza.</p> O que representa \u03b5 na equa\u00e7\u00e3o y = f(X) + \u03b5 ?Um par\u00e2metro do modeloO ru\u00eddo ou erro aleat\u00f3rioA vari\u00e1vel de entradaSubmit \u03b5 simboliza o erro aleat\u00f3rio ou ru\u00eddo que n\u00e3o \u00e9 explicado pela fun\u00e7\u00e3o f(X); \u00e9 a parte imprevis\u00edvel dos dados."},{"location":"aulas/IA/lab03/regressao-ml-completa.html#principais-familias-de-modelos","title":"Principais fam\u00edlias de modelos","text":"<ol> <li> <p>Regress\u00e3o Linear Simples</p> <ul> <li>Uma vari\u00e1vel explicativa; rela\u00e7\u00e3o aproximadamente linear: <code>y = \u03b2\u2080 + \u03b2\u2081x + \u03b5</code>.</li> </ul> </li> <li> <p>Regress\u00e3o Linear M\u00faltipla</p> <ul> <li>V\u00e1rias features: <code>y = \u03b2\u2080 + \u03b2\u2081x\u2081 + \u03b2\u2082x\u2082 + ... + \u03b2\u2099x\u2099 + \u03b5</code>.</li> </ul> </li> <li> <p>Regress\u00e3o Polinomial</p> <ul> <li>Quando a rela\u00e7\u00e3o \u00e9 n\u00e3o linear, aumentamos a base com pot\u00eancias de x: <code>y = \u03b2\u2080 + \u03b2\u2081x + \u03b2\u2082x\u00b2 + ...</code>.</li> </ul> </li> <li> <p>Regress\u00e3o Regularizada</p> <ul> <li>Ridge (L2): penaliza coeficientes grandes \u2014 \u00fatil quando h\u00e1 multicolinearidade.</li> <li>Lasso (L1): pode zerar coeficientes \u2014 ajuda a selecionar features.</li> <li>Elastic Net: combina\u00e7\u00e3o L1 + L2.</li> </ul> </li> <li> <p>SVR (Support Vector Regression) </p> <ul> <li>Ideal para datasets pequenos/m\u00e9dios com rela\u00e7\u00f5es n\u00e3o lineares, usando kernels (como RBF) para capturar padr\u00f5es complexos sem necessidade de features polinomiais.</li> </ul> </li> <li>\u00c1rvores, Florestas e Boosting<ul> <li>Modelos como Random Forest e XGBoost s\u00e3o poderosos para capturar n\u00e3o linearidades e intera\u00e7\u00f5es entre features. S\u00e3o menos sens\u00edveis a outliers e requerem menos pr\u00e9-processamento, mas podem ser mais dif\u00edceis de interpretar.</li> </ul> </li> </ol> Qual m\u00e9todo tende a zerar coeficientes, ajudando na sele\u00e7\u00e3o de features?RidgeLassoRegress\u00e3o PolinomialSVRSubmit Lasso (L1) pode reduzir coeficientes a zero, realizando sele\u00e7\u00e3o de features; Ridge (L2) encolhe coeficientes sem zer\u00e1-los."},{"location":"aulas/IA/lab03/regressao-ml-completa.html#intuicao-de-regressao-linear","title":"Intui\u00e7\u00e3o de Regress\u00e3o Linear","text":"<p>A regress\u00e3o linear procura a reta (ou hiperplano) que melhor explica a rela\u00e7\u00e3o entre X e y, minimizando discrep\u00e2ncias entre valores reais e previstos.</p>"},{"location":"aulas/IA/lab03/regressao-ml-completa.html#metodo-dos-minimos-quadrados","title":"M\u00e9todo dos M\u00ednimos Quadrados","text":"<p>Minimizamos a soma dos quadrados dos res\u00edduos:</p> <pre><code>SSR = \u03a3(y\u1d62 - \u0177\u1d62)\u00b2\n</code></pre> <p>Para regress\u00e3o linear simples, os coeficientes t\u00eam f\u00f3rmulas fechadas \u00fateis para entendimento:</p> <pre><code>\u03b2\u2081 = \u03a3((x\u1d62 - x\u0304)(y\u1d62 - \u0233)) / \u03a3((x\u1d62 - x\u0304)\u00b2)\n\u03b2\u2080 = \u0233 - \u03b2\u2081x\u0304\n</code></pre>"},{"location":"aulas/IA/lab03/regressao-ml-completa.html#intuicao-de-pressupostos-importantes","title":"Intui\u00e7\u00e3o de Pressupostos ImportantesQual pressuposto implica que os res\u00edduos tenham vari\u00e2ncia constante?","text":"<ul> <li>Linearidade: A rela\u00e7\u00e3o entre X e y deve parecer uma reta (ou um plano em m\u00faltiplas dimens\u00f5es). Se os dados formam uma curva, regress\u00e3o linear pode n\u00e3o funcionar bem.</li> <li>Independ\u00eancia: Cada observa\u00e7\u00e3o (e.g., pre\u00e7o de uma casa) n\u00e3o deve ser influenciada por outra.</li> <li>Homocedasticidade: Os erros do modelo (diferen\u00e7a entre valores reais e previstos) devem ter varia\u00e7\u00e3o constante. Imagine que os pontos est\u00e3o igualmente espalhados ao redor da reta de regress\u00e3o.</li> <li>Normalidade dos res\u00edduos: Os erros devem seguir uma distribui\u00e7\u00e3o normal (isso \u00e9 mais importante para testes estat\u00edsticos).</li> <li>Baixa multicolinearidade: As features n\u00e3o devem ser muito correlacionadas entre si (e.g., se \"\u00e1rea da casa\" e \"n\u00famero de quartos\" s\u00e3o quase id\u00eanticas, isso pode confundir o modelo).</li> </ul> LinearidadeHomocedasticidadeNormalidadeIndepend\u00eancia das observa\u00e7\u00f5esSubmit Homocedasticidade significa que a vari\u00e2ncia dos res\u00edduos \u00e9 aproximadamente constante ao longo das predi\u00e7\u00f5es; quando isso falha, temos heterocedasticidade."},{"location":"aulas/IA/lab03/regressao-ml-completa.html#exemplo-em-python","title":"Exemplo em Python","text":"<pre><code>from sklearn.linear_model import LinearRegression\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import mean_squared_error, r2_score\nimport numpy as np\n\n# Dados sint\u00e9ticos\nnp.random.seed(42)\nX = np.random.randn(100, 1)\ny = 2 + 3 * X.ravel() + np.random.randn(100)\n\n# Treino / teste\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# Treina\nmodel = LinearRegression()\nmodel.fit(X_train, y_train)\n\n# Prediz\ny_pred = model.predict(X_test)\n\n# Avalia\nmse = mean_squared_error(y_test, y_pred)\nr2 = r2_score(y_test, y_pred)\n\nprint(f\"Coeficiente: {model.coef_[0]:.2f}\")\nprint(f\"Intercepto: {model.intercept_:.2f}\")\nprint(f\"MSE: {mse:.2f}\")\nprint(f\"R\u00b2: {r2:.2f}\")\n</code></pre> <p>Para visualizar o resultado:</p> <pre><code>import matplotlib.pyplot as plt\n\n# Plot dos dados e da reta de regress\u00e3o\nplt.scatter(X_test, y_test, color='blue', label='Dados reais')\nplt.plot(X_test, y_pred, color='red', label='Reta de regress\u00e3o')\nplt.xlabel('X')\nplt.ylabel('y')\nplt.title('Regress\u00e3o Linear Simples')\nplt.legend()\nplt.show()\n</code></pre> <p></p>"},{"location":"aulas/IA/lab03/regressao-ml-completa.html#metricas-de-avaliacao","title":"M\u00e9tricas de avalia\u00e7\u00e3o","text":"<p>As m\u00e9tricas ajudam a comparar modelos e interpretar a magnitude dos erros.</p>"},{"location":"aulas/IA/lab03/regressao-ml-completa.html#mse-erro-quadratico-medio","title":"MSE (Erro Quadr\u00e1tico M\u00e9dio)","text":"<pre><code>MSE = (1/n) \u00d7 \u03a3(y\u1d62 - \u0177\u1d62)\u00b2\n</code></pre> <p>Penaliza erros grandes (unidade: quadrado da unidade do target).</p>"},{"location":"aulas/IA/lab03/regressao-ml-completa.html#rmse-raiz-do-mse","title":"RMSE (Raiz do MSE)","text":"<pre><code>RMSE = \u221aMSE\n</code></pre> <p>Tem a mesma unidade do target e \u00e9 mais intuitiva que o MSE.</p>"},{"location":"aulas/IA/lab03/regressao-ml-completa.html#mae-erro-absoluto-medio","title":"MAE (Erro Absoluto M\u00e9dio)","text":"<pre><code>MAE = (1/n) \u00d7 \u03a3|y\u1d62 - \u0177\u1d62|\n</code></pre> <p>Menos sens\u00edvel a outliers que o MSE/RMSE.</p>"},{"location":"aulas/IA/lab03/regressao-ml-completa.html#r2-coeficiente-de-determinacao","title":"R\u00b2 (Coeficiente de Determina\u00e7\u00e3o)","text":"<pre><code>R\u00b2 = 1 - (SSres / SStot)\n</code></pre> <p>Onde: - SSres = \u03a3(y\u1d62 - \u0177\u1d62)\u00b2 - SStot = \u03a3(y\u1d62 - \u0233)\u00b2</p> <p>R\u00b2 indica a propor\u00e7\u00e3o da vari\u00e2ncia explicada pelo modelo. Valores mais altos s\u00e3o melhores, mas aten\u00e7\u00e3o: R\u00b2 pode ser negativo se o modelo for pior que prever a m\u00e9dia.</p>"},{"location":"aulas/IA/lab03/regressao-ml-completa.html#exemplo-em-python_1","title":"Exemplo em PythonQual m\u00e9trica \u00e9 menos sens\u00edvel a outliers?Ajuste w (peso) e b (vi\u00e9s) para minimizar o MSE","text":"<pre><code>from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\nimport numpy as np\n\n# supondo, modelo j\u00e1 treinado e y_true e y_pred \nmse = mean_squared_error(y_true, y_pred)\nrmse = np.sqrt(mse)\nmae = mean_absolute_error(y_true, y_pred)\nr2 = r2_score(y_true, y_pred)\n\nprint(f\"MSE: {mse:.4f}\")\nprint(f\"RMSE: {rmse:.4f}\")\nprint(f\"MAE: {mae:.4f}\")\nprint(f\"R\u00b2: {r2:.4f}\")\n</code></pre> MSERMSEMAER\u00b2Submit MAE (Erro Absoluto M\u00e9dio) penaliza menos discrep\u00e2ncias grandes que o MSE/RMSE, sendo mais robusto a outliers. peso <code>w</code>: 0.50 vi\u00e9s <code>b</code>: 0.00 MSE: \u2014 Equa\u00e7\u00e3o: <code>y = w\u00b7x + b</code>  Mostrar res\u00edduos        Auto-ajustar (OLS) Reset x: peso (milhares de lbs) \u2022 y: mpg Como funciona <p>       Dados fixos (x,y). A reta <code>y = w\u00b7x + b</code> \u00e9 desenhada. O erro \u00e9       <code>MSE = (1/n) \u03a3 (y \u2212 (w\u00b7x+b))\u00b2</code>. Ajuste os sliders para reduzir o MSE ou use Auto-ajustar (OLS).     </p>"},{"location":"aulas/IA/lab03/regressao-old.html","title":"Regressao old","text":"In\u00a0[1]: Copied! <pre># Inicializ\u00e7\u00e3o das bibliotecas\n%matplotlib inline\n\nimport pandas as pd\nimport matplotlib.pyplot as plt\n</pre> # Inicializ\u00e7\u00e3o das bibliotecas %matplotlib inline  import pandas as pd import matplotlib.pyplot as plt  In\u00a0[15]: Copied! <pre>import pandas as pd\n\n# Carregando o dataset com o delimitador correto\ndf = pd.read_csv('housing.csv', delim_whitespace=True, header=None)\n\n# Atribuindo nomes \u00e0s colunas\ndf.columns = ['CRIM', 'ZN', 'INDUS', 'CHAS', 'NOX', 'RM', 'AGE', 'DIS', 'RAD', 'TAX', 'PTRATIO', 'B', 'LSTAT', 'MEDV']\n</pre> import pandas as pd  # Carregando o dataset com o delimitador correto df = pd.read_csv('housing.csv', delim_whitespace=True, header=None)  # Atribuindo nomes \u00e0s colunas df.columns = ['CRIM', 'ZN', 'INDUS', 'CHAS', 'NOX', 'RM', 'AGE', 'DIS', 'RAD', 'TAX', 'PTRATIO', 'B', 'LSTAT', 'MEDV'] In\u00a0[17]: Copied! <pre>df.head()\n</pre> df.head() Out[17]: CRIM ZN INDUS CHAS NOX RM AGE DIS RAD TAX PTRATIO B LSTAT MEDV 0 0.00632 18.0 2.31 0 0.538 6.575 65.2 4.0900 1 296.0 15.3 396.90 4.98 24.0 1 0.02731 0.0 7.07 0 0.469 6.421 78.9 4.9671 2 242.0 17.8 396.90 9.14 21.6 2 0.02729 0.0 7.07 0 0.469 7.185 61.1 4.9671 2 242.0 17.8 392.83 4.03 34.7 3 0.03237 0.0 2.18 0 0.458 6.998 45.8 6.0622 3 222.0 18.7 394.63 2.94 33.4 4 0.06905 0.0 2.18 0 0.458 7.147 54.2 6.0622 3 222.0 18.7 396.90 5.33 36.2 In\u00a0[18]: Copied! <pre># Mostra informa\u00e7\u00f5es sobre o dataframe em si\ndf.info()\n</pre> # Mostra informa\u00e7\u00f5es sobre o dataframe em si df.info() <pre>&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 506 entries, 0 to 505\nData columns (total 14 columns):\n #   Column   Non-Null Count  Dtype  \n---  ------   --------------  -----  \n 0   CRIM     506 non-null    float64\n 1   ZN       506 non-null    float64\n 2   INDUS    506 non-null    float64\n 3   CHAS     506 non-null    int64  \n 4   NOX      506 non-null    float64\n 5   RM       506 non-null    float64\n 6   AGE      506 non-null    float64\n 7   DIS      506 non-null    float64\n 8   RAD      506 non-null    int64  \n 9   TAX      506 non-null    float64\n 10  PTRATIO  506 non-null    float64\n 11  B        506 non-null    float64\n 12  LSTAT    506 non-null    float64\n 13  MEDV     506 non-null    float64\ndtypes: float64(12), int64(2)\nmemory usage: 55.5 KB\n</pre> In\u00a0[19]: Copied! <pre>df.describe()\n</pre> df.describe() Out[19]: CRIM ZN INDUS CHAS NOX RM AGE DIS RAD TAX PTRATIO B LSTAT MEDV count 506.000000 506.000000 506.000000 506.000000 506.000000 506.000000 506.000000 506.000000 506.000000 506.000000 506.000000 506.000000 506.000000 506.000000 mean 3.613524 11.363636 11.136779 0.069170 0.554695 6.284634 68.574901 3.795043 9.549407 408.237154 18.455534 356.674032 12.653063 22.532806 std 8.601545 23.322453 6.860353 0.253994 0.115878 0.702617 28.148861 2.105710 8.707259 168.537116 2.164946 91.294864 7.141062 9.197104 min 0.006320 0.000000 0.460000 0.000000 0.385000 3.561000 2.900000 1.129600 1.000000 187.000000 12.600000 0.320000 1.730000 5.000000 25% 0.082045 0.000000 5.190000 0.000000 0.449000 5.885500 45.025000 2.100175 4.000000 279.000000 17.400000 375.377500 6.950000 17.025000 50% 0.256510 0.000000 9.690000 0.000000 0.538000 6.208500 77.500000 3.207450 5.000000 330.000000 19.050000 391.440000 11.360000 21.200000 75% 3.677083 12.500000 18.100000 0.000000 0.624000 6.623500 94.075000 5.188425 24.000000 666.000000 20.200000 396.225000 16.955000 25.000000 max 88.976200 100.000000 27.740000 1.000000 0.871000 8.780000 100.000000 12.126500 24.000000 711.000000 22.000000 396.900000 37.970000 50.000000 In\u00a0[8]: Copied! <pre>## Sua resposta e seus gr\u00e1ficos para an\u00e1lisar..\n</pre> ## Sua resposta e seus gr\u00e1ficos para an\u00e1lisar..       In\u00a0[20]: Copied! <pre>#Vamos explorar um pouco uma matrix de correla\u00e7\u00e3o\n\nimport seaborn as sns \ncorrelation_matrix = df.corr().round(2)\n\nfig, ax = plt.subplots(figsize=(10,10))    \nsns.heatmap(data=correlation_matrix, annot=True, linewidths=.5, ax=ax)\n</pre> #Vamos explorar um pouco uma matrix de correla\u00e7\u00e3o  import seaborn as sns  correlation_matrix = df.corr().round(2)  fig, ax = plt.subplots(figsize=(10,10))     sns.heatmap(data=correlation_matrix, annot=True, linewidths=.5, ax=ax) Out[20]: <pre>&lt;Axes: &gt;</pre> In\u00a0[21]: Copied! <pre>df.plot.scatter('RM', 'MEDV')\n</pre> df.plot.scatter('RM', 'MEDV') Out[21]: <pre>&lt;Axes: xlabel='RM', ylabel='MEDV'&gt;</pre> In\u00a0[22]: Copied! <pre>df.plot.scatter('LSTAT', 'MEDV')\n</pre> df.plot.scatter('LSTAT', 'MEDV') Out[22]: <pre>&lt;Axes: xlabel='LSTAT', ylabel='MEDV'&gt;</pre> In\u00a0[23]: Copied! <pre># Vamos treinar nosso modelo com 2 dois atributos independentes\n# para predizer o valor de saida\nX = df[['LSTAT', 'RM']]   ### teste com duas entradas\n#X = df[['RM']]            ### teste com uma entrada\n#X = df.drop(['MEDV'], axis=1)     ### teste com todas as entradas\n\nY = df['MEDV']             \nprint(f\"Formato das tabelas de dados {X.shape} e saidas {Y.shape}\")\n</pre> # Vamos treinar nosso modelo com 2 dois atributos independentes # para predizer o valor de saida X = df[['LSTAT', 'RM']]   ### teste com duas entradas #X = df[['RM']]            ### teste com uma entrada #X = df.drop(['MEDV'], axis=1)     ### teste com todas as entradas  Y = df['MEDV']              print(f\"Formato das tabelas de dados {X.shape} e saidas {Y.shape}\") <pre>Formato das tabelas de dados (506, 2) e saidas (506,)\n</pre> In\u00a0[24]: Copied! <pre># Separamos 20% para o teste\nfrom sklearn.model_selection import train_test_split\n\nX_treino, X_teste, Y_treino, Y_teste = train_test_split(X, Y, test_size=0.2)\n\nprint(X_treino.shape)\nprint(X_teste.shape)\nprint(Y_treino.shape)\nprint(Y_teste.shape)\n</pre> # Separamos 20% para o teste from sklearn.model_selection import train_test_split  X_treino, X_teste, Y_treino, Y_teste = train_test_split(X, Y, test_size=0.2)  print(X_treino.shape) print(X_teste.shape) print(Y_treino.shape) print(Y_teste.shape) <pre>(404, 2)\n(102, 2)\n(404,)\n(102,)\n</pre> In\u00a0[25]: Copied! <pre>#Primeiras linhas do dataframe \nX_treino.head()\n</pre> #Primeiras linhas do dataframe  X_treino.head() Out[25]: LSTAT RM 378 23.69 6.380 312 11.72 6.023 480 10.74 6.242 48 30.81 5.399 359 12.67 6.112 In\u00a0[26]: Copied! <pre>Y_treino.head()\n</pre> Y_treino.head() Out[26]: <pre>378    13.1\n312    19.4\n480    23.0\n48     14.4\n359    22.6\nName: MEDV, dtype: float64</pre> In\u00a0[27]: Copied! <pre># Importa a biblioteca\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import mean_squared_error\n\n# Cria o modelo de regress\u00e3o \nlin_model = LinearRegression()\n\n# Cria o modelo de machine learning\nlin_model.fit(X_treino, Y_treino)\n</pre> # Importa a biblioteca from sklearn.linear_model import LinearRegression from sklearn.metrics import mean_squared_error  # Cria o modelo de regress\u00e3o  lin_model = LinearRegression()  # Cria o modelo de machine learning lin_model.fit(X_treino, Y_treino)    Out[27]: <pre>LinearRegression()</pre>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.\u00a0\u00a0LinearRegression?Documentation for LinearRegressioniFitted<pre>LinearRegression()</pre> <p>Pronto!! bora testar se esta funcionando....</p> In\u00a0[36]: Copied! <pre># Para obter as previs\u00f5es, basta chamar o m\u00e9todo predict()\ny_teste_predito = lin_model.predict(X_teste)\nprint(\"Predi\u00e7\u00e3o usando regress\u00e3o, retorna valores continuos: {}\".format(y_teste_predito))\n</pre> # Para obter as previs\u00f5es, basta chamar o m\u00e9todo predict() y_teste_predito = lin_model.predict(X_teste) print(\"Predi\u00e7\u00e3o usando regress\u00e3o, retorna valores continuos: {}\".format(y_teste_predito))  <pre>Predi\u00e7\u00e3o usando regress\u00e3o, retorna valores continuos: [20.26730472 30.46254362 24.8618173  32.43404913 39.86365469 23.66539013\n 20.77667386 29.75623863 30.44876087 18.5168171  19.63100525 18.74845677\n 23.7281014  27.56448461 22.52117732 18.46185252 22.38157688 26.86156941\n 20.6400214  19.98413697 33.09717059 19.85816854 32.53875855 32.57407067\n 31.32460254 20.38296853 -1.42097188 30.44060351 31.13876155 20.88665514\n 26.44421354 23.68892112 29.17773736 16.88751481 26.47090039 26.69899429\n 25.62037302 30.97988295 26.78880834 25.9065042  19.81451712 27.6467912\n 23.10809072  7.31666945 19.91170866 25.16501706 18.41082354 28.31491416\n 19.71012485 31.53337666 21.41108083 18.647106   18.79161952 21.85406815\n 29.78369494 28.11559716 32.00451181 19.20874148 19.60710514 25.48742742\n 33.17219328 37.93723556 18.13487736 19.68062523  8.94822295 19.71055637\n 36.87667587 16.22855265 32.12840062  8.63270666 40.77399223 18.15030821\n 37.36130782 35.56637856 22.41001584 20.43674263 16.88155149 20.54739459\n 26.7389648  24.91083941 21.49886199 18.11454897 29.67041747 15.20263957\n 11.35784948 36.23439232 20.13915265 16.54518163 30.86536289 13.68864763\n 20.81033789 31.06110293  9.95109888 23.66605564 18.38867028 21.75517654\n 14.85669305 25.86164138 23.90419415 33.09669227 25.29625217 20.97907392]\n</pre> In\u00a0[31]: Copied! <pre># Vamos avaliar os par\u00e2metros do nosso modelo\nprint('(A) Intercepto: ', lin_model.intercept_)\nprint('(B) Inclina\u00e7\u00e3o: ', lin_model.coef_)\n\n# Verificando a quantidade de coeficientes e exibindo a equa\u00e7\u00e3o correspondente\nif len(lin_model.coef_) &gt; 1:\n    print(f'Nossa equa\u00e7\u00e3o \u00e9: Y_pred = {lin_model.intercept_.round(2)} + {lin_model.coef_[0].round(2)} * X_LSTAT + {lin_model.coef_[1].round(2)} * X_RM')\nelse:\n    print(f'Nossa equa\u00e7\u00e3o \u00e9: Y_pred = {lin_model.intercept_.round(2)} + {lin_model.coef_[0].round(2)} * X_LSTAT')\n</pre> # Vamos avaliar os par\u00e2metros do nosso modelo print('(A) Intercepto: ', lin_model.intercept_) print('(B) Inclina\u00e7\u00e3o: ', lin_model.coef_)  # Verificando a quantidade de coeficientes e exibindo a equa\u00e7\u00e3o correspondente if len(lin_model.coef_) &gt; 1:     print(f'Nossa equa\u00e7\u00e3o \u00e9: Y_pred = {lin_model.intercept_.round(2)} + {lin_model.coef_[0].round(2)} * X_LSTAT + {lin_model.coef_[1].round(2)} * X_RM') else:     print(f'Nossa equa\u00e7\u00e3o \u00e9: Y_pred = {lin_model.intercept_.round(2)} + {lin_model.coef_[0].round(2)} * X_LSTAT')  <pre>(A) Intercepto:  -5.170015525018201\n(B) Inclina\u00e7\u00e3o:  [-0.57969707  5.57341034]\nNossa equa\u00e7\u00e3o \u00e9: Y_pred = -5.17 + -0.58 * X_LSTAT + 5.57 * X_RM\n</pre> In\u00a0[37]: Copied! <pre>import matplotlib.pyplot as plt\nimport numpy as np\n\n# Gr\u00e1fico de dispers\u00e3o para X_LSTAT vs Y_pred\nplt.figure(figsize=(12, 5))\n\n# Plot para X_LSTAT\nplt.subplot(1, 2, 1)\nplt.scatter(X_teste['LSTAT'], y_teste_predito, color='blue', alpha=0.6, s=50, label='Valores Preditos')\nplt.plot(X_teste['LSTAT'], lin_model.intercept_ + lin_model.coef_[0] * X_teste['LSTAT'], color='red', linestyle='--', label='Linha de Regress\u00e3o')\nplt.xlabel('% Status de Menor Classe (X_LSTAT)')\nplt.ylabel('Valor Predito (Y_pred)')\nplt.title('Rela\u00e7\u00e3o entre X_LSTAT e Y_pred')\nplt.legend()\n\n# Plot para X_RM\nplt.subplot(1, 2, 2)\nplt.scatter(X_teste['RM'], y_teste_predito, color='green', alpha=0.6, s=50, label='Valores Preditos')\nplt.plot(X_teste['RM'], lin_model.intercept_ + lin_model.coef_[1] * X_teste['RM'], color='red', linestyle='--', label='Linha de Regress\u00e3o')\nplt.xlabel('N\u00famero M\u00e9dio de Quartos (X_RM)')\nplt.ylabel('Valor Predito (Y_pred)')\nplt.title('Rela\u00e7\u00e3o entre X_RM e Y_pred')\nplt.legend()\n\nplt.tight_layout()\nplt.show()\n</pre> import matplotlib.pyplot as plt import numpy as np  # Gr\u00e1fico de dispers\u00e3o para X_LSTAT vs Y_pred plt.figure(figsize=(12, 5))  # Plot para X_LSTAT plt.subplot(1, 2, 1) plt.scatter(X_teste['LSTAT'], y_teste_predito, color='blue', alpha=0.6, s=50, label='Valores Preditos') plt.plot(X_teste['LSTAT'], lin_model.intercept_ + lin_model.coef_[0] * X_teste['LSTAT'], color='red', linestyle='--', label='Linha de Regress\u00e3o') plt.xlabel('% Status de Menor Classe (X_LSTAT)') plt.ylabel('Valor Predito (Y_pred)') plt.title('Rela\u00e7\u00e3o entre X_LSTAT e Y_pred') plt.legend()  # Plot para X_RM plt.subplot(1, 2, 2) plt.scatter(X_teste['RM'], y_teste_predito, color='green', alpha=0.6, s=50, label='Valores Preditos') plt.plot(X_teste['RM'], lin_model.intercept_ + lin_model.coef_[1] * X_teste['RM'], color='red', linestyle='--', label='Linha de Regress\u00e3o') plt.xlabel('N\u00famero M\u00e9dio de Quartos (X_RM)') plt.ylabel('Valor Predito (Y_pred)') plt.title('Rela\u00e7\u00e3o entre X_RM e Y_pred') plt.legend()  plt.tight_layout() plt.show()  In\u00a0[38]: Copied! <pre>from sklearn.metrics import r2_score, mean_squared_error,mean_absolute_error\nimport numpy as np\n\nprint(\"Soma dos Erros ao Quadrado (SSE): %2.f \" % np.sum((y_teste_predito - Y_teste)**2))\nprint(\"Erro Quadr\u00e1tico M\u00e9dio (MSE): %.2f\" % mean_squared_error(Y_teste, y_teste_predito))\nprint(\"Erro M\u00e9dio Absoluto (MAE): %.2f\" % mean_absolute_error(Y_teste, y_teste_predito))\nprint (\"Raiz do Erro Quadr\u00e1tico M\u00e9dio (RMSE): %.2f \" % np.sqrt(mean_squared_error(Y_teste, y_teste_predito)))\nprint(\"R2-score: %.2f\" % r2_score(y_teste_predito , Y_teste) )\n</pre> from sklearn.metrics import r2_score, mean_squared_error,mean_absolute_error import numpy as np  print(\"Soma dos Erros ao Quadrado (SSE): %2.f \" % np.sum((y_teste_predito - Y_teste)**2)) print(\"Erro Quadr\u00e1tico M\u00e9dio (MSE): %.2f\" % mean_squared_error(Y_teste, y_teste_predito)) print(\"Erro M\u00e9dio Absoluto (MAE): %.2f\" % mean_absolute_error(Y_teste, y_teste_predito)) print (\"Raiz do Erro Quadr\u00e1tico M\u00e9dio (RMSE): %.2f \" % np.sqrt(mean_squared_error(Y_teste, y_teste_predito))) print(\"R2-score: %.2f\" % r2_score(y_teste_predito , Y_teste) ) <pre>Soma dos Erros ao Quadrado (SSE): 3400 \nErro Quadr\u00e1tico M\u00e9dio (MSE): 33.34\nErro M\u00e9dio Absoluto (MAE): 3.90\nRaiz do Erro Quadr\u00e1tico M\u00e9dio (RMSE): 5.77 \nR2-score: 0.38\n</pre> In\u00a0[21]: Copied! <pre>## implemente sua sua solu\u00e7\u00e3o....\n</pre> ## implemente sua sua solu\u00e7\u00e3o....    In\u00a0[39]: Copied! <pre>import operator\n\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n\n# importa feature polinomial\nfrom sklearn.preprocessing import PolynomialFeatures\n\n#####----------- vou gerar alguns numeros aleat\u00f3rios ------------------\n\n#gerando numeros aleatorios, apenas para este exemplo\nnp.random.seed(42)\nx = 2 - 3 * np.random.normal(0, 1, 30)\ny = x - 3 * (x ** 2) + 0.8 * (x ** 3)+ 0.2 * (x ** 4) + np.random.normal(-20, 20, 30)\n\n# ajuste nos dados, pois estamos trabalhando com a numpy \nx = x[:, np.newaxis]\ny = y[:, np.newaxis]\n####---------------pronto j\u00e1 temos os dados para treinar -------------\n\n\n#----\u00c9 aqui que o seu c\u00f3digo muda ------------------------------------\n\n# Chama a fun\u00e7\u00e3o definindo o grau do polinomio e aplica o modelo\n\ngrau_poly = 1\npolynomial_features= PolynomialFeatures(degree = grau_poly)\nx_poly = polynomial_features.fit_transform(x)\n\n#----Pronto agora \u00e9 tudo como era antes, com regress\u00e3o linear\n\n\nmodel = LinearRegression()\nmodel.fit(x_poly, y)\ny_poly_pred = model.predict(x_poly)\n\n# M\u00e9trica de avalia\u00e7\u00e3o do modelo\nprint(\"Soma dos Erros ao Quadrado (SSE): %2.f \" % np.sum((y_poly_pred - y)**2))\nprint(\"Erro Quadr\u00e1tico M\u00e9dio (MSE): %.2f\" % mean_squared_error(y,y_poly_pred))\nprint(\"Erro M\u00e9dio Absoluto (MAE): %.2f\" % mean_absolute_error(y, y_poly_pred))\nprint (\"Raiz do Erro Quadr\u00e1tico M\u00e9dio (RMSE): %.2f \" % np.sqrt(mean_squared_error(y, y_poly_pred)))\nprint(\"R2-score: %.2f\" % r2_score(y,y_poly_pred) )\n\n\nplt.scatter(x, y, s=10)\n# ordena os valores de x antes de plotar\nsort_axis = operator.itemgetter(0)\nsorted_zip = sorted(zip(x,y_poly_pred), key=sort_axis)\nx, y_poly_pred = zip(*sorted_zip)\n\nplt.plot(x, y_poly_pred, color='r')\nplt.show()\n</pre> import operator  import numpy as np import matplotlib.pyplot as plt  from sklearn.linear_model import LinearRegression from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error  # importa feature polinomial from sklearn.preprocessing import PolynomialFeatures  #####----------- vou gerar alguns numeros aleat\u00f3rios ------------------  #gerando numeros aleatorios, apenas para este exemplo np.random.seed(42) x = 2 - 3 * np.random.normal(0, 1, 30) y = x - 3 * (x ** 2) + 0.8 * (x ** 3)+ 0.2 * (x ** 4) + np.random.normal(-20, 20, 30)  # ajuste nos dados, pois estamos trabalhando com a numpy  x = x[:, np.newaxis] y = y[:, np.newaxis] ####---------------pronto j\u00e1 temos os dados para treinar -------------   #----\u00c9 aqui que o seu c\u00f3digo muda ------------------------------------  # Chama a fun\u00e7\u00e3o definindo o grau do polinomio e aplica o modelo  grau_poly = 1 polynomial_features= PolynomialFeatures(degree = grau_poly) x_poly = polynomial_features.fit_transform(x)  #----Pronto agora \u00e9 tudo como era antes, com regress\u00e3o linear   model = LinearRegression() model.fit(x_poly, y) y_poly_pred = model.predict(x_poly)  # M\u00e9trica de avalia\u00e7\u00e3o do modelo print(\"Soma dos Erros ao Quadrado (SSE): %2.f \" % np.sum((y_poly_pred - y)**2)) print(\"Erro Quadr\u00e1tico M\u00e9dio (MSE): %.2f\" % mean_squared_error(y,y_poly_pred)) print(\"Erro M\u00e9dio Absoluto (MAE): %.2f\" % mean_absolute_error(y, y_poly_pred)) print (\"Raiz do Erro Quadr\u00e1tico M\u00e9dio (RMSE): %.2f \" % np.sqrt(mean_squared_error(y, y_poly_pred))) print(\"R2-score: %.2f\" % r2_score(y,y_poly_pred) )   plt.scatter(x, y, s=10) # ordena os valores de x antes de plotar sort_axis = operator.itemgetter(0) sorted_zip = sorted(zip(x,y_poly_pred), key=sort_axis) x, y_poly_pred = zip(*sorted_zip)  plt.plot(x, y_poly_pred, color='r') plt.show() <pre>Soma dos Erros ao Quadrado (SSE): 602124 \nErro Quadr\u00e1tico M\u00e9dio (MSE): 20070.81\nErro M\u00e9dio Absoluto (MAE): 104.66\nRaiz do Erro Quadr\u00e1tico M\u00e9dio (RMSE): 141.67 \nR2-score: 0.55\n</pre> In\u00a0[23]: Copied! <pre>## Implemente sua solu\u00e7\u00e3o\n</pre> ## Implemente sua solu\u00e7\u00e3o"},{"location":"aulas/IA/lab03/regressao-old.html#objetivos","title":"Objetivos\u00b6","text":"<ul> <li>Apresentar o conceito de Regress\u00e3o</li> <li>Apresentar e utilizar algoritmo de Regress\u00e3o linear</li> <li>Apresentar e utilizar Regress\u00e3o Polinomial</li> <li>Apresentar e discutir a matriz de correla\u00e7\u00e3o</li> <li>Apresentar uma intui\u00e7\u00e3o sobre m\u00e9tricas de avalia\u00e7\u00e3o (MSE, RMSE e $ R\u00b2 $ )</li> </ul>"},{"location":"aulas/IA/lab03/regressao-old.html#comecando","title":"Come\u00e7ando\u00b6","text":"<p>Sabemos que dentro de aprendizado supervisionado vamos trabalhar com dois tipos de problemas:</p> <ul> <li>Classifica\u00e7\u00e3o - (J\u00e1 conhecemos o KNN)</li> <li>Regress\u00e3o - (Objetivo de hoje)</li> </ul>"},{"location":"aulas/IA/lab03/regressao-old.html#uma-intuicao-sobre-problemas-que-envolvem-cada-um-deles","title":"Uma intui\u00e7\u00e3o sobre problemas que envolvem cada um deles:\u00b6","text":"<pre><code>    Classifica\u00e7\u00e3o --&gt; Resultados discretos (categ\u00f3ricos).\n    Regress\u00e3o --&gt; Resultados num\u00e9ricos e cont\u00ednuos.</code></pre>"},{"location":"aulas/IA/lab03/regressao-old.html#regressao-linear","title":"Regress\u00e3o linear\u00b6","text":"<p>\u00c9 uma t\u00e9cnica que consiste em representar um conjunto de dados por meio de uma reta.</p> <pre><code>Na matem\u00e1tica aprendemos que a equa\u00e7\u00e3o de uma reta \u00e9:</code></pre> <p>$$ Y = A + BX \\\\ $$ A e B s\u00e3o constantes que determinam a posi\u00e7\u00e3o e inclina\u00e7\u00e3o da reta. Para cada valor de X temos um Y associado.</p> <pre><code>Em machine learning aprendemos que uma Regress\u00e3o linear \u00e9:</code></pre> <p>$$ Y_{predito} = \\beta_o + \\beta_1X \\\\ $$</p> <p>$ \\beta_o $ e $ \\beta_1 $ s\u00e3o par\u00e2metros que determinam o peso e bias da rede. Para cada entrada $ X $ temos um $ Y_{predito} $ aproximado predito.</p> <p> </p> <p>Essa ideia se estende para mais de um par\u00e2metro independente, mas nesse caso n\u00e3o estamos associando a uma reta e sim a um plano ou hiperplano:</p> <p>$$ Y_{predito} = \\beta_o + \\beta_1X_1 + \\beta_2X_2 + ... + \\beta_nX_n\\\\ $$</p> <p> </p> <p>Em outras palavras, modelos de regress\u00e3o linear s\u00e3o intuitivos, f\u00e1ceis de interpretar e se ajustam aos dados razoavelmente bem em muitos problemas.</p>"},{"location":"aulas/IA/lab03/regressao-old.html#bora-la","title":"Bora l\u00e1!!\u00b6","text":"<p>Vamos juntos realizar um projeto, do come\u00e7o ao fim, usando regress\u00e3o.</p>"},{"location":"aulas/IA/lab03/regressao-old.html#definicao-do-problema","title":"Defini\u00e7\u00e3o do problema\u00b6","text":"<p>Vamos trabalhar com um dataset com informa\u00e7\u00f5es coletadas U.S Census Service (tipo IBGE americano) sobre habita\u00e7\u00e3o na \u00e1rea de Boston Mass.</p>"},{"location":"aulas/IA/lab03/regressao-old.html#faca-o-download-do-dataset-aqui-httpsdrivegooglecomfiled1jdbx09otyosdowzldify4ksapr23befiviewuspsharing","title":"Fa\u00e7a o download do dataset aqui: https://drive.google.com/file/d/1JDbx09otYOsDOWZlDiFY4ksaPr23befi/view?usp=sharing\u00b6","text":"<p>informa\u00e7\u00e3o importante sobre o significado de cada um dos atributos</p> <ol> <li><p>Attribute Information:</p> <ol> <li>CRIM      per capita crime rate by town</li> <li>ZN        proportion of residential land zoned for lots over 25,000 sq.ft.</li> <li>INDUS     proportion of non-retail business acres per town</li> <li>CHAS      Charles River dummy variable (= 1 if tract bounds river; 0 otherwise)</li> <li>NOX       nitric oxides concentration (parts per 10 million)</li> <li>RM        average number of rooms per dwelling</li> <li>AGE       proportion of owner-occupied units built prior to 1940</li> <li>DIS       weighted distances to five Boston employment centres</li> <li>RAD       index of accessibility to radial highways</li> <li>TAX      full-value property-tax rate per $10,000</li> <li>PTRATIO  pupil-teacher ratio by town</li> <li>B        1000(Bk - 0.63)^2 where Bk is the proportion of blacks by town</li> <li>LSTAT    % lower status of the population</li> <li>MEDV     Median value of owner-occupied homes in $1000's</li> </ol> <p>Queremos desenvolver um modelo capaz de predizer o valor de um imovel em Boston.</p> </li> </ol>"},{"location":"aulas/IA/lab03/regressao-old.html#desafio-1","title":"Desafio 1\u00b6","text":"<p>Do ponto de vista de machine learning, que problema \u00e9 esse:</p> <pre><code>Aprendizado supervisionado, n\u00e3o-supervisionado ou aprendizado por refor\u00e7o?</code></pre> <p>R:</p> <pre><code>Classifica\u00e7\u00e3o, regress\u00e3o ou clusteriza\u00e7\u00e3o?</code></pre> <p>R:</p>"},{"location":"aulas/IA/lab03/regressao-old.html#desafio-2","title":"Desafio 2\u00b6","text":"<p>Use os metodos info() e describe() para exibir as informa\u00e7\u00f5es do dataframe e responda:</p> <p>Existe dados faltantes?</p> <p>Qual o tamanho do dataset, quantas linhas e quantas colunas?</p>"},{"location":"aulas/IA/lab03/regressao-old.html#desafio-3","title":"Desafio 3\u00b6","text":"<p>Aplique os m\u00e9todos que achar conveniente (vimos algumas op\u00e7\u00f5es na \u00faltima aula) para visualizar os dados de forma gr\u00e1fica.</p>"},{"location":"aulas/IA/lab03/regressao-old.html#desafio-4","title":"Desafio 4\u00b6","text":"<p>Analisando a matriz de correla\u00e7\u00e3o acima responda:</p> <p>Qual feature possue a maior correla\u00e7\u00e3o positiva com o target?</p> <p>Qual feature possue a maior correla\u00e7\u00e3o negativa com o target?</p>"},{"location":"aulas/IA/lab03/regressao-old.html#pare","title":"PARE!!!\u00b6","text":"<p>A an\u00e1lise feita no desafio 2 e 3 \u00e9 uma das etapas mais importantes. Caso voc\u00ea tenha pulado essa etapa, volte e fa\u00e7a suas an\u00e1lises.</p> <p>Com essa etapa conclu\u00edda, vamos criar um sub-dataset com os atributos que ser\u00e3o utilizados.</p>"},{"location":"aulas/IA/lab03/regressao-old.html#dividindo-os-dados-em-conjunto-de-treinamento-e-de-testes","title":"Dividindo os dados em conjunto de treinamento e de testes\u00b6","text":"<p>Dividir nosso dataset em dois conjuntos de dados.</p> <pre><code>Treinamento - Representa 80% das amostras do conjunto de dados original,\nTeste - com 20% das amostras</code></pre> <p>Vamos escolher aleatoriamente algumas amostras do conjunto original. Isto pode ser feito com Scikit-Learn usando a fun\u00e7\u00e3o train_test_split()</p> <p>scikit-learn Caso ainda n\u00e3o tenha instalado, no terminal digite:</p> <ul> <li>pip install scikit-learn</li> </ul>"},{"location":"aulas/IA/lab03/regressao-old.html#chegou-a-hora-de-aplicar-o-modelo-preditivo","title":"Chegou a hora de aplicar o modelo preditivo\u00b6","text":"<p>Treinar um modelo no python \u00e9 simples se usar o Scikit-Learn. Treinar um modelo no Scikit-Learn \u00e9 simples: basta criar o regressor, e chamar o m\u00e9todo fit().</p> <p>Uma observa\u00e7\u00e3o sobre a sintaxe dos classificadores do <code>scikit-learn</code></p> <ul> <li>O m\u00e9todo <code>fit(X,Y)</code> recebe uma matriz ou dataframe X onde cada linha \u00e9 uma amostra de aprendizado, e um array Y contendo as sa\u00eddas esperadas do classificador, seja na forma de texto ou de inteiros</li> <li>O m\u00e9todo <code>predict(X)</code> recebe uma matriz ou dataframe X onde cada linha \u00e9 uma amostra de teste, retornando um array de classes</li> </ul>"},{"location":"aulas/IA/lab03/regressao-old.html#avaliando-o-modelo-treinado","title":"Avaliando o modelo treinado\u00b6","text":"<p>Vamos colocar alguns valores e ver a predi\u00e7\u00e3o do classificador.</p>"},{"location":"aulas/IA/lab03/regressao-old.html#desafio-5","title":"Desafio 5\u00b6","text":"<p>Refa\u00e7a o notebook substituindo o algoritmo de regress\u00e3o linear por outro algoritmo de regress\u00e3o e compare os resultados obtidos.</p> <p>Sugest\u00e3o de alguns algoritmos de ML para problemas de regress\u00e3o:</p> Nome Vantagem Desvantagem Exemplo sklearn Regress\u00e3o Linear F\u00e1cil de entender e implementar Pode n\u00e3o ser adequado para problemas mais complexos from sklearn.linear_model import LinearRegressionmodel = LinearRegression()model.fit(X, y)prediction = model.predict([X_teste]) \u00c1rvores de decis\u00e3o F\u00e1cil de entender e visualizar Pode levar a overfitting se a \u00e1rvore for muito grande from sklearn.tree import DecisionTreeRegressormodel = DecisionTreeRegressor()model.fit(X, y)prediction = model.predict([X_teste]) Random Forest Mais robusto e geralmente mais preciso do que uma \u00fanica \u00e1rvore de decis\u00e3o Pode ser mais lento e mais dif\u00edcil de ajustar from sklearn.ensemble import RandomForestRegressormodel = RandomForestRegressor(n_estimators=100)model.fit(X, y)prediction = model.predict([X_teste]) Support Vector Regression (SVR) Lida bem com dados multidimensionais e n\u00e3o lineares Pode ser dif\u00edcil de escolher o kernel correto e ajustar os hiperpar\u00e2metros from sklearn.svm import SVRmodel = SVR(kernel='rbf')model.fit(X, y)prediction = model.predict([X_teste]) Gradient Boosting Preciso e lida bem com dados multidimensionais e n\u00e3o lineares Pode ser mais lento e mais dif\u00edcil de ajustar from sklearn.ensemble import GradientBoostingRegressormodel = GradientBoostingRegressor(n_estimators=100)model.fit(X, y)prediction = model.predict([X_teste])"},{"location":"aulas/IA/lab03/regressao-old.html#regressao-polinomial","title":"Regress\u00e3o Polinomial\u00b6","text":"<p>$$ Y = A + BX + C X\u00b2 \\\\ $$ A, B e C s\u00e3o constantes que determinam a posi\u00e7\u00e3o e inclina\u00e7\u00e3o da curva, o 2 indica o grau do polin\u00f4mio. Para cada valor de X temos um Y associado.</p> <pre><code>Em machine learning aprendemos que uma Regress\u00e3o Polinomial \u00e9:</code></pre> <p>$$ Y_{predito} = \\beta_o + \\beta_1X + \\beta_2X\u00b2 \\\\ $$</p> <p>$ \\beta_o $ , $ \\beta_1 $ e $ \\beta_2 $ s\u00e3o par\u00e2metros que determinam o peso da rede. Para cada entrada $ X $ temos um $ Y_{predito} $ aproximado predito.</p> <p>Essa ideia se estende para polin\u00f4mio de graus maiores:</p> <p>$$ Y_{predito} = \\beta_o + \\beta_1X + \\beta_2X\u00b2 + ... + \\beta_nX^n\\\\ $$</p>"},{"location":"aulas/IA/lab03/regressao-old.html#desafio-6","title":"Desafio 6\u00b6","text":"<p>Fa\u00e7a uma fun\u00e7\u00e3o que calcula a regress\u00e3o polinomial (basicamente colocar o codigo acima em uma fun\u00e7\u00e3o), agora fa\u00e7a um c\u00f3digo que chama essa fun\u00e7\u00e3o alterando o grau do polinomio de 2 at\u00e9 10, basicamente um loop for que chama a fun\u00e7\u00e3o criada.</p> <p>An\u00e1lise os resultados obtidos e determine qual o melhor grau polinomio do seu modelo.</p>"},{"location":"aulas/IA/lab03/regressao.html","title":"lab1","text":"In\u00a0[1]: Copied! <pre># Inicializ\u00e7\u00e3o das bibliotecas\n%matplotlib inline\n\nimport pandas as pd\nimport matplotlib.pyplot as plt\n</pre> # Inicializ\u00e7\u00e3o das bibliotecas %matplotlib inline  import pandas as pd import matplotlib.pyplot as plt  <p>O scikit-learn possui diversos dataset em seu banco de dados, um deles \u00e9 o dataset que vamos utilizar hoje.</p> <p>fa\u00e7a o import direto usando sklearn.datasets</p> <p>caso queira, voc\u00ea pode fazer o downlod do dataset direto do site e importar em seu projeto.</p> In\u00a0[2]: Copied! <pre>from sklearn.datasets import fetch_california_housing \n\ncalifornia_dataset = fetch_california_housing()\n\n#para conhecer o que foi importado do dataset \ncalifornia_dataset.keys()\n</pre> from sklearn.datasets import fetch_california_housing   california_dataset = fetch_california_housing()  #para conhecer o que foi importado do dataset  california_dataset.keys()  Out[2]: <pre>dict_keys(['data', 'target', 'frame', 'target_names', 'feature_names', 'DESCR'])</pre> In\u00a0[3]: Copied! <pre># vamos carregar no pandas apenas data com os dados e \"feature_names\" com os nomes dos atributos\n\ndf = pd.DataFrame(california_dataset.data, columns=california_dataset.feature_names)\ndf.head()\n</pre> # vamos carregar no pandas apenas data com os dados e \"feature_names\" com os nomes dos atributos  df = pd.DataFrame(california_dataset.data, columns=california_dataset.feature_names) df.head() Out[3]: MedInc HouseAge AveRooms AveBedrms Population AveOccup Latitude Longitude 0 8.3252 41.0 6.984127 1.023810 322.0 2.555556 37.88 -122.23 1 8.3014 21.0 6.238137 0.971880 2401.0 2.109842 37.86 -122.22 2 7.2574 52.0 8.288136 1.073446 496.0 2.802260 37.85 -122.24 3 5.6431 52.0 5.817352 1.073059 558.0 2.547945 37.85 -122.25 4 3.8462 52.0 6.281853 1.081081 565.0 2.181467 37.85 -122.25 In\u00a0[4]: Copied! <pre>#vamos adicionar mais uma coluna ao nosso dataframe com o target (alvo que vamos fazer a predi\u00e7\u00e3o)\ndf['MEDV'] = california_dataset.target\n</pre> #vamos adicionar mais uma coluna ao nosso dataframe com o target (alvo que vamos fazer a predi\u00e7\u00e3o) df['MEDV'] = california_dataset.target <p>Pronto!! agora o nosso dataset est\u00e1 completamente carregado e podemos come\u00e7ar a an\u00e1lise de dados.</p> In\u00a0[5]: Copied! <pre>df.head()\n</pre> df.head() Out[5]: MedInc HouseAge AveRooms AveBedrms Population AveOccup Latitude Longitude MEDV 0 8.3252 41.0 6.984127 1.023810 322.0 2.555556 37.88 -122.23 4.526 1 8.3014 21.0 6.238137 0.971880 2401.0 2.109842 37.86 -122.22 3.585 2 7.2574 52.0 8.288136 1.073446 496.0 2.802260 37.85 -122.24 3.521 3 5.6431 52.0 5.817352 1.073059 558.0 2.547945 37.85 -122.25 3.413 4 3.8462 52.0 6.281853 1.081081 565.0 2.181467 37.85 -122.25 3.422 In\u00a0[6]: Copied! <pre># Mostra informa\u00e7\u00f5es sobre o dataframe em si\ndf.info()\n</pre> # Mostra informa\u00e7\u00f5es sobre o dataframe em si df.info() <pre>&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 20640 entries, 0 to 20639\nData columns (total 9 columns):\n #   Column      Non-Null Count  Dtype  \n---  ------      --------------  -----  \n 0   MedInc      20640 non-null  float64\n 1   HouseAge    20640 non-null  float64\n 2   AveRooms    20640 non-null  float64\n 3   AveBedrms   20640 non-null  float64\n 4   Population  20640 non-null  float64\n 5   AveOccup    20640 non-null  float64\n 6   Latitude    20640 non-null  float64\n 7   Longitude   20640 non-null  float64\n 8   MEDV        20640 non-null  float64\ndtypes: float64(9)\nmemory usage: 1.4 MB\n</pre> In\u00a0[7]: Copied! <pre>df.describe()\n</pre> df.describe() Out[7]: MedInc HouseAge AveRooms AveBedrms Population AveOccup Latitude Longitude MEDV count 20640.000000 20640.000000 20640.000000 20640.000000 20640.000000 20640.000000 20640.000000 20640.000000 20640.000000 mean 3.870671 28.639486 5.429000 1.096675 1425.476744 3.070655 35.631861 -119.569704 2.068558 std 1.899822 12.585558 2.474173 0.473911 1132.462122 10.386050 2.135952 2.003532 1.153956 min 0.499900 1.000000 0.846154 0.333333 3.000000 0.692308 32.540000 -124.350000 0.149990 25% 2.563400 18.000000 4.440716 1.006079 787.000000 2.429741 33.930000 -121.800000 1.196000 50% 3.534800 29.000000 5.229129 1.048780 1166.000000 2.818116 34.260000 -118.490000 1.797000 75% 4.743250 37.000000 6.052381 1.099526 1725.000000 3.282261 37.710000 -118.010000 2.647250 max 15.000100 52.000000 141.909091 34.066667 35682.000000 1243.333333 41.950000 -114.310000 5.000010 In\u00a0[\u00a0]: Copied! <pre>## Sua resposta e seus gr\u00e1ficos para an\u00e1lisar..\n</pre> ## Sua resposta e seus gr\u00e1ficos para an\u00e1lisar..       In\u00a0[\u00a0]: Copied! <pre># Vamos visualizar a rela\u00e7\u00e3o entre as vari\u00e1veis\n# Longitude e Latitude em rela\u00e7\u00e3o ao pre\u00e7o m\u00e9dio das casas\n\ndf.plot(kind=\"scatter\", x=\"Longitude\",y=\"Latitude\", c=\"MEDV\", cmap=\"jet\", colorbar=True, legend=True, sharex=False, figsize=(10,7), s=df['Population']/100, label=\"population\", alpha=0.7)\nplt.show()\n</pre> # Vamos visualizar a rela\u00e7\u00e3o entre as vari\u00e1veis # Longitude e Latitude em rela\u00e7\u00e3o ao pre\u00e7o m\u00e9dio das casas  df.plot(kind=\"scatter\", x=\"Longitude\",y=\"Latitude\", c=\"MEDV\", cmap=\"jet\", colorbar=True, legend=True, sharex=False, figsize=(10,7), s=df['Population']/100, label=\"population\", alpha=0.7) plt.show()  In\u00a0[8]: Copied! <pre>#Vamos explorar um pouco uma matrix de correla\u00e7\u00e3o\n\nimport seaborn as sns \ncorrelation_matrix = df.corr().round(2)\n\nfig, ax = plt.subplots(figsize=(10,10))    \nsns.heatmap(data=correlation_matrix, annot=True, linewidths=.5, ax=ax)\n</pre> #Vamos explorar um pouco uma matrix de correla\u00e7\u00e3o  import seaborn as sns  correlation_matrix = df.corr().round(2)  fig, ax = plt.subplots(figsize=(10,10))     sns.heatmap(data=correlation_matrix, annot=True, linewidths=.5, ax=ax) Out[8]: <pre>&lt;Axes: &gt;</pre> In\u00a0[23]: Copied! <pre># Vamos treinar nosso modelo com 2 dois atributos independentes\n# para predizer o valor de saida\n# X = df[['MedInc', 'HouseAge']]   ### teste com duas entradas\n\nX = df[['MedInc']]            ### teste com uma entrada\n\n#X = df.drop(['MEDV'], axis=1)     ### teste com todas as entradas\n\nY = df['MEDV']             \nprint(f\"Formato das tabelas de dados {X.shape} e saidas {Y.shape}\")\n</pre> # Vamos treinar nosso modelo com 2 dois atributos independentes # para predizer o valor de saida # X = df[['MedInc', 'HouseAge']]   ### teste com duas entradas  X = df[['MedInc']]            ### teste com uma entrada  #X = df.drop(['MEDV'], axis=1)     ### teste com todas as entradas  Y = df['MEDV']              print(f\"Formato das tabelas de dados {X.shape} e saidas {Y.shape}\") <pre>Formato das tabelas de dados (20640, 1) e saidas (20640,)\n</pre> In\u00a0[24]: Copied! <pre># Separamos 20% para o teste\nfrom sklearn.model_selection import train_test_split\n\nX_treino, X_teste, Y_treino, Y_teste = train_test_split(X, Y, test_size=0.2)\n\nprint(X_treino.shape)\nprint(X_teste.shape)\nprint(Y_treino.shape)\nprint(Y_teste.shape)\n</pre> # Separamos 20% para o teste from sklearn.model_selection import train_test_split  X_treino, X_teste, Y_treino, Y_teste = train_test_split(X, Y, test_size=0.2)  print(X_treino.shape) print(X_teste.shape) print(Y_treino.shape) print(Y_teste.shape) <pre>(16512, 1)\n(4128, 1)\n(16512,)\n(4128,)\n</pre> In\u00a0[32]: Copied! <pre># Importa a biblioteca\nfrom sklearn.linear_model import LinearRegression\n\n\n# Cria o modelo de regress\u00e3o \nlin_model = LinearRegression()\n\n# Cria o modelo de machine learning\nlin_model.fit(X_treino, Y_treino)\n</pre> # Importa a biblioteca from sklearn.linear_model import LinearRegression   # Cria o modelo de regress\u00e3o  lin_model = LinearRegression()  # Cria o modelo de machine learning lin_model.fit(X_treino, Y_treino)    Out[32]: <pre>LinearRegression()</pre>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.LinearRegression?Documentation for LinearRegressioniFitted Parameters fit_intercept\u00a0 True copy_X\u00a0 True tol\u00a0 1e-06 n_jobs\u00a0 None positive\u00a0 False <p>Pronto!! bora testar se esta funcionando....</p> In\u00a0[33]: Copied! <pre># Para obter as previs\u00f5es, basta chamar o m\u00e9todo predict()\ny_teste_predito = lin_model.predict(X_teste)\nprint(\"Predi\u00e7\u00e3o usando regress\u00e3o, retorna valores continuos: {}\".format(y_teste_predito))\n</pre> # Para obter as previs\u00f5es, basta chamar o m\u00e9todo predict() y_teste_predito = lin_model.predict(X_teste) print(\"Predi\u00e7\u00e3o usando regress\u00e3o, retorna valores continuos: {}\".format(y_teste_predito))  <pre>Predi\u00e7\u00e3o usando regress\u00e3o, retorna valores continuos: [1.22201031 1.20622349 0.8628707  ... 1.27463304 1.3798785  1.49131239]\n</pre> In\u00a0[37]: Copied! <pre># vamos avaliar os parametros do nosso modelo\nprint('(A) Intercepto: ', lin_model.intercept_)\nprint('(B) Inclina\u00e7\u00e3o: ', lin_model.coef_)\n\nprint('(C) Equa\u00e7\u00e3o: Y = {} + {} * X'.format(lin_model.intercept_, lin_model.coef_[0]))\n</pre> # vamos avaliar os parametros do nosso modelo print('(A) Intercepto: ', lin_model.intercept_) print('(B) Inclina\u00e7\u00e3o: ', lin_model.coef_)  print('(C) Equa\u00e7\u00e3o: Y = {} + {} * X'.format(lin_model.intercept_, lin_model.coef_[0]))  <pre>(A) Intercepto:  0.432669361569749\n(B) Inclina\u00e7\u00e3o:  [0.42098184]\n(C) Equa\u00e7\u00e3o: Y = 0.432669361569749 + 0.4209818390411239 * X\n</pre> In\u00a0[49]: Copied! <pre>plt.scatter(Y_teste,y_teste_predito, alpha=0.2)\nplt.xlabel('Valor Real')\nplt.ylabel('Valor Predito')\n</pre> plt.scatter(Y_teste,y_teste_predito, alpha=0.2) plt.xlabel('Valor Real') plt.ylabel('Valor Predito') Out[49]: <pre>Text(0, 0.5, 'Valor Predito')</pre> In\u00a0[52]: Copied! <pre>from sklearn.metrics import r2_score, mean_squared_error,mean_absolute_error\nimport numpy as np\n\nprint(\"Soma dos Erros ao Quadrado (SSE): %2.f \" % np.sum((y_teste_predito - Y_teste)**2))\nprint(\"Erro Quadr\u00e1tico M\u00e9dio (MSE): %.2f\" % mean_squared_error(Y_teste, y_teste_predito))\nprint(\"Erro M\u00e9dio Absoluto (MAE): %.2f\" % mean_absolute_error(Y_teste, y_teste_predito))\nprint (\"Raiz do Erro Quadr\u00e1tico M\u00e9dio (RMSE): %.2f \" % np.sqrt(mean_squared_error(Y_teste, y_teste_predito)))\nprint(\"R2-score: %.2f\" % r2_score(Y_teste, y_teste_predito))\n</pre> from sklearn.metrics import r2_score, mean_squared_error,mean_absolute_error import numpy as np  print(\"Soma dos Erros ao Quadrado (SSE): %2.f \" % np.sum((y_teste_predito - Y_teste)**2)) print(\"Erro Quadr\u00e1tico M\u00e9dio (MSE): %.2f\" % mean_squared_error(Y_teste, y_teste_predito)) print(\"Erro M\u00e9dio Absoluto (MAE): %.2f\" % mean_absolute_error(Y_teste, y_teste_predito)) print (\"Raiz do Erro Quadr\u00e1tico M\u00e9dio (RMSE): %.2f \" % np.sqrt(mean_squared_error(Y_teste, y_teste_predito))) print(\"R2-score: %.2f\" % r2_score(Y_teste, y_teste_predito)) <pre>Soma dos Erros ao Quadrado (SSE): 3014 \nErro Quadr\u00e1tico M\u00e9dio (MSE): 0.73\nErro M\u00e9dio Absoluto (MAE): 0.63\nRaiz do Erro Quadr\u00e1tico M\u00e9dio (RMSE): 0.85 \nR2-score: 0.45\n</pre> In\u00a0[\u00a0]: Copied! <pre>## implemente sua sua solu\u00e7\u00e3o....\n\n# testa o random forest\n\nfrom sklearn.ensemble import GradientBoostingRegressor\n\nmodel = GradientBoostingRegressor(n_estimators=100)\nmodel.fit(X_treino, Y_treino)\ny_teste_predito_gb = model.predict(X_teste)\n\n\ny_teste_predito_rf = model.predict(X_teste)\n\nprint(\"Soma dos Erros ao Quadrado (SSE): %2.f \" % np.sum((y_teste_predito_rf - Y_teste)**2))\nprint(\"Erro Quadr\u00e1tico M\u00e9dio (MSE): %.2f\" % mean_squared_error(Y_teste, y_teste_predito_rf))\nprint(\"Erro M\u00e9dio Absoluto (MAE): %.2f\" % mean_absolute_error(Y_teste, y_teste_predito_rf))\nprint (\"Raiz do Erro Quadr\u00e1tico M\u00e9dio (RMSE): %.2f \" % np.sqrt(mean_squared_error(Y_teste, y_teste_predito_rf)))\nprint(\"R2-score: %.2f\" % r2_score(Y_teste, y_teste_predito_rf))\n</pre> ## implemente sua sua solu\u00e7\u00e3o....  # testa o random forest  from sklearn.ensemble import GradientBoostingRegressor  model = GradientBoostingRegressor(n_estimators=100) model.fit(X_treino, Y_treino) y_teste_predito_gb = model.predict(X_teste)   y_teste_predito_rf = model.predict(X_teste)  print(\"Soma dos Erros ao Quadrado (SSE): %2.f \" % np.sum((y_teste_predito_rf - Y_teste)**2)) print(\"Erro Quadr\u00e1tico M\u00e9dio (MSE): %.2f\" % mean_squared_error(Y_teste, y_teste_predito_rf)) print(\"Erro M\u00e9dio Absoluto (MAE): %.2f\" % mean_absolute_error(Y_teste, y_teste_predito_rf)) print (\"Raiz do Erro Quadr\u00e1tico M\u00e9dio (RMSE): %.2f \" % np.sqrt(mean_squared_error(Y_teste, y_teste_predito_rf))) print(\"R2-score: %.2f\" % r2_score(Y_teste, y_teste_predito_rf))  <pre>Soma dos Erros ao Quadrado (SSE): 2914 \nErro Quadr\u00e1tico M\u00e9dio (MSE): 0.71\nErro M\u00e9dio Absoluto (MAE): 0.62\nRaiz do Erro Quadr\u00e1tico M\u00e9dio (RMSE): 0.84 \nR2-score: 0.47\n</pre> In\u00a0[\u00a0]: Copied! <pre>## implemente sua sua solu\u00e7\u00e3o....\n## implemente sua sua solu\u00e7\u00e3o....\n## implemente sua sua solu\u00e7\u00e3o....\n## implemente sua sua solu\u00e7\u00e3o....\n</pre> ## implemente sua sua solu\u00e7\u00e3o.... ## implemente sua sua solu\u00e7\u00e3o.... ## implemente sua sua solu\u00e7\u00e3o.... ## implemente sua sua solu\u00e7\u00e3o...."},{"location":"aulas/IA/lab03/regressao.html#objetivos","title":"Objetivos\u00b6","text":"<ul> <li>Apresentar o conceito de Regress\u00e3o</li> <li>Apresentar e utilizar algoritmo de Regress\u00e3o linear</li> <li>Apresentar e utilizar Regress\u00e3o Polinomial</li> <li>Apresentar e discutir a matriz de correla\u00e7\u00e3o</li> <li>Apresentar uma intui\u00e7\u00e3o sobre m\u00e9tricas de avalia\u00e7\u00e3o (MSE, RMSE e $ R\u00b2 $ )</li> </ul>"},{"location":"aulas/IA/lab03/regressao.html#comecando","title":"Come\u00e7ando\u00b6","text":"<p>Sabemos que dentro de aprendizado supervisionado vamos trabalhar com dois tipos de problemas:</p> <ul> <li>Classifica\u00e7\u00e3o - (J\u00e1 conhecemos o KNN)</li> <li>Regress\u00e3o - (Objetivo de hoje)</li> </ul>"},{"location":"aulas/IA/lab03/regressao.html#uma-intuicao-sobre-problemas-que-envolvem-cada-um-deles","title":"Uma intui\u00e7\u00e3o sobre problemas que envolvem cada um deles:\u00b6","text":"<pre><code>    Classifica\u00e7\u00e3o --&gt; Resultados discretos (categ\u00f3ricos).\n    Regress\u00e3o --&gt; Resultados num\u00e9ricos e cont\u00ednuos.</code></pre>"},{"location":"aulas/IA/lab03/regressao.html#regressao-linear","title":"Regress\u00e3o linear\u00b6","text":"<p>\u00c9 uma t\u00e9cnica que consiste em representar um conjunto de dados por meio de uma reta.</p> <pre><code>Na matem\u00e1tica aprendemos que a equa\u00e7\u00e3o de uma reta \u00e9:</code></pre> <p>$$ Y = A + BX \\\\ $$ A e B s\u00e3o constantes que determinam a posi\u00e7\u00e3o e inclina\u00e7\u00e3o da reta. Para cada valor de X temos um Y associado.</p> <pre><code>Em machine learning aprendemos que uma Regress\u00e3o linear \u00e9:</code></pre> <p>$$ Y_{predito} = \\beta_o + \\beta_1X \\\\ $$</p> <p>$ \\beta_o $ e $ \\beta_1 $ s\u00e3o par\u00e2metros que determinam o peso e bias da rede. Para cada entrada $ X $ temos um $ Y_{predito} $ aproximado predito.</p> <p></p> <p>Essa ideia se estende para mais de um par\u00e2metro independente, mas nesse caso n\u00e3o estamos associando a uma reta e sim a um plano ou hiperplano:</p> <p>$$ Y_{predito} = \\beta_o + \\beta_1X_1 + \\beta_2X_2 + ... + \\beta_nX_n\\\\ $$</p> <p> </p> <p>Em outras palavras, modelos de regress\u00e3o linear s\u00e3o intuitivos, f\u00e1ceis de interpretar e se ajustam aos dados razoavelmente bem em muitos problemas.</p>"},{"location":"aulas/IA/lab03/regressao.html#bora-la","title":"Bora l\u00e1!!\u00b6","text":"<p>Vamos juntos realizar um projeto, do come\u00e7o ao fim, usando regress\u00e3o.</p>"},{"location":"aulas/IA/lab03/regressao.html#definicao-do-problema","title":"Defini\u00e7\u00e3o do problema\u00b6","text":""},{"location":"aulas/IA/lab03/regressao.html#preco-de-casas","title":"Pre\u00e7o de Casas\u00b6","text":"<ul> <li>Entrada: Caracter\u00edsticas da casa (renda da regi\u00e3o, idade, quartos...)</li> <li>Sa\u00edda: Pre\u00e7o da casa (valor num\u00e9rico)</li> </ul>"},{"location":"aulas/IA/lab03/regressao.html#desafio-1","title":"Desafio 1\u00b6","text":"<p>Do ponto de vista de machine learning, que problema \u00e9 esse:</p> <pre><code>Aprendizado supervisionado, n\u00e3o-supervisionado ou aprendizado por refor\u00e7o?</code></pre> <p>R:</p> <pre><code>Classifica\u00e7\u00e3o, regress\u00e3o ou clusteriza\u00e7\u00e3o?</code></pre> <p>R:</p>"},{"location":"aulas/IA/lab03/regressao.html#o-que-significa-cada-coluna","title":"O que significa cada coluna?\u00b6","text":"Coluna Significado Exemplo MedInc Renda m\u00e9dia da regi\u00e3o 8.32 (dezenas de milhares) HouseAge Idade m\u00e9dia das casas 41.0 anos AveRooms N\u00famero m\u00e9dio de quartos 6.98 AveBedrms Quartos de dormir m\u00e9dios 1.02 Population Popula\u00e7\u00e3o da \u00e1rea 322 pessoas AveOccup Ocupa\u00e7\u00e3o m\u00e9dia 2.55 pessoas/casa Latitude Coordenada geogr\u00e1fica 37.88 Longitude Coordenada geogr\u00e1fica -122.23 MEDV Pre\u00e7o m\u00e9dio das casas 4.526 (centenas de milhares) <p>Importante: O pre\u00e7o est\u00e1 em centenas de milhares. 4.526 = $452,600</p>"},{"location":"aulas/IA/lab03/regressao.html#desafio-2","title":"Desafio 2\u00b6","text":"<p>Use os metodos info() e describe() para exibir as informa\u00e7\u00f5es do dataframe e responda:</p> <p>Existe dados faltantes?</p> <p>Qual o tamanho do dataset, quantas linhas e quantas colunas?</p>"},{"location":"aulas/IA/lab03/regressao.html#desafio-3","title":"Desafio 3\u00b6","text":"<p>Aplique os m\u00e9todos que achar conveniente (vimos algumas op\u00e7\u00f5es na \u00faltima aula) para visualizar os dados de forma gr\u00e1fica.</p>"},{"location":"aulas/IA/lab03/regressao.html#pare","title":"PARE!!!\u00b6","text":"<p>A an\u00e1lise feita no desafio 2 e 3 \u00e9 uma das etapas mais importantes. Caso voc\u00ea tenha pulado essa etapa, volte e fa\u00e7a suas an\u00e1lises.</p> <p>Com essa etapa conclu\u00edda, vamos criar um sub-dataset com os atributos que ser\u00e3o utilizados.</p>"},{"location":"aulas/IA/lab03/regressao.html#dividindo-os-dados-em-conjunto-de-treinamento-e-de-testes","title":"Dividindo os dados em conjunto de treinamento e de testes\u00b6","text":"<p>Dividir nosso dataset em dois conjuntos de dados.</p> <pre><code>Treinamento - Representa 80% das amostras do conjunto de dados original,\nTeste - com 20% das amostras</code></pre> <p>Vamos escolher aleatoriamente algumas amostras do conjunto original. Isto pode ser feito com Scikit-Learn usando a fun\u00e7\u00e3o train_test_split()</p> <p>scikit-learn Caso ainda n\u00e3o tenha instalado, no terminal digite:</p> <ul> <li>pip install scikit-learn</li> </ul>"},{"location":"aulas/IA/lab03/regressao.html#treinando-nosso-primeiro-modelo","title":"Treinando Nosso Primeiro Modelo\u00b6","text":"<p>Treinar um modelo no python \u00e9 simples se usar o Scikit-Learn.</p> <p>Treinar um modelo no Scikit-Learn \u00e9 simples: basta criar o regressor, e chamar o m\u00e9todo fit().</p> <p>Uma observa\u00e7\u00e3o sobre a sintaxe dos classificadores do <code>scikit-learn</code></p> <ul> <li><p>O m\u00e9todo <code>fit(X,Y)</code> recebe uma matriz ou dataframe X onde cada linha \u00e9 uma amostra de aprendizado, e um array Y contendo as sa\u00eddas esperadas do classificador, seja na forma de texto ou de inteiros</p> </li> <li><p>O m\u00e9todo <code>predict(X)</code> recebe uma matriz ou dataframe X onde cada linha \u00e9 uma amostra de teste, retornando um array de classes</p> </li> </ul>"},{"location":"aulas/IA/lab03/regressao.html#avaliando-o-modelo-treinado","title":"Avaliando o modelo treinado\u00b6","text":"<p>Vamos colocar alguns valores e ver a predi\u00e7\u00e3o do classificador.</p>"},{"location":"aulas/IA/lab03/regressao.html#algoritmos-de-ml-para-regressao","title":"Algoritmos de ML para regress\u00e3o\u00b6","text":"<p>Sugest\u00e3o de alguns algoritmos de ML para problemas de regress\u00e3o:</p> Nome Vantagem Desvantagem Exemplo sklearn Regress\u00e3o Linear F\u00e1cil de entender e implementar Pode n\u00e3o ser adequado para problemas mais complexos from sklearn.linear_model import LinearRegressionmodel = LinearRegression()model.fit(X, y)prediction = model.predict([X_teste]) \u00c1rvores de decis\u00e3o F\u00e1cil de entender e visualizar Pode levar a overfitting se a \u00e1rvore for muito grande from sklearn.tree import DecisionTreeRegressormodel = DecisionTreeRegressor()model.fit(X, y)prediction = model.predict([X_teste]) Random Forest Mais robusto e geralmente mais preciso do que uma \u00fanica \u00e1rvore de decis\u00e3o Pode ser mais lento e mais dif\u00edcil de ajustar from sklearn.ensemble import RandomForestRegressormodel = RandomForestRegressor(n_estimators=100)model.fit(X, y)prediction = model.predict([X_teste]) Support Vector Regression (SVR) Lida bem com dados multidimensionais e n\u00e3o lineares Pode ser dif\u00edcil de escolher o kernel correto e ajustar os hiperpar\u00e2metros from sklearn.svm import SVRmodel = SVR(kernel='rbf')model.fit(X, y)prediction = model.predict([X_teste]) Gradient Boosting Preciso e lida bem com dados multidimensionais e n\u00e3o lineares Pode ser mais lento e mais dif\u00edcil de ajustar from sklearn.ensemble import GradientBoostingRegressormodel = GradientBoostingRegressor(n_estimators=100)model.fit(X, y)prediction = model.predict([X_teste])"},{"location":"aulas/IA/lab03/regressao.html#exercicio-1-experimentar-outras-variaveis","title":"Exerc\u00edcio 1: Experimentar outras vari\u00e1veis\u00b6","text":"<ol> <li>Tente usar apenas <code>HouseAge</code> para predizer pre\u00e7o</li> <li>Compare o R\u00b2 com o modelo que usa <code>MedInc</code></li> <li>Qual vari\u00e1vel sozinha \u00e9 melhor preditora?</li> </ol>"},{"location":"aulas/IA/lab03/regressao.html#exercicio-2-modelo-com-todas-as-variaveis","title":"Exerc\u00edcio 2: Modelo com todas as vari\u00e1veis\u00b6","text":"<ol> <li>Crie um modelo usando todas as 8 vari\u00e1veis</li> <li>Compare com o modelo de 4 vari\u00e1veis</li> <li>Houve melhoria significativa?</li> </ol>"},{"location":"aulas/IA/lab03/regressao2.html","title":"lab2","text":"In\u00a0[55]: Copied! <pre>import operator\n\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n\n# importa feature polinomial\nfrom sklearn.preprocessing import PolynomialFeatures\n\n#####----------- vou gerar alguns numeros aleat\u00f3rios ------------------\n\n#gerando numeros aleatorios, apenas para este exemplo\nnp.random.seed(42)\nx = 2 - 3 * np.random.normal(0, 1, 30)\ny = x - 3 * (x ** 2) + 0.8 * (x ** 3)+ 0.2 * (x ** 4) + np.random.normal(-20, 20, 30)\n\n# ajuste nos dados, pois estamos trabalhando com a numpy \nx = x[:, np.newaxis]\ny = y[:, np.newaxis]\n####---------------pronto j\u00e1 temos os dados para treinar -------------\n\n\n#----\u00c9 aqui que o seu c\u00f3digo muda ------------------------------------\n\n# Chama a fun\u00e7\u00e3o definindo o grau do polinomio e aplica o modelo\n\ngrau_poly = 1\npolynomial_features= PolynomialFeatures(degree = grau_poly)\nx_poly = polynomial_features.fit_transform(x)\n\n#----Pronto agora \u00e9 tudo como era antes, com regress\u00e3o linear\n\n\nmodel = LinearRegression()\nmodel.fit(x_poly, y)\ny_poly_pred = model.predict(x_poly)\n\n# M\u00e9trica de avalia\u00e7\u00e3o do modelo\nprint(\"Soma dos Erros ao Quadrado (SSE): %2.f \" % np.sum((y_poly_pred - y)**2))\nprint(\"Erro Quadr\u00e1tico M\u00e9dio (MSE): %.2f\" % mean_squared_error(y,y_poly_pred))\nprint(\"Erro M\u00e9dio Absoluto (MAE): %.2f\" % mean_absolute_error(y, y_poly_pred))\nprint (\"Raiz do Erro Quadr\u00e1tico M\u00e9dio (RMSE): %.2f \" % np.sqrt(mean_squared_error(y, y_poly_pred)))\nprint(\"R2-score: %.2f\" % r2_score(y,y_poly_pred) )\n\n\nplt.scatter(x, y, s=10)\n# ordena os valores de x antes de plotar\nsort_axis = operator.itemgetter(0)\nsorted_zip = sorted(zip(x,y_poly_pred), key=sort_axis)\nx, y_poly_pred = zip(*sorted_zip)\n\nplt.plot(x, y_poly_pred, color='r')\nplt.show()\n</pre> import operator  import numpy as np import matplotlib.pyplot as plt  from sklearn.linear_model import LinearRegression from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error  # importa feature polinomial from sklearn.preprocessing import PolynomialFeatures  #####----------- vou gerar alguns numeros aleat\u00f3rios ------------------  #gerando numeros aleatorios, apenas para este exemplo np.random.seed(42) x = 2 - 3 * np.random.normal(0, 1, 30) y = x - 3 * (x ** 2) + 0.8 * (x ** 3)+ 0.2 * (x ** 4) + np.random.normal(-20, 20, 30)  # ajuste nos dados, pois estamos trabalhando com a numpy  x = x[:, np.newaxis] y = y[:, np.newaxis] ####---------------pronto j\u00e1 temos os dados para treinar -------------   #----\u00c9 aqui que o seu c\u00f3digo muda ------------------------------------  # Chama a fun\u00e7\u00e3o definindo o grau do polinomio e aplica o modelo  grau_poly = 1 polynomial_features= PolynomialFeatures(degree = grau_poly) x_poly = polynomial_features.fit_transform(x)  #----Pronto agora \u00e9 tudo como era antes, com regress\u00e3o linear   model = LinearRegression() model.fit(x_poly, y) y_poly_pred = model.predict(x_poly)  # M\u00e9trica de avalia\u00e7\u00e3o do modelo print(\"Soma dos Erros ao Quadrado (SSE): %2.f \" % np.sum((y_poly_pred - y)**2)) print(\"Erro Quadr\u00e1tico M\u00e9dio (MSE): %.2f\" % mean_squared_error(y,y_poly_pred)) print(\"Erro M\u00e9dio Absoluto (MAE): %.2f\" % mean_absolute_error(y, y_poly_pred)) print (\"Raiz do Erro Quadr\u00e1tico M\u00e9dio (RMSE): %.2f \" % np.sqrt(mean_squared_error(y, y_poly_pred))) print(\"R2-score: %.2f\" % r2_score(y,y_poly_pred) )   plt.scatter(x, y, s=10) # ordena os valores de x antes de plotar sort_axis = operator.itemgetter(0) sorted_zip = sorted(zip(x,y_poly_pred), key=sort_axis) x, y_poly_pred = zip(*sorted_zip)  plt.plot(x, y_poly_pred, color='r') plt.show() <pre>Soma dos Erros ao Quadrado (SSE): 602124 \nErro Quadr\u00e1tico M\u00e9dio (MSE): 20070.81\nErro M\u00e9dio Absoluto (MAE): 104.66\nRaiz do Erro Quadr\u00e1tico M\u00e9dio (RMSE): 141.67 \nR2-score: 0.55\n</pre> In\u00a0[\u00a0]: Copied! <pre># instala\u00e7\u00e3o do XGBoost\n!pip install xgboost\n</pre> # instala\u00e7\u00e3o do XGBoost !pip install xgboost <pre>Collecting xgboost\n  Downloading xgboost-3.0.4-py3-none-macosx_12_0_arm64.whl.metadata (2.1 kB)\nRequirement already satisfied: numpy in /Users/arnaldoalvesvianajunior/DisruptiveArchitectures/.venv/lib/python3.12/site-packages (from xgboost) (2.3.2)\nRequirement already satisfied: scipy in /Users/arnaldoalvesvianajunior/DisruptiveArchitectures/.venv/lib/python3.12/site-packages (from xgboost) (1.16.1)\nDownloading xgboost-3.0.4-py3-none-macosx_12_0_arm64.whl (2.0 MB)\n   \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 2.0/2.0 MB 7.6 MB/s  0:00:00 eta 0:00:01\nInstalling collected packages: xgboost\nSuccessfully installed xgboost-3.0.4\n</pre> In\u00a0[5]: Copied! <pre># Importar bibliotecas\nfrom sklearn.datasets import fetch_california_housing\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import r2_score, mean_squared_error,mean_absolute_error\n\nfrom xgboost import XGBRegressor\n\n# 1. Carregar o dataset novamente, j\u00e1 fizemos isso antes\ndata = fetch_california_housing()\nX, y = data.data, data.target\n\n\n# 2. Dividir os dados em treino (80%) e teste (20%)\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# 3. Criar e treinar o modelo XGBoost\nmodel = XGBRegressor(\n    n_estimators=100,      # N\u00famero de \u00e1rvores\n    learning_rate=0.1,     # Taxa de aprendizado\n    max_depth=6,           # Profundidade m\u00e1xima de cada \u00e1rvore\n    random_state=42        # Para reprodutibilidade\n)\nmodel.fit(X_train, y_train)\n\n\n# 4. Avaliar no conjunto de teste\n\ny_teste_predito = model.predict(X_test)\n\nprint(\"Soma dos Erros ao Quadrado (SSE): %2.f \" % np.sum((y_teste_predito - y_test)**2))\nprint(\"Erro Quadr\u00e1tico M\u00e9dio (MSE): %.2f\" % mean_squared_error(y_test, y_teste_predito))\nprint(\"Erro M\u00e9dio Absoluto (MAE): %.2f\" % mean_absolute_error(y_test, y_teste_predito))\nprint (\"Raiz do Erro Quadr\u00e1tico M\u00e9dio (RMSE): %.2f \" % np.sqrt(mean_squared_error(y_test, y_teste_predito)))\nprint(\"R2-score: %.2f\" % r2_score(y_test, y_teste_predito))\n\n\n# 5. Exibir a import\u00e2ncia das features\nimportances = model.feature_importances_\nfeature_names = data.feature_names\nfor name, importance in zip(feature_names, importances):\n    print(f\"Atributo: {name}, Import\u00e2ncia: {importance:.3f}\")\n</pre> # Importar bibliotecas from sklearn.datasets import fetch_california_housing from sklearn.model_selection import train_test_split from sklearn.metrics import r2_score, mean_squared_error,mean_absolute_error  from xgboost import XGBRegressor  # 1. Carregar o dataset novamente, j\u00e1 fizemos isso antes data = fetch_california_housing() X, y = data.data, data.target   # 2. Dividir os dados em treino (80%) e teste (20%) X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)  # 3. Criar e treinar o modelo XGBoost model = XGBRegressor(     n_estimators=100,      # N\u00famero de \u00e1rvores     learning_rate=0.1,     # Taxa de aprendizado     max_depth=6,           # Profundidade m\u00e1xima de cada \u00e1rvore     random_state=42        # Para reprodutibilidade ) model.fit(X_train, y_train)   # 4. Avaliar no conjunto de teste  y_teste_predito = model.predict(X_test)  print(\"Soma dos Erros ao Quadrado (SSE): %2.f \" % np.sum((y_teste_predito - y_test)**2)) print(\"Erro Quadr\u00e1tico M\u00e9dio (MSE): %.2f\" % mean_squared_error(y_test, y_teste_predito)) print(\"Erro M\u00e9dio Absoluto (MAE): %.2f\" % mean_absolute_error(y_test, y_teste_predito)) print (\"Raiz do Erro Quadr\u00e1tico M\u00e9dio (RMSE): %.2f \" % np.sqrt(mean_squared_error(y_test, y_teste_predito))) print(\"R2-score: %.2f\" % r2_score(y_test, y_teste_predito))   # 5. Exibir a import\u00e2ncia das features importances = model.feature_importances_ feature_names = data.feature_names for name, importance in zip(feature_names, importances):     print(f\"Atributo: {name}, Import\u00e2ncia: {importance:.3f}\") <pre>Soma dos Erros ao Quadrado (SSE): 938 \nErro Quadr\u00e1tico M\u00e9dio (MSE): 0.23\nErro M\u00e9dio Absoluto (MAE): 0.32\nRaiz do Erro Quadr\u00e1tico M\u00e9dio (RMSE): 0.48 \nR2-score: 0.83\nAtributo: MedInc, Import\u00e2ncia: 0.546\nAtributo: HouseAge, Import\u00e2ncia: 0.065\nAtributo: AveRooms, Import\u00e2ncia: 0.039\nAtributo: AveBedrms, Import\u00e2ncia: 0.021\nAtributo: Population, Import\u00e2ncia: 0.021\nAtributo: AveOccup, Import\u00e2ncia: 0.149\nAtributo: Latitude, Import\u00e2ncia: 0.074\nAtributo: Longitude, Import\u00e2ncia: 0.084\n</pre>"},{"location":"aulas/IA/lab03/regressao2.html#objetivo-da-aula","title":"Objetivo da Aula\u00b6","text":"<ul> <li>Apresentar e usar a regress\u00e3o polinomial</li> <li>Entender o funcionamento do XGBoost (eXtreme Gradient Boosting) e sua aplica\u00e7\u00e3o em problemas de regress\u00e3o.</li> <li>Aplicar o XGBoost para prever o valor.</li> <li>Aprender boas pr\u00e1ticas de pr\u00e9-processamento, treinamento e avalia\u00e7\u00e3o de modelos de machine learning.</li> </ul>"},{"location":"aulas/IA/lab03/regressao2.html#regressao-polinomial","title":"Regress\u00e3o Polinomial\u00b6","text":"<p>$$ Y = A + BX + C X\u00b2 \\\\ $$ A, B e C s\u00e3o constantes que determinam a posi\u00e7\u00e3o e inclina\u00e7\u00e3o da curva, o 2 indica o grau do polin\u00f4mio. Para cada valor de X temos um Y associado.</p> <pre><code>Em machine learning aprendemos que uma Regress\u00e3o Polinomial \u00e9:</code></pre> <p>$$ Y_{predito} = \\beta_o + \\beta_1X + \\beta_2X\u00b2 \\\\ $$</p> <p>$ \\beta_o $ , $ \\beta_1 $ e $ \\beta_2 $ s\u00e3o par\u00e2metros que determinam o peso da rede. Para cada entrada $ X $ temos um $ Y_{predito} $ aproximado predito.</p> <p>Essa ideia se estende para polin\u00f4mio de graus maiores:</p> <p>$$ Y_{predito} = \\beta_o + \\beta_1X + \\beta_2X\u00b2 + ... + \\beta_nX^n\\\\ $$</p>"},{"location":"aulas/IA/lab03/regressao2.html#xgboost","title":"XGBoost\u00b6","text":"<p>O XGBoost (eXtreme Gradient Boosting) \u00e9 um algoritmo de machine learning baseado em gradient boosting, amplamente utilizado em tarefas de regress\u00e3o, classifica\u00e7\u00e3o e ranqueamento. Ele \u00e9 conhecido por sua alta performance, escalabilidade e capacidade de lidar com datasets complexos.</p>"},{"location":"aulas/IA/lab03/regressao2.html#conceitos-fundamentais","title":"Conceitos Fundamentais\u00b6","text":"<ol> <li>Boosting:</li> </ol> <ul> <li>Boosting \u00e9 uma t\u00e9cnica de ensemble que combina v\u00e1rios modelos fracos (geralmente \u00e1rvores de decis\u00e3o) para criar um modelo forte.</li> <li>No boosting, os modelos s\u00e3o treinados sequencialmente, onde cada modelo tenta corrigir os erros dos anteriores, dando mais peso \u00e0s inst\u00e2ncias mal previstas.</li> </ul> <ol> <li>Gradient Boosting:</li> </ol> <ul> <li>O gradient boosting usa o gradiente descendente para minimizar uma fun\u00e7\u00e3o de perda (ex.: erro quadr\u00e1tico m\u00e9dio para regress\u00e3o).</li> <li>Cada \u00e1rvore \u00e9 ajustada para prever o res\u00edduo (erro) do modelo anterior, reduzindo gradualmente o erro total.</li> </ul> <ol> <li>Caracter\u00edsticas do XGBoost:</li> </ol> <ul> <li>Regulariza\u00e7\u00e3o: Inclui penalidades L1 (Lasso) e L2 (Ridge) para evitar overfitting, tornando o modelo mais robusto.</li> <li>Paralelismo: Otimiza o treinamento usando m\u00faltiplos n\u00facleos de CPU, tornando-o r\u00e1pido mesmo em datasets grandes.</li> <li>Tratamento de Missing Values: Lida automaticamente com valores ausentes, decidindo a melhor dire\u00e7\u00e3o para cada n\u00f3 da \u00e1rvore.</li> <li>Import\u00e2ncia de Features: Fornece m\u00e9tricas para avaliar a relev\u00e2ncia de cada vari\u00e1vel no modelo.</li> <li>Flexibilidade: Suporta diferentes fun\u00e7\u00f5es de perda e pode ser ajustado com hiperpar\u00e2metros como taxa de aprendizado, n\u00famero de \u00e1rvores e profundidade.</li> </ul>"},{"location":"aulas/IA/lab03/regressao2.html#funcionamento","title":"Funcionamento\u00b6","text":"<ol> <li>Inicializa\u00e7\u00e3o: Come\u00e7a com uma previs\u00e3o inicial (ex.: m\u00e9dia dos valores alvo para regress\u00e3o).</li> <li>Constru\u00e7\u00e3o de \u00c1rvores:</li> </ol> <ul> <li>Cada \u00e1rvore \u00e9 constru\u00edda para prever os res\u00edduos (erros) do modelo anterior.</li> <li>A fun\u00e7\u00e3o de perda (ex.: MSE) \u00e9 otimizada usando gradientes e hessianos (derivadas de primeira e segunda ordem).</li> </ul> <ol> <li>Atualiza\u00e7\u00e3o do Modelo: As previs\u00f5es s\u00e3o atualizadas somando as contribui\u00e7\u00f5es de cada \u00e1rvore, ponderadas por uma taxa de aprendizado.</li> <li>Regulariza\u00e7\u00e3o: Penalidades s\u00e3o aplicadas para limitar a complexidade das \u00e1rvores, evitando overfitting.</li> </ol>"},{"location":"aulas/IA/lab04/dicasDePreprocessamento.html","title":"Pr\u00e9-processamento","text":"<p>Exemplo: Vamos criar um lista com 3 atributos e vamos normalizar.</p> <ul> <li>Atributos:<ul> <li>altura (cm)</li> <li>massa (Kg)</li> <li>idade (anos)</li> </ul> </li> </ul> In\u00a0[1]: Copied! <pre>import numpy as np\nimport pandas as pd\n\ncols = ['altura (cm)', 'massa (kg)', 'idade (anos)']\ndf = pd.DataFrame(np.array([\n                            [170, 90, 20], # altura (cm), massa (Kg), idade (anos)\n                            [168, 55, 33],\n                            [173, 84, 57],\n                            [189, 98, 41]\n                        ]),columns=cols)\n\ndf.head()                  \n</pre> import numpy as np import pandas as pd  cols = ['altura (cm)', 'massa (kg)', 'idade (anos)'] df = pd.DataFrame(np.array([                             [170, 90, 20], # altura (cm), massa (Kg), idade (anos)                             [168, 55, 33],                             [173, 84, 57],                             [189, 98, 41]                         ]),columns=cols)  df.head()                   Out[1]: altura (cm) massa (kg) idade (anos) 0 170 90 20 1 168 55 33 2 173 84 57 3 189 98 41 <p>No nosso exemplo vamos usar o m\u00e9todo min-m\u00e1x:</p> <p>$$ valor_{normalizado}=\\dfrac{valor - min_{valores}}{(max_{valores} - min_{valores})}(max_{feature_range} - min_{feature_range}) + min_{feature_range} $$</p> In\u00a0[2]: Copied! <pre>from sklearn.preprocessing import MinMaxScaler\n\n#Cria o objeto da classe MinMaxScaler\nscaler_minmax = MinMaxScaler(feature_range=(0,1))\n\nscaled_data = scaler_minmax.fit_transform(df[cols])\n\nscaled_data\n</pre> from sklearn.preprocessing import MinMaxScaler  #Cria o objeto da classe MinMaxScaler scaler_minmax = MinMaxScaler(feature_range=(0,1))  scaled_data = scaler_minmax.fit_transform(df[cols])  scaled_data Out[2]: <pre>array([[0.0952381 , 0.81395349, 0.        ],\n       [0.        , 0.        , 0.35135135],\n       [0.23809524, 0.6744186 , 1.        ],\n       [1.        , 1.        , 0.56756757]])</pre> <p>Agora que os dados j\u00e1 est\u00e3o normalizados, podemos aplicar est\u00e1 transforma\u00e7\u00e3o em novos dados inseridos pelos usuario. Para isso, basta usar a fun\u00e7\u00e3o <code>transform()</code> do scaler j\u00e1 treinado.</p> In\u00a0[3]: Copied! <pre># Dados definidos pelo usu\u00e1rio\nnovos_dados = pd.DataFrame({'altura (cm)': [180, 90, 30],\n                            'massa (kg)': [185, 80, 40],\n                            'idade (anos)': [165, 57, 25]})\n# Aplicando o scaler nos novos dados\nscaled_novos_dados = scaler_minmax.transform(novos_dados)\n\nprint(scaled_novos_dados)\n</pre> # Dados definidos pelo usu\u00e1rio novos_dados = pd.DataFrame({'altura (cm)': [180, 90, 30],                             'massa (kg)': [185, 80, 40],                             'idade (anos)': [165, 57, 25]}) # Aplicando o scaler nos novos dados scaled_novos_dados = scaler_minmax.transform(novos_dados)  print(scaled_novos_dados) <pre>[[ 0.57142857  3.02325581  3.91891892]\n [-3.71428571  0.58139535  1.        ]\n [-6.57142857 -0.34883721  0.13513514]]\n</pre> <p>Outra t\u00e9cnica muito utilzada \u00e9 o <code>StandardScaler</code> que normaliza valores com m\u00e9dia 0 e desvio padr\u00e3o igual a 1.</p> In\u00a0[4]: Copied! <pre>cols = ['altura (cm)', 'massa (kg)', 'idade (anos)']\ndf = pd.DataFrame(np.array([\n                            [170, 90, 20], # altura (cm), massa (Kg), idade (anos)\n                            [168, 55, 33],\n                            [173, 84, 57],\n                            [189, 98, 41]\n                        ]),columns=cols)\n\ndf.head() \n\nfrom sklearn.preprocessing import StandardScaler\n\n#Cria o objeto da classe standardScaler\nscaler_standard = StandardScaler()\n\nscaled_data = scaler_standard.fit_transform(df[cols])\n\nscaled_data\n</pre> cols = ['altura (cm)', 'massa (kg)', 'idade (anos)'] df = pd.DataFrame(np.array([                             [170, 90, 20], # altura (cm), massa (Kg), idade (anos)                             [168, 55, 33],                             [173, 84, 57],                             [189, 98, 41]                         ]),columns=cols)  df.head()   from sklearn.preprocessing import StandardScaler  #Cria o objeto da classe standardScaler scaler_standard = StandardScaler()  scaled_data = scaler_standard.fit_transform(df[cols])  scaled_data Out[4]: <pre>array([[-0.60412209,  0.50853555, -1.32415683],\n       [-0.84577093, -1.648888  , -0.35435183],\n       [-0.24164884,  0.13869151,  1.4360574 ],\n       [ 1.69154186,  1.00166093,  0.24245125]])</pre> <p>Da mesma forma que o anterior, podemos aplicar est\u00e1 transforma\u00e7\u00e3o em novos dados inseridos pelos usuario. Para isso, basta usar a fun\u00e7\u00e3o transform() do scaler j\u00e1 treinado.</p> In\u00a0[5]: Copied! <pre># Dados definidos pelo usu\u00e1rio\nnovos_dados2 = pd.DataFrame({'altura (cm)': [180, 90, 30],\n                            'massa (kg)': [185, 80, 40],\n                            'idade (anos)': [165, 57, 25]})\n# Aplicando o scaler nos novos dados\nscaled_novos_dados2 = scaler_standard.transform(novos_dados2)\n\nprint(scaled_novos_dados2)\n</pre> # Dados definidos pelo usu\u00e1rio novos_dados2 = pd.DataFrame({'altura (cm)': [180, 90, 30],                             'massa (kg)': [185, 80, 40],                             'idade (anos)': [165, 57, 25]}) # Aplicando o scaler nos novos dados scaled_novos_dados2 = scaler_standard.transform(novos_dados2)  print(scaled_novos_dados2) <pre>[[  0.60412209   6.36439947   9.49289895]\n [-10.27007559  -0.10787118   1.4360574 ]\n [-17.51954071  -2.57349809  -0.9511549 ]]\n</pre> In\u00a0[6]: Copied! <pre># transforma\u00e7\u00f5es diferentes em no mesmo dataset\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.preprocessing import StandardScaler\n\n\ncols = ['altura', 'massa', 'idade']\ndf = pd.DataFrame(np.array([\n                            [170, 90, 20], # altura (cm), massa (Kg), idade (anos)\n                            [168, 55, 33],\n                            [173, 84, 57],\n                            [189, 98, 41]\n                        ]),columns=cols)\n\n#Cria o objeto da classe standardScaler e MinMaxScaler\nscaler_standard = StandardScaler()\nscaler_minmax = MinMaxScaler(feature_range=(0,1))\n\n# Aplica as transforma\u00e7\u00f5es\nscaled_standard = scaler_standard.fit_transform(df[['altura']])\nscaled_minmax = scaler_minmax.fit_transform(df[['massa']])\n\n# atualiza o valor e mostra o resultado\ndf[['altura']] = scaled_standard\ndf[['massa']] = scaled_minmax\n\ndf.head()\n</pre> # transforma\u00e7\u00f5es diferentes em no mesmo dataset from sklearn.preprocessing import MinMaxScaler from sklearn.preprocessing import StandardScaler   cols = ['altura', 'massa', 'idade'] df = pd.DataFrame(np.array([                             [170, 90, 20], # altura (cm), massa (Kg), idade (anos)                             [168, 55, 33],                             [173, 84, 57],                             [189, 98, 41]                         ]),columns=cols)  #Cria o objeto da classe standardScaler e MinMaxScaler scaler_standard = StandardScaler() scaler_minmax = MinMaxScaler(feature_range=(0,1))  # Aplica as transforma\u00e7\u00f5es scaled_standard = scaler_standard.fit_transform(df[['altura']]) scaled_minmax = scaler_minmax.fit_transform(df[['massa']])  # atualiza o valor e mostra o resultado df[['altura']] = scaled_standard df[['massa']] = scaled_minmax  df.head() Out[6]: altura massa idade 0 -0.604122 0.813953 20 1 -0.845771 0.000000 33 2 -0.241649 0.674419 57 3 1.691542 1.000000 41 In\u00a0[7]: Copied! <pre>### seu c\u00f3digo aqui.....\n</pre> ### seu c\u00f3digo aqui.....      In\u00a0[8]: Copied! <pre>import numpy as np\nimport pandas as pd\n\ncols = ['altura (cm)', 'massa (kg)', 'qualificacao']\ndf = pd.DataFrame(np.array([\n                            [170, 90, \"junior\"], # altura (cm), massa (Kg), g\u00eanero (f/m)\n                            [168, 55, \"pleno\"],\n                            [173, 84, \"junior\"],\n                            [189, 98, \"senior\"]\n                        ]),columns=cols)\n\ndf.head()\n</pre> import numpy as np import pandas as pd  cols = ['altura (cm)', 'massa (kg)', 'qualificacao'] df = pd.DataFrame(np.array([                             [170, 90, \"junior\"], # altura (cm), massa (Kg), g\u00eanero (f/m)                             [168, 55, \"pleno\"],                             [173, 84, \"junior\"],                             [189, 98, \"senior\"]                         ]),columns=cols)  df.head() Out[8]: altura (cm) massa (kg) qualificacao 0 170 90 junior 1 168 55 pleno 2 173 84 junior 3 189 98 senior In\u00a0[9]: Copied! <pre>from sklearn.preprocessing import LabelEncoder\n\n#Cria o objeto labelEncoder\nlabelencoder = LabelEncoder()\n\n# treina\nlabelencoder.fit(df['qualificacao'])\n# aplica transforma\u00e7\u00e3o\ndf['qualificacao'] = labelencoder.transform(df['qualificacao'])\n\n# ou treina e aplica no mesmo comando\n#df['qualificacao'] = labelencoder.fit_transform(df['qualificacao'])\ndf.head()\n</pre> from sklearn.preprocessing import LabelEncoder  #Cria o objeto labelEncoder labelencoder = LabelEncoder()  # treina labelencoder.fit(df['qualificacao']) # aplica transforma\u00e7\u00e3o df['qualificacao'] = labelencoder.transform(df['qualificacao'])  # ou treina e aplica no mesmo comando #df['qualificacao'] = labelencoder.fit_transform(df['qualificacao']) df.head() Out[9]: altura (cm) massa (kg) qualificacao 0 170 90 0 1 168 55 1 2 173 84 0 3 189 98 2 In\u00a0[10]: Copied! <pre>novos_dados2 = pd.DataFrame({'qualificao': [\"junior\", \"pleno\", \"junior\",\"senior\",\"senior\"]})\nencoded_data = labelencoder.transform(novos_dados2)\n\nprint('qualifica\u00e7\u00e3o codificada:', encoded_data)\n\n# para voltar aos atributos originais\n\nprint(labelencoder.inverse_transform(encoded_data) )\n</pre> novos_dados2 = pd.DataFrame({'qualificao': [\"junior\", \"pleno\", \"junior\",\"senior\",\"senior\"]}) encoded_data = labelencoder.transform(novos_dados2)  print('qualifica\u00e7\u00e3o codificada:', encoded_data)  # para voltar aos atributos originais  print(labelencoder.inverse_transform(encoded_data) ) <pre>qualifica\u00e7\u00e3o codificada: [0 1 0 2 2]\n['junior' 'pleno' 'junior' 'senior' 'senior']\n</pre> <pre>c:\\Users\\junior\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  return f(*args, **kwargs)\n</pre> <p>O problema aqui \u00e9 que, uma vez que existem n\u00fameros diferentes na mesma coluna, o modelo interpretar\u00e1 mal os dados como estando em algum tipo de ordem, 0 &lt;1 &lt;2.</p> <p>Voc\u00ea como desenvolvedor deve estar atento a este ponto e saber se faz sentido ou n\u00e3o, note que para qualifica\u00e7\u00e3o n\u00e3o tem problema, logo, este n\u00e3o \u00e9 o caso.</p> <p>Caso exista algum problema desta natureza, como um atributo genero, estado..., pode ser util usar One Hot Encoder.</p> In\u00a0[11]: Copied! <pre>import numpy as np\nimport pandas as pd\n\ncols = ['altura (cm)', 'massa (kg)', 'qualificacao']\ndf = pd.DataFrame(np.array([\n                            [170, 90, \"junior\"], # altura (cm), massa (Kg), g\u00eanero (f/m)\n                            [168, 55, \"pleno\"],\n                            [173, 84, \"junior\"],\n                            [189, 98, \"senior\"]\n                        ]),columns=cols)\n\ndf.head()\n</pre> import numpy as np import pandas as pd  cols = ['altura (cm)', 'massa (kg)', 'qualificacao'] df = pd.DataFrame(np.array([                             [170, 90, \"junior\"], # altura (cm), massa (Kg), g\u00eanero (f/m)                             [168, 55, \"pleno\"],                             [173, 84, \"junior\"],                             [189, 98, \"senior\"]                         ]),columns=cols)  df.head() Out[11]: altura (cm) massa (kg) qualificacao 0 170 90 junior 1 168 55 pleno 2 173 84 junior 3 189 98 senior In\u00a0[12]: Copied! <pre>from sklearn.preprocessing import OneHotEncoder\n\nohe = OneHotEncoder()\n\nponte_ohe = ohe.fit_transform(df[['qualificacao']]).toarray()\n\nponte_ohe\n</pre> from sklearn.preprocessing import OneHotEncoder  ohe = OneHotEncoder()  ponte_ohe = ohe.fit_transform(df[['qualificacao']]).toarray()  ponte_ohe Out[12]: <pre>array([[1., 0., 0.],\n       [0., 1., 0.],\n       [1., 0., 0.],\n       [0., 0., 1.]])</pre> In\u00a0[13]: Copied! <pre>#transforma o o np.arry em um dataframe\nponte_ohe = pd.DataFrame(ponte_ohe,columns=[\"qualificacao\"+str(int(i)) for i in range(df.shape[1])])\n\n#adiciona as novas colunas ao dataframe original\ndf = pd.concat([df,ponte_ohe], axis=1)\n\ndf.head()\n</pre> #transforma o o np.arry em um dataframe ponte_ohe = pd.DataFrame(ponte_ohe,columns=[\"qualificacao\"+str(int(i)) for i in range(df.shape[1])])  #adiciona as novas colunas ao dataframe original df = pd.concat([df,ponte_ohe], axis=1)  df.head() Out[13]: altura (cm) massa (kg) qualificacao qualificacao0 qualificacao1 qualificacao2 0 170 90 junior 1.0 0.0 0.0 1 168 55 pleno 0.0 1.0 0.0 2 173 84 junior 1.0 0.0 0.0 3 189 98 senior 0.0 0.0 1.0 In\u00a0[14]: Copied! <pre># faz o drop da coluna original qualificacao\n\ndf = df.drop([\"qualificacao\"], axis=1)\n\ndf.head()\n</pre> # faz o drop da coluna original qualificacao  df = df.drop([\"qualificacao\"], axis=1)  df.head() Out[14]: altura (cm) massa (kg) qualificacao0 qualificacao1 qualificacao2 0 170 90 1.0 0.0 0.0 1 168 55 0.0 1.0 0.0 2 173 84 1.0 0.0 0.0 3 189 98 0.0 0.0 1.0 <p>Note que agora temos a adi\u00e7\u00e3o de 3 novas colunas, onde cada uma corresponde a uma classifica\u00e7\u00e3o do atributo (\"junior\", \"pleno\", \"senior\")</p> In\u00a0[15]: Copied! <pre>##### seu c\u00f3digo aqui........\n</pre> ##### seu c\u00f3digo aqui........        <ul> <li><p>O PCA \u00e9 uma transforma\u00e7\u00e3o linear, ou seja, multiplica os vetores de atributos de entradas de N posi\u00e7\u00f5es por uma matriz com MxN, com M \u2264 N, resultando em um novo vetor de N dimens\u00f5es</p> </li> <li><p>O elemento que se destaca \u00e9 a da vari\u00e2ncia</p> </li> <li><p>Essa transforma\u00e7\u00e3o \u00e9 obtida por meio dos vetores de treinamento. A redu\u00e7\u00e3o na dimensionalidade \u00e9 controlada pelo par\u00e2metro que define a porcentagem de variabilidade que ser\u00e1 mantida nos novos dados</p> </li> <li><p>No Python, fazemos:</p> </li> </ul> In\u00a0[16]: Copied! <pre>from sklearn.decomposition import PCA\n\nmedidas_pca = PCA(0.5).fit_transform(df) # Mantem 50% de variabilidade\nprint(medidas_pca)\n\nprint(\"shape original: \" , df.shape, \"shape PCA: \" ,  medidas_pca.shape)\n</pre> from sklearn.decomposition import PCA  medidas_pca = PCA(0.5).fit_transform(df) # Mantem 50% de variabilidade print(medidas_pca)  print(\"shape original: \" , df.shape, \"shape PCA: \" ,  medidas_pca.shape)   <pre>[[ -5.81469106]\n [ 27.45356145]\n [ -1.35358402]\n [-20.28528637]]\nshape original:  (4, 5) shape PCA:  (4, 1)\n</pre> <ul> <li>Cada linha nessa matriz corresponde a uma vetor com N dimens\u00f5es, com um significado especial, denominado de auto-vetor</li> <li>No caso dos vetores serem imagens, essas \u201cauto-imagens\u201d guardam caracter\u00edsticas que ser\u00e3o usadas para identificar as imagens de teste</li> </ul> In\u00a0[17]: Copied! <pre>#Instale os pacotes e faz o download dos arquivos, se ja estiver na pasta n\u00e3o precisa rodar essa celula.\n\n#!pip3 install --user python-mnist\n#!pip install wget\n\n\nimport wget\nwget.download('http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz')\nwget.download('http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz')\nwget.download('http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz')\nwget.download('http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz')\n</pre> #Instale os pacotes e faz o download dos arquivos, se ja estiver na pasta n\u00e3o precisa rodar essa celula.  #!pip3 install --user python-mnist #!pip install wget   import wget wget.download('http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz') wget.download('http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz') wget.download('http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz') wget.download('http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz') Out[17]: <pre>'t10k-labels-idx1-ubyte.gz'</pre> In\u00a0[18]: Copied! <pre>import time\nimport numpy as np\n# API MNIST\nfrom mnist import MNIST\n\nt0 = time.time()\n\n# Importa os dados do dieret\u00f3rio local\nmndata = MNIST('.')\n# Habilita abrir arquivos compactados\nmndata.gz = True \n\n# Carrega os dados de treinamento\nentradas_treino, classes_treino = mndata.load_training()\n# Carrega os dados de treinamento\nentradas_teste, classes_teste = mndata.load_testing()\n\n#Transformando em array do numpy\nentradas_treino = np.array(entradas_treino)\nclasses_treino = np.array(classes_treino)\nentradas_teste = np.array(entradas_teste)\nclasses_teste = np.array(classes_teste)\n\ndados_reduzidos = False\n\nprint(\"Tempo para carregamento das imagens: {}s\".format(time.time()-t0))\n\nprint(\"Dimens\u00f5es da matriz dos dados de treinamento: \", entradas_treino.shape)\nprint(\"Dimens\u00f5es da matriz dos dados de teste: \", entradas_teste.shape)\n</pre> import time import numpy as np # API MNIST from mnist import MNIST  t0 = time.time()  # Importa os dados do dieret\u00f3rio local mndata = MNIST('.') # Habilita abrir arquivos compactados mndata.gz = True   # Carrega os dados de treinamento entradas_treino, classes_treino = mndata.load_training() # Carrega os dados de treinamento entradas_teste, classes_teste = mndata.load_testing()  #Transformando em array do numpy entradas_treino = np.array(entradas_treino) classes_treino = np.array(classes_treino) entradas_teste = np.array(entradas_teste) classes_teste = np.array(classes_teste)  dados_reduzidos = False  print(\"Tempo para carregamento das imagens: {}s\".format(time.time()-t0))  print(\"Dimens\u00f5es da matriz dos dados de treinamento: \", entradas_treino.shape) print(\"Dimens\u00f5es da matriz dos dados de teste: \", entradas_teste.shape)  <pre>Tempo para carregamento das imagens: 14.753993034362793s\nDimens\u00f5es da matriz dos dados de treinamento:  (60000, 784)\nDimens\u00f5es da matriz dos dados de teste:  (10000, 784)\n</pre> In\u00a0[19]: Copied! <pre># Fun\u00e7\u00e3o que visualiza a linha lin da matriz\nimport matplotlib.pyplot as plt\nimport math\ndef visualiza_linha_mnist(matriz, lin):\n  size = int(math.sqrt(matriz.shape[1]))\n  img = np.reshape(matriz[lin], (size, size))\n  plt.imshow(img, cmap=\"gray\")\n  \n# Visualiza\u00e7\u00e3o da linha 0\nvisualiza_linha_mnist(entradas_treino, 0)\nplt.show()\n</pre> # Fun\u00e7\u00e3o que visualiza a linha lin da matriz import matplotlib.pyplot as plt import math def visualiza_linha_mnist(matriz, lin):   size = int(math.sqrt(matriz.shape[1]))   img = np.reshape(matriz[lin], (size, size))   plt.imshow(img, cmap=\"gray\")    # Visualiza\u00e7\u00e3o da linha 0 visualiza_linha_mnist(entradas_treino, 0) plt.show() In\u00a0[20]: Copied! <pre>from sklearn.preprocessing import StandardScaler\n# PCA\nfrom sklearn.decomposition import PCA\n\nt0 = time.time()\n\nnormalizador = StandardScaler()\nredutor_dim = PCA(0.85)\n\nentradas_treino_norm = normalizador.fit_transform(entradas_treino)\nentradas_treino_norm = redutor_dim.fit_transform(entradas_treino_norm)\n\nentradas_teste_norm = normalizador.transform(entradas_teste)\nentradas_teste_norm = redutor_dim.transform(entradas_teste_norm)\n\nprint(\"Tempo para o processamento (normaliza\u00e7\u00e3o + PCA) das imagens: {}s\".format(time.time()-t0))\nprint(\"Novas dimensoes das matrizes de dados e classes (labels) de treinamento\")\nprint(entradas_treino_norm.shape, entradas_teste_norm.shape)\n</pre> from sklearn.preprocessing import StandardScaler # PCA from sklearn.decomposition import PCA  t0 = time.time()  normalizador = StandardScaler() redutor_dim = PCA(0.85)  entradas_treino_norm = normalizador.fit_transform(entradas_treino) entradas_treino_norm = redutor_dim.fit_transform(entradas_treino_norm)  entradas_teste_norm = normalizador.transform(entradas_teste) entradas_teste_norm = redutor_dim.transform(entradas_teste_norm)  print(\"Tempo para o processamento (normaliza\u00e7\u00e3o + PCA) das imagens: {}s\".format(time.time()-t0)) print(\"Novas dimensoes das matrizes de dados e classes (labels) de treinamento\") print(entradas_treino_norm.shape, entradas_teste_norm.shape) <pre>Tempo para o processamento (normaliza\u00e7\u00e3o + PCA) das imagens: 19.009876012802124s\nNovas dimensoes das matrizes de dados e classes (labels) de treinamento\n(60000, 185) (10000, 185)\n</pre> In\u00a0[21]: Copied! <pre>print(\"Dimens\u00f5es da matriz dos dados de treinamento: \", entradas_treino.shape)\nprint(\"Dimens\u00f5es da matriz dos dados de teste: \", entradas_teste.shape)\nprint(28*28)\n</pre> print(\"Dimens\u00f5es da matriz dos dados de treinamento: \", entradas_treino.shape) print(\"Dimens\u00f5es da matriz dos dados de teste: \", entradas_teste.shape) print(28*28)  <pre>Dimens\u00f5es da matriz dos dados de treinamento:  (60000, 784)\nDimens\u00f5es da matriz dos dados de teste:  (10000, 784)\n784\n</pre> In\u00a0[22]: Copied! <pre>##Avalia\u00e7\u00e3o PCA\n\nprint (len(entradas_treino_norm), len(entradas_treino_norm))\n\nprint (\"taxa de variancia explicada: \" , len(redutor_dim.explained_variance_ratio_), redutor_dim.explained_variance_ratio_)\nprint (\"valores de cada um dos componentes: \", len(redutor_dim.singular_values_), redutor_dim.singular_values_)\n</pre> ##Avalia\u00e7\u00e3o PCA  print (len(entradas_treino_norm), len(entradas_treino_norm))  print (\"taxa de variancia explicada: \" , len(redutor_dim.explained_variance_ratio_), redutor_dim.explained_variance_ratio_) print (\"valores de cada um dos componentes: \", len(redutor_dim.singular_values_), redutor_dim.singular_values_) <pre>60000 60000\ntaxa de variancia explicada:  185 [0.05646717 0.04078272 0.0373938  0.02885115 0.02521109 0.0219427\n 0.01923344 0.01745799 0.01535092 0.0140172  0.01341743 0.01203742\n 0.0111457  0.01089924 0.01028649 0.00994487 0.00936383 0.00921046\n 0.00893437 0.00869913 0.00827363 0.00803417 0.00764846 0.00741772\n 0.00715293 0.00691847 0.00684136 0.00656675 0.00631677 0.0061292\n 0.00596255 0.00587716 0.00571592 0.00562307 0.00554682 0.00538418\n 0.00531182 0.00519606 0.00508211 0.00480006 0.00476456 0.00469139\n 0.00454349 0.00451346 0.00446963 0.00443383 0.00438215 0.00430382\n 0.00426878 0.00423647 0.00404696 0.00399447 0.00397456 0.00393821\n 0.00385814 0.00379043 0.00375403 0.00370776 0.00364944 0.00359301\n 0.00352382 0.00347794 0.00344411 0.00339868 0.00335955 0.00334886\n 0.00331864 0.00323026 0.00316277 0.00313244 0.00310731 0.00307243\n 0.00304914 0.00302717 0.00299485 0.00297761 0.00295052 0.00290438\n 0.00286856 0.00285678 0.00283398 0.00282627 0.00279551 0.00279305\n 0.00278519 0.00277455 0.00275901 0.00274227 0.00271411 0.00269263\n 0.00266484 0.00263581 0.00262962 0.00261034 0.00258827 0.00256176\n 0.00253846 0.00250447 0.00247829 0.00245034 0.00242347 0.00242064\n 0.00238875 0.00237455 0.00235608 0.00233053 0.0022798  0.00226174\n 0.00222832 0.00222442 0.00218169 0.00217257 0.00214277 0.00211938\n 0.00210972 0.0020733  0.00204761 0.00204368 0.00202409 0.00200462\n 0.00198822 0.00195216 0.00193737 0.00192103 0.00191716 0.00189802\n 0.00187089 0.00186536 0.0018132  0.00180005 0.00179194 0.00178973\n 0.0017695  0.00176158 0.00174797 0.00172985 0.00172017 0.00168727\n 0.00168517 0.00166842 0.00164718 0.00164575 0.00164294 0.00161486\n 0.0016049  0.00158912 0.0015749  0.00155918 0.00155638 0.00154666\n 0.00154043 0.00151605 0.00150272 0.00148761 0.00147505 0.0014682\n 0.00145803 0.00145568 0.00144737 0.00142895 0.00141058 0.00139939\n 0.00139709 0.00139533 0.00139355 0.00139225 0.00138773 0.0013834\n 0.00137816 0.00136845 0.00136165 0.00135822 0.00133701 0.00132905\n 0.00131059 0.00130293 0.00129324 0.00128241 0.00127407 0.00126822\n 0.00125322 0.00124045 0.00122984 0.00121618 0.00121506]\nvalores de cada um dos componentes:  185 [1558.59475775 1324.56506425 1268.33806904 1114.08096949 1041.4321537\n  971.58372712  909.62781125  866.6272717   812.64796157  776.54347762\n  759.74854205  719.61780297  692.45059052  684.75186297  665.2254475\n  654.08571283  634.6905444   629.47108378  619.96491977  611.74864821\n  596.60000904  587.90318277  573.61706238  564.89867585  554.72424844\n  545.55706108  542.50833328  531.50859803  521.29389656  513.4959735\n  506.46720335  502.82760665  495.88178934  491.83803286  488.4917578\n  481.27703518  478.03201127  472.79417281  467.58152416  454.42094643\n  452.73755506  449.24798572  442.10962544  440.64606814  438.50160223\n  436.74183847  434.18923818  430.29086602  428.53573113  426.91093544\n  417.25324612  414.53862665  413.50407786  411.60868344  407.40275713\n  403.81203369  401.86842781  399.38423688  396.23108492  393.15532131\n  389.35177902  386.80851333  384.92303762  382.37581508  380.16791664\n  379.56282447  377.84621102  372.78112287  368.86630886  367.09355234\n  365.61819099  363.56002954  362.17963536  360.87245819  358.94092281\n  357.90621176  356.27402823  353.47770091  351.29123623  350.56891845\n  349.16718716  348.69212323  346.78936634  346.6369362   346.14874915\n  345.48710725  344.51781742  343.47138797  341.70285667  340.34823393\n  338.58759852  336.73828279  336.34220011  335.10707121  333.68749917\n  331.97454025  330.46102411  328.24139239  326.52136861  324.67435089\n  322.88936082  322.70086024  320.56858096  319.61385191  318.36887157\n  316.63780238  313.1725175   311.92971598  309.61609571  309.34544735\n  306.360028    305.71862309  303.61468514  301.95298194  301.26427292\n  298.6527374   296.79663011  296.51171699  295.08666108  293.66447678\n  292.46061956  289.79603176  288.69671405  287.47662373  287.18664393\n  285.74965273  283.70035923  283.28015727  279.29169961  278.27731866\n  277.64955632  277.47843311  275.90592833  275.28720761  274.22175433\n  272.7966822   272.03227791  269.41865042  269.25082545  267.90897203\n  266.19893845  266.08295896  265.85540571  263.57386832  262.7601788\n  261.46521492  260.29213116  258.9899899   258.75750421  257.94798876\n  257.42815671  255.38269599  254.25740548  252.97587879  251.90640352\n  251.32057934  250.44831234  250.24628968  249.53113324  247.93848294\n  246.33934447  245.36012105  245.15894614  245.00431129  244.84794458\n  244.73387616  244.33626317  243.95435627  243.49224383  242.63262475\n  242.0297457   241.72463554  239.82975985  239.11486781  237.44845681\n  236.75327822  235.87142391  234.8811359   234.11618726  233.57844421\n  232.19261652  231.00662861  230.01633731  228.73575127  228.63068847]\n</pre> In\u00a0[23]: Copied! <pre>plt.figure(figsize=(10,10))\nplt.subplot(4,4,1)\nfor i in range(4):\n  for j in range(4):\n    plt.subplot(4,4,i*4+j+1)\n    visualiza_linha_mnist(redutor_dim.components_, i*4 + j)\nplt.show()\n</pre> plt.figure(figsize=(10,10)) plt.subplot(4,4,1) for i in range(4):   for j in range(4):     plt.subplot(4,4,i*4+j+1)     visualiza_linha_mnist(redutor_dim.components_, i*4 + j) plt.show() <pre>&lt;ipython-input-23-e7a2857a4126&gt;:5: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n  plt.subplot(4,4,i*4+j+1)\n</pre> In\u00a0[24]: Copied! <pre>## Seu c\u00f3digo aqui.....\n</pre> ## Seu c\u00f3digo aqui....."},{"location":"aulas/IA/lab04/dicasDePreprocessamento.html#2-aprendizagem-de-maquina","title":"2. Aprendizagem de m\u00e1quina\u00b6","text":""},{"location":"aulas/IA/lab04/dicasDePreprocessamento.html#objetivos","title":"Objetivos\u00b6","text":"<ul> <li>Dicas de pr\u00e9-processamento de dados</li> <li>Entender e praticar a normaliza\u00e7\u00e3o dos dados</li> <li>Entender e praticar codifica\u00e7\u00e3o Label Encoder e One Hot Encoder.</li> <li>Redu\u00e7\u00e3o de dimensionalidade: PCA</li> </ul>"},{"location":"aulas/IA/lab04/dicasDePreprocessamento.html#pre-processamento","title":"Pr\u00e9-processamento\u00b6","text":"<p>Nesta etapa estamos interessados em tratar os dados que servir\u00e3o de entrada do nosso modelo de Machine Learning seja ele predi\u00e7\u00e3o, agrupamento ou classifica\u00e7\u00e3o. Existem diversas t\u00e9cnicas que podem (e devem) ser aplicadas, j\u00e1 conhecemos algumas e hoje veremos outras t\u00e9cnicas.</p>"},{"location":"aulas/IA/lab04/dicasDePreprocessamento.html#normalizacao-de-dados","title":"Normaliza\u00e7\u00e3o de dados\u00b6","text":"<p>O conceito de normaliza\u00e7\u00e3o \u00e9 simples, a id\u00e9ia \u00e9 deixar os dados todos na mesma ordem de grandeza, desta forma evita-se gerar discrep\u00e2ncias entre os atributos (colunas).</p> <p>Os m\u00e9todos mais populares s\u00e3o:</p> <ul> <li>Normaliza\u00e7\u00e3o Min-M\u00e1x: transforma os dados em um escala linear entre 0 e 1</li> <li>Normaliza\u00e7\u00e3o de pontua\u00e7\u00e3o Z: Escala de dados com base na m\u00e9dia e desvio padr\u00e3o (tambem chamado de padroniza\u00e7\u00e3o)</li> <li>Dimensionamento decimal: Dimensiona os dados movendo o ponto decimal do atributo (muito utilizado em sistemas embarcados).</li> </ul>"},{"location":"aulas/IA/lab04/dicasDePreprocessamento.html#desafio-1","title":"Desafio 1\u00b6","text":"<p>Lembra o dataset 'breast_cancer'. Aplique essas transforma\u00e7\u00f5es necess\u00e1rias aprendidas nos atributos num\u00e9ricos.</p>"},{"location":"aulas/IA/lab04/dicasDePreprocessamento.html#codificacao-label-encoder-e-one-hot-encoder","title":"Codifica\u00e7\u00e3o Label Encoder e One Hot Encoder\u00b6","text":"<p>Em muitos casos vamos nos deparar com atributos categoricos, que n\u00e3o possuem numeros e sim textos. Como por exemplo um atributo chamado Cidade, ser\u00e1 pararecido com [\"cotia\",\"S\u00e3o Paulo\",\"Pouso Alegre\"] ou um atributo de qualifica\u00e7\u00e3o profissional, ser\u00e1 paracido com [\"junior\",\"Pleno\",\"Senior\"].</p> <p>Para esses tipos de casos manter o atributo como esta para realizar um aprendizado de maquina pode n\u00e3o ser uma boa id\u00e9ia, para isso, podemos trocar os textos por valores numericos. Vamos ver algumas formas para realizar esse processo.</p>"},{"location":"aulas/IA/lab04/dicasDePreprocessamento.html#label-encoder","title":"Label Encoder\u00b6","text":"<p>Uma forma simples de trocar um atributo categorico de texto para numero \u00e9 associar um valor num\u00e9rico para cada texto do atributo.</p> <ul> <li><p>Exemplo:</p> <p>[\"cotia\",\"S\u00e3o Paulo\",\"Pouso Alegre\"] == [0,2,1]</p> <p>[\"junior\",\"Pleno\",\"Senior\"] == [0,1,2]</p> </li> </ul> <p>Observa\u00e7\u00e3o: Note que os indices est\u00e3o em <code>ordem alfab\u00e9tica</code>.</p>"},{"location":"aulas/IA/lab04/dicasDePreprocessamento.html#one-hot-encoder","title":"One Hot Encoder\u00b6","text":"<p>Podemos associar cada valor de um atribuco como uma nova coluna e preencher com 0 ou 1 o valor desta coluna, \u00e9 desta forma que o one hot encoder funciona.</p> <ul> <li>Exemplo:</li> </ul>"},{"location":"aulas/IA/lab04/dicasDePreprocessamento.html#desafio-2","title":"Desafio 2\u00b6","text":"<p>Vamos avaliar o efeito de transforma\u00e7\u00e3o de variavel no treinamento de um dataset, para isso:</p> <p>Treine e avalie duas vezes um classificador kNN para o dataset Wine: https://archive.ics.uci.edu/ml/datasets/Wine.</p> <p>Considere como dados de entrada apenas as colunas 'Flavanoids\u2019 e 'Proline\u2019.</p> <p>Compare o efeito da normaliza\u00e7\u00e3o na avalia\u00e7\u00e3o do classificador. Use k = 5.</p>"},{"location":"aulas/IA/lab04/dicasDePreprocessamento.html#reducao-de-dimensionalidade","title":"Redu\u00e7\u00e3o de dimensionalidade\u00b6","text":"<ul> <li>Para o bom desempenho da tarefa de classifica\u00e7\u00e3o \u00e9 importante um conjunto suficientemente grande de atributos.<ul> <li>Em muitos casos, especialmente quando se trabalha diretamente com os pixels das imagens, a informa\u00e7\u00e3o necess\u00e1ria para a classifica\u00e7\u00e3o de padr\u00f5es est\u00e1 espalhada por praticamente todos os atributos</li> </ul> </li> <li>No entanto, um n\u00famero muito grande de atributos atrapalha o desempenho dos classificadores, num efeito conhecido como a maldi\u00e7\u00e3o da dimensionalidade, curse of dimensionality.</li> <li>Frequentemente um n\u00famero grande de atributos est\u00e1 associado \u00e0 redund\u00e2ncia da informa\u00e7\u00e3o, ou seja, os valores dos tributos est\u00e3o fortemente ligados entre si.<ul> <li>Por exemplo, nas imagens de d\u00edgitos, pixels pr\u00f3ximos tendem a ter tonalidades semelhantes</li> </ul> </li> <li>Uma sa\u00edda para aproveitar a maior parte da informa\u00e7\u00e3o espalhada pelos atributos \u00e9 encontrar uma transforma\u00e7\u00e3o dos dados que use atributos o t\u00e3o independentes quanto poss\u00edvel.<ul> <li>Dessa forma, alguns atributos ter\u00e3o mais relev\u00e2ncia do que outros, pois ao desfazer a interdepend\u00eancia, conseguimos \u201cseparar\u201d a informa\u00e7\u00e3o relevante da informa\u00e7\u00e3o redundante</li> </ul> </li> </ul>"},{"location":"aulas/IA/lab04/dicasDePreprocessamento.html#pca-principal-component-analysis","title":"PCA : Principal Component Analysis\u00b6","text":"<p>(An\u00e1lise de Componentes Principais)</p>"},{"location":"aulas/IA/lab04/dicasDePreprocessamento.html#1-gera-a-matriz-de-dados-de-entradas-e-o-vetor-de-classes-alvo-para-treinamento","title":"1 - Gera a matriz de dados de entradas e o vetor de classes alvo para treinamento\u00b6","text":"<p>Cada linha da matriz de entradas (atributos) cont\u00e9m os pixels da  imagem.</p> <p>Cada posi\u00e7\u00e3o do array de r\u00f3tulos (labels) cont\u00e9m a classe alvo da imgem.</p> <p>No caso deste dataset, as imagens de trenamento e de teste j\u00e1 est\u00e3o separadas, e vamos adotar a separa\u00e7\u00e3o sugerida pelo autor da base de dados.</p>"},{"location":"aulas/IA/lab04/dicasDePreprocessamento.html#11-visualizcao-de-uma-imagem","title":"1.1 Visualiz\u00e7\u00e3o de uma imagem\u00b6","text":"<p>Neste dataset cada imagem est\u00e1 armazenada como uma linha da matriz de entrada. Para visualizar a imagem que est\u00e1 na linha <code>i</code> da matriz, temos que convert\u00ea-la novamente em uma matriz quadrada, e usar a biblioteca <code>matplotlib</code></p>"},{"location":"aulas/IA/lab04/dicasDePreprocessamento.html#2-faz-a-normalizacao-e-a-reducao-da-dimensionalidade-com-pca","title":"2 - Faz a normaliza\u00e7\u00e3o e a redu\u00e7\u00e3o da dimensionalidade com PCA\u00b6","text":"<p>Instancia o modelo PCA de forma que 85% da variabilidade de dados seja mantida. O m\u00e9todo <code>fit_transform(X)</code> treina o PCA e j\u00e1 traz os dados <code>X</code> transformados. Para reaproveitar o mesmo modelo PCA sem trein\u00e1-o novamente, usamos <code>transform()</code>.</p> <p>Uma vez que os dados de treinamento e teste j\u00e1 est\u00e3o separados,treinamos o normalizador e o PCA com os dados de treinamento, e apenas aplicamos a transforma\u00e7\u00e3o nos dados de teste.</p>"},{"location":"aulas/IA/lab04/dicasDePreprocessamento.html#21-visualizacao-das-16-primairas-imagens-principais","title":"2.1 - Visualiza\u00e7\u00e3o das 16 primairas imagens principais\u00b6","text":"<p>O PCA neste caso transforma um array (entrada ou linha da matriz) composta por um conjunto de pixels em um outro array que indica a composi\u00e7\u00e3o da imagem em termos de \"imagens principais\"</p>"},{"location":"aulas/IA/lab04/dicasDePreprocessamento.html#desafio-3","title":"Desafio 3\u00b6","text":"<p>Agora \u00e9 com voc\u00ea termine a implementa\u00e7ao deste classificador de digitos usando o KNN. Usar as novas matrizes no treinamento, teste e avalia\u00e7\u00e3o do classificador</p>"},{"location":"aulas/IA/lab04/reducao_dimensionalidade_pca.html","title":"PCA","text":"<ul> <li><p>O PCA \u00e9 uma transforma\u00e7\u00e3o linear, ou seja, multiplica os vetores de atributos de entradas de N posi\u00e7\u00f5es por uma matriz com MxN, com M \u2264 N, resultando em um novo vetor de N dimens\u00f5es</p> </li> <li><p>O elemento que se destaca \u00e9 a da vari\u00e2ncia</p> </li> <li><p>Essa transforma\u00e7\u00e3o \u00e9 obtida por meio dos vetores de treinamento. A redu\u00e7\u00e3o na dimensionalidade \u00e9 controlada pelo par\u00e2metro que define a porcentagem de variabilidade que ser\u00e1 mantida nos novos dados</p> </li> <li><p>No Python, fazemos:</p> </li> </ul> In\u00a0[16]: Copied! <pre>from sklearn.decomposition import PCA\n\nmedidas_pca = PCA(0.5).fit_transform(df) # Mantem 50% de variabilidade\nprint(medidas_pca)\n\nprint(\"shape original: \" , df.shape, \"shape PCA: \" ,  medidas_pca.shape)\n</pre> from sklearn.decomposition import PCA  medidas_pca = PCA(0.5).fit_transform(df) # Mantem 50% de variabilidade print(medidas_pca)  print(\"shape original: \" , df.shape, \"shape PCA: \" ,  medidas_pca.shape)   <pre>[[ -5.81469106]\n [ 27.45356145]\n [ -1.35358402]\n [-20.28528637]]\nshape original:  (4, 5) shape PCA:  (4, 1)\n</pre> <ul> <li>Cada linha nessa matriz corresponde a uma vetor com N dimens\u00f5es, com um significado especial, denominado de auto-vetor</li> <li>No caso dos vetores serem imagens, essas \u201cauto-imagens\u201d guardam caracter\u00edsticas que ser\u00e3o usadas para identificar as imagens de teste</li> </ul> In\u00a0[17]: Copied! <pre>#Instale os pacotes e faz o download dos arquivos, se ja estiver na pasta n\u00e3o precisa rodar essa celula.\n\n#!pip3 install --user python-mnist\n#!pip install wget\n\n\nimport wget\nwget.download('http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz')\nwget.download('http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz')\nwget.download('http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz')\nwget.download('http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz')\n</pre> #Instale os pacotes e faz o download dos arquivos, se ja estiver na pasta n\u00e3o precisa rodar essa celula.  #!pip3 install --user python-mnist #!pip install wget   import wget wget.download('http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz') wget.download('http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz') wget.download('http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz') wget.download('http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz') Out[17]: <pre>'t10k-labels-idx1-ubyte.gz'</pre> In\u00a0[18]: Copied! <pre>import time\nimport numpy as np\n# API MNIST\nfrom mnist import MNIST\n\nt0 = time.time()\n\n# Importa os dados do dieret\u00f3rio local\nmndata = MNIST('.')\n# Habilita abrir arquivos compactados\nmndata.gz = True \n\n# Carrega os dados de treinamento\nentradas_treino, classes_treino = mndata.load_training()\n# Carrega os dados de treinamento\nentradas_teste, classes_teste = mndata.load_testing()\n\n#Transformando em array do numpy\nentradas_treino = np.array(entradas_treino)\nclasses_treino = np.array(classes_treino)\nentradas_teste = np.array(entradas_teste)\nclasses_teste = np.array(classes_teste)\n\ndados_reduzidos = False\n\nprint(\"Tempo para carregamento das imagens: {}s\".format(time.time()-t0))\n\nprint(\"Dimens\u00f5es da matriz dos dados de treinamento: \", entradas_treino.shape)\nprint(\"Dimens\u00f5es da matriz dos dados de teste: \", entradas_teste.shape)\n</pre> import time import numpy as np # API MNIST from mnist import MNIST  t0 = time.time()  # Importa os dados do dieret\u00f3rio local mndata = MNIST('.') # Habilita abrir arquivos compactados mndata.gz = True   # Carrega os dados de treinamento entradas_treino, classes_treino = mndata.load_training() # Carrega os dados de treinamento entradas_teste, classes_teste = mndata.load_testing()  #Transformando em array do numpy entradas_treino = np.array(entradas_treino) classes_treino = np.array(classes_treino) entradas_teste = np.array(entradas_teste) classes_teste = np.array(classes_teste)  dados_reduzidos = False  print(\"Tempo para carregamento das imagens: {}s\".format(time.time()-t0))  print(\"Dimens\u00f5es da matriz dos dados de treinamento: \", entradas_treino.shape) print(\"Dimens\u00f5es da matriz dos dados de teste: \", entradas_teste.shape)  <pre>Tempo para carregamento das imagens: 14.753993034362793s\nDimens\u00f5es da matriz dos dados de treinamento:  (60000, 784)\nDimens\u00f5es da matriz dos dados de teste:  (10000, 784)\n</pre> In\u00a0[19]: Copied! <pre># Fun\u00e7\u00e3o que visualiza a linha lin da matriz\nimport matplotlib.pyplot as plt\nimport math\ndef visualiza_linha_mnist(matriz, lin):\n  size = int(math.sqrt(matriz.shape[1]))\n  img = np.reshape(matriz[lin], (size, size))\n  plt.imshow(img, cmap=\"gray\")\n  \n# Visualiza\u00e7\u00e3o da linha 0\nvisualiza_linha_mnist(entradas_treino, 0)\nplt.show()\n</pre> # Fun\u00e7\u00e3o que visualiza a linha lin da matriz import matplotlib.pyplot as plt import math def visualiza_linha_mnist(matriz, lin):   size = int(math.sqrt(matriz.shape[1]))   img = np.reshape(matriz[lin], (size, size))   plt.imshow(img, cmap=\"gray\")    # Visualiza\u00e7\u00e3o da linha 0 visualiza_linha_mnist(entradas_treino, 0) plt.show() In\u00a0[20]: Copied! <pre>from sklearn.preprocessing import StandardScaler\n# PCA\nfrom sklearn.decomposition import PCA\n\nt0 = time.time()\n\nnormalizador = StandardScaler()\nredutor_dim = PCA(0.85)\n\nentradas_treino_norm = normalizador.fit_transform(entradas_treino)\nentradas_treino_norm = redutor_dim.fit_transform(entradas_treino_norm)\n\nentradas_teste_norm = normalizador.transform(entradas_teste)\nentradas_teste_norm = redutor_dim.transform(entradas_teste_norm)\n\nprint(\"Tempo para o processamento (normaliza\u00e7\u00e3o + PCA) das imagens: {}s\".format(time.time()-t0))\nprint(\"Novas dimensoes das matrizes de dados e classes (labels) de treinamento\")\nprint(entradas_treino_norm.shape, entradas_teste_norm.shape)\n</pre> from sklearn.preprocessing import StandardScaler # PCA from sklearn.decomposition import PCA  t0 = time.time()  normalizador = StandardScaler() redutor_dim = PCA(0.85)  entradas_treino_norm = normalizador.fit_transform(entradas_treino) entradas_treino_norm = redutor_dim.fit_transform(entradas_treino_norm)  entradas_teste_norm = normalizador.transform(entradas_teste) entradas_teste_norm = redutor_dim.transform(entradas_teste_norm)  print(\"Tempo para o processamento (normaliza\u00e7\u00e3o + PCA) das imagens: {}s\".format(time.time()-t0)) print(\"Novas dimensoes das matrizes de dados e classes (labels) de treinamento\") print(entradas_treino_norm.shape, entradas_teste_norm.shape) <pre>Tempo para o processamento (normaliza\u00e7\u00e3o + PCA) das imagens: 19.009876012802124s\nNovas dimensoes das matrizes de dados e classes (labels) de treinamento\n(60000, 185) (10000, 185)\n</pre> In\u00a0[21]: Copied! <pre>print(\"Dimens\u00f5es da matriz dos dados de treinamento: \", entradas_treino.shape)\nprint(\"Dimens\u00f5es da matriz dos dados de teste: \", entradas_teste.shape)\nprint(28*28)\n</pre> print(\"Dimens\u00f5es da matriz dos dados de treinamento: \", entradas_treino.shape) print(\"Dimens\u00f5es da matriz dos dados de teste: \", entradas_teste.shape) print(28*28)  <pre>Dimens\u00f5es da matriz dos dados de treinamento:  (60000, 784)\nDimens\u00f5es da matriz dos dados de teste:  (10000, 784)\n784\n</pre> In\u00a0[22]: Copied! <pre>##Avalia\u00e7\u00e3o PCA\n\nprint (len(entradas_treino_norm), len(entradas_treino_norm))\n\nprint (\"taxa de variancia explicada: \" , len(redutor_dim.explained_variance_ratio_), redutor_dim.explained_variance_ratio_)\nprint (\"valores de cada um dos componentes: \", len(redutor_dim.singular_values_), redutor_dim.singular_values_)\n</pre> ##Avalia\u00e7\u00e3o PCA  print (len(entradas_treino_norm), len(entradas_treino_norm))  print (\"taxa de variancia explicada: \" , len(redutor_dim.explained_variance_ratio_), redutor_dim.explained_variance_ratio_) print (\"valores de cada um dos componentes: \", len(redutor_dim.singular_values_), redutor_dim.singular_values_) <pre>60000 60000\ntaxa de variancia explicada:  185 [0.05646717 0.04078272 0.0373938  0.02885115 0.02521109 0.0219427\n 0.01923344 0.01745799 0.01535092 0.0140172  0.01341743 0.01203742\n 0.0111457  0.01089924 0.01028649 0.00994487 0.00936383 0.00921046\n 0.00893437 0.00869913 0.00827363 0.00803417 0.00764846 0.00741772\n 0.00715293 0.00691847 0.00684136 0.00656675 0.00631677 0.0061292\n 0.00596255 0.00587716 0.00571592 0.00562307 0.00554682 0.00538418\n 0.00531182 0.00519606 0.00508211 0.00480006 0.00476456 0.00469139\n 0.00454349 0.00451346 0.00446963 0.00443383 0.00438215 0.00430382\n 0.00426878 0.00423647 0.00404696 0.00399447 0.00397456 0.00393821\n 0.00385814 0.00379043 0.00375403 0.00370776 0.00364944 0.00359301\n 0.00352382 0.00347794 0.00344411 0.00339868 0.00335955 0.00334886\n 0.00331864 0.00323026 0.00316277 0.00313244 0.00310731 0.00307243\n 0.00304914 0.00302717 0.00299485 0.00297761 0.00295052 0.00290438\n 0.00286856 0.00285678 0.00283398 0.00282627 0.00279551 0.00279305\n 0.00278519 0.00277455 0.00275901 0.00274227 0.00271411 0.00269263\n 0.00266484 0.00263581 0.00262962 0.00261034 0.00258827 0.00256176\n 0.00253846 0.00250447 0.00247829 0.00245034 0.00242347 0.00242064\n 0.00238875 0.00237455 0.00235608 0.00233053 0.0022798  0.00226174\n 0.00222832 0.00222442 0.00218169 0.00217257 0.00214277 0.00211938\n 0.00210972 0.0020733  0.00204761 0.00204368 0.00202409 0.00200462\n 0.00198822 0.00195216 0.00193737 0.00192103 0.00191716 0.00189802\n 0.00187089 0.00186536 0.0018132  0.00180005 0.00179194 0.00178973\n 0.0017695  0.00176158 0.00174797 0.00172985 0.00172017 0.00168727\n 0.00168517 0.00166842 0.00164718 0.00164575 0.00164294 0.00161486\n 0.0016049  0.00158912 0.0015749  0.00155918 0.00155638 0.00154666\n 0.00154043 0.00151605 0.00150272 0.00148761 0.00147505 0.0014682\n 0.00145803 0.00145568 0.00144737 0.00142895 0.00141058 0.00139939\n 0.00139709 0.00139533 0.00139355 0.00139225 0.00138773 0.0013834\n 0.00137816 0.00136845 0.00136165 0.00135822 0.00133701 0.00132905\n 0.00131059 0.00130293 0.00129324 0.00128241 0.00127407 0.00126822\n 0.00125322 0.00124045 0.00122984 0.00121618 0.00121506]\nvalores de cada um dos componentes:  185 [1558.59475775 1324.56506425 1268.33806904 1114.08096949 1041.4321537\n  971.58372712  909.62781125  866.6272717   812.64796157  776.54347762\n  759.74854205  719.61780297  692.45059052  684.75186297  665.2254475\n  654.08571283  634.6905444   629.47108378  619.96491977  611.74864821\n  596.60000904  587.90318277  573.61706238  564.89867585  554.72424844\n  545.55706108  542.50833328  531.50859803  521.29389656  513.4959735\n  506.46720335  502.82760665  495.88178934  491.83803286  488.4917578\n  481.27703518  478.03201127  472.79417281  467.58152416  454.42094643\n  452.73755506  449.24798572  442.10962544  440.64606814  438.50160223\n  436.74183847  434.18923818  430.29086602  428.53573113  426.91093544\n  417.25324612  414.53862665  413.50407786  411.60868344  407.40275713\n  403.81203369  401.86842781  399.38423688  396.23108492  393.15532131\n  389.35177902  386.80851333  384.92303762  382.37581508  380.16791664\n  379.56282447  377.84621102  372.78112287  368.86630886  367.09355234\n  365.61819099  363.56002954  362.17963536  360.87245819  358.94092281\n  357.90621176  356.27402823  353.47770091  351.29123623  350.56891845\n  349.16718716  348.69212323  346.78936634  346.6369362   346.14874915\n  345.48710725  344.51781742  343.47138797  341.70285667  340.34823393\n  338.58759852  336.73828279  336.34220011  335.10707121  333.68749917\n  331.97454025  330.46102411  328.24139239  326.52136861  324.67435089\n  322.88936082  322.70086024  320.56858096  319.61385191  318.36887157\n  316.63780238  313.1725175   311.92971598  309.61609571  309.34544735\n  306.360028    305.71862309  303.61468514  301.95298194  301.26427292\n  298.6527374   296.79663011  296.51171699  295.08666108  293.66447678\n  292.46061956  289.79603176  288.69671405  287.47662373  287.18664393\n  285.74965273  283.70035923  283.28015727  279.29169961  278.27731866\n  277.64955632  277.47843311  275.90592833  275.28720761  274.22175433\n  272.7966822   272.03227791  269.41865042  269.25082545  267.90897203\n  266.19893845  266.08295896  265.85540571  263.57386832  262.7601788\n  261.46521492  260.29213116  258.9899899   258.75750421  257.94798876\n  257.42815671  255.38269599  254.25740548  252.97587879  251.90640352\n  251.32057934  250.44831234  250.24628968  249.53113324  247.93848294\n  246.33934447  245.36012105  245.15894614  245.00431129  244.84794458\n  244.73387616  244.33626317  243.95435627  243.49224383  242.63262475\n  242.0297457   241.72463554  239.82975985  239.11486781  237.44845681\n  236.75327822  235.87142391  234.8811359   234.11618726  233.57844421\n  232.19261652  231.00662861  230.01633731  228.73575127  228.63068847]\n</pre> In\u00a0[23]: Copied! <pre>plt.figure(figsize=(10,10))\nplt.subplot(4,4,1)\nfor i in range(4):\n  for j in range(4):\n    plt.subplot(4,4,i*4+j+1)\n    visualiza_linha_mnist(redutor_dim.components_, i*4 + j)\nplt.show()\n</pre> plt.figure(figsize=(10,10)) plt.subplot(4,4,1) for i in range(4):   for j in range(4):     plt.subplot(4,4,i*4+j+1)     visualiza_linha_mnist(redutor_dim.components_, i*4 + j) plt.show() <pre>&lt;ipython-input-23-e7a2857a4126&gt;:5: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n  plt.subplot(4,4,i*4+j+1)\n</pre> In\u00a0[24]: Copied! <pre>## Seu c\u00f3digo aqui.....\n</pre> ## Seu c\u00f3digo aqui....."},{"location":"aulas/IA/lab04/reducao_dimensionalidade_pca.html#aprendizagem-de-maquina","title":"Aprendizagem de m\u00e1quina\u00b6","text":""},{"location":"aulas/IA/lab04/reducao_dimensionalidade_pca.html#objetivos","title":"Objetivos\u00b6","text":"<ul> <li>Intui\u00e7\u00e3o sobre Redu\u00e7\u00e3o de dimensionalidade</li> <li>Conhecer o algoritmo PCA</li> </ul>"},{"location":"aulas/IA/lab04/reducao_dimensionalidade_pca.html#reducao-de-dimensionalidade","title":"Redu\u00e7\u00e3o de dimensionalidade\u00b6","text":"<ul> <li>Para o bom desempenho da tarefa de classifica\u00e7\u00e3o \u00e9 importante um conjunto suficientemente grande de atributos.<ul> <li>Em muitos casos, especialmente quando se trabalha diretamente com os pixels das imagens, a informa\u00e7\u00e3o necess\u00e1ria para a classifica\u00e7\u00e3o de padr\u00f5es est\u00e1 espalhada por praticamente todos os atributos</li> </ul> </li> <li>No entanto, um n\u00famero muito grande de atributos atrapalha o desempenho dos classificadores, num efeito conhecido como a maldi\u00e7\u00e3o da dimensionalidade, curse of dimensionality.</li> <li>Frequentemente um n\u00famero grande de atributos est\u00e1 associado \u00e0 redund\u00e2ncia da informa\u00e7\u00e3o, ou seja, os valores dos tributos est\u00e3o fortemente ligados entre si.<ul> <li>Por exemplo, nas imagens de d\u00edgitos, pixels pr\u00f3ximos tendem a ter tonalidades semelhantes</li> </ul> </li> <li>Uma sa\u00edda para aproveitar a maior parte da informa\u00e7\u00e3o espalhada pelos atributos \u00e9 encontrar uma transforma\u00e7\u00e3o dos dados que use atributos o t\u00e3o independentes quanto poss\u00edvel.<ul> <li>Dessa forma, alguns atributos ter\u00e3o mais relev\u00e2ncia do que outros, pois ao desfazer a interdepend\u00eancia, conseguimos \u201cseparar\u201d a informa\u00e7\u00e3o relevante da informa\u00e7\u00e3o redundante</li> </ul> </li> </ul>"},{"location":"aulas/IA/lab04/reducao_dimensionalidade_pca.html#pca-principal-component-analysis","title":"PCA : Principal Component Analysis\u00b6","text":"<p>(An\u00e1lise de Componentes Principais)</p>"},{"location":"aulas/IA/lab04/reducao_dimensionalidade_pca.html#1-gera-a-matriz-de-dados-de-entradas-e-o-vetor-de-classes-alvo-para-treinamento","title":"1 - Gera a matriz de dados de entradas e o vetor de classes alvo para treinamento\u00b6","text":"<p>Cada linha da matriz de entradas (atributos) cont\u00e9m os pixels da  imagem.</p> <p>Cada posi\u00e7\u00e3o do array de r\u00f3tulos (labels) cont\u00e9m a classe alvo da imgem.</p> <p>No caso deste dataset, as imagens de trenamento e de teste j\u00e1 est\u00e3o separadas, e vamos adotar a separa\u00e7\u00e3o sugerida pelo autor da base de dados.</p>"},{"location":"aulas/IA/lab04/reducao_dimensionalidade_pca.html#11-visualizcao-de-uma-imagem","title":"1.1 Visualiz\u00e7\u00e3o de uma imagem\u00b6","text":"<p>Neste dataset cada imagem est\u00e1 armazenada como uma linha da matriz de entrada. Para visualizar a imagem que est\u00e1 na linha <code>i</code> da matriz, temos que convert\u00ea-la novamente em uma matriz quadrada, e usar a biblioteca <code>matplotlib</code></p>"},{"location":"aulas/IA/lab04/reducao_dimensionalidade_pca.html#2-faz-a-normalizacao-e-a-reducao-da-dimensionalidade-com-pca","title":"2 - Faz a normaliza\u00e7\u00e3o e a redu\u00e7\u00e3o da dimensionalidade com PCA\u00b6","text":"<p>Instancia o modelo PCA de forma que 85% da variabilidade de dados seja mantida. O m\u00e9todo <code>fit_transform(X)</code> treina o PCA e j\u00e1 traz os dados <code>X</code> transformados. Para reaproveitar o mesmo modelo PCA sem trein\u00e1-o novamente, usamos <code>transform()</code>.</p> <p>Uma vez que os dados de treinamento e teste j\u00e1 est\u00e3o separados,treinamos o normalizador e o PCA com os dados de treinamento, e apenas aplicamos a transforma\u00e7\u00e3o nos dados de teste.</p>"},{"location":"aulas/IA/lab04/reducao_dimensionalidade_pca.html#21-visualizacao-das-16-primairas-imagens-principais","title":"2.1 - Visualiza\u00e7\u00e3o das 16 primairas imagens principais\u00b6","text":"<p>O PCA neste caso transforma um array (entrada ou linha da matriz) composta por um conjunto de pixels em um outro array que indica a composi\u00e7\u00e3o da imagem em termos de \"imagens principais\"</p>"},{"location":"aulas/IA/lab04/reducao_dimensionalidade_pca.html#desafio-3","title":"Desafio 3\u00b6","text":"<p>Agora \u00e9 com voc\u00ea termine a implementa\u00e7ao deste classificador de digitos usando o KNN. Usar as novas matrizes no treinamento, teste e avalia\u00e7\u00e3o do classificador</p>"},{"location":"aulas/IA/lab05/validacaocruzada.html","title":"Valida\u00e7\u00e3o de Modelos","text":"In\u00a0[52]: Copied! <pre>from sklearn.datasets import load_iris\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn import metrics                 \n</pre> from sklearn.datasets import load_iris from sklearn.model_selection import train_test_split from sklearn.neighbors import KNeighborsClassifier from sklearn import metrics                  In\u00a0[53]: Copied! <pre># importa o dataset iris\niris = load_iris()\n\n# separa os dados em atributos (x) e alvo (y)\nX = iris.data\ny = iris.target\n</pre> # importa o dataset iris iris = load_iris()  # separa os dados em atributos (x) e alvo (y) X = iris.data y = iris.target In\u00a0[78]: Copied! <pre># divide os dados em treino e teste\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=7)\n\n# treina o modelo com knn=15\nknn = KNeighborsClassifier(n_neighbors=15)\nknn.fit(X_train, y_train)\ny_pred = knn.predict(X_test)\n\n# resultado da acuracia\nmetrics.accuracy_score(y_test, y_pred)\n</pre> # divide os dados em treino e teste X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=7)  # treina o modelo com knn=15 knn = KNeighborsClassifier(n_neighbors=15) knn.fit(X_train, y_train) y_pred = knn.predict(X_test)  # resultado da acuracia metrics.accuracy_score(y_test, y_pred) Out[78]: <pre>0.9</pre> In\u00a0[85]: Copied! <pre>from sklearn.model_selection import KFold\n\ncrossvalidation = KFold(n_splits=10,shuffle=True, random_state=7)\n\nknn = KNeighborsClassifier(n_neighbors=5)\n</pre> from sklearn.model_selection import KFold  crossvalidation = KFold(n_splits=10,shuffle=True, random_state=7)  knn = KNeighborsClassifier(n_neighbors=5) In\u00a0[86]: Copied! <pre>from sklearn.model_selection import cross_val_score\n\nscores = cross_val_score(knn, X, y, cv=crossvalidation, scoring='accuracy')\nprint(\"Array do kfold com os resultados: \",scores)\n</pre> from sklearn.model_selection import cross_val_score  scores = cross_val_score(knn, X, y, cv=crossvalidation, scoring='accuracy') print(\"Array do kfold com os resultados: \",scores) <pre>Array do kfold com os resultados:  [0.86666667 0.86666667 1.         1.         1.         1.\n 1.         0.93333333 0.93333333 0.93333333]\n</pre> In\u00a0[87]: Copied! <pre>print(\"Acuracia m\u00e9dia com kfold: \",scores.mean())\n</pre> print(\"Acuracia m\u00e9dia com kfold: \",scores.mean()) <pre>Acuracia m\u00e9dia com kfold:  0.9533333333333334\n</pre> In\u00a0[88]: Copied! <pre>## implemente aqui....\n</pre> ## implemente aqui....     In\u00a0[\u00a0]: Copied! <pre>from sklearn.model_selection import KFold, StratifiedKFold, ShuffleSplit\n</pre> from sklearn.model_selection import KFold, StratifiedKFold, ShuffleSplit"},{"location":"aulas/IA/lab05/validacaocruzada.html#2-aprendizagem-de-maquina","title":"2. Aprendizagem de m\u00e1quina\u00b6","text":""},{"location":"aulas/IA/lab05/validacaocruzada.html#objetivos","title":"Objetivos\u00b6","text":"<ul> <li>Entender e praticar valida\u00e7\u00e3o cruzada: kfold.</li> </ul>"},{"location":"aulas/IA/lab05/validacaocruzada.html#validacao-cruzada","title":"Valida\u00e7\u00e3o Cruzada\u00b6","text":"<p>A t\u00e9cnica de valida\u00e7\u00e3o cruzada consiste em dividir em partes pequenas (fold) a base de dados e realizar diversos treinamentos e valida\u00e7\u00f5es com partes diferente de treinamento e teste, ao final \u00e9 feita a m\u00e9dia e o desvio padr\u00e3o do aprendizado.</p> <p>Pr\u00f3s:</p> <ul> <li>Normalmente aumenta a performance do modelo.</li> <li>Reduz aleatoriedade, reduz viez.</li> </ul> <p>Contra:</p> <ul> <li>Mais processamento computacional.</li> </ul> <p>Dicas:</p> <ul> <li>A escolha do <code>k</code> numero de folds \u00e9 determinada tipicamente como sendo 5 ou 10.</li> </ul>"},{"location":"aulas/IA/lab05/validacaocruzada.html#diagrama-do-kfold","title":"Diagrama do kfold\u00b6","text":""},{"location":"aulas/IA/lab05/validacaocruzada.html#melhorando-o-modelo","title":"Melhorando o modelo\u00b6","text":"<p>At\u00e9 aqui, sem novidades! Mas... como ficaria o resultado se os grupos de teste e treino fossem alterados? vamos descobrir usando o kfold.</p>"},{"location":"aulas/IA/lab05/validacaocruzada.html#pergunta-o-resultado-foi-praticamente-o-mesmo-por-que","title":"Pergunta: O Resultado foi praticamente o mesmo, por que?\u00b6","text":""},{"location":"aulas/IA/lab05/validacaocruzada.html#desafio-implementamos-kfold-para-o-classificador-knn-implemente-kfold-para-um-modelo-de-regressao","title":"Desafio: Implementamos kfold para o classificador KNN, implemente kfold para um modelo de regress\u00e3o\u00b6","text":""},{"location":"aulas/IA/lab05/validacaocruzada.html#bonus-outras-tecnicas-de-avaliacao-de-modelo","title":"Bonus: Outras t\u00e9cnicas de avalia\u00e7\u00e3o de modelo\u00b6","text":"<ul> <li><p><code>StratifiedKFold</code> = Lida melhor com dados desbalanceados, ou seja, possui uma difer\u00e7a grande entre as frequencias das classes, pois tentar manter a mesma propor\u00e7\u00e3o em todos os folds.</p> </li> <li><p><code>ShuffleSplit</code> = Gera folds aleatorios de treino e teste a cada itera\u00e7\u00e3o. Um cuidado, pode ser que entre uma itera\u00e7\u00e3o e outra os mesmos dados sejam selecionados</p> </li> </ul>"},{"location":"aulas/IA/lab06/backpropagation.html","title":"Backpropagation","text":""},{"location":"aulas/IA/lab06/backpropagation.html#introducao","title":"Introdu\u00e7\u00e3o","text":"<p>Sabemos que redes neurais s\u00e3o como calculadoras especializadas que podem resolver problemas complexos. Mas uma pergunta ficou no ar: como elas aprendem? Como uma rede neural descobre quais pesos usar para acertar as respostas?</p> <p>Pense em ensinar um amigo a cobrar p\u00eanaltis. N\u00e3o adianta dizer apenas \u201cchute melhor\u201d, isso \u00e9 vago demais. \u00c9 preciso dar instru\u00e7\u00f5es precisas, como: \u201cmire um pouco mais para a esquerda\u201d, \u201creduza a for\u00e7a do chute\u201d ou \u201cajuste o \u00e2ngulo do p\u00e9\u201d.</p> <p>O backpropagation faz exatamente isso, mas para redes neurais: \u00e9 um m\u00e9todo sistem\u00e1tico para indicar a cada neur\u00f4nio o quanto e em que dire\u00e7\u00e3o ajustar seus par\u00e2metros, a fim de melhorar o resultado final.</p> <p>Este algoritmo revolucionou a intelig\u00eancia artificial e \u00e9 a base de praticamente tudo que vemos hoje em IA, desde reconhecimento de voz at\u00e9 carros aut\u00f4nomos!</p> <p></p>"},{"location":"aulas/IA/lab06/backpropagation.html#o-problema-do-aprendizado","title":"O problema do aprendizado","text":"<p>Encontrar os pesos para um perceptron \u00e9 f\u00e1cil porque h\u00e1 apenas um neur\u00f4nio. Mas em uma rede com v\u00e1rias camadas, surge um problema: como saber qual neur\u00f4nio da camada oculta \u00e9 respons\u00e1vel pelo erro?</p> <p>\u00c9 como tentar descobrir qual jogador de um time de futebol errou quando o time perde \u2014 pode ter sido o goleiro, o zagueiro, o meio-campo ou o atacante. Todos contribu\u00edram para o resultado final!</p> Por que o algoritmo de aprendizado do Perceptron n\u00e3o funciona diretamente em redes multicamadas?Porque redes multicamadas s\u00e3o muito lentasPorque usa muita mem\u00f3ria computacionalPorque n\u00e3o sabemos como atribuir responsabilidade pelo erro aos neur\u00f4nios das camadas ocultasPorque as fun\u00e7\u00f5es de ativa\u00e7\u00e3o s\u00e3o diferentesSubmit Em redes multicamadas, todos os neur\u00f4nios contribuem para o resultado final, tornando dif\u00edcil saber exatamente como ajustar cada peso individual quando h\u00e1 um erro na sa\u00edda."},{"location":"aulas/IA/lab06/backpropagation.html#o-backpropagation","title":"O Backpropagation","text":"<p>A solu\u00e7\u00e3o \u00e9 propagar o erro de volta atrav\u00e9s da rede, camada por camada. \u00c9 como rastrear a origem de um problema:</p> <ol> <li>Calcule o erro na sa\u00edda (o quanto erramos)</li> <li>Distribua a \"culpa\" para a \u00faltima camada oculta</li> <li>Continue distribuindo para as camadas anteriores</li> <li>Ajuste os pesos baseado na \"responsabilidade\" de cada um</li> </ol> <p>\u00c9 como investigar um acidente: voc\u00ea come\u00e7a pelo resultado e vai voltando para descobrir todas as causas que contribu\u00edram.</p>"},{"location":"aulas/IA/lab06/backpropagation.html#intuicao-matematica","title":"Intui\u00e7\u00e3o Matem\u00e1tica","text":""},{"location":"aulas/IA/lab06/backpropagation.html#funcao-de-perda-loss-e-entropia-cruzada-binaria-bce","title":"Fun\u00e7\u00e3o de Perda (Loss) e Entropia Cruzada Bin\u00e1ria (BCE)Qual \u00e9 o objetivo principal da fun\u00e7\u00e3o de custo no backpropagation?","text":"<p>Em redes neurais, o treinamento envolve ajustar os par\u00e2metros (pesos e biases) para que o modelo produza sa\u00eddas o mais pr\u00f3ximas poss\u00edvel das sa\u00eddas desejadas. Para guiar esse ajuste, precisamos de uma m\u00e9trica quantitativa que capture <code>o quanto o modelo est\u00e1 errando</code>. Essa m\u00e9trica \u00e9 a fun\u00e7\u00e3o de perda (ou fun\u00e7\u00e3o de custo, loss function), que mede a discrep\u00e2ncia entre as predi\u00e7\u00f5es do modelo (\\hat{y}) e os r\u00f3tulos verdadeiros (y).</p> <p>Suponha uma tarefa de regress\u00e3o linear, onde queremos prever um valor cont\u00ednuo. Uma fun\u00e7\u00e3o de perda comum \u00e9 o erro quadr\u00e1tico m\u00e9dio (Mean Squared Error, MSE):</p> <ul> <li> <p>Para um \u00fanico exemplo i:   $$   \\ell(\\hat{y}^{(i)}, y^{(i)}) = \\left( y^{(i)} - \\hat{y}^{(i)} \\right)^2   $$</p> </li> <li> <p>Para um lote (batch) de m exemplos:   $$   J = \\frac{1}{m} \\sum_{i=1}^{m} \\ell\\left( \\hat{y}^{(i)}, y^{(i)} \\right) = \\frac{1}{m} \\sum_{i=1}^{m} \\left( y^{(i)} - \\hat{y}^{(i)} \\right)^2   $$</p> </li> </ul> <p>Aqui, o quadrado garante que erros positivos e negativos n\u00e3o se cancelem, e penaliza erros maiores de forma quadr\u00e1tica (ou seja, um erro de 2 \u00e9 penalizado 4 vezes mais que um erro de 1, incentivando o modelo a evitar grandes desvios).</p> <p>Requisitos para uma Boa Fun\u00e7\u00e3o de Perda</p> <p>A fun\u00e7\u00e3o de perda deve ser diferenci\u00e1vel (quase em todos os pontos) para permitir o c\u00e1lculo de gradientes via backpropagation. Al\u00e9m disso, ela deve ser convexa ou quasi-convexa em problemas ideais, facilitando a converg\u00eancia para um m\u00ednimo global. O objetivo do treinamento \u00e9 minimizar J ajustando os pesos \\theta do modelo: $$ \\theta^* = \\arg\\min_{\\theta} J(\\theta) $$ Usamos otimiza\u00e7\u00e3o baseada em gradientes para isso, como o <code>Gradiente Descendente</code>.</p> <p>Agora, foquemos em tarefas de classifica\u00e7\u00e3o bin\u00e1ria, onde y \\in \\{0, 1\\} (ex.: \"\u00e9 spam ou n\u00e3o?\"). Aqui, a sa\u00edda do modelo \u00e9 tipicamente uma probabilidade \\hat{y} = \\sigma(z) \\in (0,1), onde \\sigma \u00e9 a fun\u00e7\u00e3o Sigmoid aplicada ao logit z (sa\u00edda linear antes da ativa\u00e7\u00e3o).  A fun\u00e7\u00e3o de perda tipica \u00e9 a Entropia Cruzada Bin\u00e1ria (Binary Cross-Entropy, BCE) ou log loss:</p>  \\ell_{\\text{BCE}}(y, \\hat{y}) = -\\left[ y \\log(\\hat{y}) + (1 - y) \\log(1 - \\hat{y}) \\right]  <ul> <li> <p>Interpreta\u00e7\u00e3o Probabil\u00edstica: A BCE deriva do negativo do logaritmo da verossimilhan\u00e7a (negative log-likelihood) sob uma distribui\u00e7\u00e3o de Bernoulli. Se y=1, a perda penaliza quando \\hat{y} est\u00e1 longe de 1 (ou seja, \\log(\\hat{y}) \u00e9 muito negativo se \\hat{y} for pequeno). Se y=0, penaliza quando \\hat{y} est\u00e1 longe de 0. Isso incentiva predi\u00e7\u00f5es \"confiantes\" apenas quando corretas; predi\u00e7\u00f5es erradas e confiantes (ex.: \\hat{y}=0.99 quando y=0) recebem penalidades altas devido ao logaritmo.</p> </li> <li> <p>Deriva\u00e7\u00e3o R\u00e1pida do Gradiente: Uma propriedade chave da BCE combinada com Sigmoid \u00e9 a simplifica\u00e7\u00e3o do gradiente. Vamos derivar brevemente:   A perda em termos do logit z \u00e9 \\ell(y, \\sigma(z)) = -[y \\log(\\sigma(z)) + (1-y) \\log(1 - \\sigma(z))].   Usando a regra da cadeia:   $$   \\frac{\\partial \\ell}{\\partial z} = \\frac{\\partial \\ell}{\\partial \\hat{y}} \\cdot \\frac{\\partial \\hat{y}}{\\partial z} = \\left( \\frac{\\hat{y} - y}{\\hat{y}(1 - \\hat{y})} \\right) \\cdot \\hat{y}(1 - \\hat{y}) = \\hat{y} - y   $$   Essa simplifica\u00e7\u00e3o torna o backpropagation computacionalmente eficiente e numericamente est\u00e1vel, evitando problemas como vanishing gradients em camadas profundas.</p> </li> </ul> <p>Para um batch: $$ J_{\\text{BCE}} = \\frac{1}{m} \\sum_{i=1}^{m} \\ell_{\\text{BCE}}(y^{(i)}, \\hat{y}^{(i)}) $$</p> <p>Extens\u00e3o para Classifica\u00e7\u00e3o Multiclasse</p> <p>Para K classes, use a ativa\u00e7\u00e3o softmax na sa\u00edda final (\\hat{y}_k = \\frac{e^{z_k}}{\\sum_{j=1}^K e^{z_j}}) e a Entropia Cruzada Categ\u00f3rica: $$ \\ell_{\\text{CE}}(y, \\hat{y}) = -\\sum_{k=1}^K y_k \\log(\\hat{y}_k) $$ onde y \u00e9 um vetor one-hot. O gradiente em rela\u00e7\u00e3o aos logits tamb\u00e9m simplifica para \\frac{\\partial \\ell}{\\partial z_k} = \\hat{y}_k - y_k, facilitando o treinamento.</p> Acelerar o treinamento da rede neuralEscolher a melhor arquitetura de redeMedir quantitativamente o erro para guiar o ajuste dos pesosDeterminar o n\u00famero ideal de neur\u00f4niosSubmit A fun\u00e7\u00e3o de custo quantifica o erro da rede, fornecendo uma m\u00e9trica clara de qu\u00e3o distantes estamos do resultado desejado, permitindo ajustar os pesos na dire\u00e7\u00e3o correta via gradientes."},{"location":"aulas/IA/lab06/backpropagation.html#o-gradiente-a-direcao-da-mudanca","title":"O Gradiente: A Dire\u00e7\u00e3o da Mudan\u00e7a","text":"<p>O gradiente de uma fun\u00e7\u00e3o J(\\theta) em rela\u00e7\u00e3o aos par\u00e2metros \\theta \u00e9 um vetor que aponta na dire\u00e7\u00e3o de maior aumento de J. Para minimizar J, movemos na dire\u00e7\u00e3o oposta (descida). Matematicamente, para um par\u00e2metro \\theta_j: $$ \\frac{\\partial J}{\\partial \\theta_j} $$ representa quanto J muda se alterarmos \\theta_j infinitesimalmente.</p> <p>Analogia da Montanha (com Toque T\u00e9cnico): Imagine J(\\theta) como uma superf\u00edcie montanhosa em um espa\u00e7o de alta dimensionalidade (cada dimens\u00e3o \u00e9 um par\u00e2metro \\theta). Voc\u00ea est\u00e1 em um ponto \\theta atual, envolto em neblina (sem vis\u00e3o global). O gradiente \\nabla J(\\theta) \u00e9 como uma b\u00fassola que mede a inclina\u00e7\u00e3o local mais \u00edngreme para cima. Para descer, siga -\\nabla J(\\theta). Em cada passo, recalcule o gradiente localmente \u2014 isso \u00e9 o Gradiente Descendente Estoc\u00e1stico (SGD) ou variantes como Adam.</p> <p></p> <p>Em redes neurais, o gradiente \u00e9 computado via backpropagation: propagamos o erro da sa\u00edda para as camadas anteriores, usando a regra da cadeia para calcular derivadas parciais em cada peso.</p>"},{"location":"aulas/IA/lab06/backpropagation.html#regra-de-atualizacao-dos-pesos","title":"Regra de Atualiza\u00e7\u00e3o dos Pesos","text":"<p>A atualiza\u00e7\u00e3o dos pesos segue o Gradiente Descendente: $$ \\theta_{\\text{novo}} = \\theta_{\\text{antigo}} - \\eta \\cdot \\nabla J(\\theta) $$ onde \\eta (se pronuncia eta) \u00e9 a taxa de aprendizado (learning rate), controlando o tamanho do passo.</p> <ul> <li>Escolha de \\eta:  </li> <li>Muito grande: Pode oscilar ou divergir (ex.: \"pular\" sobre o m\u00ednimo).  </li> <li>Muito pequeno: Converg\u00eancia lenta, risco de ficar preso em m\u00ednimos locais.   Solu\u00e7\u00f5es comuns: Agendadores de learning rate (ex.: decaimento exponencial) ou otimizadores adaptativos como Adam, que ajustam \\eta por par\u00e2metro com base em momentos de gradientes passados.</li> </ul> <p>Em pr\u00e1tica, para estabilidade, usamos mini-batches (SGD) em vez de batches completos, introduzindo ru\u00eddo que ajuda a escapar de m\u00ednimos locais. Variantes avan\u00e7adas incluem momentum (acelera em dire\u00e7\u00f5es consistentes) e RMSProp (normaliza gradientes em dimens\u00f5es vari\u00e1veis).</p>"},{"location":"aulas/IA/lab06/backpropagation.html#o-algoritmo-passo-a-passo","title":"O algoritmo passo a passo","text":"<ol> <li> <p>Propaga\u00e7\u00e3o direta (forward pass):</p> <ul> <li>Os dados de entrada percorrem a rede camada por camada, gerando a sa\u00edda final.</li> </ul> </li> <li> <p>C\u00e1lculo do erro:  </p> <ul> <li>Compara\u00e7\u00e3o entre a sa\u00edda prevista e a sa\u00edda real usando uma fun\u00e7\u00e3o de custo (ex.: erro quadr\u00e1tico m\u00e9dio).</li> </ul> <p><pre><code>Input \u2192 Camada1 \u2192 Camada2 \u2192 ... \u2192 Output \u2192 Calcular_Erro\n</code></pre> 3. Propaga\u00e7\u00e3o reversa (backward pass):  </p> <ul> <li>O erro \u00e9 propagado de volta pela rede, calculando o gradiente de cada peso em rela\u00e7\u00e3o ao erro.</li> </ul> </li> <li> <p>Atualiza\u00e7\u00e3o dos pesos:  </p> <ul> <li>Cada peso \u00e9 ajustado na dire\u00e7\u00e3o que reduz o erro, de acordo com a taxa de aprendizado.</li> </ul> <pre><code>Ajustar_Pesos \u2190 ... \u2190 Camada2 \u2190 Camada1 \u2190 Calcular_Gradientes \u2190 Erro\n</code></pre> </li> </ol>"},{"location":"aulas/IA/lab06/backpropagation.html#exercicio-interativo-passo-a-passo-do-backpropagation","title":"Exerc\u00edcio Interativo \u2013 Passo a passo do Backpropagation","text":"<p>Neste exerc\u00edcio, voc\u00ea pode controlar a execu\u00e7\u00e3o do backpropagation e visualizar:</p> <ul> <li>Como as ativa\u00e7\u00f5es s\u00e3o calculadas na propaga\u00e7\u00e3o direta.</li> <li>Como o erro se espalha de volta na propaga\u00e7\u00e3o reversa.</li> <li>Como cada peso \u00e9 atualizado ap\u00f3s cada passo.</li> </ul> <p>Controles dispon\u00edveis:</p> <ul> <li>Taxa de aprendizado (learning rate): Ajuste para ver como afeta a converg\u00eancia.</li> <li>Fun\u00e7\u00e3o de ativa\u00e7\u00e3o: Escolha entre <code>Sigmoid</code>, <code>Tanh</code> e <code>ReLU</code>.</li> <li>Bot\u00e3o \"Pr\u00f3ximo passo\": Avan\u00e7a o backpropagation de forma manual.</li> <li>Bot\u00e3o \"Treinar autom\u00e1tico\": Executa v\u00e1rias itera\u00e7\u00f5es seguidas.</li> <li>Mostrar gradientes: Ativa setas e valores num\u00e9ricos sobre cada peso.</li> </ul> <p>Objetivo:  </p> <p>Familiarizar-se com o funcionamento interno do backpropagation e entender o impacto da taxa de aprendizado e da fun\u00e7\u00e3o de ativa\u00e7\u00e3o no treinamento.</p> Backpropagation \u2013 Passo a Passo Taxa de aprendizado (\u03b7): 0.10 Fun\u00e7\u00e3o de ativa\u00e7\u00e3o Sigmoid Tanh ReLU Pr\u00f3ximo passo Treinar autom\u00e1tico Reset \u00c9poca: 0 Erro (MSE): \u2014 Sa\u00edda prevista: \u2014 Alvo (y): 1 Erro absoluto |\u0177 \u2212 y|: \u2014 Gradientes: <pre>\u2014</pre> Curva de perda (MSE) <p>Para uma rede 2\u20132\u20131 com sa\u00edda Sigmoid e MSE: $$ L=\\tfrac12(y - \\hat y)^2 \\hat y=\\sigma(z_2) z_2 = v_1 a_1 + v_2 a_2 + c  a_i = g(z_i), z_i = w_{i1}x_1 + w_{i2}x_2 + b_i $$</p> <p>As equa\u00e7\u00f5es a seguir mostram como o erro \u00e9 propagado da camada de sa\u00edda para as camadas anteriores:</p>  \\begin{align} \\frac{\\partial \\ell}{\\partial z_2} &amp;= (\\hat{y} - y) \\cdot \\sigma'(z_2) \\ \\frac{\\partial \\ell}{\\partial v_i} &amp;= a_i \\cdot \\frac{\\partial \\ell}{\\partial z_2} \\ \\frac{\\partial \\ell}{\\partial a_i} &amp;= v_i \\cdot \\frac{\\partial \\ell}{\\partial z_2} \\ \\frac{\\partial \\ell}{\\partial z_i} &amp;= \\frac{\\partial \\ell}{\\partial a_i} \\cdot g'(z_i) \\ \\frac{\\partial \\ell}{\\partial w_{ij}} &amp;= x_j \\cdot \\frac{\\partial \\ell}{\\partial z_i} \\end{align}  <p>Essas equa\u00e7\u00f5es formam a base do algoritmo de backpropagation, permitindo que os gradientes sejam calculados camada por camada, da sa\u00edda para a entrada, para atualizar os pesos da rede neural de forma eficiente.</p> <p>Reflex\u00e3o:</p> <ol> <li>O que acontece quando a taxa de aprendizado \u00e9 muito alta? E quando \u00e9 muito baixa?</li> <li> <p>Compare o comportamento do gradiente com Sigmoid, Tanh e ReLU.  </p> </li> <li> <p>Em qual caso o gradiente tende a \"desaparecer\" (vanishing gradient)?</p> </li> <li> <p>Em qual caso o gradiente \u00e9 mais est\u00e1vel?</p> </li> <li> <p>Como o n\u00famero de passos influencia na converg\u00eancia do erro?</p> </li> <li> <p>Observe o gr\u00e1fico de erro:</p> </li> <li> <p>Ele desce de forma suave ou com oscila\u00e7\u00f5es?</p> </li> <li>H\u00e1 momentos em que o treinamento \"trava\"?</li> </ol> Por que o backpropagation calcula gradientes \"de tr\u00e1s para frente\"?Porque \u00e9 mais r\u00e1pido computacionalmentePorque usa menos mem\u00f3riaPorque o erro na sa\u00edda \u00e9 conhecido, facilitando o c\u00e1lculo dos gradientes das camadas anterioresPorque as camadas ocultas s\u00e3o mais importantesSubmit Come\u00e7amos pela sa\u00edda porque conhecemos o erro desejado ali. Isso permite calcular como cada camada anterior contribuiu para esse erro, propagando a informa\u00e7\u00e3o de volta pela rede."},{"location":"aulas/IA/lab06/backpropagation.html#pseudocodigo","title":"Pseudoc\u00f3digo","text":"<pre><code># Algoritmo Backpropagation Simplificado\n\ndef treinar_rede(rede, dados_treino, taxa_aprendizado):\n    for cada_\u00e9poca:\n        for cada_exemplo in dados_treino:\n\n            # FORWARD PASS (predi\u00e7\u00e3o)\n            entrada = exemplo.dados\n            for camada in rede:\n                entrada = camada.processar(entrada)\n            sa\u00edda_predita = entrada\n\n            # CALCULAR ERRO\n            erro = exemplo.resposta_correta - sa\u00edda_predita\n\n            # BACKWARD PASS\n            gradiente = calcular_gradiente_sa\u00edda(erro)\n            for camada in reversed(rede):\n                gradiente = camada.calcular_gradiente(gradiente)\n                camada.atualizar_pesos(gradiente, taxa_aprendizado)\n</code></pre> <p>Regra da cadeia</p> <p>O backpropagation usa a regra da cadeia do c\u00e1lculo para \"quebrar\" gradientes complexos em peda\u00e7os menores.</p>"},{"location":"aulas/IA/lab06/backpropagation.html#funcoes-de-ativacao-e-derivadas","title":"Fun\u00e7\u00f5es de ativa\u00e7\u00e3o e derivadas","text":"<p>Por que ReLU \u00e9 t\u00e3o popular? Sua derivada \u00e9 super simples:</p> <pre><code>ReLU(x) = max(0, x)\nDerivada = { 1 se x &gt; 0\n           { 0 se x \u2264 0\n</code></pre> <p>Sigmoid tem derivada mais complicada, tornando o c\u00e1lculo mais lento.</p> <p>Loss em classifica\u00e7\u00e3o bin\u00e1ria</p> <ul> <li>Did\u00e1tico (ok para este exerc\u00edcio): MSE com sa\u00edda Sigmoid.  </li> <li>Pr\u00e1tica comum: Entropia Cruzada Bin\u00e1ria (BCE) com sa\u00edda Sigmoid \u2014 converge mais r\u00e1pido e com gradientes mais est\u00e1veis.</li> </ul> Por que a derivada da fun\u00e7\u00e3o de ativa\u00e7\u00e3o \u00e9 importante no backpropagation?Para determinar o n\u00famero de neur\u00f4nios necess\u00e1riosPara escolher a arquitetura da redePara calcular como o erro se propaga atrav\u00e9s de cada neur\u00f4nioPara definir a taxa de aprendizado idealSubmit A derivada da fun\u00e7\u00e3o de ativa\u00e7\u00e3o \u00e9 essencial para aplicar a regra da cadeia e calcular como pequenas mudan\u00e7as nos pesos afetam o erro final da rede."},{"location":"aulas/IA/lab06/backpropagation.html#problemas-comuns-e-solucoes","title":"Problemas comuns e solu\u00e7\u00f5es","text":""},{"location":"aulas/IA/lab06/backpropagation.html#1-vanishing-gradients-gradientes-que-somem","title":"1. Vanishing Gradients (gradientes que somem)","text":"<p>Problema: Em redes neurais com muitas camadas, o gradiente (que \u00e9 a informa\u00e7\u00e3o sobre o qu\u00e3o r\u00e1pido a rede est\u00e1 aprendendo) se torna extremamente pequeno \u00e0 medida que volta para as primeiras camadas. Isso faz com que os pesos nessas camadas iniciais sejam atualizados de forma muito lenta, impedindo a rede de aprender de maneira eficaz. \u00c9 como se a informa\u00e7\u00e3o de erro se \"evaporasse\" antes de chegar onde \u00e9 mais necess\u00e1ria.</p> <p>Solu\u00e7\u00f5es:</p> <ul> <li><code>Fun\u00e7\u00f5es de Ativa\u00e7\u00e3o</code>: Troque fun\u00e7\u00f5es como a Sigmoid ou tanh por ReLU (Rectified Linear Unit), que n\u00e3o \"sufoca\" o gradiente.</li> <li><code>Inicializa\u00e7\u00e3o de Pesos</code>: Comece o treinamento com pesos que n\u00e3o sejam nem muito grandes, nem muito pequenos. T\u00e9cnicas como a inicializa\u00e7\u00e3o de <code>He</code> ou de Xavier ajudam a manter os gradientes saud\u00e1veis.</li> <li><code>Normaliza\u00e7\u00e3o de Batch (Batch Normalization)</code>: Essa t\u00e9cnica ajusta as ativa\u00e7\u00f5es dentro da rede, garantindo que os dados que fluem entre as camadas mantenham uma distribui\u00e7\u00e3o est\u00e1vel.</li> <li><code>Conex\u00f5es de Salto (Skip Connections)</code>: Em arquiteturas como a ResNet, as camadas \"pulam\" e se conectam diretamente a camadas posteriores, criando um \"caminho alternativo\" para que o gradiente flua sem ser enfraquecido.</li> </ul>"},{"location":"aulas/IA/lab06/backpropagation.html#2-exploding-gradients-gradientes-que-explodem","title":"2. Exploding Gradients (gradientes que explodem)","text":"<p>Problema: \u00c9 o oposto do anterior. O gradiente se torna extremamente grande, levando a atualiza\u00e7\u00f5es massivas e inst\u00e1veis nos pesos. Isso faz com que o modelo \"exploda\", e o treinamento n\u00e3o converge.</p> <p>Solu\u00e7\u00f5es:</p> <ul> <li><code>Corte de Gradiente (Gradient Clipping)</code>: Simplesmente \"corte\" o gradiente quando ele atingir um valor muito alto, limitando-o a um limite pr\u00e9-definido.</li> <li><code>Taxa de Aprendizado (Learning Rate) Menor</code>: Reduza a taxa de aprendizado para que as atualiza\u00e7\u00f5es de peso sejam mais graduais e menos propensas a \"explodir\".</li> <li><code>Inicializa\u00e7\u00e3o Melhor</code>: A mesma solu\u00e7\u00e3o para o problema de \"vanishing gradients\" tamb\u00e9m ajuda a prevenir as explos\u00f5es.</li> </ul>"},{"location":"aulas/IA/lab06/backpropagation.html#3-overfitting","title":"3. OverfittingO que caracteriza o problema de \"vanishing gradients\"?","text":"<p>Problema: O modelo aprende os dados de treinamento com perfei\u00e7\u00e3o, mas n\u00e3o consegue generalizar para novos dados. \u00c9 como um aluno que memoriza as respostas da prova, mas n\u00e3o entende a mat\u00e9ria. O modelo se torna bom demais nos dados que j\u00e1 viu, mas falha em aplicar o conhecimento em situa\u00e7\u00f5es novas.</p> <p>Solu\u00e7\u00f5es:</p> <ul> <li><code>Aumente os Dados</code>: A maneira mais eficaz de evitar o overfitting \u00e9 dar mais exemplos de treinamento para o modelo.</li> <li><code>Dropout</code>: Durante o treinamento, essa t\u00e9cnica \"desliga\" aleatoriamente alguns neur\u00f4nios em cada itera\u00e7\u00e3o. Isso for\u00e7a a rede a n\u00e3o depender de neur\u00f4nios espec\u00edficos, tornando-a mais robusta.</li> <li><code>Regulariza\u00e7\u00e3o (L1/L2)</code>: Adicione uma \"penalidade\" \u00e0 fun\u00e7\u00e3o de perda para desincentivar pesos muito grandes. Isso ajuda a manter o modelo mais simples e com maior poder de generaliza\u00e7\u00e3o.</li> <li><code>Parada Antecipada (Early Stopping)</code>: Monitore a performance do modelo em um conjunto de valida\u00e7\u00e3o e pare o treinamento assim que a performance come\u00e7ar a piorar.</li> </ul> A rede aprende muito rapidamenteOs pesos ficam muito grandesOs gradientes se tornam muito pequenos nas camadas iniciais de redes profundasA fun\u00e7\u00e3o de custo aumenta durante o treinamentoSubmit Vanishing gradients ocorre quando gradientes se tornam exponencialmente menores \u00e0 medida que se propagam para tr\u00e1s, fazendo com que as primeiras camadas aprendam muito lentamente ou parem de aprender."},{"location":"aulas/IA/lab06/backpropagation.html#otimizadores","title":"Otimizadores","text":"<p>SGD (Stochastic Gradient Descent): O b\u00e1sico <pre><code>peso = peso - taxa_aprendizado \u00d7 gradiente\n</code></pre></p> <p>Momentum: Adiciona \"in\u00e9rcia\" <pre><code>velocidade = momentum \u00d7 velocidade_anterior + gradiente\npeso = peso - taxa_aprendizado \u00d7 velocidade\n</code></pre></p> <p>Adam: Adapta taxa de aprendizado automaticamente</p> <ul> <li>Muito popular atualmente</li> <li>Combina momentum com adapta\u00e7\u00e3o autom\u00e1tica</li> </ul>"},{"location":"aulas/IA/lab06/backpropagation.html#learning-rate-scheduling","title":"Learning Rate SchedulingQual \u00e9 a ideia central do algoritmo backpropagation?Por que a taxa de aprendizado \u00e9 um hiperpar\u00e2metro cr\u00edtico?O que diferencia o backpropagation do aprendizado do Perceptron simples?","text":"<ul> <li>Step decay: Reduz taxa periodicamente</li> <li>Exponential decay: Reduz exponencialmente</li> <li>Cosine annealing: Varia como coseno</li> </ul> Treinar apenas a \u00faltima camada da redeUsar apenas exemplos positivos para treinarPropagar o erro da sa\u00edda de volta atrav\u00e9s da rede para ajustar todos os pesosTreinar cada camada separadamenteSubmit Backpropagation propaga o erro calculado na sa\u00edda de volta atrav\u00e9s de todas as camadas, permitindo que cada peso seja ajustado proporcionalmente \u00e0 sua contribui\u00e7\u00e3o para o erro final. Porque determina o n\u00famero de camadas da redePorque escolhe a fun\u00e7\u00e3o de ativa\u00e7\u00e3oPorque controla o tamanho dos ajustes nos pesos durante o treinamentoPorque define quantos dados usar para treinarSubmit A taxa de aprendizado determina qu\u00e3o grandes s\u00e3o os passos de otimiza\u00e7\u00e3o. Muito alta pode causar instabilidade, muito baixa torna o aprendizado lento demais. Backpropagation \u00e9 mais lentoBackpropagation usa menos mem\u00f3riaBackpropagation pode treinar redes com m\u00faltiplas camadas ocultasBackpropagation funciona apenas com ReLUSubmit Enquanto o Perceptron s\u00f3 consegue ajustar pesos de uma \u00fanica camada, backpropagation resolve o problema de como treinar todas as camadas de uma rede neural profunda simultaneamente."},{"location":"aulas/IA/lab06/redesneurais.html","title":"Redes Neurais Artificiais","text":""},{"location":"aulas/IA/lab06/redesneurais.html#introducao","title":"Introdu\u00e7\u00e3o","text":"<p>Imagine que voc\u00ea est\u00e1 tentando ensinar um computador a reconhecer gatos em fotos. Como voc\u00ea explicaria para uma m\u00e1quina o que torna um gato um gato? As orelhas pontudas? Os bigodes? O formato dos olhos? Essa \u00e9 exatamente a inspira\u00e7\u00e3o por tr\u00e1s das Redes Neurais Artificiais (RNA) \u2014 modelos computacionais que tentam imitar como nosso c\u00e9rebro processa informa\u00e7\u00f5es complexas.</p> <p>As RNAs s\u00e3o uma das fam\u00edlia de arquiteturas de modelos para aprendizado de m\u00e1quina, especialmente \u00fateis quando:</p> <ul> <li>Precisamos capturar padr\u00f5es n\u00e3o lineares complexos que modelos tradicionais n\u00e3o conseguem</li> <li>Temos grandes volumes de dados e queremos que o pr\u00f3prio modelo descubra as caracter\u00edsticas importantes</li> <li>Queremos processar diferentes tipos de informa\u00e7\u00e3o como imagens, texto, \u00e1udio ou s\u00e9ries temporais</li> <li>O problema \u00e9 complexo demais para ser resolvido com regras simples</li> </ul>"},{"location":"aulas/IA/lab06/redesneurais.html#quando-usar-redes-neurais","title":"Quando usar Redes Neurais?Quando as redes neurais s\u00e3o especialmente recomendadas?","text":"<p>Considere RNAs quando: - Os dados mostram rela\u00e7\u00f5es claramente n\u00e3o lineares entre entradas e sa\u00eddas - Voc\u00ea tem muitos dados e alta dimensionalidade  - Precisa de extra\u00e7\u00e3o autom\u00e1tica de caracter\u00edsticas (o modelo descobre sozinho o que \u00e9 importante) - Quer processar m\u00faltiplas modalidades (imagem + texto, por exemplo)</p> <p>Talvez outras t\u00e9cnicas sejam melhores se: - Voc\u00ea tem poucos dados ou o problema \u00e9 simples \u2014 experimente modelos lineares, \u00e1rvores de decis\u00e3o ou kNN primeiro - Precisa de interpretabilidade total \u2014 prefira modelos mais transparentes como \u00e1rvores ou regress\u00e3o linear - Tem pressa para colocar em produ\u00e7\u00e3o \u2014 RNAs precisam de mais tempo para ajuste fino</p> Apenas para problemas simples com poucos dadosSomente quando precisamos de m\u00e1xima interpretabilidadePara problemas com padr\u00f5es n\u00e3o lineares complexos e grandes volumes de dadosExclusivamente para processamento de textoSubmit Redes neurais s\u00e3o boas em cen\u00e1rios com rela\u00e7\u00f5es complexas n\u00e3o lineares, grandes datasets e quando precisamos que o modelo aprenda automaticamente quais caracter\u00edsticas s\u00e3o importantes."},{"location":"aulas/IA/lab06/redesneurais.html#intuicao-rna","title":"Intui\u00e7\u00e3o RNA","text":"<p>Para conhecer um pouco da historia, vale a pena assistir esse v\u00eddeo.</p> <p></p>"},{"location":"aulas/IA/lab06/redesneurais.html#o-neuronio-biologico","title":"O neur\u00f4nio biol\u00f3gicoQual \u00e9 a fun\u00e7\u00e3o principal do soma (corpo celular) no neur\u00f4nio biol\u00f3gico?","text":"<p>Nosso c\u00e9rebro possui cerca de 86 bilh\u00f5es de neur\u00f4nios interconectados. Cada neur\u00f4nio \u00e9 como uma pequena unidade de processamento que:</p> <p></p> <pre><code>Dendritos \u2192 Soma \u2192 Ax\u00f4nio \u2192 Sinapses\n    \u2191        \u2191       \u2191        \u2191\n  Entrada  Processamento  Transmiss\u00e3o  Sa\u00edda\n</code></pre> <p>Como funciona a comunica\u00e7\u00e3o neural:</p> <ol> <li>Dendritos recebem sinais qu\u00edmicos de outros neur\u00f4nios</li> <li>Soma (corpo celular) soma e processa todos esses sinais</li> <li>Se a soma ultrapassa um limiar, o neur\u00f4nio \"dispara\"</li> <li>O sinal el\u00e9trico percorre o ax\u00f4nio</li> <li>Sinapses liberam neurotransmissores para outros neur\u00f4nios</li> </ol> <p>\u00c9 como uma corrente de domin\u00f3s inteligentes \u2014 cada pe\u00e7a decide se vai derrubar a pr\u00f3xima baseado na for\u00e7a do impulso que recebeu!</p> Receber sinais de outros neur\u00f4niosTransmitir sinais para outros neur\u00f4niosIntegrar e processar os sinais recebidosArmazenar mem\u00f3rias de longo prazoSubmit O soma \u00e9 respons\u00e1vel por integrar (somar) todos os sinais recebidos pelos dendritos e decidir se o neur\u00f4nio deve \"disparar\" ou n\u00e3o, baseado em um limiar de ativa\u00e7\u00e3o."},{"location":"aulas/IA/lab06/redesneurais.html#o-neuronio-artificial","title":"O neur\u00f4nio artificial","text":""},{"location":"aulas/IA/lab06/redesneurais.html#como-transformamos-neuronios-em-numeros","title":"Como transformamos neur\u00f4nios em n\u00famerosO que representam os \"pesos\" em um neur\u00f4nio artificial?","text":"<p>Pegamos a ideia do neur\u00f4nio biol\u00f3gico e criamos uma vers\u00e3o matem\u00e1tica simplificada. Imaginem o neur\u00f4nio artificial como uma calculadora especializada que:</p> <p></p> <pre><code>x\u2081 \u2500\u2500w\u2081\u2500\u2500\u2510\nx\u2082 \u2500\u2500w\u2082\u2500\u2500\u2524\n    ...  \u251c\u2500\u2192 \u03a3 \u2500\u2500\u2192 f(net) \u2500\u2500\u2192 y\nx\u2099 \u2500\u2500w\u2099\u2500\u2500\u2518\n    b \u2500\u2500\u2500\u2518\n</code></pre> <p>O que acontece aqui:</p> <ol> <li>Entradas (x\u2081, x\u2082, ..., x\u2099): Os \"dendritos\" \u2014 informa\u00e7\u00f5es que chegam</li> <li>Pesos (w\u2081, w\u2082, ..., w\u2099): A \"for\u00e7a das sinapses\" \u2014 o quanto cada entrada importa</li> <li>Bias (b): O \"limiar de ativa\u00e7\u00e3o\" \u2014 um ajuste fino</li> <li>Soma ponderada: Multiplicamos cada entrada pelo seu peso e somamos tudo</li> <li>Fun\u00e7\u00e3o de ativa\u00e7\u00e3o (f): Decide se o neur\u00f4nio \"dispara\" ou n\u00e3o</li> </ol> <p>As equa\u00e7\u00f5es fundamentais:</p> <pre><code>net = w\u2081\u00d7x\u2081 + w\u2082\u00d7x\u2082 + ... + w\u2099\u00d7x\u2099 + b\ny = f(net)\n</code></pre> O n\u00famero de entradas do neur\u00f4nioA import\u00e2ncia relativa de cada entrada na decis\u00e3o finalO tipo de fun\u00e7\u00e3o de ativa\u00e7\u00e3o utilizadaO valor m\u00ednimo para ativa\u00e7\u00e3o do neur\u00f4nioSubmit Os pesos determinam o quanto cada entrada influencia na sa\u00edda final do neur\u00f4nio. Pesos maiores significam maior import\u00e2ncia, enquanto pesos pr\u00f3ximos de zero indicam que aquela entrada \u00e9 quase irrelevante."},{"location":"aulas/IA/lab06/redesneurais.html#funcoes-de-ativacao","title":"Fun\u00e7\u00f5es de ativa\u00e7\u00e3o","text":"<p>As fun\u00e7\u00f5es de ativa\u00e7\u00e3o s\u00e3o respons\u00e1veis por introduzir n\u00e3o-linearidades no modelo. Sem elas, a rede seria essencialmente um modelo linear e incapaz de aprender e representar dados complexos que requerem n\u00e3o-linearidade para sua modelagem.</p> <p>A fun\u00e7\u00e3o de ativa\u00e7\u00e3o \u00e9 como o interruptor que decide se o neur\u00f4nio vai \"ligar\" (disparar) ou \"desligar\". Cada tipo tem sua personalidade:</p>"},{"location":"aulas/IA/lab06/redesneurais.html#1-funcao-degrau-step","title":"1. Fun\u00e7\u00e3o Degrau (Step)","text":"<p><pre><code>f(x) = { 1, se x \u2265 0\n       { 0, se x &lt; 0\n</code></pre> - Quando usar: Problemas simples de sim/n\u00e3o - Caracter\u00edstica: Tudo ou nada, sem meio termo</p>"},{"location":"aulas/IA/lab06/redesneurais.html#2-funcao-sigmoide","title":"2. Fun\u00e7\u00e3o Sigm\u00f3ide","text":"<p><pre><code>f(x) = 1 / (1 + e^(-x))\n</code></pre> - Faixa: Entre 0 e 1 (\u00f3timo para probabilidades!) - Vantagem: Suave e diferenci\u00e1vel - Problema: Pode \"saturar\" com valores muito grandes</p>"},{"location":"aulas/IA/lab06/redesneurais.html#3-tangente-hiperbolica-tanh","title":"3. Tangente Hiperb\u00f3lica (tanh)","text":"<p><pre><code>f(x) = (e^x - e^(-x)) / (e^x + e^(-x))\n</code></pre> - Faixa: Entre -1 e 1 - Vantagem: Centrada no zero (melhor que sigm\u00f3ide)</p>"},{"location":"aulas/IA/lab06/redesneurais.html#4-relu","title":"4. ReLU","text":"<pre><code>f(x) = max(0, x)\n</code></pre> <ul> <li>Regra: Se positivo, passa; se negativo, zero</li> <li>Por que \u00e9 popular: Simples, r\u00e1pida e resolve problemas de gradientes em redes profundas</li> </ul> Por que a fun\u00e7\u00e3o ReLU \u00e9 t\u00e3o popular em redes neurais modernas?Porque sempre retorna valores entre 0 e 1Porque \u00e9 a mais complexa matematicamentePorque \u00e9 simples, r\u00e1pida e resolve problemas de gradientes em redes profundasPorque funciona melhor com dados negativosSubmit ReLU (Rectified Linear Unit) se tornou popular porque sua simplicidade (max(0,x)) a torna computacionalmente eficiente e ajuda a resolver o problema do desvanecimento de gradientes em redes profundas."},{"location":"aulas/IA/lab06/redesneurais.html#perceptron","title":"Perceptron:","text":""},{"location":"aulas/IA/lab06/redesneurais.html#a-historia-que-mudou-tudo","title":"A hist\u00f3ria que mudou tudo","text":"<p>Em 1957, Frank Rosenblatt criou algo revolucion\u00e1rio: o Perceptron. Foi a primeira vez que uma m\u00e1quina conseguiu \"aprender\" a separar coisas de forma autom\u00e1tica. Imagine ensinar um computador a distinguir entre dois grupos de pontos apenas mostrando exemplos!</p> <p>O Perceptron \u00e9 como um neur\u00f4nio artificial muito determinado \u2014 ele fica ajustando seus pesos at\u00e9 conseguir separar corretamente os dados. \u00c9 o av\u00f4 de todas as redes neurais modernas!</p>"},{"location":"aulas/IA/lab06/redesneurais.html#como-o-perceptron-aprende","title":"Como o Perceptron aprendeQual foi a principal contribui\u00e7\u00e3o hist\u00f3rica do Perceptron?","text":"<pre><code>Entrada \u2192 Pesos \u2192 Soma \u2192 Ativa\u00e7\u00e3o \u2192 Sa\u00edda\nx\u2081,x\u2082,...,x\u2099 \u2192 w\u2081,w\u2082,...,w\u2099 \u2192 \u03a3 \u2192 f \u2192 y\n</code></pre> <p>O algoritmo de aprendizado (vers\u00e3o simplificada):</p> <ol> <li>Inicializar: Comece com pesos aleat\u00f3rios</li> <li>Para cada exemplo de treino:</li> <li>Calcule a sa\u00edda: <code>y = f(soma dos pesos \u00d7 entradas)</code></li> <li>Compare com a resposta correta</li> <li>Se errou: Ajuste os pesos na dire\u00e7\u00e3o certa</li> <li>Se acertou: Continue para o pr\u00f3ximo exemplo</li> <li>Repita at\u00e9 parar de cometer erros</li> </ol> Foi a primeira rede neural a processar imagensFoi o primeiro algoritmo de aprendizado para redes neurais com garantia de converg\u00eanciaInventou as fun\u00e7\u00f5es de ativa\u00e7\u00e3o modernasCriou o conceito de backpropagationSubmit O Perceptron foi revolucion\u00e1rio porque demonstrou pela primeira vez que uma m\u00e1quina podia aprender automaticamente a classificar dados, estabelecendo as bases para toda a \u00e1rea de redes neurais."},{"location":"aulas/IA/lab06/redesneurais.html#o-teorema-da-convergencia","title":"O Teorema da Converg\u00eancia","text":"<p>A promessa do Perceptron: Se seus dados puderem ser separados por uma linha reta (ou hiperplano), o Perceptron sempre vai encontrar essa linha, em um n\u00famero finito de passos. \u00c9 como ter a garantia de que, se existe uma solu\u00e7\u00e3o, voc\u00ea vai encontr\u00e1-la!</p>"},{"location":"aulas/IA/lab06/redesneurais.html#objetivo-deste-exercicio","title":"Objetivo deste exerc\u00edcio","text":"<p>Voc\u00ea poder\u00e1:</p> <ol> <li>Ajustar manualmente os pesos w_1, w_2 e o vi\u00e9s b para separar os pontos de cada classe.</li> <li>Treinar automaticamente usando a regra de aprendizado do Perceptron.</li> <li>Visualizar a fronteira de decis\u00e3o mudando de posi\u00e7\u00e3o conforme os par\u00e2metros.</li> </ol> <p>Atividade inicial:</p> <ul> <li>Escolha o problema AND e tente ajustar manualmente at\u00e9 atingir 100% de acur\u00e1cia.  </li> <li>Depois, avalie para problema da OR e observe o que acontece.</li> <li>Por fim, tente o problema XOR e observe o resultado.</li> </ul> Perceptron \u2014 Exerc\u00edcio Interativo w\u2081: 0.00 w\u2082: 0.00 b: 0.00 Taxa (\u03b7 lr): 0.10 \u00c9pocas: 30 Problema AND OR XOR Acur\u00e1cia: \u2014  mostrar grade        Treinar Reset        x\u2081, x\u2082 em [\u22120.2, 1.2] \u00d7 [\u22120.2, 1.2] \u2022 azul = 0 \u2022 vermelho = 1 \u2022 linha preta = fronteira w\u2081x\u2081 + w\u2082x\u2082 + b = 0"},{"location":"aulas/IA/lab06/redesneurais.html#perguntas-para-reflexao","title":"Perguntas para reflex\u00e3o","text":"<ol> <li>Por que o Perceptron consegue aprender AND mas n\u00e3o XOR?</li> <li>O que acontece com a fronteira quando alteramos apenas o vi\u00e9s?</li> <li>Como a taxa de aprendizado influencia a velocidade de converg\u00eancia?</li> </ol>"},{"location":"aulas/IA/lab06/redesneurais.html#as-limitacoes-que-mudaram-a-historia","title":"As limita\u00e7\u00f5es que mudaram a hist\u00f3riaPor que o problema XOR foi t\u00e3o significativo para a hist\u00f3ria das redes neurais?","text":"<p>O Perceptron tinha um problema fatal: s\u00f3 funcionava para problemas linearmente separ\u00e1veis. </p> <p>O famoso problema XOR:</p> Entradas Sa\u00edda XOR A  B Resultado 0  0 0 0  1 1 1  0 1 1  1 0 <p>N\u00e3o importa como voc\u00ea tente, n\u00e3o existe uma linha reta que separe corretamente os 1s dos 0s neste problema! Essa limita\u00e7\u00e3o quase matou a pesquisa em redes neurais nos anos 1970.</p> Porque era muito complexo computacionalmentePorque envolvia muitas vari\u00e1veis de entradaPorque demonstrou que o Perceptron n\u00e3o consegue resolver problemas n\u00e3o linearmente separ\u00e1veisPorque precisava de dados muito grandes para treinarSubmit O XOR mostrou uma limita\u00e7\u00e3o fundamental do Perceptron: ele s\u00f3 funciona quando os dados podem ser separados por uma linha reta, o que levou ao \"inverno da IA\" at\u00e9 o desenvolvimento de redes com m\u00faltiplas camadas."},{"location":"aulas/IA/lab06/redesneurais.html#multilayer-perceptron-mlp","title":"Multilayer Perceptron (MLP)","text":""},{"location":"aulas/IA/lab06/redesneurais.html#a-solucao-para-o-problema-xor","title":"A solu\u00e7\u00e3o para o problema XOR","text":"<p>Os cientistas descobriram algo incr\u00edvel: se voc\u00ea empilhar neur\u00f4nios em camadas, de repente consegue resolver problemas que pareciam imposs\u00edveis! O MLP (Multilayer Perceptron) nasceu dessa descoberta.</p> <p>Como o MLP supera as limita\u00e7\u00f5es:</p> <ol> <li>Camadas ocultas: Criam representa\u00e7\u00f5es intermedi\u00e1rias dos dados</li> <li>M\u00faltiplas camadas: Cada camada aprende padr\u00f5es mais complexos</li> <li>Backpropagation: Um algoritmo inteligente que ensina todas as camadas simultaneamente</li> </ol> <p>\u00c9 como ter v\u00e1rios especialistas trabalhando em sequ\u00eancia \u2014 cada um pega o trabalho do anterior e o refina ainda mais!</p>"},{"location":"aulas/IA/lab06/redesneurais.html#a-arquitetura-em-camadas","title":"A arquitetura em camadas","text":"<p>O que cada camada faz:</p> <ul> <li>Entrada: Recebe os dados originais</li> <li>Oculta(s): Transformam os dados em representa\u00e7\u00f5es mais \u00fateis</li> <li>Sa\u00edda: Produz a resposta final</li> </ul>"},{"location":"aulas/IA/lab06/redesneurais.html#objetivo-deste-exercicio_1","title":"Objetivo deste exerc\u00edcioMLP 2\u20132\u20131 \u2014 XOR","text":"<p>Voc\u00ea deve:</p> <ol> <li>Treinar um MLP para aprender o XOR usando backpropagation.</li> <li>Alterar taxa de aprendizado, \u00e9pocas e fun\u00e7\u00e3o de ativa\u00e7\u00e3o (tanh/ReLU).</li> <li>Visualizar a regi\u00e3o de decis\u00e3o sendo formada. Olhe a cor de fundo para saber a classe prevista para cada regi\u00e3o. Use a linha preta apenas para ver onde a decis\u00e3o muda (probabilidade \u2248 0.5).</li> </ol> <p>Atividade inicial:</p> <ul> <li>Treine com <code>tanh</code>, \u03b7=0.10, 300 \u00e9pocas.</li> <li>Verifique se a acur\u00e1cia chega a 100%.</li> <li>Troque para <code>ReLU</code> e compare a converg\u00eancia.</li> </ul> Ativa\u00e7\u00e3o tanh ReLU Taxa (\u03b7): 0.10 \u00c9pocas: 300 Batch full (XOR completo) SGD (embaralha) Acur\u00e1cia: \u2014  mostrar regi\u00e3o de decis\u00e3o        Treinar Reset Pesos (ler/ajustar manualmente) w11:  w12:  w21:  w22:  b1:   b2:   v1:   v2:   c:           x\u2081, x\u2082 em [\u22120.2, 1.2] \u00d7 [\u22120.2, 1.2] \u2022 azul = 0 \u2022 vermelho = 1 \u2022 contorno preto \u2248 p=0.5"},{"location":"aulas/IA/lab06/redesneurais.html#perguntas-para-reflexao_1","title":"Perguntas para reflex\u00e3oQual \u00e9 a principal vantagem das camadas ocultas em um MLP?Qual \u00e9 a diferen\u00e7a fundamental entre um Perceptron e um MLP?","text":"<ol> <li>Por que o MLP consegue resolver o XOR, mas o Perceptron simples n\u00e3o?</li> <li>Como a taxa de aprendizado afeta a converg\u00eancia?</li> </ol> Reduzem o tempo de treinamentoDiminuem a quantidade de dados necess\u00e1riosPermitem aprender representa\u00e7\u00f5es n\u00e3o lineares dos dadosSimplificam a interpreta\u00e7\u00e3o do modeloSubmit As camadas ocultas permitem que a rede neural crie transforma\u00e7\u00f5es n\u00e3o lineares dos dados de entrada, possibilitando resolver problemas como XOR que s\u00e3o imposs\u00edveis para um \u00fanico neur\u00f4nio. O Perceptron usa fun\u00e7\u00e3o ReLU, o MLP usa sigm\u00f3ideO Perceptron \u00e9 mais r\u00e1pido para treinarO MLP possui camadas ocultas que permitem resolver problemas n\u00e3o linearesO Perceptron funciona melhor com grandes datasetsSubmit A principal diferen\u00e7a \u00e9 que o MLP possui camadas ocultas entre a entrada e sa\u00edda, permitindo aprender padr\u00f5es n\u00e3o lineares que o Perceptron (com apenas entrada e sa\u00edda) n\u00e3o consegue capturar."},{"location":"aulas/IA/lab06/redesneurais.html#o-teorema-da-aproximacao-universal","title":"O Teorema da Aproxima\u00e7\u00e3o Universal","text":"<p>Teorema incr\u00edvel: Uma rede neural com apenas uma camada oculta e neur\u00f4nios suficientes pode aproximar qualquer fun\u00e7\u00e3o cont\u00ednua com a precis\u00e3o que voc\u00ea quiser!</p> <p>Em outras palavras: teoricamente, voc\u00ea pode ensinar uma rede neural a fazer qualquer coisa (desde que seja uma fun\u00e7\u00e3o matem\u00e1tica cont\u00ednua). \u00c9 como ter um \"canivete su\u00ed\u00e7o\" matem\u00e1tico universal!</p> <p>Aten\u00e7\u00e3o: o teorema n\u00e3o diz quantos neur\u00f4nios voc\u00ea precisa \u2014 \u00e0s vezes pode ser um n\u00famero astron\u00f4mico!</p>"},{"location":"aulas/IA/lab06/redesneurais.html#guia-pratico-quantos-neuronios-usar","title":"Guia pr\u00e1tico: quantos neur\u00f4nios usar?","text":"<p>Esta \u00e9 uma das perguntas mais comuns: <code>Quantos neur\u00f4nios e quantas camadas devo colocar na minha rede?</code></p> <p>Regras pr\u00e1ticas hist\u00f3ricas (use como ponto de partida, n\u00e3o como lei):</p>"},{"location":"aulas/IA/lab06/redesneurais.html#para-a-camada-oculta","title":"Para a camada oculta:","text":"<p>1. Regra dos \u2154: <pre><code>neur\u00f4nios ocultos \u2248 (2/3 \u00d7 neur\u00f4nios de entrada) + neur\u00f4nios de sa\u00edda\n</code></pre></p> <p>2. M\u00e9dia geom\u00e9trica: <pre><code>neur\u00f4nios ocultos \u2248 \u221a(entradas \u00d7 sa\u00eddas)\n</code></pre></p> <p>3. Experimenta\u00e7\u00e3o incremental <code>(recomendado hoje)</code>:</p> <ul> <li>Comece pequeno</li> <li>Monitore treino vs valida\u00e7\u00e3o</li> <li>Aumente gradualmente</li> <li>Use regulariza\u00e7\u00e3o para evitar overfitting</li> </ul>"},{"location":"aulas/IA/lab06/redesneurais.html#para-o-numero-de-camadas","title":"Para o n\u00famero de camadas:","text":"<ul> <li>1 camada oculta: Problemas que viram lineares ap\u00f3s uma transforma\u00e7\u00e3o</li> <li>2 camadas: Qualquer fun\u00e7\u00e3o cont\u00ednua (teorema da aproxima\u00e7\u00e3o)</li> <li>3+ camadas: Fun\u00e7\u00f5es descont\u00ednuas e padr\u00f5es muito complexos (<code>Deep Learning!</code>)</li> </ul> Segundo o Teorema da Aproxima\u00e7\u00e3o Universal, quantas camadas ocultas s\u00e3o teoricamente necess\u00e1rias para aproximar qualquer fun\u00e7\u00e3o cont\u00ednua?Infinitas camadasPelo menos 3 camadasApenas 1 camada oculta (com neur\u00f4nios suficientes)Depende do tipo de dadosSubmit O teorema estabelece que uma \u00fanica camada oculta com neur\u00f4nios suficientes pode aproximar qualquer fun\u00e7\u00e3o cont\u00ednua, embora na pr\u00e1tica m\u00faltiplas camadas muitas vezes sejam mais eficientes."},{"location":"aulas/IA/lab06/rna.html","title":"Rna","text":"<p>A rede Perceptron possui um algoritmo de aprendizado supervisionado que consegue definir um classificador que encontra a superf\u00edcie de separa\u00e7\u00e3o entre quaisquer duas classes linearmente separ\u00e1veis</p> In\u00a0[1]: Copied! <pre>import pandas as pd\n\n\nurl = \"https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data\"\nheader = ['sepal_length', 'sepal_width', 'petal_length', 'petal_width', 'species']\ndf = pd.read_csv(url, header=None, names=header)\n</pre> import pandas as pd   url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data\" header = ['sepal_length', 'sepal_width', 'petal_length', 'petal_width', 'species'] df = pd.read_csv(url, header=None, names=header) In\u00a0[2]: Copied! <pre># Selecionando um sub-dataframe com os campos petal_length e petal_width, \n# e outro com a vari\u00e1vel de classes\nentradas = df[['petal_length', 'petal_width']]\nclasses = df['species']\nprint(f\"Formato das tabelas de dados {entradas.shape} e classes {classes.shape}\")\n</pre> # Selecionando um sub-dataframe com os campos petal_length e petal_width,  # e outro com a vari\u00e1vel de classes entradas = df[['petal_length', 'petal_width']] classes = df['species'] print(f\"Formato das tabelas de dados {entradas.shape} e classes {classes.shape}\") <pre>Formato das tabelas de dados (150, 2) e classes (150,)\n</pre> In\u00a0[3]: Copied! <pre># Separamos 20 % para o teste\nfrom sklearn.model_selection import train_test_split\nentradas_treino, entradas_teste, classes_treino, classes_teste = train_test_split(entradas, classes, test_size=0.2)\nprint(f\"Formato das tabelas de dados de treino {entradas_treino.shape} e teste {entradas_teste.shape}\")\n</pre> # Separamos 20 % para o teste from sklearn.model_selection import train_test_split entradas_treino, entradas_teste, classes_treino, classes_teste = train_test_split(entradas, classes, test_size=0.2) print(f\"Formato das tabelas de dados de treino {entradas_treino.shape} e teste {entradas_teste.shape}\") <pre>Formato das tabelas de dados de treino (120, 2) e teste (30, 2)\n</pre> In\u00a0[4]: Copied! <pre>from sklearn.linear_model import Perceptron\n\n\nmodelo = Perceptron(tol=1.7)\nmodelo.fit(entradas_treino, classes_treino)\n</pre> from sklearn.linear_model import Perceptron   modelo = Perceptron(tol=1.7) modelo.fit(entradas_treino, classes_treino) Out[4]: <pre>Perceptron(tol=1.7)</pre>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.Perceptron<pre>Perceptron(tol=1.7)</pre> In\u00a0[5]: Copied! <pre>classes_encontradas = modelo.predict(entradas_teste)\n</pre> classes_encontradas = modelo.predict(entradas_teste) In\u00a0[6]: Copied! <pre>from sklearn.metrics import accuracy_score\n\nclasses_encontradas_train = modelo.predict(entradas_treino)\nprint(\"Acerto m\u00e9dio de classifica\u00e7\u00e3o treino: \",accuracy_score(classes_encontradas_train, classes_treino))\n\nclasses_encontradas = modelo.predict(entradas_teste)\nprint(\"Acerto m\u00e9dio de classifica\u00e7\u00e3o teste: \",accuracy_score(classes_encontradas, classes_teste))\n</pre> from sklearn.metrics import accuracy_score  classes_encontradas_train = modelo.predict(entradas_treino) print(\"Acerto m\u00e9dio de classifica\u00e7\u00e3o treino: \",accuracy_score(classes_encontradas_train, classes_treino))  classes_encontradas = modelo.predict(entradas_teste) print(\"Acerto m\u00e9dio de classifica\u00e7\u00e3o teste: \",accuracy_score(classes_encontradas, classes_teste)) <pre>Acerto m\u00e9dio de classifica\u00e7\u00e3o treino:  0.675\nAcerto m\u00e9dio de classifica\u00e7\u00e3o teste:  0.6333333333333333\n</pre> In\u00a0[7]: Copied! <pre>from sklearn.metrics import classification_report\n\nprint(classification_report(classes_encontradas, classes_teste))\n</pre>  from sklearn.metrics import classification_report  print(classification_report(classes_encontradas, classes_teste)) <pre>                 precision    recall  f1-score   support\n\n    Iris-setosa       1.00      0.77      0.87        13\nIris-versicolor       0.00      0.00      0.00         0\n Iris-virginica       1.00      0.53      0.69        17\n\n       accuracy                           0.63        30\n      macro avg       0.67      0.43      0.52        30\n   weighted avg       1.00      0.63      0.77        30\n\n</pre> <pre>/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n</pre> In\u00a0[8]: Copied! <pre>from sklearn.neural_network import MLPClassifier\n\ncamadas = [4,3]\nepocas = 1000\nbatch_size = 10\nativacao = 'relu' # Escolha dentre 'logistic', 'tanh' ou 'relu'\n\nmodelo = MLPClassifier(hidden_layer_sizes=camadas,\n                    batch_size=batch_size,\n                    activation=ativacao,\n                    max_iter=epocas)\n</pre> from sklearn.neural_network import MLPClassifier  camadas = [4,3] epocas = 1000 batch_size = 10 ativacao = 'relu' # Escolha dentre 'logistic', 'tanh' ou 'relu'  modelo = MLPClassifier(hidden_layer_sizes=camadas,                     batch_size=batch_size,                     activation=ativacao,                     max_iter=epocas) In\u00a0[9]: Copied! <pre>modelo.fit(entradas_treino, classes_treino)\n</pre>  modelo.fit(entradas_treino, classes_treino) Out[9]: <pre>MLPClassifier(batch_size=10, hidden_layer_sizes=[4, 3], max_iter=1000)</pre>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.MLPClassifier<pre>MLPClassifier(batch_size=10, hidden_layer_sizes=[4, 3], max_iter=1000)</pre> In\u00a0[10]: Copied! <pre>from sklearn.metrics import accuracy_score\n\n\nclasses_encontradas_train = modelo.predict(entradas_treino)\nprint(\"Acerto m\u00e9dio de classifica\u00e7\u00e3o treino: \",accuracy_score(classes_encontradas_train, classes_treino))\n\nclasses_encontradas = modelo.predict(entradas_teste)\nprint(\"Acerto m\u00e9dio de classifica\u00e7\u00e3o teste: \",accuracy_score(classes_encontradas, classes_teste))\n</pre> from sklearn.metrics import accuracy_score   classes_encontradas_train = modelo.predict(entradas_treino) print(\"Acerto m\u00e9dio de classifica\u00e7\u00e3o treino: \",accuracy_score(classes_encontradas_train, classes_treino))  classes_encontradas = modelo.predict(entradas_teste) print(\"Acerto m\u00e9dio de classifica\u00e7\u00e3o teste: \",accuracy_score(classes_encontradas, classes_teste))  <pre>Acerto m\u00e9dio de classifica\u00e7\u00e3o treino:  0.9666666666666667\nAcerto m\u00e9dio de classifica\u00e7\u00e3o teste:  0.9666666666666667\n</pre> In\u00a0[11]: Copied! <pre>from sklearn.metrics import classification_report\n\nprint(classification_report(classes_encontradas, classes_teste))\n</pre> from sklearn.metrics import classification_report  print(classification_report(classes_encontradas, classes_teste)) <pre>                 precision    recall  f1-score   support\n\n    Iris-setosa       1.00      1.00      1.00        10\nIris-versicolor       1.00      0.92      0.96        12\n Iris-virginica       0.89      1.00      0.94         8\n\n       accuracy                           0.97        30\n      macro avg       0.96      0.97      0.97        30\n   weighted avg       0.97      0.97      0.97        30\n\n</pre> In\u00a0[\u00a0]: Copied! <pre>## Seu c\u00f3digo aqui.......\n</pre> ## Seu c\u00f3digo aqui......."},{"location":"aulas/IA/lab06/rna.html#2-aprendizagem-de-maquina","title":"2. Aprendizagem de m\u00e1quina\u00b6","text":""},{"location":"aulas/IA/lab06/rna.html#objetivos","title":"Objetivos\u00b6","text":"<ul> <li>Conhecer uma intui\u00e7\u00e3o sobre Redes Neurais Artificiais RNA</li> <li>Praticar os algoritmos Perceptron e multilayer Perceptron (MLP)</li> </ul>"},{"location":"aulas/IA/lab06/rna.html#redes-neurais-artificiais","title":"Redes Neurais Artificiais\u00b6","text":"<p>As redes neurais s\u00e3o modelos computacionais inspirados pelo sistema nervoso de um animal capazes de realizar o aprendizado de m\u00e1quina bem como o reconhecimento de padr\u00f5es.</p> <p>Tais modelos s\u00e3o muitas vezes utilizados para a tarefa de classifica\u00e7\u00e3o de padr\u00f5es, podendo gerar classificadores com caracter\u00edsticas variadas.</p> <p>As redes neurais artificiais possuem em comum o fato de serem constitu\u00eddas por neur\u00f4nios que se conectam entre si atrav\u00e9s de atrav\u00e9s de sinapses. A rede neural mais conhecida s\u00e3o as baseadas em Perceptron multicamada (MLP) embora existam outras redes como rede de Kohonem, as redes de base radial e a rede de Hopfield.</p>"},{"location":"aulas/IA/lab06/rna.html#os-principais-componentes-dos-neuronios-sao","title":"Os principais componentes dos neur\u00f4nios s\u00e3o:\u00b6","text":"<ul> <li>Os <code>dendritos</code>, que t\u00eam por fun\u00e7\u00e3o receber os est\u00edmulos transmitidos pelos outros neur\u00f4nios;</li> <li>O <code>corpo</code> de neur\u00f4nio, tamb\u00e9m chamado de soma, que \u00e9 respons\u00e1vel por coletar e combinar informa\u00e7\u00f5es vindas de outros neur\u00f4nios;</li> <li>O <code>ax\u00f4nio</code>, que \u00e9 constitu\u00eddo de uma fibra tubular que pode alcan\u00e7ar at\u00e9 alguns metros, e \u00e9 respons\u00e1vel por transmitir os est\u00edmulos para outras c\u00e9lulas.</li> </ul>"},{"location":"aulas/IA/lab06/rna.html#perceptron","title":"Perceptron\u00b6","text":"<p>O classificador Perceptron foi o primeiro classificador baseado em redes neurais que empregou uma regra de aprendizado capaz de garantir a correta separa\u00e7\u00e3o de classes linearmente separ\u00e1veis.</p> <p>No in\u00edcio do treinamento, os pesos dos neur\u00f4nios recebem valores aleat\u00f3rios. Ent\u00e3o, para cada amostra de treinamento com erro de classifica\u00e7\u00e3o, os pesos dos neur\u00f4nios s\u00e3o ajustados de modo a tentar corrigir a classe.</p> <p>Ap\u00f3s o treinamento, cada neur\u00f4nio na camada de sa\u00edda testa a pertin\u00eancia da amostra a uma classe. No caso de mais de um neur\u00f4nio fornecer resposta positiva a amostra, a classe correspondente ao neur\u00f4nio de maior resposta vence.</p> <p> </p>"},{"location":"aulas/IA/lab06/rna.html#instanciar-o-classificador-e-treina-lo-com-as-amostras-de-treinamento","title":"Instanciar o classificador e trein\u00e1-lo com as amostras de treinamento\u00b6","text":"<p>https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Perceptron.html</p>"},{"location":"aulas/IA/lab06/rna.html#analise-f1-score","title":"An\u00e1lise F1-Score\u00b6","text":"<p>A pontua\u00e7\u00e3o F1 pode ser interpretada como uma m\u00e9dia ponderada da precision e recall.</p> <ul> <li>Melhor valor = 1</li> <li>Pior valor = 0</li> </ul> <p>A contribui\u00e7\u00e3o relativa de precision e recall para a pontua\u00e7\u00e3o F1 s\u00e3o iguais. A f\u00f3rmula para a pontua\u00e7\u00e3o F1 \u00e9:</p> <p>F1 = 2 * (precision * recall) / (precision + recall)</p>"},{"location":"aulas/IA/lab06/rna.html#multilayer-perceptron-mlp","title":"Multilayer Perceptron (MLP)\u00b6","text":"<ul> <li>O acr\u00e9scimo de uma nova camada de neur\u00f4nios, denominada camada oculta, permite criar superf\u00edcies de separa\u00e7\u00e3o n\u00e3o lineares, permitindo a classifica\u00e7\u00e3o de classes n\u00e3o-linearmente separ\u00e1veis</li> <li>A rede MLP \u00e9 considerada uma rede do tipo feed-forward, j\u00e1 que as sa\u00eddas dos neur\u00f4nios das camadas posteriores dependem apenas dos neur\u00f4nios das camadas anteriores</li> <li>Em uma rede MLP, n\u00e3o h\u00e1 regra para o n\u00famero de neur\u00f4nios a ser usado na camada oculta, e nem h\u00e1 limites para o n\u00famero de camadas ocultas a serem usadas</li> <li>Aparentemente, um bom chute inicial \u00e9 considerar o dobro de neur\u00f4nios na camada oculta com rela\u00e7\u00e3o ao tamanho da entrada</li> <li>\u00c9 conhecido que com uma \u00fanica camada oculta com um n\u00famero suficientemente grande de n\u00f3s \u00e9 poss\u00edvel representar qualquer fun\u00e7\u00e3o cont\u00ednua, e por isso essa estrutura \u00e9 conhecida como aproximador universal</li> </ul> <p>https://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPClassifier.html</p>"},{"location":"aulas/IA/lab06/rna.html#desafio1","title":"Desafio1\u00b6","text":"<p>Escolha uma dos exemplos dados em sala de aula e implemente um MLP com pelo menos 10 neuronios na camada escondida:</p> <p>OBS: S\u00f3 n\u00e3o vale o data da Iris, pois acabamos de usar...</p>"},{"location":"aulas/IA/lab07/index.html","title":"TensorFlow","text":"<p>Neste m\u00f3dulo, vamos explorar os fundamentos das redes neurais e aplicar esses conceitos usando a biblioteca TensorFlow. </p> <p>O TensorFlow n\u00e3o apenas facilita a constru\u00e7\u00e3o e o treinamento de modelos complexos, mas tamb\u00e9m oferece ferramentas robustas para o processamento de dados, essenciais para qualquer projeto de machine learning.</p>"},{"location":"aulas/IA/lab07/index.html#objetivos-de-aprendizado","title":"Objetivos de Aprendizado","text":"<ul> <li>Entender o funcionamento das redes neurais.</li> <li>Desenvolver habilidades pr\u00e1ticas em modelagem e treinamento de redes neurais com TensorFlow.</li> <li>Aplicar redes neurais em problemas reais de classifica\u00e7\u00e3o e regress\u00e3o.</li> </ul>"},{"location":"aulas/IA/lab07/index.html#atividades-praticas","title":"Atividades Pr\u00e1ticas","text":"<p>As seguintes atividades foram preparadas para refor\u00e7ar os conceitos abordados (Fa\u00e7a o downlod dos datasets nos links a seguir)</p> <p>Despesas M\u00e9dicas \u2013 Problema de Regress\u00e3o</p> <ul> <li>Contexto: Informa\u00e7\u00f5es sobre pacientes (idade, \u00edndice de massa corporal, n\u00famero de filhos, tabagismo, regi\u00e3o, etc.) para prever o custo anual de despesas m\u00e9dicas.</li> <li>Modelo Sugerido: Rede Neural Multilayer Perceptron (MLP) para regress\u00e3o.</li> <li>M\u00e9tricas de Avalia\u00e7\u00e3o: RMSE e R\u00b2 para avaliar a performance na estimativa dos custos.</li> <li>insurance: Dataset com informa\u00e7\u00f5es sobre pacientes (idade, IMC, n\u00famero de filhos, tabagismo, regi\u00e3o, etc.) para prever o custo anual de despesas m\u00e9dicas.</li> </ul> <p>Vendas com Base em Investimento Publicit\u00e1rio \u2013 Problema de Regress\u00e3o</p> <ul> <li>Contexto: Dados sobre investimentos em TV, r\u00e1dio e jornal, com o objetivo de prever o volume de vendas obtido.</li> <li>Modelo Sugerido: Rede Neural Multilayer Perceptron (MLP) para regress\u00e3o.</li> <li>M\u00e9tricas de Avalia\u00e7\u00e3o: RMSE (Root Mean Square Error) e R\u00b2 para mensurar o erro e a capacidade explicativa do modelo.</li> <li>Advertising: Dataset com dados sobre investimentos em TV, r\u00e1dio e jornal, com o objetivo de prever o volume de vendas obtido.</li> </ul> <p>Rotatividade de Funcion\u00e1rios - Problema de Classifica\u00e7\u00e3o Bin\u00e1ria</p> <ul> <li>Contexto: Dataset com informa\u00e7\u00f5es de funcion\u00e1rios, incluindo desempenho, tempo de casa, sal\u00e1rio e hist\u00f3rico profissional, para prever se o colaborador ir\u00e1 deixar a organiza\u00e7\u00e3o.</li> <li>Modelo Sugerido: Rede Neural Multilayer Perceptron (MLP) com camadas densas.</li> <li>M\u00e9tricas de Avalia\u00e7\u00e3o: Acur\u00e1cia, Recall (especialmente para a classe de sa\u00edda), F1-score e AUC para medir a capacidade do modelo em prever desligamentos.</li> <li>turnover: Dataset com informa\u00e7\u00f5es de funcion\u00e1rios (n\u00edvel de satisfa\u00e7\u00e3o, avalia\u00e7\u00f5es, n\u00famero de projetos, carga hor\u00e1ria, tempo de empresa, setor e sal\u00e1rio) para prever se o colaborador ir\u00e1 deixar a organiza\u00e7\u00e3o.</li> </ul> <p>Churn de Clientes \u2013 Problema de Classifica\u00e7\u00e3o Bin\u00e1ria </p> <ul> <li>Contexto: Dataset com informa\u00e7\u00f5es demogr\u00e1ficas e financeiras de clientes de um banco, visando prever se o cliente ir\u00e1 encerrar sua conta (churn).</li> <li>Modelo Sugerido: Rede Neural Multilayer Perceptron (MLP) com camadas densas.</li> <li>M\u00e9tricas de Avalia\u00e7\u00e3o: Acur\u00e1cia, Precis\u00e3o, Recall, F1-score e AUC para avaliar a capacidade do modelo em identificar clientes propensos ao churn.</li> <li>Churn_Modelling: Dataset com informa\u00e7\u00f5es demogr\u00e1ficas e financeiras de clientes de um banco, visando prever se o cliente ir\u00e1 encerrar sua conta (churn).</li> </ul>"},{"location":"aulas/IA/lab07/index.html#pre-processamento-e-tratamento-de-dados","title":"Pr\u00e9-processamento e Tratamento de Dados","text":"<p>Antes de aplicar o treinamento de modelos, \u00e9 necess\u00e1rio realizar o pr\u00e9-processamento e o tratamento adequado dos dados. Esse processo inclui:</p> <ul> <li>Limpeza de Dados: Remo\u00e7\u00e3o de valores ausentes ou corre\u00e7\u00e3o de dados corrompidos.</li> <li>Normaliza\u00e7\u00e3o/Padroniza\u00e7\u00e3o: Escalonamento dos valores num\u00e9ricos para que o modelo n\u00e3o seja enviesado por caracter\u00edsticas com escalas grandes.</li> <li>Codifica\u00e7\u00e3o de Vari\u00e1veis Categ\u00f3ricas: Transforma\u00e7\u00e3o de vari\u00e1veis categ\u00f3ricas em formatos num\u00e9ricos que podem ser interpretados pelo modelo, como one-hot encoding.</li> </ul> <p>Vamos come\u00e7ar!!!</p>"},{"location":"aulas/IA/lab07/Praticando_redes_neurais_com_Tensorflow.html","title":"MLP","text":"In\u00a0[\u00a0]: Copied! <p>Esta base \u00e9 composta pelos seguintes atributos:</p> <ul> <li>age: Refere-se \u00e0 idade do segurado, representada em anos.</li> <li>sex: Indica o sexo do segurado, podendo ser 'male' ou 'female'.</li> <li>bmi: Corresponde ao \u00cdndice de Massa Corporal (IMC) do segurado, uma medida que relaciona o peso e a altura da pessoa, geralmente expressa em kg/m\u00b2.</li> <li>children: Representa o n\u00famero de filhos ou dependentes do segurado.</li> <li>smoker: Indica se o segurado \u00e9 fumante ou n\u00e3o, podendo ser 'yes' ou 'no'.</li> <li>region: Refere-se \u00e0 regi\u00e3o de resid\u00eancia do segurado, podendo ser 'northeast', 'northwest', 'southeast' ou 'southwest'.</li> <li>expenses: Corresponde aos custos m\u00e9dicos do segurado, em d\u00f3lares.</li> </ul> In\u00a0[1]: Copied! <pre># Ignorar warnings\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\n# Bibliotecas para uso e visualiza\u00e7\u00e3o de dados\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\n# Import para divis\u00e3o dos dados de treino e teste\nfrom sklearn.model_selection import train_test_split\n\n# Imports para prepara\u00e7\u00e3o de dados\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.preprocessing import MinMaxScaler\n\n\n# Import de modelo preditivo de regress\u00e3o para comparar os resultados no final.\nfrom sklearn.linear_model import LinearRegression\n\n# Import de m\u00e9tricas para avalia\u00e7\u00e3o dos modelos\nfrom sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n</pre> # Ignorar warnings import warnings warnings.filterwarnings(\"ignore\")  # Bibliotecas para uso e visualiza\u00e7\u00e3o de dados import numpy as np import pandas as pd import seaborn as sns import matplotlib.pyplot as plt  # Import para divis\u00e3o dos dados de treino e teste from sklearn.model_selection import train_test_split  # Imports para prepara\u00e7\u00e3o de dados from sklearn.preprocessing import LabelEncoder from sklearn.preprocessing import StandardScaler from sklearn.preprocessing import MinMaxScaler   # Import de modelo preditivo de regress\u00e3o para comparar os resultados no final. from sklearn.linear_model import LinearRegression  # Import de m\u00e9tricas para avalia\u00e7\u00e3o dos modelos from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score In\u00a0[40]: Copied! <pre># Leitura do dataset\ndf = pd.read_csv(\"insurance.csv\")\ndf.head(5)\n</pre> # Leitura do dataset df = pd.read_csv(\"insurance.csv\") df.head(5) Out[40]: age sex bmi children smoker region expenses 0 19 female 27.9 0 yes southwest 16884.92 1 18 male 33.8 1 no southeast 1725.55 2 28 male 33.0 3 no southeast 4449.46 3 33 male 22.7 0 no northwest 21984.47 4 32 male 28.9 0 no northwest 3866.86 In\u00a0[41]: Copied! <pre># Quais os tipos? Dados faltantes?\ndf.info()\n</pre> # Quais os tipos? Dados faltantes? df.info() <pre>&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 1338 entries, 0 to 1337\nData columns (total 7 columns):\n #   Column    Non-Null Count  Dtype  \n---  ------    --------------  -----  \n 0   age       1338 non-null   int64  \n 1   sex       1338 non-null   object \n 2   bmi       1338 non-null   float64\n 3   children  1338 non-null   int64  \n 4   smoker    1338 non-null   object \n 5   region    1338 non-null   object \n 6   expenses  1338 non-null   float64\ndtypes: float64(2), int64(2), object(3)\nmemory usage: 73.3+ KB\n</pre> In\u00a0[\u00a0]: Copied! <pre>## note que temos que tratar os atributos 'sex', 'smoker' e 'region'\n</pre> ## note que temos que tratar os atributos 'sex', 'smoker' e 'region' In\u00a0[42]: Copied! <pre># Quantos dados \u00fanicos\ndf.nunique()\n</pre> # Quantos dados \u00fanicos df.nunique() Out[42]: <pre>age           47\nsex            2\nbmi          275\nchildren       6\nsmoker         2\nregion         4\nexpenses    1337\ndtype: int64</pre> In\u00a0[43]: Copied! <pre># Removendo duplicatas\ndf.drop_duplicates(inplace=True)\ndf.shape\n\n# note que existia 1 dado duplicado\n</pre> # Removendo duplicatas df.drop_duplicates(inplace=True) df.shape  # note que existia 1 dado duplicado Out[43]: <pre>(1337, 7)</pre> <p>Agora j\u00e1 podemos partir para a limpeza da base, convertendo strings para n\u00fameros, aplicando OneHotEncoder e eliminando colunas originais que j\u00e1 foram tratadas</p> In\u00a0[44]: Copied! <pre># Convertendo dados \"string\" para \"n\u00fameros\"\ndf[\"genero\"] = df[\"sex\"].apply( lambda x: 0 if x == \"male\" else 1 )\ndf[\"fumante\"] = df[\"smoker\"].apply( lambda x: 1 if x == \"yes\" else 0 )\n\n# OneHotEncoder da coluna \"region\"\naux = pd.get_dummies(df[\"region\"], drop_first=True)\ndf_final = pd.concat([df, aux], axis=1)\n\n# Remover colunas que j\u00e1 foram processadas\ndf_final.drop(columns=[\"sex\", \"smoker\", \"region\"], inplace=True)\ndf_final\n</pre> # Convertendo dados \"string\" para \"n\u00fameros\" df[\"genero\"] = df[\"sex\"].apply( lambda x: 0 if x == \"male\" else 1 ) df[\"fumante\"] = df[\"smoker\"].apply( lambda x: 1 if x == \"yes\" else 0 )  # OneHotEncoder da coluna \"region\" aux = pd.get_dummies(df[\"region\"], drop_first=True) df_final = pd.concat([df, aux], axis=1)  # Remover colunas que j\u00e1 foram processadas df_final.drop(columns=[\"sex\", \"smoker\", \"region\"], inplace=True) df_final Out[44]: age bmi children expenses genero fumante northwest southeast southwest 0 19 27.9 0 16884.92 1 1 False False True 1 18 33.8 1 1725.55 0 0 False True False 2 28 33.0 3 4449.46 0 0 False True False 3 33 22.7 0 21984.47 0 0 True False False 4 32 28.9 0 3866.86 0 0 True False False ... ... ... ... ... ... ... ... ... ... 1333 50 31.0 3 10600.55 0 0 True False False 1334 18 31.9 0 2205.98 1 0 False False False 1335 18 36.9 0 1629.83 1 0 False True False 1336 21 25.8 0 2007.95 1 0 False False True 1337 61 29.1 0 29141.36 1 1 True False False <p>1337 rows \u00d7 9 columns</p> In\u00a0[45]: Copied! <pre># Separa\u00e7\u00e3o de DADOS e LABEL\nX = df_final.drop(columns=[\"expenses\"])\ny = df_final[\"expenses\"]\n\n# Dividindo dados para TREINO e TESTE\nX_train, X_test, y_train, y_test = train_test_split(\n    X,\n    y,\n    test_size=0.3,\n    random_state=42\n)\n\n# Padroniza\u00e7\u00e3o dos dados\nss = StandardScaler()\nX_train_scaled = ss.fit_transform(X_train)\nX_test_scaled = ss.transform(X_test)\n</pre> # Separa\u00e7\u00e3o de DADOS e LABEL X = df_final.drop(columns=[\"expenses\"]) y = df_final[\"expenses\"]  # Dividindo dados para TREINO e TESTE X_train, X_test, y_train, y_test = train_test_split(     X,     y,     test_size=0.3,     random_state=42 )  # Padroniza\u00e7\u00e3o dos dados ss = StandardScaler() X_train_scaled = ss.fit_transform(X_train) X_test_scaled = ss.transform(X_test) In\u00a0[46]: Copied! <pre>X_train, X_train_scaled\n</pre> X_train, X_train_scaled Out[46]: <pre>(      age   bmi  children  genero  fumante  northwest  southeast  southwest\n 138    54  31.9         3       1        0      False       True      False\n 381    55  30.7         0       0        1      False      False      False\n 292    25  45.5         2       0        1      False       True      False\n 1090   47  36.2         0       0        1      False       True      False\n 893    47  38.9         2       0        1      False       True      False\n ...   ...   ...       ...     ...      ...        ...        ...        ...\n 1096   51  35.0         2       1        1      False      False      False\n 1131   27  45.9         2       0        0      False      False       True\n 1295   20  22.0         1       0        0      False      False       True\n 861    38  28.0         3       1        0      False      False       True\n 1127   35  35.9         2       1        0      False       True      False\n \n [935 rows x 8 columns],\n array([[ 1.07135822,  0.21232198,  1.59987002, ..., -0.57776193,\n          1.64630418, -0.57282196],\n        [ 1.14282796,  0.01300366, -0.90578906, ..., -0.57776193,\n         -0.60742116, -0.57282196],\n        [-1.00126436,  2.47126303,  0.76465033, ..., -0.57776193,\n          1.64630418, -0.57282196],\n        ...,\n        [-1.35861308, -1.43205422, -0.07056936, ..., -0.57776193,\n         -0.60742116,  1.74574312],\n        [-0.07215769, -0.43546258,  1.59987002, ..., -0.57776193,\n         -0.60742116,  1.74574312],\n        [-0.28656692,  0.87671641,  0.76465033, ..., -0.57776193,\n          1.64630418, -0.57282196]]))</pre> <p>Agora vamos treinar nossos dados, vamos fazer dois modelos:</p> <ol> <li>modelo de regress\u00e3o linear simples.</li> <li>modelo de rede neural</li> </ol> <p>Ao final, vamos compara os resultados.</p> In\u00a0[47]: Copied! <pre># fun\u00e7ao para facilitar o calculo das m\u00e9tricas\n\ndef metricas(X_tr_scaled, y_tr, y_ts, y_pr, model, id_modelo):\n  y_pr_tr = model.predict(X_tr_scaled)\n\n  # Erro quadr\u00e1tico m\u00e9dio\n  print(f\"MSE do TREINO ({id_modelo}): \", mean_squared_error(y_tr, y_pr_tr))\n  print(f\"MSE do TESTE \u00a0({id_modelo}): \", mean_squared_error(y_ts, y_pr))\n\n  # Erro absoluto m\u00e9dio\n  print(f\"MAE do TREINO ({id_modelo}): \", mean_absolute_error(y_tr, y_pr_tr))\n  print(f\"MAE do TESTE \u00a0({id_modelo}): \", mean_absolute_error(y_ts, y_pr))\n\n  # R\u00b2\n  print(f\"R\u00b2 do TREINO ({id_modelo}): \", r2_score(y_tr, y_pr_tr))\n  print(f\"R\u00b2 do TESTE \u00a0({id_modelo}): \", r2_score(y_ts, y_pr))\n</pre> # fun\u00e7ao para facilitar o calculo das m\u00e9tricas  def metricas(X_tr_scaled, y_tr, y_ts, y_pr, model, id_modelo):   y_pr_tr = model.predict(X_tr_scaled)    # Erro quadr\u00e1tico m\u00e9dio   print(f\"MSE do TREINO ({id_modelo}): \", mean_squared_error(y_tr, y_pr_tr))   print(f\"MSE do TESTE \u00a0({id_modelo}): \", mean_squared_error(y_ts, y_pr))    # Erro absoluto m\u00e9dio   print(f\"MAE do TREINO ({id_modelo}): \", mean_absolute_error(y_tr, y_pr_tr))   print(f\"MAE do TESTE \u00a0({id_modelo}): \", mean_absolute_error(y_ts, y_pr))    # R\u00b2   print(f\"R\u00b2 do TREINO ({id_modelo}): \", r2_score(y_tr, y_pr_tr))   print(f\"R\u00b2 do TESTE \u00a0({id_modelo}): \", r2_score(y_ts, y_pr)) In\u00a0[48]: Copied! <pre># Treinando o modelo usando sklearn\nmodel_lr = LinearRegression()\nmodel_lr.fit(X_train_scaled, y_train)\n\n# Fazendo as predi\u00e7\u00f5es\ny_pred = model_lr.predict(X_test_scaled)\n</pre> # Treinando o modelo usando sklearn model_lr = LinearRegression() model_lr.fit(X_train_scaled, y_train)  # Fazendo as predi\u00e7\u00f5es y_pred = model_lr.predict(X_test_scaled) In\u00a0[49]: Copied! <pre># Metricas para regress\u00e3o linear\nmetricas(X_train_scaled, y_train, y_test, y_pred, model_lr, \"Reg Linear\")\n</pre> # Metricas para regress\u00e3o linear metricas(X_train_scaled, y_train, y_test, y_pred, model_lr, \"Reg Linear\") <pre>MSE do TREINO (Reg Linear):  35810116.96256572\nMSE do TESTE \u00a0(Reg Linear):  38939165.63000257\nMAE do TREINO (Reg Linear):  4165.7883312974745\nMAE do TESTE \u00a0(Reg Linear):  4181.631594223737\nR\u00b2 do TREINO (Reg Linear):  0.7362844577541661\nR\u00b2 do TESTE \u00a0(Reg Linear):  0.772442225318259\n</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre> In\u00a0[50]: Copied! <pre>import tensorflow as tf\n\n# Cria o modelo de rede neural\n# aqui devemos definir ao menos a quantidade de camadas, a quantidade de neuronios, o tipo de ativacao ...\nmodel_rn = tf.keras.models.Sequential([\n    tf.keras.layers.Dense(64, activation='relu', input_shape=[X_train_scaled.shape[1]]),\n    tf.keras.layers.Dense(16, activation='relu',),\n    tf.keras.layers.Dense(1)\n])\n\n# Compila o modelo\nmodel_rn.compile(optimizer='adam', loss='mean_squared_error', metrics=['mae'])\n\n# Treina o modelo\nhistorico_epochs = model_rn.fit(X_train_scaled, y_train, epochs=100, validation_split=0.2)\n\n# Fazendo as predi\u00e7\u00f5es\ny_pr = model_rn.predict(X_test_scaled)\n</pre> import tensorflow as tf  # Cria o modelo de rede neural # aqui devemos definir ao menos a quantidade de camadas, a quantidade de neuronios, o tipo de ativacao ... model_rn = tf.keras.models.Sequential([     tf.keras.layers.Dense(64, activation='relu', input_shape=[X_train_scaled.shape[1]]),     tf.keras.layers.Dense(16, activation='relu',),     tf.keras.layers.Dense(1) ])  # Compila o modelo model_rn.compile(optimizer='adam', loss='mean_squared_error', metrics=['mae'])  # Treina o modelo historico_epochs = model_rn.fit(X_train_scaled, y_train, epochs=100, validation_split=0.2)  # Fazendo as predi\u00e7\u00f5es y_pr = model_rn.predict(X_test_scaled) <pre>Epoch 1/100\n24/24 [==============================] - 1s 14ms/step - loss: 308024192.0000 - mae: 13181.6006 - val_loss: 296421696.0000 - val_mae: 12449.0557\nEpoch 2/100\n24/24 [==============================] - 0s 6ms/step - loss: 307994464.0000 - mae: 13180.5371 - val_loss: 296391872.0000 - val_mae: 12447.9141\nEpoch 3/100\n24/24 [==============================] - 0s 6ms/step - loss: 307956576.0000 - mae: 13179.2100 - val_loss: 296349440.0000 - val_mae: 12446.3809\nEpoch 4/100\n24/24 [==============================] - 0s 5ms/step - loss: 307902272.0000 - mae: 13177.3838 - val_loss: 296288992.0000 - val_mae: 12444.2891\nEpoch 5/100\n24/24 [==============================] - 0s 6ms/step - loss: 307824352.0000 - mae: 13174.8447 - val_loss: 296201984.0000 - val_mae: 12441.3770\nEpoch 6/100\n24/24 [==============================] - 0s 6ms/step - loss: 307709760.0000 - mae: 13171.2451 - val_loss: 296075840.0000 - val_mae: 12437.2754\nEpoch 7/100\n24/24 [==============================] - 0s 6ms/step - loss: 307544896.0000 - mae: 13166.1885 - val_loss: 295892704.0000 - val_mae: 12431.5859\nEpoch 8/100\n24/24 [==============================] - 0s 6ms/step - loss: 307314016.0000 - mae: 13159.2715 - val_loss: 295643712.0000 - val_mae: 12423.9736\nEpoch 9/100\n24/24 [==============================] - 0s 6ms/step - loss: 306994528.0000 - mae: 13150.1514 - val_loss: 295318528.0000 - val_mae: 12414.2021\nEpoch 10/100\n24/24 [==============================] - 0s 4ms/step - loss: 306591456.0000 - mae: 13138.3623 - val_loss: 294892576.0000 - val_mae: 12401.7129\nEpoch 11/100\n24/24 [==============================] - 0s 3ms/step - loss: 306071232.0000 - mae: 13123.6416 - val_loss: 294359424.0000 - val_mae: 12386.4053\nEpoch 12/100\n24/24 [==============================] - 0s 3ms/step - loss: 305421440.0000 - mae: 13105.7822 - val_loss: 293715392.0000 - val_mae: 12368.1982\nEpoch 13/100\n24/24 [==============================] - 0s 3ms/step - loss: 304651936.0000 - mae: 13084.4570 - val_loss: 292936992.0000 - val_mae: 12346.3252\nEpoch 14/100\n24/24 [==============================] - 0s 4ms/step - loss: 303713824.0000 - mae: 13059.1729 - val_loss: 292033600.0000 - val_mae: 12321.2598\nEpoch 15/100\n24/24 [==============================] - 0s 4ms/step - loss: 302645632.0000 - mae: 13029.8467 - val_loss: 290954816.0000 - val_mae: 12291.6406\nEpoch 16/100\n24/24 [==============================] - 0s 4ms/step - loss: 301404064.0000 - mae: 12995.9268 - val_loss: 289723520.0000 - val_mae: 12257.9385\nEpoch 17/100\n24/24 [==============================] - 0s 4ms/step - loss: 299979488.0000 - mae: 12957.6992 - val_loss: 288364448.0000 - val_mae: 12220.7383\nEpoch 18/100\n24/24 [==============================] - 0s 4ms/step - loss: 298385440.0000 - mae: 12915.3516 - val_loss: 286831680.0000 - val_mae: 12179.0605\nEpoch 19/100\n24/24 [==============================] - 0s 4ms/step - loss: 296624672.0000 - mae: 12867.6387 - val_loss: 285127488.0000 - val_mae: 12132.7871\nEpoch 20/100\n24/24 [==============================] - 0s 3ms/step - loss: 294684672.0000 - mae: 12815.3584 - val_loss: 283254048.0000 - val_mae: 12081.8770\nEpoch 21/100\n24/24 [==============================] - 0s 4ms/step - loss: 292528736.0000 - mae: 12758.1953 - val_loss: 281211328.0000 - val_mae: 12026.5293\nEpoch 22/100\n24/24 [==============================] - 0s 4ms/step - loss: 290164832.0000 - mae: 12695.2744 - val_loss: 279027968.0000 - val_mae: 11967.0859\nEpoch 23/100\n24/24 [==============================] - 0s 3ms/step - loss: 287577312.0000 - mae: 12626.9883 - val_loss: 276615744.0000 - val_mae: 11901.2656\nEpoch 24/100\n24/24 [==============================] - 0s 3ms/step - loss: 284817920.0000 - mae: 12550.3613 - val_loss: 273862208.0000 - val_mae: 11827.1309\nEpoch 25/100\n24/24 [==============================] - 0s 4ms/step - loss: 281801760.0000 - mae: 12469.6982 - val_loss: 271013600.0000 - val_mae: 11749.6084\nEpoch 26/100\n24/24 [==============================] - 0s 4ms/step - loss: 278670464.0000 - mae: 12383.8594 - val_loss: 268082704.0000 - val_mae: 11669.3584\nEpoch 27/100\n24/24 [==============================] - 0s 3ms/step - loss: 275324800.0000 - mae: 12294.7109 - val_loss: 265058576.0000 - val_mae: 11585.3271\nEpoch 28/100\n24/24 [==============================] - 0s 4ms/step - loss: 271782560.0000 - mae: 12197.9414 - val_loss: 261658544.0000 - val_mae: 11491.6621\nEpoch 29/100\n24/24 [==============================] - 0s 3ms/step - loss: 268054400.0000 - mae: 12095.4717 - val_loss: 258102448.0000 - val_mae: 11393.0254\nEpoch 30/100\n24/24 [==============================] - 0s 4ms/step - loss: 264061936.0000 - mae: 11985.5469 - val_loss: 254433904.0000 - val_mae: 11290.2676\nEpoch 31/100\n24/24 [==============================] - 0s 4ms/step - loss: 259988720.0000 - mae: 11871.6328 - val_loss: 250552624.0000 - val_mae: 11180.4414\nEpoch 32/100\n24/24 [==============================] - 0s 3ms/step - loss: 255628976.0000 - mae: 11750.6670 - val_loss: 246568560.0000 - val_mae: 11067.1133\nEpoch 33/100\n24/24 [==============================] - 0s 4ms/step - loss: 251240272.0000 - mae: 11625.0967 - val_loss: 242364048.0000 - val_mae: 10946.6680\nEpoch 34/100\n24/24 [==============================] - 0s 3ms/step - loss: 246592896.0000 - mae: 11494.1426 - val_loss: 238034336.0000 - val_mae: 10821.3848\nEpoch 35/100\n24/24 [==============================] - 0s 3ms/step - loss: 241746208.0000 - mae: 11357.7549 - val_loss: 233718192.0000 - val_mae: 10694.5723\nEpoch 36/100\n24/24 [==============================] - 0s 4ms/step - loss: 236915920.0000 - mae: 11214.3076 - val_loss: 228979280.0000 - val_mae: 10556.7324\nEpoch 37/100\n24/24 [==============================] - 0s 3ms/step - loss: 231722160.0000 - mae: 11063.3906 - val_loss: 224265856.0000 - val_mae: 10417.8896\nEpoch 38/100\n24/24 [==============================] - 0s 4ms/step - loss: 226510224.0000 - mae: 10910.9033 - val_loss: 219460704.0000 - val_mae: 10274.6670\nEpoch 39/100\n24/24 [==============================] - 0s 4ms/step - loss: 221185728.0000 - mae: 10749.5986 - val_loss: 214382576.0000 - val_mae: 10123.2861\nEpoch 40/100\n24/24 [==============================] - 0s 4ms/step - loss: 215703184.0000 - mae: 10582.2109 - val_loss: 209248960.0000 - val_mae: 9968.8867\nEpoch 41/100\n24/24 [==============================] - 0s 4ms/step - loss: 210073680.0000 - mae: 10410.6133 - val_loss: 204216192.0000 - val_mae: 9817.5371\nEpoch 42/100\n24/24 [==============================] - 0s 3ms/step - loss: 204534592.0000 - mae: 10238.3750 - val_loss: 199093456.0000 - val_mae: 9661.6475\nEpoch 43/100\n24/24 [==============================] - 0s 3ms/step - loss: 198908512.0000 - mae: 10058.8135 - val_loss: 193889456.0000 - val_mae: 9503.5029\nEpoch 44/100\n24/24 [==============================] - 0s 3ms/step - loss: 193218880.0000 - mae: 9879.5518 - val_loss: 188626656.0000 - val_mae: 9339.9531\nEpoch 45/100\n24/24 [==============================] - 0s 4ms/step - loss: 187512288.0000 - mae: 9696.0898 - val_loss: 183381088.0000 - val_mae: 9174.8506\nEpoch 46/100\n24/24 [==============================] - 0s 3ms/step - loss: 181829760.0000 - mae: 9505.8057 - val_loss: 178038800.0000 - val_mae: 9007.2891\nEpoch 47/100\n24/24 [==============================] - 0s 3ms/step - loss: 176051024.0000 - mae: 9314.3721 - val_loss: 172765568.0000 - val_mae: 8845.7617\nEpoch 48/100\n24/24 [==============================] - 0s 4ms/step - loss: 170342736.0000 - mae: 9126.3125 - val_loss: 167594320.0000 - val_mae: 8682.2070\nEpoch 49/100\n24/24 [==============================] - 0s 3ms/step - loss: 164712736.0000 - mae: 8933.8652 - val_loss: 162215952.0000 - val_mae: 8508.7910\nEpoch 50/100\n24/24 [==============================] - 0s 4ms/step - loss: 159002160.0000 - mae: 8743.4521 - val_loss: 157105120.0000 - val_mae: 8346.0391\nEpoch 51/100\n24/24 [==============================] - 0s 3ms/step - loss: 153383632.0000 - mae: 8549.1221 - val_loss: 151866928.0000 - val_mae: 8176.3745\nEpoch 52/100\n24/24 [==============================] - 0s 5ms/step - loss: 147751280.0000 - mae: 8351.1963 - val_loss: 146628912.0000 - val_mae: 8006.8911\nEpoch 53/100\n24/24 [==============================] - 0s 15ms/step - loss: 142311600.0000 - mae: 8158.2930 - val_loss: 141649424.0000 - val_mae: 7839.0576\nEpoch 54/100\n24/24 [==============================] - 0s 7ms/step - loss: 137052288.0000 - mae: 7968.6030 - val_loss: 136781648.0000 - val_mae: 7673.2632\nEpoch 55/100\n24/24 [==============================] - 0s 3ms/step - loss: 131805904.0000 - mae: 7776.8003 - val_loss: 131958016.0000 - val_mae: 7506.0562\nEpoch 56/100\n24/24 [==============================] - 0s 3ms/step - loss: 126633736.0000 - mae: 7588.6479 - val_loss: 127325848.0000 - val_mae: 7339.7520\nEpoch 57/100\n24/24 [==============================] - 0s 4ms/step - loss: 121830688.0000 - mae: 7398.9072 - val_loss: 122614352.0000 - val_mae: 7165.6499\nEpoch 58/100\n24/24 [==============================] - 0s 3ms/step - loss: 116867616.0000 - mae: 7212.1631 - val_loss: 118210936.0000 - val_mae: 6997.6812\nEpoch 59/100\n24/24 [==============================] - 0s 4ms/step - loss: 112218944.0000 - mae: 7029.5034 - val_loss: 113806984.0000 - val_mae: 6825.0791\nEpoch 60/100\n24/24 [==============================] - 0s 3ms/step - loss: 107603248.0000 - mae: 6847.2158 - val_loss: 109771576.0000 - val_mae: 6672.4443\nEpoch 61/100\n24/24 [==============================] - 0s 3ms/step - loss: 103244584.0000 - mae: 6683.3677 - val_loss: 105706608.0000 - val_mae: 6524.2261\nEpoch 62/100\n24/24 [==============================] - 0s 3ms/step - loss: 99132856.0000 - mae: 6517.2505 - val_loss: 101598928.0000 - val_mae: 6364.3096\nEpoch 63/100\n24/24 [==============================] - 0s 4ms/step - loss: 94970952.0000 - mae: 6355.7822 - val_loss: 98016152.0000 - val_mae: 6222.1416\nEpoch 64/100\n24/24 [==============================] - 0s 3ms/step - loss: 91231920.0000 - mae: 6205.1357 - val_loss: 94391016.0000 - val_mae: 6073.1323\nEpoch 65/100\n24/24 [==============================] - 0s 3ms/step - loss: 87387648.0000 - mae: 6050.4199 - val_loss: 90797160.0000 - val_mae: 5926.0024\nEpoch 66/100\n24/24 [==============================] - 0s 4ms/step - loss: 83801384.0000 - mae: 5911.8970 - val_loss: 87456216.0000 - val_mae: 5787.4624\nEpoch 67/100\n24/24 [==============================] - 0s 4ms/step - loss: 80357032.0000 - mae: 5770.2314 - val_loss: 84332704.0000 - val_mae: 5654.8472\nEpoch 68/100\n24/24 [==============================] - 0s 4ms/step - loss: 77195456.0000 - mae: 5631.3193 - val_loss: 81285416.0000 - val_mae: 5519.2588\nEpoch 69/100\n24/24 [==============================] - 0s 4ms/step - loss: 74181616.0000 - mae: 5500.9248 - val_loss: 78512632.0000 - val_mae: 5397.8213\nEpoch 70/100\n24/24 [==============================] - 0s 4ms/step - loss: 71399392.0000 - mae: 5376.7144 - val_loss: 75814560.0000 - val_mae: 5279.1787\nEpoch 71/100\n24/24 [==============================] - 0s 3ms/step - loss: 68731824.0000 - mae: 5250.6655 - val_loss: 73385264.0000 - val_mae: 5164.4263\nEpoch 72/100\n24/24 [==============================] - 0s 4ms/step - loss: 66265680.0000 - mae: 5141.7153 - val_loss: 70985144.0000 - val_mae: 5072.7891\nEpoch 73/100\n24/24 [==============================] - 0s 4ms/step - loss: 63865572.0000 - mae: 5033.4941 - val_loss: 68804264.0000 - val_mae: 4990.0488\nEpoch 74/100\n24/24 [==============================] - 0s 3ms/step - loss: 61669300.0000 - mae: 4936.6753 - val_loss: 66616820.0000 - val_mae: 4909.1758\nEpoch 75/100\n24/24 [==============================] - 0s 4ms/step - loss: 59600328.0000 - mae: 4844.8169 - val_loss: 64678952.0000 - val_mae: 4847.2295\nEpoch 76/100\n24/24 [==============================] - 0s 4ms/step - loss: 57748048.0000 - mae: 4766.2852 - val_loss: 62831856.0000 - val_mae: 4788.0566\nEpoch 77/100\n24/24 [==============================] - 0s 3ms/step - loss: 55978840.0000 - mae: 4693.2549 - val_loss: 61138988.0000 - val_mae: 4733.3950\nEpoch 78/100\n24/24 [==============================] - 0s 4ms/step - loss: 54305580.0000 - mae: 4625.1113 - val_loss: 59558924.0000 - val_mae: 4679.4077\nEpoch 79/100\n24/24 [==============================] - 0s 4ms/step - loss: 52743128.0000 - mae: 4570.7480 - val_loss: 57956868.0000 - val_mae: 4630.3262\nEpoch 80/100\n24/24 [==============================] - 0s 3ms/step - loss: 51295348.0000 - mae: 4522.2739 - val_loss: 56563732.0000 - val_mae: 4583.4443\nEpoch 81/100\n24/24 [==============================] - 0s 4ms/step - loss: 49967028.0000 - mae: 4478.7407 - val_loss: 55256244.0000 - val_mae: 4536.0591\nEpoch 82/100\n24/24 [==============================] - 0s 3ms/step - loss: 48723444.0000 - mae: 4436.0522 - val_loss: 54030732.0000 - val_mae: 4496.7080\nEpoch 83/100\n24/24 [==============================] - 0s 4ms/step - loss: 47607720.0000 - mae: 4397.7729 - val_loss: 52838856.0000 - val_mae: 4457.5830\nEpoch 84/100\n24/24 [==============================] - 0s 3ms/step - loss: 46555212.0000 - mae: 4364.5078 - val_loss: 51807856.0000 - val_mae: 4426.5640\nEpoch 85/100\n24/24 [==============================] - 0s 3ms/step - loss: 45606780.0000 - mae: 4334.0249 - val_loss: 50827476.0000 - val_mae: 4393.8535\nEpoch 86/100\n24/24 [==============================] - 0s 4ms/step - loss: 44714728.0000 - mae: 4307.4604 - val_loss: 49917180.0000 - val_mae: 4365.0024\nEpoch 87/100\n24/24 [==============================] - 0s 3ms/step - loss: 43917060.0000 - mae: 4287.4868 - val_loss: 49070520.0000 - val_mae: 4346.1450\nEpoch 88/100\n24/24 [==============================] - 0s 3ms/step - loss: 43161264.0000 - mae: 4267.1626 - val_loss: 48292316.0000 - val_mae: 4328.0166\nEpoch 89/100\n24/24 [==============================] - 0s 3ms/step - loss: 42456712.0000 - mae: 4254.2334 - val_loss: 47557792.0000 - val_mae: 4314.3003\nEpoch 90/100\n24/24 [==============================] - 0s 3ms/step - loss: 41833936.0000 - mae: 4242.4316 - val_loss: 46893772.0000 - val_mae: 4299.5166\nEpoch 91/100\n24/24 [==============================] - 0s 3ms/step - loss: 41240580.0000 - mae: 4231.1001 - val_loss: 46278236.0000 - val_mae: 4285.2363\nEpoch 92/100\n24/24 [==============================] - 0s 3ms/step - loss: 40719432.0000 - mae: 4226.0356 - val_loss: 45693584.0000 - val_mae: 4276.3940\nEpoch 93/100\n24/24 [==============================] - 0s 4ms/step - loss: 40220296.0000 - mae: 4220.7168 - val_loss: 45120600.0000 - val_mae: 4267.1113\nEpoch 94/100\n24/24 [==============================] - 0s 3ms/step - loss: 39756344.0000 - mae: 4217.3608 - val_loss: 44617428.0000 - val_mae: 4261.2793\nEpoch 95/100\n24/24 [==============================] - 0s 4ms/step - loss: 39327236.0000 - mae: 4208.3306 - val_loss: 44190656.0000 - val_mae: 4252.0391\nEpoch 96/100\n24/24 [==============================] - 0s 3ms/step - loss: 38952060.0000 - mae: 4206.3081 - val_loss: 43728744.0000 - val_mae: 4246.5986\nEpoch 97/100\n24/24 [==============================] - 0s 4ms/step - loss: 38572184.0000 - mae: 4198.7144 - val_loss: 43350212.0000 - val_mae: 4241.7441\nEpoch 98/100\n24/24 [==============================] - 0s 3ms/step - loss: 38272360.0000 - mae: 4199.6626 - val_loss: 42952100.0000 - val_mae: 4241.5894\nEpoch 99/100\n24/24 [==============================] - 0s 4ms/step - loss: 37951040.0000 - mae: 4196.4678 - val_loss: 42595540.0000 - val_mae: 4237.7051\nEpoch 100/100\n24/24 [==============================] - 0s 4ms/step - loss: 37669696.0000 - mae: 4190.8159 - val_loss: 42283788.0000 - val_mae: 4233.1113\n13/13 [==============================] - 0s 2ms/step\n</pre> In\u00a0[51]: Copied! <pre>df_historico = pd.DataFrame(historico_epochs.history)\ndf_historico.info()\n\ndf_historico[['loss','val_loss']].plot()\nplt.show();\n</pre> df_historico = pd.DataFrame(historico_epochs.history) df_historico.info()  df_historico[['loss','val_loss']].plot() plt.show();  <pre>&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 100 entries, 0 to 99\nData columns (total 4 columns):\n #   Column    Non-Null Count  Dtype  \n---  ------    --------------  -----  \n 0   loss      100 non-null    float64\n 1   mae       100 non-null    float64\n 2   val_loss  100 non-null    float64\n 3   val_mae   100 non-null    float64\ndtypes: float64(4)\nmemory usage: 3.2 KB\n</pre> In\u00a0[52]: Copied! <pre># Metricas para regress\u00e3o linear\nmetricas(X_train_scaled, y_train, y_test, y_pr, model_rn, \"rede neural\")\n</pre> # Metricas para regress\u00e3o linear metricas(X_train_scaled, y_train, y_test, y_pr, model_rn, \"rede neural\") <pre>30/30 [==============================] - 0s 2ms/step\nMSE do TREINO (rede neural):  38467686.13248875\nMSE do TESTE \u00a0(rede neural):  44636508.86689253\nMAE do TREINO (rede neural):  4196.846846059544\nMAE do TESTE \u00a0(rede neural):  4426.687228262982\nR\u00b2 do TREINO (rede neural):  0.7167133880635896\nR\u00b2 do TESTE \u00a0(rede neural):  0.7391473478444126\n</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre> In\u00a0[\u00a0]: Copied! <pre># Lendo o dataset\ndf = pd.read_csv(\"advertising.csv\")\ndf.head()\n</pre> # Lendo o dataset df = pd.read_csv(\"advertising.csv\") df.head() In\u00a0[\u00a0]: Copied! <pre>\n</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre> In\u00a0[53]: Copied! <pre># Carregando o dataset\ndata = pd.read_csv('turnover.csv')\ndata.head()\n</pre> # Carregando o dataset data = pd.read_csv('turnover.csv') data.head() Out[53]: satisfaction_level last_evaluation number_project average_montly_hours time_spend_company Work_accident left promotion_last_5years sales salary 0 0.38 0.53 2 157 3 0 1 0 sales low 1 0.80 0.86 5 262 6 0 1 0 sales medium 2 0.11 0.88 7 272 4 0 1 0 sales medium 3 0.72 0.87 5 223 5 0 1 0 sales low 4 0.37 0.52 2 159 3 0 1 0 sales low In\u00a0[54]: Copied! <pre># Removendo duplicatas\ndata.drop_duplicates(inplace=True)\n\n# Criando o LabelEncoder\nle = LabelEncoder()\n\n# Convertendo strings em n\u00fameros\ndata['salary'] = le.fit_transform(data['salary'])\ndata['sales'] = le.fit_transform(data['sales'])\n</pre> # Removendo duplicatas data.drop_duplicates(inplace=True)  # Criando o LabelEncoder le = LabelEncoder()  # Convertendo strings em n\u00fameros data['salary'] = le.fit_transform(data['salary']) data['sales'] = le.fit_transform(data['sales']) In\u00a0[55]: Copied! <pre># Separando features do label\nX = data.drop(columns=[\"left\"])\ny = data[\"left\"]\n\n# Dividindo os dados em TREINO e TESTE\nX_train, X_test, y_train, y_test = train_test_split(\n    X,\n    y,\n    test_size=0.3,\n    random_state=42)\n\n# Padroniza\u00e7\u00e3o dos dados\nss = StandardScaler()\nX_train_scaled = ss.fit_transform(X_train)\nX_test_scaled = ss.transform(X_test)\n</pre> # Separando features do label X = data.drop(columns=[\"left\"]) y = data[\"left\"]  # Dividindo os dados em TREINO e TESTE X_train, X_test, y_train, y_test = train_test_split(     X,     y,     test_size=0.3,     random_state=42)  # Padroniza\u00e7\u00e3o dos dados ss = StandardScaler() X_train_scaled = ss.fit_transform(X_train) X_test_scaled = ss.transform(X_test) In\u00a0[56]: Copied! <pre>from sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score\n\n\n# Modelo baseline: regress\u00e3o log\u00edstica\nlogreg = LogisticRegression()\nlogreg.fit(X_train_scaled, y_train)\ny_pred_logreg = logreg.predict(X_test_scaled)\n\n# Calcula a acur\u00e1cia da predi\u00e7\u00e3o\naccuracy_logreg = accuracy_score(y_test, y_pred_logreg)\nprint(\"ACC (regress\u00e3o log\u00edstica):\", accuracy_logreg)\n</pre> from sklearn.linear_model import LogisticRegression from sklearn.metrics import accuracy_score   # Modelo baseline: regress\u00e3o log\u00edstica logreg = LogisticRegression() logreg.fit(X_train_scaled, y_train) y_pred_logreg = logreg.predict(X_test_scaled)  # Calcula a acur\u00e1cia da predi\u00e7\u00e3o accuracy_logreg = accuracy_score(y_test, y_pred_logreg) print(\"ACC (regress\u00e3o log\u00edstica):\", accuracy_logreg) <pre>ACC (regress\u00e3o log\u00edstica): 0.8315730961645359\n</pre> <p>Dense(1, activation='sigmoid'): Esta configura\u00e7\u00e3o na \u00faltima camada utiliza a fun\u00e7\u00e3o de ativa\u00e7\u00e3o 'sigmoid' para produzir uma probabilidade como sa\u00edda.</p> <p>loss='binary_crossentropy': Essa fun\u00e7\u00e3o de perda \u00e9 adequada para problemas de classifica\u00e7\u00e3o bin\u00e1ria, onde as classes s\u00e3o mutuamente exclusivas.</p> <p>metrics=['accuracy']: A acur\u00e1cia \u00e9 uma m\u00e9trica \u00fatil para avalia\u00e7\u00e3o em tarefas de classifica\u00e7\u00e3o, indicando a porcentagem de classifica\u00e7\u00f5es corretas.</p> In\u00a0[\u00a0]: Copied! <pre>import tensorflow as tf\n\n# Cria o modelo de rede neural\n# aqui devemos definir ao menos a quantidade de camadas, a quantidade de neuronios, o tipo de ativacao ...\nmodel_rn = tf.keras.models.Sequential([\n    tf.keras.layers.Dense(64, activation='relu', input_shape=[X_train_scaled.shape[1]]),\n    tf.keras.layers.Dense(16, activation='relu'),\n    tf.keras.layers.Dense(1, activation='sigmoid')\n])\n\n# Compila o modelo para classifica\u00e7\u00e3o bin\u00e1ria\nmodel_rn.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n\n# Treina o modelo\nhistorico_epochs = model_rn.fit(X_train_scaled, y_train, epochs=100, validation_split=0.2)\n\n\n# Fazendo as predi\u00e7\u00f5es\ny_pr = model_rn.predict(X_test_scaled)\n</pre> import tensorflow as tf  # Cria o modelo de rede neural # aqui devemos definir ao menos a quantidade de camadas, a quantidade de neuronios, o tipo de ativacao ... model_rn = tf.keras.models.Sequential([     tf.keras.layers.Dense(64, activation='relu', input_shape=[X_train_scaled.shape[1]]),     tf.keras.layers.Dense(16, activation='relu'),     tf.keras.layers.Dense(1, activation='sigmoid') ])  # Compila o modelo para classifica\u00e7\u00e3o bin\u00e1ria model_rn.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])  # Treina o modelo historico_epochs = model_rn.fit(X_train_scaled, y_train, epochs=100, validation_split=0.2)   # Fazendo as predi\u00e7\u00f5es y_pr = model_rn.predict(X_test_scaled) In\u00a0[61]: Copied! <pre>df_historico = pd.DataFrame(historico_epochs.history)\ndf_historico.info()\n\ndf_historico[['loss','val_loss']].plot()\nplt.show();\n\ndf_historico[['accuracy','val_accuracy']].plot()\nplt.show();\n</pre> df_historico = pd.DataFrame(historico_epochs.history) df_historico.info()  df_historico[['loss','val_loss']].plot() plt.show();  df_historico[['accuracy','val_accuracy']].plot() plt.show(); <pre>&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 100 entries, 0 to 99\nData columns (total 4 columns):\n #   Column        Non-Null Count  Dtype  \n---  ------        --------------  -----  \n 0   loss          100 non-null    float64\n 1   accuracy      100 non-null    float64\n 2   val_loss      100 non-null    float64\n 3   val_accuracy  100 non-null    float64\ndtypes: float64(4)\nmemory usage: 3.2 KB\n</pre> In\u00a0[65]: Copied! <pre># 'y_pr' s\u00e3o as probabilidades previstas pelo seu modelo de forma binaria\ny_pred_binario = (y_pr &gt; 0.5).astype(int)\n\n# Calcula a acur\u00e1cia\naccuracy_rn = accuracy_score(y_test, y_pred_binario)\nprint(\"Accuracy:\", accuracy_rn)\n</pre> # 'y_pr' s\u00e3o as probabilidades previstas pelo seu modelo de forma binaria y_pred_binario = (y_pr &gt; 0.5).astype(int)  # Calcula a acur\u00e1cia accuracy_rn = accuracy_score(y_test, y_pred_binario) print(\"Accuracy:\", accuracy_rn) <pre>Accuracy: 0.9727626459143969\n</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre> In\u00a0[\u00a0]: Copied! <pre>### seu c\u00f3digo...\n</pre> ### seu c\u00f3digo... In\u00a0[\u00a0]: Copied! <pre># Carregando o dataset\ndata = pd.read_csv('Churn_Modelling.csv')\ndata.head()\n</pre> # Carregando o dataset data = pd.read_csv('Churn_Modelling.csv') data.head() In\u00a0[\u00a0]: Copied! <pre>\n</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre>"},{"location":"aulas/IA/lab07/Praticando_redes_neurais_com_Tensorflow.html#trabalhando-com-redes-neurais-com-tensorflow","title":"Trabalhando com Redes Neurais com TensorFlow\u00b6","text":"<p>Neste m\u00f3dulo, exploraremos os fundamentos das redes neurais e aprenderemos a aplicar esses conceitos poderosos usando a biblioteca TensorFlow. O TensorFlow n\u00e3o apenas facilita a constru\u00e7\u00e3o e o treinamento de modelos complexos, mas tamb\u00e9m oferece ferramentas robustas para o processamento de dados, essenciais para qualquer projeto de machine learning.</p>"},{"location":"aulas/IA/lab07/Praticando_redes_neurais_com_Tensorflow.html#objetivos-de-aprendizado","title":"Objetivos de Aprendizado\u00b6","text":"<ul> <li>Entender o funcionamento das redes neurais.</li> <li>Desenvolver habilidades pr\u00e1ticas em modelagem e treinamento de redes neurais com TensorFlow.</li> <li>Aplicar redes neurais em problemas reais de classifica\u00e7\u00e3o e regress\u00e3o.</li> </ul>"},{"location":"aulas/IA/lab07/Praticando_redes_neurais_com_Tensorflow.html#desafios-a-serem-explorados","title":"Desafios a Serem Explorados\u00b6","text":"<ol> <li><p>Problema de Regress\u00e3o</p> <ul> <li>Contexto: Utilizaremos um conjunto de dados com o desafio enfrentado pelos planos de sa\u00fade na estimativa de gastos por segurado.</li> <li>Modelo Sugerido: Rede neural com m\u00faltiplas camadas densas.</li> <li>M\u00e9tricas de Avalia\u00e7\u00e3o: RMSE (Root Mean Square Error) e R2-score para quantificar a diferen\u00e7a entre os valores preditos e os reais.</li> </ul> </li> <li><p>Problema de Classifica\u00e7\u00e3o</p> <ul> <li>Contexto: otimizar processos de RH.Onde o objetivo \u00e9 prever se um colaborador ir\u00e1 deixar a empresa ou n\u00e3o.</li> <li>Modelo Sugerido: Rede neural scom m\u00faltiplas camadas densas para classifica\u00e7\u00e3o multiclasse.</li> <li>M\u00e9tricas de Avalia\u00e7\u00e3o: Acur\u00e1cia e matriz de confus\u00e3o para avaliar o desempenho do modelo.</li> </ul> </li> </ol>"},{"location":"aulas/IA/lab07/Praticando_redes_neurais_com_Tensorflow.html#pre-processamento-e-tratamento-de-dados","title":"Pr\u00e9-processamento e Tratamento de Dados\u00b6","text":"<p>Antes de aplicar o treinamento de modelos, \u00e9 essencial realizar o pr\u00e9-processamento e o tratamento adequado dos dados. Esse processo inclui:</p> <ul> <li>Limpeza de Dados: Remo\u00e7\u00e3o de valores ausentes ou corre\u00e7\u00e3o de dados corrompidos.</li> <li>Normaliza\u00e7\u00e3o/Padroniza\u00e7\u00e3o: Escalonamento dos valores num\u00e9ricos para que o modelo n\u00e3o seja enviesado por caracter\u00edsticas com escalas grandes.</li> <li>Codifica\u00e7\u00e3o de Vari\u00e1veis Categ\u00f3ricas: Transforma\u00e7\u00e3o de vari\u00e1veis categ\u00f3ricas em formatos num\u00e9ricos que podem ser interpretados pelo modelo, como one-hot encoding.</li> </ul> <p>Vamos come\u00e7ar!!!</p>"},{"location":"aulas/IA/lab07/Praticando_redes_neurais_com_Tensorflow.html#problema-de-regressao","title":"Problema de Regress\u00e3o\u00b6","text":"<p>Nosso problema \u00e9 o desafio enfrentado pelos planos de sa\u00fade na estimativa de gastos por segurado.</p> <p>Poder estimar este valor permite uma melhor aloca\u00e7\u00e3o de recursos e uma gest\u00e3o mais eficiente dos custos operacionais.</p> <p>Do ponto de vista pr\u00e1tico, utilizaremos uma base bastante conhecida contendo informa\u00e7\u00f5es sobre os segurados (como idade, g\u00eanero, regi\u00e3o de resid\u00eancia, entre outros).</p> <p>Esses atributos s\u00e3o comumente usados para prever os custos m\u00e9dicos de um segurado, o que pode ser \u00fatil para companhias de seguros na precifica\u00e7\u00e3o de ap\u00f3lices ou na identifica\u00e7\u00e3o de segmentos de clientes com diferentes perfis de risco.</p>"},{"location":"aulas/IA/lab07/Praticando_redes_neurais_com_Tensorflow.html#preste-atencao","title":"Preste aten\u00e7\u00e3o\u00b6","text":"<p>O nosso atributo alvo \u00e9 <code>expenses</code> que caracteriza o valor gasto.</p> <p>Os outros atributos s\u00e3o possiveis entradas de dados.</p> <p>Nosso objetivo \u00e9 praticar redes neurais, por essa raz\u00e3o e apenas por isso, vamos simplificar a an\u00e1lise e considerar todas outras colunas como entradas de dados. Em outros casos, \u00e9 necess\u00e1rio realizar uma explora\u00e7\u00e3o de dados mais profunda.</p>"},{"location":"aulas/IA/lab07/Praticando_redes_neurais_com_Tensorflow.html#ate-aqui-nao-existe-nenhum-novidade-ou-pelo-menos-nao-deveria","title":"at\u00e9 aqui n\u00e3o existe nenhum novidade, ou pelo menos n\u00e3o deveria...\u00b6","text":"<p>A novidade vem agora, onde vamos implementar um modelo de rede neural com Tensorflow</p> <p>Vamos seguir os seguintes passos:</p> <ul> <li>criar o modelo de rede neural</li> <li>compilar o modelo</li> <li>treinar o modelo</li> </ul>"},{"location":"aulas/IA/lab07/Praticando_redes_neurais_com_Tensorflow.html#desafio","title":"Desafio\u00b6","text":"<p>otimize o treinamento do modelo alterando a quantidade de camadas, a quantidade de neuronios, o tipo de ativacao ...</p>"},{"location":"aulas/IA/lab07/Praticando_redes_neurais_com_Tensorflow.html#desafio","title":"Desafio\u00b6","text":"<p>Aplica\u00e7\u00e3o em Marketing</p> <p>As an\u00e1lises preditivas t\u00eam uma variedade de aplica\u00e7\u00f5es no marketing, ajudando as empresas a entenderem o comportamento do consumidor, otimizar estrat\u00e9gias de vendas e melhorar o retorno sobre o investimento em publicidade. O potencial das aplica\u00e7\u00f5es \u00e9 vasto, incluindo, mas n\u00e3o se limitando, a previs\u00e3o de demanda, segmenta\u00e7\u00e3o de mercado, recomenda\u00e7\u00e3o de produtos e otimiza\u00e7\u00e3o de pre\u00e7os. As aplica\u00e7\u00f5es listadas podem ser tratadas como problemas supervisionados, n\u00e3o supervisionados e at\u00e9 mesmo an\u00e1lises estat\u00edsticas cl\u00e1ssicas. Tudo depende do objetivo principal da demanda.</p>"},{"location":"aulas/IA/lab07/Praticando_redes_neurais_com_Tensorflow.html#definicao-do-problema-e-dos-dados","title":"Defini\u00e7\u00e3o do problema e dos dados\u00b6","text":"<p>Nosso case tem como objetivo representar o impacto dos investimentos em publicidade nos resultados de vendas de um produto ou servi\u00e7o. Esse problema \u00e9 relevante no marketing porque as empresas precisam entender como a aloca\u00e7\u00e3o de recursos em diferentes canais de publicidade afeta suas vendas, para otimizar suas estrat\u00e9gias de marketing e maximizar o retorno sobre o investimento.</p> <p>Para esta modelagem utilizaremos outra base de dados cl\u00e1ssica. As vari\u00e1veis que a comp\u00f5em s\u00e3o:</p> <ul> <li>TV: Valor gasto em publicidade na televis\u00e3o.</li> <li>Radio: Valor gasto em publicidade no r\u00e1dio.</li> <li>Newspaper: Valor gasto em publicidade em jornais.</li> <li>Sales: N\u00famero de vendas do produto ou servi\u00e7o.</li> </ul> <p>Essas vari\u00e1veis representam os diferentes canais de publicidade e as vendas associadas \u00e0quela aloca\u00e7\u00e3o, permitindo que os analistas e profissionais de marketing avaliem o impacto de cada canal nas vendas totais.</p>"},{"location":"aulas/IA/lab07/Praticando_redes_neurais_com_Tensorflow.html#problema-de-classificacao","title":"Problema de Classifica\u00e7\u00e3o\u00b6","text":"<p>Defini\u00e7\u00e3o do problema e dos dados</p> <p>O problema em quest\u00e3o \u00e9 de classifica\u00e7\u00e3o bin\u00e1ria, onde o objetivo \u00e9 prever se um colaborador ir\u00e1 deixar a empresa ou n\u00e3o. Essa previs\u00e3o \u00e9 \u00fatil para o departamento de recursos humanos, pois permite identificar antecipadamente os funcion\u00e1rios com maior probabilidade de sair, possibilitando a implementa\u00e7\u00e3o de medidas preventivas para reten\u00e7\u00e3o de talentos.</p> <p>As vari\u00e1veis que comp\u00f5em a base e suas respectivas descri\u00e7\u00f5es s\u00e3o:</p> <ul> <li>satisfaction_level: N\u00edvel de satisfa\u00e7\u00e3o do colaborador com o trabalho, geralmente medido atrav\u00e9s de pesquisas de satisfa\u00e7\u00e3o ou avalia\u00e7\u00f5es internas.</li> <li>last_evaluation: \u00daltima avalia\u00e7\u00e3o de desempenho do colaborador, que pode ser realizada periodicamente pela empresa para acompanhar o progresso e a performance.</li> <li>number_project: N\u00famero de projetos em que o colaborador est\u00e1 atualmente envolvido, fornecendo uma medida da carga de trabalho e da diversidade de responsabilidades.</li> <li>average_montly_hours: M\u00e9dia de horas trabalhadas por m\u00eas pelo colaborador, um indicador do seu n\u00edvel de envolvimento e dedica\u00e7\u00e3o ao trabalho.</li> <li>time_spend_company: Tempo de perman\u00eancia do colaborador na empresa, em anos, que pode influenciar sua propens\u00e3o a deixar a organiza\u00e7\u00e3o.</li> <li>Work_accident: Indicador bin\u00e1rio que representa se o colaborador sofreu algum acidente de trabalho durante seu per\u00edodo na empresa.</li> <li>left: Vari\u00e1vel de destino bin\u00e1ria que indica se o colaborador deixou a empresa (1) ou permaneceu (0).</li> <li>promotion_last_5years: Indica se o colaborador recebeu alguma promo\u00e7\u00e3o nos \u00faltimos cinco anos, o que pode influenciar sua satisfa\u00e7\u00e3o e lealdade.</li> <li>sales: Departamento em que o colaborador trabalha, fornecendo informa\u00e7\u00f5es sobre a \u00e1rea de atua\u00e7\u00e3o e a equipe em que est\u00e1 inserido.</li> <li>salary: N\u00edvel salarial do colaborador, que pode ser classificado em baixo, m\u00e9dio ou alto, oferecendo uma indica\u00e7\u00e3o do seu status e remunera\u00e7\u00e3o na empresa.</li> </ul>"},{"location":"aulas/IA/lab07/Praticando_redes_neurais_com_Tensorflow.html#desafio","title":"Desafio\u00b6","text":"<p>otimize o modelo</p>"},{"location":"aulas/IA/lab07/Praticando_redes_neurais_com_Tensorflow.html#problema-de-classificacao-binaria-churn-de-clientes","title":"Problema de Classifica\u00e7\u00e3o Bin\u00e1ria \u2013 Churn de Clientes\u00b6","text":"<ul> <li>Contexto: Dataset com informa\u00e7\u00f5es demogr\u00e1ficas e financeiras de clientes de um banco, visando prever se o cliente ir\u00e1 encerrar sua conta (churn).</li> <li>M\u00e9tricas de Avalia\u00e7\u00e3o: Acur\u00e1cia, Precis\u00e3o, Recall, F1-score e AUC para avaliar a capacidade do modelo em identificar clientes propensos ao churn.</li> </ul>"},{"location":"aulas/IA/lab07/mlp.html","title":"Mlp","text":"In\u00a0[23]: Copied! <pre>import tensorflow as tf\nfrom tensorflow import keras\n</pre> import tensorflow as tf from tensorflow import keras  In\u00a0[25]: Copied! <pre>from tensorflow.keras import layers\n\n\nmodel = keras.Sequential([\n    layers.Dense(units=1, input_shape=[1])\n])\n\nmodel.summary()\n</pre> from tensorflow.keras import layers   model = keras.Sequential([     layers.Dense(units=1, input_shape=[1]) ])  model.summary()  <pre>Model: \"sequential_4\"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\n dense_4 (Dense)             (None, 1)                 2         \n                                                                 \n=================================================================\nTotal params: 2 (8.00 Byte)\nTrainable params: 2 (8.00 Byte)\nNon-trainable params: 0 (0.00 Byte)\n_________________________________________________________________\n</pre> In\u00a0[\u00a0]: Copied! <pre>## Sua resposta aqui...\n</pre> ## Sua resposta aqui...      In\u00a0[26]: Copied! <pre>model.compile(optimizer=tf.keras.optimizers.Adam(0.1), loss = 'mse')\n</pre> model.compile(optimizer=tf.keras.optimizers.Adam(0.1), loss = 'mse') In\u00a0[7]: Copied! <pre>!wget https://raw.githubusercontent.com/arnaldojr/cognitivecomputing/master/material/aulas/IA/lab07/SalesData.csv /content\n</pre> !wget https://raw.githubusercontent.com/arnaldojr/cognitivecomputing/master/material/aulas/IA/lab07/SalesData.csv /content  <pre>--2023-10-02 12:57:46--  https://raw.githubusercontent.com/arnaldojr/cognitivecomputing/master/material/aulas/IA/lab07/SalesData.csv\nResolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.110.133, 185.199.109.133, ...\nConnecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 11884 (12K) [text/plain]\nSaving to: \u2018SalesData.csv\u2019\n\n\r\nSalesData.csv         0%[                    ]       0  --.-KB/s               \r\nSalesData.csv       100%[===================&gt;]  11.61K  --.-KB/s    in 0s      \n\n2023-10-02 12:57:46 (39.1 MB/s) - \u2018SalesData.csv\u2019 saved [11884/11884]\n\n/content: Scheme missing.\nFINISHED --2023-10-02 12:57:46--\nTotal wall clock time: 0.2s\nDownloaded: 1 files, 12K in 0s (39.1 MB/s)\n</pre> In\u00a0[27]: Copied! <pre>import pandas as pd\nimport numpy as np\ndf = pd.read_csv('SalesData.csv')\ndf.info()\n\nX_train = df['Temperature']\ny_train = df['Revenue']\n\nprint(X_train)\n</pre> import pandas as pd import numpy as np df = pd.read_csv('SalesData.csv') df.info()  X_train = df['Temperature'] y_train = df['Revenue']  print(X_train) <pre>&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 500 entries, 0 to 499\nData columns (total 2 columns):\n #   Column       Non-Null Count  Dtype  \n---  ------       --------------  -----  \n 0   Temperature  500 non-null    float64\n 1   Revenue      500 non-null    float64\ndtypes: float64(2)\nmemory usage: 7.9 KB\n0      24.566884\n1      26.005191\n2      27.790554\n3      20.595335\n4      11.503498\n         ...    \n495    22.274899\n496    32.893092\n497    12.588157\n498    22.362402\n499    28.957736\nName: Temperature, Length: 500, dtype: float64\n</pre> In\u00a0[28]: Copied! <pre>import seaborn as sns\n\nsns.scatterplot(x=X_train, y=y_train);\n</pre> import seaborn as sns  sns.scatterplot(x=X_train, y=y_train); In\u00a0[\u00a0]: Copied! <pre>epochs_hist = model.fit(X_train, y_train, epochs=1000)\n</pre> epochs_hist = model.fit(X_train, y_train, epochs=1000) In\u00a0[30]: Copied! <pre>import pandas as pd\n\nhistory_df = pd.DataFrame(epochs_hist.history)\n\nhistory_df['loss'].plot();\n</pre> import pandas as pd  history_df = pd.DataFrame(epochs_hist.history)  history_df['loss'].plot(); In\u00a0[31]: Copied! <pre># Previs\u00f5es com o modelo treinado\ntemp = 5\nrevenue = model.predict([temp])\nprint('Revenue Predictions Using Trained ANN =', revenue)\n</pre> # Previs\u00f5es com o modelo treinado temp = 5 revenue = model.predict([temp]) print('Revenue Predictions Using Trained ANN =', revenue) <pre>1/1 [==============================] - 0s 160ms/step\nRevenue Predictions Using Trained ANN = [[152.05663]]\n</pre> In\u00a0[33]: Copied! <pre>from matplotlib import pyplot as plt\n\nplt.scatter(X_train, y_train, color = 'gray')\nplt.plot(X_train, model.predict(X_train), color = 'red')\nplt.ylabel('Revenue [dollars]')\nplt.xlabel('Temperature [degC]')\nplt.title('Revenue Generated vs. Temperature @Ice Cream Stand');\n</pre> from matplotlib import pyplot as plt  plt.scatter(X_train, y_train, color = 'gray') plt.plot(X_train, model.predict(X_train), color = 'red') plt.ylabel('Revenue [dollars]') plt.xlabel('Temperature [degC]') plt.title('Revenue Generated vs. Temperature @Ice Cream Stand'); <pre>16/16 [==============================] - 0s 3ms/step\n</pre> In\u00a0[\u00a0]: Copied! <pre>import pandas as pd\nimport numpy as np\nimport seaborn as sns\nfrom matplotlib import pyplot as plt\nfrom tensorflow.keras import layers\nimport tensorflow as tf\nfrom tensorflow import keras\n\ndef carregar_e_visualizar_dados():\n    # Carregar os dados\n    #!wget https://raw.githubusercontent.com/arnaldojr/cognitivecomputing/master/material/aulas/IA/lab07/SalesData.csv /content\n    df = pd.read_csv('SalesData.csv')\n    df.info()\n\n    # Separar os dados\n    X_train = df['Temperature']\n    y_train = df['Revenue']\n\n    # Visualizar os dados\n    sns.scatterplot(x=X_train, y=y_train)\n    plt.show()\n\n    return X_train, y_train\n\ndef criar_e_compilar_modelo():\n    # Criar o modelo\n    model = keras.Sequential([\n        layers.Dense(units=1, input_shape=[1])\n    ])\n\n    # Compilar o modelo\n    model.compile(optimizer=tf.keras.optimizers.Adam(0.1), loss='mse')\n    model.summary()\n\n    return model\n\ndef treinar_modelo(model, X_train, y_train, epochs=100):\n    historico_epochs = model.fit(X_train, y_train, epochs=epochs)\n    df_historico = pd.DataFrame(historico_epochs.history)\n    df_historico['loss'].plot()\n    plt.show()\n    return model\n\ndef avaliar_e_prever(model, X_train, y_train):\n    # Visualizar as predi\u00e7\u00f5es do modelo\n    plt.scatter(X_train, y_train, color='gray')\n    plt.plot(X_train, model.predict(X_train), color='red')\n    plt.ylabel('Receita [d\u00f3lares]')\n    plt.xlabel('Temperatura [\u00b0C]')\n    plt.title('Receita Gerada vs. Temperatura no Ponto de Venda de Sorvetes')\n    plt.show()\n\n    # Fazer uma previs\u00e3o\n    temp = 5\n    receita = model.predict([temp])\n    print('Previs\u00e3o de Receita Usando a ANN Treinada =', receita)\n\n# Carregar e visualizar os dados\nX_train, y_train = carregar_e_visualizar_dados()\n\n# Criar e compilar o modelo\nmodel = criar_e_compilar_modelo()\n\n# Treinar o modelo\nmodel = treinar_modelo(model, X_train, y_train)\n\n# Avaliar e fazer predi\u00e7\u00f5es\navaliar_e_prever(model, X_train, y_train)\n</pre> import pandas as pd import numpy as np import seaborn as sns from matplotlib import pyplot as plt from tensorflow.keras import layers import tensorflow as tf from tensorflow import keras  def carregar_e_visualizar_dados():     # Carregar os dados     #!wget https://raw.githubusercontent.com/arnaldojr/cognitivecomputing/master/material/aulas/IA/lab07/SalesData.csv /content     df = pd.read_csv('SalesData.csv')     df.info()      # Separar os dados     X_train = df['Temperature']     y_train = df['Revenue']      # Visualizar os dados     sns.scatterplot(x=X_train, y=y_train)     plt.show()      return X_train, y_train  def criar_e_compilar_modelo():     # Criar o modelo     model = keras.Sequential([         layers.Dense(units=1, input_shape=[1])     ])      # Compilar o modelo     model.compile(optimizer=tf.keras.optimizers.Adam(0.1), loss='mse')     model.summary()      return model  def treinar_modelo(model, X_train, y_train, epochs=100):     historico_epochs = model.fit(X_train, y_train, epochs=epochs)     df_historico = pd.DataFrame(historico_epochs.history)     df_historico['loss'].plot()     plt.show()     return model  def avaliar_e_prever(model, X_train, y_train):     # Visualizar as predi\u00e7\u00f5es do modelo     plt.scatter(X_train, y_train, color='gray')     plt.plot(X_train, model.predict(X_train), color='red')     plt.ylabel('Receita [d\u00f3lares]')     plt.xlabel('Temperatura [\u00b0C]')     plt.title('Receita Gerada vs. Temperatura no Ponto de Venda de Sorvetes')     plt.show()      # Fazer uma previs\u00e3o     temp = 5     receita = model.predict([temp])     print('Previs\u00e3o de Receita Usando a ANN Treinada =', receita)  # Carregar e visualizar os dados X_train, y_train = carregar_e_visualizar_dados()  # Criar e compilar o modelo model = criar_e_compilar_modelo()  # Treinar o modelo model = treinar_modelo(model, X_train, y_train)  # Avaliar e fazer predi\u00e7\u00f5es avaliar_e_prever(model, X_train, y_train)   In\u00a0[\u00a0]: Copied! <pre>### Seu c\u00f3digo aqui.....\n</pre> ### Seu c\u00f3digo aqui....."},{"location":"aulas/IA/lab07/mlp.html#2-aprendizagem-de-maquina","title":"2. Aprendizagem de m\u00e1quina\u00b6","text":""},{"location":"aulas/IA/lab07/mlp.html#objetivos","title":"Objetivos\u00b6","text":"<ul> <li>Praticar os algoritmos Perceptron e multilayer Perceptron (MLP)</li> <li>Conhecer uma intui\u00e7\u00e3o sobre fun\u00e7\u00e3o de ativa\u00e7\u00e3o, backpropagation</li> <li>Conhecer e praticar o framework TensorFlow</li> </ul>"},{"location":"aulas/IA/lab07/mlp.html#perceptron","title":"Perceptron\u00b6","text":"<p>Relembrando o neuronio artificial:</p>"},{"location":"aulas/IA/lab07/mlp.html#desafio1","title":"Desafio1\u00b6","text":"<p>Calcule a saida do perceptron abaixo:</p> <p>x0 = 2; x1 = 0; x2 = -1,24; bias = 1; w0 = 0; w1 = 2; w3 = 1; fun\u00e7\u00e3o de ativa\u00e7\u00e3o = Heaviside</p>"},{"location":"aulas/IA/lab07/mlp.html#resposta","title":"Resposta:\u00b6","text":""},{"location":"aulas/IA/lab07/mlp.html#implementacao-de-uma-rede-perceptron","title":"Implementa\u00e7\u00e3o de uma rede perceptron\u00b6","text":"<p>Vamos usar um framework de machine learnning chamado TensorFlow/keras para fazer esta implementa\u00e7\u00e3o.</p> <p>pip install tensorflow</p>"},{"location":"aulas/IA/lab07/mlp.html#layers","title":"Layers\u00b6","text":"<p>O arranjo de neuronios define a quantidade de camadas ou <code>layers</code> que a rede neural possui na rede perceptron possui apenas uma camada. Em uma rede MLP (multlayer perceptron) possui al\u00e9m das camadas de entrada e sa\u00edda, camadas ocultas ou <code>hiden layers</code>, essas redes tambem s\u00e3o conhecidas por redes densas ou fully-connected.</p>"},{"location":"aulas/IA/lab07/mlp.html#funao-de-ativacao","title":"Fun\u00e3o de ativa\u00e7\u00e3o\u00b6","text":"<p>\u00c9 basicamente uma fun\u00e7\u00e3o matematica que \u00e9 responsavel por ativar ou n\u00e3o a sa\u00edda do neuronio. Dentre as mais comuns se destaca a fun\u00e7\u00e3o ReLU (Rectifier linear unit)</p> <p>Outras fun\u00e7\u00f5es de ativa\u00e7\u00e3o muito utilizadas s\u00e3o:</p> <ul> <li>softplus</li> <li>elu</li> <li>sigmoid</li> <li>tanh</li> </ul>"},{"location":"aulas/IA/lab07/mlp.html#desafio-2","title":"Desafio 2\u00b6","text":"<p>Implemente a rede MLP abaixo usando TensorFlor/keras: fun\u00e7\u00e3o de ativa\u00e7\u00e3o Relu</p>"},{"location":"aulas/IA/lab07/mlp.html#backpropagation","title":"Backpropagation\u00b6","text":"<p>Trata-se de uma t\u00e9cnica para realizar o ajuste dos pesos de uma rede neural. O objetivo de um rede neural \u00e9 sempre minimar o seu erro, tendo a menor <code>Loss</code>para guiar o modelo para a dire\u00e7\u00e3o certa.</p> <p>A fun\u00e7\u00e3o Loss mede o qu\u00e3o boa est\u00e3o as predi\u00e7\u00f5es darede, para problemas de regress\u00e3o s\u00e3o mais utilizados o MSE, ou MAE. J\u00e1 par classifia\u00e7\u00e3o, s\u00e3o utlizados BCE.</p> <p>Os algoritimos otimizadores s\u00e3o utilzados para ajustar os pesos das redes, o passo dado na descida do gradiente \u00e9 chamada de taxa de aprendizado e mais utilizados s\u00e3o:</p> <ul> <li>SGD</li> <li>RMSprop</li> <li>Adam</li> <li>Adadelta</li> <li>Adagrad</li> <li>Adamax</li> <li>Nadam</li> <li>Ftrl</li> </ul> <p></p> <p></p> <p>Cada itera\u00e7\u00e3o das amostras de treinamento \u00e9 chamada de bach e uma rodada completa de treinamento \u00e9 chamada de epoch. O numero</p>"},{"location":"aulas/IA/lab07/mlp.html#em-resumo-nos-fizemos-o-seguinte","title":"em resumo nos fizemos o seguinte:\u00b6","text":"<ul> <li>Carregar e Visualizar os Dados</li> <li>Criar e Compilar o Modelo</li> <li>Treinamento</li> <li>Avalia\u00e7\u00e3o e Predi\u00e7\u00e3o</li> </ul>"},{"location":"aulas/IA/lab07/mlp.html#desafio-implementacao-end-to-end-mlp","title":"Desafio: Implementa\u00e7\u00e3o end-to-end MLP\u00b6","text":"<p>Realize o treinamento de uma rede MLP para o dataset Fashion MNIST. Um guia passo a passo pode ser encontrado no link https://www.tensorflow.org/tutorials/keras/classification.</p>"},{"location":"aulas/IA/lab08/Exemplo_CNN_Dataset_CIFAR10_com_Salvamento_no_GDrive.html","title":"O keras passa a salvar o melhor modelo pela acur\u00e1cia de valida\u00e7\u00e3o","text":"In\u00a0[1]: Copied! <pre>from keras.datasets import cifar10\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom keras.models import Sequential,load_model\nfrom keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, AveragePooling2D\n#from keras.utils import np_utils\nfrom keras.utils import to_categorical\n#from keras.utils import plot_model\nfrom keras.utils import plot_model\n\nimport tensorflow as tf\n</pre> from keras.datasets import cifar10 import numpy as np import matplotlib.pyplot as plt from keras.models import Sequential,load_model from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, AveragePooling2D #from keras.utils import np_utils from keras.utils import to_categorical #from keras.utils import plot_model from keras.utils import plot_model  import tensorflow as tf <p>Inicializa o Google Drive. \u00c9 necess\u00e1rio entrar com as credenciais do Gmail</p> In\u00a0[2]: Copied! <pre>from google.colab import drive\ndrive.mount('/content/drive')\n</pre> from google.colab import drive drive.mount('/content/drive') <pre>Mounted at /content/drive\n</pre> In\u00a0[3]: Copied! <pre>(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n</pre> (x_train, y_train), (x_test, y_test) = cifar10.load_data() <pre>Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n170498071/170498071 [==============================] - 13s 0us/step\n</pre> In\u00a0[4]: Copied! <pre>print(f'Train: X={x_train.shape}, y={y_train.shape}')\nprint(f'Test: X={x_test.shape}, y={y_test.shape}')\n# plot first few images\nfor i in range(9):\n\t# define subplot\n\tplt.subplot(330 + 1 + i)\n\t# plot raw pixel data\n\tplt.imshow(x_train[i])\n# show the figure\nplt.show()\n</pre> print(f'Train: X={x_train.shape}, y={y_train.shape}') print(f'Test: X={x_test.shape}, y={y_test.shape}') # plot first few images for i in range(9): \t# define subplot \tplt.subplot(330 + 1 + i) \t# plot raw pixel data \tplt.imshow(x_train[i]) # show the figure plt.show() <pre>Train: X=(50000, 32, 32, 3), y=(50000, 1)\nTest: X=(10000, 32, 32, 3), y=(10000, 1)\n</pre> In\u00a0[5]: Copied! <pre>x_train = x_train.astype('float32')/255\nx_test = x_test.astype('float32')/255\n</pre> x_train = x_train.astype('float32')/255 x_test = x_test.astype('float32')/255 <p>\"One-hot encoding\" aplicado aos r\u00f3tulos</p> In\u00a0[6]: Copied! <pre>num_classes = len(np.unique(y_train))\ny_train = to_categorical(y_train, num_classes)\ny_test = to_categorical(y_test, num_classes)\n</pre> num_classes = len(np.unique(y_train)) y_train = to_categorical(y_train, num_classes) y_test = to_categorical(y_test, num_classes) In\u00a0[7]: Copied! <pre>y_train\n</pre> y_train Out[7]: <pre>array([[0., 0., 0., ..., 0., 0., 0.],\n       [0., 0., 0., ..., 0., 0., 1.],\n       [0., 0., 0., ..., 0., 0., 1.],\n       ...,\n       [0., 0., 0., ..., 0., 0., 1.],\n       [0., 1., 0., ..., 0., 0., 0.],\n       [0., 1., 0., ..., 0., 0., 0.]], dtype=float32)</pre> In\u00a0[8]: Copied! <pre>num_classes\n</pre> num_classes Out[8]: <pre>10</pre> <p>divindo dataset de treinamento em treinamento, teste e valida\u00e7\u00e3o - Apenas para exemplo em um ambiente real as amostras devem ser seleciondas de forma aleat\u00f3ria</p> In\u00a0[9]: Copied! <pre>(x_train, x_valid) = x_train[5000:], x_train[:5000]\n(y_train, y_valid) = y_train[5000:], y_train[:5000]\n</pre> (x_train, x_valid) = x_train[5000:], x_train[:5000] (y_train, y_valid) = y_train[5000:], y_train[:5000] <p>Impress\u00e3o da forma do conjunto de treino</p> In\u00a0[10]: Copied! <pre>print('x_train shape:', x_train.shape)\n</pre> print('x_train shape:', x_train.shape) <pre>x_train shape: (45000, 32, 32, 3)\n</pre> In\u00a0[11]: Copied! <pre>print('x_valid shape:', x_valid.shape)\n</pre> print('x_valid shape:', x_valid.shape) <pre>x_valid shape: (5000, 32, 32, 3)\n</pre> <p>Impress\u00e3o do n\u00famero de imagens nos datasets de treinamento, teste e valida\u00e7\u00e3o</p> In\u00a0[12]: Copied! <pre>print(x_train.shape[0], 'train samples')\nprint(x_test.shape[0], 'test samples')\nprint(x_valid.shape[0], 'validation samples')\n</pre> print(x_train.shape[0], 'train samples') print(x_test.shape[0], 'test samples') print(x_valid.shape[0], 'validation samples') <pre>45000 train samples\n10000 test samples\n5000 validation samples\n</pre> <p>Um pouquinho de novos conceitos.</p> <p>Dropout: T\u00e9cnica de regulariza\u00e7\u00e3o usada para prevenir o overfitting em redes neurais. Consiste em \"desligar\" aleatoriamente alguns neur\u00f4nios durante o treinamento, for\u00e7ando a rede a n\u00e3o depender excessivamente de caracter\u00edsticas espec\u00edficas de entrada. Utilize dropout principalmente em redes densas (fully connected) e convolucionais para melhorar a generaliza\u00e7\u00e3o do modelo.</p> <p>Saiba mais em: https://www.deeplearningbook.com.br/capitulo-23-como-funciona-o-dropout/</p> <p>Batch Normalization: M\u00e9todo que normaliza as ativa\u00e7\u00f5es de uma camada para m\u00e9dia zero e vari\u00e2ncia unit\u00e1ria, utilizando estat\u00edsticas do mini-lote. Ajuda a acelerar o treinamento e a estabilizar a converg\u00eancia ao mitigar o problema de deslocamento interno das distribui\u00e7\u00f5es das ativa\u00e7\u00f5es. \u00c9 \u00fatil em praticamente todos os tipos de redes neurais, especialmente em redes profundas, para facilitar um treinamento mais r\u00e1pido e est\u00e1vel.</p> <p>Saiba mais em: https://machinelearningmastery.com/batch-normalization-for-training-of-deep-neural-networks/</p> In\u00a0[13]: Copied! <pre>## primeira tentativa\nmodel = Sequential()\n## CNN\nmodel.add(Conv2D(filters=64, kernel_size=3,  activation='relu', input_shape=(32, 32, 3), padding='same'))\nmodel.add(MaxPooling2D(pool_size=2))\nmodel.add(Conv2D(filters=128, kernel_size=3,  activation='relu'))\nmodel.add(MaxPooling2D(pool_size=2))\n\n## MLP\nmodel.add(Flatten())\nmodel.add(Dense(256, activation='relu'))\nmodel.add(Dropout(0.2))\nmodel.add(Dense(128, activation='relu'))\nmodel.add(Dropout(0.2))\nmodel.add(Dense(num_classes, activation='softmax'))\n</pre> ## primeira tentativa model = Sequential() ## CNN model.add(Conv2D(filters=64, kernel_size=3,  activation='relu', input_shape=(32, 32, 3), padding='same')) model.add(MaxPooling2D(pool_size=2)) model.add(Conv2D(filters=128, kernel_size=3,  activation='relu')) model.add(MaxPooling2D(pool_size=2))  ## MLP model.add(Flatten()) model.add(Dense(256, activation='relu')) model.add(Dropout(0.2)) model.add(Dense(128, activation='relu')) model.add(Dropout(0.2)) model.add(Dense(num_classes, activation='softmax'))  <p>Tentem executar a rede configurando outras fun\u00e7\u00f5es de ativa\u00e7\u00e3o (como visto em nossa Aula 3) mais informa\u00e7\u00f5es em https://keras.io/activations/</p> In\u00a0[14]: Copied! <pre>plot_model(model, to_file='cnn-CIFAR10.png', show_shapes=True, show_layer_names=True)\n</pre> plot_model(model, to_file='cnn-CIFAR10.png', show_shapes=True, show_layer_names=True) Out[14]: <p>Compilando o modelo escolhendo como se dar\u00e1 nossa perda, otimiza\u00e7\u00e3o e m\u00e9tricas (par\u00e2metros do Keras)</p> <ul> <li>mais informa\u00e7\u00f5es em https://keras.io/losses/</li> <li>mais informa\u00e7\u00f5es em https://keras.io/optimizers/</li> <li>mais informa\u00e7\u00f5es em https://keras.io/metrics/</li> </ul> In\u00a0[15]: Copied! <pre>model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n</pre> model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy']) In\u00a0[16]: Copied! <pre>from keras.callbacks import ModelCheckpoint\n</pre> from keras.callbacks import ModelCheckpoint In\u00a0[17]: Copied! <pre>checkpointer = ModelCheckpoint(filepath='/content/drive/My Drive/modelocifar.h5', verbose=1,  save_best_only=True, monitor='val_accuracy') #\n\nhist = model.fit(x_train, y_train, batch_size=100, epochs=30, validation_data=(x_valid, y_valid), callbacks=[checkpointer], verbose=1, shuffle=True)\n</pre> checkpointer = ModelCheckpoint(filepath='/content/drive/My Drive/modelocifar.h5', verbose=1,  save_best_only=True, monitor='val_accuracy') #  hist = model.fit(x_train, y_train, batch_size=100, epochs=30, validation_data=(x_valid, y_valid), callbacks=[checkpointer], verbose=1, shuffle=True) <pre>Epoch 1/30\n450/450 [==============================] - ETA: 0s - loss: 1.6596 - accuracy: 0.3873\nEpoch 1: val_accuracy improved from -inf to 0.54340, saving model to /content/drive/My Drive/modelocifar.h5\n</pre> <pre>/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n  saving_api.save_model(\n</pre> <pre>\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r450/450 [==============================] - 23s 34ms/step - loss: 1.6596 - accuracy: 0.3873 - val_loss: 1.2678 - val_accuracy: 0.5434\nEpoch 2/30\n449/450 [============================&gt;.] - ETA: 0s - loss: 1.2054 - accuracy: 0.5708\nEpoch 2: val_accuracy improved from 0.54340 to 0.64180, saving model to /content/drive/My Drive/modelocifar.h5\n450/450 [==============================] - 15s 33ms/step - loss: 1.2050 - accuracy: 0.5710 - val_loss: 1.0195 - val_accuracy: 0.6418\nEpoch 3/30\n449/450 [============================&gt;.] - ETA: 0s - loss: 0.9949 - accuracy: 0.6510\nEpoch 3: val_accuracy improved from 0.64180 to 0.67520, saving model to /content/drive/My Drive/modelocifar.h5\n450/450 [==============================] - 14s 31ms/step - loss: 0.9948 - accuracy: 0.6510 - val_loss: 0.9110 - val_accuracy: 0.6752\nEpoch 4/30\n449/450 [============================&gt;.] - ETA: 0s - loss: 0.8725 - accuracy: 0.6961\nEpoch 4: val_accuracy improved from 0.67520 to 0.71120, saving model to /content/drive/My Drive/modelocifar.h5\n450/450 [==============================] - 15s 32ms/step - loss: 0.8724 - accuracy: 0.6962 - val_loss: 0.8161 - val_accuracy: 0.7112\nEpoch 5/30\n449/450 [============================&gt;.] - ETA: 0s - loss: 0.7531 - accuracy: 0.7382\nEpoch 5: val_accuracy improved from 0.71120 to 0.75360, saving model to /content/drive/My Drive/modelocifar.h5\n450/450 [==============================] - 14s 31ms/step - loss: 0.7537 - accuracy: 0.7379 - val_loss: 0.7239 - val_accuracy: 0.7536\nEpoch 6/30\n449/450 [============================&gt;.] - ETA: 0s - loss: 0.6821 - accuracy: 0.7607\nEpoch 6: val_accuracy improved from 0.75360 to 0.75420, saving model to /content/drive/My Drive/modelocifar.h5\n450/450 [==============================] - 14s 30ms/step - loss: 0.6823 - accuracy: 0.7607 - val_loss: 0.7095 - val_accuracy: 0.7542\nEpoch 7/30\n449/450 [============================&gt;.] - ETA: 0s - loss: 0.6144 - accuracy: 0.7873\nEpoch 7: val_accuracy did not improve from 0.75420\n450/450 [==============================] - 13s 29ms/step - loss: 0.6145 - accuracy: 0.7872 - val_loss: 0.7180 - val_accuracy: 0.7518\nEpoch 8/30\n449/450 [============================&gt;.] - ETA: 0s - loss: 0.5596 - accuracy: 0.8047\nEpoch 8: val_accuracy improved from 0.75420 to 0.75560, saving model to /content/drive/My Drive/modelocifar.h5\n450/450 [==============================] - 14s 31ms/step - loss: 0.5596 - accuracy: 0.8046 - val_loss: 0.7373 - val_accuracy: 0.7556\nEpoch 9/30\n449/450 [============================&gt;.] - ETA: 0s - loss: 0.5109 - accuracy: 0.8213\nEpoch 9: val_accuracy improved from 0.75560 to 0.76760, saving model to /content/drive/My Drive/modelocifar.h5\n450/450 [==============================] - 14s 31ms/step - loss: 0.5108 - accuracy: 0.8213 - val_loss: 0.7121 - val_accuracy: 0.7676\nEpoch 10/30\n449/450 [============================&gt;.] - ETA: 0s - loss: 0.4656 - accuracy: 0.8360\nEpoch 10: val_accuracy improved from 0.76760 to 0.78060, saving model to /content/drive/My Drive/modelocifar.h5\n450/450 [==============================] - 15s 33ms/step - loss: 0.4662 - accuracy: 0.8358 - val_loss: 0.6823 - val_accuracy: 0.7806\nEpoch 11/30\n449/450 [============================&gt;.] - ETA: 0s - loss: 0.4193 - accuracy: 0.8531\nEpoch 11: val_accuracy improved from 0.78060 to 0.78720, saving model to /content/drive/My Drive/modelocifar.h5\n450/450 [==============================] - 14s 31ms/step - loss: 0.4195 - accuracy: 0.8531 - val_loss: 0.6579 - val_accuracy: 0.7872\nEpoch 12/30\n449/450 [============================&gt;.] - ETA: 0s - loss: 0.3839 - accuracy: 0.8664\nEpoch 12: val_accuracy did not improve from 0.78720\n450/450 [==============================] - 13s 28ms/step - loss: 0.3836 - accuracy: 0.8664 - val_loss: 0.6945 - val_accuracy: 0.7870\nEpoch 13/30\n449/450 [============================&gt;.] - ETA: 0s - loss: 0.3553 - accuracy: 0.8731\nEpoch 13: val_accuracy did not improve from 0.78720\n450/450 [==============================] - 13s 29ms/step - loss: 0.3552 - accuracy: 0.8732 - val_loss: 0.7023 - val_accuracy: 0.7844\nEpoch 14/30\n449/450 [============================&gt;.] - ETA: 0s - loss: 0.3315 - accuracy: 0.8841\nEpoch 14: val_accuracy improved from 0.78720 to 0.78940, saving model to /content/drive/My Drive/modelocifar.h5\n450/450 [==============================] - 14s 31ms/step - loss: 0.3314 - accuracy: 0.8841 - val_loss: 0.7158 - val_accuracy: 0.7894\nEpoch 15/30\n449/450 [============================&gt;.] - ETA: 0s - loss: 0.3022 - accuracy: 0.8936\nEpoch 15: val_accuracy did not improve from 0.78940\n450/450 [==============================] - 13s 29ms/step - loss: 0.3022 - accuracy: 0.8937 - val_loss: 0.7378 - val_accuracy: 0.7864\nEpoch 16/30\n449/450 [============================&gt;.] - ETA: 0s - loss: 0.2873 - accuracy: 0.8997\nEpoch 16: val_accuracy did not improve from 0.78940\n450/450 [==============================] - 13s 28ms/step - loss: 0.2874 - accuracy: 0.8996 - val_loss: 0.7250 - val_accuracy: 0.7884\nEpoch 17/30\n449/450 [============================&gt;.] - ETA: 0s - loss: 0.2698 - accuracy: 0.9057\nEpoch 17: val_accuracy improved from 0.78940 to 0.79020, saving model to /content/drive/My Drive/modelocifar.h5\n450/450 [==============================] - 14s 31ms/step - loss: 0.2700 - accuracy: 0.9056 - val_loss: 0.7565 - val_accuracy: 0.7902\nEpoch 18/30\n449/450 [============================&gt;.] - ETA: 0s - loss: 0.2494 - accuracy: 0.9104\nEpoch 18: val_accuracy did not improve from 0.79020\n450/450 [==============================] - 13s 29ms/step - loss: 0.2496 - accuracy: 0.9103 - val_loss: 0.7710 - val_accuracy: 0.7846\nEpoch 19/30\n449/450 [============================&gt;.] - ETA: 0s - loss: 0.2389 - accuracy: 0.9173\nEpoch 19: val_accuracy did not improve from 0.79020\n450/450 [==============================] - 13s 29ms/step - loss: 0.2387 - accuracy: 0.9174 - val_loss: 0.8072 - val_accuracy: 0.7792\nEpoch 20/30\n449/450 [============================&gt;.] - ETA: 0s - loss: 0.2214 - accuracy: 0.9230\nEpoch 20: val_accuracy did not improve from 0.79020\n450/450 [==============================] - 13s 29ms/step - loss: 0.2213 - accuracy: 0.9230 - val_loss: 0.8105 - val_accuracy: 0.7858\nEpoch 21/30\n449/450 [============================&gt;.] - ETA: 0s - loss: 0.2198 - accuracy: 0.9239\nEpoch 21: val_accuracy did not improve from 0.79020\n450/450 [==============================] - 13s 28ms/step - loss: 0.2199 - accuracy: 0.9238 - val_loss: 0.8193 - val_accuracy: 0.7760\nEpoch 22/30\n449/450 [============================&gt;.] - ETA: 0s - loss: 0.2105 - accuracy: 0.9277\nEpoch 22: val_accuracy did not improve from 0.79020\n450/450 [==============================] - 13s 29ms/step - loss: 0.2103 - accuracy: 0.9278 - val_loss: 0.8385 - val_accuracy: 0.7788\nEpoch 23/30\n449/450 [============================&gt;.] - ETA: 0s - loss: 0.1959 - accuracy: 0.9337\nEpoch 23: val_accuracy did not improve from 0.79020\n450/450 [==============================] - 14s 31ms/step - loss: 0.1960 - accuracy: 0.9337 - val_loss: 0.8522 - val_accuracy: 0.7844\nEpoch 24/30\n450/450 [==============================] - ETA: 0s - loss: 0.1879 - accuracy: 0.9356\nEpoch 24: val_accuracy did not improve from 0.79020\n450/450 [==============================] - 14s 31ms/step - loss: 0.1879 - accuracy: 0.9356 - val_loss: 0.8254 - val_accuracy: 0.7874\nEpoch 25/30\n450/450 [==============================] - ETA: 0s - loss: 0.1892 - accuracy: 0.9346\nEpoch 25: val_accuracy did not improve from 0.79020\n450/450 [==============================] - 14s 31ms/step - loss: 0.1892 - accuracy: 0.9346 - val_loss: 0.8485 - val_accuracy: 0.7842\nEpoch 26/30\n449/450 [============================&gt;.] - ETA: 0s - loss: 0.1756 - accuracy: 0.9394\nEpoch 26: val_accuracy did not improve from 0.79020\n450/450 [==============================] - 13s 28ms/step - loss: 0.1754 - accuracy: 0.9395 - val_loss: 0.8510 - val_accuracy: 0.7872\nEpoch 27/30\n449/450 [============================&gt;.] - ETA: 0s - loss: 0.1663 - accuracy: 0.9429\nEpoch 27: val_accuracy did not improve from 0.79020\n450/450 [==============================] - 13s 30ms/step - loss: 0.1663 - accuracy: 0.9429 - val_loss: 0.9397 - val_accuracy: 0.7748\nEpoch 28/30\n449/450 [============================&gt;.] - ETA: 0s - loss: 0.1638 - accuracy: 0.9445\nEpoch 28: val_accuracy did not improve from 0.79020\n450/450 [==============================] - 14s 31ms/step - loss: 0.1640 - accuracy: 0.9444 - val_loss: 0.9216 - val_accuracy: 0.7844\nEpoch 29/30\n449/450 [============================&gt;.] - ETA: 0s - loss: 0.1631 - accuracy: 0.9444\nEpoch 29: val_accuracy did not improve from 0.79020\n450/450 [==============================] - 13s 29ms/step - loss: 0.1630 - accuracy: 0.9444 - val_loss: 0.8593 - val_accuracy: 0.7868\nEpoch 30/30\n449/450 [============================&gt;.] - ETA: 0s - loss: 0.1556 - accuracy: 0.9484\nEpoch 30: val_accuracy improved from 0.79020 to 0.79040, saving model to /content/drive/My Drive/modelocifar.h5\n450/450 [==============================] - 14s 30ms/step - loss: 0.1556 - accuracy: 0.9484 - val_loss: 0.8718 - val_accuracy: 0.7904\n</pre> In\u00a0[18]: Copied! <pre>plt.figure(1)\nplt.plot(hist.history['accuracy'])\nplt.plot(hist.history['val_accuracy'])\nplt.title('model accuracy')\nplt.ylabel('accuracy')\nplt.xlabel('epoch')\nplt.legend(['train', 'validation'], loc='upper left')\nplt.show()\n</pre> plt.figure(1) plt.plot(hist.history['accuracy']) plt.plot(hist.history['val_accuracy']) plt.title('model accuracy') plt.ylabel('accuracy') plt.xlabel('epoch') plt.legend(['train', 'validation'], loc='upper left') plt.show() <p>Carregar o melhor modelo que obteve a melhor acur\u00e1cia de valida\u00e7\u00e3o no treinamento</p> In\u00a0[19]: Copied! <pre>model = load_model(\"/content/drive/My Drive/modelocifar.h5\")\n</pre> model = load_model(\"/content/drive/My Drive/modelocifar.h5\") <p>Avaliar e imprimir a precis\u00e3o do teste</p> In\u00a0[20]: Copied! <pre>score = model.evaluate(x_test, y_test, verbose=0)\nprint('\\n', 'Test accuracy:', score[1])\n</pre> score = model.evaluate(x_test, y_test, verbose=0) print('\\n', 'Test accuracy:', score[1]) <pre>\n Test accuracy: 0.7854999899864197\n</pre> In\u00a0[21]: Copied! <pre>y_hat = model.predict(x_test)\n</pre> y_hat = model.predict(x_test) <pre>313/313 [==============================] - 1s 3ms/step\n</pre> In\u00a0[22]: Copied! <pre>y_hat[100,:]\n</pre> y_hat[100,:] Out[22]: <pre>array([1.03396337e-06, 3.92779587e-09, 2.90912110e-03, 1.52367875e-05,\n       6.07605755e-01, 2.14876439e-02, 6.69553160e-08, 3.67980659e-01,\n       3.33775603e-07, 6.63219666e-08], dtype=float32)</pre> In\u00a0[23]: Copied! <pre>np.argmax(y_hat[100,:])\n</pre> np.argmax(y_hat[100,:]) Out[23]: <pre>4</pre> <p>Definindo r\u00f3tulos de texto (r\u00f3tulos dispon\u00edveis na fonte original: https://www.cs.toronto.edu/~kriz/cifar.html)</p> In\u00a0[24]: Copied! <pre>cifar10_labels = ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n</pre> cifar10_labels = ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck'] <p>Plot de amostra aleat\u00f3ria de imagens de teste, r\u00f3tulos preditos e a \"ground truth\" advinda do dataset CIFAR-10</p> In\u00a0[25]: Copied! <pre>fig = plt.figure(figsize=(20, 8))\nfor i, idx in enumerate(np.random.choice(x_test.shape[0], size=32, replace=False)):\n    ax = fig.add_subplot(4, 8, i + 1, xticks=[], yticks=[])\n    ax.imshow(np.squeeze(x_test[idx]))\n    pred_idx = np.argmax(y_hat[idx])\n    true_idx = np.argmax(y_test[idx])\n    ax.set_title(\"{} ({})\".format(cifar10_labels[pred_idx], cifar10_labels[true_idx]),\n                 color=(\"green\" if pred_idx == true_idx else \"red\"))\n    # amostras corretamente classificadas em verde, incorretamente classificadas em vermelho\n</pre> fig = plt.figure(figsize=(20, 8)) for i, idx in enumerate(np.random.choice(x_test.shape[0], size=32, replace=False)):     ax = fig.add_subplot(4, 8, i + 1, xticks=[], yticks=[])     ax.imshow(np.squeeze(x_test[idx]))     pred_idx = np.argmax(y_hat[idx])     true_idx = np.argmax(y_test[idx])     ax.set_title(\"{} ({})\".format(cifar10_labels[pred_idx], cifar10_labels[true_idx]),                  color=(\"green\" if pred_idx == true_idx else \"red\"))     # amostras corretamente classificadas em verde, incorretamente classificadas em vermelho"},{"location":"aulas/IA/lab08/Exemplo_CNN_Dataset_CIFAR10_com_Salvamento_no_GDrive.html#1-carregando-bibliotecas","title":"1. Carregando Bibliotecas\u00b6","text":""},{"location":"aulas/IA/lab08/Exemplo_CNN_Dataset_CIFAR10_com_Salvamento_no_GDrive.html#2-carregando-o-dataset-pre-embaralhado-de-treinamento-bem-como-os-dados-de-teste","title":"2. Carregando o dataset pr\u00e9-embaralhado de treinamento bem como os dados de teste\u00b6","text":""},{"location":"aulas/IA/lab08/Exemplo_CNN_Dataset_CIFAR10_com_Salvamento_no_GDrive.html#3-redimensionando-as-imagens-e-dividindo-cada-pixel-em-cada-imagem-por-255","title":"3. Redimensionando as imagens e dividindo cada pixel em cada imagem por 255\u00b6","text":""},{"location":"aulas/IA/lab08/Exemplo_CNN_Dataset_CIFAR10_com_Salvamento_no_GDrive.html#4-dividindo-o-dataset-em-treinamento-teste-e-validacao","title":"4.  Dividindo o dataset em treinamento, teste e valida\u00e7\u00e3o\u00b6","text":""},{"location":"aulas/IA/lab08/Exemplo_CNN_Dataset_CIFAR10_com_Salvamento_no_GDrive.html#5-definindo-a-arquitetura-do-modelo-importante","title":"5. Definindo a arquitetura do modelo (IMPORTANTE!)\u00b6","text":"<p>Defina uma rede simples, vou sugerir a seguinte: LeNet-5</p> <ul> <li><p>2 camadas convolucionais de tamanho progressivamente crescente</p> </li> <li><p>Com \"maxpooling\" (2x2)</p> </li> <li><p>Uma camada do tipo totalmente conectada de 120 neur\u00f4nios</p> </li> <li><p>Uma camada do tipo totalmente conectada de 84 neur\u00f4nios</p> </li> <li><p>Ultimas camadas do tipo totalmente conectadas de 10 sa\u00eddas (10 classes de categoria de imagem)</p> </li> <li><p>\"Dropout\" de 0,2-0,3</p> </li> </ul>"},{"location":"aulas/IA/lab08/Exemplo_CNN_Dataset_CIFAR10_com_Salvamento_no_GDrive.html#6-compilando-o-modelo","title":"6. Compilando o modelo\u00b6","text":""},{"location":"aulas/IA/lab08/Exemplo_CNN_Dataset_CIFAR10_com_Salvamento_no_GDrive.html#7-treinando-o-modelo","title":"7. Treinando o modelo\u00b6","text":""},{"location":"aulas/IA/lab08/Exemplo_CNN_Dataset_CIFAR10_com_Salvamento_no_GDrive.html#o-keras-passa-a-salvar-o-melhor-modelo-pela-acuracia-de-validacao","title":"O keras passa a salvar o melhor modelo pela acur\u00e1cia de valida\u00e7\u00e3o\u00b6","text":""},{"location":"aulas/IA/lab08/Exemplo_CNN_Dataset_CIFAR10_com_Salvamento_no_GDrive.html#8-calculo-da-precisao-de-classificacao-no-dataset-de-testes","title":"8. C\u00e1lculo da precis\u00e3o de classifica\u00e7\u00e3o no dataset de testes\u00b6","text":""},{"location":"aulas/IA/lab08/Exemplo_CNN_Dataset_CIFAR10_com_Salvamento_no_GDrive.html#9-visualizar-algumas-predicoes","title":"9. Visualizar algumas predi\u00e7\u00f5es\u00b6","text":"<p>As visualiza\u00e7\u00f5es podem nos dar algumas dicas sobre por que a rede classifica erroneamente alguns objetos. Obtendo previs\u00f5es no conjunto de testes:</p>"},{"location":"aulas/IA/lab08/cnn-pratica.html","title":"Pr\u00e1tica","text":"In\u00a0[\u00a0]: Copied! <pre>import tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\n\n\nmodel = keras.Sequential([\n    layers.Flatten(input_shape=(400,600)),\n    layers.Dense(units=100)\n])\n\nmodel.summary()\n</pre> import tensorflow as tf from tensorflow import keras from tensorflow.keras import layers   model = keras.Sequential([     layers.Flatten(input_shape=(400,600)),     layers.Dense(units=100) ])  model.summary()  <pre>Model: \"sequential_1\"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\n flatten_1 (Flatten)         (None, 480000)            0         \n                                                                 \n dense_1 (Dense)             (None, 100)               48000100  \n                                                                 \n=================================================================\nTotal params: 48,000,100\nTrainable params: 48,000,100\nNon-trainable params: 0\n_________________________________________________________________\n</pre> In\u00a0[\u00a0]: Copied! <pre>import tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\n\n\nmodel_conv = keras.Sequential([\n    layers.Conv2D(\n        filters=100, \n        kernel_size=(3, 3), \n        activation='relu', \n        input_shape=(400, 600, 3),\n        name=\"conv_layer_1\"\n    ),\n])\n\nmodel.summary()\n</pre> import tensorflow as tf from tensorflow import keras from tensorflow.keras import layers   model_conv = keras.Sequential([     layers.Conv2D(         filters=100,          kernel_size=(3, 3),          activation='relu',          input_shape=(400, 600, 3),         name=\"conv_layer_1\"     ), ])  model.summary()  <pre>Model: \"sequential_9\"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\n conv2d_10 (Conv2D)          (None, 798, 598, 100)     2800      \n                                                                 \n=================================================================\nTotal params: 2,800\nTrainable params: 2,800\nNon-trainable params: 0\n_________________________________________________________________\n</pre> In\u00a0[\u00a0]: Copied! <pre>### Sua resposta aqui...\n</pre> ### Sua resposta aqui...    In\u00a0[\u00a0]: Copied! <pre>import tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\n\n\nmodel = keras.Sequential([\n    layers.Conv2D(filters=100, kernel_size=(3, 3), activation='relu', \n                  input_shape=(400, 600, 3), name=\"conv2d_layer\"),\n    layers.MaxPool2D(pool_size=2, strides=2, name=\"maxpool_layer\")\n])\n\nmodel.summary()\n</pre> import tensorflow as tf from tensorflow import keras from tensorflow.keras import layers   model = keras.Sequential([     layers.Conv2D(filters=100, kernel_size=(3, 3), activation='relu',                    input_shape=(400, 600, 3), name=\"conv2d_layer\"),     layers.MaxPool2D(pool_size=2, strides=2, name=\"maxpool_layer\") ])  model.summary() <pre>Model: \"sequential_8\"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\n conv2d_9 (Conv2D)           (None, 798, 598, 100)     2800      \n                                                                 \n max_pooling2d_5 (MaxPooling  (None, 399, 299, 100)    0         \n 2D)                                                             \n                                                                 \n=================================================================\nTotal params: 2,800\nTrainable params: 2,800\nNon-trainable params: 0\n_________________________________________________________________\n</pre> In\u00a0[\u00a0]: Copied! <pre>'''\n### suas respostas.....\n\n1.\n\n\n2.\n\n\n'''\n</pre> ''' ### suas respostas.....  1.   2.   ''' Out[\u00a0]: <pre>'\\n### suas respostas.....\\n\\n1.\\n\\n\\n2.\\n\\n\\n'</pre> In\u00a0[\u00a0]: Copied! <pre>import tensorflow as tf\nfrom tensorflow import keras\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom tensorflow.keras import layers\n</pre> import tensorflow as tf from tensorflow import keras import numpy as np import matplotlib.pyplot as plt from tensorflow.keras import layers In\u00a0[\u00a0]: Copied! <pre># Importa o dataset Fashion Mnist\nfashion_mnist = keras.datasets.fashion_mnist\n(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()\n\n#normaliza os dados para o pixel ficar com valores entre 0 e 1\ntrain_images = train_images / 255.0\ntest_images = test_images / 255.0\nclass_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n               'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\n</pre> # Importa o dataset Fashion Mnist fashion_mnist = keras.datasets.fashion_mnist (train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()  #normaliza os dados para o pixel ficar com valores entre 0 e 1 train_images = train_images / 255.0 test_images = test_images / 255.0 class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',                'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot'] In\u00a0[\u00a0]: Copied! <pre>train_images = train_images.reshape(-1,28,28,1)\nprint(train_images.shape)\ntest_images = test_images.reshape(-1,28,28,1)\ntest_images.shape\n</pre> train_images = train_images.reshape(-1,28,28,1) print(train_images.shape) test_images = test_images.reshape(-1,28,28,1) test_images.shape <pre>(60000, 28, 28, 1)\n</pre> Out[\u00a0]: <pre>(10000, 28, 28, 1)</pre> In\u00a0[\u00a0]: Copied! <pre>###### montar a arquitetura da rede neural\n\nfrom tensorflow.keras import layers\n\nmodel = keras.Sequential([\n\n#####-------CNN-------####\n# EXTRATOR DE CARACTER\u00cdSTICAS#\n\n    layers.Conv2D(5, (3,3), activation='relu', padding=\"same\", input_shape=(28, 28,1)),\n    layers.MaxPooling2D((2,2)),\n\n\n #######------ MLP-----###\n # CLASSIFICADOR  #\n    layers.Flatten(),\n    layers.Dense(120, activation='relu'),\n    layers.Dense(10, activation='softmax')  ###### neur\u00f4nios especialistas\n])\n\n\nmodel.summary()\n</pre> ###### montar a arquitetura da rede neural  from tensorflow.keras import layers  model = keras.Sequential([  #####-------CNN-------#### # EXTRATOR DE CARACTER\u00cdSTICAS#      layers.Conv2D(5, (3,3), activation='relu', padding=\"same\", input_shape=(28, 28,1)),     layers.MaxPooling2D((2,2)),    #######------ MLP-----###  # CLASSIFICADOR  #     layers.Flatten(),     layers.Dense(120, activation='relu'),     layers.Dense(10, activation='softmax')  ###### neur\u00f4nios especialistas ])   model.summary()  <pre>Model: \"sequential_11\"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\n conv2d_12 (Conv2D)          (None, 28, 28, 5)         50        \n                                                                 \n max_pooling2d_7 (MaxPooling  (None, 14, 14, 5)        0         \n 2D)                                                             \n                                                                 \n flatten_5 (Flatten)         (None, 980)               0         \n                                                                 \n dense_9 (Dense)             (None, 120)               117720    \n                                                                 \n dense_10 (Dense)            (None, 10)                1210      \n                                                                 \n=================================================================\nTotal params: 118,980\nTrainable params: 118,980\nNon-trainable params: 0\n_________________________________________________________________\n</pre> In\u00a0[\u00a0]: Copied! <pre>model.compile(optimizer='adam',\n              loss='sparse_categorical_crossentropy',\n              metrics=['accuracy'])\n\nepochs_hist = model.fit(train_images, train_labels, epochs=3, validation_split=0.2)\n</pre> model.compile(optimizer='adam',               loss='sparse_categorical_crossentropy',               metrics=['accuracy'])  epochs_hist = model.fit(train_images, train_labels, epochs=3, validation_split=0.2)  <pre>Epoch 1/3\n1500/1500 [==============================] - 23s 15ms/step - loss: 0.2374 - accuracy: 0.9128 - val_loss: 0.2589 - val_accuracy: 0.9027\nEpoch 2/3\n1500/1500 [==============================] - 24s 16ms/step - loss: 0.2136 - accuracy: 0.9217 - val_loss: 0.2328 - val_accuracy: 0.9143\nEpoch 3/3\n1500/1500 [==============================] - 21s 14ms/step - loss: 0.1950 - accuracy: 0.9287 - val_loss: 0.2393 - val_accuracy: 0.9117\n</pre> In\u00a0[\u00a0]: Copied! <pre>## exibe os graficos da fun\u00e7\u00e3o loss e acuracia\n\nhistory_df = pd.DataFrame(epochs_hist.history)\n\nhistory_df[['loss','val_loss']].plot();\nhistory_df[['accuracy','val_accuracy']].plot();\n</pre> ## exibe os graficos da fun\u00e7\u00e3o loss e acuracia  history_df = pd.DataFrame(epochs_hist.history)  history_df[['loss','val_loss']].plot(); history_df[['accuracy','val_accuracy']].plot();  In\u00a0[\u00a0]: Copied! <pre>#Validad\u00e7\u00e3o\ntrain_loss, train_acc = model.evaluate(train_images,  train_labels, verbose=2)\ntest_loss, test_acc = model.evaluate(test_images,  test_labels, verbose=2)\n</pre> #Validad\u00e7\u00e3o train_loss, train_acc = model.evaluate(train_images,  train_labels, verbose=2) test_loss, test_acc = model.evaluate(test_images,  test_labels, verbose=2)  <pre>1875/1875 - 10s - loss: 0.1883 - accuracy: 0.9318 - 10s/epoch - 5ms/step\n313/313 - 4s - loss: 0.2789 - accuracy: 0.8977 - 4s/epoch - 12ms/step\n</pre> In\u00a0[\u00a0]: Copied! <pre># Previs\u00f5es com o modelo treinado\n\npredictions = model.predict(test_images)\n</pre> # Previs\u00f5es com o modelo treinado  predictions = model.predict(test_images) <pre>313/313 [==============================] - 2s 6ms/step\n</pre> In\u00a0[\u00a0]: Copied! <pre>#Verica\u00e7\u00e3o dos itens preditos\n\nitem = 4000\n\nprint(\"\\nClasse predita foi {} com {:2.0f}%. Classe correta \u00e9 {}, {}.\".format(np.argmax(predictions[item]),\n                                                                 100*np.max(predictions[item]),\n                                                                 test_labels[item],\n                                                                 class_names[test_labels[item]]))\n\na=100*np.max(predictions[item])\n</pre> #Verica\u00e7\u00e3o dos itens preditos  item = 4000  print(\"\\nClasse predita foi {} com {:2.0f}%. Classe correta \u00e9 {}, {}.\".format(np.argmax(predictions[item]),                                                                  100*np.max(predictions[item]),                                                                  test_labels[item],                                                                  class_names[test_labels[item]]))  a=100*np.max(predictions[item]) <pre>\nClasse predita foi 0 com 100%. Classe correta \u00e9 0, T-shirt/top.\n</pre> In\u00a0[\u00a0]: Copied! <pre>def plot_image(i, predictions_array, true_label, img):\n  predictions_array, true_label, img = predictions_array[i], true_label[i], img[i]\n  plt.grid(False)\n  plt.xticks([])\n  plt.yticks([])\n\n  plt.imshow(img, cmap=plt.cm.binary)\n\n  predicted_label = np.argmax(predictions_array)\n  if predicted_label == true_label:\n    color = 'blue'\n  else:\n    color = 'red'\n\n  plt.xlabel(\"{} {:2.0f}% ({})\".format(class_names[predicted_label],\n                                100*np.max(predictions_array),\n                                class_names[true_label]),\n                                color=color)\n</pre> def plot_image(i, predictions_array, true_label, img):   predictions_array, true_label, img = predictions_array[i], true_label[i], img[i]   plt.grid(False)   plt.xticks([])   plt.yticks([])    plt.imshow(img, cmap=plt.cm.binary)    predicted_label = np.argmax(predictions_array)   if predicted_label == true_label:     color = 'blue'   else:     color = 'red'    plt.xlabel(\"{} {:2.0f}% ({})\".format(class_names[predicted_label],                                 100*np.max(predictions_array),                                 class_names[true_label]),                                 color=color) In\u00a0[\u00a0]: Copied! <pre>plt.figure(figsize=(6,3))\nplt.subplot(1,2,1)\nplot_image(item, predictions, test_labels, test_images)\nplt.show()\n</pre> plt.figure(figsize=(6,3)) plt.subplot(1,2,1) plot_image(item, predictions, test_labels, test_images) plt.show() In\u00a0[\u00a0]: Copied! <pre>###### Seu c\u00f3digo aqui......\n</pre> ###### Seu c\u00f3digo aqui......      In\u00a0[\u00a0]: Copied! <pre>###### Seu c\u00f3digo aqui......\n\n### Para testar se melhora\n\nmodel = keras.Sequential([\n    keras.Input(shape=(28, 28, 1)),  # imagem de entrada\n#####-------CNN-------#####\n    layers.Conv2D(32, (3,3), activation='relu', padding=\"same\"),\n    layers.BatchNormalization(),   \n    layers.Conv2D(64, (3,3), activation='relu', padding=\"same\"),\n    layers.BatchNormalization(),\n    layers.MaxPooling2D((2,2)),      \n\n    layers.Conv2D(128, (3,3), activation='relu', padding=\"same\"),\n    layers.BatchNormalization(),\n    layers.MaxPooling2D((2,2)),\n\n #######------ MLP-----####\n \n    # Flatten (transformar o mapa de caracter\u00edsticas em um vetor)\n    layers.Flatten(),\n    # Camadas densas para classifica\u00e7\u00e3o\n    layers.Dense(256, activation='relu'),\n    # layers.BatchNormalization(), # pode ajudar a estabilizar o treinamento, tem que testar!\n    layers.Dropout(0.5),\n    layers.Dense(10, activation='softmax') ###### neuroniios especialistas\n])\n\nmodel.summary()\n</pre> ###### Seu c\u00f3digo aqui......  ### Para testar se melhora  model = keras.Sequential([     keras.Input(shape=(28, 28, 1)),  # imagem de entrada #####-------CNN-------#####     layers.Conv2D(32, (3,3), activation='relu', padding=\"same\"),     layers.BatchNormalization(),        layers.Conv2D(64, (3,3), activation='relu', padding=\"same\"),     layers.BatchNormalization(),     layers.MaxPooling2D((2,2)),            layers.Conv2D(128, (3,3), activation='relu', padding=\"same\"),     layers.BatchNormalization(),     layers.MaxPooling2D((2,2)),   #######------ MLP-----####       # Flatten (transformar o mapa de caracter\u00edsticas em um vetor)     layers.Flatten(),     # Camadas densas para classifica\u00e7\u00e3o     layers.Dense(256, activation='relu'),     # layers.BatchNormalization(), # pode ajudar a estabilizar o treinamento, tem que testar!     layers.Dropout(0.5),     layers.Dense(10, activation='softmax') ###### neuroniios especialistas ])  model.summary()"},{"location":"aulas/IA/lab08/cnn-pratica.html#laboratorio-redes-neurais-convolucionais-cnns","title":"Laborat\u00f3rio: Redes Neurais Convolucionais (CNNs)\u00b6","text":""},{"location":"aulas/IA/lab08/cnn-pratica.html#objetivos","title":"Objetivos\u00b6","text":"<ul> <li>Conhecer e praticar Redes Neurais Convolucionais</li> <li>Conhecer uma intui\u00e7\u00e3o sobre Convolu\u00e7\u00e3o, Pooling</li> <li>Praticar a classifica\u00e7\u00e3o de objeto usando Keras/TensorFlow</li> </ul>"},{"location":"aulas/IA/lab08/cnn-pratica.html#material-de-apoio","title":"Material de Apoio\u00b6","text":"<ul> <li>Leitura complementar: cnn-pratica.md - Guia te\u00f3rico sobre CNNs</li> </ul>"},{"location":"aulas/IA/lab08/cnn-pratica.html#problema-com-mlps-tradicionais","title":"Problema com MLPs Tradicionais\u00b6","text":"<p>Imagine processar uma imagem 400\u00d7600 pixels com um MLP:</p> <ul> <li>Par\u00e2metros: 400 \u00d7 600 \u00d7 100 + 100 = 24.000.100 par\u00e2metros s\u00f3 na primeira camada!</li> <li>Problemas:<ul> <li>Ignora estrutura espacial</li> <li>Sens\u00edvel \u00e0 posi\u00e7\u00e3o</li> <li>Computacionalmente caro</li> <li>Overfitting garantido</li> </ul> </li> </ul>"},{"location":"aulas/IA/lab08/cnn-pratica.html#solucao-redes-neurais-convolucionais","title":"Solu\u00e7\u00e3o: Redes Neurais Convolucionais\u00b6","text":"<p>A Redes Neurais Convolucionais ou CNN (Convolutional Neural Network) ou at\u00e9 mesmo ConvNet, s\u00e3o redes neurais de aprendizado profundo, <code>Deep Learning</code> muito utilizadas na \u00e1rea de Vis\u00e3o Computacional <code>classifica\u00e7\u00e3o</code>,<code>detec\u00e7\u00e3o de objetos</code> ou <code>segmenta\u00e7\u00e3o sem\u00e2ntica</code>.</p> <ul> <li>Compartilhamento de pesos: Mesmos filtros em toda imagem</li> <li>Invari\u00e2ncia espacial: Reconhece padr\u00f5es independente da posi\u00e7\u00e3o</li> <li>Hierarquia de features: Bordas \u2192 Formas \u2192 Objetos</li> <li>Efici\u00eancia: Drasticamente menos par\u00e2metros</li> </ul> <p>Para compreender uma CNN, precisamos compreender o funcionamento de alguns blocos novos fundamentais.</p> <ul> <li>Extra\u00e7\u00e3o de caracteristicas</li> <li>Convolu\u00e7\u00e3o</li> <li>Pooling</li> </ul>"},{"location":"aulas/IA/lab08/cnn-pratica.html#convolucao","title":"Convolu\u00e7\u00e3o\u00b6","text":"<p>A convolu\u00e7\u00e3o  permite uma filtragem no dom\u00ednio espacial. Esse processo ocorre com a aplica\u00e7\u00e3o de filtros (pequenas matrizes), posicionadas sob cada pixel da imagem. Estes filtros, normalmente, s\u00e3o chamados de kernels (ou n\u00facleos). O resultado final do valor do pixel \u00e9 calculado atrav\u00e9s de um produto de convolu\u00e7\u00e3o.</p> <p>Normalmente os kernels s\u00e3o matrizes 3x3. E os pesos s\u00e3o ajustados a cada itera\u00e7\u00e3o pelo backpropagation</p> <p>Nesta imagem temos a imagem original em azul, o kernel em cinza varrendo a imagem e o resultado da convolu\u00e7\u00e3o em verde.</p> <p>Vamos analizar o que acontece em apenas um pixel da imagem:</p> <p>O resultado para cada pixel \u00e9 esse:</p> <p>O resultado em uma imagem \u00e9 o seguinte:</p>"},{"location":"aulas/IA/lab08/cnn-pratica.html#implementacao-em-codigo","title":"Implementa\u00e7\u00e3o em c\u00f3digo\u00b6","text":"<p>Para implementar \u00e9 simples.</p> <pre>layers.Conv2D(filters=100, kernel_size=(3, 3), activation='relu', input_shape=(height, width, channels))\n</pre> <p>Par\u00e2metros:</p> <ul> <li>filters: N\u00famero de filtros (kernels) - define quantos feature maps s\u00e3o gerados</li> <li>kernel_size: Tamanho do filtro - (3,3) \u00e9 mais comum</li> <li>activation: Fun\u00e7\u00e3o de ativa\u00e7\u00e3o aplicada ap\u00f3s convolu\u00e7\u00e3o</li> <li>input_shape: Formato da entrada (apenas na primeira camada)</li> </ul> <p>Outros Par\u00e2metros avan\u00e7ados:</p> <ul> <li>strides: Passo do filtro (default: (1,1))</li> <li>padding: 'valid' (sem padding) ou 'same' (mant\u00e9m dimens\u00e3o)</li> <li>dilation_rate: Convolu\u00e7\u00f5es dilatadas para campo receptivo maior</li> </ul>"},{"location":"aulas/IA/lab08/cnn-pratica.html#desafio-1","title":"Desafio 1\u00b6","text":"<p>Realize uma <code>An\u00e1lise de Par\u00e2metros</code> comparando a quantidade de <code>Total params</code>, em uma rede CNN e uma rede MLP. Em qual a quantidade de par\u00e2metros \u00e9 menor ou maior?</p> <p>adote:</p> <pre># Definindo dimens\u00f5es de uma imagem t\u00edpica\naltura, largura, canais = 400, 600, 3\n</pre>"},{"location":"aulas/IA/lab08/cnn-pratica.html#para-responder","title":"Para Responder:\u00b6","text":"<ol> <li>Observe os modelos criados acima</li> <li>Compare CNN (100 filtros 3\u00d73) vs MLP (entrada flattened)</li> <li>Analise como o compartilhamento de pesos afeta o total</li> <li>Considere o que acontece com imagens maiores</li> </ol> <p>Dica</p> <pre># Compara\u00e7\u00e3o de par\u00e2metros use: count_params()\nmodel_params = model.count_params()\n</pre>"},{"location":"aulas/IA/lab08/cnn-pratica.html#pooling","title":"Pooling\u00b6","text":"<p>De forma geral a camada de <code>pooling</code> realiza uma opera\u00e7\u00e3o de redu\u00e7\u00e3o da imagem de entrada tentando manter as caracteristicas mais relevantes. Por consequ\u00eancia, o custo computacional diminui, al\u00e9m disso, \u00e9 nesta etapa que s\u00e3o extra\u00eddas as caracter\u00edstica <code>features</code> mais importantes da imagem.</p> <p>O pooling mais comum \u00e9 utilizando um kernel 2x2, e um passo <code>stride</code> de 2, por consequ\u00eancia a imagem de sa\u00edda ter\u00e1 a metade da imagem de entrada. A opera\u00e7\u00e3o de pooling ir\u00e1 selecionar dentro da janela do kernel o valor que ser\u00e1 aplicado na pr\u00f3xima camada, pode ser o maior valor <code>Maxpooling()</code> ou a m\u00e9dia <code>AveragePooling()</code></p> <p>O resultado visual \u00e9 o seguinte:</p>"},{"location":"aulas/IA/lab08/cnn-pratica.html#implementacao-em-codigo","title":"Implementa\u00e7\u00e3o em c\u00f3digo\u00b6","text":"<p>Para implementar pooling \u00e9 muito simples:</p> <pre>layers.MaxPool2D(pool_size=2, strides=2)\n</pre> <p>Par\u00e2metros principais:</p> <ul> <li>pool_size: Tamanho da janela de pooling (2\u00d72 \u00e9 padr\u00e3o)</li> <li>strides: Passo do deslocamento (geralmente = pool_size)</li> <li>padding: 'valid' (padr\u00e3o) ou 'same'</li> </ul> <p>Outros tipos:</p> <ul> <li><code>layers.AveragePooling2D()</code>: Average pooling</li> <li><code>layers.GlobalMaxPooling2D()</code>: Max pooling global</li> <li><code>layers.GlobalAveragePooling2D()</code>: Average pooling global</li> </ul>"},{"location":"aulas/IA/lab08/cnn-pratica.html#desafio-2","title":"Desafio 2\u00b6","text":"<p>Perguntas para responder:</p> <ol> <li>Qual a dimens\u00e3o da imagem antes e depois do pooling?</li> <li>A camada de pooling alterou o <code>total params</code>?</li> <li>Por que o pooling n\u00e3o tem par\u00e2metros trein\u00e1veis?</li> </ol>"},{"location":"aulas/IA/lab08/cnn-pratica.html#uma-cnn-completa-e-composta-por-duas-partes-principais","title":"Uma CNN completa \u00e9 composta por duas partes principais:\u00b6","text":""},{"location":"aulas/IA/lab08/cnn-pratica.html#1-extrator-de-caracteristicas-feature-extractor","title":"1 Extrator de Caracter\u00edsticas (Feature Extractor)\u00b6","text":"<p>A extra\u00e7\u00e3o de caracter\u00edsticas \u00e9 o processo pelo qual a CNN identifica padr\u00f5es e caracter\u00edsticas relevantes em uma imagem. As caracter\u00edsticas s\u00e3o extra\u00eddas usando camadas convolucionais seguidas de camadas de pooling.</p> <ul> <li>Fun\u00e7\u00e3o: Detectar padr\u00f5es visuais hier\u00e1rquicos</li> <li>Componentes: Conv2D + Pooling + Ativa\u00e7\u00e3o</li> <li>Processo: Bordas \u2192 Texturas \u2192 Formas \u2192 Objetos</li> <li>Sa\u00edda: Feature maps com caracter\u00edsticas extra\u00eddas</li> </ul>"},{"location":"aulas/IA/lab08/cnn-pratica.html#2-classificador-classifier","title":"2 Classificador (Classifier)\u00b6","text":"<p>Ap\u00f3s a extra\u00e7\u00e3o de caracter\u00edsticas \u00e9 aplicado uma rede MLP para realizar a etapa de classica\u00e7\u00e3o da imagem.</p> <ul> <li>Fun\u00e7\u00e3o: Tomar decis\u00e3o baseada nas caracter\u00edsticas</li> <li>Componentes: Flatten + Dense layers (MLP)</li> <li>Processo: Features \u2192 Combina\u00e7\u00f5es \u2192 Probabilidades</li> <li>Sa\u00edda: Classifica\u00e7\u00e3o final</li> </ul>"},{"location":"aulas/IA/lab08/cnn-pratica.html#exemplo-pratico-fashion-mnist-com-cnn","title":"Exemplo Pr\u00e1tico - Fashion MNIST com CNN\u00b6","text":"<p>Vamos utilizar novamente o dataset do Fashion MNIST para classifica\u00e7\u00e3o de imagens, mas desta vez vamos utilizar uma CNN para realizar a extra\u00e7\u00e3o de caracteristicas da imagem seguida de um classificador MLP.</p>"},{"location":"aulas/IA/lab08/cnn-pratica.html#nossa-estrategia","title":"Nossa Estrat\u00e9gia:\u00b6","text":"<ol> <li>Carregar e explorar os dados</li> <li>Pr\u00e9-processar as imagens</li> <li>Construir CNN progressivamente</li> <li>Treinar e avaliar o modelo</li> <li>Visualizar resultados e interpretar erros</li> <li>Comparar com MLP tradicional</li> </ol>"},{"location":"aulas/IA/lab08/cnn-pratica.html#desafio-3-implementando-a-lenet-5-a-cnn-pioneira","title":"Desafio 3: Implementando a LeNet-5 - A CNN Pioneira\u00b6","text":"<p>O resultado n\u00e3o ficou muito bom, mas podemos melhorar!</p> <p>A LeNet-5, desenvolvida por Yann LeCun em 1998, foi uma das primeiras CNNs bem-sucedidas e estabeleceu muitos dos princ\u00edpios fundamentais ainda usados hoje.</p> <ul> <li>Convolutional Layers (CONV);</li> <li>Pooling Layers (POOL);</li> <li>Fully-Connected Layers (FC).</li> </ul> <p>Um exemplo de aplica\u00e7\u00e3o: https://github.com/gary30404/convolutional-neural-network-from-scratch-python</p>"},{"location":"aulas/IA/lab08/cnn-pratica.html#desafio-para-voce","title":"Desafio para Voc\u00ea:\u00b6","text":"<p>Implemente a LeNet-5 adaptada para Fashion MNIST (28\u00d728) seguindo estas especifica\u00e7\u00f5es:</p>"},{"location":"aulas/IA/lab08/cnn-pratica.html#batch-normalization-e-dropout","title":"Batch Normalization e Dropout\u00b6","text":"<p>Durante o treinamento de redes neurais profundas, \u00e9 comum enfrentar problemas como instabilidade no aprendizado e overfitting. Duas t\u00e9cnicas utilizadas para mitigar esses problemas s\u00e3o:</p>"},{"location":"aulas/IA/lab08/cnn-pratica.html#batch-normalization","title":"Batch Normalization\u00b6","text":"<p>A Batch Normalization (ou normaliza\u00e7\u00e3o em lote) \u00e9 uma t\u00e9cnica que normaliza as ativa\u00e7\u00f5es de uma camada, mantendo a m\u00e9dia pr\u00f3xima de 0 e o desvio padr\u00e3o pr\u00f3ximo de 1.</p>"},{"location":"aulas/IA/lab08/cnn-pratica.html#beneficios","title":"Benef\u00edcios:\u00b6","text":"<ul> <li>Acelera o treinamento</li> <li>Reduz a sensibilidade \u00e0 inicializa\u00e7\u00e3o dos pesos</li> <li>Permite usar taxas de aprendizado maiores</li> <li>Atua como uma forma leve de regulariza\u00e7\u00e3o</li> </ul> <p>Saiba mais em: https://machinelearningmastery.com/batch-normalization-for-training-of-deep-neural-networks/</p>"},{"location":"aulas/IA/lab08/cnn-pratica.html#exemplo-de-uso","title":"Exemplo de uso:\u00b6","text":"<pre>layers.BatchNormalization()\n</pre>"},{"location":"aulas/IA/lab08/cnn-pratica.html#dropout","title":"Dropout\u00b6","text":"<p>O Dropout \u00e9 uma t\u00e9cnica de regulariza\u00e7\u00e3o que desativa aleatoriamente uma fra\u00e7\u00e3o dos neur\u00f4nios durante o treinamento. Isso for\u00e7a a rede a n\u00e3o depender de neur\u00f4nios espec\u00edficos, promovendo robustez e generaliza\u00e7\u00e3o. Utilize dropout principalmente em redes densas (fully connected).</p>"},{"location":"aulas/IA/lab08/cnn-pratica.html#beneficios","title":"Benef\u00edcios:\u00b6","text":"<ul> <li>Reduz o overfitting</li> <li>Simples de implementar</li> <li>Funciona bem em redes densas e convolucionais</li> </ul>"},{"location":"aulas/IA/lab08/cnn-pratica.html#exemplo-de-uso","title":"Exemplo de uso:\u00b6","text":"<pre>layers.Dropout(0.5)  # desativa 50% dos neur\u00f4nios durante o treinamento\n</pre> <p>Saiba mais em: https://www.deeplearningbook.com.br/capitulo-23-como-funciona-o-dropout/</p>"},{"location":"aulas/IA/lab08/cnn.html","title":"Teoria","text":""},{"location":"aulas/IA/lab08/cnn.html#introducao-as-cnns","title":"Introdu\u00e7\u00e3o \u00e0s CNNs","text":""},{"location":"aulas/IA/lab08/cnn.html#o-que-sao-redes-neurais-convolucionais","title":"O que s\u00e3o Redes Neurais Convolucionais?","text":"<p>As Redes Neurais Convolucionais (CNNs) s\u00e3o um tipo de rede neural artificial, projetada para processar dados que possuem uma estrutura topol\u00f3gica similar a uma grade, como:</p> <p>Aplica\u00e7\u00f5es comuns:</p> <ul> <li>Classifica\u00e7\u00e3o e segmenta\u00e7\u00e3o de imagens</li> <li>Reconhecimento facial e detec\u00e7\u00e3o de objetos</li> <li>An\u00e1lise de sinais e s\u00e9ries temporais</li> <li>Bioinform\u00e1tica (motivos em DNA/RNA)</li> </ul>"},{"location":"aulas/IA/lab08/cnn.html#vantagens-sobre-mlps","title":"Vantagens sobre MLPs","text":"Aspecto MLP CNN Par\u00e2metros Crescem explosivamente Muito menos (filtros reutilizados) Estrutura espacial Perdida Preservada Robustez a deslocamentos Baixa Maior (quase invariante a transla\u00e7\u00e3o) Compartilhamento de pesos N\u00e3o Sim Escalabilidade em vis\u00e3o Limitada Alta"},{"location":"aulas/IA/lab08/cnn.html#arquitetura-geral-de-uma-cnn","title":"Arquitetura Geral de uma CNN","text":""},{"location":"aulas/IA/lab08/cnn.html#fundamentos-matematicos","title":"Fundamentos Matem\u00e1ticos","text":""},{"location":"aulas/IA/lab08/cnn.html#convolucao-intuicao","title":"Convolu\u00e7\u00e3o (Intui\u00e7\u00e3o)","text":"<p>A convolu\u00e7\u00e3o mede o alinhamento entre um pequeno padr\u00e3o (kernel) e regi\u00f5es da entrada. </p> <p></p> <p>Convolu\u00e7\u00e3o Cont\u00ednua:</p> <pre><code>(f * g)(t) = \u222b_{-\u221e}^{\u221e} f(\u03c4)g(t-\u03c4)d\u03c4\n</code></pre> <p>Convolu\u00e7\u00e3o Discreta (usada em CNNs):</p> <pre><code>(f * g)[n] = \u03a3_{m=-\u221e}^{\u221e} f[m]g[n-m]\n</code></pre>"},{"location":"aulas/IA/lab08/cnn.html#convolucao-2d-para-imagens","title":"Convolu\u00e7\u00e3o 2D para Imagens","text":"<p>Em vis\u00e3o usamos, tecnicamente, correla\u00e7\u00e3o cruzada (n\u00e3o invertendo o kernel), mas chamamos de convolu\u00e7\u00e3o por conven\u00e7\u00e3o.</p> <p></p> <pre><code>S(i,j) = (I * K)(i,j) = \u03a3\u03a3 I(i+m, j+n) \u00d7 K(m,n)\n                        m n\n</code></pre> <p>Onde:</p> <ul> <li><code>I</code>: Imagem de entrada</li> <li><code>K</code>: Kernel (filtro)</li> <li><code>S</code>: Feature map (mapa de caracter\u00edsticas)</li> </ul>"},{"location":"aulas/IA/lab08/cnn.html#exemplo-pratico-de-convolucao","title":"Exemplo Pr\u00e1tico de Convolu\u00e7\u00e3o","text":"<p>Imagem 5\u00d75: <pre><code>1  2  3  0  1\n0  1  2  3  1\n1  0  1  2  0\n2  1  0  1  2\n1  0  2  1  0\n</code></pre></p> <p>Kernel 3\u00d73 (Detector de Borda): <pre><code>-1 -1 -1\n-1  8 -1\n-1 -1 -1\n</code></pre></p> <p>Resultado (Feature Map): <pre><code>Posi\u00e7\u00e3o (1,1): (-1\u00d71) + (-1\u00d72) + (-1\u00d73) + (-1\u00d70) + (8\u00d71) + (-1\u00d72) + (-1\u00d71) + (-1\u00d70) + (-1\u00d71) = -5\n</code></pre></p>"},{"location":"aulas/IA/lab08/cnn.html#parametros-da-camada-convolucional","title":"Parametros da Camada Convolucional","text":""},{"location":"aulas/IA/lab08/cnn.html#1-kernelfiltro","title":"1. Kernel/Filtro","text":"<ul> <li>Tamanho: Normalmente 3\u00d73, 5\u00d75, 7\u00d77</li> <li>Profundidade do kernel: Igual \u00e0 profundidade da entrada</li> <li>N\u00ba de filtros: Hyperpar\u00e2metro (32, 64, 128, 256...)</li> <li>Pesos: Aprendidos durante treinamento</li> </ul>"},{"location":"aulas/IA/lab08/cnn.html#2-stride-passo","title":"2. Stride (Passo)","text":"<ul> <li>Defini\u00e7\u00e3o: Quantos pixels o kernel \"pula\" a cada opera\u00e7\u00e3o</li> <li>Stride = 1: Sobreposi\u00e7\u00e3o m\u00e1xima</li> <li>Stride = 2: Reduz dimens\u00e3o pela metade</li> </ul>"},{"location":"aulas/IA/lab08/cnn.html#3-padding-preenchimento","title":"3. Padding (Preenchimento)Efeito de padding='valid' com kernel 3\u00d73 e stride=1 em H\u00d7W?Principal efeito de stride=2 em convolu\u00e7\u00e3o?","text":"<ul> <li>Valid: Sem padding (sa\u00edda menor)</li> <li>Same: Padding para manter dimens\u00e3o</li> <li>Causal: Para dados sequenciais</li> </ul> Aumenta tamanhoReduz 2 pixels (1 por borda)N\u00e3o alteraDobra dimens\u00f5esSubmitSem padding, a janela n\u00e3o cobre bordas externas totalmente, reduzindo largura e altura em 1 de cada lado. Aumentar resolu\u00e7\u00e3o espacialDiminuir resolu\u00e7\u00e3o e custo computacionalSubstituir fun\u00e7\u00e3o de ativa\u00e7\u00e3oTornar o kernel maiorSubmitStride&gt;1 \u201cpula\u201d posi\u00e7\u00f5es, gerando feature maps menores e opera\u00e7\u00e3o mais barata."},{"location":"aulas/IA/lab08/cnn.html#tipos-de-convolucoes","title":"Tipos de Convolu\u00e7\u00f5es","text":""},{"location":"aulas/IA/lab08/cnn.html#convolucao-standard","title":"Convolu\u00e7\u00e3o Standard","text":"<pre><code># Exemplo com TensorFlow/Keras\nlayers.Conv2D(filters=32, kernel_size=(3,3), stride=(1,1), padding='same')\n</code></pre>"},{"location":"aulas/IA/lab08/cnn.html#convolucao-depthwise-separable","title":"Convolu\u00e7\u00e3o Depthwise Separable","text":"<p><pre><code>layers.SeparableConv2D(filters=32, kernel_size=(3,3))\n</code></pre> - Vantagem: Menos par\u00e2metros (~9x redu\u00e7\u00e3o) - Uso: MobileNets, Xception</p>"},{"location":"aulas/IA/lab08/cnn.html#convolucao-dilatada-atrous","title":"Convolu\u00e7\u00e3o Dilatada (Atrous)","text":"<p><pre><code>layers.Conv2D(filters=32, kernel_size=(3,3), dilation_rate=(2,2))\n</code></pre> - Vantagem: Campo receptivo maior sem perder resolu\u00e7\u00e3o - Uso: Segmenta\u00e7\u00e3o sem\u00e2ntica</p>"},{"location":"aulas/IA/lab08/cnn.html#convolucao-transposta-deconvolucao","title":"Convolu\u00e7\u00e3o Transposta (Deconvolu\u00e7\u00e3o)","text":"<p><pre><code>layers.Conv2DTranspose(filters=32, kernel_size=(3,3), strides=(2,2))\n</code></pre> - Uso: Upsampling, GANs, Autoencoders</p>"},{"location":"aulas/IA/lab08/cnn.html#visualizacao-da-convolucao","title":"Visualiza\u00e7\u00e3o da Convolu\u00e7\u00e3oCNN \u2013 Convolu\u00e7\u00e3o, Ativa\u00e7\u00e3o e Pooling (interativo)","text":"Entrada (28\u00d728) Limpar Ru\u00eddo Demo \u201c7\u201d Dica: desenhe com o mouse (clique e arraste). A imagem \u00e9 28\u00d728, mostrada ampliada. Kernel Identity Blur (Box) Sharpen Edge (Laplacian) Sobel X Sobel Y Emboss Custom (3\u00d73) Kernel 3\u00d73 (Custom): Padding same valid Stride Ativa\u00e7\u00e3o None ReLU Pooling None Max 2\u00d72 (s=2) Avg 2\u00d72 (s=2) Aplicar Reset kernel Sa\u00eddas: Conv: \u2014 \u2022 Pool: \u2014 Resumo: \u2014 Feature map (ap\u00f3s conv/ativa\u00e7\u00e3o) Pooling (veremos a seguir)"},{"location":"aulas/IA/lab08/cnn.html#pooling-e-subsampling","title":"Pooling e Subsampling","text":"<p>Diminui tamanho dos feature maps alem de permitir que pequenas transla\u00e7\u00f5es n\u00e3o afetem resultado, ajuda na redu\u00e7\u00e3o de overfitting e acelera o processamento.</p>"},{"location":"aulas/IA/lab08/cnn.html#max-pooling","title":"Max Pooling","text":"<p><pre><code>layers.MaxPool2D(pool_size=(2,2), strides=(2,2))\n</code></pre> Mant\u00e9m o valor mais forte (presen\u00e7a de padr\u00e3o).</p>"},{"location":"aulas/IA/lab08/cnn.html#average-pooling","title":"Average Pooling","text":"<p>Suaviza (m\u00e9dia local), diluindo picos.</p> <pre><code>layers.AveragePooling2D(pool_size=(2,2))\n</code></pre>"},{"location":"aulas/IA/lab08/cnn.html#global-average-pooling","title":"Global Average PoolingDiferen\u00e7a essencial Max vs Average Pooling?","text":"<p>Resume cada feature map em um \u00fanico n\u00famero. Substitui densas finais, reduz par\u00e2metros.</p> <pre><code>layers.GlobalAveragePooling2D()\n</code></pre> Max reduz canais, Average aumenta canaisMax preserva picos; Average suaviza respostasAverage n\u00e3o \u00e9 diferenci\u00e1velS\u00e3o iguais em pr\u00e1ticaSubmitMax enfatiza presen\u00e7a; Average enfatiza contexto m\u00e9dio."},{"location":"aulas/IA/lab08/cnn.html#batch-normalization","title":"Batch Normalization","text":"<p>A Batch Normalization \u00e9 uma t\u00e9cnica que normaliza as ativa\u00e7\u00f5es de uma camada, mantendo a m\u00e9dia pr\u00f3xima de 0 e o desvio padr\u00e3o pr\u00f3ximo de 1.</p> <ul> <li>Acelera o treinamento</li> <li>Reduz a sensibilidade \u00e0 inicializa\u00e7\u00e3o dos pesos</li> <li>Permite usar taxas de aprendizado maiores</li> <li>Atua como uma forma leve de regulariza\u00e7\u00e3o</li> </ul> <p>Saiba mais em: https://machinelearningmastery.com/batch-normalization-for-training-of-deep-neural-networks/</p> <pre><code>layers.BatchNormalization()\n</code></pre>"},{"location":"aulas/IA/lab08/cnn.html#dropout","title":"Dropout","text":"<p>O Dropout \u00e9 uma t\u00e9cnica de regulariza\u00e7\u00e3o que desativa aleatoriamente uma fra\u00e7\u00e3o dos neur\u00f4nios durante o treinamento. Isso for\u00e7a a rede a n\u00e3o depender de neur\u00f4nios espec\u00edficos, promovendo robustez e generaliza\u00e7\u00e3o. Utilize dropout principalmente em redes densas (fully connected).</p> <ul> <li>Reduz o overfitting</li> <li>Simples de implementar</li> <li>Funciona bem em redes densas e convolucionais</li> </ul> <pre><code>layers.Dropout(0.5)  # desativa 50% dos neur\u00f4nios durante o treinamento\n</code></pre> <p>Saiba mais em: https://www.deeplearningbook.com.br/capitulo-23-como-funciona-o-dropout/</p>"},{"location":"aulas/IA/lab08/cnn.html#arquiteturas-classicas-de-cnn","title":"Arquiteturas Cl\u00e1ssicas de CNN","text":""},{"location":"aulas/IA/lab08/cnn.html#lenet-5-1998-yann-lecun","title":"LeNet-5 (1998) - Yann LeCun","text":"<pre><code>from tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Conv2D, AveragePooling2D, Flatten, Dense\n\nmodel = Sequential([\n    Conv2D(6, (5,5), activation='tanh', input_shape=(32,32,1)),\n    AveragePooling2D((2,2)),\n    Conv2D(16, (5,5), activation='tanh'),\n    AveragePooling2D((2,2)),\n    Flatten(),\n    Dense(120, activation='tanh'),\n    Dense(84, activation='tanh'),\n    Dense(10, activation='softmax')\n])\n</code></pre>"},{"location":"aulas/IA/lab08/cnn.html#alexnet-2012-alex-krizhevsky","title":"AlexNet (2012) - Alex Krizhevsky","text":"<p>Primeira grande vit\u00f3ria em ImageNet: ReLU em larga escala, Dropout, Data Augmentation pesado, uso de m\u00faltiplas GPUs.</p> <p></p> <p>Note</p> <p>A AlexNet foi um marco pois provou que CNNs profundas funcionavam em datasets massivos e impulsionou a revolu\u00e7\u00e3o do Deep Learning.</p>"},{"location":"aulas/IA/lab08/cnn.html#vggnet-2014-oxford","title":"VGGNet (2014) - Oxford","text":"<p>Convolu\u00e7\u00f5es pequenas (blocos de conv 3\u00d73 + pooling) e profundas (16/19 camdas). </p> <pre><code># Bloco 1\nConv2D(64, (3,3), activation='relu', padding='same')\nConv2D(64, (3,3), activation='relu', padding='same')\nMaxPooling2D((2,2), strides=(2,2))\n\n# Bloco 2\nConv2D(128, (3,3), activation='relu', padding='same')\nConv2D(128, (3,3), activation='relu', padding='same')\nMaxPooling2D((2,2), strides=(2,2))\n\n# ... continua com blocos similares\n</code></pre>"},{"location":"aulas/IA/lab08/cnn.html#resnet-2015-microsoft-research","title":"ResNet (2015) - Microsoft ResearchConex\u00f5es residuais ajudam principalmente a:","text":"<p>Resolveu o problema da degrada\u00e7\u00e3o em redes muito profundas com Conex\u00f5es Residuais (Skip Connections).</p> <pre><code>def residual_block(x, filters):\n    shortcut = x\n\n    x = Conv2D(filters, (3,3), padding='same')(x)\n    x = BatchNormalization()(x)\n    x = Activation('relu')(x)\n\n    x = Conv2D(filters, (3,3), padding='same')(x)\n    x = BatchNormalization()(x)\n\n    x = Add()([x, shortcut]) # concatena\n    x = Activation('relu')(x)\n\n    return x\n</code></pre> Diminuir o uso de GPUFacilitar fluxo de gradiente em redes profundasRemover necessidade de normaliza\u00e7\u00e3oEliminar fun\u00e7\u00f5es de ativa\u00e7\u00e3oSubmitO atalho preserva sinais e gradientes, mitigando o problema de degrada\u00e7\u00e3o."},{"location":"aulas/IA/lab08/cnn2.html","title":"Exerc\u00edcio","text":""},{"location":"aulas/IA/lab08/cnn2.html#deteccao-de-expressoes-faciais","title":"Detec\u00e7\u00e3o de Express\u00f5es Faciais","text":"<p>Nesta atividade vamos realizar o treinamento de um classificador de 7 express\u00f5es faciais do dataset <code>FER2013</code>. O objetivo \u00e9 reconhecer automaticamente diferentes emo\u00e7\u00f5es humanas a partir de imagens.</p> <p></p> <ul> <li>angry, disgust, fear, happiness, sad, surprise, neutral</li> <li>Imagens 48\u00d748 pixels em escala de cinza</li> <li>~35k imagens de treinamento, ~4k valida\u00e7\u00e3o, ~4k teste</li> </ul>"},{"location":"aulas/IA/lab08/cnn2.html#2-visao-geral-do-pipeline","title":"2. Vis\u00e3o Geral do Pipeline","text":"<pre><code>Dataset FER2013 \u2192 Pr\u00e9-processamento \u2192 Data Augmentation \u2192 CNN \u2192 Treinamento \u2192 Avalia\u00e7\u00e3o \u2192 Modelo Final\n</code></pre>"},{"location":"aulas/IA/lab08/cnn2.html#estrutura-dos-dados","title":"Estrutura dos Dados","text":"<p>O dataset est\u00e1 em CSV e possui a seguinte estrutura: - <code>emotion</code>: classe (0-6) - <code>pixels</code>: string com 2304 valores (48\u00d748 pixels) - <code>Usage</code>: Training/PublicTest/PrivateTest</p>"},{"location":"aulas/IA/lab08/cnn2.html#atividades-praticas","title":"Atividades Pr\u00e1ticas","text":"<p>Fa\u00e7a o downlod dos arquivos desse projeto:</p> <ul> <li>Notebook da implementa\u00e7\u00e3o</li> <li>Script Python para execu\u00e7\u00e3o em tempo real com webcam</li> <li>Modelo treinado Rede treinada para infer\u00eancia</li> </ul>"},{"location":"aulas/IA/lab08/cnn2.html#destaque-para-alguns-pontos-importantes","title":"Destaque para alguns pontos importantes:","text":""},{"location":"aulas/IA/lab08/cnn2.html#data-augmentation","title":"Data Augmentation","text":""},{"location":"aulas/IA/lab08/cnn2.html#callbacks","title":"Callbacks","text":""},{"location":"aulas/IA/lab08/cnn_drive.html","title":"Lab04 - GDrive","text":"In\u00a0[\u00a0]: Copied! <pre>from keras.datasets import cifar10\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom keras.models import Sequential,load_model\nfrom keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, AveragePooling2D\nfrom keras.layers import BatchNormalization\n#from keras.utils import np_utils\nfrom keras.utils import to_categorical\n#from keras.utils import plot_model\nfrom keras.utils import plot_model\n\nimport tensorflow as tf\n</pre> from keras.datasets import cifar10 import numpy as np import matplotlib.pyplot as plt from keras.models import Sequential,load_model from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, AveragePooling2D from keras.layers import BatchNormalization #from keras.utils import np_utils from keras.utils import to_categorical #from keras.utils import plot_model from keras.utils import plot_model  import tensorflow as tf <p>Inicializa o Google Drive. \u00c9 necess\u00e1rio entrar com as credenciais do Gmail</p> In\u00a0[\u00a0]: Copied! <pre>from google.colab import drive\ndrive.mount('/content/drive')\n</pre> from google.colab import drive drive.mount('/content/drive') <pre>Mounted at /content/drive\n</pre> In\u00a0[\u00a0]: Copied! <pre>(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n</pre> (x_train, y_train), (x_test, y_test) = cifar10.load_data() <pre>Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n170498071/170498071 [==============================] - 4s 0us/step\n</pre> In\u00a0[\u00a0]: Copied! <pre>print('Train: X=%s, y=%s' % (x_train.shape, y_train.shape))\nprint('Test: X=%s, y=%s' % (x_test.shape, y_test.shape))\n# plot first few images\nfor i in range(9):\n\t# define subplot\n\tplt.subplot(330 + 1 + i)\n\t# plot raw pixel data\n\tplt.imshow(x_train[i])\n# show the figure\nplt.show()\n</pre> print('Train: X=%s, y=%s' % (x_train.shape, y_train.shape)) print('Test: X=%s, y=%s' % (x_test.shape, y_test.shape)) # plot first few images for i in range(9): \t# define subplot \tplt.subplot(330 + 1 + i) \t# plot raw pixel data \tplt.imshow(x_train[i]) # show the figure plt.show() <pre>Train: X=(50000, 32, 32, 3), y=(50000, 1)\nTest: X=(10000, 32, 32, 3), y=(10000, 1)\n</pre> In\u00a0[\u00a0]: Copied! <pre>x_train = x_train.astype('float32')/255\nx_test = x_test.astype('float32')/255\n</pre> x_train = x_train.astype('float32')/255 x_test = x_test.astype('float32')/255 <p>\"One-hot encoding\" aplicado aos r\u00f3tulos</p> In\u00a0[\u00a0]: Copied! <pre>num_classes = len(np.unique(y_train))\ny_train = to_categorical(y_train, num_classes)\ny_test = to_categorical(y_test, num_classes)\n</pre> num_classes = len(np.unique(y_train)) y_train = to_categorical(y_train, num_classes) y_test = to_categorical(y_test, num_classes) In\u00a0[\u00a0]: Copied! <pre>y_train\n</pre> y_train Out[\u00a0]: <pre>array([[0., 0., 0., ..., 0., 0., 0.],\n       [0., 0., 0., ..., 0., 0., 1.],\n       [0., 0., 0., ..., 0., 0., 1.],\n       ...,\n       [0., 0., 0., ..., 0., 0., 1.],\n       [0., 1., 0., ..., 0., 0., 0.],\n       [0., 1., 0., ..., 0., 0., 0.]], dtype=float32)</pre> In\u00a0[\u00a0]: Copied! <pre>num_classes\n</pre> num_classes Out[\u00a0]: <pre>10</pre> <p>divindo dataset de treinamento em treinamento, teste e valida\u00e7\u00e3o - Apenas para exemplo em um ambiente real as amostras devem ser seleciondas de forma aleat\u00f3ria</p> In\u00a0[\u00a0]: Copied! <pre>(x_train, x_valid) = x_train[5000:], x_train[:5000]\n(y_train, y_valid) = y_train[5000:], y_train[:5000]\n</pre> (x_train, x_valid) = x_train[5000:], x_train[:5000] (y_train, y_valid) = y_train[5000:], y_train[:5000] <p>Impress\u00e3o da forma do conjunto de treino</p> In\u00a0[\u00a0]: Copied! <pre>print('x_train shape:', x_train.shape)\n</pre> print('x_train shape:', x_train.shape) <pre>x_train shape: (45000, 32, 32, 3)\n</pre> In\u00a0[\u00a0]: Copied! <pre>print('x_valid shape:', x_valid.shape)\n</pre> print('x_valid shape:', x_valid.shape) <pre>x_valid shape: (5000, 32, 32, 3)\n</pre> <p>Impress\u00e3o do n\u00famero de imagens nos datasets de treinamento, teste e valida\u00e7\u00e3o</p> In\u00a0[\u00a0]: Copied! <pre>print(x_train.shape[0], 'train samples')\nprint(x_test.shape[0], 'test samples')\nprint(x_valid.shape[0], 'validation samples')\n</pre> print(x_train.shape[0], 'train samples') print(x_test.shape[0], 'test samples') print(x_valid.shape[0], 'validation samples') <pre>45000 train samples\n10000 test samples\n5000 validation samples\n</pre> In\u00a0[\u00a0]: Copied! <pre>## primeira tentativa\nmodel = Sequential()\nmodel.add(Conv2D(filters=128, kernel_size=3,  activation='relu', input_shape=(32, 32, 3), padding='same'))\nmodel.add(Conv2D(filters=128, kernel_size=3,  activation='relu'))\nmodel.add(MaxPooling2D(pool_size=2))\nmodel.add(Conv2D(filters=128, kernel_size=3,  activation='relu'))\nmodel.add(Conv2D(filters=128, kernel_size=3,  activation='relu'))\nmodel.add(MaxPooling2D(pool_size=2))\n\nmodel.add(Dropout(0.2))\nmodel.add(Flatten())\nmodel.add(Dense(256, activation='relu'))\nmodel.add(Dropout(0.2))\nmodel.add(Dense(128, activation='relu'))\nmodel.add(Dropout(0.2))\nmodel.add(Dense(num_classes, activation='softmax'))\n\n\n\n## Segunda tentativa\n\n# from keras.layers import BatchNormalization\n# model = Sequential()\n\n# model.add(Conv2D(filters=32, kernel_size=(3,3),  activation='relu', input_shape=(32, 32, 3), padding='same'))\n# model.add(BatchNormalization())\n# model.add(Conv2D(filters=32, kernel_size=(3,3), activation='relu', padding='same'))\n# model.add(BatchNormalization())\n# model.add(MaxPooling2D(pool_size=(2,2)))\n# model.add(Dropout(0.3))\n\n# model.add(Conv2D(64, (3,3), padding='same', activation='relu'))\n# model.add(BatchNormalization())\n# model.add(Conv2D(64, (3,3), padding='same', activation='relu'))\n# model.add(BatchNormalization())\n# model.add(MaxPooling2D(pool_size=(2,2)))\n# model.add(Dropout(0.5))\n\n# model.add(Conv2D(128, (3,3), padding='same', activation='relu'))\n# model.add(BatchNormalization())\n# model.add(Conv2D(128, (3,3), padding='same', activation='relu'))\n# model.add(BatchNormalization())\n# model.add(MaxPooling2D(pool_size=(2,2)))\n# model.add(Dropout(0.5))\n\n# model.add(Flatten())\n# model.add(Dense(128, activation='relu'))\n# model.add(BatchNormalization())\n# model.add(Dropout(0.5))\n# model.add(Dense(num_classes, activation='softmax'))\n</pre> ## primeira tentativa model = Sequential() model.add(Conv2D(filters=128, kernel_size=3,  activation='relu', input_shape=(32, 32, 3), padding='same')) model.add(Conv2D(filters=128, kernel_size=3,  activation='relu')) model.add(MaxPooling2D(pool_size=2)) model.add(Conv2D(filters=128, kernel_size=3,  activation='relu')) model.add(Conv2D(filters=128, kernel_size=3,  activation='relu')) model.add(MaxPooling2D(pool_size=2))  model.add(Dropout(0.2)) model.add(Flatten()) model.add(Dense(256, activation='relu')) model.add(Dropout(0.2)) model.add(Dense(128, activation='relu')) model.add(Dropout(0.2)) model.add(Dense(num_classes, activation='softmax'))    ## Segunda tentativa  # from keras.layers import BatchNormalization # model = Sequential()  # model.add(Conv2D(filters=32, kernel_size=(3,3),  activation='relu', input_shape=(32, 32, 3), padding='same')) # model.add(BatchNormalization()) # model.add(Conv2D(filters=32, kernel_size=(3,3), activation='relu', padding='same')) # model.add(BatchNormalization()) # model.add(MaxPooling2D(pool_size=(2,2))) # model.add(Dropout(0.3))  # model.add(Conv2D(64, (3,3), padding='same', activation='relu')) # model.add(BatchNormalization()) # model.add(Conv2D(64, (3,3), padding='same', activation='relu')) # model.add(BatchNormalization()) # model.add(MaxPooling2D(pool_size=(2,2))) # model.add(Dropout(0.5))  # model.add(Conv2D(128, (3,3), padding='same', activation='relu')) # model.add(BatchNormalization()) # model.add(Conv2D(128, (3,3), padding='same', activation='relu')) # model.add(BatchNormalization()) # model.add(MaxPooling2D(pool_size=(2,2))) # model.add(Dropout(0.5))  # model.add(Flatten()) # model.add(Dense(128, activation='relu')) # model.add(BatchNormalization()) # model.add(Dropout(0.5)) # model.add(Dense(num_classes, activation='softmax')) <p>Tentem executar a rede configurando outras fun\u00e7\u00f5es de ativa\u00e7\u00e3o (como visto em nossa Aula 3) mais informa\u00e7\u00f5es em https://keras.io/activations/</p> In\u00a0[\u00a0]: Copied! <pre>plot_model(model, to_file='cnn-CIFAR10.png', show_shapes=True, show_layer_names=True)\n</pre> plot_model(model, to_file='cnn-CIFAR10.png', show_shapes=True, show_layer_names=True) Out[\u00a0]: <p>Compilando o modelo escolhendo como se dar\u00e1 nossa perda, otimiza\u00e7\u00e3o e m\u00e9tricas (par\u00e2metros do Keras)</p> <ul> <li>mais informa\u00e7\u00f5es em https://keras.io/losses/</li> <li>mais informa\u00e7\u00f5es em https://keras.io/optimizers/</li> <li>mais informa\u00e7\u00f5es em https://keras.io/metrics/</li> </ul> In\u00a0[\u00a0]: Copied! <pre>model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n</pre> model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy']) In\u00a0[\u00a0]: Copied! <pre>from keras.callbacks import ModelCheckpoint\n</pre> from keras.callbacks import ModelCheckpoint <p>O keras passa a salvar o melhor modelo pela acur\u00e1cia de valida\u00e7\u00e3o</p> In\u00a0[\u00a0]: Copied! <pre>checkpointer = ModelCheckpoint(filepath='/content/drive/My Drive/checkpoints/modelocifar.h5', verbose=1,  save_best_only=True, monitor='val_accuracy') #\n\nhist = model.fit(x_train, y_train, batch_size=100, epochs=30, validation_data=(x_valid, y_valid), callbacks=[checkpointer], verbose=1, shuffle=True)\n</pre> checkpointer = ModelCheckpoint(filepath='/content/drive/My Drive/checkpoints/modelocifar.h5', verbose=1,  save_best_only=True, monitor='val_accuracy') #  hist = model.fit(x_train, y_train, batch_size=100, epochs=30, validation_data=(x_valid, y_valid), callbacks=[checkpointer], verbose=1, shuffle=True) <pre>Epoch 1/30\n450/450 [==============================] - ETA: 0s - loss: 1.8334 - accuracy: 0.3789\nEpoch 1: val_accuracy improved from -inf to 0.33460, saving model to /content/drive/My Drive/checkpoints/modelocifar_FIAP_Shift.hdf5\n450/450 [==============================] - 14s 18ms/step - loss: 1.8334 - accuracy: 0.3789 - val_loss: 2.0108 - val_accuracy: 0.3346\nEpoch 2/30\n448/450 [============================&gt;.] - ETA: 0s - loss: 1.2611 - accuracy: 0.5463\nEpoch 2: val_accuracy improved from 0.33460 to 0.62680, saving model to /content/drive/My Drive/checkpoints/modelocifar_FIAP_Shift.hdf5\n450/450 [==============================] - 9s 19ms/step - loss: 1.2608 - accuracy: 0.5466 - val_loss: 1.0417 - val_accuracy: 0.6268\nEpoch 3/30\n450/450 [==============================] - ETA: 0s - loss: 1.0718 - accuracy: 0.6208\nEpoch 3: val_accuracy improved from 0.62680 to 0.66700, saving model to /content/drive/My Drive/checkpoints/modelocifar_FIAP_Shift.hdf5\n450/450 [==============================] - 7s 16ms/step - loss: 1.0718 - accuracy: 0.6208 - val_loss: 0.9174 - val_accuracy: 0.6670\nEpoch 4/30\n447/450 [============================&gt;.] - ETA: 0s - loss: 0.9540 - accuracy: 0.6639\nEpoch 4: val_accuracy improved from 0.66700 to 0.68700, saving model to /content/drive/My Drive/checkpoints/modelocifar_FIAP_Shift.hdf5\n450/450 [==============================] - 8s 17ms/step - loss: 0.9543 - accuracy: 0.6639 - val_loss: 0.8978 - val_accuracy: 0.6870\nEpoch 5/30\n449/450 [============================&gt;.] - ETA: 0s - loss: 0.8712 - accuracy: 0.6943\nEpoch 5: val_accuracy did not improve from 0.68700\n450/450 [==============================] - 7s 16ms/step - loss: 0.8711 - accuracy: 0.6942 - val_loss: 0.9451 - val_accuracy: 0.6798\nEpoch 6/30\n448/450 [============================&gt;.] - ETA: 0s - loss: 0.8112 - accuracy: 0.7161\nEpoch 6: val_accuracy improved from 0.68700 to 0.71700, saving model to /content/drive/My Drive/checkpoints/modelocifar_FIAP_Shift.hdf5\n450/450 [==============================] - 8s 18ms/step - loss: 0.8113 - accuracy: 0.7161 - val_loss: 0.8033 - val_accuracy: 0.7170\nEpoch 7/30\n448/450 [============================&gt;.] - ETA: 0s - loss: 0.7626 - accuracy: 0.7341\nEpoch 7: val_accuracy improved from 0.71700 to 0.76720, saving model to /content/drive/My Drive/checkpoints/modelocifar_FIAP_Shift.hdf5\n450/450 [==============================] - 8s 18ms/step - loss: 0.7623 - accuracy: 0.7342 - val_loss: 0.6699 - val_accuracy: 0.7672\nEpoch 8/30\n450/450 [==============================] - ETA: 0s - loss: 0.7229 - accuracy: 0.7507\nEpoch 8: val_accuracy did not improve from 0.76720\n450/450 [==============================] - 7s 16ms/step - loss: 0.7229 - accuracy: 0.7507 - val_loss: 0.9428 - val_accuracy: 0.6904\nEpoch 9/30\n450/450 [==============================] - ETA: 0s - loss: 0.6865 - accuracy: 0.7623\nEpoch 9: val_accuracy did not improve from 0.76720\n450/450 [==============================] - 8s 17ms/step - loss: 0.6865 - accuracy: 0.7623 - val_loss: 0.7274 - val_accuracy: 0.7484\nEpoch 10/30\n448/450 [============================&gt;.] - ETA: 0s - loss: 0.6619 - accuracy: 0.7719\nEpoch 10: val_accuracy improved from 0.76720 to 0.79100, saving model to /content/drive/My Drive/checkpoints/modelocifar_FIAP_Shift.hdf5\n450/450 [==============================] - 8s 18ms/step - loss: 0.6614 - accuracy: 0.7721 - val_loss: 0.6355 - val_accuracy: 0.7910\nEpoch 11/30\n447/450 [============================&gt;.] - ETA: 0s - loss: 0.6306 - accuracy: 0.7842\nEpoch 11: val_accuracy improved from 0.79100 to 0.80300, saving model to /content/drive/My Drive/checkpoints/modelocifar_FIAP_Shift.hdf5\n450/450 [==============================] - 8s 18ms/step - loss: 0.6310 - accuracy: 0.7840 - val_loss: 0.5668 - val_accuracy: 0.8030\nEpoch 12/30\n447/450 [============================&gt;.] - ETA: 0s - loss: 0.6087 - accuracy: 0.7903\nEpoch 12: val_accuracy did not improve from 0.80300\n450/450 [==============================] - 8s 17ms/step - loss: 0.6090 - accuracy: 0.7903 - val_loss: 0.5881 - val_accuracy: 0.8002\nEpoch 13/30\n449/450 [============================&gt;.] - ETA: 0s - loss: 0.5870 - accuracy: 0.7985\nEpoch 13: val_accuracy improved from 0.80300 to 0.81220, saving model to /content/drive/My Drive/checkpoints/modelocifar_FIAP_Shift.hdf5\n450/450 [==============================] - 8s 18ms/step - loss: 0.5869 - accuracy: 0.7985 - val_loss: 0.5339 - val_accuracy: 0.8122\nEpoch 14/30\n449/450 [============================&gt;.] - ETA: 0s - loss: 0.5685 - accuracy: 0.8063\nEpoch 14: val_accuracy improved from 0.81220 to 0.82560, saving model to /content/drive/My Drive/checkpoints/modelocifar_FIAP_Shift.hdf5\n450/450 [==============================] - 8s 17ms/step - loss: 0.5687 - accuracy: 0.8062 - val_loss: 0.5192 - val_accuracy: 0.8256\nEpoch 15/30\n448/450 [============================&gt;.] - ETA: 0s - loss: 0.5509 - accuracy: 0.8112\nEpoch 15: val_accuracy improved from 0.82560 to 0.82700, saving model to /content/drive/My Drive/checkpoints/modelocifar_FIAP_Shift.hdf5\n450/450 [==============================] - 8s 17ms/step - loss: 0.5516 - accuracy: 0.8111 - val_loss: 0.5204 - val_accuracy: 0.8270\nEpoch 16/30\n450/450 [==============================] - ETA: 0s - loss: 0.5372 - accuracy: 0.8141\nEpoch 16: val_accuracy did not improve from 0.82700\n450/450 [==============================] - 8s 17ms/step - loss: 0.5372 - accuracy: 0.8141 - val_loss: 0.5340 - val_accuracy: 0.8150\nEpoch 17/30\n448/450 [============================&gt;.] - ETA: 0s - loss: 0.5219 - accuracy: 0.8201\nEpoch 17: val_accuracy improved from 0.82700 to 0.83160, saving model to /content/drive/My Drive/checkpoints/modelocifar_FIAP_Shift.hdf5\n450/450 [==============================] - 8s 18ms/step - loss: 0.5218 - accuracy: 0.8202 - val_loss: 0.4938 - val_accuracy: 0.8316\nEpoch 18/30\n450/450 [==============================] - ETA: 0s - loss: 0.5073 - accuracy: 0.8267\nEpoch 18: val_accuracy improved from 0.83160 to 0.83600, saving model to /content/drive/My Drive/checkpoints/modelocifar_FIAP_Shift.hdf5\n450/450 [==============================] - 8s 17ms/step - loss: 0.5073 - accuracy: 0.8267 - val_loss: 0.4806 - val_accuracy: 0.8360\nEpoch 19/30\n450/450 [==============================] - ETA: 0s - loss: 0.5002 - accuracy: 0.8286\nEpoch 19: val_accuracy did not improve from 0.83600\n450/450 [==============================] - 7s 16ms/step - loss: 0.5002 - accuracy: 0.8286 - val_loss: 0.5290 - val_accuracy: 0.8166\nEpoch 20/30\n450/450 [==============================] - ETA: 0s - loss: 0.4842 - accuracy: 0.8338\nEpoch 20: val_accuracy improved from 0.83600 to 0.84180, saving model to /content/drive/My Drive/checkpoints/modelocifar_FIAP_Shift.hdf5\n450/450 [==============================] - 8s 18ms/step - loss: 0.4842 - accuracy: 0.8338 - val_loss: 0.4589 - val_accuracy: 0.8418\nEpoch 21/30\n449/450 [============================&gt;.] - ETA: 0s - loss: 0.4767 - accuracy: 0.8372\nEpoch 21: val_accuracy did not improve from 0.84180\n450/450 [==============================] - 7s 16ms/step - loss: 0.4765 - accuracy: 0.8373 - val_loss: 0.4804 - val_accuracy: 0.8394\nEpoch 22/30\n450/450 [==============================] - ETA: 0s - loss: 0.4654 - accuracy: 0.8406\nEpoch 22: val_accuracy improved from 0.84180 to 0.84900, saving model to /content/drive/My Drive/checkpoints/modelocifar_FIAP_Shift.hdf5\n450/450 [==============================] - 8s 18ms/step - loss: 0.4654 - accuracy: 0.8406 - val_loss: 0.4492 - val_accuracy: 0.8490\nEpoch 23/30\n448/450 [============================&gt;.] - ETA: 0s - loss: 0.4577 - accuracy: 0.8414\nEpoch 23: val_accuracy did not improve from 0.84900\n450/450 [==============================] - 7s 17ms/step - loss: 0.4577 - accuracy: 0.8414 - val_loss: 0.5467 - val_accuracy: 0.8178\nEpoch 24/30\n447/450 [============================&gt;.] - ETA: 0s - loss: 0.4514 - accuracy: 0.8440\nEpoch 24: val_accuracy did not improve from 0.84900\n450/450 [==============================] - 7s 16ms/step - loss: 0.4516 - accuracy: 0.8438 - val_loss: 0.4474 - val_accuracy: 0.8462\nEpoch 25/30\n448/450 [============================&gt;.] - ETA: 0s - loss: 0.4457 - accuracy: 0.8461\nEpoch 25: val_accuracy did not improve from 0.84900\n450/450 [==============================] - 8s 17ms/step - loss: 0.4460 - accuracy: 0.8460 - val_loss: 0.4541 - val_accuracy: 0.8456\nEpoch 26/30\n447/450 [============================&gt;.] - ETA: 0s - loss: 0.4319 - accuracy: 0.8517\nEpoch 26: val_accuracy improved from 0.84900 to 0.85200, saving model to /content/drive/My Drive/checkpoints/modelocifar_FIAP_Shift.hdf5\n450/450 [==============================] - 8s 18ms/step - loss: 0.4315 - accuracy: 0.8518 - val_loss: 0.4302 - val_accuracy: 0.8520\nEpoch 27/30\n447/450 [============================&gt;.] - ETA: 0s - loss: 0.4217 - accuracy: 0.8535\nEpoch 27: val_accuracy improved from 0.85200 to 0.85920, saving model to /content/drive/My Drive/checkpoints/modelocifar_FIAP_Shift.hdf5\n450/450 [==============================] - 8s 17ms/step - loss: 0.4219 - accuracy: 0.8536 - val_loss: 0.4242 - val_accuracy: 0.8592\nEpoch 28/30\n449/450 [============================&gt;.] - ETA: 0s - loss: 0.4214 - accuracy: 0.8552\nEpoch 28: val_accuracy did not improve from 0.85920\n450/450 [==============================] - 7s 16ms/step - loss: 0.4215 - accuracy: 0.8552 - val_loss: 0.4665 - val_accuracy: 0.8438\nEpoch 29/30\n447/450 [============================&gt;.] - ETA: 0s - loss: 0.4081 - accuracy: 0.8589\nEpoch 29: val_accuracy improved from 0.85920 to 0.86180, saving model to /content/drive/My Drive/checkpoints/modelocifar_FIAP_Shift.hdf5\n450/450 [==============================] - 9s 19ms/step - loss: 0.4086 - accuracy: 0.8589 - val_loss: 0.4131 - val_accuracy: 0.8618\nEpoch 30/30\n447/450 [============================&gt;.] - ETA: 0s - loss: 0.4077 - accuracy: 0.8592\nEpoch 30: val_accuracy did not improve from 0.86180\n450/450 [==============================] - 7s 17ms/step - loss: 0.4075 - accuracy: 0.8592 - val_loss: 0.4369 - val_accuracy: 0.8532\n</pre> In\u00a0[\u00a0]: Copied! <pre>plt.figure(1)\nplt.plot(hist.history['accuracy'])\nplt.plot(hist.history['val_accuracy'])\nplt.title('model accuracy')\nplt.ylabel('accuracy')\nplt.xlabel('epoch')\nplt.legend(['train', 'validation'], loc='upper left')\nplt.show()\n</pre> plt.figure(1) plt.plot(hist.history['accuracy']) plt.plot(hist.history['val_accuracy']) plt.title('model accuracy') plt.ylabel('accuracy') plt.xlabel('epoch') plt.legend(['train', 'validation'], loc='upper left') plt.show() <p>Carregar o melhor modelo que obteve a melhor acur\u00e1cia de valida\u00e7\u00e3o no treinamento</p> In\u00a0[\u00a0]: Copied! <pre>model = load_model(\"/content/drive/My Drive/checkpoints/modelocifar.h5\")\n</pre> model = load_model(\"/content/drive/My Drive/checkpoints/modelocifar.h5\") <p>Avaliar e imprimir a precis\u00e3o do teste</p> In\u00a0[\u00a0]: Copied! <pre>score = model.evaluate(x_test, y_test, verbose=0)\nprint('\\n', 'Test accuracy:', score[1])\n</pre> score = model.evaluate(x_test, y_test, verbose=0) print('\\n', 'Test accuracy:', score[1]) <pre>\n Test accuracy: 0.7767000198364258\n</pre> In\u00a0[\u00a0]: Copied! <pre>y_hat = model.predict(x_test)\n</pre> y_hat = model.predict(x_test) <pre>313/313 [==============================] - 1s 3ms/step\n</pre> In\u00a0[\u00a0]: Copied! <pre>y_hat[100,:]\n</pre> y_hat[100,:] Out[\u00a0]: <pre>array([5.8770423e-05, 9.3314156e-08, 5.6933337e-03, 1.1897533e-04,\n       3.1580424e-01, 3.2564318e-03, 6.1175911e-08, 6.7506504e-01,\n       1.1326588e-06, 1.8971995e-06], dtype=float32)</pre> In\u00a0[\u00a0]: Copied! <pre>np.argmax(y_hat[100,:])\n</pre> np.argmax(y_hat[100,:]) Out[\u00a0]: <pre>7</pre> <p>Definindo r\u00f3tulos de texto (r\u00f3tulos dispon\u00edveis na fonte original: https://www.cs.toronto.edu/~kriz/cifar.html)</p> In\u00a0[\u00a0]: Copied! <pre>cifar10_labels = ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n</pre> cifar10_labels = ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck'] <p>Plot de amostra aleat\u00f3ria de imagens de teste, r\u00f3tulos preditos e a \"ground truth\" advinda do dataset CIFAR-10</p> In\u00a0[\u00a0]: Copied! <pre>fig = plt.figure(figsize=(20, 8))\nfor i, idx in enumerate(np.random.choice(x_test.shape[0], size=32, replace=False)):\n    ax = fig.add_subplot(4, 8, i + 1, xticks=[], yticks=[])\n    ax.imshow(np.squeeze(x_test[idx]))\n    pred_idx = np.argmax(y_hat[idx])\n    true_idx = np.argmax(y_test[idx])\n    ax.set_title(\"{} ({})\".format(cifar10_labels[pred_idx], cifar10_labels[true_idx]),\n                 color=(\"green\" if pred_idx == true_idx else \"red\"))\n    # amostras corretamente classificadas em verde, incorretamente classificadas em vermelho\n</pre> fig = plt.figure(figsize=(20, 8)) for i, idx in enumerate(np.random.choice(x_test.shape[0], size=32, replace=False)):     ax = fig.add_subplot(4, 8, i + 1, xticks=[], yticks=[])     ax.imshow(np.squeeze(x_test[idx]))     pred_idx = np.argmax(y_hat[idx])     true_idx = np.argmax(y_test[idx])     ax.set_title(\"{} ({})\".format(cifar10_labels[pred_idx], cifar10_labels[true_idx]),                  color=(\"green\" if pred_idx == true_idx else \"red\"))     # amostras corretamente classificadas em verde, incorretamente classificadas em vermelho"},{"location":"aulas/IA/lab08/cnn_drive.html#objetivos","title":"Objetivos\u00b6","text":"<ul> <li>Conhecer e praticar t\u00e9cnicas de Dropout, BatchNormalization e AveragePooling2D</li> <li>Aprender e aplicar a estr\u00e1t\u00e9gia de treinamento com ModelCheckpoint</li> <li>conhecer e utilizar o google drive em conjunto com o colab</li> </ul>"},{"location":"aulas/IA/lab08/cnn_drive.html#1-carregando-bibliotecas","title":"1. Carregando Bibliotecas\u00b6","text":""},{"location":"aulas/IA/lab08/cnn_drive.html#2-carregando-o-dataset-pre-embaralhado-de-treinamento-bem-como-os-dados-de-teste","title":"2. Carregando o dataset pr\u00e9-embaralhado de treinamento bem como os dados de teste\u00b6","text":""},{"location":"aulas/IA/lab08/cnn_drive.html#3-redimensionando-as-imagens-e-dividindo-cada-pixel-em-cada-imagem-por-255","title":"3. Redimensionando as imagens e dividindo cada pixel em cada imagem por 255\u00b6","text":""},{"location":"aulas/IA/lab08/cnn_drive.html#4-dividindo-o-dataset-em-treinamento-teste-e-validacao","title":"4.  Dividindo o dataset em treinamento, teste e valida\u00e7\u00e3o\u00b6","text":""},{"location":"aulas/IA/lab08/cnn_drive.html#5-definindo-a-arquitetura-do-modelo-importante","title":"5. Definindo a arquitetura do modelo (IMPORTANTE!)\u00b6","text":"<ul> <li><p>Use camadas convolucionais de tamanho progressivamente crescente: Utilize m\u00faltiplas camadas convolucionais com um n\u00famero crescente de filtros (por exemplo, 32, 64, 128). Isso ajuda a capturar caracter\u00edsticas mais complexas nas imagens \u00e0 medida que se aprofunda na rede.</p> </li> <li><p>M\u00e1ximo de camadas de \"pooling\" (2x2): Insira camadas de pooling (m\u00e1ximo pooling) ap\u00f3s grupos de camadas convolucionais para reduzir as dimens\u00f5es espaciais da entrada (por exemplo, 2x2 pooling). Isso ajuda a reduzir a complexidade computacional e controlar o overfitting.</p> </li> <li><p>Camadas totalmente conectadas: Adicione uma ou mais camadas totalmente conectadas (fully connected layers) ap\u00f3s as camadas convolucionais e de pooling para combinar as caracter\u00edsticas extra\u00eddas e realizar a classifica\u00e7\u00e3o.</p> </li> <li><p>\u00daltima camada totalmente conectada com 10 sa\u00eddas (10 classes de categoria de imagem): A \u00faltima camada da rede deve ser uma camada totalmente conectada com 10 neur\u00f4nios (unidades) de sa\u00edda, correspondendo \u00e0s 10 classes de imagem no seu problema de classifica\u00e7\u00e3o. Use a fun\u00e7\u00e3o de ativa\u00e7\u00e3o softmax para obter as probabilidades das classes.</p> </li> <li><p>\"Dropout\" de 0,2-0,5: Aplique a t\u00e9cnica de Dropout entre as camadas, especialmente nas camadas totalmente conectadas, com uma taxa de dropout entre 0,2 e 0,5. Isso ajuda a prevenir overfitting, desligando aleatoriamente neur\u00f4nios durante o treinamento.</p> </li> <li><p>\"BatchNormalization\" ap\u00f3s convolu\u00e7\u00e3o: Utilize camadas de Batch Normalization ap\u00f3s as camadas convolucionais para normalizar as ativa\u00e7\u00f5es da camada anterior. Isso ajuda a acelerar o treinamento e a estabilizar a rede neural.</p> </li> </ul>"},{"location":"aulas/IA/lab08/cnn_drive.html#6-compilando-o-modelo","title":"6. Compilando o modelo\u00b6","text":""},{"location":"aulas/IA/lab08/cnn_drive.html#7-treinando-o-modelo","title":"7. Treinando o modelo\u00b6","text":"<p>Treinar modelos de aprendizado profundo pode ser uma tarefa demorada, especialmente para modelos complexos e conjuntos de dados grandes. Para garantir que voc\u00ea n\u00e3o perca o progresso e consiga restaurar o melhor modelo encontrado durante o treinamento, o Keras oferece a callback ModelCheckpoint. Esta ferramenta permite salvar o modelo atual ap\u00f3s cada \u00e9poca, ou quando uma m\u00e9trica espec\u00edfica melhora, facilitando a recupera\u00e7\u00e3o do melhor modelo</p>"},{"location":"aulas/IA/lab08/cnn_drive.html#8-calculo-da-precisao-de-classificacao-no-dataset-de-testes","title":"8. C\u00e1lculo da precis\u00e3o de classifica\u00e7\u00e3o no dataset de testes\u00b6","text":""},{"location":"aulas/IA/lab08/cnn_drive.html#9-visualizar-algumas-predicoes","title":"9. Visualizar algumas predi\u00e7\u00f5es\u00b6","text":"<p>As visualiza\u00e7\u00f5es podem nos dar algumas dicas sobre por que a rede classifica erroneamente alguns objetos. Obtendo previs\u00f5es no conjunto de testes:</p>"},{"location":"aulas/IA/lab08/cnn_guia_completo%20copy.html","title":"Cnn guia completo copy","text":""},{"location":"aulas/IA/lab08/cnn_guia_completo%20copy.html#introducao-as-cnns","title":"Introdu\u00e7\u00e3o \u00e0s CNNs","text":""},{"location":"aulas/IA/lab08/cnn_guia_completo%20copy.html#o-que-sao-redes-neurais-convolucionais","title":"O que s\u00e3o Redes Neurais Convolucionais?","text":"<p>As Redes Neurais Convolucionais (CNNs) s\u00e3o um tipo de rede neural artificial, projetada para processar dados que possuem uma estrutura topol\u00f3gica similar a uma grade, como:</p> <ul> <li>Imagens (grade 2D de pixels)</li> <li>Sinais de \u00e1udio (grade 1D temporal)</li> <li>V\u00eddeos (grade 3D: altura \u00d7 largura \u00d7 tempo)</li> <li>Sequ\u00eancias de DNA (grade 1D de nucleot\u00eddeos)</li> </ul>"},{"location":"aulas/IA/lab08/cnn_guia_completo%20copy.html#vantagens-sobre-mlps-tradicionais","title":"Vantagens sobre MLPs Tradicionais","text":"Aspecto MLP Tradicional CNN Par\u00e2metros 24M+ para imagem 400\u00d7600 ~100K para mesma imagem Estrutura espacial Ignorada Preservada Invari\u00e2ncia Sens\u00edvel \u00e0 posi\u00e7\u00e3o Invariante \u00e0 transla\u00e7\u00e3o Compartilhamento Sem reutiliza\u00e7\u00e3o Compartilha pesos Efici\u00eancia Computacionalmente caro Eficiente"},{"location":"aulas/IA/lab08/cnn_guia_completo%20copy.html#arquitetura-geral-de-uma-cnn","title":"Arquitetura Geral de uma CNN","text":""},{"location":"aulas/IA/lab08/cnn_guia_completo%20copy.html#fundamentos-matematicos","title":"Fundamentos Matem\u00e1ticos","text":""},{"location":"aulas/IA/lab08/cnn_guia_completo%20copy.html#operacao-de-convolucao-matematica","title":"Opera\u00e7\u00e3o de Convolu\u00e7\u00e3o Matem\u00e1tica","text":"<p>A convolu\u00e7\u00e3o \u00e9 uma opera\u00e7\u00e3o matem\u00e1tica fundamental definida como:</p> <p></p> <p>Convolu\u00e7\u00e3o Cont\u00ednua:</p> <pre><code>(f * g)(t) = \u222b_{-\u221e}^{\u221e} f(\u03c4)g(t-\u03c4)d\u03c4\n</code></pre> <p>Convolu\u00e7\u00e3o Discreta (usada em CNNs):</p> <pre><code>(f * g)[n] = \u03a3_{m=-\u221e}^{\u221e} f[m]g[n-m]\n</code></pre>"},{"location":"aulas/IA/lab08/cnn_guia_completo%20copy.html#convolucao-2d-para-imagens","title":"Convolu\u00e7\u00e3o 2D para Imagens","text":"<p>Para imagens, usamos correla\u00e7\u00e3o cruzada (tecnicamente, n\u00e3o convolu\u00e7\u00e3o pura):</p> <p></p> <pre><code>S(i,j) = (I * K)(i,j) = \u03a3\u03a3 I(i+m, j+n) \u00d7 K(m,n)\n                        m n\n</code></pre> <p>Onde: - <code>I</code>: Imagem de entrada - <code>K</code>: Kernel (filtro) - <code>S</code>: Feature map (mapa de caracter\u00edsticas)</p>"},{"location":"aulas/IA/lab08/cnn_guia_completo%20copy.html#exemplo-pratico-de-convolucao","title":"Exemplo Pr\u00e1tico de Convolu\u00e7\u00e3o","text":"<p>Imagem 5\u00d75: <pre><code>1  2  3  0  1\n0  1  2  3  1\n1  0  1  2  0\n2  1  0  1  2\n1  0  2  1  0\n</code></pre></p> <p>Kernel 3\u00d73 (Detector de Borda): <pre><code>-1 -1 -1\n-1  8 -1\n-1 -1 -1\n</code></pre></p> <p>Resultado (Feature Map): <pre><code>Posi\u00e7\u00e3o (1,1): (-1\u00d71) + (-1\u00d72) + (-1\u00d73) + (-1\u00d70) + (8\u00d71) + (-1\u00d72) + (-1\u00d71) + (-1\u00d70) + (-1\u00d71) = -5\n</code></pre></p>"},{"location":"aulas/IA/lab08/cnn_guia_completo%20copy.html#parametros-da-camada-convolucional","title":"Parametros da Camada Convolucional","text":""},{"location":"aulas/IA/lab08/cnn_guia_completo%20copy.html#1-kernelsfiltros","title":"1. Kernels/Filtros","text":"<ul> <li>Tamanho: Normalmente 3\u00d73, 5\u00d75, 7\u00d77</li> <li>Profundidade: Igual \u00e0 profundidade da entrada</li> <li>Quantidade: Hyperpar\u00e2metro (32, 64, 128, 256...)</li> <li>Pesos: Aprendidos durante treinamento</li> </ul>"},{"location":"aulas/IA/lab08/cnn_guia_completo%20copy.html#2-stride-passo","title":"2. Stride (Passo)","text":"<ul> <li>Defini\u00e7\u00e3o: Quantos pixels o kernel \"pula\" a cada opera\u00e7\u00e3o</li> <li>Stride = 1: Sobreposi\u00e7\u00e3o m\u00e1xima</li> <li>Stride = 2: Reduz dimens\u00e3o pela metade</li> <li>F\u00f3rmula de sa\u00edda: <code>(W - F + 2P) / S + 1</code></li> </ul>"},{"location":"aulas/IA/lab08/cnn_guia_completo%20copy.html#3-padding-preenchimento","title":"3. Padding (Preenchimento)","text":"<ul> <li>Valid: Sem padding (sa\u00edda menor)</li> <li>Same: Padding para manter dimens\u00e3o</li> <li>Causal: Para dados sequenciais</li> </ul>"},{"location":"aulas/IA/lab08/cnn_guia_completo%20copy.html#tipos-de-convolucoes","title":"Tipos de Convolu\u00e7\u00f5es","text":""},{"location":"aulas/IA/lab08/cnn_guia_completo%20copy.html#convolucao-standard","title":"Convolu\u00e7\u00e3o Standard","text":"<pre><code># Exemplo com TensorFlow/Keras\nlayers.Conv2D(filters=32, kernel_size=(3,3), stride=(1,1), padding='same')\n</code></pre>"},{"location":"aulas/IA/lab08/cnn_guia_completo%20copy.html#convolucao-depthwise-separable","title":"Convolu\u00e7\u00e3o Depthwise Separable","text":"<p><pre><code>layers.SeparableConv2D(filters=32, kernel_size=(3,3))\n</code></pre> - Vantagem: Menos par\u00e2metros (~9x redu\u00e7\u00e3o) - Uso: MobileNets, Xception</p>"},{"location":"aulas/IA/lab08/cnn_guia_completo%20copy.html#convolucao-dilatada-atrous","title":"Convolu\u00e7\u00e3o Dilatada (Atrous)","text":"<p><pre><code>layers.Conv2D(filters=32, kernel_size=(3,3), dilation_rate=(2,2))\n</code></pre> - Vantagem: Campo receptivo maior sem perder resolu\u00e7\u00e3o - Uso: Segmenta\u00e7\u00e3o sem\u00e2ntica</p>"},{"location":"aulas/IA/lab08/cnn_guia_completo%20copy.html#convolucao-transposta-deconvolucao","title":"Convolu\u00e7\u00e3o Transposta (Deconvolu\u00e7\u00e3o)","text":"<p><pre><code>layers.Conv2DTranspose(filters=32, kernel_size=(3,3), strides=(2,2))\n</code></pre> - Uso: Upsampling, GANs, Autoencoders</p>"},{"location":"aulas/IA/lab08/cnn_guia_completo%20copy.html#visualizacao-da-convolucao","title":"Visualiza\u00e7\u00e3o da Convolu\u00e7\u00e3oCNN \u2013 Convolu\u00e7\u00e3o, Ativa\u00e7\u00e3o e Pooling (interativo)","text":"Entrada (28\u00d728) Limpar Ru\u00eddo Demo \u201c7\u201d Dica: desenhe com o mouse (clique e arraste). A imagem \u00e9 28\u00d728, mostrada ampliada. Kernel Identity Blur (Box) Sharpen Edge (Laplacian) Sobel X Sobel Y Emboss Custom (3\u00d73) Kernel 3\u00d73 (Custom): Padding same valid Stride Ativa\u00e7\u00e3o None ReLU Pooling None Max 2\u00d72 (s=2) Avg 2\u00d72 (s=2) Aplicar Reset kernel Sa\u00eddas: Conv: \u2014 \u2022 Pool: \u2014 Resumo: \u2014 Feature map (ap\u00f3s conv/ativa\u00e7\u00e3o) Pooling (veremos a seguir)"},{"location":"aulas/IA/lab08/cnn_guia_completo%20copy.html#pooling-e-subsampling","title":"Pooling e Subsampling","text":"<ol> <li>Redu\u00e7\u00e3o dimensional: Diminui tamanho dos feature maps</li> <li>Invari\u00e2ncia: Pequenas transla\u00e7\u00f5es n\u00e3o afetam resultado</li> <li>Redu\u00e7\u00e3o de overfitting: Menos par\u00e2metros</li> <li>Efici\u00eancia computacional: Opera\u00e7\u00e3o mais r\u00e1pida</li> </ol>"},{"location":"aulas/IA/lab08/cnn_guia_completo%20copy.html#tipos-de-pooling","title":"Tipos de Pooling","text":""},{"location":"aulas/IA/lab08/cnn_guia_completo%20copy.html#max-pooling","title":"Max Pooling","text":"<pre><code>layers.MaxPool2D(pool_size=(2,2), strides=(2,2))\n</code></pre>"},{"location":"aulas/IA/lab08/cnn_guia_completo%20copy.html#average-pooling","title":"Average Pooling","text":"<p>reduz parcialmente a dimens\u00e3o espacial (em blocos).</p> <pre><code>layers.AveragePooling2D(pool_size=(2,2))\n</code></pre>"},{"location":"aulas/IA/lab08/cnn_guia_completo%20copy.html#global-average-pooling","title":"Global Average Pooling","text":"<p>reduz totalmente a dimens\u00e3o espacial, sobrando apenas os canais.</p> <pre><code>layers.GlobalAveragePooling2D()\n</code></pre> <ul> <li>Uso: Substituir camadas FC finais</li> <li>Vantagem: Reduz overfitting, menos par\u00e2metros</li> </ul>"},{"location":"aulas/IA/lab08/cnn_guia_completo%20copy.html#adaptive-pooling","title":"Adaptive Pooling","text":"<ul> <li>Objetivo: Sa\u00edda com tamanho fixo independente da entrada</li> <li>Uso: Redes com entradas de tamanhos variados</li> </ul>"},{"location":"aulas/IA/lab08/cnn_guia_completo%20copy.html#pooling-vs-stride-convolution","title":"Pooling vs Stride Convolution","text":"Aspecto Pooling Strided Convolution Par\u00e2metros 0 Sim Aprendizado N\u00e3o Sim Flexibilidade Fixa Adapt\u00e1vel Tend\u00eancia atual \u2193 Diminuindo \u2191 Aumentando"},{"location":"aulas/IA/lab08/cnn_guia_completo%20copy.html#arquiteturas-classicas","title":"Arquiteturas Cl\u00e1ssicas","text":""},{"location":"aulas/IA/lab08/cnn_guia_completo%20copy.html#lenet-5-1998-yann-lecun","title":"LeNet-5 (1998) - Yann LeCun","text":"<pre><code>INPUT(32\u00d732\u00d71) \u2192 CONV1(28\u00d728\u00d76) \u2192 POOL1(14\u00d714\u00d76) \u2192 \nCONV2(10\u00d710\u00d716) \u2192 POOL2(5\u00d75\u00d716) \u2192 FC1(120) \u2192 FC2(84) \u2192 OUTPUT(10)\n</code></pre> <p>Implementa\u00e7\u00e3o:</p> <pre><code>model = Sequential([\n    Conv2D(6, (5,5), activation='tanh', input_shape=(32,32,1)),\n    AveragePooling2D((2,2)),\n    Conv2D(16, (5,5), activation='tanh'),\n    AveragePooling2D((2,2)),\n    Flatten(),\n    Dense(120, activation='tanh'),\n    Dense(84, activation='tanh'),\n    Dense(10, activation='softmax')\n])\n</code></pre>"},{"location":"aulas/IA/lab08/cnn_guia_completo%20copy.html#alexnet-2012-alex-krizhevsky","title":"AlexNet (2012) - Alex Krizhevsky","text":"<p>Inova\u00e7\u00f5es: - \ud83d\ude80 ReLU: Primeira CNN com ReLU em larga escala - \ud83d\udd04 Dropout: Regulariza\u00e7\u00e3o efetiva - \ud83d\udcca Data Augmentation: Aumento artificial do dataset - \u26a1 GPU: Treinamento paralelo</p> <p>Arquitetura: <pre><code>INPUT(224\u00d7224\u00d73) \u2192 CONV1(55\u00d755\u00d796) \u2192 POOL1 \u2192 CONV2(27\u00d727\u00d7256) \u2192 POOL2 \u2192\nCONV3(13\u00d713\u00d7384) \u2192 CONV4(13\u00d713\u00d7384) \u2192 CONV5(13\u00d713\u00d7256) \u2192 POOL3 \u2192\nFC1(4096) \u2192 FC2(4096) \u2192 FC3(1000)\n</code></pre></p>"},{"location":"aulas/IA/lab08/cnn_guia_completo%20copy.html#vggnet-2014-oxford","title":"VGGNet (2014) - Oxford","text":"<p>Filosofia: \"Convolu\u00e7\u00f5es pequenas e profundas\"</p> <p>Princ\u00edpios: - \ud83d\udd39 Kernels 3\u00d73: Exclusivamente - \ud83d\udcda Profundidade: 16-19 camadas - \ud83d\udd04 Repeti\u00e7\u00e3o: Padr\u00f5es consistentes</p> <p>VGG-16 Arquitetura: <pre><code># Bloco 1\nConv2D(64, (3,3), activation='relu', padding='same')\nConv2D(64, (3,3), activation='relu', padding='same')\nMaxPooling2D((2,2), strides=(2,2))\n\n# Bloco 2\nConv2D(128, (3,3), activation='relu', padding='same')\nConv2D(128, (3,3), activation='relu', padding='same')\nMaxPooling2D((2,2), strides=(2,2))\n\n# ... continua com blocos similares\n</code></pre></p>"},{"location":"aulas/IA/lab08/cnn_guia_completo%20copy.html#resnet-2015-microsoft-research","title":"ResNet (2015) - Microsoft Research","text":"<p>Problema Resolvido: Degrada\u00e7\u00e3o em redes muito profundas</p> <p>Inova\u00e7\u00e3o: Conex\u00f5es Residuais (Skip Connections)</p> <pre><code>x \u2192 [CONV\u2192BN\u2192ReLU\u2192CONV\u2192BN] \u2192 + \u2192 ReLU\n\u2193                              \u2191\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n        (skip connection)\n</code></pre> <p>Bloco Residual: <pre><code>def residual_block(x, filters):\n    shortcut = x\n\n    x = Conv2D(filters, (3,3), padding='same')(x)\n    x = BatchNormalization()(x)\n    x = Activation('relu')(x)\n\n    x = Conv2D(filters, (3,3), padding='same')(x)\n    x = BatchNormalization()(x)\n\n    x = Add()([x, shortcut])\n    x = Activation('relu')(x)\n\n    return x\n</code></pre></p>"},{"location":"aulas/IA/lab08/cnn_guia_completo%20copy.html#arquiteturas-modernas","title":"Arquiteturas Modernas","text":""},{"location":"aulas/IA/lab08/cnn_guia_completo%20copy.html#efficientnet-2019","title":"EfficientNet (2019)","text":"<ul> <li>Compound Scaling: Balanceia largura, profundidade e resolu\u00e7\u00e3o</li> <li>Neural Architecture Search: Arquitetura otimizada automaticamente</li> </ul>"},{"location":"aulas/IA/lab08/cnn_guia_completo%20copy.html#vision-transformer-vit-2020","title":"Vision Transformer (ViT) (2020)","text":"<ul> <li>Attention Mechanism: Substitui convolu\u00e7\u00f5es por aten\u00e7\u00e3o</li> <li>Patches: Divide imagem em patches como tokens</li> </ul>"},{"location":"aulas/IA/lab08/cnn_guia_completo%20copy.html#convnext-2022","title":"ConvNeXt (2022)","text":"<ul> <li>CNN Modernizada: Incorpora ideias dos Transformers</li> <li>Performance: Competitiva com ViTs</li> </ul>"},{"location":"aulas/IA/lab08/cnn_guia_completo%20copy.html#implementacao-pratica","title":"Implementa\u00e7\u00e3o Pr\u00e1tica","text":""},{"location":"aulas/IA/lab08/cnn_guia_completo%20copy.html#preparacao-dos-dados","title":"Prepara\u00e7\u00e3o dos Dados","text":"<pre><code>import tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# Carregamento e prepara\u00e7\u00e3o\n(x_train, y_train), (x_test, y_test) = keras.datasets.cifar10.load_data()\n\n# Normaliza\u00e7\u00e3o\nx_train = x_train.astype('float32') / 255.0\nx_test = x_test.astype('float32') / 255.0\n\n# One-hot encoding\ny_train = keras.utils.to_categorical(y_train, 10)\ny_test = keras.utils.to_categorical(y_test, 10)\n</code></pre>"},{"location":"aulas/IA/lab08/cnn_guia_completo%20copy.html#cnn-basica-para-cifar-10","title":"CNN B\u00e1sica para CIFAR-10","text":"<pre><code>def create_basic_cnn():\n    model = keras.Sequential([\n        # Bloco 1\n        layers.Conv2D(32, (3,3), activation='relu', input_shape=(32,32,3)),\n        layers.BatchNormalization(),\n        layers.Conv2D(32, (3,3), activation='relu'),\n        layers.MaxPooling2D((2,2)),\n        layers.Dropout(0.25),\n\n        # Bloco 2\n        layers.Conv2D(64, (3,3), activation='relu'),\n        layers.BatchNormalization(),\n        layers.Conv2D(64, (3,3), activation='relu'),\n        layers.MaxPooling2D((2,2)),\n        layers.Dropout(0.25),\n\n        # Bloco 3\n        layers.Conv2D(128, (3,3), activation='relu'),\n        layers.BatchNormalization(),\n        layers.Conv2D(128, (3,3), activation='relu'),\n        layers.MaxPooling2D((2,2)),\n        layers.Dropout(0.25),\n\n        # Classificador\n        layers.GlobalAveragePooling2D(),\n        layers.Dense(512, activation='relu'),\n        layers.Dropout(0.5),\n        layers.Dense(10, activation='softmax')\n    ])\n\n    return model\n\nmodel = create_basic_cnn()\nmodel.summary()\n</code></pre>"},{"location":"aulas/IA/lab08/cnn_guia_completo%20copy.html#tecnicas-de-treinamento","title":"T\u00e9cnicas de Treinamento","text":""},{"location":"aulas/IA/lab08/cnn_guia_completo%20copy.html#data-augmentation","title":"Data Augmentation","text":"<pre><code>datagen = keras.preprocessing.image.ImageDataGenerator(\n    rotation_range=15,\n    width_shift_range=0.1,\n    height_shift_range=0.1,\n    horizontal_flip=True,\n    zoom_range=0.1\n)\n\ndatagen.fit(x_train)\n</code></pre>"},{"location":"aulas/IA/lab08/cnn_guia_completo%20copy.html#callbacks","title":"Callbacks","text":"<pre><code>callbacks = [\n    keras.callbacks.EarlyStopping(patience=10, restore_best_weights=True),\n    keras.callbacks.ReduceLROnPlateau(factor=0.2, patience=5),\n    keras.callbacks.ModelCheckpoint('best_model.h5', save_best_only=True)\n]\n</code></pre>"},{"location":"aulas/IA/lab08/cnn_guia_completo%20copy.html#compilacao-e-treinamento","title":"Compila\u00e7\u00e3o e Treinamento","text":"<pre><code>model.compile(\n    optimizer=keras.optimizers.Adam(learning_rate=0.001),\n    loss='categorical_crossentropy',\n    metrics=['accuracy']\n)\n\nhistory = model.fit(\n    datagen.flow(x_train, y_train, batch_size=32),\n    steps_per_epoch=len(x_train) // 32,\n    epochs=100,\n    validation_data=(x_test, y_test),\n    callbacks=callbacks\n)\n</code></pre>"},{"location":"aulas/IA/lab08/cnn_guia_completo%20copy.html#tecnicas-avancadas","title":"T\u00e9cnicas Avan\u00e7adas","text":""},{"location":"aulas/IA/lab08/cnn_guia_completo%20copy.html#transfer-learning","title":"Transfer Learning","text":"<p>Conceito: Usar modelos pr\u00e9-treinados como ponto de partida</p> <pre><code># Carregar modelo pr\u00e9-treinado\nbase_model = keras.applications.VGG16(\n    weights='imagenet',\n    include_top=False,\n    input_shape=(224, 224, 3)\n)\n\n# Congelar camadas base\nbase_model.trainable = False\n\n# Adicionar cabe\u00e7alho personalizado\nmodel = keras.Sequential([\n    base_model,\n    layers.GlobalAveragePooling2D(),\n    layers.Dense(128, activation='relu'),\n    layers.Dropout(0.2),\n    layers.Dense(num_classes, activation='softmax')\n])\n</code></pre>"},{"location":"aulas/IA/lab08/cnn_guia_completo%20copy.html#fine-tuning","title":"Fine-tuning","text":"<pre><code># Ap\u00f3s treinamento inicial, descongelar e treinar com LR baixa\nbase_model.trainable = True\n\nmodel.compile(\n    optimizer=keras.optimizers.Adam(1e-5),  # LR muito baixa\n    loss='categorical_crossentropy',\n    metrics=['accuracy']\n)\n\n# Treinar mais algumas \u00e9pocas\nhistory_fine = model.fit(...)\n</code></pre>"},{"location":"aulas/IA/lab08/cnn_guia_completo%20copy.html#interpretabilidade","title":"Interpretabilidade","text":""},{"location":"aulas/IA/lab08/cnn_guia_completo%20copy.html#grad-cam-gradient-weighted-class-activation-mapping","title":"Grad-CAM (Gradient-weighted Class Activation Mapping)","text":"<pre><code>def generate_gradcam(model, img_array, layer_name, class_index):\n    grad_model = keras.Model(\n        inputs=model.inputs,\n        outputs=[model.get_layer(layer_name).output, model.output]\n    )\n\n    with tf.GradientTape() as tape:\n        conv_outputs, predictions = grad_model(img_array)\n        loss = predictions[:, class_index]\n\n    grads = tape.gradient(loss, conv_outputs)\n    pooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2))\n\n    conv_outputs = conv_outputs[0]\n    heatmap = conv_outputs @ pooled_grads[..., tf.newaxis]\n    heatmap = tf.squeeze(heatmap)\n    heatmap = tf.maximum(heatmap, 0) / tf.math.reduce_max(heatmap)\n\n    return heatmap.numpy()\n</code></pre>"},{"location":"aulas/IA/lab08/cnn_guia_completo%20copy.html#otimizacoes-de-performance","title":"Otimiza\u00e7\u00f5es de Performance","text":""},{"location":"aulas/IA/lab08/cnn_guia_completo%20copy.html#mixed-precision-training","title":"Mixed Precision Training","text":"<pre><code>policy = keras.mixed_precision.Policy('mixed_float16')\nkeras.mixed_precision.set_global_policy(policy)\n</code></pre>"},{"location":"aulas/IA/lab08/cnn_guia_completo%20copy.html#quantizacao","title":"Quantiza\u00e7\u00e3o","text":"<pre><code># Post-training quantization\nconverter = tf.lite.TFLiteConverter.from_saved_model('model_path')\nconverter.optimizations = [tf.lite.Optimize.DEFAULT]\nquantized_model = converter.convert()\n</code></pre>"},{"location":"aulas/IA/lab08/cnn_guia_completo%20copy.html#aplicacoes-e-casos-de-uso","title":"Aplica\u00e7\u00f5es e Casos de Uso","text":""},{"location":"aulas/IA/lab08/cnn_guia_completo%20copy.html#1-classificacao-de-imagens","title":"1. Classifica\u00e7\u00e3o de Imagens","text":"<p>Datasets Cl\u00e1ssicos: - MNIST: D\u00edgitos manuscritos (28\u00d728) - CIFAR-10/100: Objetos naturais (32\u00d732) - ImageNet: 1000 classes, milh\u00f5es de imagens - Places365: Reconhecimento de cenas</p> <p>Aplica\u00e7\u00f5es Reais: - \ud83c\udfe5 Diagn\u00f3stico m\u00e9dico: Raio-X, resson\u00e2ncia, dermatologia - \ud83d\ude97 Ve\u00edculos aut\u00f4nomos: Detec\u00e7\u00e3o de placas, pedestres - \ud83d\udee1\ufe0f Seguran\u00e7a: Reconhecimento facial, videomonitoramento - \ud83d\udcf1 Mobile: Filtros, busca por imagem</p>"},{"location":"aulas/IA/lab08/cnn_guia_completo%20copy.html#2-deteccao-de-objetos","title":"2. Detec\u00e7\u00e3o de Objetos","text":"<p>Arquiteturas: - R-CNN Family: R-CNN, Fast R-CNN, Faster R-CNN - YOLO: You Only Look Once (v1-v8) - SSD: Single Shot MultiBox Detector - EfficientDet: Detec\u00e7\u00e3o eficiente</p> <p>Aplica\u00e7\u00f5es: - \ud83d\udea6 Tr\u00e2nsito inteligente: Contagem de ve\u00edculos - \ud83c\udfed Ind\u00fastria: Controle de qualidade, automa\u00e7\u00e3o - \ud83c\udfea Retail: Checkout autom\u00e1tico, invent\u00e1rio - \ud83c\udf3e Agricultura: Monitoramento de culturas</p>"},{"location":"aulas/IA/lab08/cnn_guia_completo%20copy.html#3-segmentacao-semantica","title":"3. Segmenta\u00e7\u00e3o Sem\u00e2ntica","text":"<p>Arquiteturas: - U-Net: Segmenta\u00e7\u00e3o m\u00e9dica - DeepLab: Convolu\u00e7\u00e3o atrous - PSPNet: Pyramid Scene Parsing - Mask R-CNN: Segmenta\u00e7\u00e3o de inst\u00e2ncias</p> <p>Aplica\u00e7\u00f5es: - \ud83c\udfe5 Medicina: Segmenta\u00e7\u00e3o de \u00f3rg\u00e3os, tumores - \ud83d\udef0\ufe0f Sensoriamento remoto: An\u00e1lise de sat\u00e9lites - \ud83c\udfac Entretenimento: Chroma key, efeitos especiais - \ud83c\udfd7\ufe0f Arquitetura: An\u00e1lise urbana, planejamento</p>"},{"location":"aulas/IA/lab08/cnn_guia_completo%20copy.html#4-processamento-de-video","title":"4. Processamento de V\u00eddeo","text":"<p>T\u00e9cnicas: - 3D CNNs: Convolu\u00e7\u00e3o espa\u00e7o-temporal - Two-Stream Networks: RGB + Optical Flow - LSTM + CNN: Sequ\u00eancias temporais</p> <p>Aplica\u00e7\u00f5es: - \ud83c\udfaf Reconhecimento de a\u00e7\u00f5es: Esportes, vigil\u00e2ncia - \ud83c\udf9e\ufe0f An\u00e1lise de v\u00eddeo: Sumariza\u00e7\u00e3o, indexa\u00e7\u00e3o - \ud83c\udfc3 An\u00e1lise de movimento: Biomec\u00e2nica, reabilita\u00e7\u00e3o</p>"},{"location":"aulas/IA/lab08/cnn_guia_completo%20copy.html#exercicios-e-projetos","title":"Exerc\u00edcios e Projetos","text":""},{"location":"aulas/IA/lab08/cnn_guia_completo%20copy.html#nivel-iniciante","title":"N\u00edvel Iniciante","text":""},{"location":"aulas/IA/lab08/cnn_guia_completo%20copy.html#projeto-1-classificador-de-digitos-mnist","title":"Projeto 1: Classificador de D\u00edgitos MNIST","text":"<pre><code># Implemente uma CNN simples para MNIST\n# Objetivo: &gt;98% de acur\u00e1cia\n# T\u00e9cnicas: Conv2D, MaxPooling, Dropout\n\ndef create_mnist_cnn():\n    # Seu c\u00f3digo aqui\n    pass\n</code></pre>"},{"location":"aulas/IA/lab08/cnn_guia_completo%20copy.html#projeto-2-fashion-mnist","title":"Projeto 2: Fashion-MNIST","text":"<pre><code># Classifique itens de vestu\u00e1rio\n# Objetivo: &gt;90% de acur\u00e1cia\n# Desafio: Mais complexo que d\u00edgitos\n\ndef create_fashion_cnn():\n    # Seu c\u00f3digo aqui\n    pass\n</code></pre>"},{"location":"aulas/IA/lab08/cnn_guia_completo%20copy.html#nivel-intermediario","title":"N\u00edvel Intermedi\u00e1rio","text":""},{"location":"aulas/IA/lab08/cnn_guia_completo%20copy.html#projeto-3-cifar-10-com-data-augmentation","title":"Projeto 3: CIFAR-10 com Data Augmentation","text":"<pre><code># Objetivo: &gt;85% de acur\u00e1cia\n# T\u00e9cnicas: Data augmentation, batch normalization\n# Tempo limite: 2 horas de treinamento\n\ndef create_cifar10_cnn():\n    # Seu c\u00f3digo aqui\n    pass\n</code></pre>"},{"location":"aulas/IA/lab08/cnn_guia_completo%20copy.html#projeto-4-transfer-learning","title":"Projeto 4: Transfer Learning","text":"<pre><code># Use um modelo pr\u00e9-treinado para novo dataset\n# Compare com treinamento do zero\n# Analise o tempo de converg\u00eancia\n\ndef transfer_learning_project():\n    # Seu c\u00f3digo aqui\n    pass\n</code></pre>"},{"location":"aulas/IA/lab08/cnn_guia_completo%20copy.html#nivel-avancado","title":"N\u00edvel Avan\u00e7ado","text":""},{"location":"aulas/IA/lab08/cnn_guia_completo%20copy.html#projeto-5-implementar-resnet-do-zero","title":"Projeto 5: Implementar ResNet do Zero","text":"<pre><code># Implemente blocos residuais\n# Compare com CNN convencional\n# Analise o gradiente em redes profundas\n\nclass ResNetBlock(layers.Layer):\n    def __init__(self, filters, downsample=False):\n        # Seu c\u00f3digo aqui\n        pass\n</code></pre>"},{"location":"aulas/IA/lab08/cnn_guia_completo%20copy.html#projeto-6-deteccao-de-objetos-simples","title":"Projeto 6: Detec\u00e7\u00e3o de Objetos Simples","text":"<pre><code># Implemente um detector simples\n# Use t\u00e9cnicas de sliding window\n# Avalie com m\u00e9tricas de detec\u00e7\u00e3o (mAP)\n\ndef simple_object_detector():\n    # Seu c\u00f3digo aqui\n    pass\n</code></pre>"},{"location":"aulas/IA/lab08/cnn_guia_completo%20copy.html#projetos-aplicados","title":"Projetos Aplicados","text":""},{"location":"aulas/IA/lab08/cnn_guia_completo%20copy.html#projeto-7-diagnostico-medico","title":"Projeto 7: Diagn\u00f3stico M\u00e9dico","text":"<ul> <li>Dataset: Chest X-Ray pneumonia</li> <li>Objetivo: Classificar pneumonia vs normal</li> <li>M\u00e9tricas: Sensibilidade, especificidade, F1-score</li> <li>Considera\u00e7\u00f5es \u00e9ticas: Falsos negativos</li> </ul>"},{"location":"aulas/IA/lab08/cnn_guia_completo%20copy.html#projeto-8-classificacao-de-plantas","title":"Projeto 8: Classifica\u00e7\u00e3o de Plantas","text":"<ul> <li>Dataset: PlantNet ou similar</li> <li>T\u00e9cnicas: Transfer learning, data augmentation</li> <li>Aplica\u00e7\u00e3o: App m\u00f3vel de identifica\u00e7\u00e3o</li> </ul>"},{"location":"aulas/IA/lab08/cnn_guia_completo%20copy.html#projeto-9-analise-de-sentimentos-visual","title":"Projeto 9: An\u00e1lise de Sentimentos Visual","text":"<ul> <li>Dataset: Imagens de redes sociais</li> <li>Objetivo: Predizer sentimento pela imagem</li> <li>Desafio: Multimodalidade (imagem + texto)</li> </ul>"},{"location":"aulas/IA/lab08/cnn_guia_completo%20copy.html#debugging-e-troubleshooting","title":"Debugging e Troubleshooting","text":""},{"location":"aulas/IA/lab08/cnn_guia_completo%20copy.html#problemas-comuns","title":"Problemas Comuns","text":""},{"location":"aulas/IA/lab08/cnn_guia_completo%20copy.html#1-overfitting","title":"1. Overfitting","text":"<p>Sintomas: - Alta acur\u00e1cia no treino, baixa no teste - Gap crescente entre curvas de treino e valida\u00e7\u00e3o</p> <p>Solu\u00e7\u00f5es: <pre><code># Mais dados\ndatagen = ImageDataGenerator(...)\n\n# Dropout\nlayers.Dropout(0.5)\n\n# Regulariza\u00e7\u00e3o L2\nlayers.Conv2D(64, (3,3), kernel_regularizer=l2(0.01))\n\n# Early stopping\ncallbacks = [EarlyStopping(patience=10)]\n</code></pre></p>"},{"location":"aulas/IA/lab08/cnn_guia_completo%20copy.html#2-underfitting","title":"2. Underfitting","text":"<p>Sintomas: - Baixa acur\u00e1cia tanto no treino quanto no teste - Curvas de loss n\u00e3o convergem</p> <p>Solu\u00e7\u00f5es: <pre><code># Modelo mais complexo\n# Mais camadas ou mais filtros\n\n# Learning rate adequada\noptimizer = Adam(learning_rate=0.001)\n\n# Mais \u00e9pocas de treinamento\nepochs = 200\n</code></pre></p>"},{"location":"aulas/IA/lab08/cnn_guia_completo%20copy.html#3-vanishing-gradients","title":"3. Vanishing Gradients","text":"<p>Sintomas: - Camadas iniciais n\u00e3o aprendem - Gradientes muito pequenos</p> <p>Solu\u00e7\u00f5es: <pre><code># Batch Normalization\nlayers.BatchNormalization()\n\n# Residual connections\n# Skip connections\n\n# Ativa\u00e7\u00f5es adequadas (ReLU, n\u00e3o sigmoid)\nactivation='relu'\n</code></pre></p>"},{"location":"aulas/IA/lab08/cnn_guia_completo%20copy.html#4-exploding-gradients","title":"4. Exploding Gradients","text":"<p>Sintomas: - Loss explode para infinito - Pesos ficam NaN</p> <p>Solu\u00e7\u00f5es: <pre><code># Gradient clipping\noptimizer = Adam(clipnorm=1.0)\n\n# Learning rate menor\nlearning_rate = 0.0001\n\n# Batch normalization\nlayers.BatchNormalization()\n</code></pre></p>"},{"location":"aulas/IA/lab08/cnn_guia_completo%20copy.html#monitoramento-de-treinamento","title":"Monitoramento de Treinamento","text":"<pre><code># Visualiza\u00e7\u00e3o em tempo real\ndef plot_training_history(history):\n    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4))\n\n    # Loss\n    ax1.plot(history.history['loss'], label='Train Loss')\n    ax1.plot(history.history['val_loss'], label='Val Loss')\n    ax1.set_title('Model Loss')\n    ax1.set_xlabel('Epoch')\n    ax1.set_ylabel('Loss')\n    ax1.legend()\n\n    # Accuracy\n    ax2.plot(history.history['accuracy'], label='Train Acc')\n    ax2.plot(history.history['val_accuracy'], label='Val Acc')\n    ax2.set_title('Model Accuracy')\n    ax2.set_xlabel('Epoch')\n    ax2.set_ylabel('Accuracy')\n    ax2.legend()\n\n    plt.tight_layout()\n    plt.show()\n</code></pre>"},{"location":"aulas/IA/lab08/cnn_guia_completo%20copy.html#metricas-de-avaliacao","title":"M\u00e9tricas de Avalia\u00e7\u00e3o","text":""},{"location":"aulas/IA/lab08/cnn_guia_completo%20copy.html#classificacao","title":"Classifica\u00e7\u00e3o","text":""},{"location":"aulas/IA/lab08/cnn_guia_completo%20copy.html#metricas-basicas","title":"M\u00e9tricas B\u00e1sicas","text":"<pre><code>from sklearn.metrics import classification_report, confusion_matrix\n\n# Predi\u00e7\u00f5es\ny_pred = model.predict(x_test)\ny_pred_classes = np.argmax(y_pred, axis=1)\ny_true = np.argmax(y_test, axis=1)\n\n# Relat\u00f3rio completo\nprint(classification_report(y_true, y_pred_classes))\n\n# Matriz de confus\u00e3o\ncm = confusion_matrix(y_true, y_pred_classes)\n</code></pre>"},{"location":"aulas/IA/lab08/cnn_guia_completo%20copy.html#metricas-avancadas","title":"M\u00e9tricas Avan\u00e7adas","text":"<pre><code># Top-k accuracy\ntop_k_acc = keras.metrics.top_k_categorical_accuracy(y_test, y_pred, k=5)\n\n# Curva ROC (para classifica\u00e7\u00e3o bin\u00e1ria)\nfrom sklearn.metrics import roc_curve, auc\nfpr, tpr, _ = roc_curve(y_true, y_pred_proba)\nroc_auc = auc(fpr, tpr)\n</code></pre>"},{"location":"aulas/IA/lab08/cnn_guia_completo%20copy.html#deteccao-de-objetos","title":"Detec\u00e7\u00e3o de Objetos","text":""},{"location":"aulas/IA/lab08/cnn_guia_completo%20copy.html#mean-average-precision-map","title":"Mean Average Precision (mAP)","text":"<pre><code>def calculate_map(true_boxes, pred_boxes, iou_threshold=0.5):\n    \"\"\"\n    Calcula mAP para detec\u00e7\u00e3o de objetos\n    \"\"\"\n    # Implementa\u00e7\u00e3o simplificada\n    pass\n</code></pre>"},{"location":"aulas/IA/lab08/cnn_guia_completo%20copy.html#segmentacao","title":"Segmenta\u00e7\u00e3o","text":""},{"location":"aulas/IA/lab08/cnn_guia_completo%20copy.html#intersection-over-union-iou","title":"Intersection over Union (IoU)","text":"<pre><code>def calculate_iou(y_true, y_pred):\n    intersection = np.logical_and(y_true, y_pred)\n    union = np.logical_or(y_true, y_pred)\n    iou = np.sum(intersection) / np.sum(union)\n    return iou\n</code></pre>"},{"location":"aulas/IA/lab08/cnn_guia_completo%20copy.html#ferramentas-e-frameworks","title":"Ferramentas e Frameworks","text":""},{"location":"aulas/IA/lab08/cnn_guia_completo%20copy.html#tensorflowkeras","title":"TensorFlow/Keras","text":"<pre><code># Instala\u00e7\u00e3o\npip install tensorflow tensorflow-gpu\n\n# Uso b\u00e1sico\nimport tensorflow as tf\nfrom tensorflow import keras\n</code></pre>"},{"location":"aulas/IA/lab08/cnn_guia_completo%20copy.html#pytorch","title":"PyTorch","text":"<pre><code># Instala\u00e7\u00e3o\npip install torch torchvision\n\n# Uso b\u00e1sico\nimport torch\nimport torch.nn as nn\nimport torchvision\n</code></pre>"},{"location":"aulas/IA/lab08/cnn_guia_completo%20copy.html#outras-ferramentas","title":"Outras Ferramentas","text":""},{"location":"aulas/IA/lab08/cnn_guia_completo%20copy.html#visualizacao","title":"Visualiza\u00e7\u00e3o","text":"<pre><code># TensorBoard\ntensorboard_callback = keras.callbacks.TensorBoard(log_dir='./logs')\n\n# Weights &amp; Biases\nimport wandb\nwandb.init(project=\"my-cnn-project\")\n</code></pre>"},{"location":"aulas/IA/lab08/cnn_guia_completo%20copy.html#datasets","title":"Datasets","text":"<pre><code># TensorFlow Datasets\nimport tensorflow_datasets as tfds\ndataset = tfds.load('cifar10', split='train')\n\n# Torchvision datasets\nfrom torchvision import datasets\ndataset = datasets.CIFAR10(root='./data', download=True)\n</code></pre>"},{"location":"aulas/IA/lab08/cnn_guia_completo%20copy.html#augmentation","title":"Augmentation","text":"<pre><code># Albumentations\nimport albumentations as A\ntransform = A.Compose([\n    A.HorizontalFlip(p=0.5),\n    A.Rotate(limit=15, p=0.5),\n    A.RandomBrightnessContrast(p=0.2)\n])\n</code></pre>"},{"location":"aulas/IA/lab08/cnn_guia_completo%20copy.html#recursos-adicionais","title":"Recursos Adicionais","text":""},{"location":"aulas/IA/lab08/cnn_guia_completo%20copy.html#cursos-online","title":"Cursos Online","text":"<ul> <li>\ud83c\udf93 CS231n: Stanford - Convolutional Neural Networks</li> <li>\ud83c\udf93 Fast.ai: Practical Deep Learning for Coders</li> <li>\ud83c\udf93 Deep Learning Specialization: Coursera (Andrew Ng)</li> <li>\ud83c\udf93 TensorFlow Developer Certificate: Google</li> </ul>"},{"location":"aulas/IA/lab08/cnn_guia_completo%20copy.html#livros-recomendados","title":"Livros Recomendados","text":"<ul> <li>\ud83d\udcda \"Deep Learning\" - Ian Goodfellow, Yoshua Bengio, Aaron Courville</li> <li>\ud83d\udcda \"Hands-On Machine Learning\" - Aur\u00e9lien G\u00e9ron</li> <li>\ud83d\udcda \"Deep Learning with Python\" - Fran\u00e7ois Chollet</li> <li>\ud83d\udcda \"Computer Vision: Algorithms and Applications\" - Richard Szeliski</li> </ul>"},{"location":"aulas/IA/lab08/cnn_guia_completo%20copy.html#papers-fundamentais","title":"Papers Fundamentais","text":"<ul> <li>\ud83d\udcc4 LeNet-5 (1998): \"Gradient-based learning applied to document recognition\"</li> <li>\ud83d\udcc4 AlexNet (2012): \"ImageNet Classification with Deep Convolutional Neural Networks\"</li> <li>\ud83d\udcc4 VGG (2014): \"Very Deep Convolutional Networks for Large-Scale Image Recognition\"</li> <li>\ud83d\udcc4 ResNet (2015): \"Deep Residual Learning for Image Recognition\"</li> <li>\ud83d\udcc4 Attention (2017): \"Attention Is All You Need\"</li> </ul>"},{"location":"aulas/IA/lab08/cnn_guia_completo%20copy.html#datasets-populares","title":"Datasets Populares","text":"<ul> <li>\ud83d\uddc2\ufe0f ImageNet: 14M imagens, 1000 classes</li> <li>\ud83d\uddc2\ufe0f COCO: Detec\u00e7\u00e3o e segmenta\u00e7\u00e3o</li> <li>\ud83d\uddc2\ufe0f Open Images: 9M imagens anotadas</li> <li>\ud83d\uddc2\ufe0f Places365: Reconhecimento de cenas</li> <li>\ud83d\uddc2\ufe0f CelebA: Atributos faciais</li> </ul>"},{"location":"aulas/IA/lab08/cnn_guia_completo%20copy.html#competicoes-e-desafios","title":"Competi\u00e7\u00f5es e Desafios","text":"<ul> <li>\ud83c\udfc6 ImageNet Large Scale Visual Recognition Challenge (ILSVRC)</li> <li>\ud83c\udfc6 Kaggle Computer Vision Competitions</li> <li>\ud83c\udfc6 COCO Detection Challenge</li> <li>\ud83c\udfc6 Pascal VOC Challenge</li> </ul>"},{"location":"aulas/IA/lab08/cnn_guia_completo%20copy.html#comunidades","title":"Comunidades","text":"<ul> <li>\ud83d\udcac Reddit: r/MachineLearning, r/ComputerVision</li> <li>\ud83d\udcac Discord: TensorFlow Community, PyTorch Community</li> <li>\ud83d\udcac Stack Overflow: Tags [tensorflow], [computer-vision]</li> <li>\ud83d\udcac Papers with Code: Estado da arte em CV</li> </ul>"},{"location":"aulas/IA/lab08/cnn_guia_completo%20copy.html#tendencias-futuras","title":"Tend\u00eancias Futuras","text":""},{"location":"aulas/IA/lab08/cnn_guia_completo%20copy.html#vision-transformers-vits","title":"Vision Transformers (ViTs)","text":"<ul> <li>Substitui\u00e7\u00e3o gradual de CNNs em alguns dom\u00ednios</li> <li>Melhor performance em datasets grandes</li> <li>Aten\u00e7\u00e3o global vs. campos receptivos locais</li> </ul>"},{"location":"aulas/IA/lab08/cnn_guia_completo%20copy.html#neural-architecture-search-nas","title":"Neural Architecture Search (NAS)","text":"<ul> <li>Automa\u00e7\u00e3o do design de arquiteturas</li> <li>EfficientNet, RegNet como exemplos</li> <li>Otimiza\u00e7\u00e3o para dispositivos espec\u00edficos</li> </ul>"},{"location":"aulas/IA/lab08/cnn_guia_completo%20copy.html#self-supervised-learning","title":"Self-Supervised Learning","text":"<ul> <li>Aprendizado sem r\u00f3tulos</li> <li>Contrastive learning, MAE (Masked Autoencoders)</li> <li>Redu\u00e7\u00e3o da depend\u00eancia de dados anotados</li> </ul>"},{"location":"aulas/IA/lab08/cnn_guia_completo%20copy.html#edge-computing","title":"Edge Computing","text":"<ul> <li>CNNs otimizadas para dispositivos m\u00f3veis</li> <li>Quantiza\u00e7\u00e3o, pruning, knowledge distillation</li> <li>MobileNets, EfficientNets como precursores</li> </ul>"},{"location":"aulas/IA/lab08/cnn_guia_completo%20copy.html#multimodalidade","title":"Multimodalidade","text":"<ul> <li>Integra\u00e7\u00e3o de vis\u00e3o com linguagem</li> <li>CLIP, DALL-E como exemplos</li> <li>Aplica\u00e7\u00f5es em rob\u00f3tica e IA geral</li> </ul>"},{"location":"aulas/IA/lab08/cnn_guia_completo%20copy.html#conclusao","title":"Conclus\u00e3o","text":"<p>As Redes Neurais Convolucionais revolucionaram o campo da Vis\u00e3o Computacional e continuam sendo uma ferramenta fundamental para processamento de dados visuais. Desde a simples LeNet-5 at\u00e9 as arquiteturas modernas como EfficientNet e Vision Transformers, as CNNs demonstraram capacidade excepcional de:</p> <p>\u2705 Aprender representa\u00e7\u00f5es hier\u00e1rquicas de caracter\u00edsticas visuais \u2705 Generalizar para novos dados com performance superior \u2705 Escalar para problemas complexos do mundo real \u2705 Adaptar-se a diferentes dom\u00ednios atrav\u00e9s de transfer learning</p>"},{"location":"aulas/IA/lab08/cnn_guia_completo%20copy.html#pontos-chave-para-lembrar","title":"Pontos-chave para lembrar:","text":"<ol> <li>Fundamentos s\u00f3lidos: Entenda convolu\u00e7\u00e3o, pooling e backpropagation</li> <li>Pr\u00e1tica constante: Implemente desde CNNs b\u00e1sicas at\u00e9 arquiteturas avan\u00e7adas  </li> <li>Experimenta\u00e7\u00e3o: Teste diferentes arquiteturas e hiperpar\u00e2metros</li> <li>Dados de qualidade: Invista tempo em prepara\u00e7\u00e3o e augmentation</li> <li>Avalia\u00e7\u00e3o rigorosa: Use m\u00e9tricas apropriadas e valida\u00e7\u00e3o cruzada</li> <li>Acompanhe tend\u00eancias: Campo em r\u00e1pida evolu\u00e7\u00e3o</li> </ol>"},{"location":"aulas/IA/lab08/cnn_guia_completo%20copy.html#proximos-passos-recomendados","title":"Pr\u00f3ximos passos recomendados:","text":"<p>\ud83d\ude80 Imediatos: Complete os exerc\u00edcios pr\u00e1ticos deste guia \ud83d\ude80 Curto prazo: Participe de competi\u00e7\u00f5es Kaggle \ud83d\ude80 M\u00e9dio prazo: Estude Vision Transformers e t\u00e9cnicas modernas \ud83d\ude80 Longo prazo: Contribua para projetos open source e pesquisa</p> <p>O dom\u00ednio das CNNs abre portas para \u00e1reas fascinantes como rob\u00f3tica, realidade aumentada, medicina digital e muito mais. Continue praticando, experimentando e explorando - o futuro da vis\u00e3o computacional est\u00e1 em suas m\u00e3os! \ud83c\udf1f</p> <p>\"The best way to learn deep learning is by doing deep learning.\" - Andrew Ng</p> <p>Bons estudos e que a for\u00e7a (convolucional) esteja com voc\u00ea! \ud83e\udd16\u2728</p>"},{"location":"aulas/IA/lab08/detecta_emocao.html","title":"Detecta emocao","text":"In\u00a0[\u00a0]: Copied! <pre>import cv2\nimport numpy as np\nfrom tensorflow.keras.models import load_model\n</pre> import cv2 import numpy as np from tensorflow.keras.models import load_model In\u00a0[\u00a0]: Copied! <pre># Dicion\u00e1rio para mapear \u00edndices de emo\u00e7\u00e3o para r\u00f3tulos textuais\nlabel_to_text = {0: 'angry', 1: 'disgust', 2: 'fear', 3: 'happiness', 4: 'sad', 5: 'surprise', 6: 'neutral'}\n</pre> # Dicion\u00e1rio para mapear \u00edndices de emo\u00e7\u00e3o para r\u00f3tulos textuais label_to_text = {0: 'angry', 1: 'disgust', 2: 'fear', 3: 'happiness', 4: 'sad', 5: 'surprise', 6: 'neutral'} In\u00a0[\u00a0]: Copied! <pre># Carregar o modelo treinado\nmodel_path = 'best_model.h5'\nmodel = load_model(model_path)\n</pre> # Carregar o modelo treinado model_path = 'best_model.h5' model = load_model(model_path) In\u00a0[\u00a0]: Copied! <pre># Inicializar a webcam\ncap = cv2.VideoCapture(1)  #webcam\n# cap = cv2.VideoCapture(\"Jeff.mp4\")\nface_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n</pre> # Inicializar a webcam cap = cv2.VideoCapture(1)  #webcam # cap = cv2.VideoCapture(\"Jeff.mp4\") face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml') In\u00a0[\u00a0]: Copied! <pre>def preprocess_frame(frame):\n    \n    gray_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n    # Resize 48x48 pixels\n    resized_frame = cv2.resize(gray_frame, (48, 48))\n    # Normaliza\n    normalized_frame = resized_frame / 255.0\n    # Reshape\n    reshaped_frame = np.reshape(normalized_frame, (1, 48, 48, 1))\n    return reshaped_frame\n</pre> def preprocess_frame(frame):          gray_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)     # Resize 48x48 pixels     resized_frame = cv2.resize(gray_frame, (48, 48))     # Normaliza     normalized_frame = resized_frame / 255.0     # Reshape     reshaped_frame = np.reshape(normalized_frame, (1, 48, 48, 1))     return reshaped_frame In\u00a0[\u00a0]: Copied! <pre>while True:\n    # Capturar frame\n    ret, frame = cap.read()\n    if not ret:\n        break\n    \n    frame = cv2.flip(frame, 1)  \n    \n    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n    faces = face_cascade.detectMultiScale(gray, scaleFactor=1.2, minNeighbors=7)\n\n    for (x, y, w, h) in faces:\n        face = frame[y:y+h, x:x+w]\n        cv2.rectangle(frame, (x, y), (x+w, y+h), (255, 0, 0), 2)\n        \n        # Pr\u00e9-processar o frame\n        preprocessed_frame = preprocess_frame(face)\n        \n        # Fazer a previs\u00e3o\n        predictions = model.predict(preprocessed_frame)\n        emotion_index = np.argmax(predictions)\n        emotion_label = label_to_text[emotion_index]\n        \n        # Escrever o r\u00f3tulo da emo\u00e7\u00e3o na borda do ret\u00e2ngulo\n        cv2.rectangle(frame, (x, y-40), (x+w, y), (255, 0, 0), -1)\n        cv2.putText(frame, emotion_label, (x, y-10), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (255, 255, 255), 2, cv2.LINE_AA)\n\n        # # Desenhar a emo\u00e7\u00e3o prevista no frame\n        # cv2.putText(frame, emotion_label, (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 0), 20, cv2.LINE_AA)\n        # cv2.putText(frame, emotion_label, (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2, cv2.LINE_AA)\n        \n        # Mostrar o frame\n    cv2.imshow('Emotion Detection', frame)\n    \n    # Sair do loop ao pressionar 'q'\n    if cv2.waitKey(1) &amp; 0xFF == ord('q'):\n        break\n</pre> while True:     # Capturar frame     ret, frame = cap.read()     if not ret:         break          frame = cv2.flip(frame, 1)            gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)     faces = face_cascade.detectMultiScale(gray, scaleFactor=1.2, minNeighbors=7)      for (x, y, w, h) in faces:         face = frame[y:y+h, x:x+w]         cv2.rectangle(frame, (x, y), (x+w, y+h), (255, 0, 0), 2)                  # Pr\u00e9-processar o frame         preprocessed_frame = preprocess_frame(face)                  # Fazer a previs\u00e3o         predictions = model.predict(preprocessed_frame)         emotion_index = np.argmax(predictions)         emotion_label = label_to_text[emotion_index]                  # Escrever o r\u00f3tulo da emo\u00e7\u00e3o na borda do ret\u00e2ngulo         cv2.rectangle(frame, (x, y-40), (x+w, y), (255, 0, 0), -1)         cv2.putText(frame, emotion_label, (x, y-10), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (255, 255, 255), 2, cv2.LINE_AA)          # # Desenhar a emo\u00e7\u00e3o prevista no frame         # cv2.putText(frame, emotion_label, (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 0), 20, cv2.LINE_AA)         # cv2.putText(frame, emotion_label, (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2, cv2.LINE_AA)                  # Mostrar o frame     cv2.imshow('Emotion Detection', frame)          # Sair do loop ao pressionar 'q'     if cv2.waitKey(1) &amp; 0xFF == ord('q'):         break In\u00a0[\u00a0]: Copied! <pre># Quando tudo estiver feito, libere a captura\ncap.release()\ncv2.destroyAllWindows()\n</pre> # Quando tudo estiver feito, libere a captura cap.release() cv2.destroyAllWindows()"},{"location":"aulas/IA/lab08/detecta_emocao_notebook.html","title":"Detecta emocao notebook","text":"In\u00a0[\u00a0]: Copied! <pre>### USANDO O GOOGLE COLAB PARA BAIXAR O DATASET\n\nimport os\n\n# Baixa o arquivo do Google Drive\n!gdown 1MvvLoQzUbodQQ-eOCHU89LwX44gWxDgq -O utkface.zip\n\n# Descompacta o zip\n!unzip -q utkface.zip\n\n# Descompacta o tar.gz\ntar_path = '/content/fer2013.tar.gz'\nextract_path = '/content/fer2013'\nos.makedirs(extract_path, exist_ok=True)\n!tar -xzf {tar_path} -C {extract_path}\n\n# Caminho do CSV\ncsv_path = os.path.join(extract_path, 'fer2013/fer2013.csv')\n</pre> ### USANDO O GOOGLE COLAB PARA BAIXAR O DATASET  import os  # Baixa o arquivo do Google Drive !gdown 1MvvLoQzUbodQQ-eOCHU89LwX44gWxDgq -O utkface.zip  # Descompacta o zip !unzip -q utkface.zip  # Descompacta o tar.gz tar_path = '/content/fer2013.tar.gz' extract_path = '/content/fer2013' os.makedirs(extract_path, exist_ok=True) !tar -xzf {tar_path} -C {extract_path}  # Caminho do CSV csv_path = os.path.join(extract_path, 'fer2013/fer2013.csv') In\u00a0[\u00a0]: Copied! <pre>import pandas as pd\n\ndata = pd.read_csv(csv_path)\n\ndata.head()\n</pre> import pandas as pd  data = pd.read_csv(csv_path)  data.head() Out[\u00a0]: emotion pixels Usage 0 0 70 80 82 72 58 58 60 63 54 58 60 48 89 115 121... Training 1 0 151 150 147 155 148 133 111 140 170 174 182 15... Training 2 2 231 212 156 164 174 138 161 173 182 200 106 38... Training 3 4 24 32 36 30 32 23 19 20 30 41 21 22 32 34 21 1... Training 4 6 4 0 0 0 0 0 0 0 0 0 0 0 3 15 23 28 48 50 58 84... Training In\u00a0[\u00a0]: Copied! <pre>from tensorflow.keras.utils import to_categorical\nimport numpy as np\n\n# Fun\u00e7\u00e3o de pr\u00e9-processamento\ndef preprocess_data(data):\n    pixels = data['pixels'].tolist()\n    faces = [np.fromstring(pixel_sequence, dtype=int, sep=' ').reshape(48, 48, 1) for pixel_sequence in pixels]\n    faces = np.array(faces).astype('float32')\n    faces /= 255.0\n    emotions = to_categorical(data['emotion'], num_classes=7)\n    return faces, emotions\n\n# Separar os dados de treinamento, valida\u00e7\u00e3o e teste\ntrain_data = data[data['Usage'] == 'Training']\nval_data = data[data['Usage'] == 'PublicTest']\ntest_data = data[data['Usage'] == 'PrivateTest']\n\nx_train, y_train = preprocess_data(train_data)\nx_val, y_val = preprocess_data(val_data)\nx_test, y_test = preprocess_data(test_data)\n\n# Verificar as formas dos dados\nprint('x_train shape:', x_train.shape)\nprint('y_train shape:', y_train.shape)\nprint('x_val shape:', x_val.shape)\nprint('y_val shape:', y_val.shape)\nprint('x_test shape:', x_test.shape)\nprint('y_test shape:', y_test.shape)\n</pre> from tensorflow.keras.utils import to_categorical import numpy as np  # Fun\u00e7\u00e3o de pr\u00e9-processamento def preprocess_data(data):     pixels = data['pixels'].tolist()     faces = [np.fromstring(pixel_sequence, dtype=int, sep=' ').reshape(48, 48, 1) for pixel_sequence in pixels]     faces = np.array(faces).astype('float32')     faces /= 255.0     emotions = to_categorical(data['emotion'], num_classes=7)     return faces, emotions  # Separar os dados de treinamento, valida\u00e7\u00e3o e teste train_data = data[data['Usage'] == 'Training'] val_data = data[data['Usage'] == 'PublicTest'] test_data = data[data['Usage'] == 'PrivateTest']  x_train, y_train = preprocess_data(train_data) x_val, y_val = preprocess_data(val_data) x_test, y_test = preprocess_data(test_data)  # Verificar as formas dos dados print('x_train shape:', x_train.shape) print('y_train shape:', y_train.shape) print('x_val shape:', x_val.shape) print('y_val shape:', y_val.shape) print('x_test shape:', x_test.shape) print('y_test shape:', y_test.shape) <pre>x_train shape: (28709, 48, 48, 1)\ny_train shape: (28709, 7)\nx_val shape: (3589, 48, 48, 1)\ny_val shape: (3589, 7)\nx_test shape: (3589, 48, 48, 1)\ny_test shape: (3589, 7)\n</pre> In\u00a0[4]: Copied! <pre>import matplotlib.pyplot as plt\nimport numpy as np\n\n# Dicion\u00e1rio para mapear \u00edndices de emo\u00e7\u00e3o para r\u00f3tulos textuais\nlabel_to_text = {0: 'angry', 1: 'disgust', 2: 'fear', 3: 'happiness', 4: 'sad', 5: 'surprise', 6: 'neutral'}\n\n# Fun\u00e7\u00e3o para exibir algumas imagens do dataset\ndef show_sample_images(faces, emotions, num_images=10):\n    plt.figure(figsize=(15, 5))\n    for i in range(num_images):\n        ax = plt.subplot(2, num_images // 2, i + 1)\n        plt.imshow(faces[i].reshape(48, 48), cmap='gray')\n        plt.title(label_to_text[np.argmax(emotions[i])])\n        plt.axis('off')\n    plt.show()\n\n# Exibir 10 imagens de exemplo do conjunto de treinamento\nshow_sample_images(x_train, y_train, num_images=10)\n</pre> import matplotlib.pyplot as plt import numpy as np  # Dicion\u00e1rio para mapear \u00edndices de emo\u00e7\u00e3o para r\u00f3tulos textuais label_to_text = {0: 'angry', 1: 'disgust', 2: 'fear', 3: 'happiness', 4: 'sad', 5: 'surprise', 6: 'neutral'}  # Fun\u00e7\u00e3o para exibir algumas imagens do dataset def show_sample_images(faces, emotions, num_images=10):     plt.figure(figsize=(15, 5))     for i in range(num_images):         ax = plt.subplot(2, num_images // 2, i + 1)         plt.imshow(faces[i].reshape(48, 48), cmap='gray')         plt.title(label_to_text[np.argmax(emotions[i])])         plt.axis('off')     plt.show()  # Exibir 10 imagens de exemplo do conjunto de treinamento show_sample_images(x_train, y_train, num_images=10)   In\u00a0[7]: Copied! <pre>from tensorflow.keras.preprocessing.image import ImageDataGenerator\n# Criar geradores de dados\ntrain_datagen = ImageDataGenerator(\n    rotation_range=30,\n    width_shift_range=0.2,\n    height_shift_range=0.2,\n    shear_range=0.2,\n    zoom_range=0.2,\n    horizontal_flip=True,\n    fill_mode='nearest'\n)\n\nval_datagen = ImageDataGenerator()\ntest_datagen = ImageDataGenerator()\n\n# Criar geradores\ntrain_generator = train_datagen.flow(x_train, y_train, batch_size=64)\nvalidation_generator = val_datagen.flow(x_val, y_val, batch_size=64)\ntest_generator = test_datagen.flow(x_test, y_test, batch_size=64)\n</pre> from tensorflow.keras.preprocessing.image import ImageDataGenerator # Criar geradores de dados train_datagen = ImageDataGenerator(     rotation_range=30,     width_shift_range=0.2,     height_shift_range=0.2,     shear_range=0.2,     zoom_range=0.2,     horizontal_flip=True,     fill_mode='nearest' )  val_datagen = ImageDataGenerator() test_datagen = ImageDataGenerator()  # Criar geradores train_generator = train_datagen.flow(x_train, y_train, batch_size=64) validation_generator = val_datagen.flow(x_val, y_val, batch_size=64) test_generator = test_datagen.flow(x_test, y_test, batch_size=64) In\u00a0[8]: Copied! <pre>from tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n\nmodel = Sequential([\n\n    Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(48, 48, 1)),\n    Conv2D(64, kernel_size=(3, 3), activation='relu'),\n    MaxPooling2D(pool_size=(2, 2)),\n    Dropout(0.2),\n\n    Conv2D(128, kernel_size=(3, 3), activation='relu'),\n    MaxPooling2D(pool_size=(2, 2)),\n    Conv2D(128, kernel_size=(3, 3), activation='relu'),\n    MaxPooling2D(pool_size=(2, 2)),\n    Dropout(0.2),\n\n    Flatten(),\n    Dense(512, activation='relu'),\n    Dropout(0.2),\n    Dense(255, activation='relu'),\n    Dropout(0.5),\n    Dense(128, activation='relu'),\n    Dropout(0.5),\n    Dense(7, activation='softmax')\n])\n</pre> from tensorflow.keras.models import Sequential from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout  model = Sequential([      Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(48, 48, 1)),     Conv2D(64, kernel_size=(3, 3), activation='relu'),     MaxPooling2D(pool_size=(2, 2)),     Dropout(0.2),      Conv2D(128, kernel_size=(3, 3), activation='relu'),     MaxPooling2D(pool_size=(2, 2)),     Conv2D(128, kernel_size=(3, 3), activation='relu'),     MaxPooling2D(pool_size=(2, 2)),     Dropout(0.2),      Flatten(),     Dense(512, activation='relu'),     Dropout(0.2),     Dense(255, activation='relu'),     Dropout(0.5),     Dense(128, activation='relu'),     Dropout(0.5),     Dense(7, activation='softmax') ]) <pre>/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n</pre> In\u00a0[9]: Copied! <pre>model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n</pre> model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])   In\u00a0[10]: Copied! <pre>from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n\n\n# Callbacks\ncheckpoint = ModelCheckpoint('best_model.h5', monitor='val_loss', save_best_only=True, mode='min')\nearly_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\nreduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=5, min_lr=0.001)\n\n# Treinamento do modelo usando geradores\nhistory = model.fit(\n    train_generator,\n    steps_per_epoch=len(x_train) // 64,\n    epochs=500,\n    validation_data=validation_generator,\n    validation_steps=len(x_val) // 64,\n    callbacks=[checkpoint, early_stopping, reduce_lr]\n)\n</pre> from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau   # Callbacks checkpoint = ModelCheckpoint('best_model.h5', monitor='val_loss', save_best_only=True, mode='min') early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True) reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=5, min_lr=0.001)  # Treinamento do modelo usando geradores history = model.fit(     train_generator,     steps_per_epoch=len(x_train) // 64,     epochs=500,     validation_data=validation_generator,     validation_steps=len(x_val) // 64,     callbacks=[checkpoint, early_stopping, reduce_lr] ) <pre>Epoch 1/500\n</pre> <pre>/usr/local/lib/python3.11/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n  self._warn_if_super_not_called()\n</pre> <pre>447/448 \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 0s 36ms/step - accuracy: 0.2316 - loss: 1.8410</pre> <pre>WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n</pre> <pre>\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r448/448 \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 31s 48ms/step - accuracy: 0.2317 - loss: 1.8409 - val_accuracy: 0.2489 - val_loss: 1.7968 - learning_rate: 0.0010\nEpoch 2/500\n  1/448 \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 3s 7ms/step - accuracy: 0.2969 - loss: 1.7708</pre> <pre>/usr/local/lib/python3.11/dist-packages/keras/src/trainers/epoch_iterator.py:107: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n  self._interrupted_warning()\n</pre> <pre>\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r448/448 \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 0s 528us/step - accuracy: 0.2969 - loss: 1.7708 - val_accuracy: 0.2486 - val_loss: 1.7968 - learning_rate: 0.0010\nEpoch 3/500\n448/448 \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 0s 26ms/step - accuracy: 0.2533 - loss: 1.8024</pre> <pre>WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n</pre> <pre>\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r448/448 \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 12s 26ms/step - accuracy: 0.2533 - loss: 1.8024 - val_accuracy: 0.2606 - val_loss: 1.7812 - learning_rate: 0.0010\nEpoch 4/500\n448/448 \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 0s 471us/step - accuracy: 0.2812 - loss: 1.7220 - val_accuracy: 0.2592 - val_loss: 1.7813 - learning_rate: 0.0010\nEpoch 5/500\n448/448 \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 0s 26ms/step - accuracy: 0.2519 - loss: 1.7956</pre> <pre>WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n</pre> <pre>\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r448/448 \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 12s 27ms/step - accuracy: 0.2519 - loss: 1.7956 - val_accuracy: 0.2734 - val_loss: 1.7686 - learning_rate: 0.0010\nEpoch 6/500\n  1/448 \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 2s 5ms/step - accuracy: 0.2656 - loss: 1.7674</pre> <pre>WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n</pre> <pre>\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r448/448 \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 0s 700us/step - accuracy: 0.2656 - loss: 1.7674 - val_accuracy: 0.2693 - val_loss: 1.7665 - learning_rate: 0.0010\nEpoch 7/500\n448/448 \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 0s 25ms/step - accuracy: 0.2581 - loss: 1.7811</pre> <pre>WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n</pre> <pre>\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r448/448 \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 12s 26ms/step - accuracy: 0.2581 - loss: 1.7811 - val_accuracy: 0.3064 - val_loss: 1.7246 - learning_rate: 0.0010\nEpoch 8/500\n  1/448 \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 2s 5ms/step - accuracy: 0.2188 - loss: 1.7671</pre> <pre>WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n</pre> <pre>\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r448/448 \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 0s 729us/step - accuracy: 0.2188 - loss: 1.7671 - val_accuracy: 0.3058 - val_loss: 1.7240 - learning_rate: 0.0010\nEpoch 9/500\n448/448 \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 0s 26ms/step - accuracy: 0.2694 - loss: 1.7648</pre> <pre>WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n</pre> <pre>\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r448/448 \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 12s 26ms/step - accuracy: 0.2694 - loss: 1.7648 - val_accuracy: 0.3078 - val_loss: 1.6776 - learning_rate: 0.0010\nEpoch 10/500\n448/448 \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 0s 474us/step - accuracy: 0.2969 - loss: 1.7628 - val_accuracy: 0.3114 - val_loss: 1.6825 - learning_rate: 0.0010\nEpoch 11/500\n447/448 \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 0s 26ms/step - accuracy: 0.2817 - loss: 1.7338</pre> <pre>WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n</pre> <pre>\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r448/448 \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 12s 26ms/step - accuracy: 0.2817 - loss: 1.7338 - val_accuracy: 0.3404 - val_loss: 1.6429 - learning_rate: 0.0010\nEpoch 12/500\n448/448 \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 0s 542us/step - accuracy: 0.2969 - loss: 1.7480 - val_accuracy: 0.3379 - val_loss: 1.6450 - learning_rate: 0.0010\nEpoch 13/500\n446/448 \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 0s 26ms/step - accuracy: 0.2946 - loss: 1.7198</pre> <pre>WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n</pre> <pre>\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r448/448 \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 12s 27ms/step - accuracy: 0.2947 - loss: 1.7198 - val_accuracy: 0.3334 - val_loss: 1.6414 - learning_rate: 0.0010\nEpoch 14/500\n  1/448 \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 2s 5ms/step - accuracy: 0.3281 - loss: 1.7200</pre> <pre>WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n</pre> <pre>\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r448/448 \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 0s 667us/step - accuracy: 0.3281 - loss: 1.7200 - val_accuracy: 0.3438 - val_loss: 1.6309 - learning_rate: 0.0010\nEpoch 15/500\n447/448 \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 0s 25ms/step - accuracy: 0.3049 - loss: 1.6943</pre> <pre>WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n</pre> <pre>\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r448/448 \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 12s 26ms/step - accuracy: 0.3049 - loss: 1.6942 - val_accuracy: 0.3736 - val_loss: 1.5558 - learning_rate: 0.0010\nEpoch 16/500\n  1/448 \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 2s 5ms/step - accuracy: 0.2812 - loss: 1.7498</pre> <pre>WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n</pre> <pre>\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r448/448 \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 0s 715us/step - accuracy: 0.2812 - loss: 1.7498 - val_accuracy: 0.3842 - val_loss: 1.5515 - learning_rate: 0.0010\nEpoch 17/500\n448/448 \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 0s 26ms/step - accuracy: 0.3359 - loss: 1.6607</pre> <pre>WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n</pre> <pre>\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r448/448 \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 12s 26ms/step - accuracy: 0.3359 - loss: 1.6607 - val_accuracy: 0.4174 - val_loss: 1.4809 - learning_rate: 0.0010\nEpoch 18/500\n448/448 \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 0s 492us/step - accuracy: 0.3438 - loss: 1.6901 - val_accuracy: 0.4169 - val_loss: 1.4821 - learning_rate: 0.0010\nEpoch 19/500\n447/448 \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 0s 25ms/step - accuracy: 0.3635 - loss: 1.6056</pre> <pre>WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n</pre> <pre>\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r448/448 \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 12s 26ms/step - accuracy: 0.3635 - loss: 1.6056 - val_accuracy: 0.4562 - val_loss: 1.4127 - learning_rate: 0.0010\nEpoch 20/500\n  1/448 \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 2s 5ms/step - accuracy: 0.4219 - loss: 1.4722</pre> <pre>WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n</pre> <pre>\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r448/448 \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 0s 719us/step - accuracy: 0.4219 - loss: 1.4722 - val_accuracy: 0.4579 - val_loss: 1.4106 - learning_rate: 0.0010\nEpoch 21/500\n447/448 \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 0s 25ms/step - accuracy: 0.3798 - loss: 1.5749</pre> <pre>WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n</pre> <pre>\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r448/448 \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 11s 26ms/step - accuracy: 0.3798 - loss: 1.5749 - val_accuracy: 0.4754 - val_loss: 1.3532 - learning_rate: 0.0010\nEpoch 22/500\n448/448 \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 0s 501us/step - accuracy: 0.3906 - loss: 1.4922 - val_accuracy: 0.4704 - val_loss: 1.3552 - learning_rate: 0.0010\nEpoch 23/500\n447/448 \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 0s 26ms/step - accuracy: 0.4017 - loss: 1.5345</pre> <pre>WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n</pre> <pre>\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r448/448 \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 12s 26ms/step - accuracy: 0.4017 - loss: 1.5345 - val_accuracy: 0.4760 - val_loss: 1.3469 - learning_rate: 0.0010\nEpoch 24/500\n448/448 \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 0s 505us/step - accuracy: 0.4219 - loss: 1.5386 - val_accuracy: 0.4766 - val_loss: 1.3475 - learning_rate: 0.0010\nEpoch 25/500\n447/448 \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 0s 26ms/step - accuracy: 0.4209 - loss: 1.5013</pre> <pre>WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n</pre> <pre>\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r448/448 \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 12s 26ms/step - accuracy: 0.4208 - loss: 1.5013 - val_accuracy: 0.4830 - val_loss: 1.3233 - learning_rate: 0.0010\nEpoch 26/500\n  1/448 \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 2s 5ms/step - accuracy: 0.4688 - loss: 1.3883</pre> <pre>WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n</pre> <pre>\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r448/448 \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 0s 719us/step - accuracy: 0.4688 - loss: 1.3883 - val_accuracy: 0.4858 - val_loss: 1.3172 - learning_rate: 0.0010\nEpoch 27/500\n448/448 \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 0s 26ms/step - accuracy: 0.4228 - loss: 1.4874</pre> <pre>WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n</pre> <pre>\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r448/448 \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 12s 27ms/step - accuracy: 0.4228 - loss: 1.4874 - val_accuracy: 0.4967 - val_loss: 1.3062 - learning_rate: 0.0010\nEpoch 28/500\n448/448 \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 0s 488us/step - accuracy: 0.4531 - loss: 1.4086 - val_accuracy: 0.4908 - val_loss: 1.3116 - learning_rate: 0.0010\nEpoch 29/500\n448/448 \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 0s 26ms/step - accuracy: 0.4273 - loss: 1.4789</pre> <pre>WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n</pre> <pre>\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r448/448 \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 12s 27ms/step - accuracy: 0.4273 - loss: 1.4789 - val_accuracy: 0.5075 - val_loss: 1.2880 - learning_rate: 0.0010\nEpoch 30/500\n448/448 \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 0s 514us/step - accuracy: 0.2969 - loss: 1.5920 - val_accuracy: 0.5050 - val_loss: 1.2881 - learning_rate: 0.0010\nEpoch 31/500\n448/448 \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 12s 26ms/step - accuracy: 0.4367 - loss: 1.4683 - val_accuracy: 0.4947 - val_loss: 1.3114 - learning_rate: 0.0010\nEpoch 32/500\n448/448 \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 0s 499us/step - accuracy: 0.5000 - loss: 1.3740 - val_accuracy: 0.4972 - val_loss: 1.3071 - learning_rate: 0.0010\nEpoch 33/500\n447/448 \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 0s 26ms/step - accuracy: 0.4449 - loss: 1.4461</pre> <pre>WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n</pre> <pre>\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r448/448 \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 12s 26ms/step - accuracy: 0.4449 - loss: 1.4461 - val_accuracy: 0.5042 - val_loss: 1.2732 - learning_rate: 0.0010\nEpoch 34/500\n448/448 \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 0s 511us/step - accuracy: 0.5000 - loss: 1.4909 - val_accuracy: 0.5047 - val_loss: 1.2743 - learning_rate: 0.0010\nEpoch 35/500\n448/448 \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 0s 26ms/step - accuracy: 0.4414 - loss: 1.4490</pre> <pre>WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n</pre> <pre>\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r448/448 \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 12s 26ms/step - accuracy: 0.4414 - loss: 1.4490 - val_accuracy: 0.5162 - val_loss: 1.2642 - learning_rate: 0.0010\nEpoch 36/500\n  1/448 \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 2s 5ms/step - accuracy: 0.3750 - loss: 1.5260</pre> <pre>WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n</pre> <pre>\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r448/448 \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 0s 724us/step - accuracy: 0.3750 - loss: 1.5260 - val_accuracy: 0.5181 - val_loss: 1.2631 - learning_rate: 0.0010\nEpoch 37/500\n448/448 \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 0s 26ms/step - accuracy: 0.4570 - loss: 1.4247</pre> <pre>WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n</pre> <pre>\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r448/448 \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 12s 27ms/step - accuracy: 0.4570 - loss: 1.4247 - val_accuracy: 0.5134 - val_loss: 1.2589 - learning_rate: 0.0010\nEpoch 38/500\n  1/448 \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 2s 6ms/step - accuracy: 0.5312 - loss: 1.2810</pre> <pre>WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n</pre> <pre>\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r448/448 \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 0s 716us/step - accuracy: 0.5312 - loss: 1.2810 - val_accuracy: 0.5145 - val_loss: 1.2578 - learning_rate: 0.0010\nEpoch 39/500\n447/448 \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 0s 26ms/step - accuracy: 0.4542 - loss: 1.4290</pre> <pre>WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n</pre> <pre>\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r448/448 \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 12s 26ms/step - accuracy: 0.4542 - loss: 1.4290 - val_accuracy: 0.5137 - val_loss: 1.2540 - learning_rate: 0.0010\nEpoch 40/500\n  1/448 \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 2s 6ms/step - accuracy: 0.5469 - loss: 1.2792</pre> <pre>WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n</pre> <pre>\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r448/448 \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 0s 758us/step - accuracy: 0.5469 - loss: 1.2792 - val_accuracy: 0.5170 - val_loss: 1.2508 - learning_rate: 0.0010\nEpoch 41/500\n447/448 \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 0s 26ms/step - accuracy: 0.4572 - loss: 1.4035</pre> <pre>WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n</pre> <pre>\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r448/448 \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 12s 27ms/step - accuracy: 0.4572 - loss: 1.4036 - val_accuracy: 0.5220 - val_loss: 1.2319 - learning_rate: 0.0010\nEpoch 42/500\n  1/448 \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 2s 6ms/step - accuracy: 0.3906 - loss: 1.5330</pre> <pre>WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n</pre> <pre>\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r448/448 \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 0s 730us/step - accuracy: 0.3906 - loss: 1.5330 - val_accuracy: 0.5257 - val_loss: 1.2291 - learning_rate: 0.0010\nEpoch 43/500\n448/448 \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 12s 26ms/step - accuracy: 0.4603 - loss: 1.4033 - val_accuracy: 0.5193 - val_loss: 1.2364 - learning_rate: 0.0010\nEpoch 44/500\n448/448 \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 0s 530us/step - accuracy: 0.3281 - loss: 1.4966 - val_accuracy: 0.5193 - val_loss: 1.2332 - learning_rate: 0.0010\nEpoch 45/500\n448/448 \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 0s 26ms/step - accuracy: 0.4624 - loss: 1.4050</pre> <pre>WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n</pre> <pre>\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r448/448 \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 12s 27ms/step - accuracy: 0.4624 - loss: 1.4050 - val_accuracy: 0.5187 - val_loss: 1.2288 - learning_rate: 0.0010\nEpoch 46/500\n448/448 \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 0s 511us/step - accuracy: 0.5781 - loss: 1.2230 - val_accuracy: 0.5195 - val_loss: 1.2291 - learning_rate: 0.0010\nEpoch 47/500\n447/448 \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 0s 26ms/step - accuracy: 0.4648 - loss: 1.3957</pre> <pre>WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n</pre> <pre>\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r448/448 \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 12s 27ms/step - accuracy: 0.4648 - loss: 1.3957 - val_accuracy: 0.5312 - val_loss: 1.2280 - learning_rate: 0.0010\nEpoch 48/500\n448/448 \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 0s 492us/step - accuracy: 0.4062 - loss: 1.5087 - val_accuracy: 0.5290 - val_loss: 1.2296 - learning_rate: 0.0010\nEpoch 49/500\n447/448 \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 0s 26ms/step - accuracy: 0.4677 - loss: 1.3843</pre> <pre>WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n</pre> <pre>\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r448/448 \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 12s 26ms/step - accuracy: 0.4677 - loss: 1.3843 - val_accuracy: 0.5360 - val_loss: 1.1992 - learning_rate: 0.0010\nEpoch 50/500\n  1/448 \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 2s 5ms/step - accuracy: 0.5156 - loss: 1.2925</pre> <pre>WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n</pre> <pre>\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r448/448 \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 0s 729us/step - accuracy: 0.5156 - loss: 1.2925 - val_accuracy: 0.5360 - val_loss: 1.1984 - learning_rate: 0.0010\nEpoch 51/500\n447/448 \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 0s 26ms/step - accuracy: 0.4709 - loss: 1.3880</pre> <pre>WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n</pre> <pre>\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r448/448 \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 12s 27ms/step - accuracy: 0.4709 - loss: 1.3880 - val_accuracy: 0.5449 - val_loss: 1.1979 - learning_rate: 0.0010\nEpoch 52/500\n448/448 \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 0s 501us/step - accuracy: 0.4844 - loss: 1.7526 - val_accuracy: 0.5463 - val_loss: 1.1981 - learning_rate: 0.0010\nEpoch 53/500\n448/448 \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 12s 26ms/step - accuracy: 0.4784 - loss: 1.3806 - val_accuracy: 0.5382 - val_loss: 1.1983 - learning_rate: 0.0010\nEpoch 54/500\n448/448 \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 0s 478us/step - accuracy: 0.5312 - loss: 1.3241 - val_accuracy: 0.5377 - val_loss: 1.2000 - learning_rate: 0.0010\nEpoch 55/500\n448/448 \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 12s 26ms/step - accuracy: 0.4721 - loss: 1.3732 - val_accuracy: 0.5315 - val_loss: 1.2094 - learning_rate: 0.0010\nEpoch 56/500\n448/448 \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 0s 498us/step - accuracy: 0.4375 - loss: 1.3556 - val_accuracy: 0.5301 - val_loss: 1.2099 - learning_rate: 0.0010\nEpoch 57/500\n447/448 \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 0s 26ms/step - accuracy: 0.4763 - loss: 1.3681</pre> <pre>WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n</pre> <pre>\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r448/448 \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 12s 26ms/step - accuracy: 0.4763 - loss: 1.3681 - val_accuracy: 0.5405 - val_loss: 1.1971 - learning_rate: 0.0010\nEpoch 58/500\n448/448 \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 0s 517us/step - accuracy: 0.4375 - loss: 1.5089 - val_accuracy: 0.5405 - val_loss: 1.2037 - learning_rate: 0.0010\nEpoch 59/500\n448/448 \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 12s 26ms/step - accuracy: 0.4783 - loss: 1.3689 - val_accuracy: 0.5382 - val_loss: 1.2070 - learning_rate: 0.0010\nEpoch 60/500\n448/448 \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 0s 519us/step - accuracy: 0.3906 - loss: 1.5061 - val_accuracy: 0.5371 - val_loss: 1.2083 - learning_rate: 0.0010\nEpoch 61/500\n448/448 \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 0s 26ms/step - accuracy: 0.4899 - loss: 1.3485</pre> <pre>WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n</pre> <pre>\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r448/448 \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 12s 26ms/step - accuracy: 0.4899 - loss: 1.3485 - val_accuracy: 0.5444 - val_loss: 1.1810 - learning_rate: 0.0010\nEpoch 62/500\n  1/448 \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 2s 5ms/step - accuracy: 0.4844 - loss: 1.3667</pre> <pre>WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n</pre> <pre>\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r448/448 \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 0s 715us/step - accuracy: 0.4844 - loss: 1.3667 - val_accuracy: 0.5463 - val_loss: 1.1809 - learning_rate: 0.0010\nEpoch 63/500\n448/448 \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 12s 26ms/step - accuracy: 0.4854 - loss: 1.3486 - val_accuracy: 0.5366 - val_loss: 1.1987 - learning_rate: 0.0010\nEpoch 64/500\n448/448 \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 0s 500us/step - accuracy: 0.3906 - loss: 1.4372 - val_accuracy: 0.5366 - val_loss: 1.1986 - learning_rate: 0.0010\nEpoch 65/500\n448/448 \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 12s 26ms/step - accuracy: 0.4824 - loss: 1.3554 - val_accuracy: 0.5416 - val_loss: 1.2121 - learning_rate: 0.0010\nEpoch 66/500\n448/448 \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 0s 507us/step - accuracy: 0.5938 - loss: 1.3561 - val_accuracy: 0.5416 - val_loss: 1.2089 - learning_rate: 0.0010\nEpoch 67/500\n448/448 \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 0s 26ms/step - accuracy: 0.4826 - loss: 1.3587</pre> <pre>WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n</pre> <pre>\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r448/448 \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 12s 27ms/step - accuracy: 0.4826 - loss: 1.3586 - val_accuracy: 0.5480 - val_loss: 1.1722 - learning_rate: 0.0010\nEpoch 68/500\n448/448 \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 0s 513us/step - accuracy: 0.4375 - loss: 1.3768 - val_accuracy: 0.5446 - val_loss: 1.1758 - learning_rate: 0.0010\nEpoch 69/500\n448/448 \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 12s 27ms/step - accuracy: 0.4894 - loss: 1.3464 - val_accuracy: 0.5458 - val_loss: 1.1875 - learning_rate: 0.0010\nEpoch 70/500\n448/448 \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 0s 496us/step - accuracy: 0.5156 - loss: 1.4458 - val_accuracy: 0.5485 - val_loss: 1.1861 - learning_rate: 0.0010\nEpoch 71/500\n448/448 \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 12s 26ms/step - accuracy: 0.4850 - loss: 1.3472 - val_accuracy: 0.5522 - val_loss: 1.1787 - learning_rate: 0.0010\nEpoch 72/500\n448/448 \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 0s 482us/step - accuracy: 0.5312 - loss: 1.2559 - val_accuracy: 0.5539 - val_loss: 1.1793 - learning_rate: 0.0010\nEpoch 73/500\n447/448 \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 0s 25ms/step - accuracy: 0.4888 - loss: 1.3482</pre> <pre>WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n</pre> <pre>\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r448/448 \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 12s 26ms/step - accuracy: 0.4888 - loss: 1.3481 - val_accuracy: 0.5527 - val_loss: 1.1647 - learning_rate: 0.0010\nEpoch 74/500\n  1/448 \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 2s 5ms/step - accuracy: 0.5312 - loss: 1.3610</pre> <pre>WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n</pre> <pre>\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r448/448 \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 0s 683us/step - accuracy: 0.5312 - loss: 1.3610 - val_accuracy: 0.5544 - val_loss: 1.1634 - learning_rate: 0.0010\nEpoch 75/500\n448/448 \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 0s 26ms/step - accuracy: 0.4935 - loss: 1.3302</pre> <pre>WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n</pre> <pre>\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r448/448 \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 12s 26ms/step - accuracy: 0.4935 - loss: 1.3301 - val_accuracy: 0.5578 - val_loss: 1.1531 - learning_rate: 0.0010\nEpoch 76/500\n448/448 \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 0s 494us/step - accuracy: 0.5625 - loss: 1.2465 - val_accuracy: 0.5580 - val_loss: 1.1550 - learning_rate: 0.0010\nEpoch 77/500\n448/448 \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 0s 26ms/step - accuracy: 0.4902 - loss: 1.3386</pre> <pre>WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n</pre> <pre>\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r448/448 \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 12s 26ms/step - accuracy: 0.4902 - loss: 1.3386 - val_accuracy: 0.5647 - val_loss: 1.1510 - learning_rate: 0.0010\nEpoch 78/500\n448/448 \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 0s 530us/step - accuracy: 0.5312 - loss: 1.2438 - val_accuracy: 0.5647 - val_loss: 1.1551 - learning_rate: 0.0010\nEpoch 79/500\n448/448 \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 12s 27ms/step - accuracy: 0.4989 - loss: 1.3207 - val_accuracy: 0.5611 - val_loss: 1.1557 - learning_rate: 0.0010\nEpoch 80/500\n448/448 \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 0s 494us/step - accuracy: 0.5312 - loss: 1.3652 - val_accuracy: 0.5608 - val_loss: 1.1568 - learning_rate: 0.0010\nEpoch 81/500\n448/448 \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 12s 27ms/step - accuracy: 0.4939 - loss: 1.3305 - val_accuracy: 0.5572 - val_loss: 1.1630 - learning_rate: 0.0010\nEpoch 82/500\n448/448 \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 0s 556us/step - accuracy: 0.4531 - loss: 1.4783 - val_accuracy: 0.5552 - val_loss: 1.1636 - learning_rate: 0.0010\nEpoch 83/500\n448/448 \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 12s 26ms/step - accuracy: 0.4932 - loss: 1.3353 - val_accuracy: 0.5572 - val_loss: 1.1605 - learning_rate: 0.0010\nEpoch 84/500\n448/448 \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 0s 539us/step - accuracy: 0.4844 - loss: 1.3984 - val_accuracy: 0.5580 - val_loss: 1.1586 - learning_rate: 0.0010\nEpoch 85/500\n448/448 \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 0s 26ms/step - accuracy: 0.5051 - loss: 1.3185</pre> <pre>WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n</pre> <pre>\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r448/448 \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 12s 26ms/step - accuracy: 0.5050 - loss: 1.3185 - val_accuracy: 0.5653 - val_loss: 1.1437 - learning_rate: 0.0010\nEpoch 86/500\n  1/448 \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 2s 5ms/step - accuracy: 0.5938 - loss: 1.2073</pre> <pre>WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n</pre> <pre>\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r448/448 \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 0s 696us/step - accuracy: 0.5938 - loss: 1.2073 - val_accuracy: 0.5636 - val_loss: 1.1437 - learning_rate: 0.0010\nEpoch 87/500\n448/448 \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 12s 27ms/step - accuracy: 0.4969 - loss: 1.3222 - val_accuracy: 0.5664 - val_loss: 1.1506 - learning_rate: 0.0010\nEpoch 88/500\n448/448 \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 0s 501us/step - accuracy: 0.5000 - loss: 1.4272 - val_accuracy: 0.5695 - val_loss: 1.1510 - learning_rate: 0.0010\nEpoch 89/500\n448/448 \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 12s 26ms/step - accuracy: 0.4974 - loss: 1.3223 - val_accuracy: 0.5597 - val_loss: 1.1438 - learning_rate: 0.0010\nEpoch 90/500\n  1/448 \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 2s 5ms/step - accuracy: 0.5938 - loss: 1.0789</pre> <pre>WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n</pre> <pre>\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r448/448 \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 0s 672us/step - accuracy: 0.5938 - loss: 1.0789 - val_accuracy: 0.5569 - val_loss: 1.1417 - learning_rate: 0.0010\nEpoch 91/500\n448/448 \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 12s 26ms/step - accuracy: 0.4996 - loss: 1.3272 - val_accuracy: 0.5575 - val_loss: 1.1460 - learning_rate: 0.0010\nEpoch 92/500\n448/448 \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 0s 507us/step - accuracy: 0.4062 - loss: 1.3718 - val_accuracy: 0.5594 - val_loss: 1.1474 - learning_rate: 0.0010\nEpoch 93/500\n448/448 \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 12s 26ms/step - accuracy: 0.4977 - loss: 1.3195 - val_accuracy: 0.5681 - val_loss: 1.1482 - learning_rate: 0.0010\nEpoch 94/500\n448/448 \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 0s 489us/step - accuracy: 0.4375 - loss: 1.4178 - val_accuracy: 0.5686 - val_loss: 1.1498 - learning_rate: 0.0010\nEpoch 95/500\n448/448 \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 12s 27ms/step - accuracy: 0.5098 - loss: 1.3130 - val_accuracy: 0.5639 - val_loss: 1.1609 - learning_rate: 0.0010\nEpoch 96/500\n448/448 \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 0s 483us/step - accuracy: 0.4844 - loss: 1.2244 - val_accuracy: 0.5619 - val_loss: 1.1648 - learning_rate: 0.0010\nEpoch 97/500\n447/448 \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 0s 26ms/step - accuracy: 0.5083 - loss: 1.3042</pre> <pre>WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n</pre> <pre>\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r448/448 \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 12s 27ms/step - accuracy: 0.5083 - loss: 1.3042 - val_accuracy: 0.5670 - val_loss: 1.1373 - learning_rate: 0.0010\nEpoch 98/500\n448/448 \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 0s 542us/step - accuracy: 0.5676 - loss: 1.3522 - val_accuracy: 0.5647 - val_loss: 1.1381 - learning_rate: 0.0010\nEpoch 99/500\n447/448 \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 0s 26ms/step - accuracy: 0.5038 - loss: 1.3107</pre> <pre>WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n</pre> <pre>\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r448/448 \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 12s 26ms/step - accuracy: 0.5038 - loss: 1.3107 - val_accuracy: 0.5778 - val_loss: 1.1338 - learning_rate: 0.0010\nEpoch 100/500\n448/448 \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 0s 473us/step - accuracy: 0.4688 - loss: 1.4680 - val_accuracy: 0.5801 - val_loss: 1.1360 - learning_rate: 0.0010\nEpoch 101/500\n448/448 \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 12s 26ms/step - accuracy: 0.5066 - loss: 1.3098 - val_accuracy: 0.5614 - val_loss: 1.1417 - learning_rate: 0.0010\nEpoch 102/500\n448/448 \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 0s 476us/step - accuracy: 0.4844 - loss: 1.2748 - val_accuracy: 0.5628 - val_loss: 1.1407 - learning_rate: 0.0010\nEpoch 103/500\n448/448 \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 12s 26ms/step - accuracy: 0.5089 - loss: 1.3076 - val_accuracy: 0.5558 - val_loss: 1.1589 - learning_rate: 0.0010\nEpoch 104/500\n448/448 \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 0s 559us/step - accuracy: 0.4688 - loss: 1.3199 - val_accuracy: 0.5533 - val_loss: 1.1583 - learning_rate: 0.0010\nEpoch 105/500\n448/448 \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 12s 26ms/step - accuracy: 0.5076 - loss: 1.3008 - val_accuracy: 0.5631 - val_loss: 1.1553 - learning_rate: 0.0010\nEpoch 106/500\n448/448 \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 0s 518us/step - accuracy: 0.5000 - loss: 1.5081 - val_accuracy: 0.5617 - val_loss: 1.1599 - learning_rate: 0.0010\nEpoch 107/500\n447/448 \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 0s 26ms/step - accuracy: 0.5096 - loss: 1.3022</pre> <pre>WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n</pre> <pre>\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r448/448 \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 12s 26ms/step - accuracy: 0.5096 - loss: 1.3022 - val_accuracy: 0.5723 - val_loss: 1.1293 - learning_rate: 0.0010\nEpoch 108/500\n  1/448 \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 2s 5ms/step - accuracy: 0.4531 - loss: 1.2126</pre> <pre>WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n</pre> <pre>\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r448/448 \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 0s 690us/step - accuracy: 0.4531 - loss: 1.2126 - val_accuracy: 0.5700 - val_loss: 1.1291 - learning_rate: 0.0010\nEpoch 109/500\n448/448 \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 0s 26ms/step - accuracy: 0.5091 - loss: 1.2975</pre> <pre>WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n</pre> <pre>\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r448/448 \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 12s 27ms/step - accuracy: 0.5091 - loss: 1.2975 - val_accuracy: 0.5642 - val_loss: 1.1267 - learning_rate: 0.0010\nEpoch 110/500\n448/448 \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 0s 469us/step - accuracy: 0.4219 - loss: 1.4107 - val_accuracy: 0.5614 - val_loss: 1.1277 - learning_rate: 0.0010\nEpoch 111/500\n448/448 \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 12s 26ms/step - accuracy: 0.5069 - loss: 1.3058 - val_accuracy: 0.5678 - val_loss: 1.1361 - learning_rate: 0.0010\nEpoch 112/500\n448/448 \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 0s 476us/step - accuracy: 0.6250 - loss: 1.0984 - val_accuracy: 0.5672 - val_loss: 1.1361 - learning_rate: 0.0010\nEpoch 113/500\n448/448 \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 0s 26ms/step - accuracy: 0.5134 - loss: 1.2914</pre> <pre>WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n</pre> <pre>\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r448/448 \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 12s 26ms/step - accuracy: 0.5134 - loss: 1.2914 - val_accuracy: 0.5670 - val_loss: 1.1131 - learning_rate: 0.0010\nEpoch 114/500\n448/448 \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 0s 545us/step - accuracy: 0.3594 - loss: 1.4330 - val_accuracy: 0.5658 - val_loss: 1.1151 - learning_rate: 0.0010\nEpoch 115/500\n448/448 \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 12s 27ms/step - accuracy: 0.5129 - loss: 1.2867 - val_accuracy: 0.5742 - val_loss: 1.1205 - learning_rate: 0.0010\nEpoch 116/500\n448/448 \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 0s 516us/step - accuracy: 0.4375 - loss: 1.3622 - val_accuracy: 0.5717 - val_loss: 1.1190 - learning_rate: 0.0010\nEpoch 117/500\n448/448 \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 12s 26ms/step - accuracy: 0.5125 - loss: 1.2864 - val_accuracy: 0.5711 - val_loss: 1.1141 - learning_rate: 0.0010\nEpoch 118/500\n  1/448 \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 2s 6ms/step - accuracy: 0.3594 - loss: 1.6869</pre> <pre>WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n</pre> <pre>\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r448/448 \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 0s 698us/step - accuracy: 0.3594 - loss: 1.6869 - val_accuracy: 0.5714 - val_loss: 1.1121 - learning_rate: 0.0010\nEpoch 119/500\n448/448 \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 12s 26ms/step - accuracy: 0.5133 - loss: 1.2935 - val_accuracy: 0.5706 - val_loss: 1.1265 - learning_rate: 0.0010\nEpoch 120/500\n448/448 \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 0s 535us/step - accuracy: 0.5312 - loss: 1.3436 - val_accuracy: 0.5720 - val_loss: 1.1277 - learning_rate: 0.0010\nEpoch 121/500\n448/448 \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 12s 26ms/step - accuracy: 0.5169 - loss: 1.2861 - val_accuracy: 0.5714 - val_loss: 1.1316 - learning_rate: 0.0010\nEpoch 122/500\n448/448 \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 0s 519us/step - accuracy: 0.4844 - loss: 1.3687 - val_accuracy: 0.5695 - val_loss: 1.1366 - learning_rate: 0.0010\nEpoch 123/500\n448/448 \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 12s 26ms/step - accuracy: 0.5206 - loss: 1.2850 - val_accuracy: 0.5583 - val_loss: 1.1430 - learning_rate: 0.0010\nEpoch 124/500\n448/448 \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 0s 478us/step - accuracy: 0.3906 - loss: 1.6088 - val_accuracy: 0.5575 - val_loss: 1.1425 - learning_rate: 0.0010\nEpoch 125/500\n448/448 \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 0s 26ms/step - accuracy: 0.5128 - loss: 1.2846</pre> <pre>WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n</pre> <pre>\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r448/448 \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 12s 26ms/step - accuracy: 0.5128 - loss: 1.2846 - val_accuracy: 0.5698 - val_loss: 1.1109 - learning_rate: 0.0010\nEpoch 126/500\n448/448 \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 0s 520us/step - accuracy: 0.5625 - loss: 1.2036 - val_accuracy: 0.5695 - val_loss: 1.1115 - learning_rate: 0.0010\nEpoch 127/500\n448/448 \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 12s 26ms/step - accuracy: 0.5143 - loss: 1.2927 - val_accuracy: 0.5717 - val_loss: 1.1179 - learning_rate: 0.0010\nEpoch 128/500\n448/448 \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 0s 541us/step - accuracy: 0.5781 - loss: 1.2078 - val_accuracy: 0.5695 - val_loss: 1.1210 - learning_rate: 0.0010\nEpoch 129/500\n448/448 \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 12s 27ms/step - accuracy: 0.5182 - loss: 1.2823 - val_accuracy: 0.5723 - val_loss: 1.1224 - learning_rate: 0.0010\nEpoch 130/500\n448/448 \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 0s 479us/step - accuracy: 0.4531 - loss: 1.3808 - val_accuracy: 0.5720 - val_loss: 1.1216 - learning_rate: 0.0010\nEpoch 131/500\n447/448 \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 0s 26ms/step - accuracy: 0.5168 - loss: 1.2837</pre> <pre>WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n</pre> <pre>\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r448/448 \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 12s 27ms/step - accuracy: 0.5169 - loss: 1.2837 - val_accuracy: 0.5795 - val_loss: 1.1088 - learning_rate: 0.0010\nEpoch 132/500\n448/448 \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 0s 519us/step - accuracy: 0.4062 - loss: 1.4958 - val_accuracy: 0.5767 - val_loss: 1.1112 - learning_rate: 0.0010\nEpoch 133/500\n448/448 \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 12s 27ms/step - accuracy: 0.5172 - loss: 1.2839 - val_accuracy: 0.5709 - val_loss: 1.1382 - learning_rate: 0.0010\nEpoch 134/500\n448/448 \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 0s 593us/step - accuracy: 0.5312 - loss: 1.3565 - val_accuracy: 0.5653 - val_loss: 1.1435 - learning_rate: 0.0010\nEpoch 135/500\n448/448 \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 12s 26ms/step - accuracy: 0.5192 - loss: 1.2753 - val_accuracy: 0.5714 - val_loss: 1.1158 - learning_rate: 0.0010\nEpoch 136/500\n448/448 \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 0s 463us/step - accuracy: 0.5156 - loss: 1.2716 - val_accuracy: 0.5714 - val_loss: 1.1166 - learning_rate: 0.0010\nEpoch 137/500\n448/448 \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 0s 26ms/step - accuracy: 0.5239 - loss: 1.2672</pre> <pre>WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n</pre> <pre>\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r448/448 \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 12s 27ms/step - accuracy: 0.5239 - loss: 1.2672 - val_accuracy: 0.5770 - val_loss: 1.1055 - learning_rate: 0.0010\nEpoch 138/500\n448/448 \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 0s 523us/step - accuracy: 0.5625 - loss: 1.2348 - val_accuracy: 0.5778 - val_loss: 1.1058 - learning_rate: 0.0010\nEpoch 139/500\n448/448 \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 12s 26ms/step - accuracy: 0.5188 - loss: 1.2736 - val_accuracy: 0.5561 - val_loss: 1.1608 - learning_rate: 0.0010\nEpoch 140/500\n448/448 \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 0s 497us/step - accuracy: 0.5000 - loss: 1.1921 - val_accuracy: 0.5550 - val_loss: 1.1614 - learning_rate: 0.0010\nEpoch 141/500\n448/448 \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 12s 26ms/step - accuracy: 0.5257 - loss: 1.2709 - val_accuracy: 0.5737 - val_loss: 1.1286 - learning_rate: 0.0010\nEpoch 142/500\n448/448 \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 0s 488us/step - accuracy: 0.5469 - loss: 1.2749 - val_accuracy: 0.5748 - val_loss: 1.1291 - learning_rate: 0.0010\nEpoch 143/500\n448/448 \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 12s 26ms/step - accuracy: 0.5212 - loss: 1.2734 - val_accuracy: 0.5792 - val_loss: 1.1056 - learning_rate: 0.0010\nEpoch 144/500\n  1/448 \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 2s 5ms/step - accuracy: 0.5312 - loss: 1.2941</pre> <pre>WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n</pre> <pre>\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r448/448 \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 0s 683us/step - accuracy: 0.5312 - loss: 1.2941 - val_accuracy: 0.5787 - val_loss: 1.1048 - learning_rate: 0.0010\nEpoch 145/500\n448/448 \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 12s 26ms/step - accuracy: 0.5225 - loss: 1.2763 - val_accuracy: 0.5742 - val_loss: 1.1179 - learning_rate: 0.0010\nEpoch 146/500\n448/448 \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 0s 525us/step - accuracy: 0.5469 - loss: 1.2302 - val_accuracy: 0.5725 - val_loss: 1.1173 - learning_rate: 0.0010\nEpoch 147/500\n448/448 \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 12s 26ms/step - accuracy: 0.5181 - loss: 1.2888 - val_accuracy: 0.5689 - val_loss: 1.1259 - learning_rate: 0.0010\nEpoch 148/500\n448/448 \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 0s 498us/step - accuracy: 0.5781 - loss: 1.2177 - val_accuracy: 0.5698 - val_loss: 1.1240 - learning_rate: 0.0010\nEpoch 149/500\n448/448 \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 12s 26ms/step - accuracy: 0.5199 - loss: 1.2727 - val_accuracy: 0.5751 - val_loss: 1.1111 - learning_rate: 0.0010\nEpoch 150/500\n448/448 \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 0s 506us/step - accuracy: 0.5000 - loss: 1.4143 - val_accuracy: 0.5770 - val_loss: 1.1145 - learning_rate: 0.0010\nEpoch 151/500\n448/448 \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 12s 26ms/step - accuracy: 0.5225 - loss: 1.2670 - val_accuracy: 0.5804 - val_loss: 1.1062 - learning_rate: 0.0010\nEpoch 152/500\n  1/448 \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 2s 6ms/step - accuracy: 0.5625 - loss: 1.2851</pre> <pre>WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n</pre> <pre>\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r448/448 \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 0s 732us/step - accuracy: 0.5625 - loss: 1.2851 - val_accuracy: 0.5809 - val_loss: 1.1037 - learning_rate: 0.0010\nEpoch 153/500\n448/448 \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 12s 26ms/step - accuracy: 0.5284 - loss: 1.2679 - val_accuracy: 0.5776 - val_loss: 1.1213 - learning_rate: 0.0010\nEpoch 154/500\n448/448 \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 0s 514us/step - accuracy: 0.4688 - loss: 1.4563 - val_accuracy: 0.5739 - val_loss: 1.1200 - learning_rate: 0.0010\nEpoch 155/500\n448/448 \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 12s 27ms/step - accuracy: 0.5220 - loss: 1.2736 - val_accuracy: 0.5834 - val_loss: 1.1220 - learning_rate: 0.0010\nEpoch 156/500\n448/448 \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 0s 510us/step - accuracy: 0.4688 - loss: 1.4023 - val_accuracy: 0.5812 - val_loss: 1.1211 - learning_rate: 0.0010\nEpoch 157/500\n448/448 \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 12s 26ms/step - accuracy: 0.5227 - loss: 1.2715 - val_accuracy: 0.5753 - val_loss: 1.1301 - learning_rate: 0.0010\nEpoch 158/500\n448/448 \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 0s 490us/step - accuracy: 0.5625 - loss: 1.1950 - val_accuracy: 0.5751 - val_loss: 1.1306 - learning_rate: 0.0010\nEpoch 159/500\n448/448 \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 12s 26ms/step - accuracy: 0.5221 - loss: 1.2686 - val_accuracy: 0.5706 - val_loss: 1.1233 - learning_rate: 0.0010\nEpoch 160/500\n448/448 \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 0s 535us/step - accuracy: 0.4844 - loss: 1.3019 - val_accuracy: 0.5709 - val_loss: 1.1236 - learning_rate: 0.0010\nEpoch 161/500\n448/448 \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 12s 26ms/step - accuracy: 0.5285 - loss: 1.2636 - val_accuracy: 0.5756 - val_loss: 1.1286 - learning_rate: 0.0010\nEpoch 162/500\n448/448 \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 0s 498us/step - accuracy: 0.5156 - loss: 1.2959 - val_accuracy: 0.5751 - val_loss: 1.1263 - learning_rate: 0.0010\n</pre> In\u00a0[11]: Copied! <pre># prompt: plote as curvas de loss e acuracia de treinameto do modelo\n\nimport matplotlib.pyplot as plt\n# Plot the training and validation loss\nplt.plot(history.history['loss'], label='Training Loss')\nplt.plot(history.history['val_loss'], label='Validation Loss')\nplt.title('Model Loss')\nplt.ylabel('Loss')\nplt.xlabel('Epoch')\nplt.legend()\nplt.show()\n\n# Plot the training and validation accuracy\nplt.plot(history.history['accuracy'], label='Training Accuracy')\nplt.plot(history.history['val_accuracy'], label='Validation Accuracy')\nplt.title('Model Accuracy')\nplt.ylabel('Accuracy')\nplt.xlabel('Epoch')\nplt.legend()\nplt.show()\n</pre> # prompt: plote as curvas de loss e acuracia de treinameto do modelo  import matplotlib.pyplot as plt # Plot the training and validation loss plt.plot(history.history['loss'], label='Training Loss') plt.plot(history.history['val_loss'], label='Validation Loss') plt.title('Model Loss') plt.ylabel('Loss') plt.xlabel('Epoch') plt.legend() plt.show()  # Plot the training and validation accuracy plt.plot(history.history['accuracy'], label='Training Accuracy') plt.plot(history.history['val_accuracy'], label='Validation Accuracy') plt.title('Model Accuracy') plt.ylabel('Accuracy') plt.xlabel('Epoch') plt.legend() plt.show()  In\u00a0[12]: Copied! <pre>from sklearn.metrics import confusion_matrix, classification_report\nimport seaborn as sns\n\n\n# Avalia\u00e7\u00e3o do modelo usando geradores\ntest_loss, test_acc = model.evaluate(x_test,y_test, steps=len(x_test) // 64)\nprint('Test accuracy:', test_acc)\n\n# Previs\u00f5es\ny_pred = model.predict(x_test, steps=len(x_test) // 64)\ny_pred_classes = np.argmax(y_pred, axis=1)\ny_true = np.argmax(y_test, axis=1)\n\n# Calcular a matriz de confus\u00e3o\nconf_matrix = confusion_matrix(y_true, y_pred_classes)\n\n# Fun\u00e7\u00e3o para plotar a matriz de confus\u00e3o\ndef plot_confusion_matrix(cm, classes, title='Confusion Matrix', cmap=plt.cm.Blues):\n    plt.figure(figsize=(10, 8))\n    sns.heatmap(cm, annot=True, fmt='d', cmap=cmap, xticklabels=classes, yticklabels=classes)\n    plt.title(title)\n    plt.ylabel('True Label')\n    plt.xlabel('Predicted Label')\n    plt.show()\n\n# Plotar a matriz de confus\u00e3o\nplot_confusion_matrix(conf_matrix, classes=[label_to_text[i] for i in range(7)])\n</pre> from sklearn.metrics import confusion_matrix, classification_report import seaborn as sns   # Avalia\u00e7\u00e3o do modelo usando geradores test_loss, test_acc = model.evaluate(x_test,y_test, steps=len(x_test) // 64) print('Test accuracy:', test_acc)  # Previs\u00f5es y_pred = model.predict(x_test, steps=len(x_test) // 64) y_pred_classes = np.argmax(y_pred, axis=1) y_true = np.argmax(y_test, axis=1)  # Calcular a matriz de confus\u00e3o conf_matrix = confusion_matrix(y_true, y_pred_classes)  # Fun\u00e7\u00e3o para plotar a matriz de confus\u00e3o def plot_confusion_matrix(cm, classes, title='Confusion Matrix', cmap=plt.cm.Blues):     plt.figure(figsize=(10, 8))     sns.heatmap(cm, annot=True, fmt='d', cmap=cmap, xticklabels=classes, yticklabels=classes)     plt.title(title)     plt.ylabel('True Label')     plt.xlabel('Predicted Label')     plt.show()  # Plotar a matriz de confus\u00e3o plot_confusion_matrix(conf_matrix, classes=[label_to_text[i] for i in range(7)])  <pre>56/56 \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 10s 66ms/step - accuracy: 0.5816 - loss: 1.0889\nTest accuracy: 0.591251015663147\n56/56 \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 2s 22ms/step\n</pre> In\u00a0[13]: Copied! <pre># Exibir 10 imagens de exemplo do conjunto de teste\nshow_sample_images(x_test, y_pred, num_images=10)\n</pre> # Exibir 10 imagens de exemplo do conjunto de teste show_sample_images(x_test, y_pred, num_images=10)"},{"location":"aulas/IA/lab09/transferlearning.html","title":"Transferlearning","text":"In\u00a0[\u00a0]: Copied! <pre>import numpy as np\nfrom tensorflow.keras.preprocessing import image\n\n\n## importa o modelo da VGG16 pr\u00e9-treinado\nfrom tensorflow.keras.applications.vgg16 import VGG16, preprocess_input, decode_predictions\n</pre> import numpy as np from tensorflow.keras.preprocessing import image   ## importa o modelo da VGG16 pr\u00e9-treinado from tensorflow.keras.applications.vgg16 import VGG16, preprocess_input, decode_predictions   In\u00a0[\u00a0]: Copied! <pre># Carrega o modelo VGG16 pr\u00e9-treinado com ImageNet:\nmodel = VGG16()\n</pre> # Carrega o modelo VGG16 pr\u00e9-treinado com ImageNet: model = VGG16()  <pre>Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels.h5\n553467096/553467096 [==============================] - 24s 0us/step\n</pre> In\u00a0[\u00a0]: Copied! <pre># Carrega uma imagem e prepara para ser predita pela VGG16\n\n## teste 1\n!wget https://images.tcdn.com.br/img/img_prod/777105/bicicleta_29_hope_21_velocidades_shimano_freios_disco_tamanho_17_12475_1_ac0b7c63eee851b87bcc9832033c9826.jpg -O /content/bike.jpg\nimg_path = 'bike.jpg'\n\n# teste 2\n#!wget https://liberal.com.br/wp-content/uploads/2019/11/buraco-rua-dos-anturios.jpg -O /content/buraco.jpg\n#img_path = 'buraco.jpg'\n\n\n# teste 3\n#img_path = 'COLOQUE_UMA_IMAGEM.jpg'\n\n\nimg = image.load_img(img_path, target_size=(224, 224))\nx = image.img_to_array(img)\nx = np.expand_dims(x, axis=0)\nx = preprocess_input(x)\nprint(\"A imagem \u00e9 carregada e transformada de {}, para {}\".format(img.size,x.shape))\n</pre> # Carrega uma imagem e prepara para ser predita pela VGG16  ## teste 1 !wget https://images.tcdn.com.br/img/img_prod/777105/bicicleta_29_hope_21_velocidades_shimano_freios_disco_tamanho_17_12475_1_ac0b7c63eee851b87bcc9832033c9826.jpg -O /content/bike.jpg img_path = 'bike.jpg'  # teste 2 #!wget https://liberal.com.br/wp-content/uploads/2019/11/buraco-rua-dos-anturios.jpg -O /content/buraco.jpg #img_path = 'buraco.jpg'   # teste 3 #img_path = 'COLOQUE_UMA_IMAGEM.jpg'   img = image.load_img(img_path, target_size=(224, 224)) x = image.img_to_array(img) x = np.expand_dims(x, axis=0) x = preprocess_input(x) print(\"A imagem \u00e9 carregada e transformada de {}, para {}\".format(img.size,x.shape)) <pre>--2023-05-02 11:35:17--  https://images.tcdn.com.br/img/img_prod/777105/bicicleta_29_hope_21_velocidades_shimano_freios_disco_tamanho_17_12475_1_ac0b7c63eee851b87bcc9832033c9826.jpg\nResolving images.tcdn.com.br (images.tcdn.com.br)... 152.199.40.152\nConnecting to images.tcdn.com.br (images.tcdn.com.br)|152.199.40.152|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 286478 (280K) [image/jpeg]\nSaving to: \u2018/content/bike.jpg\u2019\n\n/content/bike.jpg   100%[===================&gt;] 279.76K  --.-KB/s    in 0.005s  \n\n2023-05-02 11:35:18 (57.9 MB/s) - \u2018/content/bike.jpg\u2019 saved [286478/286478]\n\nA imagem \u00e9 carregada e transformada de (224, 224), para (1, 224, 224, 3)\n</pre> In\u00a0[\u00a0]: Copied! <pre>## faz a predi\u00e7\u00e3o da imagem\n\npreds = model.predict(x)\n</pre> ## faz a predi\u00e7\u00e3o da imagem  preds = model.predict(x)  <pre>1/1 [==============================] - 0s 21ms/step\n</pre> In\u00a0[\u00a0]: Copied! <pre>decoded_preds = decode_predictions(preds)[0]\n\nfor i, (imagenet_id, label, score) in enumerate(decoded_preds):\n    print(f\"{i+1}. {label}: {score * 100:.2f}%\")\n</pre> decoded_preds = decode_predictions(preds)[0]  for i, (imagenet_id, label, score) in enumerate(decoded_preds):     print(f\"{i+1}. {label}: {score * 100:.2f}%\")  <pre>1. mountain_bike: 81.59%\n2. alp: 3.85%\n3. crash_helmet: 1.89%\n4. bicycle-built-for-two: 1.80%\n5. tricycle: 1.75%\n</pre> In\u00a0[21]: Copied! <pre>from tensorflow.keras.applications.resnet50 import ResNet50, preprocess_input, decode_predictions\n\nmodel = ResNet50(weights='imagenet')\n\n\n#### seu c\u00f3digo aqui....\n</pre> from tensorflow.keras.applications.resnet50 import ResNet50, preprocess_input, decode_predictions  model = ResNet50(weights='imagenet')   #### seu c\u00f3digo aqui....    <pre>Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels.h5\n102967424/102967424 [==============================] - 5s 0us/step\n</pre> In\u00a0[47]: Copied! <pre>import os\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport tensorflow as tf\nfrom tensorflow.keras import layers, models\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\n\n# Configura\u00e7\u00e3o dos diret\u00f3rios e par\u00e2metros do conjunto de dados\n_URL = 'https://storage.googleapis.com/mledu-datasets/cats_and_dogs_filtered.zip'\npath_to_zip = tf.keras.utils.get_file('cats_and_dogs.zip', origin=_URL, extract=True)\nPATH = os.path.join(os.path.dirname(path_to_zip), 'cats_and_dogs_filtered')\n\ntrain_dir = os.path.join(PATH, 'train')\nvalidation_dir = os.path.join(PATH, 'validation')\n\nbatch_size = 32\nimage_size = (224, 224)\n</pre> import os import numpy as np import matplotlib.pyplot as plt import tensorflow as tf from tensorflow.keras import layers, models from tensorflow.keras.preprocessing.image import ImageDataGenerator  # Configura\u00e7\u00e3o dos diret\u00f3rios e par\u00e2metros do conjunto de dados _URL = 'https://storage.googleapis.com/mledu-datasets/cats_and_dogs_filtered.zip' path_to_zip = tf.keras.utils.get_file('cats_and_dogs.zip', origin=_URL, extract=True) PATH = os.path.join(os.path.dirname(path_to_zip), 'cats_and_dogs_filtered')  train_dir = os.path.join(PATH, 'train') validation_dir = os.path.join(PATH, 'validation')  batch_size = 32 image_size = (224, 224)  In\u00a0[43]: Copied! <pre># Fun\u00e7\u00e3o para exibir algumas imagens do conjunto de dados\ndef plot_images(images, labels, class_names):\n    plt.figure(figsize=(10, 10))\n    for i, (img, label) in enumerate(zip(images, labels)):\n        plt.subplot(3, 3, i + 1)\n        plt.imshow(img)\n        plt.title(class_names[label])\n        plt.axis(\"off\")\n    plt.show()\n\n# Carregar imagens e r\u00f3tulos do conjunto de dados de treinamento\ntrain_datagen = ImageDataGenerator(preprocessing_function=preprocess_input)\nvalidation_datagen = ImageDataGenerator(preprocessing_function=preprocess_input)\n\ntrain_generator = train_datagen.flow_from_directory(\n    train_dir,\n    target_size=image_size,\n    batch_size=batch_size,\n    class_mode='binary'\n)\n\n# Carregar imagens e r\u00f3tulos do conjunto de dados de valida\u00e7\u00e3o\nvalidation_generator = validation_datagen.flow_from_directory(\n    validation_dir,\n    target_size=image_size,\n    batch_size=batch_size,\n    class_mode='binary'\n)\n\n# Carregar algumas imagens e r\u00f3tulos do conjunto de dados de treinamento\nsample_datagen = ImageDataGenerator(rescale=1./255)\nsample_generator = sample_datagen.flow_from_directory(\n    train_dir,\n    target_size=image_size,\n    batch_size=9,\n    class_mode='binary'\n)\n\nsample_images, sample_labels = next(sample_generator)\nclass_names = {v: k for k, v in sample_generator.class_indices.items()}\nplot_images(sample_images, sample_labels, class_names)\n</pre> # Fun\u00e7\u00e3o para exibir algumas imagens do conjunto de dados def plot_images(images, labels, class_names):     plt.figure(figsize=(10, 10))     for i, (img, label) in enumerate(zip(images, labels)):         plt.subplot(3, 3, i + 1)         plt.imshow(img)         plt.title(class_names[label])         plt.axis(\"off\")     plt.show()  # Carregar imagens e r\u00f3tulos do conjunto de dados de treinamento train_datagen = ImageDataGenerator(preprocessing_function=preprocess_input) validation_datagen = ImageDataGenerator(preprocessing_function=preprocess_input)  train_generator = train_datagen.flow_from_directory(     train_dir,     target_size=image_size,     batch_size=batch_size,     class_mode='binary' )  # Carregar imagens e r\u00f3tulos do conjunto de dados de valida\u00e7\u00e3o validation_generator = validation_datagen.flow_from_directory(     validation_dir,     target_size=image_size,     batch_size=batch_size,     class_mode='binary' )  # Carregar algumas imagens e r\u00f3tulos do conjunto de dados de treinamento sample_datagen = ImageDataGenerator(rescale=1./255) sample_generator = sample_datagen.flow_from_directory(     train_dir,     target_size=image_size,     batch_size=9,     class_mode='binary' )  sample_images, sample_labels = next(sample_generator) class_names = {v: k for k, v in sample_generator.class_indices.items()} plot_images(sample_images, sample_labels, class_names) <pre>Found 2000 images belonging to 2 classes.\nFound 1000 images belonging to 2 classes.\nFound 2000 images belonging to 2 classes.\n</pre> In\u00a0[87]: Copied! <pre>from tensorflow.keras.applications.mobilenet_v2 import MobileNetV2, preprocess_input\n\n# Cria o base_model referente a MobileNet V2, sem a camada de classifica\u00e7\u00e3o\nbase_model = MobileNetV2(input_shape=(224, 224, 3),\n                        include_top=False,\n                        weights='imagenet')\n</pre> from tensorflow.keras.applications.mobilenet_v2 import MobileNetV2, preprocess_input  # Cria o base_model referente a MobileNet V2, sem a camada de classifica\u00e7\u00e3o base_model = MobileNetV2(input_shape=(224, 224, 3),                         include_top=False,                         weights='imagenet') In\u00a0[\u00a0]: Copied! <pre>base_model.summary()\n</pre> base_model.summary() In\u00a0[90]: Copied! <pre>#Congela a base_model para n\u00e3o atuaizar os pesos quando treinar.\n\nbase_model.trainable = False\n</pre> #Congela a base_model para n\u00e3o atuaizar os pesos quando treinar.  base_model.trainable = False In\u00a0[\u00a0]: Copied! <pre>base_model.summary()\n</pre> base_model.summary() In\u00a0[92]: Copied! <pre>#Camada  para gerar um vetor de 1280 elementos \nglobal_average_layer = layers.GlobalAveragePooling2D()\n\n# O Classificador para gato cachorro com 1 neuronio \nsaida_layer = layers.Dense(1, activation='sigmoid')\n</pre> #Camada  para gerar um vetor de 1280 elementos  global_average_layer = layers.GlobalAveragePooling2D()  # O Classificador para gato cachorro com 1 neuronio  saida_layer = layers.Dense(1, activation='sigmoid') In\u00a0[93]: Copied! <pre>model = tf.keras.Sequential([\n  base_model,   #### cnn mobilenet\n  global_average_layer, ###flatten\n  saida_layer ### especiallista\n])\n\nmodel.summary()\n</pre> model = tf.keras.Sequential([   base_model,   #### cnn mobilenet   global_average_layer, ###flatten   saida_layer ### especiallista ])  model.summary() <pre>Model: \"sequential_1\"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\n mobilenetv2_1.00_224 (Funct  (None, 7, 7, 1280)       2257984   \n ional)                                                          \n                                                                 \n global_average_pooling2d_5   (None, 1280)             0         \n (GlobalAveragePooling2D)                                        \n                                                                 \n dense_4 (Dense)             (None, 1)                 1281      \n                                                                 \n=================================================================\nTotal params: 2,259,265\nTrainable params: 1,281\nNon-trainable params: 2,257,984\n_________________________________________________________________\n</pre> <p>Pronto! J\u00e1 criamos a nossa rede para classifica\u00e7\u00e3o. Agora podemos treinar nossa rede e testar.</p> In\u00a0[94]: Copied! <pre>model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n</pre>  model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy']) In\u00a0[95]: Copied! <pre>#Avalia\u00e7\u00e3o do modelo antes de trein\u00e1-lo com novas imagens\nvalidation_steps=20\n\nloss0,accuracy0 = model.evaluate(train_generator, steps = validation_steps)\n</pre> #Avalia\u00e7\u00e3o do modelo antes de trein\u00e1-lo com novas imagens validation_steps=20  loss0,accuracy0 = model.evaluate(train_generator, steps = validation_steps) <pre>20/20 [==============================] - 5s 178ms/step - loss: 0.8159 - accuracy: 0.5125\n</pre> In\u00a0[62]: Copied! <pre># Treinamento da nova CNN\n\nhistory = model.fit(train_generator, epochs=5, validation_data=validation_generator)\n</pre> # Treinamento da nova CNN  history = model.fit(train_generator, epochs=5, validation_data=validation_generator)  <pre>Epoch 1/5\n63/63 [==============================] - 19s 232ms/step - loss: 0.6893 - accuracy: 0.6200 - val_loss: 0.5397 - val_accuracy: 0.7490\nEpoch 2/5\n63/63 [==============================] - 13s 205ms/step - loss: 0.4975 - accuracy: 0.7575 - val_loss: 0.4721 - val_accuracy: 0.7780\nEpoch 3/5\n63/63 [==============================] - 13s 206ms/step - loss: 0.4484 - accuracy: 0.7880 - val_loss: 0.4458 - val_accuracy: 0.7980\nEpoch 4/5\n63/63 [==============================] - 13s 202ms/step - loss: 0.4176 - accuracy: 0.8005 - val_loss: 0.4327 - val_accuracy: 0.8020\nEpoch 5/5\n63/63 [==============================] - 13s 204ms/step - loss: 0.3953 - accuracy: 0.8235 - val_loss: 0.4159 - val_accuracy: 0.8180\n</pre> In\u00a0[64]: Copied! <pre>import pandas as pd\n\nmetrics_df = pd.DataFrame(history.history)\nmetrics_df[[\"loss\",\"val_loss\"]].plot();\nmetrics_df[[\"accuracy\", \"val_accuracy\"]].plot();\n</pre> import pandas as pd  metrics_df = pd.DataFrame(history.history) metrics_df[[\"loss\",\"val_loss\"]].plot(); metrics_df[[\"accuracy\", \"val_accuracy\"]].plot(); In\u00a0[67]: Copied! <pre>import numpy as np\nfrom tensorflow.keras.preprocessing import image\n\ndef predict_cat_or_dog(img_path):\n    img = image.load_img(img_path, target_size=image_size)\n    img_array = image.img_to_array(img)\n    img_array = np.expand_dims(img_array, axis=0)\n    img_array = preprocess_input(img_array)\n\n    prediction = model.predict(img_array)\n    \n    if prediction[0][0] &lt; 0.5:\n        return \"gatinhooooo\"\n    else:\n        return \"cachorrinho\"\n\n# Teste a fun\u00e7\u00e3o de previs\u00e3o com uma imagem\n\n!wget https://uploads.metropoles.com/wp-content/uploads/2022/07/21154234/como-identificar-que-um-cachorro-esta-sendo-vitima-de-maus-tratos-1.jpg -O /content/cachorro.jpg\nimg_path = \"cachorro.jpg\"\nresult = predict_cat_or_dog(img_path)\nprint(\"Essa foto \u00e9 de um \", result)\n</pre> import numpy as np from tensorflow.keras.preprocessing import image  def predict_cat_or_dog(img_path):     img = image.load_img(img_path, target_size=image_size)     img_array = image.img_to_array(img)     img_array = np.expand_dims(img_array, axis=0)     img_array = preprocess_input(img_array)      prediction = model.predict(img_array)          if prediction[0][0] &lt; 0.5:         return \"gatinhooooo\"     else:         return \"cachorrinho\"  # Teste a fun\u00e7\u00e3o de previs\u00e3o com uma imagem  !wget https://uploads.metropoles.com/wp-content/uploads/2022/07/21154234/como-identificar-que-um-cachorro-esta-sendo-vitima-de-maus-tratos-1.jpg -O /content/cachorro.jpg img_path = \"cachorro.jpg\" result = predict_cat_or_dog(img_path) print(\"Essa foto \u00e9 de um \", result) <pre>--2023-05-02 12:32:46--  https://uploads.metropoles.com/wp-content/uploads/2022/07/21154234/como-identificar-que-um-cachorro-esta-sendo-vitima-de-maus-tratos-1.jpg\nResolving uploads.metropoles.com (uploads.metropoles.com)... 179.191.175.68, 179.191.175.67, 179.191.177.66, ...\nConnecting to uploads.metropoles.com (uploads.metropoles.com)|179.191.175.68|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 47409 (46K) [image/jpeg]\nSaving to: \u2018/content/cachorro.jpg\u2019\n\n/content/cachorro.j 100%[===================&gt;]  46.30K   200KB/s    in 0.2s    \n\n2023-05-02 12:32:47 (200 KB/s) - \u2018/content/cachorro.jpg\u2019 saved [47409/47409]\n\n1/1 [==============================] - 0s 23ms/step\nEssa foto \u00e9 de um  cachorrinho\n</pre> In\u00a0[69]: Copied! <pre># Salvando a rede \nmodel.save(\"dogs_vs_cats.h5\")\n\n#Carregando uma rede .h5\nnew_model = models.load_model('dogs_vs_cats.h5')\n</pre> # Salvando a rede  model.save(\"dogs_vs_cats.h5\")  #Carregando uma rede .h5 new_model = models.load_model('dogs_vs_cats.h5') In\u00a0[\u00a0]: Copied! <pre>### Seu c\u00f3digo aqui....\n</pre> ### Seu c\u00f3digo aqui...."},{"location":"aulas/IA/lab09/transferlearning.html#2-redes-neurais","title":"2. Redes Neurais\u00b6","text":""},{"location":"aulas/IA/lab09/transferlearning.html#objetivos","title":"Objetivos\u00b6","text":"<ul> <li>Conhecer e praticar Arquiteturas complexas de Redes Neurais Convolucionais</li> <li>Aprendizagem por transfer\u00eancia</li> <li>Praticar a classifica\u00e7\u00e3o de objeto usando framework TensorFlow</li> </ul>"},{"location":"aulas/IA/lab09/transferlearning.html#arquitetura-de-redes-neurais-convolucionais","title":"Arquitetura de Redes Neurais Convolucionais\u00b6","text":"<p>Existem diversas arquitetura de CNN, cada rede com suas pr\u00f3prias caracter\u00edsticas, principalmente para vis\u00e3o computacional. Mas todas ter\u00e3o em comum camadas de convolu\u00e7\u00e3o e maxpooling, dropout e algumas coisas a mais...</p>"},{"location":"aulas/IA/lab09/transferlearning.html#por-que-utilizar-uma-arquitetura-cnn","title":"Por que utilizar uma arquitetura CNN\u00b6","text":"<p>Utilizar uma arquitetura de CNN possibilita reduzir o tempo de pesquisa com o desenvolvimento de novas arquiteturas uma vez que essas arquiteturas j\u00e1 foram sistematicamente revisadas.</p>"},{"location":"aulas/IA/lab09/transferlearning.html#exemplos-de-arquiteturas","title":"Exemplos de arquiteturas:\u00b6","text":"<p><code>LeNET</code>: Desenvolvida em 1998 por Yann LeCun, a LeNet foi pioneira no uso de camadas de convolu\u00e7\u00e3o com filtros 5x5 e passo 1, al\u00e9m de camadas de agrupamento com filtros 2x2 e passo 2, intercaladas por camadas totalmente conectadas (FC). A ordem das camadas \u00e9: CONV-POOL-CONV-POOL-FC-FC. Essa arquitetura teve um papel fundamental no reconhecimento de d\u00edgitos manuscritos.</p> <p></p> <p><code>AlexNET</code>: Criada em 2012 por Alex Krizhevsky, Ilya Sutskever e Geoffrey Hinton, a AlexNet \u00e9 uma arquitetura mais avan\u00e7ada que a LeNet. Possui cinco camadas convolucionais seguidas de tr\u00eas camadas FC, e emprega a fun\u00e7\u00e3o de ativa\u00e7\u00e3o ReLU. Vencedora da competi\u00e7\u00e3o ImageNet de 2012, marcou o in\u00edcio da populariza\u00e7\u00e3o das redes neurais convolucionais profundas.</p> <p></p> <p><code>VGG</code>: A arquitetura VGG, concebida em 2014 pelo Visual Geometry Group da Universidade de Oxford, prop\u00f4s o uso de filtros menores (3x3) em redes mais profundas, com no m\u00ednimo 16 camadas convolucionais e maxpooling com filtros 2x2. Apesar de os filtros menores gerarem menos par\u00e2metros, as camadas FC e as convolu\u00e7\u00f5es iniciais demandavam grande quantidade de mem\u00f3ria RAM, resultando em uma rede pesada.</p> <p></p> <p><code>GoogleNET</code>: Paralelamente \u00e0 VGG, em 2014, pesquisadores do Google desenvolveram a GoogleNet, que introduziu o m\u00f3dulo Inception como elemento fundamental. Com nove m\u00f3dulos Inception em sequ\u00eancia, a arquitetura utiliza convolu\u00e7\u00f5es 3x3 e 5x5 precedidas por convolu\u00e7\u00f5es 1x1 para diminuir o custo computacional. A GoogleNet foi projetada para ser eficiente em termos de recursos e venceu a competi\u00e7\u00e3o ImageNet de 2014.</p> <p></p> <p><code>ResNET</code>: A rede residual, proposta em 2015 por Kaiming He e colaboradores, tem como caracter\u00edstica principal a inclus\u00e3o de conex\u00f5es residuais (curto-circuitos) a cada duas convolu\u00e7\u00f5es, adicionando um resultado anterior ao resultado futuro. Isso permite treinar redes mais profundas sem problemas de degrada\u00e7\u00e3o do desempenho. ResNets com 50, 101 e 152 camadas utilizam blocos residuais com \"bottleneck\", que consistem em duas convolu\u00e7\u00f5es 3x3 intercaladas por convolu\u00e7\u00f5es 1x1, diminuindo o custo computacional.</p> <p></p> <p><code>MobileNet</code>: Proposta em 2017, \u00e9 uma arquitetura otimizada para dispositivos m\u00f3veis e aplicativos com limita\u00e7\u00f5es de recursos computacionais. Utiliza convolu\u00e7\u00f5es separ\u00e1veis por profundidade para reduzir o n\u00famero de par\u00e2metros e o consumo de mem\u00f3ria.</p> <p><code>EfficientNet</code>: Proposta em 2019, \u00e9 uma fam\u00edlia de redes neurais convolucionais que busca melhorar a efici\u00eancia em termos de recursos computacionais e desempenho, atrav\u00e9s do ajuste coordenado da largura, profundidade e resolu\u00e7\u00e3o das redes.</p> <p><code>InceptionV3</code>: Uma evolu\u00e7\u00e3o do GoogleNet, a InceptionV3 \u00e9 uma arquitetura desenvolvida em 2015 que aprimora o m\u00f3dulo Inception e implementa t\u00e9cnicas de normaliza\u00e7\u00e3o em lotes. Essa arquitetura alcan\u00e7a um desempenho superior com menos par\u00e2metros e menor custo computacional.</p> <p><code>DenseNet</code>: Proposta em 2016, a DenseNet \u00e9 uma arquitetura que introduz conex\u00f5es densas entre as camadas. Cada camada recebe as caracter\u00edsticas de todas as camadas anteriores, o que melhora o fluxo de informa\u00e7\u00f5es e gradientes durante o treinamento. Isso permite a constru\u00e7\u00e3o de redes mais profundas e eficientes.</p> <p><code>YOLO</code> (You Only Look Once): \u00c9 uma arquitetura de rede neural focada em detec\u00e7\u00e3o de objetos em tempo real. Proposta em 2016, a YOLO divide a imagem em regi\u00f5es e prev\u00ea, de uma s\u00f3 vez, as probabilidades de classes e as coordenadas das caixas delimitadoras. A YOLO \u00e9 conhecida por sua velocidade e capacidade de detectar objetos em tempo real.</p> <p><code>Transformer</code>: Embora n\u00e3o seja uma arquitetura de rede neural convolucional, o Transformer, proposto em 2017, \u00e9 uma arquitetura de rede neural not\u00e1vel para processamento de linguagem natural e outras tarefas sequenciais. O Transformer introduziu o conceito de aten\u00e7\u00e3o auto-regressiva, que permite que a rede aprenda relacionamentos complexos entre as entradas, e tem sido a base para modelos de linguagem de \u00faltima gera\u00e7\u00e3o, como BERT e GPT.</p> <p>Parace que s\u00e3o muitas, mas essas s\u00e3o apenas algumas arquiteturas de redes neurais desenvolvidas nos \u00faltimos anos. Dependendo da aplica\u00e7\u00e3o e das restri\u00e7\u00f5es de recursos, voc\u00ea pode encontrar uma arquitetura adequada \u00e0s suas necessidades espec\u00edficas.</p>"},{"location":"aulas/IA/lab09/transferlearning.html#modelos-de-cnn-pre-treinados","title":"Modelos de CNN pr\u00e9-treinados\u00b6","text":"<p>O treinamento de uma boa CNN n\u00e3o \u00e9 simples, al\u00e9m de muitos dados (milhares de imagens) e muito tempo de processamento.</p> <p>Mas usar essas redes \u00e9 super super facil!!</p> <p>Vamos usar o VGG16 para fazer a classifica\u00e7\u00e3o de uma imagem.</p> <p>Recomendo dar uma olhada na documenta\u00e7\u00e3o oficial do Keras:  https://keras.io/api/applications/</p>"},{"location":"aulas/IA/lab09/transferlearning.html#desafio-1","title":"Desafio 1\u00b6","text":"<p>Agora avalie outras arquiteturas de redes neurais dispon\u00edveis no Keras, como ResNet50, InceptionV3, MobileNet e EfficientNet.</p> <p>Basta substituir a importa\u00e7\u00e3o e a fun\u00e7\u00e3o de carregamento do modelo conforme necess\u00e1rio. Por exemplo, para usar a ResNet50:</p>"},{"location":"aulas/IA/lab09/transferlearning.html#introducao-ao-transfer-learning-com-redes-pre-treinadas","title":"Introdu\u00e7\u00e3o ao Transfer Learning com redes pr\u00e9-treinadas\u00b6","text":"<p>Excelente! Agora que j\u00e1 sabemos como utilizar uma rede pr\u00e9-treinada, vamos explorar uma t\u00e9cnica poderosa chamada Transfer Learning (Aprendizagem por Transfer\u00eancia). Essa abordagem nos permite tirar proveito das arquiteturas de redes neurais existentes e trein\u00e1-las para classificar objetos personalizados ou novas categorias de imagens.</p> <p>O Transfer Learning \u00e9 uma t\u00e9cnica em que um modelo de aprendizado profundo, treinado previamente em um conjunto de dados maior e mais diversificado, \u00e9 adaptado para ser aplicado a um novo problema. O conhecimento adquirido pelo modelo original \u00e9 transferido para o novo problema, permitindo um treinamento mais r\u00e1pido e, muitas vezes, um desempenho melhor do que treinar uma rede neural do zero.</p> <p>A ideia por tr\u00e1s do Transfer Learning \u00e9 que as redes neurais pr\u00e9-treinadas, como VGG, ResNet e Inception, j\u00e1 aprenderam a <code>extrair caracter\u00edsticas</code> importantes das imagens em seus primeiros est\u00e1gios. Essas caracter\u00edsticas podem ser comuns a muitos problemas de classifica\u00e7\u00e3o de imagens, como detec\u00e7\u00e3o de bordas, texturas e padr\u00f5es. Ao aproveitar esse conhecimento pr\u00e9vio, podemos nos concentrar no treinamento das \u00faltimas camadas do modelo, que s\u00e3o respons\u00e1veis por aprender caracter\u00edsticas espec\u00edficas do novo problema.</p> <p>Ao utilizar o Transfer Learning, podemos economizar tempo e recursos computacionais, al\u00e9m de obter melhores resultados do que treinar uma rede do zero para um conjunto de dados menor e espec\u00edfico. Portanto, \u00e9 uma t\u00e9cnica amplamente utilizada em aplica\u00e7\u00f5es pr\u00e1ticas de aprendizado profundo e processamento de imagens.</p>"},{"location":"aulas/IA/lab09/transferlearning.html#combinando-a-rede-pre-treinada-com-um-classificador-mlp","title":"Combinando a rede pr\u00e9-treinada com um classificador MLP\u00b6","text":"<p>Ao aplicar o Transfer Learning, nossa rede convolucional ser\u00e1 composta por duas partes principais: o extrator de caracter\u00edsticas e o classificador. O extrator de caracter\u00edsticas ser\u00e1 baseado em uma rede pr\u00e9-treinada, como VGG16, ResNet50 ou InceptionV3. Essa parte da rede j\u00e1 aprendeu a extrair caracter\u00edsticas relevantes de imagens, como bordas, texturas e padr\u00f5es, durante o treinamento em um grande conjunto de dados, como o ImageNet.</p> <p>Em seguida, adicionaremos um classificador MLP (Multilayer Perceptron) personalizado para resolver o nosso problema espec\u00edfico de classifica\u00e7\u00e3o de imagens. Esse classificador ser\u00e1 respons\u00e1vel por aprender as caracter\u00edsticas espec\u00edficas do novo conjunto de dados e classificar as imagens nas categorias desejadas.</p> <p>Dessa forma, a rede ajustada combina o poder das redes pr\u00e9-treinadas, que j\u00e1 aprenderam a extrair caracter\u00edsticas gerais de imagens, com um classificador personalizado que aprender\u00e1 a distinguir as categorias espec\u00edficas do nosso problema. Como mostra a figura abaixo:</p> <p></p> <p>Agora que entendemos os conceitos b\u00e1sicos de Transfer Learning, podemos prosseguir com os passos para aplicar o Transfer Learning e adaptar a rede pr\u00e9-treinada ao nosso problema de classifica\u00e7\u00e3o de imagens.</p>"},{"location":"aulas/IA/lab09/transferlearning.html#passo-a-passo-para-aplicar-transfer-learning","title":"Passo a passo para aplicar Transfer Learning\u00b6","text":"<ol> <li><p>Escolha uma rede pr\u00e9-treinada: Selecione uma rede neural pr\u00e9-treinada dispon\u00edvel no Keras (por exemplo, VGG16, ResNet50, InceptionV3) com base nas caracter\u00edsticas e requisitos do seu problema. Cada arquitetura tem suas pr\u00f3prias vantagens e desvantagens, portanto, escolha aquela que melhor se adapta \u00e0s suas necessidades.</p> </li> <li><p>Remova a camada de classifica\u00e7\u00e3o: Carregue a rede neural pr\u00e9-treinada sem a camada de classifica\u00e7\u00e3o final. Isso pode ser feito usando o argumento include_top=False ao carregar o modelo no Keras. Isso permitir\u00e1 que voc\u00ea adicione suas pr\u00f3prias camadas personalizadas para classificar as novas categorias.</p> </li> <li><p>Adicione camadas personalizadas: Adicione camadas espec\u00edficas para o seu problema de classifica\u00e7\u00e3o. Normalmente, isso inclui uma camada de GlobalAveragePooling2D, seguida por uma camada densa com uma fun\u00e7\u00e3o de ativa\u00e7\u00e3o softmax e o n\u00famero de neuronios igual ao n\u00famero de classes do novo problema.</p> </li> <li><p>Congele as camadas pr\u00e9-treinadas: \u00c9 uma boa pr\u00e1tica congelar as camadas pr\u00e9-treinadas da rede neural, especialmente durante as primeiras \u00e9pocas do treinamento. Isso evitar\u00e1 que os pesos dessas camadas sejam atualizados e preservar\u00e1 o conhecimento pr\u00e9vio que elas possuem. No Keras, voc\u00ea pode fazer isso com o modelxxx.trainable = False</p> </li> <li><p>Pr\u00e9-processamento dos dados: Prepare os dados de acordo com a rede pr\u00e9-treinada escolhida. Isso inclui redimensionar as imagens, normalizar os valores dos pixels e codificar as etiquetas das categorias. Lembre-se de aplicar as mesmas transforma\u00e7\u00f5es usadas no conjunto de dados original da rede pr\u00e9-treinada.</p> </li> <li><p>Treine o modelo: Treine o modelo ajustado no seu conjunto de dados. Durante as primeiras \u00e9pocas, com as camadas pr\u00e9-treinadas congeladas, o modelo aprender\u00e1 as caracter\u00edsticas espec\u00edficas do novo problema.</p> </li> <li><p>Avalie e otimize: Avalie o desempenho do modelo ajustado em um conjunto de teste e otimize os hiperpar\u00e2metros conforme necess\u00e1rio. Voc\u00ea pode experimentar diferentes arquiteturas de redes neurais, taxas de aprendizado, otimizadores e outros hiperpar\u00e2metros para encontrar a melhor configura\u00e7\u00e3o para o seu problema.</p> </li> </ol>"},{"location":"aulas/IA/lab09/transferlearning.html#aplicando-transfer-learning-em-um-dataset-ja-preparado-pelo-tensorflow","title":"Aplicando transfer learning em um dataset j\u00e1 preparado pelo tensorflow\u00b6","text":"<p>Vamos usar o dataset <code>cats_vs_dogs</code> que \u00e9 disponibilizado pelo proprio tensorflow, desta forma focamos apenas no entendimento da tecnica de transfer learning e menos em preprocessamento e cria\u00e7\u00e3o de dados. nas proximas aulas vamos criar nosso proprio dataset...</p>"},{"location":"aulas/IA/lab09/transferlearning.html#escolhendo-um-modelo-pre-treinado","title":"Escolhendo um modelo pr\u00e9-treinado\u00b6","text":"<p>A <code>MobileNet V2</code> desenvolvido no Google e foi treinado com <code>1,4 milh\u00e3o de imagens</code> e possui <code>1000 classes diferentes</code> com pesos predeterminados do imagenet (Googles dataset).</p> <p>Carregue a rede neural pr\u00e9-treinada sem a camada de classifica\u00e7\u00e3o final. Isso pode ser feito usando o argumento <code>include_top=False</code></p>"},{"location":"aulas/IA/lab09/transferlearning.html#adicionando-um-classificador","title":"Adicionando um Classificador\u00b6","text":""},{"location":"aulas/IA/lab09/transferlearning.html#desafio-2","title":"Desafio 2\u00b6","text":"<p>Vamos entender o que acabamos de fazer. Avalie a quantidade de parametros total, treinaveis e n\u00e3o treinaveis. O que foi identificado?</p>"},{"location":"aulas/IA/lab09/transferlearning.html#sua-resposta-aqui","title":"sua resposta aqui.....\u00b6","text":"<p>.</p>"},{"location":"aulas/IA/lab09/transferlearning.html#treinamento-do-modelo","title":"Treinamento do modelo\u00b6","text":""},{"location":"aulas/IA/lab09/transferlearning.html#fazendo-predicoes","title":"Fazendo predi\u00e7\u00f5es\u00b6","text":""},{"location":"aulas/IA/lab09/transferlearning.html#salvando-o-modelo-da-rede-treinada","title":"Salvando o modelo da rede treinada\u00b6","text":"<p>Agora que j\u00e1 temos um modelo treinado e ajustado para resolver o problema especifico que temos, podemos salver a arquitetura e os pesos em um arquivo com extens\u00e3o .h5</p> <p>para usar esta rede, basta carregar o arquivo.h5</p>"},{"location":"aulas/IA/lab09/transferlearning.html#desafio-3","title":"Desafio 3\u00b6","text":"<p>Aplicar o Transfer Learning usando a rede pr\u00e9-treinada ResNet50 e o conjunto de dados CIFAR-10, que possui 10 classes de objetos.</p>"},{"location":"aulas/IA/lab09/transferlearning_1.html","title":"Lab06 - Pr\u00e9-treinadas","text":"In\u00a0[3]: Copied! <pre>import numpy as np\nfrom tensorflow.keras.preprocessing import image\n\n\n## importa o modelo da VGG16 pr\u00e9-treinado\nfrom tensorflow.keras.applications.vgg16 import VGG16, preprocess_input, decode_predictions\n</pre> import numpy as np from tensorflow.keras.preprocessing import image   ## importa o modelo da VGG16 pr\u00e9-treinado from tensorflow.keras.applications.vgg16 import VGG16, preprocess_input, decode_predictions   <pre>/Users/arnaldoalvesvianajunior/Library/Python/3.9/lib/python/site-packages/urllib3/__init__.py:34: NotOpenSSLWarning: urllib3 v2.0 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n  warnings.warn(\n</pre> In\u00a0[13]: Copied! <pre># Carrega o modelo VGG16 pr\u00e9-treinado com ImageNet:\nmodel = VGG16()\n</pre> # Carrega o modelo VGG16 pr\u00e9-treinado com ImageNet: model = VGG16()  <pre>Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels.h5\n553467096/553467096 \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 75s 0us/step\n</pre> In\u00a0[15]: Copied! <pre>import matplotlib.pyplot as plt\n\n# Fun\u00e7\u00e3o para visualizar imagem\ndef display_image(img_path):\n    img = image.load_img(img_path)\n    plt.imshow(img)\n    plt.axis('off')\n    plt.show()\n</pre> import matplotlib.pyplot as plt  # Fun\u00e7\u00e3o para visualizar imagem def display_image(img_path):     img = image.load_img(img_path)     plt.imshow(img)     plt.axis('off')     plt.show() In\u00a0[16]: Copied! <pre># Carrega uma imagem e prepara para ser predita pela VGG16\n\n## teste 1\n# !wget https://images.tcdn.com.br/img/img_prod/777105/bicicleta_29_hope_21_velocidades_shimano_freios_disco_tamanho_17_12475_1_ac0b7c63eee851b87bcc9832033c9826.jpg -O /content/bike.jpg\n# img_path = 'bike.jpg'\n\n# teste 2\n#!wget https://liberal.com.br/wp-content/uploads/2019/11/buraco-rua-dos-anturios.jpg -O /content/buraco.jpg\n#img_path = 'buraco.jpg'\n\n# teste 3\n#img_path = 'COLOQUE_UMA_IMAGEM.jpg'\n\n# se estiver rodando localmente, descomente a linha abaixo\n#img_path = 'COLOQUE_UMA_IMAGEM.jpg'\nimg_path = 'bicicleta.png'\n\n\n\nimg = image.load_img(img_path, target_size=(224, 224))\nx = image.img_to_array(img)\nx = np.expand_dims(x, axis=0)\nx = preprocess_input(x)\nprint(\"A imagem \u00e9 carregada e transformada de {}, para {}\".format(img.size,x.shape))\ndisplay_image(img_path)\n</pre> # Carrega uma imagem e prepara para ser predita pela VGG16  ## teste 1 # !wget https://images.tcdn.com.br/img/img_prod/777105/bicicleta_29_hope_21_velocidades_shimano_freios_disco_tamanho_17_12475_1_ac0b7c63eee851b87bcc9832033c9826.jpg -O /content/bike.jpg # img_path = 'bike.jpg'  # teste 2 #!wget https://liberal.com.br/wp-content/uploads/2019/11/buraco-rua-dos-anturios.jpg -O /content/buraco.jpg #img_path = 'buraco.jpg'  # teste 3 #img_path = 'COLOQUE_UMA_IMAGEM.jpg'  # se estiver rodando localmente, descomente a linha abaixo #img_path = 'COLOQUE_UMA_IMAGEM.jpg' img_path = 'bicicleta.png'    img = image.load_img(img_path, target_size=(224, 224)) x = image.img_to_array(img) x = np.expand_dims(x, axis=0) x = preprocess_input(x) print(\"A imagem \u00e9 carregada e transformada de {}, para {}\".format(img.size,x.shape)) display_image(img_path) <pre>A imagem \u00e9 carregada e transformada de (224, 224), para (1, 224, 224, 3)\n</pre> In\u00a0[17]: Copied! <pre>## faz a predi\u00e7\u00e3o da imagem\n\npreds = model.predict(x)\n</pre> ## faz a predi\u00e7\u00e3o da imagem  preds = model.predict(x)  <pre>1/1 \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 0s 327ms/step\n</pre> In\u00a0[18]: Copied! <pre>decoded_preds = decode_predictions(preds)[0]\n\nfor i, (imagenet_id, label, score) in enumerate(decoded_preds):\n    print(f\"{i+1}. {label}: {score * 100:.2f}%\")\n</pre> decoded_preds = decode_predictions(preds)[0]  for i, (imagenet_id, label, score) in enumerate(decoded_preds):     print(f\"{i+1}. {label}: {score * 100:.2f}%\")  <pre>Downloading data from https://storage.googleapis.com/download.tensorflow.org/data/imagenet_class_index.json\n35363/35363 \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 0s 1us/step\n1. mountain_bike: 82.86%\n2. alp: 3.89%\n3. crash_helmet: 1.95%\n4. bicycle-built-for-two: 1.51%\n5. tricycle: 1.51%\n</pre> In\u00a0[21]: Copied! <pre>from tensorflow.keras.applications.resnet50 import ResNet50, preprocess_input, decode_predictions\n\nmodel = ResNet50(weights='imagenet')\n\n\n#### seu c\u00f3digo aqui....\n</pre> from tensorflow.keras.applications.resnet50 import ResNet50, preprocess_input, decode_predictions  model = ResNet50(weights='imagenet')   #### seu c\u00f3digo aqui....     <pre>Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels.h5\n102967424/102967424 [==============================] - 5s 0us/step\n</pre>"},{"location":"aulas/IA/lab09/transferlearning_1.html#2-redes-neurais","title":"2. Redes Neurais\u00b6","text":""},{"location":"aulas/IA/lab09/transferlearning_1.html#objetivos","title":"Objetivos\u00b6","text":"<ul> <li>Conhecer e praticar Arquiteturas complexas de Redes Neurais Convolucionais</li> </ul>"},{"location":"aulas/IA/lab09/transferlearning_1.html#arquitetura-de-redes-neurais-convolucionais","title":"Arquitetura de Redes Neurais Convolucionais\u00b6","text":"<p>Existem diversas arquitetura de CNN, cada rede com suas pr\u00f3prias caracter\u00edsticas, principalmente para vis\u00e3o computacional. Mas todas ter\u00e3o em comum camadas de convolu\u00e7\u00e3o e maxpooling, dropout e algumas coisas a mais...</p>"},{"location":"aulas/IA/lab09/transferlearning_1.html#por-que-utilizar-uma-arquitetura-cnn","title":"Por que utilizar uma arquitetura CNN\u00b6","text":"<p>Utilizar uma arquitetura de CNN possibilita reduzir o tempo de pesquisa com o desenvolvimento de novas arquiteturas uma vez que essas arquiteturas j\u00e1 foram sistematicamente revisadas.</p>"},{"location":"aulas/IA/lab09/transferlearning_1.html#exemplos-de-arquiteturas","title":"Exemplos de arquiteturas:\u00b6","text":"<p><code>LeNET</code>: Desenvolvida em 1998 por Yann LeCun, a LeNet foi pioneira no uso de camadas de convolu\u00e7\u00e3o com filtros 5x5 e passo 1, al\u00e9m de camadas de agrupamento com filtros 2x2 e passo 2, intercaladas por camadas totalmente conectadas (FC). A ordem das camadas \u00e9: CONV-POOL-CONV-POOL-FC-FC. Essa arquitetura teve um papel fundamental no reconhecimento de d\u00edgitos manuscritos.</p> <p></p> <p><code>AlexNET</code>: Criada em 2012 por Alex Krizhevsky, Ilya Sutskever e Geoffrey Hinton, a AlexNet \u00e9 uma arquitetura mais avan\u00e7ada que a LeNet. Possui cinco camadas convolucionais seguidas de tr\u00eas camadas FC, e emprega a fun\u00e7\u00e3o de ativa\u00e7\u00e3o ReLU. Vencedora da competi\u00e7\u00e3o ImageNet de 2012, marcou o in\u00edcio da populariza\u00e7\u00e3o das redes neurais convolucionais profundas.</p> <p></p> <p><code>VGG</code>: A arquitetura VGG, concebida em 2014 pelo Visual Geometry Group da Universidade de Oxford, prop\u00f4s o uso de filtros menores (3x3) em redes mais profundas, com no m\u00ednimo 16 camadas convolucionais e maxpooling com filtros 2x2. Apesar de os filtros menores gerarem menos par\u00e2metros, as camadas FC e as convolu\u00e7\u00f5es iniciais demandavam grande quantidade de mem\u00f3ria RAM, resultando em uma rede pesada.</p> <p></p> <p><code>GoogleNET</code>: Paralelamente \u00e0 VGG, em 2014, pesquisadores do Google desenvolveram a GoogleNet, que introduziu o m\u00f3dulo Inception como elemento fundamental. Com nove m\u00f3dulos Inception em sequ\u00eancia, a arquitetura utiliza convolu\u00e7\u00f5es 3x3 e 5x5 precedidas por convolu\u00e7\u00f5es 1x1 para diminuir o custo computacional. A GoogleNet foi projetada para ser eficiente em termos de recursos e venceu a competi\u00e7\u00e3o ImageNet de 2014.</p> <p></p> <p><code>ResNET</code>: A rede residual, proposta em 2015 por Kaiming He e colaboradores, tem como caracter\u00edstica principal a inclus\u00e3o de conex\u00f5es residuais (curto-circuitos) a cada duas convolu\u00e7\u00f5es, adicionando um resultado anterior ao resultado futuro. Isso permite treinar redes mais profundas sem problemas de degrada\u00e7\u00e3o do desempenho. ResNets com 50, 101 e 152 camadas utilizam blocos residuais com \"bottleneck\", que consistem em duas convolu\u00e7\u00f5es 3x3 intercaladas por convolu\u00e7\u00f5es 1x1, diminuindo o custo computacional.</p> <p></p> <p><code>MobileNet</code>: Proposta em 2017, \u00e9 uma arquitetura otimizada para dispositivos m\u00f3veis e aplicativos com limita\u00e7\u00f5es de recursos computacionais. Utiliza convolu\u00e7\u00f5es separ\u00e1veis por profundidade para reduzir o n\u00famero de par\u00e2metros e o consumo de mem\u00f3ria.</p> <p><code>EfficientNet</code>: Proposta em 2019, \u00e9 uma fam\u00edlia de redes neurais convolucionais que busca melhorar a efici\u00eancia em termos de recursos computacionais e desempenho, atrav\u00e9s do ajuste coordenado da largura, profundidade e resolu\u00e7\u00e3o das redes.</p> <p><code>InceptionV3</code>: Uma evolu\u00e7\u00e3o do GoogleNet, a InceptionV3 \u00e9 uma arquitetura desenvolvida em 2015 que aprimora o m\u00f3dulo Inception e implementa t\u00e9cnicas de normaliza\u00e7\u00e3o em lotes. Essa arquitetura alcan\u00e7a um desempenho superior com menos par\u00e2metros e menor custo computacional.</p> <p><code>DenseNet</code>: Proposta em 2016, a DenseNet \u00e9 uma arquitetura que introduz conex\u00f5es densas entre as camadas. Cada camada recebe as caracter\u00edsticas de todas as camadas anteriores, o que melhora o fluxo de informa\u00e7\u00f5es e gradientes durante o treinamento. Isso permite a constru\u00e7\u00e3o de redes mais profundas e eficientes.</p> <p><code>YOLO</code> (You Only Look Once): \u00c9 uma arquitetura de rede neural focada em detec\u00e7\u00e3o de objetos em tempo real. Proposta em 2016, a YOLO divide a imagem em regi\u00f5es e prev\u00ea, de uma s\u00f3 vez, as probabilidades de classes e as coordenadas das caixas delimitadoras. A YOLO \u00e9 conhecida por sua velocidade e capacidade de detectar objetos em tempo real.</p> <p><code>Transformer</code>: Embora n\u00e3o seja uma arquitetura de rede neural convolucional, o Transformer, proposto em 2017, \u00e9 uma arquitetura de rede neural not\u00e1vel para processamento de linguagem natural e outras tarefas sequenciais. O Transformer introduziu o conceito de aten\u00e7\u00e3o auto-regressiva, que permite que a rede aprenda relacionamentos complexos entre as entradas, e tem sido a base para modelos de linguagem de \u00faltima gera\u00e7\u00e3o, como BERT e GPT.</p> <p>Parace que s\u00e3o muitas, mas essas s\u00e3o apenas algumas arquiteturas de redes neurais desenvolvidas nos \u00faltimos anos. Dependendo da aplica\u00e7\u00e3o e das restri\u00e7\u00f5es de recursos, voc\u00ea pode encontrar uma arquitetura adequada \u00e0s suas necessidades espec\u00edficas.</p>"},{"location":"aulas/IA/lab09/transferlearning_1.html#modelos-de-cnn-pre-treinados","title":"Modelos de CNN pr\u00e9-treinados\u00b6","text":"<p>O treinamento de uma boa CNN n\u00e3o \u00e9 simples, al\u00e9m de muitos dados (milhares de imagens) e muito tempo de processamento.</p> <p>Mas usar essas redes \u00e9 super super facil!!</p> <p>Vamos usar o VGG16 para fazer a classifica\u00e7\u00e3o de uma imagem.</p> <p>Recomendo dar uma olhada na documenta\u00e7\u00e3o oficial do Keras:  https://keras.io/api/applications/</p>"},{"location":"aulas/IA/lab09/transferlearning_1.html#desafio-1","title":"Desafio 1\u00b6","text":"<p>Agora avalie outras arquiteturas de redes neurais dispon\u00edveis no Keras, como ResNet50, InceptionV3, MobileNet e EfficientNet.</p> <p>Basta substituir a importa\u00e7\u00e3o e a fun\u00e7\u00e3o de carregamento do modelo conforme necess\u00e1rio. Por exemplo, para usar a ResNet50:</p>"},{"location":"aulas/IA/lab09/transferlearning_2.html","title":"Lab07 - Transfer learning","text":"In\u00a0[4]: Copied! <pre>import os\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport tensorflow as tf\nfrom tensorflow.keras import layers, models\nfrom tensorflow.keras.applications.mobilenet_v2 import MobileNetV2, preprocess_input\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\n\n# Configura\u00e7\u00e3o dos diret\u00f3rios e par\u00e2metros do conjunto de dados\n_URL = 'https://storage.googleapis.com/mledu-datasets/cats_and_dogs_filtered.zip'\npath_to_zip = tf.keras.utils.get_file('cats_and_dogs.zip', origin=_URL, extract=True)\nPATH = os.path.join(os.path.dirname(path_to_zip), 'cats_and_dogs_filtered')\n\ntrain_dir = os.path.join(PATH, 'train')\nvalidation_dir = os.path.join(PATH, 'validation')\n\nbatch_size = 32\nimage_size = (224, 224)\n</pre> import os import numpy as np import matplotlib.pyplot as plt import tensorflow as tf from tensorflow.keras import layers, models from tensorflow.keras.applications.mobilenet_v2 import MobileNetV2, preprocess_input from tensorflow.keras.preprocessing.image import ImageDataGenerator  # Configura\u00e7\u00e3o dos diret\u00f3rios e par\u00e2metros do conjunto de dados _URL = 'https://storage.googleapis.com/mledu-datasets/cats_and_dogs_filtered.zip' path_to_zip = tf.keras.utils.get_file('cats_and_dogs.zip', origin=_URL, extract=True) PATH = os.path.join(os.path.dirname(path_to_zip), 'cats_and_dogs_filtered')  train_dir = os.path.join(PATH, 'train') validation_dir = os.path.join(PATH, 'validation')  batch_size = 32 image_size = (224, 224)  In\u00a0[5]: Copied! <pre># Fun\u00e7\u00e3o para exibir algumas imagens do conjunto de dados\ndef plot_images(images, labels, class_names):\n    plt.figure(figsize=(10, 10))\n    for i, (img, label) in enumerate(zip(images, labels)):\n        plt.subplot(3, 3, i + 1)\n        plt.imshow(img)\n        plt.title(class_names[label])\n        plt.axis(\"off\")\n    plt.show()\n\n# Carregar imagens e r\u00f3tulos do conjunto de dados de treinamento\ntrain_datagen = ImageDataGenerator(preprocessing_function=preprocess_input)\nvalidation_datagen = ImageDataGenerator(preprocessing_function=preprocess_input)\n\ntrain_generator = train_datagen.flow_from_directory(\n    train_dir,\n    target_size=image_size,\n    batch_size=batch_size,\n    class_mode='binary'\n)\n\n# Carregar imagens e r\u00f3tulos do conjunto de dados de valida\u00e7\u00e3o\nvalidation_generator = validation_datagen.flow_from_directory(\n    validation_dir,\n    target_size=image_size,\n    batch_size=batch_size,\n    class_mode='binary'\n)\n\n# Carregar algumas imagens e r\u00f3tulos do conjunto de dados de treinamento\nsample_datagen = ImageDataGenerator(rescale=1./255)\nsample_generator = sample_datagen.flow_from_directory(\n    train_dir,\n    target_size=image_size,\n    batch_size=9,\n    class_mode='binary'\n)\n\nsample_images, sample_labels = next(sample_generator)\nclass_names = {v: k for k, v in sample_generator.class_indices.items()}\nplot_images(sample_images, sample_labels, class_names)\n</pre> # Fun\u00e7\u00e3o para exibir algumas imagens do conjunto de dados def plot_images(images, labels, class_names):     plt.figure(figsize=(10, 10))     for i, (img, label) in enumerate(zip(images, labels)):         plt.subplot(3, 3, i + 1)         plt.imshow(img)         plt.title(class_names[label])         plt.axis(\"off\")     plt.show()  # Carregar imagens e r\u00f3tulos do conjunto de dados de treinamento train_datagen = ImageDataGenerator(preprocessing_function=preprocess_input) validation_datagen = ImageDataGenerator(preprocessing_function=preprocess_input)  train_generator = train_datagen.flow_from_directory(     train_dir,     target_size=image_size,     batch_size=batch_size,     class_mode='binary' )  # Carregar imagens e r\u00f3tulos do conjunto de dados de valida\u00e7\u00e3o validation_generator = validation_datagen.flow_from_directory(     validation_dir,     target_size=image_size,     batch_size=batch_size,     class_mode='binary' )  # Carregar algumas imagens e r\u00f3tulos do conjunto de dados de treinamento sample_datagen = ImageDataGenerator(rescale=1./255) sample_generator = sample_datagen.flow_from_directory(     train_dir,     target_size=image_size,     batch_size=9,     class_mode='binary' )  sample_images, sample_labels = next(sample_generator) class_names = {v: k for k, v in sample_generator.class_indices.items()} plot_images(sample_images, sample_labels, class_names) <pre>Found 2000 images belonging to 2 classes.\nFound 1000 images belonging to 2 classes.\nFound 2000 images belonging to 2 classes.\n</pre> In\u00a0[6]: Copied! <pre># Cria o base_model referente a MobileNet V2, sem a camada de classifica\u00e7\u00e3o\nbase_model = MobileNetV2(input_shape=(224, 224, 3),\n                        include_top=False,\n                        weights='imagenet')\n</pre> # Cria o base_model referente a MobileNet V2, sem a camada de classifica\u00e7\u00e3o base_model = MobileNetV2(input_shape=(224, 224, 3),                         include_top=False,                         weights='imagenet') <pre>Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet_v2/mobilenet_v2_weights_tf_dim_ordering_tf_kernels_1.0_224_no_top.h5\n9406464/9406464 \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 2s 0us/step\n</pre> In\u00a0[\u00a0]: Copied! <pre>base_model.summary()\n</pre> base_model.summary() In\u00a0[7]: Copied! <pre>#Congela a base_model para n\u00e3o atuaizar os pesos quando treinar.\n\nbase_model.trainable = False\n</pre> #Congela a base_model para n\u00e3o atuaizar os pesos quando treinar.  base_model.trainable = False In\u00a0[8]: Copied! <pre>base_model.summary()\n</pre> base_model.summary() <pre>Model: \"mobilenetv2_1.00_224\"\n</pre> <pre>\u250f\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2513\n\u2503 Layer (type)        \u2503 Output Shape      \u2503    Param # \u2503 Connected to      \u2503\n\u2521\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2529\n\u2502 input_layer         \u2502 (None, 224, 224,  \u2502          0 \u2502 -                 \u2502\n\u2502 (InputLayer)        \u2502 3)                \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 Conv1 (Conv2D)      \u2502 (None, 112, 112,  \u2502        864 \u2502 input_layer[0][0] \u2502\n\u2502                     \u2502 32)               \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 bn_Conv1            \u2502 (None, 112, 112,  \u2502        128 \u2502 Conv1[0][0]       \u2502\n\u2502 (BatchNormalizatio\u2026 \u2502 32)               \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 Conv1_relu (ReLU)   \u2502 (None, 112, 112,  \u2502          0 \u2502 bn_Conv1[0][0]    \u2502\n\u2502                     \u2502 32)               \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 expanded_conv_dept\u2026 \u2502 (None, 112, 112,  \u2502        288 \u2502 Conv1_relu[0][0]  \u2502\n\u2502 (DepthwiseConv2D)   \u2502 32)               \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 expanded_conv_dept\u2026 \u2502 (None, 112, 112,  \u2502        128 \u2502 expanded_conv_de\u2026 \u2502\n\u2502 (BatchNormalizatio\u2026 \u2502 32)               \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 expanded_conv_dept\u2026 \u2502 (None, 112, 112,  \u2502          0 \u2502 expanded_conv_de\u2026 \u2502\n\u2502 (ReLU)              \u2502 32)               \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 expanded_conv_proj\u2026 \u2502 (None, 112, 112,  \u2502        512 \u2502 expanded_conv_de\u2026 \u2502\n\u2502 (Conv2D)            \u2502 16)               \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 expanded_conv_proj\u2026 \u2502 (None, 112, 112,  \u2502         64 \u2502 expanded_conv_pr\u2026 \u2502\n\u2502 (BatchNormalizatio\u2026 \u2502 16)               \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_1_expand      \u2502 (None, 112, 112,  \u2502      1,536 \u2502 expanded_conv_pr\u2026 \u2502\n\u2502 (Conv2D)            \u2502 96)               \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_1_expand_BN   \u2502 (None, 112, 112,  \u2502        384 \u2502 block_1_expand[0\u2026 \u2502\n\u2502 (BatchNormalizatio\u2026 \u2502 96)               \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_1_expand_relu \u2502 (None, 112, 112,  \u2502          0 \u2502 block_1_expand_B\u2026 \u2502\n\u2502 (ReLU)              \u2502 96)               \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_1_pad         \u2502 (None, 113, 113,  \u2502          0 \u2502 block_1_expand_r\u2026 \u2502\n\u2502 (ZeroPadding2D)     \u2502 96)               \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_1_depthwise   \u2502 (None, 56, 56,    \u2502        864 \u2502 block_1_pad[0][0] \u2502\n\u2502 (DepthwiseConv2D)   \u2502 96)               \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_1_depthwise_\u2026 \u2502 (None, 56, 56,    \u2502        384 \u2502 block_1_depthwis\u2026 \u2502\n\u2502 (BatchNormalizatio\u2026 \u2502 96)               \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_1_depthwise_\u2026 \u2502 (None, 56, 56,    \u2502          0 \u2502 block_1_depthwis\u2026 \u2502\n\u2502 (ReLU)              \u2502 96)               \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_1_project     \u2502 (None, 56, 56,    \u2502      2,304 \u2502 block_1_depthwis\u2026 \u2502\n\u2502 (Conv2D)            \u2502 24)               \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_1_project_BN  \u2502 (None, 56, 56,    \u2502         96 \u2502 block_1_project[\u2026 \u2502\n\u2502 (BatchNormalizatio\u2026 \u2502 24)               \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_2_expand      \u2502 (None, 56, 56,    \u2502      3,456 \u2502 block_1_project_\u2026 \u2502\n\u2502 (Conv2D)            \u2502 144)              \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_2_expand_BN   \u2502 (None, 56, 56,    \u2502        576 \u2502 block_2_expand[0\u2026 \u2502\n\u2502 (BatchNormalizatio\u2026 \u2502 144)              \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_2_expand_relu \u2502 (None, 56, 56,    \u2502          0 \u2502 block_2_expand_B\u2026 \u2502\n\u2502 (ReLU)              \u2502 144)              \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_2_depthwise   \u2502 (None, 56, 56,    \u2502      1,296 \u2502 block_2_expand_r\u2026 \u2502\n\u2502 (DepthwiseConv2D)   \u2502 144)              \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_2_depthwise_\u2026 \u2502 (None, 56, 56,    \u2502        576 \u2502 block_2_depthwis\u2026 \u2502\n\u2502 (BatchNormalizatio\u2026 \u2502 144)              \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_2_depthwise_\u2026 \u2502 (None, 56, 56,    \u2502          0 \u2502 block_2_depthwis\u2026 \u2502\n\u2502 (ReLU)              \u2502 144)              \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_2_project     \u2502 (None, 56, 56,    \u2502      3,456 \u2502 block_2_depthwis\u2026 \u2502\n\u2502 (Conv2D)            \u2502 24)               \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_2_project_BN  \u2502 (None, 56, 56,    \u2502         96 \u2502 block_2_project[\u2026 \u2502\n\u2502 (BatchNormalizatio\u2026 \u2502 24)               \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_2_add (Add)   \u2502 (None, 56, 56,    \u2502          0 \u2502 block_1_project_\u2026 \u2502\n\u2502                     \u2502 24)               \u2502            \u2502 block_2_project_\u2026 \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_3_expand      \u2502 (None, 56, 56,    \u2502      3,456 \u2502 block_2_add[0][0] \u2502\n\u2502 (Conv2D)            \u2502 144)              \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_3_expand_BN   \u2502 (None, 56, 56,    \u2502        576 \u2502 block_3_expand[0\u2026 \u2502\n\u2502 (BatchNormalizatio\u2026 \u2502 144)              \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_3_expand_relu \u2502 (None, 56, 56,    \u2502          0 \u2502 block_3_expand_B\u2026 \u2502\n\u2502 (ReLU)              \u2502 144)              \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_3_pad         \u2502 (None, 57, 57,    \u2502          0 \u2502 block_3_expand_r\u2026 \u2502\n\u2502 (ZeroPadding2D)     \u2502 144)              \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_3_depthwise   \u2502 (None, 28, 28,    \u2502      1,296 \u2502 block_3_pad[0][0] \u2502\n\u2502 (DepthwiseConv2D)   \u2502 144)              \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_3_depthwise_\u2026 \u2502 (None, 28, 28,    \u2502        576 \u2502 block_3_depthwis\u2026 \u2502\n\u2502 (BatchNormalizatio\u2026 \u2502 144)              \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_3_depthwise_\u2026 \u2502 (None, 28, 28,    \u2502          0 \u2502 block_3_depthwis\u2026 \u2502\n\u2502 (ReLU)              \u2502 144)              \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_3_project     \u2502 (None, 28, 28,    \u2502      4,608 \u2502 block_3_depthwis\u2026 \u2502\n\u2502 (Conv2D)            \u2502 32)               \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_3_project_BN  \u2502 (None, 28, 28,    \u2502        128 \u2502 block_3_project[\u2026 \u2502\n\u2502 (BatchNormalizatio\u2026 \u2502 32)               \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_4_expand      \u2502 (None, 28, 28,    \u2502      6,144 \u2502 block_3_project_\u2026 \u2502\n\u2502 (Conv2D)            \u2502 192)              \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_4_expand_BN   \u2502 (None, 28, 28,    \u2502        768 \u2502 block_4_expand[0\u2026 \u2502\n\u2502 (BatchNormalizatio\u2026 \u2502 192)              \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_4_expand_relu \u2502 (None, 28, 28,    \u2502          0 \u2502 block_4_expand_B\u2026 \u2502\n\u2502 (ReLU)              \u2502 192)              \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_4_depthwise   \u2502 (None, 28, 28,    \u2502      1,728 \u2502 block_4_expand_r\u2026 \u2502\n\u2502 (DepthwiseConv2D)   \u2502 192)              \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_4_depthwise_\u2026 \u2502 (None, 28, 28,    \u2502        768 \u2502 block_4_depthwis\u2026 \u2502\n\u2502 (BatchNormalizatio\u2026 \u2502 192)              \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_4_depthwise_\u2026 \u2502 (None, 28, 28,    \u2502          0 \u2502 block_4_depthwis\u2026 \u2502\n\u2502 (ReLU)              \u2502 192)              \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_4_project     \u2502 (None, 28, 28,    \u2502      6,144 \u2502 block_4_depthwis\u2026 \u2502\n\u2502 (Conv2D)            \u2502 32)               \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_4_project_BN  \u2502 (None, 28, 28,    \u2502        128 \u2502 block_4_project[\u2026 \u2502\n\u2502 (BatchNormalizatio\u2026 \u2502 32)               \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_4_add (Add)   \u2502 (None, 28, 28,    \u2502          0 \u2502 block_3_project_\u2026 \u2502\n\u2502                     \u2502 32)               \u2502            \u2502 block_4_project_\u2026 \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_5_expand      \u2502 (None, 28, 28,    \u2502      6,144 \u2502 block_4_add[0][0] \u2502\n\u2502 (Conv2D)            \u2502 192)              \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_5_expand_BN   \u2502 (None, 28, 28,    \u2502        768 \u2502 block_5_expand[0\u2026 \u2502\n\u2502 (BatchNormalizatio\u2026 \u2502 192)              \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_5_expand_relu \u2502 (None, 28, 28,    \u2502          0 \u2502 block_5_expand_B\u2026 \u2502\n\u2502 (ReLU)              \u2502 192)              \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_5_depthwise   \u2502 (None, 28, 28,    \u2502      1,728 \u2502 block_5_expand_r\u2026 \u2502\n\u2502 (DepthwiseConv2D)   \u2502 192)              \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_5_depthwise_\u2026 \u2502 (None, 28, 28,    \u2502        768 \u2502 block_5_depthwis\u2026 \u2502\n\u2502 (BatchNormalizatio\u2026 \u2502 192)              \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_5_depthwise_\u2026 \u2502 (None, 28, 28,    \u2502          0 \u2502 block_5_depthwis\u2026 \u2502\n\u2502 (ReLU)              \u2502 192)              \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_5_project     \u2502 (None, 28, 28,    \u2502      6,144 \u2502 block_5_depthwis\u2026 \u2502\n\u2502 (Conv2D)            \u2502 32)               \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_5_project_BN  \u2502 (None, 28, 28,    \u2502        128 \u2502 block_5_project[\u2026 \u2502\n\u2502 (BatchNormalizatio\u2026 \u2502 32)               \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_5_add (Add)   \u2502 (None, 28, 28,    \u2502          0 \u2502 block_4_add[0][0\u2026 \u2502\n\u2502                     \u2502 32)               \u2502            \u2502 block_5_project_\u2026 \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_6_expand      \u2502 (None, 28, 28,    \u2502      6,144 \u2502 block_5_add[0][0] \u2502\n\u2502 (Conv2D)            \u2502 192)              \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_6_expand_BN   \u2502 (None, 28, 28,    \u2502        768 \u2502 block_6_expand[0\u2026 \u2502\n\u2502 (BatchNormalizatio\u2026 \u2502 192)              \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_6_expand_relu \u2502 (None, 28, 28,    \u2502          0 \u2502 block_6_expand_B\u2026 \u2502\n\u2502 (ReLU)              \u2502 192)              \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_6_pad         \u2502 (None, 29, 29,    \u2502          0 \u2502 block_6_expand_r\u2026 \u2502\n\u2502 (ZeroPadding2D)     \u2502 192)              \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_6_depthwise   \u2502 (None, 14, 14,    \u2502      1,728 \u2502 block_6_pad[0][0] \u2502\n\u2502 (DepthwiseConv2D)   \u2502 192)              \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_6_depthwise_\u2026 \u2502 (None, 14, 14,    \u2502        768 \u2502 block_6_depthwis\u2026 \u2502\n\u2502 (BatchNormalizatio\u2026 \u2502 192)              \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_6_depthwise_\u2026 \u2502 (None, 14, 14,    \u2502          0 \u2502 block_6_depthwis\u2026 \u2502\n\u2502 (ReLU)              \u2502 192)              \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_6_project     \u2502 (None, 14, 14,    \u2502     12,288 \u2502 block_6_depthwis\u2026 \u2502\n\u2502 (Conv2D)            \u2502 64)               \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_6_project_BN  \u2502 (None, 14, 14,    \u2502        256 \u2502 block_6_project[\u2026 \u2502\n\u2502 (BatchNormalizatio\u2026 \u2502 64)               \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_7_expand      \u2502 (None, 14, 14,    \u2502     24,576 \u2502 block_6_project_\u2026 \u2502\n\u2502 (Conv2D)            \u2502 384)              \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_7_expand_BN   \u2502 (None, 14, 14,    \u2502      1,536 \u2502 block_7_expand[0\u2026 \u2502\n\u2502 (BatchNormalizatio\u2026 \u2502 384)              \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_7_expand_relu \u2502 (None, 14, 14,    \u2502          0 \u2502 block_7_expand_B\u2026 \u2502\n\u2502 (ReLU)              \u2502 384)              \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_7_depthwise   \u2502 (None, 14, 14,    \u2502      3,456 \u2502 block_7_expand_r\u2026 \u2502\n\u2502 (DepthwiseConv2D)   \u2502 384)              \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_7_depthwise_\u2026 \u2502 (None, 14, 14,    \u2502      1,536 \u2502 block_7_depthwis\u2026 \u2502\n\u2502 (BatchNormalizatio\u2026 \u2502 384)              \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_7_depthwise_\u2026 \u2502 (None, 14, 14,    \u2502          0 \u2502 block_7_depthwis\u2026 \u2502\n\u2502 (ReLU)              \u2502 384)              \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_7_project     \u2502 (None, 14, 14,    \u2502     24,576 \u2502 block_7_depthwis\u2026 \u2502\n\u2502 (Conv2D)            \u2502 64)               \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_7_project_BN  \u2502 (None, 14, 14,    \u2502        256 \u2502 block_7_project[\u2026 \u2502\n\u2502 (BatchNormalizatio\u2026 \u2502 64)               \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_7_add (Add)   \u2502 (None, 14, 14,    \u2502          0 \u2502 block_6_project_\u2026 \u2502\n\u2502                     \u2502 64)               \u2502            \u2502 block_7_project_\u2026 \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_8_expand      \u2502 (None, 14, 14,    \u2502     24,576 \u2502 block_7_add[0][0] \u2502\n\u2502 (Conv2D)            \u2502 384)              \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_8_expand_BN   \u2502 (None, 14, 14,    \u2502      1,536 \u2502 block_8_expand[0\u2026 \u2502\n\u2502 (BatchNormalizatio\u2026 \u2502 384)              \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_8_expand_relu \u2502 (None, 14, 14,    \u2502          0 \u2502 block_8_expand_B\u2026 \u2502\n\u2502 (ReLU)              \u2502 384)              \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_8_depthwise   \u2502 (None, 14, 14,    \u2502      3,456 \u2502 block_8_expand_r\u2026 \u2502\n\u2502 (DepthwiseConv2D)   \u2502 384)              \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_8_depthwise_\u2026 \u2502 (None, 14, 14,    \u2502      1,536 \u2502 block_8_depthwis\u2026 \u2502\n\u2502 (BatchNormalizatio\u2026 \u2502 384)              \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_8_depthwise_\u2026 \u2502 (None, 14, 14,    \u2502          0 \u2502 block_8_depthwis\u2026 \u2502\n\u2502 (ReLU)              \u2502 384)              \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_8_project     \u2502 (None, 14, 14,    \u2502     24,576 \u2502 block_8_depthwis\u2026 \u2502\n\u2502 (Conv2D)            \u2502 64)               \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_8_project_BN  \u2502 (None, 14, 14,    \u2502        256 \u2502 block_8_project[\u2026 \u2502\n\u2502 (BatchNormalizatio\u2026 \u2502 64)               \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_8_add (Add)   \u2502 (None, 14, 14,    \u2502          0 \u2502 block_7_add[0][0\u2026 \u2502\n\u2502                     \u2502 64)               \u2502            \u2502 block_8_project_\u2026 \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_9_expand      \u2502 (None, 14, 14,    \u2502     24,576 \u2502 block_8_add[0][0] \u2502\n\u2502 (Conv2D)            \u2502 384)              \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_9_expand_BN   \u2502 (None, 14, 14,    \u2502      1,536 \u2502 block_9_expand[0\u2026 \u2502\n\u2502 (BatchNormalizatio\u2026 \u2502 384)              \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_9_expand_relu \u2502 (None, 14, 14,    \u2502          0 \u2502 block_9_expand_B\u2026 \u2502\n\u2502 (ReLU)              \u2502 384)              \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_9_depthwise   \u2502 (None, 14, 14,    \u2502      3,456 \u2502 block_9_expand_r\u2026 \u2502\n\u2502 (DepthwiseConv2D)   \u2502 384)              \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_9_depthwise_\u2026 \u2502 (None, 14, 14,    \u2502      1,536 \u2502 block_9_depthwis\u2026 \u2502\n\u2502 (BatchNormalizatio\u2026 \u2502 384)              \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_9_depthwise_\u2026 \u2502 (None, 14, 14,    \u2502          0 \u2502 block_9_depthwis\u2026 \u2502\n\u2502 (ReLU)              \u2502 384)              \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_9_project     \u2502 (None, 14, 14,    \u2502     24,576 \u2502 block_9_depthwis\u2026 \u2502\n\u2502 (Conv2D)            \u2502 64)               \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_9_project_BN  \u2502 (None, 14, 14,    \u2502        256 \u2502 block_9_project[\u2026 \u2502\n\u2502 (BatchNormalizatio\u2026 \u2502 64)               \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_9_add (Add)   \u2502 (None, 14, 14,    \u2502          0 \u2502 block_8_add[0][0\u2026 \u2502\n\u2502                     \u2502 64)               \u2502            \u2502 block_9_project_\u2026 \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_10_expand     \u2502 (None, 14, 14,    \u2502     24,576 \u2502 block_9_add[0][0] \u2502\n\u2502 (Conv2D)            \u2502 384)              \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_10_expand_BN  \u2502 (None, 14, 14,    \u2502      1,536 \u2502 block_10_expand[\u2026 \u2502\n\u2502 (BatchNormalizatio\u2026 \u2502 384)              \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_10_expand_re\u2026 \u2502 (None, 14, 14,    \u2502          0 \u2502 block_10_expand_\u2026 \u2502\n\u2502 (ReLU)              \u2502 384)              \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_10_depthwise  \u2502 (None, 14, 14,    \u2502      3,456 \u2502 block_10_expand_\u2026 \u2502\n\u2502 (DepthwiseConv2D)   \u2502 384)              \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_10_depthwise\u2026 \u2502 (None, 14, 14,    \u2502      1,536 \u2502 block_10_depthwi\u2026 \u2502\n\u2502 (BatchNormalizatio\u2026 \u2502 384)              \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_10_depthwise\u2026 \u2502 (None, 14, 14,    \u2502          0 \u2502 block_10_depthwi\u2026 \u2502\n\u2502 (ReLU)              \u2502 384)              \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_10_project    \u2502 (None, 14, 14,    \u2502     36,864 \u2502 block_10_depthwi\u2026 \u2502\n\u2502 (Conv2D)            \u2502 96)               \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_10_project_BN \u2502 (None, 14, 14,    \u2502        384 \u2502 block_10_project\u2026 \u2502\n\u2502 (BatchNormalizatio\u2026 \u2502 96)               \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_11_expand     \u2502 (None, 14, 14,    \u2502     55,296 \u2502 block_10_project\u2026 \u2502\n\u2502 (Conv2D)            \u2502 576)              \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_11_expand_BN  \u2502 (None, 14, 14,    \u2502      2,304 \u2502 block_11_expand[\u2026 \u2502\n\u2502 (BatchNormalizatio\u2026 \u2502 576)              \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_11_expand_re\u2026 \u2502 (None, 14, 14,    \u2502          0 \u2502 block_11_expand_\u2026 \u2502\n\u2502 (ReLU)              \u2502 576)              \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_11_depthwise  \u2502 (None, 14, 14,    \u2502      5,184 \u2502 block_11_expand_\u2026 \u2502\n\u2502 (DepthwiseConv2D)   \u2502 576)              \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_11_depthwise\u2026 \u2502 (None, 14, 14,    \u2502      2,304 \u2502 block_11_depthwi\u2026 \u2502\n\u2502 (BatchNormalizatio\u2026 \u2502 576)              \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_11_depthwise\u2026 \u2502 (None, 14, 14,    \u2502          0 \u2502 block_11_depthwi\u2026 \u2502\n\u2502 (ReLU)              \u2502 576)              \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_11_project    \u2502 (None, 14, 14,    \u2502     55,296 \u2502 block_11_depthwi\u2026 \u2502\n\u2502 (Conv2D)            \u2502 96)               \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_11_project_BN \u2502 (None, 14, 14,    \u2502        384 \u2502 block_11_project\u2026 \u2502\n\u2502 (BatchNormalizatio\u2026 \u2502 96)               \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_11_add (Add)  \u2502 (None, 14, 14,    \u2502          0 \u2502 block_10_project\u2026 \u2502\n\u2502                     \u2502 96)               \u2502            \u2502 block_11_project\u2026 \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_12_expand     \u2502 (None, 14, 14,    \u2502     55,296 \u2502 block_11_add[0][\u2026 \u2502\n\u2502 (Conv2D)            \u2502 576)              \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_12_expand_BN  \u2502 (None, 14, 14,    \u2502      2,304 \u2502 block_12_expand[\u2026 \u2502\n\u2502 (BatchNormalizatio\u2026 \u2502 576)              \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_12_expand_re\u2026 \u2502 (None, 14, 14,    \u2502          0 \u2502 block_12_expand_\u2026 \u2502\n\u2502 (ReLU)              \u2502 576)              \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_12_depthwise  \u2502 (None, 14, 14,    \u2502      5,184 \u2502 block_12_expand_\u2026 \u2502\n\u2502 (DepthwiseConv2D)   \u2502 576)              \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_12_depthwise\u2026 \u2502 (None, 14, 14,    \u2502      2,304 \u2502 block_12_depthwi\u2026 \u2502\n\u2502 (BatchNormalizatio\u2026 \u2502 576)              \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_12_depthwise\u2026 \u2502 (None, 14, 14,    \u2502          0 \u2502 block_12_depthwi\u2026 \u2502\n\u2502 (ReLU)              \u2502 576)              \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_12_project    \u2502 (None, 14, 14,    \u2502     55,296 \u2502 block_12_depthwi\u2026 \u2502\n\u2502 (Conv2D)            \u2502 96)               \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_12_project_BN \u2502 (None, 14, 14,    \u2502        384 \u2502 block_12_project\u2026 \u2502\n\u2502 (BatchNormalizatio\u2026 \u2502 96)               \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_12_add (Add)  \u2502 (None, 14, 14,    \u2502          0 \u2502 block_11_add[0][\u2026 \u2502\n\u2502                     \u2502 96)               \u2502            \u2502 block_12_project\u2026 \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_13_expand     \u2502 (None, 14, 14,    \u2502     55,296 \u2502 block_12_add[0][\u2026 \u2502\n\u2502 (Conv2D)            \u2502 576)              \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_13_expand_BN  \u2502 (None, 14, 14,    \u2502      2,304 \u2502 block_13_expand[\u2026 \u2502\n\u2502 (BatchNormalizatio\u2026 \u2502 576)              \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_13_expand_re\u2026 \u2502 (None, 14, 14,    \u2502          0 \u2502 block_13_expand_\u2026 \u2502\n\u2502 (ReLU)              \u2502 576)              \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_13_pad        \u2502 (None, 15, 15,    \u2502          0 \u2502 block_13_expand_\u2026 \u2502\n\u2502 (ZeroPadding2D)     \u2502 576)              \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_13_depthwise  \u2502 (None, 7, 7, 576) \u2502      5,184 \u2502 block_13_pad[0][\u2026 \u2502\n\u2502 (DepthwiseConv2D)   \u2502                   \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_13_depthwise\u2026 \u2502 (None, 7, 7, 576) \u2502      2,304 \u2502 block_13_depthwi\u2026 \u2502\n\u2502 (BatchNormalizatio\u2026 \u2502                   \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_13_depthwise\u2026 \u2502 (None, 7, 7, 576) \u2502          0 \u2502 block_13_depthwi\u2026 \u2502\n\u2502 (ReLU)              \u2502                   \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_13_project    \u2502 (None, 7, 7, 160) \u2502     92,160 \u2502 block_13_depthwi\u2026 \u2502\n\u2502 (Conv2D)            \u2502                   \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_13_project_BN \u2502 (None, 7, 7, 160) \u2502        640 \u2502 block_13_project\u2026 \u2502\n\u2502 (BatchNormalizatio\u2026 \u2502                   \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_14_expand     \u2502 (None, 7, 7, 960) \u2502    153,600 \u2502 block_13_project\u2026 \u2502\n\u2502 (Conv2D)            \u2502                   \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_14_expand_BN  \u2502 (None, 7, 7, 960) \u2502      3,840 \u2502 block_14_expand[\u2026 \u2502\n\u2502 (BatchNormalizatio\u2026 \u2502                   \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_14_expand_re\u2026 \u2502 (None, 7, 7, 960) \u2502          0 \u2502 block_14_expand_\u2026 \u2502\n\u2502 (ReLU)              \u2502                   \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_14_depthwise  \u2502 (None, 7, 7, 960) \u2502      8,640 \u2502 block_14_expand_\u2026 \u2502\n\u2502 (DepthwiseConv2D)   \u2502                   \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_14_depthwise\u2026 \u2502 (None, 7, 7, 960) \u2502      3,840 \u2502 block_14_depthwi\u2026 \u2502\n\u2502 (BatchNormalizatio\u2026 \u2502                   \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_14_depthwise\u2026 \u2502 (None, 7, 7, 960) \u2502          0 \u2502 block_14_depthwi\u2026 \u2502\n\u2502 (ReLU)              \u2502                   \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_14_project    \u2502 (None, 7, 7, 160) \u2502    153,600 \u2502 block_14_depthwi\u2026 \u2502\n\u2502 (Conv2D)            \u2502                   \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_14_project_BN \u2502 (None, 7, 7, 160) \u2502        640 \u2502 block_14_project\u2026 \u2502\n\u2502 (BatchNormalizatio\u2026 \u2502                   \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_14_add (Add)  \u2502 (None, 7, 7, 160) \u2502          0 \u2502 block_13_project\u2026 \u2502\n\u2502                     \u2502                   \u2502            \u2502 block_14_project\u2026 \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_15_expand     \u2502 (None, 7, 7, 960) \u2502    153,600 \u2502 block_14_add[0][\u2026 \u2502\n\u2502 (Conv2D)            \u2502                   \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_15_expand_BN  \u2502 (None, 7, 7, 960) \u2502      3,840 \u2502 block_15_expand[\u2026 \u2502\n\u2502 (BatchNormalizatio\u2026 \u2502                   \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_15_expand_re\u2026 \u2502 (None, 7, 7, 960) \u2502          0 \u2502 block_15_expand_\u2026 \u2502\n\u2502 (ReLU)              \u2502                   \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_15_depthwise  \u2502 (None, 7, 7, 960) \u2502      8,640 \u2502 block_15_expand_\u2026 \u2502\n\u2502 (DepthwiseConv2D)   \u2502                   \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_15_depthwise\u2026 \u2502 (None, 7, 7, 960) \u2502      3,840 \u2502 block_15_depthwi\u2026 \u2502\n\u2502 (BatchNormalizatio\u2026 \u2502                   \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_15_depthwise\u2026 \u2502 (None, 7, 7, 960) \u2502          0 \u2502 block_15_depthwi\u2026 \u2502\n\u2502 (ReLU)              \u2502                   \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_15_project    \u2502 (None, 7, 7, 160) \u2502    153,600 \u2502 block_15_depthwi\u2026 \u2502\n\u2502 (Conv2D)            \u2502                   \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_15_project_BN \u2502 (None, 7, 7, 160) \u2502        640 \u2502 block_15_project\u2026 \u2502\n\u2502 (BatchNormalizatio\u2026 \u2502                   \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_15_add (Add)  \u2502 (None, 7, 7, 160) \u2502          0 \u2502 block_14_add[0][\u2026 \u2502\n\u2502                     \u2502                   \u2502            \u2502 block_15_project\u2026 \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_16_expand     \u2502 (None, 7, 7, 960) \u2502    153,600 \u2502 block_15_add[0][\u2026 \u2502\n\u2502 (Conv2D)            \u2502                   \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_16_expand_BN  \u2502 (None, 7, 7, 960) \u2502      3,840 \u2502 block_16_expand[\u2026 \u2502\n\u2502 (BatchNormalizatio\u2026 \u2502                   \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_16_expand_re\u2026 \u2502 (None, 7, 7, 960) \u2502          0 \u2502 block_16_expand_\u2026 \u2502\n\u2502 (ReLU)              \u2502                   \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_16_depthwise  \u2502 (None, 7, 7, 960) \u2502      8,640 \u2502 block_16_expand_\u2026 \u2502\n\u2502 (DepthwiseConv2D)   \u2502                   \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_16_depthwise\u2026 \u2502 (None, 7, 7, 960) \u2502      3,840 \u2502 block_16_depthwi\u2026 \u2502\n\u2502 (BatchNormalizatio\u2026 \u2502                   \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_16_depthwise\u2026 \u2502 (None, 7, 7, 960) \u2502          0 \u2502 block_16_depthwi\u2026 \u2502\n\u2502 (ReLU)              \u2502                   \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_16_project    \u2502 (None, 7, 7, 320) \u2502    307,200 \u2502 block_16_depthwi\u2026 \u2502\n\u2502 (Conv2D)            \u2502                   \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_16_project_BN \u2502 (None, 7, 7, 320) \u2502      1,280 \u2502 block_16_project\u2026 \u2502\n\u2502 (BatchNormalizatio\u2026 \u2502                   \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 Conv_1 (Conv2D)     \u2502 (None, 7, 7,      \u2502    409,600 \u2502 block_16_project\u2026 \u2502\n\u2502                     \u2502 1280)             \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 Conv_1_bn           \u2502 (None, 7, 7,      \u2502      5,120 \u2502 Conv_1[0][0]      \u2502\n\u2502 (BatchNormalizatio\u2026 \u2502 1280)             \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 out_relu (ReLU)     \u2502 (None, 7, 7,      \u2502          0 \u2502 Conv_1_bn[0][0]   \u2502\n\u2502                     \u2502 1280)             \u2502            \u2502                   \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</pre> <pre> Total params: 2,257,984 (8.61 MB)\n</pre> <pre> Trainable params: 0 (0.00 B)\n</pre> <pre> Non-trainable params: 2,257,984 (8.61 MB)\n</pre> In\u00a0[9]: Copied! <pre>#Camada  para gerar um vetor de 1280 elementos \nglobal_average_layer = layers.GlobalAveragePooling2D()\n\n# O Classificador para gato cachorro com 1 neuronio \nsaida_layer = layers.Dense(1, activation='sigmoid')\n</pre> #Camada  para gerar um vetor de 1280 elementos  global_average_layer = layers.GlobalAveragePooling2D()  # O Classificador para gato cachorro com 1 neuronio  saida_layer = layers.Dense(1, activation='sigmoid') In\u00a0[10]: Copied! <pre>model = tf.keras.Sequential([\n  base_model,   #### cnn mobilenet\n  global_average_layer, ###flatten\n  saida_layer ### especiallista\n])\n\nmodel.summary()\n</pre> model = tf.keras.Sequential([   base_model,   #### cnn mobilenet   global_average_layer, ###flatten   saida_layer ### especiallista ])  model.summary() <pre>Model: \"sequential\"\n</pre> <pre>\u250f\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2513\n\u2503 Layer (type)                    \u2503 Output Shape           \u2503       Param # \u2503\n\u2521\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2529\n\u2502 mobilenetv2_1.00_224            \u2502 ?                      \u2502     2,257,984 \u2502\n\u2502 (Functional)                    \u2502                        \u2502               \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 global_average_pooling2d        \u2502 ?                      \u2502   0 (unbuilt) \u2502\n\u2502 (GlobalAveragePooling2D)        \u2502                        \u2502               \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 dense (Dense)                   \u2502 ?                      \u2502   0 (unbuilt) \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</pre> <pre> Total params: 2,257,984 (8.61 MB)\n</pre> <pre> Trainable params: 0 (0.00 B)\n</pre> <pre> Non-trainable params: 2,257,984 (8.61 MB)\n</pre> <p>Pronto! J\u00e1 criamos a nossa rede para classifica\u00e7\u00e3o. Agora podemos treinar nossa rede e testar.</p> In\u00a0[11]: Copied! <pre>model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n</pre>  model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy']) In\u00a0[12]: Copied! <pre>#Avalia\u00e7\u00e3o do modelo antes de trein\u00e1-lo com novas imagens\nvalidation_steps=20\n\nloss0,accuracy0 = model.evaluate(train_generator, steps = validation_steps)\n</pre> #Avalia\u00e7\u00e3o do modelo antes de trein\u00e1-lo com novas imagens validation_steps=20  loss0,accuracy0 = model.evaluate(train_generator, steps = validation_steps) <pre>/Users/arnaldoalvesvianajunior/Library/Python/3.9/lib/python/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n  self._warn_if_super_not_called()\n</pre> <pre>20/20 \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 12s 532ms/step - accuracy: 0.4012 - loss: 0.8502\n</pre> In\u00a0[13]: Copied! <pre># Treinamento da nova CNN\n\nhistory = model.fit(train_generator, epochs=5, validation_data=validation_generator)\n</pre> # Treinamento da nova CNN  history = model.fit(train_generator, epochs=5, validation_data=validation_generator)  <pre>Epoch 1/5\n63/63 \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 57s 839ms/step - accuracy: 0.7936 - loss: 0.4272 - val_accuracy: 0.9800 - val_loss: 0.0941\nEpoch 2/5\n63/63 \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 51s 808ms/step - accuracy: 0.9750 - loss: 0.0902 - val_accuracy: 0.9820 - val_loss: 0.0717\nEpoch 3/5\n63/63 \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 51s 799ms/step - accuracy: 0.9825 - loss: 0.0656 - val_accuracy: 0.9830 - val_loss: 0.0602\nEpoch 4/5\n63/63 \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 50s 801ms/step - accuracy: 0.9880 - loss: 0.0511 - val_accuracy: 0.9840 - val_loss: 0.0511\nEpoch 5/5\n63/63 \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 50s 794ms/step - accuracy: 0.9904 - loss: 0.0442 - val_accuracy: 0.9830 - val_loss: 0.0503\n</pre> In\u00a0[14]: Copied! <pre>import pandas as pd\n\nmetrics_df = pd.DataFrame(history.history)\nmetrics_df[[\"loss\",\"val_loss\"]].plot();\nmetrics_df[[\"accuracy\", \"val_accuracy\"]].plot();\n</pre> import pandas as pd  metrics_df = pd.DataFrame(history.history) metrics_df[[\"loss\",\"val_loss\"]].plot(); metrics_df[[\"accuracy\", \"val_accuracy\"]].plot(); In\u00a0[16]: Copied! <pre>import numpy as np\nfrom tensorflow.keras.preprocessing import image\n\ndef predict_cat_or_dog(img_path):\n    img = image.load_img(img_path, target_size=image_size)\n    img_array = image.img_to_array(img)\n    img_array = np.expand_dims(img_array, axis=0)\n    img_array = preprocess_input(img_array)\n\n    prediction = model.predict(img_array)\n    \n    if prediction[0][0] &lt; 0.5:\n        return \"gatinhooooo\"\n    else:\n        return \"cachorrinho\"\n\n# Teste a fun\u00e7\u00e3o de previs\u00e3o com uma imagem\n\n# !wget https://uploads.metropoles.com/wp-content/uploads/2022/07/21154234/como-identificar-que-um-cachorro-esta-sendo-vitima-de-maus-tratos-1.jpg -O /content/cachorro.jpg\n# img_path = \"cachorro.jpg\"\nimg_path = \"dog.png\"\n\nresult = predict_cat_or_dog(img_path)\nprint(\"Essa foto \u00e9 de um \", result)\n</pre> import numpy as np from tensorflow.keras.preprocessing import image  def predict_cat_or_dog(img_path):     img = image.load_img(img_path, target_size=image_size)     img_array = image.img_to_array(img)     img_array = np.expand_dims(img_array, axis=0)     img_array = preprocess_input(img_array)      prediction = model.predict(img_array)          if prediction[0][0] &lt; 0.5:         return \"gatinhooooo\"     else:         return \"cachorrinho\"  # Teste a fun\u00e7\u00e3o de previs\u00e3o com uma imagem  # !wget https://uploads.metropoles.com/wp-content/uploads/2022/07/21154234/como-identificar-que-um-cachorro-esta-sendo-vitima-de-maus-tratos-1.jpg -O /content/cachorro.jpg # img_path = \"cachorro.jpg\" img_path = \"dog.png\"  result = predict_cat_or_dog(img_path) print(\"Essa foto \u00e9 de um \", result) <pre>1/1 \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 1s 899ms/step\nEssa foto \u00e9 de um  cachorrinho\n</pre> In\u00a0[\u00a0]: Copied! <pre># Salvando a rede \nmodel.save(\"dogs_vs_cats.h5\")\n\n#Carregando uma rede .h5\nnew_model = models.load_model('dogs_vs_cats.h5')\n</pre> # Salvando a rede  model.save(\"dogs_vs_cats.h5\")  #Carregando uma rede .h5 new_model = models.load_model('dogs_vs_cats.h5') In\u00a0[\u00a0]: Copied! <pre>### Seu c\u00f3digo aqui....\n</pre> ### Seu c\u00f3digo aqui...."},{"location":"aulas/IA/lab09/transferlearning_2.html#2-redes-neurais","title":"2. Redes Neurais\u00b6","text":""},{"location":"aulas/IA/lab09/transferlearning_2.html#objetivos","title":"Objetivos\u00b6","text":"<ul> <li>Conhecer e praticar Aprendizagem por transfer\u00eancia</li> <li>Praticar a classifica\u00e7\u00e3o de objeto usando framework TensorFlow</li> </ul>"},{"location":"aulas/IA/lab09/transferlearning_2.html#introducao-ao-transfer-learning-com-redes-pre-treinadas","title":"Introdu\u00e7\u00e3o ao Transfer Learning com redes pr\u00e9-treinadas\u00b6","text":"<p>Excelente! Agora que j\u00e1 sabemos como utilizar uma rede pr\u00e9-treinada, vamos explorar uma t\u00e9cnica poderosa chamada Transfer Learning (Aprendizagem por Transfer\u00eancia). Essa abordagem nos permite tirar proveito das arquiteturas de redes neurais existentes e trein\u00e1-las para classificar objetos personalizados ou novas categorias de imagens.</p> <p>O Transfer Learning \u00e9 uma t\u00e9cnica em que um modelo de aprendizado profundo, treinado previamente em um conjunto de dados maior e mais diversificado, \u00e9 adaptado para ser aplicado a um novo problema. O conhecimento adquirido pelo modelo original \u00e9 transferido para o novo problema, permitindo um treinamento mais r\u00e1pido e, muitas vezes, um desempenho melhor do que treinar uma rede neural do zero.</p> <p>A ideia por tr\u00e1s do Transfer Learning \u00e9 que as redes neurais pr\u00e9-treinadas, como VGG, ResNet e Inception, j\u00e1 aprenderam a <code>extrair caracter\u00edsticas</code> importantes das imagens em seus primeiros est\u00e1gios. Essas caracter\u00edsticas podem ser comuns a muitos problemas de classifica\u00e7\u00e3o de imagens, como detec\u00e7\u00e3o de bordas, texturas e padr\u00f5es. Ao aproveitar esse conhecimento pr\u00e9vio, podemos nos concentrar no treinamento das \u00faltimas camadas do modelo, que s\u00e3o respons\u00e1veis por aprender caracter\u00edsticas espec\u00edficas do novo problema.</p> <p>Ao utilizar o Transfer Learning, podemos economizar tempo e recursos computacionais, al\u00e9m de obter melhores resultados do que treinar uma rede do zero para um conjunto de dados menor e espec\u00edfico. Portanto, \u00e9 uma t\u00e9cnica amplamente utilizada em aplica\u00e7\u00f5es pr\u00e1ticas de aprendizado profundo e processamento de imagens.</p>"},{"location":"aulas/IA/lab09/transferlearning_2.html#combinando-a-rede-pre-treinada-com-um-classificador-mlp","title":"Combinando a rede pr\u00e9-treinada com um classificador MLP\u00b6","text":"<p>Ao aplicar o Transfer Learning, nossa rede convolucional ser\u00e1 composta por duas partes principais: o extrator de caracter\u00edsticas e o classificador. O extrator de caracter\u00edsticas ser\u00e1 baseado em uma rede pr\u00e9-treinada, como VGG16, ResNet50 ou InceptionV3. Essa parte da rede j\u00e1 aprendeu a extrair caracter\u00edsticas relevantes de imagens, como bordas, texturas e padr\u00f5es, durante o treinamento em um grande conjunto de dados, como o ImageNet.</p> <p>Em seguida, adicionaremos um classificador MLP (Multilayer Perceptron) personalizado para resolver o nosso problema espec\u00edfico de classifica\u00e7\u00e3o de imagens. Esse classificador ser\u00e1 respons\u00e1vel por aprender as caracter\u00edsticas espec\u00edficas do novo conjunto de dados e classificar as imagens nas categorias desejadas.</p> <p>Dessa forma, a rede ajustada combina o poder das redes pr\u00e9-treinadas, que j\u00e1 aprenderam a extrair caracter\u00edsticas gerais de imagens, com um classificador personalizado que aprender\u00e1 a distinguir as categorias espec\u00edficas do nosso problema. Como mostra a figura abaixo:</p> <p></p> <p>Agora que entendemos os conceitos b\u00e1sicos de Transfer Learning, podemos prosseguir com os passos para aplicar o Transfer Learning e adaptar a rede pr\u00e9-treinada ao nosso problema de classifica\u00e7\u00e3o de imagens.</p>"},{"location":"aulas/IA/lab09/transferlearning_2.html#passo-a-passo-para-aplicar-transfer-learning","title":"Passo a passo para aplicar Transfer Learning\u00b6","text":"<ol> <li><p>Escolha uma rede pr\u00e9-treinada: Selecione uma rede neural pr\u00e9-treinada dispon\u00edvel no Keras (por exemplo, VGG16, ResNet50, InceptionV3) com base nas caracter\u00edsticas e requisitos do seu problema. Cada arquitetura tem suas pr\u00f3prias vantagens e desvantagens, portanto, escolha aquela que melhor se adapta \u00e0s suas necessidades.</p> </li> <li><p>Remova a camada de classifica\u00e7\u00e3o: Carregue a rede neural pr\u00e9-treinada sem a camada de classifica\u00e7\u00e3o final. Isso pode ser feito usando o argumento include_top=False ao carregar o modelo no Keras. Isso permitir\u00e1 que voc\u00ea adicione suas pr\u00f3prias camadas personalizadas para classificar as novas categorias.</p> </li> <li><p>Adicione camadas personalizadas: Adicione camadas espec\u00edficas para o seu problema de classifica\u00e7\u00e3o. Normalmente, isso inclui uma camada de GlobalAveragePooling2D, seguida por uma camada densa com uma fun\u00e7\u00e3o de ativa\u00e7\u00e3o softmax e o n\u00famero de neuronios igual ao n\u00famero de classes do novo problema.</p> </li> <li><p>Congele as camadas pr\u00e9-treinadas: \u00c9 uma boa pr\u00e1tica congelar as camadas pr\u00e9-treinadas da rede neural, especialmente durante as primeiras \u00e9pocas do treinamento. Isso evitar\u00e1 que os pesos dessas camadas sejam atualizados e preservar\u00e1 o conhecimento pr\u00e9vio que elas possuem. No Keras, voc\u00ea pode fazer isso com o modelxxx.trainable = False</p> </li> <li><p>Pr\u00e9-processamento dos dados: Prepare os dados de acordo com a rede pr\u00e9-treinada escolhida. Isso inclui redimensionar as imagens, normalizar os valores dos pixels e codificar as etiquetas das categorias. Lembre-se de aplicar as mesmas transforma\u00e7\u00f5es usadas no conjunto de dados original da rede pr\u00e9-treinada.</p> </li> <li><p>Treine o modelo: Treine o modelo ajustado no seu conjunto de dados. Durante as primeiras \u00e9pocas, com as camadas pr\u00e9-treinadas congeladas, o modelo aprender\u00e1 as caracter\u00edsticas espec\u00edficas do novo problema.</p> </li> <li><p>Avalie e otimize: Avalie o desempenho do modelo ajustado em um conjunto de teste e otimize os hiperpar\u00e2metros conforme necess\u00e1rio. Voc\u00ea pode experimentar diferentes arquiteturas de redes neurais, taxas de aprendizado, otimizadores e outros hiperpar\u00e2metros para encontrar a melhor configura\u00e7\u00e3o para o seu problema.</p> </li> </ol>"},{"location":"aulas/IA/lab09/transferlearning_2.html#aplicando-transfer-learning-em-um-dataset-ja-preparado-pelo-tensorflow","title":"Aplicando transfer learning em um dataset j\u00e1 preparado pelo tensorflow\u00b6","text":"<p>Vamos usar o dataset <code>cats_vs_dogs</code> que \u00e9 disponibilizado pelo proprio tensorflow, desta forma focamos apenas no entendimento da tecnica de transfer learning e menos em preprocessamento e cria\u00e7\u00e3o de dados. nas proximas aulas vamos criar nosso proprio dataset...</p>"},{"location":"aulas/IA/lab09/transferlearning_2.html#escolhendo-um-modelo-pre-treinado","title":"Escolhendo um modelo pr\u00e9-treinado\u00b6","text":"<p>A <code>MobileNet V2</code> desenvolvido no Google e foi treinado com <code>1,4 milh\u00e3o de imagens</code> e possui <code>1000 classes diferentes</code> com pesos predeterminados do imagenet (Googles dataset).</p> <p>Carregue a rede neural pr\u00e9-treinada sem a camada de classifica\u00e7\u00e3o final. Isso pode ser feito usando o argumento <code>include_top=False</code></p>"},{"location":"aulas/IA/lab09/transferlearning_2.html#adicionando-um-classificador","title":"Adicionando um Classificador\u00b6","text":""},{"location":"aulas/IA/lab09/transferlearning_2.html#desafio-2","title":"Desafio 2\u00b6","text":"<p>Vamos entender o que acabamos de fazer. Avalie a quantidade de parametros total, treinaveis e n\u00e3o treinaveis. O que foi identificado?</p>"},{"location":"aulas/IA/lab09/transferlearning_2.html#sua-resposta-aqui","title":"sua resposta aqui.....\u00b6","text":"<p>.</p>"},{"location":"aulas/IA/lab09/transferlearning_2.html#treinamento-do-modelo","title":"Treinamento do modelo\u00b6","text":""},{"location":"aulas/IA/lab09/transferlearning_2.html#fazendo-predicoes","title":"Fazendo predi\u00e7\u00f5es\u00b6","text":""},{"location":"aulas/IA/lab09/transferlearning_2.html#salvando-o-modelo-da-rede-treinada","title":"Salvando o modelo da rede treinada\u00b6","text":"<p>Agora que j\u00e1 temos um modelo treinado e ajustado para resolver o problema especifico que temos, podemos salver a arquitetura e os pesos em um arquivo com extens\u00e3o .h5</p> <p>para usar esta rede, basta carregar o arquivo.h5</p>"},{"location":"aulas/IA/lab09/transferlearning_2.html#desafio-3","title":"Desafio 3\u00b6","text":"<p>Aplicar o Transfer Learning usando a rede pr\u00e9-treinada ResNet50 e o conjunto de dados CIFAR-10, que possui 10 classes de objetos.</p>"},{"location":"aulas/IA/lab10/data-augmentation.html","title":"Lab03 - Data Augmentation","text":"In\u00a0[1]: Copied! <pre># Carrega os dados\nfrom keras.datasets import cifar10\n\n(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n</pre> # Carrega os dados from keras.datasets import cifar10  (x_train, y_train), (x_test, y_test) = cifar10.load_data() In\u00a0[2]: Copied! <pre>import matplotlib.pyplot as plt\n\nclass_names = ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n\n# Fun\u00e7\u00e3o para exibir imagens do conjunto de dados\ndef show_images(images, labels, n_rows=2, n_cols=5):\n    fig, axes = plt.subplots(n_rows, n_cols, figsize=(10, 4))\n    for i, ax in enumerate(axes.flat):\n        ax.imshow(images[i])\n        ax.set_title(class_names[labels[i][0]])\n        ax.axis('off')\n    plt.show()\n\nshow_images(x_train, y_train)\n</pre> import matplotlib.pyplot as plt  class_names = ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']  # Fun\u00e7\u00e3o para exibir imagens do conjunto de dados def show_images(images, labels, n_rows=2, n_cols=5):     fig, axes = plt.subplots(n_rows, n_cols, figsize=(10, 4))     for i, ax in enumerate(axes.flat):         ax.imshow(images[i])         ax.set_title(class_names[labels[i][0]])         ax.axis('off')     plt.show()  show_images(x_train, y_train) <p>No Keras usamos o pacote <code>ImageDataGenerator</code>.</p> <p>A partir dele vamos aplicar v\u00e1rias transforma\u00e7\u00f5es nas imagens do conjunto de dados durante o treinamento do modelo.</p> <p><code>rotation_range</code> = 15</p> <ul> <li>Isso permitir\u00e1 que as imagens sejam rotacionadas aleatoriamente em um intervalo de at\u00e9 \u00b115 graus.</li> </ul> <p><code>width_shift_range</code> = 0.1</p> <ul> <li>Este par\u00e2metro permite que as imagens sejam deslocadas horizontalmente. O valor 0.1 significa que a imagem pode ser deslocada aleatoriamente at\u00e9 10% de sua largura.</li> </ul> <p><code>height_shift_range</code> = 0.1</p> <ul> <li>Similar ao par\u00e2metro anterior, mas para deslocamento vertical. As imagens podem ser deslocadas aleatoriamente at\u00e9 10% de sua altura.</li> </ul> <p><code>shear_range</code> = 0.1</p> <ul> <li>Este par\u00e2metro permite que uma distor\u00e7\u00e3o de cisalhamento seja aplicada \u00e0s imagens. Um cisalhamento \u00e9 uma transforma\u00e7\u00e3o que desliza uma parte da imagem em uma dire\u00e7\u00e3o, enquanto a outra parte \u00e9 deslizada na dire\u00e7\u00e3o oposta. O valor 0.1 indica a intensidade do cisalhamento.</li> </ul> <p><code>zoom_range</code> = 0.1</p> <ul> <li>Isso permite que as imagens sejam ampliadas ou reduzidas aleatoriamente. O valor 0.1 indica que o zoom pode variar de 0,9 (zoom out) a 1,1 (zoom in).</li> </ul> <p><code>horizontal_flip</code> = True</p> <ul> <li>Isso permite que as imagens sejam espelhadas horizontalmente (ou seja, invertidas de esquerda para direita) com uma probabilidade de 50%.</li> </ul> <p><code>fill_mode</code> = 'nearest'</p> <ul> <li>Durante transforma\u00e7\u00f5es como rota\u00e7\u00e3o ou deslocamento, podem aparecer alguns pixels vazios na imagem. O fill_mode determina como preencher esses pixels. O valor 'nearest' significa que ele usar\u00e1 o valor do pixel mais pr\u00f3ximo para preencher os pixels vazios.</li> </ul> <p><code>rescale</code> = 1./255</p> <ul> <li>Este \u00e9 um passo importante de pr\u00e9-processamento. As imagens geralmente t\u00eam valores de pixel no intervalo [0, 255]. Este par\u00e2metro ir\u00e1 reescalar esses valores para o intervalo [0, 1], dividindo cada pixel por 255. Isso \u00e9 comumente feito para facilitar a converg\u00eancia durante o treinamento de redes neurais.</li> </ul> <p>Existem outros parametros e n\u00e3o \u00e9 obrigat\u00f3rio o uso de todos s\u00e3o necess\u00e1rios, vai depender do problema que est\u00e1 sendo atacado.</p> In\u00a0[6]: Copied! <pre>from tensorflow.keras.preprocessing.image import ImageDataGenerator\n\ndata_gen = ImageDataGenerator(\n    rotation_range=15,          # Rotaciona as imagens em at\u00e9 15 graus\n    width_shift_range=0.1,      # Desloca as imagens horizontalmente em at\u00e9 10%\n    height_shift_range=0.1,     # Desloca as imagens verticalmente em at\u00e9 10%\n    shear_range=0.1,            # Aplica cisalhamento\n    zoom_range=0.1,             # Aplica zoom\n    horizontal_flip=True,       # Inverte as imagens horizontalmente\n    fill_mode='nearest',        # Preenche os pixels vazios ap\u00f3s transforma\u00e7\u00f5es\n    rescale=1./255)             # Normaliza os valores dos pixels para o intervalo [0, 1]\n</pre> from tensorflow.keras.preprocessing.image import ImageDataGenerator  data_gen = ImageDataGenerator(     rotation_range=15,          # Rotaciona as imagens em at\u00e9 15 graus     width_shift_range=0.1,      # Desloca as imagens horizontalmente em at\u00e9 10%     height_shift_range=0.1,     # Desloca as imagens verticalmente em at\u00e9 10%     shear_range=0.1,            # Aplica cisalhamento     zoom_range=0.1,             # Aplica zoom     horizontal_flip=True,       # Inverte as imagens horizontalmente     fill_mode='nearest',        # Preenche os pixels vazios ap\u00f3s transforma\u00e7\u00f5es     rescale=1./255)             # Normaliza os valores dos pixels para o intervalo [0, 1]  In\u00a0[\u00a0]: Copied! <pre>\n</pre> In\u00a0[7]: Copied! <pre>import numpy as np\n\ndef show_augmented_images(data_gen, image, label, n_rows=2, n_cols=5):\n    fig, axes = plt.subplots(n_rows, n_cols, figsize=(10, 4))\n    img_iterator = data_gen.flow(np.array([image]), np.array([label]))\n\n    for i, ax in enumerate(axes.flat):\n        img, lbl = next(img_iterator)\n        ax.imshow(img[0])\n        ax.set_title(class_names[lbl[0].item()])\n        ax.axis('off')\n    plt.show()\n\n\n# Selecionar uma imagem do conjunto de dados\nimage_index = 0\nimage = x_train[image_index]\nlabel = y_train[image_index]\n\n# Exibir imagens aumentadas\nshow_augmented_images(data_gen, image, label)\n</pre> import numpy as np  def show_augmented_images(data_gen, image, label, n_rows=2, n_cols=5):     fig, axes = plt.subplots(n_rows, n_cols, figsize=(10, 4))     img_iterator = data_gen.flow(np.array([image]), np.array([label]))      for i, ax in enumerate(axes.flat):         img, lbl = next(img_iterator)         ax.imshow(img[0])         ax.set_title(class_names[lbl[0].item()])         ax.axis('off')     plt.show()   # Selecionar uma imagem do conjunto de dados image_index = 0 image = x_train[image_index] label = y_train[image_index]  # Exibir imagens aumentadas show_augmented_images(data_gen, image, label)  <p>Note nas varia\u00e7\u00f5es criadas a partir de uma \u00fanica imagem.</p> In\u00a0[8]: Copied! <pre>from keras.models import Model\nfrom keras.layers import Input, Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n\n# Defini\u00e7\u00e3o da entrada\ninputs = Input(shape=(32, 32, 3))\n\n# Bloco convolucional 1\nx = Conv2D(32, (3, 3), activation='relu')(inputs)\nx = MaxPooling2D(pool_size=(2, 2))(x)\n\n# Bloco convolucional 2\nx = Conv2D(64, (3, 3), activation='relu')(x)\nx = MaxPooling2D(pool_size=(2, 2))(x)\n\n# Flatten + densas\nx = Flatten()(x)\nx = Dense(512, activation='relu')(x)\nx = Dropout(0.5)(x)\n\n# Sa\u00edda (10 classes)\noutputs = Dense(10, activation='softmax')(x)\n\n# Cria\u00e7\u00e3o do modelo funcional\nmodel = Model(inputs=inputs, outputs=outputs)\n\n# Compila\u00e7\u00e3o\nmodel.compile(loss='sparse_categorical_crossentropy',\n              optimizer='adam',\n              metrics=['accuracy'])\n\n# Resumo da arquitetura\nmodel.summary()\n</pre> from keras.models import Model from keras.layers import Input, Conv2D, MaxPooling2D, Flatten, Dense, Dropout  # Defini\u00e7\u00e3o da entrada inputs = Input(shape=(32, 32, 3))  # Bloco convolucional 1 x = Conv2D(32, (3, 3), activation='relu')(inputs) x = MaxPooling2D(pool_size=(2, 2))(x)  # Bloco convolucional 2 x = Conv2D(64, (3, 3), activation='relu')(x) x = MaxPooling2D(pool_size=(2, 2))(x)  # Flatten + densas x = Flatten()(x) x = Dense(512, activation='relu')(x) x = Dropout(0.5)(x)  # Sa\u00edda (10 classes) outputs = Dense(10, activation='softmax')(x)  # Cria\u00e7\u00e3o do modelo funcional model = Model(inputs=inputs, outputs=outputs)  # Compila\u00e7\u00e3o model.compile(loss='sparse_categorical_crossentropy',               optimizer='adam',               metrics=['accuracy'])  # Resumo da arquitetura model.summary()  <pre>Model: \"functional\"\n</pre> <pre>\u250f\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2513\n\u2503 Layer (type)                    \u2503 Output Shape           \u2503       Param # \u2503\n\u2521\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2529\n\u2502 input_layer (InputLayer)        \u2502 (None, 32, 32, 3)      \u2502             0 \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 conv2d (Conv2D)                 \u2502 (None, 30, 30, 32)     \u2502           896 \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 max_pooling2d (MaxPooling2D)    \u2502 (None, 15, 15, 32)     \u2502             0 \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 conv2d_1 (Conv2D)               \u2502 (None, 13, 13, 64)     \u2502        18,496 \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 max_pooling2d_1 (MaxPooling2D)  \u2502 (None, 6, 6, 64)       \u2502             0 \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 flatten (Flatten)               \u2502 (None, 2304)           \u2502             0 \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 dense (Dense)                   \u2502 (None, 512)            \u2502     1,180,160 \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 dropout (Dropout)               \u2502 (None, 512)            \u2502             0 \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 dense_1 (Dense)                 \u2502 (None, 10)             \u2502         5,130 \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</pre> <pre> Total params: 1,204,682 (4.60 MB)\n</pre> <pre> Trainable params: 1,204,682 (4.60 MB)\n</pre> <pre> Non-trainable params: 0 (0.00 B)\n</pre> In\u00a0[9]: Copied! <pre># Definir o n\u00famero de imagens aumentadas por imagem original\naugmentation_factor = 5\n\n# Criar listas vazias para armazenar as imagens e r\u00f3tulos aumentados\nx_train_augmented = []\ny_train_augmented = []\n\n# Aplicar a augmenta\u00e7\u00e3o de dados\nfor img, lbl in zip(x_train, y_train):\n    x_train_augmented.append(img)  # Adicionar a imagem original\n    y_train_augmented.append(lbl)  # Adicionar o r\u00f3tulo original\n\n    for _ in range(augmentation_factor - 1):\n        # Gerar uma imagem aumentada\n        augmented_img = data_gen.random_transform(img)\n\n        # Adicionar a imagem e o r\u00f3tulo aumentado \u00e0s listas\n        x_train_augmented.append(augmented_img)\n        y_train_augmented.append(lbl)\n\n# Converter as listas em arrays numpy\nx_train_augmented = np.array(x_train_augmented)\ny_train_augmented = np.array(y_train_augmented)\n\n# Normalizar as imagens\nx_train_augmented = x_train_augmented / 255.0\n</pre> # Definir o n\u00famero de imagens aumentadas por imagem original augmentation_factor = 5  # Criar listas vazias para armazenar as imagens e r\u00f3tulos aumentados x_train_augmented = [] y_train_augmented = []  # Aplicar a augmenta\u00e7\u00e3o de dados for img, lbl in zip(x_train, y_train):     x_train_augmented.append(img)  # Adicionar a imagem original     y_train_augmented.append(lbl)  # Adicionar o r\u00f3tulo original      for _ in range(augmentation_factor - 1):         # Gerar uma imagem aumentada         augmented_img = data_gen.random_transform(img)          # Adicionar a imagem e o r\u00f3tulo aumentado \u00e0s listas         x_train_augmented.append(augmented_img)         y_train_augmented.append(lbl)  # Converter as listas em arrays numpy x_train_augmented = np.array(x_train_augmented) y_train_augmented = np.array(y_train_augmented)  # Normalizar as imagens x_train_augmented = x_train_augmented / 255.0  In\u00a0[10]: Copied! <pre>## seu c\u00f3digo aqui....\n</pre> ## seu c\u00f3digo aqui....     <pre>Tamanho do conjunto de dados original: 50000 imagens\nTamanho do conjunto de dados aumentado: 250000 imagens\n</pre> In\u00a0[12]: Copied! <pre>batch_size = 64\nsteps_per_epoch = len(x_train) // batch_size\n\nhistory = model.fit(data_gen.flow(x_train, y_train, batch_size=batch_size),\n                              steps_per_epoch=steps_per_epoch,\n                              epochs=20,\n                              validation_data=(x_test / 255, y_test))\n</pre> batch_size = 64 steps_per_epoch = len(x_train) // batch_size  history = model.fit(data_gen.flow(x_train, y_train, batch_size=batch_size),                               steps_per_epoch=steps_per_epoch,                               epochs=20,                               validation_data=(x_test / 255, y_test))  <pre>Epoch 1/20\n</pre> <pre>/Users/arnaldoalvesvianajunior/cognitivecomputing/.venv/lib/python3.12/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n  self._warn_if_super_not_called()\n</pre> <pre>476/781 \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 15s 51ms/step - accuracy: 0.3018 - loss: 1.8932</pre> <pre>\n---------------------------------------------------------------------------\nKeyboardInterrupt                         Traceback (most recent call last)\nCell In[12], line 4\n      1 batch_size = 64\n      2 steps_per_epoch = len(x_train) // batch_size\n----&gt; 4 history = model.fit(data_gen.flow(x_train, y_train, batch_size=batch_size),\n      5                               steps_per_epoch=steps_per_epoch,\n      6                               epochs=20,\n      7                               validation_data=(x_test / 255, y_test))\n\nFile ~/cognitivecomputing/.venv/lib/python3.12/site-packages/keras/src/utils/traceback_utils.py:117, in filter_traceback.&lt;locals&gt;.error_handler(*args, **kwargs)\n    115 filtered_tb = None\n    116 try:\n--&gt; 117     return fn(*args, **kwargs)\n    118 except Exception as e:\n    119     filtered_tb = _process_traceback_frames(e.__traceback__)\n\nFile ~/cognitivecomputing/.venv/lib/python3.12/site-packages/keras/src/backend/tensorflow/trainer.py:377, in TensorFlowTrainer.fit(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\n    375 for begin_step, end_step, iterator in epoch_iterator:\n    376     callbacks.on_train_batch_begin(begin_step)\n--&gt; 377     logs = self.train_function(iterator)\n    378     callbacks.on_train_batch_end(end_step, logs)\n    379     if self.stop_training:\n\nFile ~/cognitivecomputing/.venv/lib/python3.12/site-packages/keras/src/backend/tensorflow/trainer.py:220, in TensorFlowTrainer._make_function.&lt;locals&gt;.function(iterator)\n    216 def function(iterator):\n    217     if isinstance(\n    218         iterator, (tf.data.Iterator, tf.distribute.DistributedIterator)\n    219     ):\n--&gt; 220         opt_outputs = multi_step_on_iterator(iterator)\n    221         if not opt_outputs.has_value():\n    222             raise StopIteration\n\nFile ~/cognitivecomputing/.venv/lib/python3.12/site-packages/tensorflow/python/util/traceback_utils.py:150, in filter_traceback.&lt;locals&gt;.error_handler(*args, **kwargs)\n    148 filtered_tb = None\n    149 try:\n--&gt; 150   return fn(*args, **kwargs)\n    151 except Exception as e:\n    152   filtered_tb = _process_traceback_frames(e.__traceback__)\n\nFile ~/cognitivecomputing/.venv/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:833, in Function.__call__(self, *args, **kwds)\n    830 compiler = \"xla\" if self._jit_compile else \"nonXla\"\n    832 with OptionalXlaContext(self._jit_compile):\n--&gt; 833   result = self._call(*args, **kwds)\n    835 new_tracing_count = self.experimental_get_tracing_count()\n    836 without_tracing = (tracing_count == new_tracing_count)\n\nFile ~/cognitivecomputing/.venv/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:878, in Function._call(self, *args, **kwds)\n    875 self._lock.release()\n    876 # In this case we have not created variables on the first call. So we can\n    877 # run the first trace but we should fail if variables are created.\n--&gt; 878 results = tracing_compilation.call_function(\n    879     args, kwds, self._variable_creation_config\n    880 )\n    881 if self._created_variables:\n    882   raise ValueError(\"Creating variables on a non-first call to a function\"\n    883                    \" decorated with tf.function.\")\n\nFile ~/cognitivecomputing/.venv/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:139, in call_function(args, kwargs, tracing_options)\n    137 bound_args = function.function_type.bind(*args, **kwargs)\n    138 flat_inputs = function.function_type.unpack_inputs(bound_args)\n--&gt; 139 return function._call_flat(  # pylint: disable=protected-access\n    140     flat_inputs, captured_inputs=function.captured_inputs\n    141 )\n\nFile ~/cognitivecomputing/.venv/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py:1322, in ConcreteFunction._call_flat(self, tensor_inputs, captured_inputs)\n   1318 possible_gradient_type = gradients_util.PossibleTapeGradientTypes(args)\n   1319 if (possible_gradient_type == gradients_util.POSSIBLE_GRADIENT_TYPES_NONE\n   1320     and executing_eagerly):\n   1321   # No tape is watching; skip to running the function.\n-&gt; 1322   return self._inference_function.call_preflattened(args)\n   1323 forward_backward = self._select_forward_and_backward_functions(\n   1324     args,\n   1325     possible_gradient_type,\n   1326     executing_eagerly)\n   1327 forward_function, args_with_tangents = forward_backward.forward()\n\nFile ~/cognitivecomputing/.venv/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:216, in AtomicFunction.call_preflattened(self, args)\n    214 def call_preflattened(self, args: Sequence[core.Tensor]) -&gt; Any:\n    215   \"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\n--&gt; 216   flat_outputs = self.call_flat(*args)\n    217   return self.function_type.pack_output(flat_outputs)\n\nFile ~/cognitivecomputing/.venv/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:251, in AtomicFunction.call_flat(self, *args)\n    249 with record.stop_recording():\n    250   if self._bound_context.executing_eagerly():\n--&gt; 251     outputs = self._bound_context.call_function(\n    252         self.name,\n    253         list(args),\n    254         len(self.function_type.flat_outputs),\n    255     )\n    256   else:\n    257     outputs = make_call_op_in_graph(\n    258         self,\n    259         list(args),\n    260         self._bound_context.function_call_options.as_attrs(),\n    261     )\n\nFile ~/cognitivecomputing/.venv/lib/python3.12/site-packages/tensorflow/python/eager/context.py:1688, in Context.call_function(self, name, tensor_inputs, num_outputs)\n   1686 cancellation_context = cancellation.context()\n   1687 if cancellation_context is None:\n-&gt; 1688   outputs = execute.execute(\n   1689       name.decode(\"utf-8\"),\n   1690       num_outputs=num_outputs,\n   1691       inputs=tensor_inputs,\n   1692       attrs=attrs,\n   1693       ctx=self,\n   1694   )\n   1695 else:\n   1696   outputs = execute.execute_with_cancellation(\n   1697       name.decode(\"utf-8\"),\n   1698       num_outputs=num_outputs,\n   (...)   1702       cancellation_manager=cancellation_context,\n   1703   )\n\nFile ~/cognitivecomputing/.venv/lib/python3.12/site-packages/tensorflow/python/eager/execute.py:53, in quick_execute(op_name, num_outputs, inputs, attrs, ctx, name)\n     51 try:\n     52   ctx.ensure_initialized()\n---&gt; 53   tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n     54                                       inputs, attrs, num_outputs)\n     55 except core._NotOkStatusException as e:\n     56   if name is not None:\n\nKeyboardInterrupt: </pre> In\u00a0[\u00a0]: Copied! <pre>## seu c\u00f3digo aqui....\n</pre> ## seu c\u00f3digo aqui...."},{"location":"aulas/IA/lab10/data-augmentation.html#objetivos","title":"Objetivos\u00b6","text":"<ul> <li>Conhecer e praticar Aumento de dados</li> </ul>"},{"location":"aulas/IA/lab10/data-augmentation.html#data-augmentation","title":"Data Augmentation\u00b6","text":"<p>O aumento de dados \u00e9 uma t\u00e9cnica amplamente utilizada no campo do aprendizado profundo e da vis\u00e3o computacional para melhorar a generaliza\u00e7\u00e3o e o desempenho dos modelos de aprendizado de m\u00e1quina. Essa t\u00e9cnica \u00e9 especialmente \u00fatil em cen\u00e1rios onde os conjuntos de dados s\u00e3o limitados ou desequilibrados, pois ajuda a criar varia\u00e7\u00f5es nos dados existentes, aumentando assim a quantidade de dados dispon\u00edveis para treinamento e reduzindo o overfitting.</p> <p>O overfitting ocorre quando um modelo de aprendizado de m\u00e1quina aprende padr\u00f5es espec\u00edficos do conjunto de dados de treinamento e n\u00e3o consegue generalizar adequadamente para novos dados. Isso pode levar a um desempenho ruim quando o modelo \u00e9 exposto a dados n\u00e3o vistos anteriormente. A t\u00e9cnica de aumento de dados aborda esse problema criando exemplos sint\u00e9ticos, aplicando transforma\u00e7\u00f5es \u00e0s imagens originais, como rota\u00e7\u00e3o, transla\u00e7\u00e3o, redimensionamento e invers\u00e3o. Essas transforma\u00e7\u00f5es geram varia\u00e7\u00f5es das imagens originais que podem ajudar o modelo a aprender caracter\u00edsticas mais generaliz\u00e1veis e a se tornar mais robusto a poss\u00edveis varia\u00e7\u00f5es nos dados de entrada.</p> <p>De forma geral em imagens pode ser aplicado as transforma\u00e7\u00f5s:</p> <ul> <li>Rota\u00e7\u00e3o</li> <li>Transla\u00e7\u00e3o (deslocamento horizontal e vertical)</li> <li>Zoom (in e out)</li> <li>Invers\u00e3o horizontal e vertical</li> <li>Ajuste de brilho e contraste</li> <li>Ru\u00eddo (adicionar ru\u00eddo gaussiano ou salt-and-pepper)</li> <li>Corte aleat\u00f3rio (Random Cropping)</li> <li>Existem mais....</li> </ul>"},{"location":"aulas/IA/lab10/data-augmentation.html#como-usar-data-augmentation","title":"Como usar Data Augmentation\u00b6","text":"<p>Para demonstrar, vamos aplicar essa t\u00e9cnica no dataset do Cifar10.</p>"},{"location":"aulas/IA/lab10/data-augmentation.html#desafio","title":"desafio:\u00b6","text":"<p>Avalie os atributos que podem ser usados no ImageDataGenerator para aumentar o conjunto de dados de forma eficiente</p>"},{"location":"aulas/IA/lab10/data-augmentation.html#desafio","title":"Desafio\u00b6","text":"<p>Comparar o tamanho dos conjuntos de dados original e aumentado</p>"},{"location":"aulas/IA/lab10/data-augmentation.html#desafio","title":"Desafio:\u00b6","text":"<p>Aumente o conjunto de dados de treinamento em 50% usando data augmentation para o treinamento</p>"},{"location":"aulas/IA/lab11/index.html","title":"Lab05 - Resumo","text":""},{"location":"aulas/IA/lab11/index.html#resumo-sobre-redes-neurais","title":"Resumo sobre redes neurais","text":"<p>A cria\u00e7\u00e3o de redes neurais envolve muitas etapas onde devem ser consideradow diversos pontos e aspectos de complexidade do problema envolvido, tratando-se de modelos para vis\u00e3o computacional tivemos contato com alguns tipos de arquitetura, otimiza\u00e7\u00e3o, dados, e implementa\u00e7\u00e3o.</p>"},{"location":"aulas/IA/lab11/index.html#notebook-completo","title":"Notebook completo","text":"<p>No link a seguir tem um notebook completo com sugest\u00f5es de implemeta\u00e7\u00e3o</p> <ul> <li>LINK o notebook completo</li> </ul>"},{"location":"aulas/IA/lab11/index.html#etapas-de-construcao-de-redes-neurais","title":"Etapas de constru\u00e7\u00e3o de redes neurais","text":"<ul> <li>Arquitetura de Rede: Escolha arquiteturas como VGG, ResNet, ou Mobilenet para aproveitar modelos pr\u00e9-treinados atrav\u00e9s de fine-tuning.</li> <li>Ajuste Fino (Fine-Tuning): Utilize transfer\u00eancia de aprendizado para acelerar o treinamento.</li> <li>Dados: Augmenta\u00e7\u00e3o de dados e normaliza\u00e7\u00e3o s\u00e3o essenciais para a prepara\u00e7\u00e3o eficaz de dados.</li> <li>Otimiza\u00e7\u00e3o: Otimizadores como Adam ou SGD (com momento), taxas de aprendizado ajust\u00e1veis e schedules s\u00e3o importantes.</li> <li>Regulariza\u00e7\u00e3o: Utilize t\u00e9cnicas como early stopping e L2 regularization para promover a generaliza\u00e7\u00e3o.</li> </ul>"},{"location":"aulas/IA/lab11/index.html#pipeline-de-treinamento","title":"Pipeline de Treinamento","text":"<p>A cria\u00e7\u00e3o de uma rede neural envolve um pipeline de treinamento bem definido para garantir um modelo eficaz e robusto. A seguir est\u00e3o as <code>etapas t\u00edpicas que podem ou n\u00e3o fazer parte</code> de um pipeline de treinamento:</p> <ol> <li> <p>Prepara\u00e7\u00e3o de Dados:</p> <ul> <li>Coleta e Limpeza: Reunir dados de diversas fontes e garantir que est\u00e3o limpos e livres de ru\u00eddos.</li> <li>Augmenta\u00e7\u00e3o: Aplicar t\u00e9cnicas de augmenta\u00e7\u00e3o, como rota\u00e7\u00e3o, corte, ajuste de brilho e contraste, e distor\u00e7\u00f5es geom\u00e9tricas para aumentar a variedade dos dados de treino.</li> <li>Divis\u00e3o: Dividir os dados em conjuntos de treino, valida\u00e7\u00e3o e teste.</li> </ul> </li> <li> <p>Defini\u00e7\u00e3o do Modelo:</p> <ul> <li>Arquitetura: Escolher a arquitetura da rede neural com base na complexidade do problema e recursos dispon\u00edveis.</li> <li>Camadas e Par\u00e2metros: Definir a quantidade de camadas, neur\u00f4nios, filtros de convolu\u00e7\u00e3o, e outros par\u00e2metros.</li> </ul> </li> <li> <p>Compila\u00e7\u00e3o:</p> <ul> <li>Fun\u00e7\u00e3o de Perda: Selecionar a fun\u00e7\u00e3o de perda apropriada (ex.: cross-entropy para classifica\u00e7\u00e3o).</li> <li>Otimiza\u00e7\u00e3o: Escolher o otimizador (ex.: Adam, SGD).</li> <li>M\u00e9tricas: Definir m\u00e9tricas para avaliar o desempenho do modelo (ex.: precis\u00e3o, recall).</li> </ul> </li> <li> <p>Treinamento:</p> <ul> <li>Batch Size: Determinar o tamanho do batch para o treinamento.</li> <li>\u00c9pocas: Definir o n\u00famero de \u00e9pocas para o treinamento.</li> <li>Callback Functions: Utilizar callbacks como early stopping, redu\u00e7\u00e3o da taxa de aprendizado on plateau, etc.</li> </ul> </li> <li> <p>Valida\u00e7\u00e3o:</p> <ul> <li>Monitoramento: Avaliar o desempenho do modelo no conjunto de valida\u00e7\u00e3o ap\u00f3s cada \u00e9poca.</li> <li>Ajuste de Hiperpar\u00e2metros: Ajustar hiperpar\u00e2metros com base no desempenho de valida\u00e7\u00e3o.</li> </ul> </li> <li> <p>Avalia\u00e7\u00e3o:</p> <ul> <li>Teste: Avaliar o modelo final no conjunto de teste para medir sua performance.</li> <li>M\u00e9tricas de Avalia\u00e7\u00e3o: Utilizar m\u00e9tricas como precis\u00e3o, recall, F1-score, e AUC-ROC.</li> </ul> </li> <li> <p>Deploy de Modelos:</p> <ul> <li>Exporta\u00e7\u00e3o: Salvar o modelo treinado em um formato apropriado.</li> <li>Servi\u00e7o de Modelo: Utilizar frameworks como TensorFlow Serving ou ONNX para colocar o modelo em produ\u00e7\u00e3o.</li> <li>Monitoramento em Produ\u00e7\u00e3o: Monitorar o desempenho do modelo em produ\u00e7\u00e3o e realizar ajustes conforme necess\u00e1rio.</li> </ul> </li> </ol>"},{"location":"aulas/IA/lab11/index.html#elementos-de-redes-neurais","title":"Elementos de Redes Neurais","text":"<p>Elementos como dropout e batch normalization s\u00e3o fundamentais para o desempenho e a estabilidade do treinamento.</p> Elemento Descri\u00e7\u00e3o e Casos de Uso Dropout Use para reduzir o overfitting, aplic\u00e1vel em redes densas ou MLPs, com taxa de 0.2 a 0.5. Batch Normalization Utilize para estabilizar e acelerar o treinamento, aplic\u00e1vel tanto em camadas convolucionais quanto densas. Quantidade de Filtros de Convolu\u00e7\u00e3o Inicie com menos filtros e aumente nas camadas profundas. Exemplos: comece com 32 ou 64 e dobre em camadas subsequentes. Max Pooling Reduz a dimensionalidade espacial ap\u00f3s camadas convolucionais. Pooling de 2x2 \u00e9 comum. Quantidade de Camadas e Neur\u00f4nios em MLP Comece com uma ou duas camadas escondidas, com 100 a 300 neur\u00f4nios por camada, ajustando conforme a necessidade."},{"location":"aulas/IA/lab11/index.html#funcoes-de-ativacao","title":"Fun\u00e7\u00f5es de Ativa\u00e7\u00e3o","text":"<p>A escolha da fun\u00e7\u00e3o de ativa\u00e7\u00e3o \u00e9 crucial no desenvolvimento de modelos de redes neurais para vis\u00e3o computacional.</p> Fun\u00e7\u00e3o de Ativa\u00e7\u00e3o Local de Uso Descri\u00e7\u00e3o e Casos de Uso Relu Camadas intermedi\u00e1rias Ideal em problemas de vis\u00e3o computacional, pois adicionam n\u00e3o linearidades que colaboram para o treinamento. SIGMOID \u00daltima camada Usada na \u00faltima camada para problemas de classifica\u00e7\u00e3o bin\u00e1ria, onde a sa\u00edda \u00e9 interpretada como uma probabilidade. N\u00e3o \u00e9 ideal para multiclasses devido \u00e0 satura\u00e7\u00e3o do gradiente. SOFTMAX \u00daltima camada Indicada para a \u00faltima camada em problemas de classifica\u00e7\u00e3o multiclasse, convertendo logits em probabilidades condicionais para cada classe. A soma das probabilidades \u00e9 1. <pre><code>import tensorflow as tf\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization\nfrom tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n\n# Definindo o modelo\nmodel = Sequential()\n\n# Camadas convolucionais com n\u00famero crescente de filtros\nmodel.add(Conv2D(32, (3, 3), activation='relu', input_shape=(64, 64, 3)))\nmodel.add(BatchNormalization())\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\n\nmodel.add(Conv2D(64, (3, 3), activation='relu'))\nmodel.add(BatchNormalization())\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\n\nmodel.add(Conv2D(128, (3, 3), activation='relu'))\nmodel.add(BatchNormalization())\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\n\n# Camada Flatten para converter a sa\u00edda das camadas convolucionais em um vetor 1D\nmodel.add(Flatten())\n\n# Camadas totalmente conectadas\nmodel.add(Dense(128, activation='relu'))\nmodel.add(Dropout(0.5))\n\nmodel.add(Dense(64, activation='relu'))\nmodel.add(Dropout(0.5))\n\n# \u00daltima camada totalmente conectada com 10 sa\u00eddas (10 classes de categoria de imagem)\nmodel.add(Dense(10, activation='softmax'))\n\n# Compilando o modelo\nmodel.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n\n# Configurando a callback ModelCheckpoint\ncheckpoint = ModelCheckpoint('best_model.h5', \n                             monitor='val_accuracy', \n                             save_best_only=True, \n                             mode='max', \n                             verbose=1)\n\n# Configurando a callback EarlyStopping\nearly_stopping = EarlyStopping(monitor='val_loss', \n                               patience=10, \n                               verbose=1, \n                               restore_best_weights=True)\n\n# Configurando a callback ReduceLROnPlateau\nreduce_lr = ReduceLROnPlateau(monitor='val_loss', \n                              factor=0.2, \n                              patience=5, \n                              min_lr=0.001, \n                              verbose=1)\n\n# Treinando o modelo com as callbacks\nhistory = model.fit(x_train, y_train, \n                    epochs=100, \n                    validation_data=(x_val, y_val), \n                    callbacks=[checkpoint, early_stopping, reduce_lr])\n\n# Resumo do modelo\nmodel.summary()\n</code></pre>"},{"location":"aulas/IA/lab11/index.html#data-augmentation","title":"Data Augmentation:","text":"<p>Data augmentation \u00e9 uma t\u00e9cnica usada para aumentar a diversidade do conjunto de dados de treinamento sem realmente coletar novos dados. Isso \u00e9 feito aplicando v\u00e1rias transforma\u00e7\u00f5es (como rota\u00e7\u00f5es, transla\u00e7\u00f5es, flip horizontal/vertical, zoom, etc.) \u00e0s imagens de treinamento, o que ajuda a melhorar a generaliza\u00e7\u00e3o do modelo.</p> <p>Podemos usar a classe <code>ImageDataGenerator</code> para aplicar data augmentation. Ela permite configurar e aplicar transforma\u00e7\u00f5es \u00e0s imagens em tempo real durante o treinamento.</p>"},{"location":"aulas/IA/lab11/index.html#imagedatagenerator","title":"ImageDataGenerator:","text":"<ul> <li>rotation_range: Grau de rota\u00e7\u00e3o aleat\u00f3ria das imagens.</li> <li>width_shift_range: Fra\u00e7\u00e3o do total da largura para deslocamento horizontal aleat\u00f3rio.</li> <li>height_shift_range: Fra\u00e7\u00e3o do total da altura para deslocamento vertical aleat\u00f3rio.</li> <li>horizontal_flip: Permite flip horizontal aleat\u00f3rio.</li> <li>zoom_range: Faixa de zoom aleat\u00f3rio.</li> </ul> <p>Existem outros parametros....</p>"},{"location":"aulas/IA/lab11/index.html#train_generator","title":"train_generator:","text":"<p>Usamos <code>flow</code> para criar um gerador que fornece lotes de dados augmentados durante o treinamento.</p> <pre><code>import tensorflow as tf\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization\nfrom tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nimport numpy as np\n\n# Definindo o modelo\nmodel = Sequential()\n\n# Camadas convolucionais com n\u00famero crescente de filtros\nmodel.add(Conv2D(32, (3, 3), activation='relu', input_shape=(64, 64, 3)))\nmodel.add(BatchNormalization())\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\n\nmodel.add(Conv2D(64, (3, 3), activation='relu'))\nmodel.add(BatchNormalization())\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\n\nmodel.add(Conv2D(128, (3, 3), activation='relu'))\nmodel.add(BatchNormalization())\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\n\n# Camada Flatten para converter a sa\u00edda das camadas convolucionais em um vetor 1D\nmodel.add(Flatten())\n\n# Camadas totalmente conectadas\nmodel.add(Dense(128, activation='relu'))\nmodel.add(Dropout(0.5))\n\nmodel.add(Dense(64, activation='relu'))\nmodel.add(Dropout(0.5))\n\n# \u00daltima camada totalmente conectada com 10 sa\u00eddas (10 classes de categoria de imagem)\nmodel.add(Dense(10, activation='softmax'))\n\n# Compilando o modelo\nmodel.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n\n# Configurando a callback ModelCheckpoint\ncheckpoint = ModelCheckpoint('best_model.h5', \n                             monitor='val_accuracy', \n                             save_best_only=True, \n                             mode='max', \n                             verbose=1)\n\n# Configurando a callback EarlyStopping\nearly_stopping = EarlyStopping(monitor='val_loss', \n                               patience=10, \n                               verbose=1, \n                               restore_best_weights=True)\n\n# Configurando a callback ReduceLROnPlateau\nreduce_lr = ReduceLROnPlateau(monitor='val_loss', \n                              factor=0.2, \n                              patience=5, \n                              min_lr=0.001, \n                              verbose=1)\n\n# Configurando o data augmentation\ndatagen = ImageDataGenerator(\n    rotation_range=20,\n    width_shift_range=0.2,\n    height_shift_range=0.2,\n    horizontal_flip=True,\n    zoom_range=0.2\n)\n\n# Gerando dados de treinamento augmentados\ntrain_generator = datagen.flow(x_train, y_train, batch_size=32)\n\n# Treinando o modelo com as callbacks e data augmentation\nhistory = model.fit(train_generator, \n                    epochs=100, \n                    validation_data=(x_val, y_val), \n                    callbacks=[checkpoint, early_stopping, reduce_lr])\n\n# Resumo do modelo\nmodel.summary()\n</code></pre>"},{"location":"aulas/IA/lab11/index.html#carregando-imagens-de-um-diretorio","title":"Carregando imagens de um diret\u00f3rio","text":"<p>Podemos utilizar o TensorFlow para carregar e pr\u00e9-processar os dados com o <code>image_dataset_from_directory</code>. </p> <p>Para funcionar corretamente as imagens devem estar dispostas da seguinte forma:</p> <pre><code> dataset_dir/\n    \u251c\u2500\u2500 class_1/\n    \u2502   \u251c\u2500\u2500 image1.jpg\n    \u2502   \u251c\u2500\u2500 image2.jpg\n    \u2502   \u2514\u2500\u2500 ...\n    \u251c\u2500\u2500 class_2/\n    \u2502   \u251c\u2500\u2500 image1.jpg\n    \u2502   \u251c\u2500\u2500 image2.jpg\n    \u2502   \u2514\u2500\u2500 ...\n    \u2514\u2500\u2500 class_n/\n        \u251c\u2500\u2500 image1.jpg\n        \u251c\u2500\u2500 image2.jpg\n        \u2514\u2500\u2500 ...\n</code></pre> <p>Aqui est\u00e1 um exemplo de como fazer isso:</p> <pre><code>import tensorflow as tf\nfrom tensorflow.keras.preprocessing import image_dataset_from_directory\n\n# Define o caminho para o diret\u00f3rio onde as imagens est\u00e3o organizadas em subpastas\ndataset_dir = \"caminho/para/seu/dataset\"\n\n# Carrega o dataset e divide em treino e valida\u00e7\u00e3o\ntrain_dataset = image_dataset_from_directory(\n    dataset_dir,\n    validation_split=0.2,\n    subset=\"training\",\n    seed=123,\n    image_size=(224, 224),  # Redimensiona as imagens para 224x224\n    batch_size=32\n)\n\nvalidation_dataset = image_dataset_from_directory(\n    dataset_dir,\n    validation_split=0.2,\n    subset=\"validation\",\n    seed=123,\n    image_size=(224, 224),\n    batch_size=32\n)\n\n# Normaliza os valores dos pixels para o intervalo [0, 1]\nnormalization_layer = tf.keras.layers.Rescaling(1./255)\n\nnormalized_train_dataset = train_dataset.map(lambda x, y: (normalization_layer(x), y))\nnormalized_validation_dataset = validation_dataset.map(lambda x, y: (normalization_layer(x), y))\n</code></pre>"},{"location":"aulas/IA/lab11/cnn_completo.html","title":"Cnn completo","text":"In\u00a0[5]: Copied! <pre>from google.colab import drive\ndrive.mount('/content/drive')\n\n# Vamos definir o caminho onde o modelo ser\u00e1 salvo no Google Drive\nmodel_save_path = '/content/drive/MyDrive/checkpoints/cifar10_best_model.h5'\n</pre> from google.colab import drive drive.mount('/content/drive')  # Vamos definir o caminho onde o modelo ser\u00e1 salvo no Google Drive model_save_path = '/content/drive/MyDrive/checkpoints/cifar10_best_model.h5'  <pre>Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n</pre> In\u00a0[6]: Copied! <pre>import tensorflow as tf\nfrom tensorflow.keras.datasets import cifar10\nfrom tensorflow.keras.utils import to_categorical\n\n# Carregando o conjunto de dados CIFAR-10\n(x_train, y_train), (x_val, y_val) = cifar10.load_data()\n\n# Normalizando os valores dos pixels para o intervalo [0, 1]\nx_train = x_train.astype('float32') / 255.0\nx_val = x_val.astype('float32') / 255.0\n\n# Convertendo os r\u00f3tulos para vetores one-hot\ny_train = to_categorical(y_train, 10)\ny_val = to_categorical(y_val, 10)\n</pre> import tensorflow as tf from tensorflow.keras.datasets import cifar10 from tensorflow.keras.utils import to_categorical  # Carregando o conjunto de dados CIFAR-10 (x_train, y_train), (x_val, y_val) = cifar10.load_data()  # Normalizando os valores dos pixels para o intervalo [0, 1] x_train = x_train.astype('float32') / 255.0 x_val = x_val.astype('float32') / 255.0  # Convertendo os r\u00f3tulos para vetores one-hot y_train = to_categorical(y_train, 10) y_val = to_categorical(y_val, 10)  In\u00a0[7]: Copied! <pre>from tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization\nfrom tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\n\n# Definindo o modelo\nmodel = Sequential()\n\n# Camadas convolucionais com n\u00famero crescente de filtros\nmodel.add(Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3)))\nmodel.add(BatchNormalization())\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\n\nmodel.add(Conv2D(64, (3, 3), activation='relu'))\nmodel.add(BatchNormalization())\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\n\nmodel.add(Conv2D(128, (3, 3), activation='relu'))\nmodel.add(BatchNormalization())\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\n\n# Camada Flatten para converter a sa\u00edda das camadas convolucionais em um vetor 1D\nmodel.add(Flatten())\n\n# Camadas totalmente conectadas\nmodel.add(Dense(128, activation='relu'))\nmodel.add(Dropout(0.5))\n\nmodel.add(Dense(64, activation='relu'))\nmodel.add(Dropout(0.5))\n\n# \u00daltima camada totalmente conectada com 10 sa\u00eddas (10 classes de categoria de imagem)\nmodel.add(Dense(10, activation='softmax'))\n\n# Compilando o modelo\nmodel.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n\n# Resumo do modelo\nmodel.summary()\n</pre> from tensorflow.keras.models import Sequential from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau from tensorflow.keras.preprocessing.image import ImageDataGenerator  # Definindo o modelo model = Sequential()  # Camadas convolucionais com n\u00famero crescente de filtros model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3))) model.add(BatchNormalization()) model.add(MaxPooling2D(pool_size=(2, 2)))  model.add(Conv2D(64, (3, 3), activation='relu')) model.add(BatchNormalization()) model.add(MaxPooling2D(pool_size=(2, 2)))  model.add(Conv2D(128, (3, 3), activation='relu')) model.add(BatchNormalization()) model.add(MaxPooling2D(pool_size=(2, 2)))  # Camada Flatten para converter a sa\u00edda das camadas convolucionais em um vetor 1D model.add(Flatten())  # Camadas totalmente conectadas model.add(Dense(128, activation='relu')) model.add(Dropout(0.5))  model.add(Dense(64, activation='relu')) model.add(Dropout(0.5))  # \u00daltima camada totalmente conectada com 10 sa\u00eddas (10 classes de categoria de imagem) model.add(Dense(10, activation='softmax'))  # Compilando o modelo model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])  # Resumo do modelo model.summary()  <pre>Model: \"sequential_1\"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\n conv2d_3 (Conv2D)           (None, 30, 30, 32)        896       \n                                                                 \n batch_normalization_3 (Bat  (None, 30, 30, 32)        128       \n chNormalization)                                                \n                                                                 \n max_pooling2d_3 (MaxPoolin  (None, 15, 15, 32)        0         \n g2D)                                                            \n                                                                 \n conv2d_4 (Conv2D)           (None, 13, 13, 64)        18496     \n                                                                 \n batch_normalization_4 (Bat  (None, 13, 13, 64)        256       \n chNormalization)                                                \n                                                                 \n max_pooling2d_4 (MaxPoolin  (None, 6, 6, 64)          0         \n g2D)                                                            \n                                                                 \n conv2d_5 (Conv2D)           (None, 4, 4, 128)         73856     \n                                                                 \n batch_normalization_5 (Bat  (None, 4, 4, 128)         512       \n chNormalization)                                                \n                                                                 \n max_pooling2d_5 (MaxPoolin  (None, 2, 2, 128)         0         \n g2D)                                                            \n                                                                 \n flatten_1 (Flatten)         (None, 512)               0         \n                                                                 \n dense_3 (Dense)             (None, 128)               65664     \n                                                                 \n dropout_2 (Dropout)         (None, 128)               0         \n                                                                 \n dense_4 (Dense)             (None, 64)                8256      \n                                                                 \n dropout_3 (Dropout)         (None, 64)                0         \n                                                                 \n dense_5 (Dense)             (None, 10)                650       \n                                                                 \n=================================================================\nTotal params: 168714 (659.04 KB)\nTrainable params: 168266 (657.29 KB)\nNon-trainable params: 448 (1.75 KB)\n_________________________________________________________________\n</pre> In\u00a0[8]: Copied! <pre># Configurando a callback ModelCheckpoint para salvar o modelo no google drive\ncheckpoint = ModelCheckpoint(model_save_path,\n                             monitor='val_accuracy',\n                             save_best_only=True,\n                             mode='max',\n                             verbose=1)\n\n# Configurando a callback EarlyStopping\nearly_stopping = EarlyStopping(monitor='val_loss',\n                               patience=10,\n                               verbose=1,\n                               restore_best_weights=True)\n\n# Configurando a callback ReduceLROnPlateau\nreduce_lr = ReduceLROnPlateau(monitor='val_loss',\n                              factor=0.2,\n                              patience=5,\n                              min_lr=0.001,\n                              verbose=1)\n</pre> # Configurando a callback ModelCheckpoint para salvar o modelo no google drive checkpoint = ModelCheckpoint(model_save_path,                              monitor='val_accuracy',                              save_best_only=True,                              mode='max',                              verbose=1)  # Configurando a callback EarlyStopping early_stopping = EarlyStopping(monitor='val_loss',                                patience=10,                                verbose=1,                                restore_best_weights=True)  # Configurando a callback ReduceLROnPlateau reduce_lr = ReduceLROnPlateau(monitor='val_loss',                               factor=0.2,                               patience=5,                               min_lr=0.001,                               verbose=1)  In\u00a0[9]: Copied! <pre># Configurando o data augmentation\ndatagen = ImageDataGenerator(\n    rotation_range=20,\n    width_shift_range=0.2,\n    height_shift_range=0.2,\n    horizontal_flip=True,\n    zoom_range=0.2\n)\n\n# Gerando dados de treinamento augmentados\ntrain_generator = datagen.flow(x_train, y_train, batch_size=32)\n</pre> # Configurando o data augmentation datagen = ImageDataGenerator(     rotation_range=20,     width_shift_range=0.2,     height_shift_range=0.2,     horizontal_flip=True,     zoom_range=0.2 )  # Gerando dados de treinamento augmentados train_generator = datagen.flow(x_train, y_train, batch_size=32)  In\u00a0[10]: Copied! <pre># Treinando o modelo com as callbacks e data augmentation\nhistory = model.fit(train_generator,\n                    epochs=100,\n                    validation_data=(x_val, y_val),\n                    callbacks=[checkpoint, early_stopping, reduce_lr])\n</pre> # Treinando o modelo com as callbacks e data augmentation history = model.fit(train_generator,                     epochs=100,                     validation_data=(x_val, y_val),                     callbacks=[checkpoint, early_stopping, reduce_lr])  <pre>Epoch 1/100\n1562/1563 [============================&gt;.] - ETA: 0s - loss: 2.0423 - accuracy: 0.2451\nEpoch 1: val_accuracy improved from -inf to 0.28590, saving model to /content/drive/MyDrive/checkpoints/cifar10_best_model.h5\n1563/1563 [==============================] - 43s 23ms/step - loss: 2.0421 - accuracy: 0.2451 - val_loss: 2.0514 - val_accuracy: 0.2859 - lr: 0.0010\nEpoch 2/100\n   1/1563 [..............................] - ETA: 52s - loss: 1.8313 - accuracy: 0.1562</pre> <pre>/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n  saving_api.save_model(\n</pre> <pre>1561/1563 [============================&gt;.] - ETA: 0s - loss: 1.7979 - accuracy: 0.3332\nEpoch 2: val_accuracy improved from 0.28590 to 0.45100, saving model to /content/drive/MyDrive/checkpoints/cifar10_best_model.h5\n1563/1563 [==============================] - 36s 23ms/step - loss: 1.7977 - accuracy: 0.3333 - val_loss: 1.4733 - val_accuracy: 0.4510 - lr: 0.0010\nEpoch 3/100\n1561/1563 [============================&gt;.] - ETA: 0s - loss: 1.6728 - accuracy: 0.3916\nEpoch 3: val_accuracy improved from 0.45100 to 0.48650, saving model to /content/drive/MyDrive/checkpoints/cifar10_best_model.h5\n1563/1563 [==============================] - 37s 23ms/step - loss: 1.6729 - accuracy: 0.3917 - val_loss: 1.3924 - val_accuracy: 0.4865 - lr: 0.0010\nEpoch 4/100\n1562/1563 [============================&gt;.] - ETA: 0s - loss: 1.6007 - accuracy: 0.4219\nEpoch 4: val_accuracy did not improve from 0.48650\n1563/1563 [==============================] - 37s 23ms/step - loss: 1.6007 - accuracy: 0.4219 - val_loss: 1.5411 - val_accuracy: 0.4524 - lr: 0.0010\nEpoch 5/100\n1563/1563 [==============================] - ETA: 0s - loss: 1.5361 - accuracy: 0.4527\nEpoch 5: val_accuracy improved from 0.48650 to 0.49570, saving model to /content/drive/MyDrive/checkpoints/cifar10_best_model.h5\n1563/1563 [==============================] - 36s 23ms/step - loss: 1.5361 - accuracy: 0.4527 - val_loss: 1.4323 - val_accuracy: 0.4957 - lr: 0.0010\nEpoch 6/100\n1562/1563 [============================&gt;.] - ETA: 0s - loss: 1.4981 - accuracy: 0.4708\nEpoch 6: val_accuracy did not improve from 0.49570\n1563/1563 [==============================] - 35s 22ms/step - loss: 1.4981 - accuracy: 0.4708 - val_loss: 1.4484 - val_accuracy: 0.4790 - lr: 0.0010\nEpoch 7/100\n1562/1563 [============================&gt;.] - ETA: 0s - loss: 1.4468 - accuracy: 0.4942\nEpoch 7: val_accuracy improved from 0.49570 to 0.56870, saving model to /content/drive/MyDrive/checkpoints/cifar10_best_model.h5\n1563/1563 [==============================] - 35s 23ms/step - loss: 1.4468 - accuracy: 0.4941 - val_loss: 1.1967 - val_accuracy: 0.5687 - lr: 0.0010\nEpoch 8/100\n1563/1563 [==============================] - ETA: 0s - loss: 1.4102 - accuracy: 0.5118\nEpoch 8: val_accuracy improved from 0.56870 to 0.60030, saving model to /content/drive/MyDrive/checkpoints/cifar10_best_model.h5\n1563/1563 [==============================] - 36s 23ms/step - loss: 1.4102 - accuracy: 0.5118 - val_loss: 1.1149 - val_accuracy: 0.6003 - lr: 0.0010\nEpoch 9/100\n1562/1563 [============================&gt;.] - ETA: 0s - loss: 1.3760 - accuracy: 0.5249\nEpoch 9: val_accuracy did not improve from 0.60030\n1563/1563 [==============================] - 34s 22ms/step - loss: 1.3763 - accuracy: 0.5249 - val_loss: 1.2569 - val_accuracy: 0.5386 - lr: 0.0010\nEpoch 10/100\n1562/1563 [============================&gt;.] - ETA: 0s - loss: 1.3509 - accuracy: 0.5376\nEpoch 10: val_accuracy improved from 0.60030 to 0.63180, saving model to /content/drive/MyDrive/checkpoints/cifar10_best_model.h5\n1563/1563 [==============================] - 35s 22ms/step - loss: 1.3510 - accuracy: 0.5376 - val_loss: 1.0326 - val_accuracy: 0.6318 - lr: 0.0010\nEpoch 11/100\n1563/1563 [==============================] - ETA: 0s - loss: 1.3254 - accuracy: 0.5463\nEpoch 11: val_accuracy did not improve from 0.63180\n1563/1563 [==============================] - 36s 23ms/step - loss: 1.3254 - accuracy: 0.5463 - val_loss: 1.0348 - val_accuracy: 0.6258 - lr: 0.0010\nEpoch 12/100\n1562/1563 [============================&gt;.] - ETA: 0s - loss: 1.3049 - accuracy: 0.5532\nEpoch 12: val_accuracy did not improve from 0.63180\n1563/1563 [==============================] - 35s 23ms/step - loss: 1.3051 - accuracy: 0.5532 - val_loss: 1.1351 - val_accuracy: 0.6115 - lr: 0.0010\nEpoch 13/100\n1562/1563 [============================&gt;.] - ETA: 0s - loss: 1.2862 - accuracy: 0.5637\nEpoch 13: val_accuracy improved from 0.63180 to 0.63310, saving model to /content/drive/MyDrive/checkpoints/cifar10_best_model.h5\n1563/1563 [==============================] - 35s 22ms/step - loss: 1.2863 - accuracy: 0.5636 - val_loss: 1.0346 - val_accuracy: 0.6331 - lr: 0.0010\nEpoch 14/100\n1563/1563 [==============================] - ETA: 0s - loss: 1.2669 - accuracy: 0.5699\nEpoch 14: val_accuracy did not improve from 0.63310\n1563/1563 [==============================] - 35s 23ms/step - loss: 1.2669 - accuracy: 0.5699 - val_loss: 1.2640 - val_accuracy: 0.5506 - lr: 0.0010\nEpoch 15/100\n1561/1563 [============================&gt;.] - ETA: 0s - loss: 1.2572 - accuracy: 0.5741\nEpoch 15: val_accuracy did not improve from 0.63310\n1563/1563 [==============================] - 34s 22ms/step - loss: 1.2573 - accuracy: 0.5740 - val_loss: 1.1206 - val_accuracy: 0.6215 - lr: 0.0010\nEpoch 16/100\n1562/1563 [============================&gt;.] - ETA: 0s - loss: 1.2447 - accuracy: 0.5805\nEpoch 16: val_accuracy did not improve from 0.63310\n1563/1563 [==============================] - 35s 23ms/step - loss: 1.2446 - accuracy: 0.5805 - val_loss: 1.1991 - val_accuracy: 0.6057 - lr: 0.0010\nEpoch 17/100\n1562/1563 [============================&gt;.] - ETA: 0s - loss: 1.2226 - accuracy: 0.5873\nEpoch 17: val_accuracy improved from 0.63310 to 0.64720, saving model to /content/drive/MyDrive/checkpoints/cifar10_best_model.h5\n1563/1563 [==============================] - 35s 22ms/step - loss: 1.2227 - accuracy: 0.5873 - val_loss: 0.9827 - val_accuracy: 0.6472 - lr: 0.0010\nEpoch 18/100\n1562/1563 [============================&gt;.] - ETA: 0s - loss: 1.2050 - accuracy: 0.5965\nEpoch 18: val_accuracy did not improve from 0.64720\n1563/1563 [==============================] - 35s 22ms/step - loss: 1.2047 - accuracy: 0.5966 - val_loss: 1.0118 - val_accuracy: 0.6391 - lr: 0.0010\nEpoch 19/100\n1563/1563 [==============================] - ETA: 0s - loss: 1.1952 - accuracy: 0.5983\nEpoch 19: val_accuracy improved from 0.64720 to 0.65800, saving model to /content/drive/MyDrive/checkpoints/cifar10_best_model.h5\n1563/1563 [==============================] - 37s 23ms/step - loss: 1.1952 - accuracy: 0.5983 - val_loss: 0.9626 - val_accuracy: 0.6580 - lr: 0.0010\nEpoch 20/100\n1561/1563 [============================&gt;.] - ETA: 0s - loss: 1.1898 - accuracy: 0.6032\nEpoch 20: val_accuracy improved from 0.65800 to 0.68460, saving model to /content/drive/MyDrive/checkpoints/cifar10_best_model.h5\n1563/1563 [==============================] - 37s 24ms/step - loss: 1.1898 - accuracy: 0.6032 - val_loss: 0.9178 - val_accuracy: 0.6846 - lr: 0.0010\nEpoch 21/100\n1562/1563 [============================&gt;.] - ETA: 0s - loss: 1.1815 - accuracy: 0.6051\nEpoch 21: val_accuracy did not improve from 0.68460\n1563/1563 [==============================] - 37s 23ms/step - loss: 1.1815 - accuracy: 0.6051 - val_loss: 1.0920 - val_accuracy: 0.6279 - lr: 0.0010\nEpoch 22/100\n1563/1563 [==============================] - ETA: 0s - loss: 1.1674 - accuracy: 0.6085\nEpoch 22: val_accuracy improved from 0.68460 to 0.69460, saving model to /content/drive/MyDrive/checkpoints/cifar10_best_model.h5\n1563/1563 [==============================] - 36s 23ms/step - loss: 1.1674 - accuracy: 0.6085 - val_loss: 0.8778 - val_accuracy: 0.6946 - lr: 0.0010\nEpoch 23/100\n1563/1563 [==============================] - ETA: 0s - loss: 1.1468 - accuracy: 0.6188\nEpoch 23: val_accuracy improved from 0.69460 to 0.71950, saving model to /content/drive/MyDrive/checkpoints/cifar10_best_model.h5\n1563/1563 [==============================] - 36s 23ms/step - loss: 1.1468 - accuracy: 0.6188 - val_loss: 0.8091 - val_accuracy: 0.7195 - lr: 0.0010\nEpoch 24/100\n1563/1563 [==============================] - ETA: 0s - loss: 1.1462 - accuracy: 0.6197\nEpoch 24: val_accuracy did not improve from 0.71950\n1563/1563 [==============================] - 35s 23ms/step - loss: 1.1462 - accuracy: 0.6197 - val_loss: 0.9789 - val_accuracy: 0.6681 - lr: 0.0010\nEpoch 25/100\n1563/1563 [==============================] - ETA: 0s - loss: 1.1482 - accuracy: 0.6186\nEpoch 25: val_accuracy did not improve from 0.71950\n1563/1563 [==============================] - 36s 23ms/step - loss: 1.1482 - accuracy: 0.6186 - val_loss: 0.9466 - val_accuracy: 0.6623 - lr: 0.0010\nEpoch 26/100\n1562/1563 [============================&gt;.] - ETA: 0s - loss: 1.1343 - accuracy: 0.6254\nEpoch 26: val_accuracy did not improve from 0.71950\n1563/1563 [==============================] - 35s 23ms/step - loss: 1.1342 - accuracy: 0.6254 - val_loss: 0.8559 - val_accuracy: 0.7100 - lr: 0.0010\nEpoch 27/100\n1561/1563 [============================&gt;.] - ETA: 0s - loss: 1.1221 - accuracy: 0.6244\nEpoch 27: val_accuracy did not improve from 0.71950\n1563/1563 [==============================] - 36s 23ms/step - loss: 1.1218 - accuracy: 0.6245 - val_loss: 0.9000 - val_accuracy: 0.6829 - lr: 0.0010\nEpoch 28/100\n1562/1563 [============================&gt;.] - ETA: 0s - loss: 1.1122 - accuracy: 0.6333\nEpoch 28: val_accuracy did not improve from 0.71950\n1563/1563 [==============================] - 36s 23ms/step - loss: 1.1123 - accuracy: 0.6333 - val_loss: 0.8558 - val_accuracy: 0.7058 - lr: 0.0010\nEpoch 29/100\n1561/1563 [============================&gt;.] - ETA: 0s - loss: 1.1095 - accuracy: 0.6322\nEpoch 29: val_accuracy did not improve from 0.71950\n1563/1563 [==============================] - 36s 23ms/step - loss: 1.1096 - accuracy: 0.6322 - val_loss: 0.9187 - val_accuracy: 0.6892 - lr: 0.0010\nEpoch 30/100\n1563/1563 [==============================] - ETA: 0s - loss: 1.1052 - accuracy: 0.6344\nEpoch 30: val_accuracy did not improve from 0.71950\n1563/1563 [==============================] - 35s 22ms/step - loss: 1.1052 - accuracy: 0.6344 - val_loss: 0.8275 - val_accuracy: 0.7135 - lr: 0.0010\nEpoch 31/100\n1563/1563 [==============================] - ETA: 0s - loss: 1.1002 - accuracy: 0.6357\nEpoch 31: val_accuracy did not improve from 0.71950\n1563/1563 [==============================] - 35s 23ms/step - loss: 1.1002 - accuracy: 0.6357 - val_loss: 1.0448 - val_accuracy: 0.6508 - lr: 0.0010\nEpoch 32/100\n1563/1563 [==============================] - ETA: 0s - loss: 1.0892 - accuracy: 0.6390\nEpoch 32: val_accuracy did not improve from 0.71950\n1563/1563 [==============================] - 36s 23ms/step - loss: 1.0892 - accuracy: 0.6390 - val_loss: 0.8500 - val_accuracy: 0.7127 - lr: 0.0010\nEpoch 33/100\n1563/1563 [==============================] - ETA: 0s - loss: 1.0825 - accuracy: 0.6395\nEpoch 33: val_accuracy improved from 0.71950 to 0.73240, saving model to /content/drive/MyDrive/checkpoints/cifar10_best_model.h5\n1563/1563 [==============================] - 35s 22ms/step - loss: 1.0825 - accuracy: 0.6395 - val_loss: 0.7995 - val_accuracy: 0.7324 - lr: 0.0010\nEpoch 34/100\n1562/1563 [============================&gt;.] - ETA: 0s - loss: 1.0815 - accuracy: 0.6441\nEpoch 34: val_accuracy did not improve from 0.73240\n1563/1563 [==============================] - 36s 23ms/step - loss: 1.0817 - accuracy: 0.6440 - val_loss: 0.7821 - val_accuracy: 0.7324 - lr: 0.0010\nEpoch 35/100\n1562/1563 [============================&gt;.] - ETA: 0s - loss: 1.0743 - accuracy: 0.6473\nEpoch 35: val_accuracy did not improve from 0.73240\n1563/1563 [==============================] - 36s 23ms/step - loss: 1.0742 - accuracy: 0.6473 - val_loss: 0.7895 - val_accuracy: 0.7282 - lr: 0.0010\nEpoch 36/100\n1562/1563 [============================&gt;.] - ETA: 0s - loss: 1.0695 - accuracy: 0.6486\nEpoch 36: val_accuracy did not improve from 0.73240\n1563/1563 [==============================] - 37s 24ms/step - loss: 1.0693 - accuracy: 0.6487 - val_loss: 0.8054 - val_accuracy: 0.7223 - lr: 0.0010\nEpoch 37/100\n1562/1563 [============================&gt;.] - ETA: 0s - loss: 1.0633 - accuracy: 0.6510\nEpoch 37: val_accuracy improved from 0.73240 to 0.73660, saving model to /content/drive/MyDrive/checkpoints/cifar10_best_model.h5\n1563/1563 [==============================] - 35s 23ms/step - loss: 1.0631 - accuracy: 0.6511 - val_loss: 0.7637 - val_accuracy: 0.7366 - lr: 0.0010\nEpoch 38/100\n1562/1563 [============================&gt;.] - ETA: 0s - loss: 1.0701 - accuracy: 0.6509\nEpoch 38: val_accuracy did not improve from 0.73660\n1563/1563 [==============================] - 37s 23ms/step - loss: 1.0701 - accuracy: 0.6509 - val_loss: 0.8457 - val_accuracy: 0.7136 - lr: 0.0010\nEpoch 39/100\n1561/1563 [============================&gt;.] - ETA: 0s - loss: 1.0467 - accuracy: 0.6584\nEpoch 39: val_accuracy did not improve from 0.73660\n1563/1563 [==============================] - 38s 24ms/step - loss: 1.0463 - accuracy: 0.6585 - val_loss: 0.8873 - val_accuracy: 0.7043 - lr: 0.0010\nEpoch 40/100\n1562/1563 [============================&gt;.] - ETA: 0s - loss: 1.0546 - accuracy: 0.6548\nEpoch 40: val_accuracy did not improve from 0.73660\n1563/1563 [==============================] - 37s 24ms/step - loss: 1.0547 - accuracy: 0.6547 - val_loss: 0.8820 - val_accuracy: 0.6985 - lr: 0.0010\nEpoch 41/100\n1561/1563 [============================&gt;.] - ETA: 0s - loss: 1.0483 - accuracy: 0.6572\nEpoch 41: val_accuracy did not improve from 0.73660\n1563/1563 [==============================] - 37s 24ms/step - loss: 1.0483 - accuracy: 0.6572 - val_loss: 1.1795 - val_accuracy: 0.6351 - lr: 0.0010\nEpoch 42/100\n1563/1563 [==============================] - ETA: 0s - loss: 1.0463 - accuracy: 0.6583\nEpoch 42: val_accuracy improved from 0.73660 to 0.74890, saving model to /content/drive/MyDrive/checkpoints/cifar10_best_model.h5\n1563/1563 [==============================] - 35s 22ms/step - loss: 1.0463 - accuracy: 0.6583 - val_loss: 0.7433 - val_accuracy: 0.7489 - lr: 0.0010\nEpoch 43/100\n1563/1563 [==============================] - ETA: 0s - loss: 1.0436 - accuracy: 0.6599\nEpoch 43: val_accuracy did not improve from 0.74890\n1563/1563 [==============================] - 38s 25ms/step - loss: 1.0436 - accuracy: 0.6599 - val_loss: 0.8552 - val_accuracy: 0.7113 - lr: 0.0010\nEpoch 44/100\n1563/1563 [==============================] - ETA: 0s - loss: 1.0321 - accuracy: 0.6626\nEpoch 44: val_accuracy did not improve from 0.74890\n1563/1563 [==============================] - 36s 23ms/step - loss: 1.0321 - accuracy: 0.6626 - val_loss: 0.7819 - val_accuracy: 0.7274 - lr: 0.0010\nEpoch 45/100\n1562/1563 [============================&gt;.] - ETA: 0s - loss: 1.0337 - accuracy: 0.6601\nEpoch 45: val_accuracy did not improve from 0.74890\n1563/1563 [==============================] - 36s 23ms/step - loss: 1.0336 - accuracy: 0.6602 - val_loss: 0.7743 - val_accuracy: 0.7347 - lr: 0.0010\nEpoch 46/100\n1563/1563 [==============================] - ETA: 0s - loss: 1.0330 - accuracy: 0.6638\nEpoch 46: val_accuracy improved from 0.74890 to 0.75150, saving model to /content/drive/MyDrive/checkpoints/cifar10_best_model.h5\n1563/1563 [==============================] - 36s 23ms/step - loss: 1.0330 - accuracy: 0.6638 - val_loss: 0.7259 - val_accuracy: 0.7515 - lr: 0.0010\nEpoch 47/100\n1561/1563 [============================&gt;.] - ETA: 0s - loss: 1.0208 - accuracy: 0.6666\nEpoch 47: val_accuracy improved from 0.75150 to 0.76160, saving model to /content/drive/MyDrive/checkpoints/cifar10_best_model.h5\n1563/1563 [==============================] - 35s 23ms/step - loss: 1.0209 - accuracy: 0.6665 - val_loss: 0.7046 - val_accuracy: 0.7616 - lr: 0.0010\nEpoch 48/100\n1562/1563 [============================&gt;.] - ETA: 0s - loss: 1.0166 - accuracy: 0.6695\nEpoch 48: val_accuracy did not improve from 0.76160\n1563/1563 [==============================] - 35s 22ms/step - loss: 1.0166 - accuracy: 0.6695 - val_loss: 0.9199 - val_accuracy: 0.6951 - lr: 0.0010\nEpoch 49/100\n1561/1563 [============================&gt;.] - ETA: 0s - loss: 1.0137 - accuracy: 0.6683\nEpoch 49: val_accuracy did not improve from 0.76160\n1563/1563 [==============================] - 35s 23ms/step - loss: 1.0139 - accuracy: 0.6682 - val_loss: 0.7090 - val_accuracy: 0.7582 - lr: 0.0010\nEpoch 50/100\n1561/1563 [============================&gt;.] - ETA: 0s - loss: 1.0255 - accuracy: 0.6638\nEpoch 50: val_accuracy did not improve from 0.76160\n1563/1563 [==============================] - 35s 22ms/step - loss: 1.0254 - accuracy: 0.6638 - val_loss: 0.7449 - val_accuracy: 0.7444 - lr: 0.0010\nEpoch 51/100\n1563/1563 [==============================] - ETA: 0s - loss: 1.0145 - accuracy: 0.6688\nEpoch 51: val_accuracy did not improve from 0.76160\n1563/1563 [==============================] - 38s 24ms/step - loss: 1.0145 - accuracy: 0.6688 - val_loss: 0.8169 - val_accuracy: 0.7207 - lr: 0.0010\nEpoch 52/100\n1563/1563 [==============================] - ETA: 0s - loss: 1.0186 - accuracy: 0.6681\nEpoch 52: val_accuracy did not improve from 0.76160\n1563/1563 [==============================] - 37s 24ms/step - loss: 1.0186 - accuracy: 0.6681 - val_loss: 0.7924 - val_accuracy: 0.7355 - lr: 0.0010\nEpoch 53/100\n1561/1563 [============================&gt;.] - ETA: 0s - loss: 1.0113 - accuracy: 0.6686\nEpoch 53: val_accuracy did not improve from 0.76160\n1563/1563 [==============================] - 36s 23ms/step - loss: 1.0113 - accuracy: 0.6685 - val_loss: 0.7319 - val_accuracy: 0.7498 - lr: 0.0010\nEpoch 54/100\n1563/1563 [==============================] - ETA: 0s - loss: 1.0109 - accuracy: 0.6712\nEpoch 54: val_accuracy did not improve from 0.76160\n1563/1563 [==============================] - 36s 23ms/step - loss: 1.0109 - accuracy: 0.6712 - val_loss: 1.0983 - val_accuracy: 0.6648 - lr: 0.0010\nEpoch 55/100\n1561/1563 [============================&gt;.] - ETA: 0s - loss: 1.0129 - accuracy: 0.6713\nEpoch 55: val_accuracy did not improve from 0.76160\n1563/1563 [==============================] - 36s 23ms/step - loss: 1.0129 - accuracy: 0.6713 - val_loss: 0.8429 - val_accuracy: 0.7179 - lr: 0.0010\nEpoch 56/100\n1561/1563 [============================&gt;.] - ETA: 0s - loss: 0.9992 - accuracy: 0.6728\nEpoch 56: val_accuracy did not improve from 0.76160\n1563/1563 [==============================] - 37s 23ms/step - loss: 0.9993 - accuracy: 0.6729 - val_loss: 0.8258 - val_accuracy: 0.7244 - lr: 0.0010\nEpoch 57/100\n1563/1563 [==============================] - ETA: 0s - loss: 0.9956 - accuracy: 0.6758\nEpoch 57: val_accuracy improved from 0.76160 to 0.77110, saving model to /content/drive/MyDrive/checkpoints/cifar10_best_model.h5\n1563/1563 [==============================] - 37s 24ms/step - loss: 0.9956 - accuracy: 0.6758 - val_loss: 0.6726 - val_accuracy: 0.7711 - lr: 0.0010\nEpoch 58/100\n1563/1563 [==============================] - ETA: 0s - loss: 1.0006 - accuracy: 0.6737\nEpoch 58: val_accuracy did not improve from 0.77110\n1563/1563 [==============================] - 36s 23ms/step - loss: 1.0006 - accuracy: 0.6737 - val_loss: 0.8017 - val_accuracy: 0.7251 - lr: 0.0010\nEpoch 59/100\n1563/1563 [==============================] - ETA: 0s - loss: 0.9981 - accuracy: 0.6732\nEpoch 59: val_accuracy did not improve from 0.77110\n1563/1563 [==============================] - 37s 24ms/step - loss: 0.9981 - accuracy: 0.6732 - val_loss: 0.7429 - val_accuracy: 0.7520 - lr: 0.0010\nEpoch 60/100\n1562/1563 [============================&gt;.] - ETA: 0s - loss: 0.9920 - accuracy: 0.6789\nEpoch 60: val_accuracy did not improve from 0.77110\n1563/1563 [==============================] - 38s 24ms/step - loss: 0.9920 - accuracy: 0.6789 - val_loss: 0.7769 - val_accuracy: 0.7382 - lr: 0.0010\nEpoch 61/100\n1563/1563 [==============================] - ETA: 0s - loss: 0.9926 - accuracy: 0.6794\nEpoch 61: val_accuracy did not improve from 0.77110\n1563/1563 [==============================] - 36s 23ms/step - loss: 0.9926 - accuracy: 0.6794 - val_loss: 0.8365 - val_accuracy: 0.7146 - lr: 0.0010\nEpoch 62/100\n1563/1563 [==============================] - ETA: 0s - loss: 0.9928 - accuracy: 0.6751\nEpoch 62: val_accuracy did not improve from 0.77110\n1563/1563 [==============================] - 37s 23ms/step - loss: 0.9928 - accuracy: 0.6751 - val_loss: 0.7080 - val_accuracy: 0.7619 - lr: 0.0010\nEpoch 63/100\n1562/1563 [============================&gt;.] - ETA: 0s - loss: 0.9901 - accuracy: 0.6787\nEpoch 63: val_accuracy did not improve from 0.77110\n1563/1563 [==============================] - 36s 23ms/step - loss: 0.9901 - accuracy: 0.6787 - val_loss: 0.8295 - val_accuracy: 0.7269 - lr: 0.0010\nEpoch 64/100\n1562/1563 [============================&gt;.] - ETA: 0s - loss: 0.9890 - accuracy: 0.6796\nEpoch 64: val_accuracy did not improve from 0.77110\n1563/1563 [==============================] - 37s 24ms/step - loss: 0.9888 - accuracy: 0.6796 - val_loss: 0.7512 - val_accuracy: 0.7521 - lr: 0.0010\nEpoch 65/100\n1563/1563 [==============================] - ETA: 0s - loss: 0.9867 - accuracy: 0.6767\nEpoch 65: val_accuracy did not improve from 0.77110\n1563/1563 [==============================] - 35s 23ms/step - loss: 0.9867 - accuracy: 0.6767 - val_loss: 0.7518 - val_accuracy: 0.7448 - lr: 0.0010\nEpoch 66/100\n1562/1563 [============================&gt;.] - ETA: 0s - loss: 0.9789 - accuracy: 0.6827\nEpoch 66: val_accuracy did not improve from 0.77110\n1563/1563 [==============================] - 37s 24ms/step - loss: 0.9788 - accuracy: 0.6828 - val_loss: 0.7259 - val_accuracy: 0.7563 - lr: 0.0010\nEpoch 67/100\n1562/1563 [============================&gt;.] - ETA: 0s - loss: 0.9799 - accuracy: 0.6839\nEpoch 67: val_accuracy did not improve from 0.77110\nRestoring model weights from the end of the best epoch: 57.\n1563/1563 [==============================] - 37s 24ms/step - loss: 0.9799 - accuracy: 0.6838 - val_loss: 0.8824 - val_accuracy: 0.7192 - lr: 0.0010\nEpoch 67: early stopping\n</pre> In\u00a0[20]: Copied! <pre>from matplotlib import pyplot as plt\n\n## exibe history com plot de loss e\n#acuracia\ndef plot_history(history):\n  # summarize history for loss\n  plt.plot(history.history['loss'])\n  plt.plot(history.history['val_loss'])\n  plt.title('Model loss')\n  plt.ylabel('loss')\n  plt.xlabel('epoch')\n  plt.legend(['train', 'test'], loc='upper left')\n  plt.show()\n  # summarize history for accuracy\n  plt.plot(history.history['accuracy'])\n  plt.plot(history.history['val_accuracy'])\n  plt.title('model accuracy')\n  plt.ylabel('accuracy')\n  plt.xlabel('epoch')\n  plt.legend(['train', 'test'], loc='upper left')\n  plt.show()\n\nplot_history(history)\n</pre> from matplotlib import pyplot as plt  ## exibe history com plot de loss e #acuracia def plot_history(history):   # summarize history for loss   plt.plot(history.history['loss'])   plt.plot(history.history['val_loss'])   plt.title('Model loss')   plt.ylabel('loss')   plt.xlabel('epoch')   plt.legend(['train', 'test'], loc='upper left')   plt.show()   # summarize history for accuracy   plt.plot(history.history['accuracy'])   plt.plot(history.history['val_accuracy'])   plt.title('model accuracy')   plt.ylabel('accuracy')   plt.xlabel('epoch')   plt.legend(['train', 'test'], loc='upper left')   plt.show()  plot_history(history)  In\u00a0[11]: Copied! <pre># Carregando o conjunto de dados de teste CIFAR-10\n(x_test, y_test) = cifar10.load_data()[1]\n\n# Normalizando os valores dos pixels para o intervalo [0, 1]\nx_test = x_test.astype('float32') / 255.0\n\n# Convertendo os r\u00f3tulos para vetores one-hot\ny_test = to_categorical(y_test, 10)\n</pre> # Carregando o conjunto de dados de teste CIFAR-10 (x_test, y_test) = cifar10.load_data()[1]  # Normalizando os valores dos pixels para o intervalo [0, 1] x_test = x_test.astype('float32') / 255.0  # Convertendo os r\u00f3tulos para vetores one-hot y_test = to_categorical(y_test, 10)  In\u00a0[13]: Copied! <pre># Carregando o melhor modelo salvo durante o treinamento\nbest_model = tf.keras.models.load_model(model_save_path)\n\n# Avaliando o melhor modelo salvo nos dados de teste\nbest_test_loss, best_test_accuracy = best_model.evaluate(x_test, y_test, verbose=2)\nprint(f'Best test loss: {best_test_loss}')\nprint(f'Best test accuracy: {best_test_accuracy}')\n</pre> # Carregando o melhor modelo salvo durante o treinamento best_model = tf.keras.models.load_model(model_save_path)  # Avaliando o melhor modelo salvo nos dados de teste best_test_loss, best_test_accuracy = best_model.evaluate(x_test, y_test, verbose=2) print(f'Best test loss: {best_test_loss}') print(f'Best test accuracy: {best_test_accuracy}')  <pre>313/313 - 1s - loss: 0.6726 - accuracy: 0.7711 - 1s/epoch - 4ms/step\nBest test loss: 0.6726096868515015\nBest test accuracy: 0.7710999846458435\n</pre> In\u00a0[21]: Copied! <pre>import numpy as np\n\n# Fazendo previs\u00f5es no conjunto de dados de teste\npredictions = best_model.predict(x_test)\npredicted_classes = np.argmax(predictions, axis=1)\ntrue_classes = np.argmax(y_test, axis=1)\n\n# Nomes das classes CIFAR-10\nclass_names = ['Airplane', 'Automobile', 'Bird', 'Cat', 'Deer', 'Dog', 'Frog', 'Horse', 'Ship', 'Truck']\n</pre> import numpy as np  # Fazendo previs\u00f5es no conjunto de dados de teste predictions = best_model.predict(x_test) predicted_classes = np.argmax(predictions, axis=1) true_classes = np.argmax(y_test, axis=1)  # Nomes das classes CIFAR-10 class_names = ['Airplane', 'Automobile', 'Bird', 'Cat', 'Deer', 'Dog', 'Frog', 'Horse', 'Ship', 'Truck'] <pre>313/313 [==============================] - 1s 2ms/step\n</pre> In\u00a0[23]: Copied! <pre>import seaborn as sns\nfrom sklearn.metrics import confusion_matrix\n\n# Fun\u00e7\u00e3o para plotar a matriz de confus\u00e3o\ndef plot_confusion_matrix(true_labels, predicted_labels, class_names):\n    cm = confusion_matrix(true_labels, predicted_labels)\n    plt.figure(figsize=(10, 8))\n    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=class_names, yticklabels=class_names)\n    plt.xlabel('Predicted')\n    plt.ylabel('True')\n    plt.show()\n\n\n# Visualizando a matriz de confus\u00e3o\nprint(\"Matriz de Confus\u00e3o:\")\nplot_confusion_matrix(true_classes, predicted_classes, class_names)\n</pre> import seaborn as sns from sklearn.metrics import confusion_matrix  # Fun\u00e7\u00e3o para plotar a matriz de confus\u00e3o def plot_confusion_matrix(true_labels, predicted_labels, class_names):     cm = confusion_matrix(true_labels, predicted_labels)     plt.figure(figsize=(10, 8))     sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=class_names, yticklabels=class_names)     plt.xlabel('Predicted')     plt.ylabel('True')     plt.show()   # Visualizando a matriz de confus\u00e3o print(\"Matriz de Confus\u00e3o:\") plot_confusion_matrix(true_classes, predicted_classes, class_names) <pre>Matriz de Confus\u00e3o:\n</pre> In\u00a0[25]: Copied! <pre>import matplotlib.pyplot as plt\n\n# Fun\u00e7\u00e3o para plotar imagens com r\u00f3tulos verdadeiros e previstos\ndef plot_images(images, true_labels, predicted_labels, class_names, num_images=10):\n    plt.figure(figsize=(15, 15))\n    for i in range(num_images):\n        plt.subplot(5, 5, i + 1)\n        plt.imshow(images[i])\n        plt.title(f'True: {class_names[true_labels[i]]}\\nPred: {class_names[predicted_labels[i]]}')\n        plt.axis('off')\n    plt.show()\n\n# Fun\u00e7\u00e3o para plotar imagens de resultados corretos\ndef plot_correct_predictions(images, true_labels, predicted_labels, class_names):\n    correct_indices = np.where(predicted_labels == true_labels)[0]\n    plot_images(images[correct_indices], true_labels[correct_indices], predicted_labels[correct_indices], class_names)\n\n# Fun\u00e7\u00e3o para plotar imagens de resultados incorretos\ndef plot_incorrect_predictions(images, true_labels, predicted_labels, class_names):\n    incorrect_indices = np.where(predicted_labels != true_labels)[0]\n    plot_images(images[incorrect_indices], true_labels[incorrect_indices], predicted_labels[incorrect_indices], class_names)\n</pre> import matplotlib.pyplot as plt  # Fun\u00e7\u00e3o para plotar imagens com r\u00f3tulos verdadeiros e previstos def plot_images(images, true_labels, predicted_labels, class_names, num_images=10):     plt.figure(figsize=(15, 15))     for i in range(num_images):         plt.subplot(5, 5, i + 1)         plt.imshow(images[i])         plt.title(f'True: {class_names[true_labels[i]]}\\nPred: {class_names[predicted_labels[i]]}')         plt.axis('off')     plt.show()  # Fun\u00e7\u00e3o para plotar imagens de resultados corretos def plot_correct_predictions(images, true_labels, predicted_labels, class_names):     correct_indices = np.where(predicted_labels == true_labels)[0]     plot_images(images[correct_indices], true_labels[correct_indices], predicted_labels[correct_indices], class_names)  # Fun\u00e7\u00e3o para plotar imagens de resultados incorretos def plot_incorrect_predictions(images, true_labels, predicted_labels, class_names):     incorrect_indices = np.where(predicted_labels != true_labels)[0]     plot_images(images[incorrect_indices], true_labels[incorrect_indices], predicted_labels[incorrect_indices], class_names) <p>chamando as fun\u00e7\u00f5es</p> In\u00a0[26]: Copied! <pre># Visualizando algumas imagens de resultados corretos\nprint(\"Imagens de Resultados Corretos:\")\nplot_correct_predictions(x_test, true_classes, predicted_classes, class_names)\n\n# Visualizando algumas imagens de resultados incorretos\nprint(\"Imagens de Resultados Incorretos:\")\nplot_incorrect_predictions(x_test, true_classes, predicted_classes, class_names)\n</pre> # Visualizando algumas imagens de resultados corretos print(\"Imagens de Resultados Corretos:\") plot_correct_predictions(x_test, true_classes, predicted_classes, class_names)  # Visualizando algumas imagens de resultados incorretos print(\"Imagens de Resultados Incorretos:\") plot_incorrect_predictions(x_test, true_classes, predicted_classes, class_names)   <pre>Imagens de Resultados Corretos:\n</pre> <pre>Imagens de Resultados Incorretos:\n</pre>"},{"location":"aulas/IA/lab11/cnn_completo.html#exemplo-completo-juntando-tudo-que-ja-vimos-e-mais-um-pouco","title":"Exemplo completo juntando tudo que j\u00e1 vimos e mais um pouco...\u00b6","text":"<p>Vamos usar o conjunto de dados CIFAR-10, que \u00e9 um conjunto de dados de 60.000 imagens de 10 classes, com 6.000 imagens por classe.</p> <p>As imagens s\u00e3o de tamanho 32x32 pixels com tr\u00eas canais de cores (RGB).</p> <p>Ao longo do notebook vamos relembrar alguns conceitos e conhecer novos.</p> <p><code>LEMBRETE IMPORTANTE</code>: Lembre-se de setar o colab para usar a GPU.</p>"},{"location":"aulas/IA/lab11/cnn_completo.html#configurando-o-google-drive","title":"Configurando o google drive\u00b6","text":"<p>Vamos setar o google drive para salvar o modelo durante o treinamento</p>"},{"location":"aulas/IA/lab11/cnn_completo.html#importando-e-preparando-os-dados-cifar-10","title":"Importando e Preparando os Dados CIFAR-10\u00b6","text":"<p>Primeiro, vamos importar e preparar os dados CIFAR-10:</p>"},{"location":"aulas/IA/lab11/cnn_completo.html#definindo-o-modelo","title":"Definindo o Modelo\u00b6","text":"<p>Vamos definir o modelo para o dataset:</p>"},{"location":"aulas/IA/lab11/cnn_completo.html#configurando-callbacks","title":"Configurando Callbacks\u00b6","text":"<p>Vamos configurar as <code>callbacks</code>: <code>ModelCheckpoint</code>, <code>EarlyStopping</code> e <code>ReduceLROnPlateau</code>:</p>"},{"location":"aulas/IA/lab11/cnn_completo.html#configurando-data-augmentation","title":"Configurando Data Augmentation\u00b6","text":"<p>Vamos configurar a data augmentation usando ImageDataGenerator:</p>"},{"location":"aulas/IA/lab11/cnn_completo.html#treinando-o-modelo","title":"Treinando o Modelo\u00b6","text":"<p>Finalmente chegou o momento de treinar o modelo com as callbacks e data augmentation:</p>"},{"location":"aulas/IA/lab11/cnn_completo.html#avaliando-o-treinamento","title":"avaliando o treinamento\u00b6","text":"<p>Vamos dar uma olhada n curva de loss e acuracia do treinamento</p>"},{"location":"aulas/IA/lab11/cnn_completo.html#avaliando-o-modelo-e-carregando-o-melhor-modelo","title":"Avaliando o Modelo e Carregando o Melhor Modelo\u00b6","text":"<p>Vamos carregar conjunto de dados de teste e normalize os valores dos pixels:</p>"},{"location":"aulas/IA/lab11/cnn_completo.html#avaliacao-do-modelo","title":"Avalia\u00e7\u00e3o do Modelo\u00b6","text":"<p>Vamos avaliar o modelo nos dados de teste.</p> <p>Durante o treinamento salvamos no google drive o modelo para garantir que estamos utilizando o modelo com melhor desempenho:</p>"},{"location":"aulas/IA/lab11/cnn_completo.html#fazendo-predicoes-nas-imagens-de-teste","title":"fazendo predi\u00e7\u00f5es nas imagens de teste\u00b6","text":"<p>vamos fazer previs\u00f5es no conjunto de dados de teste:</p>"},{"location":"aulas/IA/lab11/cnn_completo.html#explorando-a-matriz-de-confusao","title":"Explorando a matriz de confus\u00e3o\u00b6","text":"<p>A matriz de confus\u00e3o \u00e9 uma ferramenta para avaliar a performance de um modelo de classifica\u00e7\u00e3o. Ela apresenta uma tabela que resume os resultados das previs\u00f5es do modelo, comparando os r\u00f3tulos previstos com os r\u00f3tulos reais.</p> <p>Como Interpretar:</p> <ul> <li><code>True Positives (TP)</code>: N\u00famero de previs\u00f5es corretas da classe positiva.</li> <li><code>True Negatives (TN)</code>: N\u00famero de previs\u00f5es corretas da classe negativa.</li> <li><code>False Positives (FP)</code>: N\u00famero de previs\u00f5es incorretas onde a classe negativa foi prevista como positiva (erro tipo I).</li> <li><code>False Negatives (FN)</code>: N\u00famero de previs\u00f5es incorretas onde a classe positiva foi prevista como negativa (erro tipo II).</li> </ul> <p>A matriz de confus\u00e3o ajuda a entender n\u00e3o apenas a acur\u00e1cia do modelo, mas tamb\u00e9m os tipos de erros que ele comete. Isso pode ser \u00fatil para:</p> <ul> <li>Identificar classes que s\u00e3o frequentemente confundidas.</li> <li>Melhorar o modelo ao ajustar os hiperpar\u00e2metros ou coletar mais dados para classes espec\u00edficas.</li> </ul>"},{"location":"aulas/IA/lab11/cnn_completo.html#exibindo-os-resultados","title":"Exibindo os resultados\u00b6","text":"<p>Vamos plotar algumas imagens para visualizar os resultados</p>"},{"location":"aulas/PDI/lab04_quiz.html","title":"Quiz Avan\u00e7ado sobre Filtros de Convolu\u00e7\u00e3o (Lab04)","text":""},{"location":"aulas/PDI/lab04_quiz.html#questoes-teoricas","title":"Quest\u00f5es Te\u00f3ricas","text":"<ol> <li>O que \u00e9 um filtro de convolu\u00e7\u00e3o em processamento de imagens e como ele funciona matematicamente?</li> <li>a) Um m\u00e9todo para aumentar o tamanho da imagem atrav\u00e9s de interpola\u00e7\u00e3o bilinear</li> <li>b) Uma opera\u00e7\u00e3o matem\u00e1tica que aplica uma matriz (kernel) em cada pixel da imagem, calculando a soma ponderada dos valores dos pixels vizinhos</li> <li>c) Um processo para converter imagens coloridas em preto e branco usando limiariza\u00e7\u00e3o adaptativa</li> <li>d) Uma t\u00e9cnica para compress\u00e3o de imagens baseada na transformada de Fourier</li> </ol> <ol> <li>Qual \u00e9 o efeito matem\u00e1tico dos filtros de suaviza\u00e7\u00e3o (blurring) na frequ\u00eancia espacial de uma imagem?</li> <li>a) Atuam como passa-altas, preservando as altas frequ\u00eancias (detalhes)</li> <li>b) N\u00e3o alteram o conte\u00fado de frequ\u00eancia da imagem</li> <li>c) Atuam como passa-baixas, atenuando as altas frequ\u00eancias (detalhes)</li> <li> <p>d) Amplificam seletivamente as frequ\u00eancias m\u00e9dias</p> </li> <li> <p>O que acontece com a resposta ao impulso de um filtro Gaussiano quando aumentamos o valor de sigma?</p> </li> <li>a) A resposta se torna mais estreita, resultando em menos suaviza\u00e7\u00e3o</li> <li>b) A resposta se torna mais ampla, resultando em maior suaviza\u00e7\u00e3o</li> <li>c) A resposta oscila mais, criando efeitos de ringing</li> <li> <p>d) A resposta se torna mais direcional, suavizando apenas em uma dire\u00e7\u00e3o</p> </li> <li> <p>Qual \u00e9 a principal diferen\u00e7a te\u00f3rica entre os operadores de Sobel e Laplaciano para detec\u00e7\u00e3o de bordas?</p> </li> <li>a) Sobel \u00e9 baseado na primeira derivada (gradiente), enquanto Laplaciano \u00e9 baseado na segunda derivada</li> <li>b) Sobel funciona apenas em imagens coloridas, enquanto Laplaciano funciona em escala de cinza</li> <li>c) Sobel detecta apenas bordas horizontais, enquanto Laplaciano detecta bordas em todas as dire\u00e7\u00f5es</li> <li> <p>d) Sobel \u00e9 um filtro n\u00e3o-linear, enquanto Laplaciano \u00e9 linear</p> </li> <li> <p>Por que o detector de bordas de Canny \u00e9 considerado superior a simples operadores de gradiente?</p> </li> <li>a) Porque utiliza cores para destacar as bordas</li> <li>b) Porque implementa m\u00faltiplos est\u00e1gios: suaviza\u00e7\u00e3o, c\u00e1lculo de gradiente, supress\u00e3o n\u00e3o-m\u00e1xima e limiariza\u00e7\u00e3o com histerese</li> <li>c) Porque \u00e9 computacionalmente mais eficiente</li> <li>d) Porque funciona exclusivamente em imagens de alta resolu\u00e7\u00e3o</li> </ol>"},{"location":"aulas/PDI/lab04_quiz.html#questoes-praticas","title":"Quest\u00f5es Pr\u00e1ticas","text":"<ol> <li>Observe as imagens abaixo. Qual filtro foi aplicado na imagem da direita?</li> </ol> <ul> <li>a) Filtro de m\u00e9dia (blur)</li> <li>b) Filtro de Sobel</li> <li>c) Filtro Gaussiano</li> <li> <p>d) Filtro de Canny</p> </li> <li> <p>Qual seria o resultado da aplica\u00e7\u00e3o do seguinte kernel em uma imagem? <pre><code>[-1, -1, -1]\n[-1,  9, -1]\n[-1, -1, -1]\n</code></pre></p> </li> <li>a) Suaviza\u00e7\u00e3o da imagem</li> <li>b) Detec\u00e7\u00e3o de bordas</li> <li>c) Aumento de nitidez (sharpening)</li> <li> <p>d) Emboss (efeito de relevo)</p> </li> <li> <p>Calcule o resultado da convolu\u00e7\u00e3o da seguinte matriz de imagem 3x3 com o kernel 3x3 apresentado, considerando o pixel central: <pre><code>Matriz da imagem:       Kernel:\n[10, 20, 30]            [0, 1, 0]\n[40, 50, 60]            [1, -4, 1]\n[70, 80, 90]            [0, 1, 0]\n</code></pre></p> </li> <li>a) -60</li> <li>b) 0</li> <li>c) 60</li> <li> <p>d) 240</p> </li> <li> <p>Ao implementar um filtro de m\u00e9dia 5x5 no OpenCV, qual seria o c\u00f3digo correto?</p> </li> <li>a) <code>cv2.blur(img, (5, 5))</code></li> <li>b) <code>cv2.filter2D(img, -1, np.ones((5,5))/25)</code></li> <li>c) <code>cv2.boxFilter(img, -1, (5, 5), normalize=True)</code></li> <li> <p>d) Todas as alternativas acima produzem o mesmo resultado</p> </li> <li> <p>Analise o c\u00f3digo abaixo e determine sua fun\u00e7\u00e3o: <pre><code>gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\nsobelx = cv2.Sobel(gray, cv2.CV_64F, 1, 0, ksize=3)\nsobely = cv2.Sobel(gray, cv2.CV_64F, 0, 1, ksize=3)\nmagnitude = np.sqrt(sobelx**2 + sobely**2)\ndirection = np.arctan2(sobely, sobelx) * (180/np.pi)\n</code></pre></p> </li> <li>a) Implementa\u00e7\u00e3o do detector de bordas de Canny</li> <li>b) C\u00e1lculo da magnitude e dire\u00e7\u00e3o do gradiente usando operadores de Sobel</li> <li>c) Aplica\u00e7\u00e3o de um filtro de Gabor para an\u00e1lise de textura</li> <li> <p>d) Implementa\u00e7\u00e3o de um filtro passa-banda direcional</p> </li> <li> <p>Qual seria o efeito da seguinte sequ\u00eancia de opera\u00e7\u00f5es em uma imagem com ru\u00eddo? <pre><code>blurred = cv2.GaussianBlur(img, (5, 5), 0)\nsharpened = cv2.addWeighted(img, 1.5, blurred, -0.5, 0)\n</code></pre></p> <ul> <li>a) Remo\u00e7\u00e3o de ru\u00eddo sem perda significativa de detalhes</li> <li>b) Amplifica\u00e7\u00e3o do ru\u00eddo e aumento da nitidez</li> <li>c) Remo\u00e7\u00e3o completa de bordas e detalhes</li> <li>d) Convers\u00e3o para escala de cinza com preserva\u00e7\u00e3o de bordas</li> </ul> </li> </ul>"},{"location":"aulas/PDI/lab04_quiz.html#questoes-de-desafio","title":"Quest\u00f5es de Desafio","text":"<ol> <li> <p>Observe a imagem abaixo. Qual combina\u00e7\u00e3o de t\u00e9cnicas seria mais eficaz para detectar apenas as linhas do tabuleiro de sudoku?</p> <p></p> <ul> <li>a) Limiariza\u00e7\u00e3o adaptativa seguida de opera\u00e7\u00f5es morfol\u00f3gicas</li> <li>b) Filtro Gaussiano seguido de detector de Canny e Transformada de Hough</li> <li>c) Segmenta\u00e7\u00e3o por watershed ap\u00f3s aplica\u00e7\u00e3o de gradiente morfol\u00f3gico</li> <li>d) K-means clustering seguido de detec\u00e7\u00e3o de contornos</li> </ul> </li> <li> <p>Qual \u00e9 o impacto do \"padding\" em opera\u00e7\u00f5es de convolu\u00e7\u00e3o e como ele afeta o tamanho da imagem resultante?</p> <ul> <li>a) O padding SAME mant\u00e9m as dimens\u00f5es originais da imagem, enquanto o padding VALID reduz as dimens\u00f5es</li> <li>b) O padding n\u00e3o afeta o tamanho da imagem, apenas a intensidade dos pixels de borda</li> <li>c) O padding sempre aumenta o tamanho da imagem final proporcionalmente ao tamanho do kernel</li> <li>d) O padding \u00e9 usado apenas para kernels de tamanho par</li> </ul> <p></p> </li> <li> <p>Considere um filtro bilateral aplicado a uma imagem. O que diferencia este filtro de um filtro Gaussiano tradicional?</p> <ul> <li>a) O filtro bilateral \u00e9 mais r\u00e1pido computacionalmente</li> <li>b) O filtro bilateral preserva bordas enquanto suaviza regi\u00f5es homog\u00eaneas, pois considera tanto a proximidade espacial quanto a similaridade de intensidade</li> <li>c) O filtro bilateral funciona apenas em imagens coloridas</li> <li>d) O filtro bilateral aplica suaviza\u00e7\u00e3o apenas na dire\u00e7\u00e3o do gradiente local</li> </ul> </li> <li> <p>Qual seria o resultado da aplica\u00e7\u00e3o do seguinte kernel em uma imagem em escala de cinza? <pre><code>[ 0, -1,  0]\n[-1,  4, -1]\n[ 0, -1,  0]\n</code></pre></p> <ul> <li>a) Suaviza\u00e7\u00e3o da imagem</li> <li>b) Detec\u00e7\u00e3o de bordas usando aproxima\u00e7\u00e3o do Laplaciano</li> <li>c) Aumento de nitidez (sharpening)</li> <li>d) Detec\u00e7\u00e3o de cantos (corner detection)</li> </ul> </li> <li> <p>Observe a imagem abaixo. Que sequ\u00eancia de opera\u00e7\u00f5es seria mais adequada para isolar apenas o pinguim Tux do fundo?</p> <p></p> <ul> <li>a) Convers\u00e3o para escala de cinza, limiariza\u00e7\u00e3o de Otsu e opera\u00e7\u00f5es morfol\u00f3gicas</li> <li>b) Segmenta\u00e7\u00e3o baseada em cor no espa\u00e7o HSV, seguida de detec\u00e7\u00e3o de contornos</li> <li>c) Aplica\u00e7\u00e3o do algoritmo GrabCut com inicializa\u00e7\u00e3o autom\u00e1tica</li> <li>d) Detector de Canny seguido de preenchimento de contornos fechados</li> </ul> </li> <li> <p>Em processamento de imagens m\u00e9dicas, qual t\u00e9cnica baseada em convolu\u00e7\u00e3o \u00e9 frequentemente usada para real\u00e7ar estruturas tubulares como vasos sangu\u00edneos?</p> <ul> <li>a) Filtros de Gabor em m\u00faltiplas escalas e orienta\u00e7\u00f5es</li> <li>b) Filtros de casamento (matched filters) baseados em perfis gaussianos</li> <li>c) Filtros de difus\u00e3o anisotr\u00f3pica</li> <li>d) Todas as alternativas acima</li> </ul> </li> <li> <p>Qual \u00e9 o princ\u00edpio matem\u00e1tico por tr\u00e1s da implementa\u00e7\u00e3o eficiente de filtros de convolu\u00e7\u00e3o separ\u00e1veis?</p> <ul> <li>a) A decomposi\u00e7\u00e3o do kernel 2D em dois vetores 1D, reduzindo a complexidade computacional de O(n\u00b2) para O(2n)</li> <li>b) A aplica\u00e7\u00e3o da transformada r\u00e1pida de Fourier (FFT) para converter a convolu\u00e7\u00e3o em multiplica\u00e7\u00e3o no dom\u00ednio da frequ\u00eancia</li> <li>c) A utiliza\u00e7\u00e3o de integrais de imagem (summed area tables) para calcular somas em regi\u00f5es retangulares</li> <li>d) A implementa\u00e7\u00e3o de algoritmos paralelos em GPU</li> </ul> </li> <li> <p>Qual destas afirma\u00e7\u00f5es sobre o detector de bordas de Canny \u00e9 FALSA?</p> <ul> <li>a) Utiliza dois limiares para detectar bordas fortes e fracas</li> <li>b) Inclui uma etapa de supress\u00e3o n\u00e3o-m\u00e1xima para afinar as bordas</li> <li>c) \u00c9 invariante a rota\u00e7\u00f5es e mudan\u00e7as de escala</li> <li>d) Geralmente aplica um filtro Gaussiano como pr\u00e9-processamento</li> </ul> </li> </ol>"},{"location":"aulas/PDI/lab04_quiz.html#respostas","title":"Respostas","text":"<ol> <li>b</li> <li>c</li> <li>b</li> <li>a</li> <li>b</li> <li>b</li> <li>c</li> <li>a</li> <li>d</li> <li>b</li> <li>a</li> <li>b</li> <li>a</li> <li>b</li> <li>b</li> <li>b</li> <li>d</li> <li>a</li> <li>c</li> </ol>"},{"location":"aulas/PDI/lab05_quiz.html","title":"Quiz Lab05 - Espa\u00e7o de Cor e Contornos","text":"<p>Este quiz aborda os conceitos de espa\u00e7o de cor HSV, m\u00e1scaras, detec\u00e7\u00e3o de contornos, c\u00e1lculo de centro de massa, e opera\u00e7\u00f5es de desenho em imagens utilizando OpenCV.</p>"},{"location":"aulas/PDI/lab05_quiz.html#questoes-teoricas","title":"Quest\u00f5es Te\u00f3ricas","text":""},{"location":"aulas/PDI/lab05_quiz.html#1-o-que-representa-o-componente-h-no-espaco-de-cores-hsv","title":"1. O que representa o componente H no espa\u00e7o de cores HSV?","text":"<p>a) Brilho (Brightness) b) Satura\u00e7\u00e3o (Saturation) c) Matiz (Hue) d) Valor (Value)</p> <p></p>"},{"location":"aulas/PDI/lab05_quiz.html#2-qual-a-principal-vantagem-do-espaco-de-cor-hsv-em-relacao-ao-rgb-para-segmentacao-de-cores","title":"2. Qual a principal vantagem do espa\u00e7o de cor HSV em rela\u00e7\u00e3o ao RGB para segmenta\u00e7\u00e3o de cores?","text":"<p>a) \u00c9 mais r\u00e1pido para processar b) Separa a informa\u00e7\u00e3o de cor (matiz) da intensidade c) Utiliza menos mem\u00f3ria d) Tem melhor representa\u00e7\u00e3o de cores escuras</p>"},{"location":"aulas/PDI/lab05_quiz.html#3-na-opencv-qual-e-o-intervalo-de-valores-para-o-componente-h-matiz-no-espaco-hsv","title":"3. Na OpenCV, qual \u00e9 o intervalo de valores para o componente H (matiz) no espa\u00e7o HSV?","text":"<p>a) 0 a 100 b) 0 a 255 c) 0 a 179 d) 0 a 360</p>"},{"location":"aulas/PDI/lab05_quiz.html#4-o-que-e-uma-mascara-binaria-no-contexto-de-processamento-de-imagens","title":"4. O que \u00e9 uma m\u00e1scara bin\u00e1ria no contexto de processamento de imagens?","text":"<p>a) Uma imagem que cont\u00e9m apenas pixels pretos e brancos b) Um filtro que aplica efeitos art\u00edsticos c) Um algoritmo para compress\u00e3o de imagens d) Uma t\u00e9cnica para reduzir ru\u00eddo</p>"},{"location":"aulas/PDI/lab05_quiz.html#5-qual-funcao-da-opencv-e-utilizada-para-encontrar-contornos-em-uma-imagem","title":"5. Qual fun\u00e7\u00e3o da OpenCV \u00e9 utilizada para encontrar contornos em uma imagem?","text":"<p>a) cv2.findEdges() b) cv2.detectContours() c) cv2.findContours() d) cv2.getContours()</p>"},{"location":"aulas/PDI/lab05_quiz.html#questoes-praticas","title":"Quest\u00f5es Pr\u00e1ticas","text":""},{"location":"aulas/PDI/lab05_quiz.html#6-observe-a-imagem-abaixo-qual-seria-a-melhor-abordagem-para-detectar-apenas-o-objeto-vermelho","title":"6. Observe a imagem abaixo. Qual seria a melhor abordagem para detectar apenas o objeto vermelho?","text":"<p>a) Aplicar um filtro de suaviza\u00e7\u00e3o e depois detec\u00e7\u00e3o de bordas b) Converter para HSV e criar uma m\u00e1scara para a faixa de vermelho c) Usar apenas o canal R do RGB e aplicar um limiar d) Converter para escala de cinza e aplicar limiariza\u00e7\u00e3o adaptativa</p>"},{"location":"aulas/PDI/lab05_quiz.html#7-para-calcular-o-centro-de-massa-de-um-contorno-detectado-qual-metodo-da-opencv-e-utilizado","title":"7. Para calcular o centro de massa de um contorno detectado, qual m\u00e9todo da OpenCV \u00e9 utilizado?","text":"<p>a) cv2.contourCenter() b) cv2.moments() c) cv2.centerOfMass() d) cv2.contourCentroid()</p>"},{"location":"aulas/PDI/lab05_quiz.html#8-qual-e-o-resultado-da-seguinte-operacao","title":"8. Qual \u00e9 o resultado da seguinte opera\u00e7\u00e3o?","text":"<pre><code>img = cv2.imread('imagem.png')\nhsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\nlower_blue = np.array([110, 50, 50])\nupper_blue = np.array([130, 255, 255])\nmask = cv2.inRange(hsv, lower_blue, upper_blue)\n</code></pre> <p>a) Convers\u00e3o da imagem para tons de cinza b) Cria\u00e7\u00e3o de uma m\u00e1scara que isola pixels azuis c) Aplica\u00e7\u00e3o de um filtro de suaviza\u00e7\u00e3o d) Detec\u00e7\u00e3o de bordas na imagem</p>"},{"location":"aulas/PDI/lab05_quiz.html#9-observe-a-imagem-abaixo-com-contornos-detectados-qual-funcao-foi-usada-para-desenhar-estes-contornos","title":"9. Observe a imagem abaixo com contornos detectados. Qual fun\u00e7\u00e3o foi usada para desenhar estes contornos?","text":"<p>a) cv2.rectangle() b) cv2.line() c) cv2.drawContours() d) cv2.circle()</p>"},{"location":"aulas/PDI/lab05_quiz.html#10-para-desenhar-um-circulo-no-centro-de-massa-de-um-contorno-qual-sequencia-de-funcoes-deve-ser-usada","title":"10. Para desenhar um c\u00edrculo no centro de massa de um contorno, qual sequ\u00eancia de fun\u00e7\u00f5es deve ser usada?","text":"<p>a) cv2.moments(), c\u00e1lculo do centroide, cv2.circle() b) cv2.findContours(), cv2.boundingRect(), cv2.rectangle() c) cv2.Canny(), cv2.HoughCircles(), cv2.circle() d) cv2.findContours(), cv2.approxPolyDP(), cv2.polylines()</p>"},{"location":"aulas/PDI/lab05_quiz.html#questoes-de-desafio","title":"Quest\u00f5es de Desafio","text":""},{"location":"aulas/PDI/lab05_quiz.html#11-observe-a-imagem-abaixo-que-tecnica-foi-utilizada-para-segmentar-apenas-a-parte-vermelha-da-melancia","title":"11. Observe a imagem abaixo. Que t\u00e9cnica foi utilizada para segmentar apenas a parte vermelha da melancia?","text":"<p>a) Limiariza\u00e7\u00e3o simples em escala de cinza b) Segmenta\u00e7\u00e3o no espa\u00e7o de cor HSV c) Detec\u00e7\u00e3o de bordas seguida de preenchimento d) Subtra\u00e7\u00e3o de fundo</p>"},{"location":"aulas/PDI/lab05_quiz.html#12-qual-e-a-diferenca-entre-cv2chain_approx_simple-e-cv2chain_approx_none-no-contexto-da-funcao-cv2findcontours","title":"12. Qual \u00e9 a diferen\u00e7a entre cv2.CHAIN_APPROX_SIMPLE e cv2.CHAIN_APPROX_NONE no contexto da fun\u00e7\u00e3o cv2.findContours()?","text":"<p>a) CHAIN_APPROX_SIMPLE armazena apenas os pontos extremos, enquanto CHAIN_APPROX_NONE armazena todos os pontos do contorno b) CHAIN_APPROX_SIMPLE \u00e9 mais preciso, enquanto CHAIN_APPROX_NONE \u00e9 mais r\u00e1pido c) CHAIN_APPROX_SIMPLE funciona apenas com formas simples, enquanto CHAIN_APPROX_NONE funciona com qualquer forma d) CHAIN_APPROX_SIMPLE detecta apenas contornos externos, enquanto CHAIN_APPROX_NONE detecta todos os contornos</p>"},{"location":"aulas/PDI/lab05_quiz.html#13-ao-utilizar-a-funcao-cv2findcontours-qual-e-o-significado-do-parametro-de-hierarquia-retornado","title":"13. Ao utilizar a fun\u00e7\u00e3o cv2.findContours(), qual \u00e9 o significado do par\u00e2metro de hierarquia retornado?","text":"<p>a) Indica o tamanho relativo dos contornos b) Representa a rela\u00e7\u00e3o pai-filho entre contornos (contornos dentro de outros) c) Determina a ordem em que os contornos foram detectados d) Indica a profundidade de cor dos contornos</p>"},{"location":"aulas/PDI/lab05_quiz.html#14-observe-a-imagem-abaixo-como-voce-identificaria-apenas-o-pinguim-tux-ignorando-o-fundo-branco","title":"14. Observe a imagem abaixo. Como voc\u00ea identificaria apenas o pinguim Tux, ignorando o fundo branco?","text":"<p>a) Aplicar detec\u00e7\u00e3o de bordas com Canny e preencher o interior b) Usar segmenta\u00e7\u00e3o por watershed c) Converter para HSV e criar uma m\u00e1scara para cores n\u00e3o-brancas d) Aplicar limiariza\u00e7\u00e3o adaptativa seguida de opera\u00e7\u00f5es morfol\u00f3gicas</p>"},{"location":"aulas/PDI/lab05_quiz.html#15-qual-tecnica-seria-mais-adequada-para-detectar-e-contar-os-quadrados-em-uma-imagem-de-um-tabuleiro-de-sudoku","title":"15. Qual t\u00e9cnica seria mais adequada para detectar e contar os quadrados em uma imagem de um tabuleiro de sudoku?","text":"<p>a) Transformada de Hough para linhas b) Detec\u00e7\u00e3o de contornos seguida de aproxima\u00e7\u00e3o poligonal c) Template matching com um modelo de quadrado d) Segmenta\u00e7\u00e3o baseada em cor</p>"},{"location":"aulas/PDI/lab05_quiz.html#respostas","title":"Respostas","text":"<ol> <li>c) Matiz (Hue)</li> <li>b) Separa a informa\u00e7\u00e3o de cor (matiz) da intensidade</li> <li>c) 0 a 179</li> <li>a) Uma imagem que cont\u00e9m apenas pixels pretos e brancos</li> <li>c) cv2.findContours()</li> <li>b) Converter para HSV e criar uma m\u00e1scara para a faixa de vermelho</li> <li>b) cv2.moments()</li> <li>b) Cria\u00e7\u00e3o de uma m\u00e1scara que isola pixels azuis</li> <li>c) cv2.drawContours()</li> <li>a) cv2.moments(), c\u00e1lculo do centroide, cv2.circle()</li> <li>b) Segmenta\u00e7\u00e3o no espa\u00e7o de cor HSV</li> <li>a) CHAIN_APPROX_SIMPLE armazena apenas os pontos extremos, enquanto CHAIN_APPROX_NONE armazena todos os pontos do contorno</li> <li>b) Representa a rela\u00e7\u00e3o pai-filho entre contornos (contornos dentro de outros)</li> <li>c) Converter para HSV e criar uma m\u00e1scara para cores n\u00e3o-brancas</li> <li>b) Detec\u00e7\u00e3o de contornos seguida de aproxima\u00e7\u00e3o poligonal</li> </ol>"},{"location":"aulas/PDI/intro/index.html","title":"Introdu\u00e7\u00e3o","text":"<p>Fa\u00e7a o download do pdf de Introdu\u00e7\u00e3o.</p> <ul> <li>arquivo pdf: Introdu\u00e7\u00e3o</li> </ul>"},{"location":"aulas/PDI/lab01/IntroPID.html","title":"Lab01 - Intro PID","text":"<p>Objetivos da aula:</p> <ul> <li>Conhecer o que \u00e9 uma imagem digital</li> <li>Conhecer como fazer leitura e exibi\u00e7\u00e3o de imagens</li> <li>conhecer algumas propriedades de imagens</li> <li>conhecer canais de cores de imagens</li> </ul> In\u00a0[20]: Copied! <pre># Importando a biblioteca OpenCV\nimport cv2 \n\n#import a biblioteca Numpy8 bits\nimport numpy as np\n\n#linha magica para imprimir graficos no notebook\n%matplotlib inline\nfrom matplotlib import pyplot as plt\n\n\nprint (\"OpenCV Vers\u00e3o : %s \" % cv2.__version__)\n</pre> # Importando a biblioteca OpenCV import cv2   #import a biblioteca Numpy8 bits import numpy as np  #linha magica para imprimir graficos no notebook %matplotlib inline from matplotlib import pyplot as plt   print (\"OpenCV Vers\u00e3o : %s \" % cv2.__version__) <pre>OpenCV Vers\u00e3o : 4.6.0 \n</pre> In\u00a0[21]: Copied! <pre># Para facilitar o download das imagens utilizadas neste notebook\n\n!wget \"https://raw.githubusercontent.com/arnaldojr/cognitivecomputing/master/material/aulas/PDI/lab01/NATUREZA_1.jpg\" /content # este link \u00e9 o local onde a imagem est\u00e1 salva\n!wget \"https://raw.githubusercontent.com/arnaldojr/cognitivecomputing/master/material/aulas/PDI/lab01/img3x3.png\" /content\n</pre> # Para facilitar o download das imagens utilizadas neste notebook  !wget \"https://raw.githubusercontent.com/arnaldojr/cognitivecomputing/master/material/aulas/PDI/lab01/NATUREZA_1.jpg\" /content # este link \u00e9 o local onde a imagem est\u00e1 salva !wget \"https://raw.githubusercontent.com/arnaldojr/cognitivecomputing/master/material/aulas/PDI/lab01/img3x3.png\" /content  <pre>--2023-02-10 19:17:06--  https://raw.githubusercontent.com/arnaldojr/cognitivecomputing/master/material/aulas/lab01/NATUREZA_1.jpg\nResolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.110.133, 185.199.111.133, ...\nConnecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 233789 (228K) [image/jpeg]\nSaving to: \u2018NATUREZA_1.jpg\u2019\n\n\rNATUREZA_1.jpg        0%[                    ]       0  --.-KB/s               \rNATUREZA_1.jpg      100%[===================&gt;] 228.31K  --.-KB/s    in 0.03s   \n\n2023-02-10 19:17:07 (8.44 MB/s) - \u2018NATUREZA_1.jpg\u2019 saved [233789/233789]\n\n/content: Scheme missing.\nFINISHED --2023-02-10 19:17:07--\nTotal wall clock time: 0.2s\nDownloaded: 1 files, 228K in 0.03s (8.44 MB/s)\n--2023-02-10 19:17:07--  https://raw.githubusercontent.com/arnaldojr/cognitivecomputing/master/material/aulas/lab01/img3x3.png\nResolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.110.133, 185.199.111.133, 185.199.108.133, ...\nConnecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.110.133|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 171 [image/png]\nSaving to: \u2018img3x3.png\u2019\n\nimg3x3.png          100%[===================&gt;]     171  --.-KB/s    in 0s      \n\n2023-02-10 19:17:07 (7.21 MB/s) - \u2018img3x3.png\u2019 saved [171/171]\n\n/content: Scheme missing.\nFINISHED --2023-02-10 19:17:07--\nTotal wall clock time: 0.1s\nDownloaded: 1 files, 171 in 0s (7.21 MB/s)\n</pre> In\u00a0[22]: Copied! <pre># para nao imprimir os eixos \nimage = cv2.imread(\"NATUREZA_1.jpg\")\n\nplt.imshow(image,interpolation=\"none\")\nplt.axis('off') \nplt.show()\n</pre> # para nao imprimir os eixos  image = cv2.imread(\"NATUREZA_1.jpg\")  plt.imshow(image,interpolation=\"none\") plt.axis('off')  plt.show() <p>A imagem colorida possui tr\u00eas dimens\u00f5es: as linhas e as colunas da matriz, bem como os canais da imagem. Uma imagem colorida geralmente possui tr\u00eas canais: R (Red - vermelho) G (Green - verde) B (Blue - azul)</p> <p>Mas porque a imagem \u00e9 mostrada de modo estranho pelo pacote matplotlib? Porque a OpenCV representa os canais da imagem na ordem B - G - R, e n\u00e3o R - G - B como \u00e9 esperado pela maior parte das bibliotecas.</p> <p>Assim, para podermos visualizar corretamente uma imagem do OpenCV com matplotlib, precisamos inverter os canais, como no c\u00f3digo abaixo:</p> In\u00a0[\u00a0]: Copied! <pre>image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n\nplt.imshow(image_rgb)\n\nplt.axis('off') \nplt.show()\n</pre> image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)  plt.imshow(image_rgb)  plt.axis('off')  plt.show() In\u00a0[\u00a0]: Copied! <pre># Mostrando a representa\u00e7\u00e3o interna da imagem\nprint(\"Dimens\u00f5es da imagem: \", image_rgb.shape)\nprint(\"Quantidade de linhas: \", image_rgb.shape[0])\nprint(\"Quantidade de colunas: \", image_rgb.shape[1])\nprint(\"Camadas de cores: \", image_rgb.shape[2])\n</pre> # Mostrando a representa\u00e7\u00e3o interna da imagem print(\"Dimens\u00f5es da imagem: \", image_rgb.shape) print(\"Quantidade de linhas: \", image_rgb.shape[0]) print(\"Quantidade de colunas: \", image_rgb.shape[1]) print(\"Camadas de cores: \", image_rgb.shape[2]) <pre>Dimens\u00f5es da imagem:  (768, 1024, 3)\nQuantidade de linhas:  768\nQuantidade de colunas:  1024\nCamadas de cores:  3\n</pre> In\u00a0[\u00a0]: Copied! <pre># Mostrando a representa\u00e7\u00e3o interna da imagem\nprint(\"Dimens\u00f5es da imagem: \\n\", image_rgb)\n</pre> # Mostrando a representa\u00e7\u00e3o interna da imagem print(\"Dimens\u00f5es da imagem: \\n\", image_rgb)  <pre>Dimens\u00f5es da imagem: \n [[[ 10  92 194]\n  [ 12  94 196]\n  [ 12  95 197]\n  ...\n  [  6  98 201]\n  [  5  97 200]\n  [  2  95 198]]\n\n [[ 11  93 195]\n  [ 11  94 196]\n  [ 11  94 196]\n  ...\n  [  6  98 201]\n  [  6  98 201]\n  [  4  97 200]]\n\n [[ 11  94 196]\n  [ 11  94 196]\n  [  9  95 196]\n  ...\n  [  5  97 200]\n  [  7  99 202]\n  [  7 100 203]]\n\n ...\n\n [[  0  69 111]\n  [  1  70 112]\n  [  1  70 112]\n  ...\n  [ 11  31   6]\n  [ 17  41  17]\n  [  6  34   9]]\n\n [[  0  67 109]\n  [  0  69 111]\n  [  2  71 113]\n  ...\n  [ 65 105  68]\n  [ 86 135  90]\n  [ 82 136  86]]\n\n [[  0  66 108]\n  [  0  69 111]\n  [  2  71 113]\n  ...\n  [ 53 109  62]\n  [ 72 138  77]\n  [ 74 145  77]]]\n</pre> <p>A matriz acima \u00e9 a representa\u00e7\u00e3o da imagem de forma num\u00e9rica, \u00e9 o valor de cada pixel da imagem. Com esta imagem fica complicado. Vamos tentar analisar separando os canais de cores de um pixel espec\u00edfico.</p> In\u00a0[\u00a0]: Copied! <pre>(b, g, r) = image[450, 50]\nprint('O pixel (50, 50) tem as seguintes cores:')\nprint('Vermelho:',r, 'Verde:', g, 'Azul:', b)\n</pre> (b, g, r) = image[450, 50] print('O pixel (50, 50) tem as seguintes cores:') print('Vermelho:',r, 'Verde:', g, 'Azul:', b) <pre>O pixel (50, 50) tem as seguintes cores:\nVermelho: 2 Verde: 14 Azul: 36\n</pre> In\u00a0[\u00a0]: Copied! <pre># implemente aqui o seu c\u00f3digo.\n</pre> # implemente aqui o seu c\u00f3digo.     In\u00a0[23]: Copied! <pre>import cv2\nimport numpy as np\n\nfrom matplotlib import pyplot as plt\n\n\n# Carregando a imagem na vers\u00e3o tons de cinza (grayscale) de um arquivo\nimagem_cinza = cv2.imread(\"img3x3.png\", cv2.IMREAD_GRAYSCALE)\n\n# ou use o argumento 0, tem o mesmo efeito de importar na escala de cinza\n#imagem_cinza = cv2.imread(\"img3x3.png\", 0)\n\n\nplt.imshow(imagem_cinza)\n\nplt.axis('off') \nplt.show()\nimagem_cinza\n</pre> import cv2 import numpy as np  from matplotlib import pyplot as plt   # Carregando a imagem na vers\u00e3o tons de cinza (grayscale) de um arquivo imagem_cinza = cv2.imread(\"img3x3.png\", cv2.IMREAD_GRAYSCALE)  # ou use o argumento 0, tem o mesmo efeito de importar na escala de cinza #imagem_cinza = cv2.imread(\"img3x3.png\", 0)   plt.imshow(imagem_cinza)  plt.axis('off')  plt.show() imagem_cinza Out[23]: <pre>array([[ 79, 255,  29],\n       [255, 150, 255],\n       [179, 228, 105]], dtype=uint8)</pre> In\u00a0[\u00a0]: Copied! <pre># Coloque aqui sua solu\u00e7\u00e3o. \nimport cv2\nimport numpy as np\n\nfrom matplotlib import pyplot as plt\n\n\n# Carregando a imagem na vers\u00e3o tons de cinza (grayscale) de um arquivo\nimagem_cinza = cv2.imread(\"img3x3.png\", 0)\n\nplt.imshow(imagem_cinza, cmap='gray')\n\nplt.axis('off') \nplt.show()\nimagem_cinza\n</pre> # Coloque aqui sua solu\u00e7\u00e3o.  import cv2 import numpy as np  from matplotlib import pyplot as plt   # Carregando a imagem na vers\u00e3o tons de cinza (grayscale) de um arquivo imagem_cinza = cv2.imread(\"img3x3.png\", 0)  plt.imshow(imagem_cinza, cmap='gray')  plt.axis('off')  plt.show() imagem_cinza  Out[\u00a0]: <pre>array([[ 79, 255,  29],\n       [255, 150, 255],\n       [179, 228, 105]], dtype=uint8)</pre> In\u00a0[\u00a0]: Copied! <pre># Carregando a imagem na vers\u00e3o colorida de um arquivo\nimport cv2\nimport matplotlib.pyplot as plt\n\nimagem = cv2.imread(\"NATUREZA_1.jpg\")\nimage = cv2.cvtColor(imagem, cv2.COLOR_BGR2RGB)\n\nprint(\"Dimens\u00f5es da imagem: \", image.shape)\n\n\nimagem2 = cv2.resize(image, (600,400), cv2.INTER_LINEAR)\nprint(\"Novas dimens\u00f5es da imagem: \", imagem2.shape)\n\n\nplt.imshow(imagem2)\nplt.show()\n</pre> # Carregando a imagem na vers\u00e3o colorida de um arquivo import cv2 import matplotlib.pyplot as plt  imagem = cv2.imread(\"NATUREZA_1.jpg\") image = cv2.cvtColor(imagem, cv2.COLOR_BGR2RGB)  print(\"Dimens\u00f5es da imagem: \", image.shape)   imagem2 = cv2.resize(image, (600,400), cv2.INTER_LINEAR) print(\"Novas dimens\u00f5es da imagem: \", imagem2.shape)   plt.imshow(imagem2) plt.show() <pre>Dimens\u00f5es da imagem:  (768, 1024, 3)\nNovas dimens\u00f5es da imagem:  (400, 600, 3)\n</pre> In\u00a0[\u00a0]: Copied! <pre>#Implemente aqui sua solu\u00e7\u00e3o............\n\n\n\n\n\n\n\n\n\n\n\n\n# Dica para imprimir varias imagens de forma mais organizada com o matplotlib\n\n#plt.figure(figsize = (20,20))\n#plt.subplot(1, 2, 1);plt.imshow(img)\n#plt.subplot(1, 2, 2);plt.imshow(img2)\n#plt.show()\n</pre> #Implemente aqui sua solu\u00e7\u00e3o............             # Dica para imprimir varias imagens de forma mais organizada com o matplotlib  #plt.figure(figsize = (20,20)) #plt.subplot(1, 2, 1);plt.imshow(img) #plt.subplot(1, 2, 2);plt.imshow(img2) #plt.show() In\u00a0[\u00a0]: Copied! <pre>import cv2\nimport numpy as np\n\n\n# Carregando a imagem na vers\u00e3o tons de cinza (grayscale) de um arquivo\nimagem_cinza = cv2.imread(\"img3x3.png\", cv2.IMREAD_COLOR)\n\nplt.imshow(imagem_cinza)\n\nplt.axis('off') \nplt.show()\n</pre> import cv2 import numpy as np   # Carregando a imagem na vers\u00e3o tons de cinza (grayscale) de um arquivo imagem_cinza = cv2.imread(\"img3x3.png\", cv2.IMREAD_COLOR)  plt.imshow(imagem_cinza)  plt.axis('off')  plt.show() In\u00a0[\u00a0]: Copied! <pre># implemente aqui sua solu\u00e7\u00e3o....\n</pre> # implemente aqui sua solu\u00e7\u00e3o....              In\u00a0[\u00a0]: Copied! <pre># Come\u00e7amos importanto as bibliotecas \nimport cv2\nimport numpy as np\nfrom matplotlib import pyplot as plt\n\n# Criamos o array de zero 3x3\nletra = np.zeros((8,5), dtype=int)\n\n# implemente aqui o seu c\u00f3digo.........\n\n\n\n\n\n\n\n\n\n\n# Plota resultado\n\nplt.imshow(letra)\n</pre> # Come\u00e7amos importanto as bibliotecas  import cv2 import numpy as np from matplotlib import pyplot as plt  # Criamos o array de zero 3x3 letra = np.zeros((8,5), dtype=int)  # implemente aqui o seu c\u00f3digo.........           # Plota resultado  plt.imshow(letra) Out[\u00a0]: <pre>&lt;matplotlib.image.AxesImage at 0x1f695118070&gt;</pre> In\u00a0[\u00a0]: Copied! <pre>import cv2\nimagem = cv2.imread(\"NATUREZA_1.jpg\")\nimage = cv2.cvtColor(imagem, cv2.COLOR_BGR2RGB)\n\nfor y in range(0, image.shape[0]):\n  for x in range(0, image.shape[1]):\n    image[y, x] = (255,0,0) #sobreescrevendo todos os pixels da imagem para a cor vermelha\n    #pass\nplt.imshow(image, interpolation=\"none\")\nplt.show()\n</pre> import cv2 imagem = cv2.imread(\"NATUREZA_1.jpg\") image = cv2.cvtColor(imagem, cv2.COLOR_BGR2RGB)  for y in range(0, image.shape[0]):   for x in range(0, image.shape[1]):     image[y, x] = (255,0,0) #sobreescrevendo todos os pixels da imagem para a cor vermelha     #pass plt.imshow(image, interpolation=\"none\") plt.show() In\u00a0[\u00a0]: Copied! <pre>### seu c\u00f3digo aqui\n</pre> ### seu c\u00f3digo aqui"},{"location":"aulas/PDI/lab01/IntroPID.html#representacao-e-visualizacao-de-imagem","title":"Representa\u00e7\u00e3o e visualiza\u00e7\u00e3o de imagem\u00b6","text":"<p>Uma imagem digital nada mais \u00e9 que uma uma matriz de linhas e colunas, onde cada posi\u00e7\u00e3o desta matriz contem o valor de um pixel.</p> <p>O valor de cada pixel representa a intensidade de cor naquele ponto especifico.</p>"},{"location":"aulas/PDI/lab01/IntroPID.html#dica-para-quem-esta-utilizando-o-google-colab","title":"Dica para quem est\u00e1 utilizando o google colab\u00b6","text":"<p>Por ser uma inst\u00e2ncia que \u00e9 alocada temporariamente precisamos carregar as imagens neste se\u00e7\u00e3o.</p> <p>Est\u00e1 etapa pode ser feita de forma manual, fazendo o upload das imagens.</p> <p>Outra forma \u00e9 fazer o download da imagem para o notebook, lempre-se que \u00e9 um linux rodando! :) da uma olhada no exemplo abaixo.</p>"},{"location":"aulas/PDI/lab01/IntroPID.html#desafio-1","title":"Desafio 1\u00b6","text":"<p>Abra a imagem \"img3x3.png\" e plote suas componentes externas (shape) e internas (matriz).</p> <p>Como voc\u00ea esta relacionado as possi\u00e7\u00f5es da matriz com os pixels da imagem??</p>"},{"location":"aulas/PDI/lab01/IntroPID.html#imagem-em-tons-de-cinza","title":"Imagem em tons de cinza\u00b6","text":"<p>Em muitos casos trabalhamos com imagens na escala de cinza, logo, a imagem possui apenas 1 canal de cor.</p>"},{"location":"aulas/PDI/lab01/IntroPID.html#desafio-2","title":"Desafio 2\u00b6","text":"<p>Eita! alguma est\u00e1 errada nesse plot, era esperado uma imagem na escala de cinza. Por que apareceu isso, como corrigir?</p>"},{"location":"aulas/PDI/lab01/IntroPID.html#amostragem-da-imagem","title":"Amostragem da imagem\u00b6","text":"<p>As imagens capturadas por dispositivos digitais possuem as caracter\u00edsticas de resolu\u00e7\u00e3o espacial e resolu\u00e7\u00e3o de cores Enquanto a resolu\u00e7\u00e3o de cores afeta o n\u00famero de cores que podem serr epresentadas na imagem, sua resolu\u00e7\u00e3o espacial afeta o tamanho que a imagem ir\u00e1 ter. Embora n\u00e3o se possa comparar diretamente a resolu\u00e7\u00e3o de duas imagens com tamanhos diferentes, a imagem do mesmo objeto, se possui mais pixels, significar\u00e1 que tam\u00e9m possui maior resolu\u00e7\u00e3o</p>"},{"location":"aulas/PDI/lab01/IntroPID.html#alterando-o-tamanho-de-uma-imagem","title":"Alterando o tamanho de uma imagem\u00b6","text":"<p>O redimensionamento da imagem pode ser feito na OpenCV atrav\u00e9s do comando <code>cv2.resize(imagem, tamanho, interpola\u00e7\u00e3o)</code></p> <p>O tamanho \u00e9 dado por uma tupla (W,H), onde W \u00e9 a largura (n\u00famero de colunas) e H \u00e9 a altura (n\u00famero de linhas)</p>"},{"location":"aulas/PDI/lab01/IntroPID.html#desafio-3","title":"Desafio 3\u00b6","text":"<p>Comparar os diferentes m\u00e9todos de interpola\u00e7\u00e3o (vizinho mais pr\u00f3ximo, bilinear e bic\u00fabica) ao ampliarmos uma imagem em 10 vezes seu tamanho. Escolha uma imagem pequena.</p> <p>Dica de onde encontrar na documenta\u00e7\u00e3o as flags de interpola\u00e7\u00e3o: https://docs.opencv.org/3.4/da/d54/group__imgproc__transform.html#ga5bb5a1fea74ea38e1a5445ca803ff121</p> <p>Para saber mais sobre interpola\u00e7\u00e3o, sugiro assistir ao video: https://www.youtube.com/watch?v=8bTDssnJyZc&amp;ab_channel=S.M.RiazulIslam</p>"},{"location":"aulas/PDI/lab01/IntroPID.html#alterando-os-valores-dos-pixels-de-uma-imagem","title":"Alterando os valores dos pixels de uma imagem\u00b6","text":""},{"location":"aulas/PDI/lab01/IntroPID.html#range-de-valores","title":"Range de valores\u00b6","text":"<p>Antes de alterar os valores dos pixels temos que entender que a OpenCV trabalha com valores de 8 bits para cada componente de cor ou escala de cinza, quer dizer que os valores possiveis est\u00e3o no range entre 0 e 2\u2078-1, que \u00e9 a mesma que dizer entre 0 e 255.</p>"},{"location":"aulas/PDI/lab01/IntroPID.html#desafio-4","title":"Desafio 4\u00b6","text":"<p>Implemente um codigo que faz a altera\u00e7\u00e3o do pixel(0,0) para a a cor Magenta - RGB (255,0,255);</p>"},{"location":"aulas/PDI/lab01/IntroPID.html#desafio-5","title":"Desafio 5\u00b6","text":"<p>Crie uma array de zero com 8 linhas e 5 colunas. E escreva (desenhe) a primeira letra do seu nome ou grupo.</p> <p>Plot a imagem para visualizar o resultado.</p> <p>Dica: Use np.zeros() para criar o array, para facilitar fa\u00e7a em escala de cinza onde o valor de intensidade do pixel 0=branco e 255=preto.</p>"},{"location":"aulas/PDI/lab01/IntroPID.html#varredura-de-uma-imagem","title":"Varredura de uma imagem\u00b6","text":"<p>Desenvolver uma rotina capaz de varrer sua imagem pixel a pixel \u00e9 muito mais interessante para aplica\u00e7\u00f5es mais pr\u00e1ticas, embora exista tecnicas mais otimizadas e r\u00e1pidas para essa aplica\u00e7\u00e3o, podemos utilizar uma estrutura de dois la\u00e7os For para passar sobre todas as linhas e todas as colunas da matriz (imagem).</p>"},{"location":"aulas/PDI/lab01/IntroPID.html#desafio-6","title":"Desafio 6\u00b6","text":"<p>Utilizando a t\u00e9cnica dos 2 for, implemente uma fun\u00e7\u00e3o que desenha um linha branca na vertical no centro da imagem de largura 50 pixeis. Dica: use um if para checar a posi\u00e7\u00e3o (x,y) antes de pintar de branco o pixel.</p>"},{"location":"aulas/PDI/lab01/sol_IntroPID.html","title":"sol IntroPID","text":"<p>Objetivos da aula:</p> <ul> <li>Conhecer o que \u00e9 uma imagem digital</li> <li>Conhecer como fazer leitura e exibi\u00e7\u00e3o de imagens</li> <li>conhecer algumas propriedades de imagens</li> <li>conhecer canais de cores de imagens</li> </ul> In\u00a0[70]: Copied! <pre># Importando a biblioteca OpenCV\nimport cv2 \n\n#import a biblioteca Numpy8 bits\nimport numpy as np\n\n#linha magica para imprimir graficos no notebook\n%matplotlib inline\nfrom matplotlib import pyplot as plt\n\n\nprint (\"OpenCV Vers\u00e3o : %s \" % cv2.__version__)\n</pre> # Importando a biblioteca OpenCV import cv2   #import a biblioteca Numpy8 bits import numpy as np  #linha magica para imprimir graficos no notebook %matplotlib inline from matplotlib import pyplot as plt   print (\"OpenCV Vers\u00e3o : %s \" % cv2.__version__) <pre>OpenCV Vers\u00e3o : 4.9.0 \n</pre> In\u00a0[\u00a0]: Copied! <pre># Para facilitar o download das imagens utilizadas neste notebook\n\n!wget \"https://raw.githubusercontent.com/arnaldojr/cognitivecomputing/master/material/aulas/PDI/lab01/NATUREZA_1.jpg\" /content # este link \u00e9 o local onde a imagem est\u00e1 salva\n!wget \"https://raw.githubusercontent.com/arnaldojr/cognitivecomputing/master/material/aulas/PDI/lab01/img3x3.png\" /content\n</pre> # Para facilitar o download das imagens utilizadas neste notebook  !wget \"https://raw.githubusercontent.com/arnaldojr/cognitivecomputing/master/material/aulas/PDI/lab01/NATUREZA_1.jpg\" /content # este link \u00e9 o local onde a imagem est\u00e1 salva !wget \"https://raw.githubusercontent.com/arnaldojr/cognitivecomputing/master/material/aulas/PDI/lab01/img3x3.png\" /content  In\u00a0[71]: Copied! <pre># para nao imprimir os eixos \nimage = cv2.imread(\"NATUREZA_1.jpg\")\n\nplt.imshow(image,interpolation=\"none\")\nplt.axis('off') \nplt.show()\n</pre> # para nao imprimir os eixos  image = cv2.imread(\"NATUREZA_1.jpg\")  plt.imshow(image,interpolation=\"none\") plt.axis('off')  plt.show() <p>A imagem colorida possui tr\u00eas dimens\u00f5es: as linhas e as colunas da matriz, bem como os canais da imagem. Uma imagem colorida geralmente possui tr\u00eas canais: R (Red - vermelho) G (Green - verde) B (Blue - azul)</p> <p>Mas porque a imagem \u00e9 mostrada de modo estranho pelo pacote matplotlib? Porque a OpenCV representa os canais da imagem na ordem B - G - R, e n\u00e3o R - G - B como \u00e9 esperado pela maior parte das bibliotecas.</p> <p>Assim, para podermos visualizar corretamente uma imagem do OpenCV com matplotlib, precisamos inverter os canais, como no c\u00f3digo abaixo:</p> In\u00a0[72]: Copied! <pre>image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n\nplt.imshow(image_rgb)\n\nplt.axis('off') \nplt.show()\n</pre> image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)  plt.imshow(image_rgb)  plt.axis('off')  plt.show() In\u00a0[73]: Copied! <pre># Mostrando a representa\u00e7\u00e3o interna da imagem\nprint(\"Dimens\u00f5es da imagem: \", image_rgb.shape)\nprint(\"Quantidade de linhas: \", image_rgb.shape[0])\nprint(\"Quantidade de colunas: \", image_rgb.shape[1])\nprint(\"Camadas de cores: \", image_rgb.shape[2])\n</pre> # Mostrando a representa\u00e7\u00e3o interna da imagem print(\"Dimens\u00f5es da imagem: \", image_rgb.shape) print(\"Quantidade de linhas: \", image_rgb.shape[0]) print(\"Quantidade de colunas: \", image_rgb.shape[1]) print(\"Camadas de cores: \", image_rgb.shape[2]) <pre>Dimens\u00f5es da imagem:  (768, 1024, 3)\nQuantidade de linhas:  768\nQuantidade de colunas:  1024\nCamadas de cores:  3\n</pre> In\u00a0[74]: Copied! <pre># Mostrando a representa\u00e7\u00e3o interna da imagem\nprint(\"Dimens\u00f5es da imagem: \\n\", image_rgb)\n</pre> # Mostrando a representa\u00e7\u00e3o interna da imagem print(\"Dimens\u00f5es da imagem: \\n\", image_rgb)  <pre>Dimens\u00f5es da imagem: \n [[[ 10  92 194]\n  [ 12  94 196]\n  [ 12  95 197]\n  ...\n  [  6  98 201]\n  [  5  97 200]\n  [  2  95 198]]\n\n [[ 11  93 195]\n  [ 11  94 196]\n  [ 11  94 196]\n  ...\n  [  6  98 201]\n  [  6  98 201]\n  [  4  97 200]]\n\n [[ 11  94 196]\n  [ 11  94 196]\n  [  9  95 196]\n  ...\n  [  5  97 200]\n  [  7  99 202]\n  [  7 100 203]]\n\n ...\n\n [[  0  69 111]\n  [  1  70 112]\n  [  1  70 112]\n  ...\n  [ 11  31   6]\n  [ 17  41  17]\n  [  6  34   9]]\n\n [[  0  67 109]\n  [  0  69 111]\n  [  2  71 113]\n  ...\n  [ 65 105  68]\n  [ 86 135  90]\n  [ 82 136  86]]\n\n [[  0  66 108]\n  [  0  69 111]\n  [  2  71 113]\n  ...\n  [ 53 109  62]\n  [ 72 138  77]\n  [ 74 145  77]]]\n</pre> <p>A matriz acima \u00e9 a representa\u00e7\u00e3o da imagem de forma num\u00e9rica, \u00e9 o valor de cada pixel da imagem. Com esta imagem fica complicado. Vamos tentar analisar separando os canais de cores de um pixel espec\u00edfico.</p> In\u00a0[75]: Copied! <pre>(b, g, r) = image[450, 50]\nprint('O pixel (50, 50) tem as seguintes cores:')\nprint('Vermelho:',r, 'Verde:', g, 'Azul:', b)\n</pre> (b, g, r) = image[450, 50] print('O pixel (50, 50) tem as seguintes cores:') print('Vermelho:',r, 'Verde:', g, 'Azul:', b) <pre>O pixel (50, 50) tem as seguintes cores:\nVermelho: 2 Verde: 14 Azul: 36\n</pre> In\u00a0[76]: Copied! <pre># implemente aqui o seu c\u00f3digo.\n\n# vou carregar a imagem\nimage = cv2.imread(\"img3x3.png\")\n\n# vou converter a imagem para RGB\nimage_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n\n# vou mostrar a imagem\nplt.imshow(image_rgb)\nplt.axis('off')\nplt.show()\n\n# Mostrando a representa\u00e7\u00e3o interna e externa da imagem\nprint(\"Dimens\u00f5es da imagem: \", image_rgb.shape)\nprint(\"Quantidade de linhas: \", image_rgb.shape[0])\nprint(\"Quantidade de colunas: \", image_rgb.shape[1])\nprint(\"Camadas de cores: \", image_rgb.shape[2])\nprint(image_rgb)\n</pre> # implemente aqui o seu c\u00f3digo.  # vou carregar a imagem image = cv2.imread(\"img3x3.png\")  # vou converter a imagem para RGB image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)  # vou mostrar a imagem plt.imshow(image_rgb) plt.axis('off') plt.show()  # Mostrando a representa\u00e7\u00e3o interna e externa da imagem print(\"Dimens\u00f5es da imagem: \", image_rgb.shape) print(\"Quantidade de linhas: \", image_rgb.shape[0]) print(\"Quantidade de colunas: \", image_rgb.shape[1]) print(\"Camadas de cores: \", image_rgb.shape[2]) print(image_rgb)   <pre>Dimens\u00f5es da imagem:  (3, 3, 3)\nQuantidade de linhas:  3\nQuantidade de colunas:  3\nCamadas de cores:  3\n[[[255   5   5]\n  [255 255 255]\n  [  1   1 255]]\n\n [[255 255 255]\n  [  1 255   1]\n  [255 255 255]]\n\n [[  2 255 255]\n  [255 255  21]\n  [255   1 255]]]\n</pre> In\u00a0[77]: Copied! <pre>import cv2\nimport numpy as np\n\nfrom matplotlib import pyplot as plt\n\n\n# Carregando a imagem na vers\u00e3o tons de cinza (grayscale) de um arquivo\nimagem_cinza = cv2.imread(\"img3x3.png\", cv2.IMREAD_GRAYSCALE)\n\n# ou use o argumento 0, tem o mesmo efeito de importar na escala de cinza\n#imagem_cinza = cv2.imread(\"img3x3.png\", 0)\n\n\nplt.imshow(imagem_cinza)\n\nplt.axis('off') \nplt.show()\nimagem_cinza\n</pre> import cv2 import numpy as np  from matplotlib import pyplot as plt   # Carregando a imagem na vers\u00e3o tons de cinza (grayscale) de um arquivo imagem_cinza = cv2.imread(\"img3x3.png\", cv2.IMREAD_GRAYSCALE)  # ou use o argumento 0, tem o mesmo efeito de importar na escala de cinza #imagem_cinza = cv2.imread(\"img3x3.png\", 0)   plt.imshow(imagem_cinza)  plt.axis('off')  plt.show() imagem_cinza Out[77]: <pre>array([[ 79, 255,  29],\n       [255, 150, 255],\n       [179, 228, 105]], dtype=uint8)</pre> In\u00a0[78]: Copied! <pre># Coloque aqui sua solu\u00e7\u00e3o. \n\n# Importando a biblioteca OpenCV, Numpy e matplotlib\nimport cv2\nimport numpy as np\nfrom matplotlib import pyplot as plt\n\n\n# Carregando a imagem na vers\u00e3o tons de cinza (grayscale) de um arquivo\nimagem_cinza = cv2.imread(\"img3x3.png\", 0)\n\n# por padrao o matplotlib usa o cmap='viridis' para mostrar a imagem em tons de cinza.\n# para mostrar a imagem em tons de cinza com o matplotlib \u00e9 necess\u00e1rio usar o cmap='gray'\n# mas pode ser usado outro cmap para mostrar a imagem em tons de cinza com cores diferentes  \n\n# Mostrando a imagem em tons de cinza\nplt.subplot(1,2,1)\nplt.imshow(imagem_cinza)\nplt.axis('off')\nplt.title('cinza com cmap= viridis (padr\u00e3o)') \n\nplt.subplot(1,2,2)\nplt.imshow(imagem_cinza, cmap='gray')\nplt.axis('off')\nplt.title('Imagem em tons de cinza')\n\nplt.show()\n\n# o plt.subplot \u00e9 usado para mostrar mais de uma imagem na mesma janela do matplotlib \n# o primeiro argumento \u00e9 o n\u00famero de linhas\n# o segundo argumento \u00e9 o n\u00famero de colunas\n# o terceiro argumento \u00e9 o n\u00famero da imagem\n# o plt.title \u00e9 usado para mostrar o t\u00edtulo da imagem\n# o plt.show \u00e9 usado para mostrar a imagem\n</pre> # Coloque aqui sua solu\u00e7\u00e3o.   # Importando a biblioteca OpenCV, Numpy e matplotlib import cv2 import numpy as np from matplotlib import pyplot as plt   # Carregando a imagem na vers\u00e3o tons de cinza (grayscale) de um arquivo imagem_cinza = cv2.imread(\"img3x3.png\", 0)  # por padrao o matplotlib usa o cmap='viridis' para mostrar a imagem em tons de cinza. # para mostrar a imagem em tons de cinza com o matplotlib \u00e9 necess\u00e1rio usar o cmap='gray' # mas pode ser usado outro cmap para mostrar a imagem em tons de cinza com cores diferentes    # Mostrando a imagem em tons de cinza plt.subplot(1,2,1) plt.imshow(imagem_cinza) plt.axis('off') plt.title('cinza com cmap= viridis (padr\u00e3o)')   plt.subplot(1,2,2) plt.imshow(imagem_cinza, cmap='gray') plt.axis('off') plt.title('Imagem em tons de cinza')  plt.show()  # o plt.subplot \u00e9 usado para mostrar mais de uma imagem na mesma janela do matplotlib  # o primeiro argumento \u00e9 o n\u00famero de linhas # o segundo argumento \u00e9 o n\u00famero de colunas # o terceiro argumento \u00e9 o n\u00famero da imagem # o plt.title \u00e9 usado para mostrar o t\u00edtulo da imagem # o plt.show \u00e9 usado para mostrar a imagem In\u00a0[79]: Copied! <pre># Carregando a imagem na vers\u00e3o colorida de um arquivo\nimport cv2\nimport matplotlib.pyplot as plt\n\nimagem = cv2.imread(\"NATUREZA_1.jpg\")\nimage = cv2.cvtColor(imagem, cv2.COLOR_BGR2RGB)\n\nprint(\"Dimens\u00f5es da imagem: \", image.shape)\n\n\nimagem2 = cv2.resize(image, (600,400), cv2.INTER_LINEAR)\nprint(\"Novas dimens\u00f5es da imagem: \", imagem2.shape)\n\n\nplt.imshow(imagem2)\nplt.show()\n</pre> # Carregando a imagem na vers\u00e3o colorida de um arquivo import cv2 import matplotlib.pyplot as plt  imagem = cv2.imread(\"NATUREZA_1.jpg\") image = cv2.cvtColor(imagem, cv2.COLOR_BGR2RGB)  print(\"Dimens\u00f5es da imagem: \", image.shape)   imagem2 = cv2.resize(image, (600,400), cv2.INTER_LINEAR) print(\"Novas dimens\u00f5es da imagem: \", imagem2.shape)   plt.imshow(imagem2) plt.show() <pre>Dimens\u00f5es da imagem:  (768, 1024, 3)\nNovas dimens\u00f5es da imagem:  (400, 600, 3)\n</pre> In\u00a0[80]: Copied! <pre>#Implemente aqui sua solu\u00e7\u00e3o............\n\n# Carregando a imagem na vers\u00e3o colorida de um arquivo\nimport cv2\nimport matplotlib.pyplot as plt\nimagem = cv2.imread(\"img3x3.png\")\nimage = cv2.cvtColor(imagem, cv2.COLOR_BGR2RGB)\n\nprint(\"Dimens\u00f5es da imagem original: \", image.shape)\n\n# para testar diferentes m\u00e9todos de interpola\u00e7\u00e3o, vamos redimensionar a imagem para um tamanho maior\n# e vamos usar diferentes m\u00e9todos de interpola\u00e7\u00e3o para redimensionar a imagem \n# vamos usar os m\u00e9todos cv2.INTER_NEAREST, cv2.INTER_LINEAR, cv2.INTER_AREA, cv2.INTER_CUBIC e cv2.INTER_LANCZOS4 \n# que s\u00e3o os m\u00e9todos de interpola\u00e7\u00e3o dispon\u00edveis no OpenCV\ninterpolacao = [cv2.INTER_NEAREST, cv2.INTER_LINEAR, cv2.INTER_AREA, cv2.INTER_CUBIC, cv2.INTER_LANCZOS4]\n\n# essa fun\u00e7\u00e3o \u00e9 um list comprehension do python que cria uma lista com as imagens redimensionadas com os diferentes m\u00e9todos de interpola\u00e7\u00e3o \nresized_images = [cv2.resize(image, (image.shape[1] * 2, image.shape[0] * 5), interpolation=nome) for nome in interpolacao] \n\n# Vamos exibir as imagens redimensionadas com os diferentes m\u00e9todos de interpola\u00e7\u00e3o usando o matplotlib com o loop for.\ninterpolation_names = ['INTER_NEAREST', 'INTER_LINEAR', 'INTER_AREA', 'INTER_CUBIC', 'INTER_LANCZOS4']\nplt.figure(figsize=(15, 10))\nfor i, resized_image in enumerate(resized_images):\n    plt.subplot(2, 3, i + 1)\n    plt.imshow(resized_image)\n    plt.title(interpolation_names[i])\n    plt.axis('off')\n\nplt.show()\n</pre> #Implemente aqui sua solu\u00e7\u00e3o............  # Carregando a imagem na vers\u00e3o colorida de um arquivo import cv2 import matplotlib.pyplot as plt imagem = cv2.imread(\"img3x3.png\") image = cv2.cvtColor(imagem, cv2.COLOR_BGR2RGB)  print(\"Dimens\u00f5es da imagem original: \", image.shape)  # para testar diferentes m\u00e9todos de interpola\u00e7\u00e3o, vamos redimensionar a imagem para um tamanho maior # e vamos usar diferentes m\u00e9todos de interpola\u00e7\u00e3o para redimensionar a imagem  # vamos usar os m\u00e9todos cv2.INTER_NEAREST, cv2.INTER_LINEAR, cv2.INTER_AREA, cv2.INTER_CUBIC e cv2.INTER_LANCZOS4  # que s\u00e3o os m\u00e9todos de interpola\u00e7\u00e3o dispon\u00edveis no OpenCV interpolacao = [cv2.INTER_NEAREST, cv2.INTER_LINEAR, cv2.INTER_AREA, cv2.INTER_CUBIC, cv2.INTER_LANCZOS4]  # essa fun\u00e7\u00e3o \u00e9 um list comprehension do python que cria uma lista com as imagens redimensionadas com os diferentes m\u00e9todos de interpola\u00e7\u00e3o  resized_images = [cv2.resize(image, (image.shape[1] * 2, image.shape[0] * 5), interpolation=nome) for nome in interpolacao]   # Vamos exibir as imagens redimensionadas com os diferentes m\u00e9todos de interpola\u00e7\u00e3o usando o matplotlib com o loop for. interpolation_names = ['INTER_NEAREST', 'INTER_LINEAR', 'INTER_AREA', 'INTER_CUBIC', 'INTER_LANCZOS4'] plt.figure(figsize=(15, 10)) for i, resized_image in enumerate(resized_images):     plt.subplot(2, 3, i + 1)     plt.imshow(resized_image)     plt.title(interpolation_names[i])     plt.axis('off')  plt.show() <pre>Dimens\u00f5es da imagem original:  (3, 3, 3)\n</pre> In\u00a0[81]: Copied! <pre>import cv2\nimport numpy as np\n\n\n# Carregando a imagem\nimagem_cinza = cv2.imread(\"img3x3.png\", cv2.IMREAD_COLOR)\n\nplt.imshow(imagem_cinza)\n\nplt.axis('off') \nplt.show()\n</pre> import cv2 import numpy as np   # Carregando a imagem imagem_cinza = cv2.imread(\"img3x3.png\", cv2.IMREAD_COLOR)  plt.imshow(imagem_cinza)  plt.axis('off')  plt.show() In\u00a0[82]: Copied! <pre># implemente aqui sua solu\u00e7\u00e3o....\n\nimport cv2\nimport numpy as np\n\n\n# Carregando a imagem na vers\u00e3o colorida de um arquivo\nimagem = cv2.imread(\"img3x3.png\", cv2.IMREAD_COLOR)\nimagem_rgb = cv2.cvtColor(imagem, cv2.COLOR_BGR2RGB)\n\nimagem_rgb[0,0] = [255, 0, 255] # alterando a cor do pixel (0,0) para magenta \n\n\n\n# Mostrando a imagem em tons de cinza\nplt.subplot(1,2,1)\nplt.imshow(cv2.cvtColor(imagem, cv2.COLOR_BGR2RGB))\nplt.axis('off')\nplt.title('original') \n\nplt.subplot(1,2,2)\nplt.imshow(imagem_rgb)\nplt.axis('off')\nplt.title('alterada')\n\nplt.show()\n</pre> # implemente aqui sua solu\u00e7\u00e3o....  import cv2 import numpy as np   # Carregando a imagem na vers\u00e3o colorida de um arquivo imagem = cv2.imread(\"img3x3.png\", cv2.IMREAD_COLOR) imagem_rgb = cv2.cvtColor(imagem, cv2.COLOR_BGR2RGB)  imagem_rgb[0,0] = [255, 0, 255] # alterando a cor do pixel (0,0) para magenta     # Mostrando a imagem em tons de cinza plt.subplot(1,2,1) plt.imshow(cv2.cvtColor(imagem, cv2.COLOR_BGR2RGB)) plt.axis('off') plt.title('original')   plt.subplot(1,2,2) plt.imshow(imagem_rgb) plt.axis('off') plt.title('alterada')  plt.show() In\u00a0[83]: Copied! <pre># Come\u00e7amos importanto as bibliotecas \nimport cv2\nimport numpy as np\nfrom matplotlib import pyplot as plt\n\n# Criamos o array de zero 3x3\nletra = np.zeros((8,5), dtype=int)\n\n# implemente aqui o seu c\u00f3digo.........\n\nletra[0, 2] = 255\nletra[1, 1] = 255\nletra[1, 3] = 255\nletra[2, 0] = 255\nletra[2, 4] = 255\nletra[3, 0] = 255\nletra[3, 4] = 255\nletra[4, 0] = 255\nletra[4, 1] = 255\nletra[4, 2] = 255\nletra[4, 3] = 255\nletra[4, 4] = 255\nletra[5, 0] = 255\nletra[5, 4] = 255\nletra[6, 0] = 255\nletra[6, 4] = 255\nletra[7, 0] = 255\nletra[7, 4] = 255\n# Plota resultado\n\nplt.imshow(letra, cmap='gray')\nplt.show()\n</pre> # Come\u00e7amos importanto as bibliotecas  import cv2 import numpy as np from matplotlib import pyplot as plt  # Criamos o array de zero 3x3 letra = np.zeros((8,5), dtype=int)  # implemente aqui o seu c\u00f3digo.........  letra[0, 2] = 255 letra[1, 1] = 255 letra[1, 3] = 255 letra[2, 0] = 255 letra[2, 4] = 255 letra[3, 0] = 255 letra[3, 4] = 255 letra[4, 0] = 255 letra[4, 1] = 255 letra[4, 2] = 255 letra[4, 3] = 255 letra[4, 4] = 255 letra[5, 0] = 255 letra[5, 4] = 255 letra[6, 0] = 255 letra[6, 4] = 255 letra[7, 0] = 255 letra[7, 4] = 255 # Plota resultado  plt.imshow(letra, cmap='gray') plt.show() In\u00a0[6]: Copied! <pre>import cv2\nimagem = cv2.imread(\"NATUREZA_1.jpg\")\nimage = cv2.cvtColor(imagem, cv2.COLOR_BGR2RGB)\n\nfor y in range(0, image.shape[0]):\n  for x in range(0, image.shape[1]):\n    image[y, x] = (255,0,0) #sobreescrevendo todos os pixels da imagem para a cor vermelha\n    #pass\n    \nplt.imshow(image, interpolation=\"none\")\nplt.show()\n</pre> import cv2 imagem = cv2.imread(\"NATUREZA_1.jpg\") image = cv2.cvtColor(imagem, cv2.COLOR_BGR2RGB)  for y in range(0, image.shape[0]):   for x in range(0, image.shape[1]):     image[y, x] = (255,0,0) #sobreescrevendo todos os pixels da imagem para a cor vermelha     #pass      plt.imshow(image, interpolation=\"none\") plt.show() In\u00a0[5]: Copied! <pre>### seu c\u00f3digo aqui\nimport cv2\nimport matplotlib.pyplot as plt\n\nimagem = cv2.imread(\"NATUREZA_1.jpg\")\nimage = cv2.cvtColor(imagem, cv2.COLOR_BGR2RGB)\n\n# Achar o meio da imagem e o range\nmeio = image.shape[1] // 2 # Divis\u00e3o inteira para achar o meio da imagem (largura)\nfaixa = 50 // 2\nmin = meio - faixa\nmax = meio + faixa\n\nfor y in range(0, image.shape[0]):\n    for x in range(0, image.shape[1]):\n        if x &gt; min and x &lt; max:\n            image[y, x] = (255, 0, 0)  # Sobreescrevendo todos os pixels da imagem para a cor vermelha\n\nplt.imshow(image, interpolation=\"none\")\nplt.show()\n</pre> ### seu c\u00f3digo aqui import cv2 import matplotlib.pyplot as plt  imagem = cv2.imread(\"NATUREZA_1.jpg\") image = cv2.cvtColor(imagem, cv2.COLOR_BGR2RGB)  # Achar o meio da imagem e o range meio = image.shape[1] // 2 # Divis\u00e3o inteira para achar o meio da imagem (largura) faixa = 50 // 2 min = meio - faixa max = meio + faixa  for y in range(0, image.shape[0]):     for x in range(0, image.shape[1]):         if x &gt; min and x &lt; max:             image[y, x] = (255, 0, 0)  # Sobreescrevendo todos os pixels da imagem para a cor vermelha  plt.imshow(image, interpolation=\"none\") plt.show()"},{"location":"aulas/PDI/lab01/sol_IntroPID.html#representacao-e-visualizacao-de-imagem","title":"Representa\u00e7\u00e3o e visualiza\u00e7\u00e3o de imagem\u00b6","text":"<p>Uma imagem digital nada mais \u00e9 que uma uma matriz de linhas e colunas, onde cada posi\u00e7\u00e3o desta matriz contem o valor de um pixel.</p> <p>O valor de cada pixel representa a intensidade de cor naquele ponto especifico.</p>"},{"location":"aulas/PDI/lab01/sol_IntroPID.html#dica-para-quem-esta-utilizando-o-google-colab","title":"Dica para quem est\u00e1 utilizando o google colab\u00b6","text":"<p>Por ser uma inst\u00e2ncia que \u00e9 alocada temporariamente precisamos carregar as imagens neste se\u00e7\u00e3o.</p> <p>Est\u00e1 etapa pode ser feita de forma manual, fazendo o upload das imagens.</p> <p>Outra forma \u00e9 fazer o download da imagem para o notebook, lempre-se que \u00e9 um linux rodando! :) da uma olhada no exemplo abaixo.</p>"},{"location":"aulas/PDI/lab01/sol_IntroPID.html#desafio-1","title":"Desafio 1\u00b6","text":"<p>Abra a imagem \"img3x3.png\" e plote suas componentes externas (shape) e internas (matriz).</p> <p>Como voc\u00ea esta relacionado as possi\u00e7\u00f5es da matriz com os pixels da imagem??</p>"},{"location":"aulas/PDI/lab01/sol_IntroPID.html#imagem-em-tons-de-cinza","title":"Imagem em tons de cinza\u00b6","text":"<p>Em muitos casos trabalhamos com imagens na escala de cinza, logo, a imagem possui apenas 1 canal de cor.</p>"},{"location":"aulas/PDI/lab01/sol_IntroPID.html#desafio-2","title":"Desafio 2\u00b6","text":"<p>Eita! alguma est\u00e1 errada nesse plot, era esperado uma imagem na escala de cinza. Por que apareceu isso, como corrigir?</p>"},{"location":"aulas/PDI/lab01/sol_IntroPID.html#amostragem-da-imagem","title":"Amostragem da imagem\u00b6","text":"<p>As imagens capturadas por dispositivos digitais possuem as caracter\u00edsticas de resolu\u00e7\u00e3o espacial e resolu\u00e7\u00e3o de cores Enquanto a resolu\u00e7\u00e3o de cores afeta o n\u00famero de cores que podem serr epresentadas na imagem, sua resolu\u00e7\u00e3o espacial afeta o tamanho que a imagem ir\u00e1 ter. Embora n\u00e3o se possa comparar diretamente a resolu\u00e7\u00e3o de duas imagens com tamanhos diferentes, a imagem do mesmo objeto, se possui mais pixels, significar\u00e1 que tam\u00e9m possui maior resolu\u00e7\u00e3o</p>"},{"location":"aulas/PDI/lab01/sol_IntroPID.html#alterando-o-tamanho-de-uma-imagem","title":"Alterando o tamanho de uma imagem\u00b6","text":"<p>O redimensionamento da imagem pode ser feito na OpenCV atrav\u00e9s do comando <code>cv2.resize(imagem, tamanho, interpola\u00e7\u00e3o)</code></p> <p>O tamanho \u00e9 dado por uma tupla (W,H), onde W \u00e9 a largura (n\u00famero de colunas) e H \u00e9 a altura (n\u00famero de linhas)</p>"},{"location":"aulas/PDI/lab01/sol_IntroPID.html#desafio-3","title":"Desafio 3\u00b6","text":"<p>Comparar os diferentes m\u00e9todos de interpola\u00e7\u00e3o (vizinho mais pr\u00f3ximo, bilinear e bic\u00fabica) ao ampliarmos uma imagem em 10 vezes seu tamanho. Escolha uma imagem pequena.</p> <p>Dica de onde encontrar na documenta\u00e7\u00e3o as flags de interpola\u00e7\u00e3o: https://docs.opencv.org/3.4/da/d54/group__imgproc__transform.html#ga5bb5a1fea74ea38e1a5445ca803ff121</p> <p>Para saber mais sobre interpola\u00e7\u00e3o, sugiro assistir ao video: https://www.youtube.com/watch?v=8bTDssnJyZc&amp;ab_channel=S.M.RiazulIslam</p>"},{"location":"aulas/PDI/lab01/sol_IntroPID.html#alterando-os-valores-dos-pixels-de-uma-imagem","title":"Alterando os valores dos pixels de uma imagem\u00b6","text":""},{"location":"aulas/PDI/lab01/sol_IntroPID.html#range-de-valores","title":"Range de valores\u00b6","text":"<p>Antes de alterar os valores dos pixels temos que entender que a OpenCV trabalha com valores de 8 bits para cada componente de cor ou escala de cinza, quer dizer que os valores possiveis est\u00e3o no range entre 0 e 2\u2078-1, que \u00e9 a mesma que dizer entre 0 e 255.</p>"},{"location":"aulas/PDI/lab01/sol_IntroPID.html#desafio-4","title":"Desafio 4\u00b6","text":"<p>Implemente um codigo que faz a altera\u00e7\u00e3o do pixel(0,0) para a a cor Magenta - RGB (255,0,255);</p>"},{"location":"aulas/PDI/lab01/sol_IntroPID.html#desafio-5","title":"Desafio 5\u00b6","text":"<p>Crie uma array de zero com 8 linhas e 5 colunas. E escreva (desenhe) a primeira letra do seu nome ou grupo.</p> <p>Plot a imagem para visualizar o resultado.</p> <p>Dica: Use np.zeros() para criar o array, para facilitar fa\u00e7a em escala de cinza onde o valor de intensidade do pixel 0=branco e 255=preto.</p>"},{"location":"aulas/PDI/lab01/sol_IntroPID.html#varredura-de-uma-imagem","title":"Varredura de uma imagem\u00b6","text":"<p>Desenvolver uma rotina capaz de varrer sua imagem pixel a pixel \u00e9 muito mais interessante para aplica\u00e7\u00f5es mais pr\u00e1ticas, embora exista tecnicas mais otimizadas e r\u00e1pidas para essa aplica\u00e7\u00e3o, podemos utilizar uma estrutura de dois la\u00e7os For para passar sobre todas as linhas e todas as colunas da matriz (imagem).</p>"},{"location":"aulas/PDI/lab01/sol_IntroPID.html#desafio-6","title":"Desafio 6\u00b6","text":"<p>Utilizando a t\u00e9cnica dos 2 for, implemente uma fun\u00e7\u00e3o que desenha um linha branca na vertical no centro da imagem de largura 50 pixeis. Dica: use um if para checar a posi\u00e7\u00e3o (x,y) antes de pintar de branco o pixel.</p>"},{"location":"aulas/PDI/lab02/atividade2.html","title":"Lab02 - Seguimenta\u00e7\u00e3o por pixel","text":"<p>Objetivos da aula:</p> <ul> <li>Filtro negativo de imagem</li> <li>Recorte da imagem</li> <li>Seguimenta\u00e7\u00e3o por pixel</li> </ul> In\u00a0[4]: Copied! <pre>%matplotlib inline\n# Importando a biblioteca OpenCV\nimport cv2 \n\n#import a biblioteca Numpy\nimport numpy as np\n\nfrom matplotlib import pyplot as plt\n\n\nprint (\"OpenCV Vers\u00e3o : %s \" % cv2.__version__)\n</pre> %matplotlib inline # Importando a biblioteca OpenCV import cv2   #import a biblioteca Numpy import numpy as np  from matplotlib import pyplot as plt   print (\"OpenCV Vers\u00e3o : %s \" % cv2.__version__) <pre>OpenCV Vers\u00e3o : 4.6.0 \n</pre> In\u00a0[5]: Copied! <pre>!wget \"https://raw.githubusercontent.com/arnaldojr/cognitivecomputing/master/material/aulas/PDI/lab02/cogumelo.png\" /content\n!wget \"https://raw.githubusercontent.com/arnaldojr/cognitivecomputing/master/material/aulas/PDI/lab02/droneinvertido.jpg\" /content\n!wget \"https://raw.githubusercontent.com/arnaldojr/cognitivecomputing/master/material/aulas/PDI/lab02/drone.jpg\" /content\n!wget \"https://raw.githubusercontent.com/arnaldojr/cognitivecomputing/master/material/aulas/PDI/lab02/droneinvertido.jpg\" /content\n!wget \"https://raw.githubusercontent.com/arnaldojr/cognitivecomputing/master/material/aulas/PDI/lab02/goku.jpg\" /content\n!wget \"https://raw.githubusercontent.com/arnaldojr/cognitivecomputing/master/material/aulas/PDI/lab02/gokuinvertido.jpg\" /content\n!wget \"https://raw.githubusercontent.com/arnaldojr/cognitivecomputing/master/material/aulas/PDI/lab02/cogumelo.png\" /content\n</pre> !wget \"https://raw.githubusercontent.com/arnaldojr/cognitivecomputing/master/material/aulas/PDI/lab02/cogumelo.png\" /content !wget \"https://raw.githubusercontent.com/arnaldojr/cognitivecomputing/master/material/aulas/PDI/lab02/droneinvertido.jpg\" /content !wget \"https://raw.githubusercontent.com/arnaldojr/cognitivecomputing/master/material/aulas/PDI/lab02/drone.jpg\" /content !wget \"https://raw.githubusercontent.com/arnaldojr/cognitivecomputing/master/material/aulas/PDI/lab02/droneinvertido.jpg\" /content !wget \"https://raw.githubusercontent.com/arnaldojr/cognitivecomputing/master/material/aulas/PDI/lab02/goku.jpg\" /content !wget \"https://raw.githubusercontent.com/arnaldojr/cognitivecomputing/master/material/aulas/PDI/lab02/gokuinvertido.jpg\" /content !wget \"https://raw.githubusercontent.com/arnaldojr/cognitivecomputing/master/material/aulas/PDI/lab02/cogumelo.png\" /content <pre>--2023-02-10 19:36:13--  https://raw.githubusercontent.com/arnaldojr/cognitivecomputing/master/material/aulas/lab02/cogumelo.png\nResolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.111.133, 185.199.109.133, ...\nConnecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 48478 (47K) [image/png]\nSaving to: \u2018cogumelo.png.2\u2019\n\n\rcogumelo.png.2        0%[                    ]       0  --.-KB/s               \rcogumelo.png.2      100%[===================&gt;]  47.34K  --.-KB/s    in 0.01s   \n\n2023-02-10 19:36:13 (4.58 MB/s) - \u2018cogumelo.png.2\u2019 saved [48478/48478]\n\n/content: Scheme missing.\nFINISHED --2023-02-10 19:36:13--\nTotal wall clock time: 0.06s\nDownloaded: 1 files, 47K in 0.01s (4.58 MB/s)\n--2023-02-10 19:36:13--  https://raw.githubusercontent.com/arnaldojr/cognitivecomputing/master/material/aulas/lab02/droneinvertido.jpg\nResolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.109.133, 185.199.110.133, ...\nConnecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 52937 (52K) [image/jpeg]\nSaving to: \u2018droneinvertido.jpg.2\u2019\n\ndroneinvertido.jpg. 100%[===================&gt;]  51.70K  --.-KB/s    in 0.01s   \n\n2023-02-10 19:36:13 (4.78 MB/s) - \u2018droneinvertido.jpg.2\u2019 saved [52937/52937]\n\n/content: Scheme missing.\nFINISHED --2023-02-10 19:36:13--\nTotal wall clock time: 0.06s\nDownloaded: 1 files, 52K in 0.01s (4.78 MB/s)\n--2023-02-10 19:36:13--  https://raw.githubusercontent.com/arnaldojr/cognitivecomputing/master/material/aulas/lab02/drone.jpg\nResolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\nConnecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 37505 (37K) [image/jpeg]\nSaving to: \u2018drone.jpg.1\u2019\n\ndrone.jpg.1         100%[===================&gt;]  36.63K  --.-KB/s    in 0.003s  \n\n2023-02-10 19:36:13 (11.0 MB/s) - \u2018drone.jpg.1\u2019 saved [37505/37505]\n\n/content: Scheme missing.\nFINISHED --2023-02-10 19:36:13--\nTotal wall clock time: 0.06s\nDownloaded: 1 files, 37K in 0.003s (11.0 MB/s)\n--2023-02-10 19:36:13--  https://raw.githubusercontent.com/arnaldojr/cognitivecomputing/master/material/aulas/lab02/droneinvertido.jpg\nResolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\nConnecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 52937 (52K) [image/jpeg]\nSaving to: \u2018droneinvertido.jpg.3\u2019\n\ndroneinvertido.jpg. 100%[===================&gt;]  51.70K  --.-KB/s    in 0.01s   \n\n2023-02-10 19:36:13 (4.84 MB/s) - \u2018droneinvertido.jpg.3\u2019 saved [52937/52937]\n\n/content: Scheme missing.\nFINISHED --2023-02-10 19:36:13--\nTotal wall clock time: 0.06s\nDownloaded: 1 files, 52K in 0.01s (4.84 MB/s)\n--2023-02-10 19:36:13--  https://raw.githubusercontent.com/arnaldojr/cognitivecomputing/master/material/aulas/lab02/goku.jpg\nResolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\nConnecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 113004 (110K) [image/jpeg]\nSaving to: \u2018goku.jpg.1\u2019\n\ngoku.jpg.1          100%[===================&gt;] 110.36K  --.-KB/s    in 0.02s   \n\n2023-02-10 19:36:13 (5.17 MB/s) - \u2018goku.jpg.1\u2019 saved [113004/113004]\n\n/content: Scheme missing.\nFINISHED --2023-02-10 19:36:13--\nTotal wall clock time: 0.07s\nDownloaded: 1 files, 110K in 0.02s (5.17 MB/s)\n--2023-02-10 19:36:14--  https://raw.githubusercontent.com/arnaldojr/cognitivecomputing/master/material/aulas/lab02/gokuinvertido.jpg\nResolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\nConnecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 154233 (151K) [image/jpeg]\nSaving to: \u2018gokuinvertido.jpg.1\u2019\n\ngokuinvertido.jpg.1 100%[===================&gt;] 150.62K  --.-KB/s    in 0.02s   \n\n2023-02-10 19:36:14 (6.56 MB/s) - \u2018gokuinvertido.jpg.1\u2019 saved [154233/154233]\n\n/content: Scheme missing.\nFINISHED --2023-02-10 19:36:14--\nTotal wall clock time: 0.07s\nDownloaded: 1 files, 151K in 0.02s (6.56 MB/s)\n--2023-02-10 19:36:14--  https://raw.githubusercontent.com/arnaldojr/cognitivecomputing/master/material/aulas/lab02/cogumelo.png\nResolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\nConnecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 48478 (47K) [image/png]\nSaving to: \u2018cogumelo.png.3\u2019\n\ncogumelo.png.3      100%[===================&gt;]  47.34K  --.-KB/s    in 0.01s   \n\n2023-02-10 19:36:14 (4.43 MB/s) - \u2018cogumelo.png.3\u2019 saved [48478/48478]\n\n/content: Scheme missing.\nFINISHED --2023-02-10 19:36:14--\nTotal wall clock time: 0.06s\nDownloaded: 1 files, 47K in 0.01s (4.43 MB/s)\n</pre> In\u00a0[6]: Copied! <pre>import cv2\nimagem = cv2.imread(\"cogumelo.png\")\nimage = cv2.cvtColor(imagem, cv2.COLOR_BGR2GRAY)\n\nplt.imshow(image, interpolation=\"none\", cmap=\"gray\")\nplt.show()\n</pre> import cv2 imagem = cv2.imread(\"cogumelo.png\") image = cv2.cvtColor(imagem, cv2.COLOR_BGR2GRAY)  plt.imshow(image, interpolation=\"none\", cmap=\"gray\") plt.show() In\u00a0[7]: Copied! <pre>import cv2\nimagem = cv2.imread(\"cogumelo.png\")\nimage = cv2.cvtColor(imagem, cv2.COLOR_BGR2GRAY)\n\nfor y in range(0, image.shape[0]):\n  for x in range(0, image.shape[1]):\n    ##### aqui eu inverto o valor do pixel\n    if image[y, x] == 255:\n      image[y,x] = 0\n    else:\n      image[y,x] = 255\n\nplt.imshow(image, interpolation=\"none\", cmap=\"gray\")\nplt.show()\n</pre> import cv2 imagem = cv2.imread(\"cogumelo.png\") image = cv2.cvtColor(imagem, cv2.COLOR_BGR2GRAY)  for y in range(0, image.shape[0]):   for x in range(0, image.shape[1]):     ##### aqui eu inverto o valor do pixel     if image[y, x] == 255:       image[y,x] = 0     else:       image[y,x] = 255  plt.imshow(image, interpolation=\"none\", cmap=\"gray\") plt.show() In\u00a0[8]: Copied! <pre># implemente aqui sua solu\u00e7\u00e3o\n</pre> # implemente aqui sua solu\u00e7\u00e3o      In\u00a0[9]: Copied! <pre># Implemente aqui sua solu\u00e7\u00e3o\n</pre> # Implemente aqui sua solu\u00e7\u00e3o         In\u00a0[10]: Copied! <pre>import cv2\nimagem = cv2.imread(\"drone.jpg\")\nimage = cv2.cvtColor(imagem, cv2.COLOR_BGR2RGB)\n\nplt.imshow(image, interpolation=\"none\")\n\nplt.show()\n</pre> import cv2 imagem = cv2.imread(\"drone.jpg\") image = cv2.cvtColor(imagem, cv2.COLOR_BGR2RGB)  plt.imshow(image, interpolation=\"none\")  plt.show()  In\u00a0[11]: Copied! <pre>image2 = image.copy()\n\n#crop_img = img[y:y+h, x:x+w]\nimage2 = image[50:250,580:950]\n\nplt.imshow(image2, interpolation=\"none\", cmap=\"gray\")\nplt.show()\n</pre> image2 = image.copy()  #crop_img = img[y:y+h, x:x+w] image2 = image[50:250,580:950]  plt.imshow(image2, interpolation=\"none\", cmap=\"gray\") plt.show() In\u00a0[12]: Copied! <pre>import cv2\nimagem = cv2.imread(\"gokuinvertido.jpg\")\nimage = cv2.cvtColor(imagem, cv2.COLOR_BGR2RGB)\n\naltura = image.shape[0]\nlargura = image.shape[1]\n\nprint(\"altura: {} largura: {}\".format(altura, largura))\n\nplt.imshow(image, interpolation=\"none\")\n\nplt.show()\n\n# para salvar imagem\n#cv2.imwrite(\"gokunormal.jpg\", cv2.cvtColor(image2, cv2.COLOR_RGB2BGR))\n</pre> import cv2 imagem = cv2.imread(\"gokuinvertido.jpg\") image = cv2.cvtColor(imagem, cv2.COLOR_BGR2RGB)  altura = image.shape[0] largura = image.shape[1]  print(\"altura: {} largura: {}\".format(altura, largura))  plt.imshow(image, interpolation=\"none\")  plt.show()  # para salvar imagem #cv2.imwrite(\"gokunormal.jpg\", cv2.cvtColor(image2, cv2.COLOR_RGB2BGR)) <pre>altura: 720 largura: 1280\n</pre> In\u00a0[13]: Copied! <pre>#implemente sua solu\u00e7\u00e3o \n</pre> #implemente sua solu\u00e7\u00e3o       In\u00a0[14]: Copied! <pre># Entenda o codigo e fa\u00e7a as altera\u00e7\u00f5es que achar necess\u00e1rias\nimport cv2\nimagem = cv2.imread(\"drone.jpg\")\nimage = cv2.cvtColor(imagem, cv2.COLOR_BGR2RGB)\nprint(image.shape)\n\nfor y in range(0, image.shape[0]):\n  for x in range(0, image.shape[1]):\n    if image[y,x,1] &gt; 170 :\n      image[y,x]= (255,255,255)\n    \n\nplt.imshow(image, interpolation=\"none\")\nplt.show()\n</pre> # Entenda o codigo e fa\u00e7a as altera\u00e7\u00f5es que achar necess\u00e1rias import cv2 imagem = cv2.imread(\"drone.jpg\") image = cv2.cvtColor(imagem, cv2.COLOR_BGR2RGB) print(image.shape)  for y in range(0, image.shape[0]):   for x in range(0, image.shape[1]):     if image[y,x,1] &gt; 170 :       image[y,x]= (255,255,255)       plt.imshow(image, interpolation=\"none\") plt.show() <pre>(420, 1120, 3)\n</pre> In\u00a0[15]: Copied! <pre># Implemente seu c\u00f3digo aqui\n</pre> # Implemente seu c\u00f3digo aqui"},{"location":"aulas/PDI/lab02/atividade2.html#filtro-negativo-inverte-imagem","title":"Filtro negativo (Inverte imagem)\u00b6","text":"<p>Para aplicar um filtro negativo precisamos inverter os seus valores, ou seja, em uma imagem bin\u00e1ria realizamos a troca de 0 pra 1 e de 1 para 0 para cada pixel da imagem.</p>"},{"location":"aulas/PDI/lab02/atividade2.html#desafio-1","title":"Desafio 1\u00b6","text":"<p>Fa\u00e7a uma implementa\u00e7\u00e3o que inverte as cores de uma imagem em escala de cinza, com valores que v\u00e3o de 0 ate 255. dica: a forma explicita de fazer uma invers\u00e3\u00e3o \u00e9: a = 255 - a</p>"},{"location":"aulas/PDI/lab02/atividade2.html#desafio-2","title":"Desafio 2\u00b6","text":"<p>Fa\u00e7a o mesmo par uma imagem colorida, realize a invers\u00e3o de cores dos canais R, G e B.</p> <p>o resultado deve ser parecido com a imagem abaixo: </p>"},{"location":"aulas/PDI/lab02/atividade2.html#recorte-da-imagem-crop","title":"Recorte da imagem (crop)\u00b6","text":"<p>O recorte de uma parte da imagem, ou crop, consiste em extrair da imagem uma regi\u00e3o de interresse (ROI).</p>"},{"location":"aulas/PDI/lab02/atividade2.html#desafio3","title":"Desafio3\u00b6","text":"<p>Ajude o nosso sayajin!!</p> <p></p> <p>A imagem foi dividida em 4 quadrantes aleatorios e precisamos organizar essa bagun\u00e7a. Fa\u00e7a a reconstru\u00e7\u00e3o da imagem nas posi\u00e7\u00f5es corretas.</p> <p>Dica: Crie uma copia da imagem original (img2 = img.copy()), fa\u00e7a um crop da imagem 4 partes (crop1, crop2, crop3, crop4), junte as partes cortadas na ordem correta na img2. no final Salve a imagem (cv2.imwrite())</p>"},{"location":"aulas/PDI/lab02/atividade2.html#seguimentacao-de-imagens","title":"Seguimenta\u00e7\u00e3o de imagens\u00b6","text":"<p>Agora que sabemos como manipular pixel e como alterar seu valor e sua posi\u00e7\u00e3o. Podemos fazer atividades mais complexas como conseguir reaalizar a seguimenta\u00e7\u00e3o de algum objeto ou item da imagem (video), Como na imagem abaixo.</p>"},{"location":"aulas/PDI/lab02/atividade2.html#desafio-4","title":"Desafio 4\u00b6","text":"<p>De forma intuitiva realize algumas mudan\u00e7as no c\u00f3digo e veja o efeito que causa na imagem. Este exercio \u00e9 apenas um aperitivo de algumas tecnicas que vamos estudar na proxima aula.</p>"},{"location":"aulas/PDI/lab02/atividade2.html#desafio-5","title":"Desafio 5\u00b6","text":"<p>Vamos tentar fazer o contrario, vamos tentar filtar o fundo da imagem sem o drone</p>"},{"location":"aulas/PDI/lab02/sol_atividade2.html","title":"Sol atividade2","text":"<p>Objetivos da aula:</p> <ul> <li>Filtro negativo de imagem</li> <li>Recorte da imagem</li> <li>Seguimenta\u00e7\u00e3o por pixel</li> </ul> In\u00a0[1]: Copied! <pre>%matplotlib inline\n# Importando a biblioteca OpenCV\nimport cv2 \n\n#import a biblioteca Numpy\nimport numpy as np\n\nfrom matplotlib import pyplot as plt\n\n\nprint (\"OpenCV Vers\u00e3o : %s \" % cv2.__version__)\n</pre> %matplotlib inline # Importando a biblioteca OpenCV import cv2   #import a biblioteca Numpy import numpy as np  from matplotlib import pyplot as plt   print (\"OpenCV Vers\u00e3o : %s \" % cv2.__version__) <pre>OpenCV Vers\u00e3o : 4.9.0 \n</pre> In\u00a0[\u00a0]: Copied! <pre>!wget \"https://raw.githubusercontent.com/arnaldojr/cognitivecomputing/master/material/aulas/PDI/lab02/cogumelo.png\" /content\n!wget \"https://raw.githubusercontent.com/arnaldojr/cognitivecomputing/master/material/aulas/PDI/lab02/droneinvertido.jpg\" /content\n!wget \"https://raw.githubusercontent.com/arnaldojr/cognitivecomputing/master/material/aulas/PDI/lab02/drone.jpg\" /content\n!wget \"https://raw.githubusercontent.com/arnaldojr/cognitivecomputing/master/material/aulas/PDI/lab02/droneinvertido.jpg\" /content\n!wget \"https://raw.githubusercontent.com/arnaldojr/cognitivecomputing/master/material/aulas/PDI/lab02/goku.jpg\" /content\n!wget \"https://raw.githubusercontent.com/arnaldojr/cognitivecomputing/master/material/aulas/PDI/lab02/gokuinvertido.jpg\" /content\n!wget \"https://raw.githubusercontent.com/arnaldojr/cognitivecomputing/master/material/aulas/PDI/lab02/cogumelo.png\" /content\n</pre> !wget \"https://raw.githubusercontent.com/arnaldojr/cognitivecomputing/master/material/aulas/PDI/lab02/cogumelo.png\" /content !wget \"https://raw.githubusercontent.com/arnaldojr/cognitivecomputing/master/material/aulas/PDI/lab02/droneinvertido.jpg\" /content !wget \"https://raw.githubusercontent.com/arnaldojr/cognitivecomputing/master/material/aulas/PDI/lab02/drone.jpg\" /content !wget \"https://raw.githubusercontent.com/arnaldojr/cognitivecomputing/master/material/aulas/PDI/lab02/droneinvertido.jpg\" /content !wget \"https://raw.githubusercontent.com/arnaldojr/cognitivecomputing/master/material/aulas/PDI/lab02/goku.jpg\" /content !wget \"https://raw.githubusercontent.com/arnaldojr/cognitivecomputing/master/material/aulas/PDI/lab02/gokuinvertido.jpg\" /content !wget \"https://raw.githubusercontent.com/arnaldojr/cognitivecomputing/master/material/aulas/PDI/lab02/cogumelo.png\" /content In\u00a0[2]: Copied! <pre>import cv2\nimagem = cv2.imread(\"cogumelo.png\")\nimage = cv2.cvtColor(imagem, cv2.COLOR_BGR2GRAY)\n\nplt.imshow(image, interpolation=\"none\", cmap=\"gray\")\nplt.show()\n</pre> import cv2 imagem = cv2.imread(\"cogumelo.png\") image = cv2.cvtColor(imagem, cv2.COLOR_BGR2GRAY)  plt.imshow(image, interpolation=\"none\", cmap=\"gray\") plt.show() In\u00a0[4]: Copied! <pre>import cv2\nimagem = cv2.imread(\"cogumelo.png\")\nimage = cv2.cvtColor(imagem, cv2.COLOR_BGR2GRAY)\n\nfor y in range(0, image.shape[0]):\n  for x in range(0, image.shape[1]):\n    ##### aqui eu inverto o valor do pixel\n    if image[y, x] == 255:\n      image[y,x] = 0\n    else:\n      image[y,x] = 255\n\nplt.imshow(image, interpolation=\"none\", cmap=\"gray\")\nplt.show()\n</pre> import cv2 imagem = cv2.imread(\"cogumelo.png\") image = cv2.cvtColor(imagem, cv2.COLOR_BGR2GRAY)  for y in range(0, image.shape[0]):   for x in range(0, image.shape[1]):     ##### aqui eu inverto o valor do pixel     if image[y, x] == 255:       image[y,x] = 0     else:       image[y,x] = 255  plt.imshow(image, interpolation=\"none\", cmap=\"gray\") plt.show() In\u00a0[5]: Copied! <pre># implemente aqui sua solu\u00e7\u00e3o\n\n\nimport cv2\nimagem = cv2.imread(\"cogumelo.png\")\nimage = cv2.cvtColor(imagem, cv2.COLOR_BGR2GRAY)\n\nfor y in range(0, image.shape[0]):\n  for x in range(0, image.shape[1]):\n    ##### aqui eu inverto o valor do pixel\n    image[y, x] = 255 -image[y, x]\n\n\nplt.imshow(image, interpolation=\"none\", cmap=\"gray\")\nplt.show()\n</pre> # implemente aqui sua solu\u00e7\u00e3o   import cv2 imagem = cv2.imread(\"cogumelo.png\") image = cv2.cvtColor(imagem, cv2.COLOR_BGR2GRAY)  for y in range(0, image.shape[0]):   for x in range(0, image.shape[1]):     ##### aqui eu inverto o valor do pixel     image[y, x] = 255 -image[y, x]   plt.imshow(image, interpolation=\"none\", cmap=\"gray\") plt.show()   In\u00a0[9]: Copied! <pre># Implemente aqui sua solu\u00e7\u00e3o\n\nimport cv2\nimagem = cv2.imread(\"drone.jpg\")\nimage = cv2.cvtColor(imagem, cv2.COLOR_BGR2RGB)\n\nfor y in range(0, image.shape[0]):\n  for x in range(0, image.shape[1]):\n    ##### aqui eu inverto o valor do pixel\n    image[y, x] = 255 -image[y, x]\n\n\nplt.imshow(image, interpolation=\"none\", cmap=\"gray\")\nplt.show()\n</pre> # Implemente aqui sua solu\u00e7\u00e3o  import cv2 imagem = cv2.imread(\"drone.jpg\") image = cv2.cvtColor(imagem, cv2.COLOR_BGR2RGB)  for y in range(0, image.shape[0]):   for x in range(0, image.shape[1]):     ##### aqui eu inverto o valor do pixel     image[y, x] = 255 -image[y, x]   plt.imshow(image, interpolation=\"none\", cmap=\"gray\") plt.show() In\u00a0[10]: Copied! <pre>import cv2\nimagem = cv2.imread(\"drone.jpg\")\nimage = cv2.cvtColor(imagem, cv2.COLOR_BGR2RGB)\n\nplt.imshow(image, interpolation=\"none\")\n\nplt.show()\n</pre> import cv2 imagem = cv2.imread(\"drone.jpg\") image = cv2.cvtColor(imagem, cv2.COLOR_BGR2RGB)  plt.imshow(image, interpolation=\"none\")  plt.show()  In\u00a0[11]: Copied! <pre>image2 = image.copy()\n\n#crop_img = img[y:y+h, x:x+w]\nimage2 = image[50:250,580:950]\n\nplt.imshow(image2, interpolation=\"none\", cmap=\"gray\")\nplt.show()\n</pre> image2 = image.copy()  #crop_img = img[y:y+h, x:x+w] image2 = image[50:250,580:950]  plt.imshow(image2, interpolation=\"none\", cmap=\"gray\") plt.show() In\u00a0[12]: Copied! <pre>import cv2\nimagem = cv2.imread(\"gokuinvertido.jpg\")\nimage = cv2.cvtColor(imagem, cv2.COLOR_BGR2RGB)\n\naltura = image.shape[0]\nlargura = image.shape[1]\n\nprint(\"altura: {} largura: {}\".format(altura, largura))\n\nplt.imshow(image, interpolation=\"none\")\n\nplt.show()\n\n# para salvar imagem\n#cv2.imwrite(\"gokunormal.jpg\", cv2.cvtColor(image2, cv2.COLOR_RGB2BGR))\n</pre> import cv2 imagem = cv2.imread(\"gokuinvertido.jpg\") image = cv2.cvtColor(imagem, cv2.COLOR_BGR2RGB)  altura = image.shape[0] largura = image.shape[1]  print(\"altura: {} largura: {}\".format(altura, largura))  plt.imshow(image, interpolation=\"none\")  plt.show()  # para salvar imagem #cv2.imwrite(\"gokunormal.jpg\", cv2.cvtColor(image2, cv2.COLOR_RGB2BGR)) <pre>altura: 720 largura: 1280\n</pre> In\u00a0[12]: Copied! <pre>#implemente sua solu\u00e7\u00e3o \n\nimport cv2\nimagem = cv2.imread(\"gokuinvertido.jpg\")\nimage = cv2.cvtColor(imagem, cv2.COLOR_BGR2RGB)\n\naltura_metade = image.shape[0]//2\nlargura_metade = image.shape[1]//2\n\n#crop_img = img[y:y+h, x:x+w] em 4 partes\ncrop1 = image[0:altura_metade,0:largura_metade]\ncrop2 = image[0:altura_metade,largura_metade:largura_metade*2]\ncrop3 = image[altura_metade:altura_metade*2,0:largura_metade]\ncrop4 = image[altura_metade:altura_metade*2,largura_metade:largura_metade*2]\n\n# copia da imagem original\nimage2 = image.copy()\n\n# coloca os crops da imagem nas posi\u00e7\u00f5es corretas, por exemplo: crop1 na parte inferior direita\nimage2[0:altura_metade,0:largura_metade] = crop4\nimage2[0:altura_metade,largura_metade:largura_metade*2] = crop3\nimage2[altura_metade:altura_metade*2,0:largura_metade] = crop2\nimage2[altura_metade:altura_metade*2,largura_metade:largura_metade*2] = crop1\n\n\nplt.imshow(image2, interpolation=\"none\")\nplt.show()\n</pre> #implemente sua solu\u00e7\u00e3o   import cv2 imagem = cv2.imread(\"gokuinvertido.jpg\") image = cv2.cvtColor(imagem, cv2.COLOR_BGR2RGB)  altura_metade = image.shape[0]//2 largura_metade = image.shape[1]//2  #crop_img = img[y:y+h, x:x+w] em 4 partes crop1 = image[0:altura_metade,0:largura_metade] crop2 = image[0:altura_metade,largura_metade:largura_metade*2] crop3 = image[altura_metade:altura_metade*2,0:largura_metade] crop4 = image[altura_metade:altura_metade*2,largura_metade:largura_metade*2]  # copia da imagem original image2 = image.copy()  # coloca os crops da imagem nas posi\u00e7\u00f5es corretas, por exemplo: crop1 na parte inferior direita image2[0:altura_metade,0:largura_metade] = crop4 image2[0:altura_metade,largura_metade:largura_metade*2] = crop3 image2[altura_metade:altura_metade*2,0:largura_metade] = crop2 image2[altura_metade:altura_metade*2,largura_metade:largura_metade*2] = crop1   plt.imshow(image2, interpolation=\"none\") plt.show()     In\u00a0[14]: Copied! <pre># Entenda o codigo e fa\u00e7a as altera\u00e7\u00f5es que achar necess\u00e1rias\nimport cv2\nimagem = cv2.imread(\"drone.jpg\")\nimage = cv2.cvtColor(imagem, cv2.COLOR_BGR2RGB)\nprint(image.shape)\n\nfor y in range(0, image.shape[0]):\n  for x in range(0, image.shape[1]):\n    if image[y,x,1] &gt; 170 :\n      image[y,x]= (255,255,255)\n    \n\nplt.imshow(image, interpolation=\"none\")\nplt.show()\n</pre> # Entenda o codigo e fa\u00e7a as altera\u00e7\u00f5es que achar necess\u00e1rias import cv2 imagem = cv2.imread(\"drone.jpg\") image = cv2.cvtColor(imagem, cv2.COLOR_BGR2RGB) print(image.shape)  for y in range(0, image.shape[0]):   for x in range(0, image.shape[1]):     if image[y,x,1] &gt; 170 :       image[y,x]= (255,255,255)       plt.imshow(image, interpolation=\"none\") plt.show() <pre>(420, 1120, 3)\n</pre> In\u00a0[18]: Copied! <pre># Implemente seu c\u00f3digo aqui\n\nimport cv2\nimagem = cv2.imread(\"drone.jpg\")\nimage = cv2.cvtColor(imagem, cv2.COLOR_BGR2RGB)\nprint(image.shape)\n\nfor y in range(0, image.shape[0]):\n  for x in range(0, image.shape[1]):\n    if image[y,x,0] &lt; 70 :\n      image[y,x]= (255,255,255)\n    \n\nplt.imshow(image, interpolation=\"none\")\nplt.show()\n</pre> # Implemente seu c\u00f3digo aqui  import cv2 imagem = cv2.imread(\"drone.jpg\") image = cv2.cvtColor(imagem, cv2.COLOR_BGR2RGB) print(image.shape)  for y in range(0, image.shape[0]):   for x in range(0, image.shape[1]):     if image[y,x,0] &lt; 70 :       image[y,x]= (255,255,255)       plt.imshow(image, interpolation=\"none\") plt.show()   <pre>(420, 1120, 3)\n</pre>"},{"location":"aulas/PDI/lab02/sol_atividade2.html#filtro-negativo-inverte-imagem","title":"Filtro negativo (Inverte imagem)\u00b6","text":"<p>Para aplicar um filtro negativo precisamos inverter os seus valores, ou seja, em uma imagem bin\u00e1ria realizamos a troca de 0 pra 1 e de 1 para 0 para cada pixel da imagem.</p>"},{"location":"aulas/PDI/lab02/sol_atividade2.html#desafio-1","title":"Desafio 1\u00b6","text":"<p>Fa\u00e7a uma implementa\u00e7\u00e3o que inverte as cores de uma imagem em escala de cinza, com valores que v\u00e3o de 0 ate 255. dica: a forma explicita de fazer uma invers\u00e3\u00e3o \u00e9: a = 255 - a</p>"},{"location":"aulas/PDI/lab02/sol_atividade2.html#desafio-2","title":"Desafio 2\u00b6","text":"<p>Fa\u00e7a o mesmo par uma imagem colorida, realize a invers\u00e3o de cores dos canais R, G e B.</p> <p>o resultado deve ser parecido com a imagem abaixo: </p>"},{"location":"aulas/PDI/lab02/sol_atividade2.html#recorte-da-imagem-crop","title":"Recorte da imagem (crop)\u00b6","text":"<p>O recorte de uma parte da imagem, ou crop, consiste em extrair da imagem uma regi\u00e3o de interresse (ROI).</p>"},{"location":"aulas/PDI/lab02/sol_atividade2.html#desafio3","title":"Desafio3\u00b6","text":"<p>Ajude o nosso sayajin!!</p> <p></p> <p>A imagem foi dividida em 4 quadrantes aleatorios e precisamos organizar essa bagun\u00e7a. Fa\u00e7a a reconstru\u00e7\u00e3o da imagem nas posi\u00e7\u00f5es corretas.</p> <p>Dica: Crie uma copia da imagem original (img2 = img.copy()), fa\u00e7a um crop da imagem 4 partes (crop1, crop2, crop3, crop4), junte as partes cortadas na ordem correta na img2. no final Salve a imagem (cv2.imwrite())</p>"},{"location":"aulas/PDI/lab02/sol_atividade2.html#seguimentacao-de-imagens","title":"Seguimenta\u00e7\u00e3o de imagens\u00b6","text":"<p>Agora que sabemos como manipular pixel e como alterar seu valor e sua posi\u00e7\u00e3o. Podemos fazer atividades mais complexas como conseguir reaalizar a seguimenta\u00e7\u00e3o de algum objeto ou item da imagem (video), Como na imagem abaixo.</p>"},{"location":"aulas/PDI/lab02/sol_atividade2.html#desafio-4","title":"Desafio 4\u00b6","text":"<p>De forma intuitiva realize algumas mudan\u00e7as no c\u00f3digo e veja o efeito que causa na imagem. Este exercio \u00e9 apenas um aperitivo de algumas tecnicas que vamos estudar na proxima aula.</p>"},{"location":"aulas/PDI/lab02/sol_atividade2.html#desafio-5","title":"Desafio 5\u00b6","text":"<p>Vamos tentar fazer o contrario, vamos tentar filtar o fundo da imagem sem o drone</p>"},{"location":"aulas/PDI/lab03/atividade3.html","title":"Lab03 - Histograma e equaliza\u00e7\u00e3o","text":"<p>Objetivos da aula:</p> <ul> <li>Histograma e equaliza\u00e7\u00e3o de histograma</li> <li>Seguimenta\u00e7\u00e3o com auxilio do histograma</li> <li>Webcam opencv</li> </ul> In\u00a0[37]: Copied! <pre>## Vou fazer o download das imagens do laborat\u00f3rio diretamente do reposit\u00f3rio para ficar mais facil....\n\nimport requests\nimport os\n\n# Define o laborat\u00f3rio\nlaboratorio = 'lab03'  ### altere para o laborat\u00f3rio desejado\ndiretorio = 'lab_images'  ### altere para o diret\u00f3rio que deseja salvar as imagens\n\n# Download de um arquivo\ndef download_file(url, destination):\n    response = requests.get(url, stream=True)\n    if response.status_code == 200:\n        with open(destination, 'wb') as file:\n            for chunk in response.iter_content(chunk_size=8192):\n                file.write(chunk)\n        print(f\"Baixado: {destination}\")\n    else:\n        print(f\"Erro ao baixar {url}\")\n\n# Monta a URL completa\napi_url = \"https://api.github.com/repos/arnaldojr/cognitivecomputing/contents/material/aulas/PDI/\"\nurl_completa = api_url + laboratorio\nprint(f\"Fazendo o download de: {url_completa}\")\n\n# checa se a URL est\u00e1 acess\u00edvel\nresponse = requests.get(url_completa)\nif response.status_code != 200:\n    raise Exception(f\"Erro ao acessar o reposit\u00f3rio: {response.status_code}\")\nfiles = response.json()\n\n\n# Faz o download de cada arquivo\nos.makedirs(diretorio, exist_ok=True) # Cria a pasta downloads\nfor file in files:\n    file_name = file['name']\n    if file_name.endswith(('.png', '.jpg', '.jpeg', '.mp4')):  # Adicione mais extens\u00f5es se necess\u00e1rio\n        file_url = file['download_url']\n        destination = os.path.join(diretorio, file_name)\n        download_file(file_url, destination)\n\nprint(f\"Download conclu\u00eddo. Arquivos salvos na pasta {diretorio}.\")\n</pre> ## Vou fazer o download das imagens do laborat\u00f3rio diretamente do reposit\u00f3rio para ficar mais facil....  import requests import os  # Define o laborat\u00f3rio laboratorio = 'lab03'  ### altere para o laborat\u00f3rio desejado diretorio = 'lab_images'  ### altere para o diret\u00f3rio que deseja salvar as imagens  # Download de um arquivo def download_file(url, destination):     response = requests.get(url, stream=True)     if response.status_code == 200:         with open(destination, 'wb') as file:             for chunk in response.iter_content(chunk_size=8192):                 file.write(chunk)         print(f\"Baixado: {destination}\")     else:         print(f\"Erro ao baixar {url}\")  # Monta a URL completa api_url = \"https://api.github.com/repos/arnaldojr/cognitivecomputing/contents/material/aulas/PDI/\" url_completa = api_url + laboratorio print(f\"Fazendo o download de: {url_completa}\")  # checa se a URL est\u00e1 acess\u00edvel response = requests.get(url_completa) if response.status_code != 200:     raise Exception(f\"Erro ao acessar o reposit\u00f3rio: {response.status_code}\") files = response.json()   # Faz o download de cada arquivo os.makedirs(diretorio, exist_ok=True) # Cria a pasta downloads for file in files:     file_name = file['name']     if file_name.endswith(('.png', '.jpg', '.jpeg', '.mp4')):  # Adicione mais extens\u00f5es se necess\u00e1rio         file_url = file['download_url']         destination = os.path.join(diretorio, file_name)         download_file(file_url, destination)  print(f\"Download conclu\u00eddo. Arquivos salvos na pasta {diretorio}.\") <pre>Fazendo o download de: https://api.github.com/repos/arnaldojr/cognitivecomputing/contents/material/aulas/PDI/lab03\nBaixado: lab_images/bola.png\nBaixado: lab_images/bolinha.png\nBaixado: lab_images/fuca.png\nDownload conclu\u00eddo. Arquivos salvos na pasta lab_images.\n</pre> In\u00a0[1]: Copied! <pre>%matplotlib inline\nimport cv2\nfrom matplotlib import pyplot as plt\nimport numpy as np\n\nprint (\"OpenCV Version : %s \" % cv2.__version__)\n</pre> %matplotlib inline import cv2 from matplotlib import pyplot as plt import numpy as np  print (\"OpenCV Version : %s \" % cv2.__version__) <pre>OpenCV Version : 4.6.0 \n</pre> In\u00a0[2]: Copied! <pre>img = cv2.imread(\"fuca.png\", cv2.IMREAD_GRAYSCALE)\nplt.imshow(img, cmap=\"Greys_r\", vmin=0, vmax=255)\n</pre> img = cv2.imread(\"fuca.png\", cv2.IMREAD_GRAYSCALE) plt.imshow(img, cmap=\"Greys_r\", vmin=0, vmax=255)  Out[2]: <pre>&lt;matplotlib.image.AxesImage at 0x131d46d60&gt;</pre> In\u00a0[3]: Copied! <pre>img_gray = img\n\n# Calculando histograma com NumPy para imagem em escala de cinza\nhist_np, bins = np.histogram(img_gray.ravel(), bins=256, range=[0,256])\nplt.figure(figsize=(10,4))\nplt.title('Histograma com NumPy - Escala de Cinza')\nplt.xlabel('Intensidade')\nplt.ylabel('Frequ\u00eancia')\nplt.plot(hist_np)\nplt.xlim([0,256])\nplt.show()\n\n# Calculando histograma com OpenCV para imagem em escala de cinza\nhist_cv = cv2.calcHist([img_gray], [0], None, [256], [0,256])\nplt.figure(figsize=(10,4))\nplt.title('Histograma com OpenCV - Escala de Cinza')\nplt.xlabel('Intensidade')\nplt.ylabel('Frequ\u00eancia')\nplt.plot(hist_cv)\nplt.xlim([0,256])\nplt.show()\n\n# Exibindo o histograma com a fun\u00e7\u00e3o plt.hist\nplt.figure(figsize=(10,4))\nplt.hist(img_gray.ravel(),256,[0,256])\nplt.title('Histograma com Matplotlib - Escala de Cinza')\nplt.xlabel('Intensidade')\nplt.ylabel('Frequ\u00eancia')\nplt.xlim([0,256])\nplt.show()\n</pre>  img_gray = img  # Calculando histograma com NumPy para imagem em escala de cinza hist_np, bins = np.histogram(img_gray.ravel(), bins=256, range=[0,256]) plt.figure(figsize=(10,4)) plt.title('Histograma com NumPy - Escala de Cinza') plt.xlabel('Intensidade') plt.ylabel('Frequ\u00eancia') plt.plot(hist_np) plt.xlim([0,256]) plt.show()  # Calculando histograma com OpenCV para imagem em escala de cinza hist_cv = cv2.calcHist([img_gray], [0], None, [256], [0,256]) plt.figure(figsize=(10,4)) plt.title('Histograma com OpenCV - Escala de Cinza') plt.xlabel('Intensidade') plt.ylabel('Frequ\u00eancia') plt.plot(hist_cv) plt.xlim([0,256]) plt.show()  # Exibindo o histograma com a fun\u00e7\u00e3o plt.hist plt.figure(figsize=(10,4)) plt.hist(img_gray.ravel(),256,[0,256]) plt.title('Histograma com Matplotlib - Escala de Cinza') plt.xlabel('Intensidade') plt.ylabel('Frequ\u00eancia') plt.xlim([0,256]) plt.show()  In\u00a0[4]: Copied! <pre># Equaliza\u00e7\u00e3o do histograma utilizando OpenCV\nimg_eq = cv2.equalizeHist(img_gray)\n\n# Plotando as imagens original e equalizada\nplt.figure(figsize=(12,6))\nplt.subplot(1,2,1)\nplt.title('Imagem Original')\nplt.imshow(img_gray, cmap='gray')\nplt.axis('off')\n\nplt.subplot(1,2,2)\nplt.title('Imagem Equalizada')\nplt.imshow(img_eq, cmap='gray')\nplt.axis('off')\nplt.show()\n\n# Comparando os histogramas antes e depois da equaliza\u00e7\u00e3o\nhist_original = cv2.calcHist([img_gray], [0], None, [256], [0,256])\nhist_equalizado = cv2.calcHist([img_eq], [0], None, [256], [0,256])\n\nplt.figure(figsize=(10,4))\nplt.plot(hist_original, label='Original')\nplt.plot(hist_equalizado, label='Equalizado')\nplt.title('Compara\u00e7\u00e3o dos Histogramas')\nplt.xlabel('Intensidade')\nplt.ylabel('Frequ\u00eancia')\nplt.legend()\nplt.xlim([0,256])\nplt.show()\n</pre> # Equaliza\u00e7\u00e3o do histograma utilizando OpenCV img_eq = cv2.equalizeHist(img_gray)  # Plotando as imagens original e equalizada plt.figure(figsize=(12,6)) plt.subplot(1,2,1) plt.title('Imagem Original') plt.imshow(img_gray, cmap='gray') plt.axis('off')  plt.subplot(1,2,2) plt.title('Imagem Equalizada') plt.imshow(img_eq, cmap='gray') plt.axis('off') plt.show()  # Comparando os histogramas antes e depois da equaliza\u00e7\u00e3o hist_original = cv2.calcHist([img_gray], [0], None, [256], [0,256]) hist_equalizado = cv2.calcHist([img_eq], [0], None, [256], [0,256])  plt.figure(figsize=(10,4)) plt.plot(hist_original, label='Original') plt.plot(hist_equalizado, label='Equalizado') plt.title('Compara\u00e7\u00e3o dos Histogramas') plt.xlabel('Intensidade') plt.ylabel('Frequ\u00eancia') plt.legend() plt.xlim([0,256]) plt.show() <p>Podemos fazer o mesmo para uma imgem colorida</p> In\u00a0[5]: Copied! <pre>imagem = cv2.imread(\"bola.png\")\nimage = cv2.cvtColor(imagem, cv2.COLOR_BGR2RGB)\nplt.imshow(image, vmin=0, vmax=255); plt.show()\nplt.hist(image.ravel(),256,[0,256]); plt.show()\n</pre> imagem = cv2.imread(\"bola.png\") image = cv2.cvtColor(imagem, cv2.COLOR_BGR2RGB) plt.imshow(image, vmin=0, vmax=255); plt.show() plt.hist(image.ravel(),256,[0,256]); plt.show() In\u00a0[6]: Copied! <pre>#histograma Vermelho\nplt.imshow(image[:,:,0], cmap=\"gray\", vmin=0, vmax=255); plt.show()\nplt.hist(image[:,:,0].ravel(),256,[0,256]); plt.show()\n</pre> #histograma Vermelho plt.imshow(image[:,:,0], cmap=\"gray\", vmin=0, vmax=255); plt.show() plt.hist(image[:,:,0].ravel(),256,[0,256]); plt.show() In\u00a0[7]: Copied! <pre># Histogrma Verde\nplt.imshow(image[:,:,1], cmap=\"Greys_r\", vmin=0, vmax=255); plt.show()\nplt.hist(image[:,:,1].ravel(),256,[0,256]); plt.show()\n</pre> # Histogrma Verde plt.imshow(image[:,:,1], cmap=\"Greys_r\", vmin=0, vmax=255); plt.show() plt.hist(image[:,:,1].ravel(),256,[0,256]); plt.show() In\u00a0[8]: Copied! <pre># Histograma Azul\nplt.imshow(image[:,:,2], cmap=\"Greys_r\", vmin=0, vmax=255); plt.show()\nplt.hist(image[:,:,2].ravel(),256,[0,256]); plt.show()\n</pre> # Histograma Azul plt.imshow(image[:,:,2], cmap=\"Greys_r\", vmin=0, vmax=255); plt.show() plt.hist(image[:,:,2].ravel(),256,[0,256]); plt.show() In\u00a0[11]: Copied! <pre># Cria uma c\u00f3pia para a segmenta\u00e7\u00e3o\nimg_bola = image.copy()\n\n# Varredura pixel a pixel utilizando la\u00e7os for\nfor y in range(img_bola.shape[0]):\n    for x in range(img_bola.shape[1]):\n        # Condi\u00e7\u00f5es aplicadas para o pixel (no formato RGB)\n        # Aqui, se o canal verde &lt;= 230 ou o canal vermelho &gt;= 240, zera o pixel\n        if img_bola[y, x, 1] &lt;= 230 or img_bola[y, x, 0] &gt;= 240:\n            img_bola[y, x] = [0, 0, 0]\n\nplt.figure(figsize=(6,4))\nplt.title('Segmenta\u00e7\u00e3o (Loop For)')\n# Convertendo de BGR para RGB para exibi\u00e7\u00e3o correta\nplt.imshow(img_bola)\nplt.axis('off')\nplt.show()\n</pre> # Cria uma c\u00f3pia para a segmenta\u00e7\u00e3o img_bola = image.copy()  # Varredura pixel a pixel utilizando la\u00e7os for for y in range(img_bola.shape[0]):     for x in range(img_bola.shape[1]):         # Condi\u00e7\u00f5es aplicadas para o pixel (no formato RGB)         # Aqui, se o canal verde &lt;= 230 ou o canal vermelho &gt;= 240, zera o pixel         if img_bola[y, x, 1] &lt;= 230 or img_bola[y, x, 0] &gt;= 240:             img_bola[y, x] = [0, 0, 0]  plt.figure(figsize=(6,4)) plt.title('Segmenta\u00e7\u00e3o (Loop For)') # Convertendo de BGR para RGB para exibi\u00e7\u00e3o correta plt.imshow(img_bola) plt.axis('off') plt.show() In\u00a0[13]: Copied! <pre>img_bola_vet = image.copy()\n\n# Separando os canais (lembrando: B, G, R)\ncanal_vermelho = img_bola_vet[:, :, 0]\ncanal_verde = img_bola_vet[:, :, 1]\n\n# Criar m\u00e1scaras para as condi\u00e7\u00f5es:\n# - pixels com canal verde &lt;= 230\n# - pixels com canal vermelho &gt;= 240\nmask_verde = canal_verde &lt;= 230\nmask_vermelho  = canal_vermelho &gt;= 240\n\n# Combina as m\u00e1scaras com operador l\u00f3gico OR\nmask = mask_verde | mask_vermelho\n\n# Aplica a m\u00e1scara: onde a condi\u00e7\u00e3o \u00e9 True, zera o pixel\nimg_bola_vet[mask] = [0, 0, 0]\n\nplt.figure(figsize=(6,4))\nplt.title('Segmenta\u00e7\u00e3o (Vetorizada)')\nplt.imshow(img_bola_vet)\nplt.axis('off')\nplt.show()\n</pre> img_bola_vet = image.copy()  # Separando os canais (lembrando: B, G, R) canal_vermelho = img_bola_vet[:, :, 0] canal_verde = img_bola_vet[:, :, 1]  # Criar m\u00e1scaras para as condi\u00e7\u00f5es: # - pixels com canal verde &lt;= 230 # - pixels com canal vermelho &gt;= 240 mask_verde = canal_verde &lt;= 230 mask_vermelho  = canal_vermelho &gt;= 240  # Combina as m\u00e1scaras com operador l\u00f3gico OR mask = mask_verde | mask_vermelho  # Aplica a m\u00e1scara: onde a condi\u00e7\u00e3o \u00e9 True, zera o pixel img_bola_vet[mask] = [0, 0, 0]  plt.figure(figsize=(6,4)) plt.title('Segmenta\u00e7\u00e3o (Vetorizada)') plt.imshow(img_bola_vet) plt.axis('off') plt.show()  In\u00a0[\u00a0]: Copied! <pre># Implemente seu c\u00f3digo\n</pre> # Implemente seu c\u00f3digo       In\u00a0[14]: Copied! <pre>imagem = cv2.imread(\"bolinha.png\")\nimage = cv2.cvtColor(imagem, cv2.COLOR_BGR2RGB)\nplt.imshow(image, vmin=0, vmax=255); plt.show()\n</pre> imagem = cv2.imread(\"bolinha.png\") image = cv2.cvtColor(imagem, cv2.COLOR_BGR2RGB) plt.imshow(image, vmin=0, vmax=255); plt.show() In\u00a0[13]: Copied! <pre># Implemente seu c\u00f3digo\n</pre> # Implemente seu c\u00f3digo         In\u00a0[\u00a0]: Copied! <pre>import cv2\n\n# Iniciando a captura de v\u00eddeo\ncap = cv2.VideoCapture(0)\n\nwhile True:\n    # Tenta fazer a Captura do frame\n    ret, frame = cap.read()\n\n    # verifica se o frame foi capturado corretamente\n    if not ret:\n        print(\"Erro: N\u00e3o foi poss\u00edvel capturar o frame.\")\n        break\n    \n    # processa o frame capturado\n    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n    \n    # Exibe o frame processado\n    cv2.imshow('frame', gray)\n    \n    # Aguarda 1 ms e verifica se a tecla 'q' foi pressionada para sair\n    if cv2.waitKey(1) &amp; 0xFF == ord('q'):\n        break\n\n# Libera a captura e fecha todas as janelas\ncap.release()\ncv2.destroyAllWindows()\n</pre> import cv2  # Iniciando a captura de v\u00eddeo cap = cv2.VideoCapture(0)  while True:     # Tenta fazer a Captura do frame     ret, frame = cap.read()      # verifica se o frame foi capturado corretamente     if not ret:         print(\"Erro: N\u00e3o foi poss\u00edvel capturar o frame.\")         break          # processa o frame capturado     gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)          # Exibe o frame processado     cv2.imshow('frame', gray)          # Aguarda 1 ms e verifica se a tecla 'q' foi pressionada para sair     if cv2.waitKey(1) &amp; 0xFF == ord('q'):         break  # Libera a captura e fecha todas as janelas cap.release() cv2.destroyAllWindows() <pre>Erro: N\u00e3o foi poss\u00edvel capturar o frame.\n</pre> <pre>OpenCV: out device of bound (0-1): 2\nOpenCV: camera failed to properly initialize!\n</pre> In\u00a0[\u00a0]: Copied! <pre># implemente seu c\u00f3digo em um novo script python, n\u00e3o se esque\u00e7a de salvar o script no formato .py \n</pre> # implemente seu c\u00f3digo em um novo script python, n\u00e3o se esque\u00e7a de salvar o script no formato .py"},{"location":"aulas/PDI/lab03/atividade3.html#introducao-aos-histogramas","title":"Introdu\u00e7\u00e3o aos Histogramas\u00b6","text":"<p>Um histograma \u00e9 uma representa\u00e7\u00e3o gr\u00e1fica da distribui\u00e7\u00e3o dos n\u00edveis de intensidade em uma imagem. Em imagens em escala de cinza, ele mostra a frequ\u00eancia de ocorr\u00eancia de cada n\u00edvel de cinza (0 a 255). Em imagens coloridas, o histograma pode ser calculado separadamente para cada canal (R, G e B).</p> <p>Por que utilizar histogramas?</p> <ul> <li>An\u00e1lise de contraste e brilho.</li> <li>Detec\u00e7\u00e3o de problemas de exposi\u00e7\u00e3o.</li> <li>Base para t\u00e9cnicas de equaliza\u00e7\u00e3o e normaliza\u00e7\u00e3o.</li> </ul>"},{"location":"aulas/PDI/lab03/atividade3.html#desafio1","title":"Desafio1\u00b6","text":"<ul> <li><p>Quais s\u00e3o as diferen\u00e7as e similaridades entre as abordagens?</p> </li> <li><p>Import\u00e2ncia do par\u00e2metro range e do n\u00famero de bins.</p> </li> </ul>"},{"location":"aulas/PDI/lab03/atividade3.html#equalizacao-do-histograma","title":"Equaliza\u00e7\u00e3o do Histograma\u00b6","text":"<p>A equaliza\u00e7\u00e3o de histograma \u00e9 uma t\u00e9cnica utilizada para melhorar o contraste de uma imagem. Ela redistribui os n\u00edveis de intensidade de modo que o histograma da imagem equalizada se aproxime de uma distribui\u00e7\u00e3o uniforme. Isso \u00e9 especialmente \u00fatil em imagens com contraste baixo ou m\u00e1 distribui\u00e7\u00e3o dos tons de cinza.</p>"},{"location":"aulas/PDI/lab03/atividade3.html#objetivos-da-equalizacao","title":"Objetivos da Equaliza\u00e7\u00e3o:\u00b6","text":"<ul> <li>Melhorar o contraste: Ao expandir as \u00e1reas de baixa intensidade e comprimir as de alta intensidade, a imagem passa a apresentar mais detalhes.</li> <li>Real\u00e7ar detalhes ocultos: Em imagens com fundo e objeto de intensidades muito pr\u00f3ximas, a equaliza\u00e7\u00e3o pode ajudar a evidenciar detalhes que passariam despercebidos.</li> </ul>"},{"location":"aulas/PDI/lab03/atividade3.html#versao-2-abordagem-vetorizada-com-numpy","title":"Vers\u00e3o 2: Abordagem Vetorizada com NumPy\u00b6","text":"<p>Nesta vers\u00e3o, criamos m\u00e1scaras booleanas para cada condi\u00e7\u00e3o e combinamos as m\u00e1scaras para aplicar a segmenta\u00e7\u00e3o de forma vetorizada.</p> <p>Essa abordagem \u00e9 muito mais eficiente e concisa.</p>"},{"location":"aulas/PDI/lab03/atividade3.html#desafio-2","title":"Desafio 2\u00b6","text":"<p>Fa\u00e7a a seguimenta\u00e7\u00e3o da bolinha de cor laranja.</p> <p>Dica use 2 canais de cores para conseguir seguimentar.</p>"},{"location":"aulas/PDI/lab03/atividade3.html#desafio-3","title":"Desafio 3\u00b6","text":"<p>Fa\u00e7a a seguimenta\u00e7\u00e3o da bolinha para a imagem \"bolinha.png\".</p>"},{"location":"aulas/PDI/lab03/atividade3.html#webcam-e-opencv","title":"Webcam e OpenCV\u00b6","text":""},{"location":"aulas/PDI/lab03/atividade3.html#este-recurso-nao-vai-funcionar-no-google-colab","title":"Este recurso n\u00e3o vai funcionar no Google Colab\u00b6","text":"<p>Podemos usar a nossa webcam para registrar imagens e v\u00eddeos. Para isso, usamos a fun\u00e7\u00e3o <code>cv2.VideoCapture</code>.</p>"},{"location":"aulas/PDI/lab03/atividade3.html#em-sua-maquina-local","title":"Em sua m\u00e1quina local\u00b6","text":"<ol> <li><p>Crie um novo arquivo Python ou use este notebook para executar o c\u00f3digo abaixo.</p> </li> <li><p>Escolha a fonte do video se voc\u00ea quiser usar um v\u00eddeo MP4 em vez da webcam, basta passar o caminho do arquivo para cv2.VideoCapture:</p> <ul> <li>cv2.VideoCapture(0) # Inicializa a captura de v\u00eddeo da webcam (0 \u00e9 o \u00edndice da c\u00e2mera padr\u00e3o)</li> <li>cv2.VideoCapture(\"video.mp4\") # Carrega o arquivo de video</li> </ul> </li> </ol>"},{"location":"aulas/PDI/lab03/atividade3.html#desafio-4","title":"Desafio 4\u00b6","text":"<p>Crie um script Python que execute o processameento de um video (webcam ou arquivo mp4) em sua maquina local. Crie uma fun\u00e7\u00e3o que processa a imagem e realizada uma opera\u00e7\u00e3o de processamento de imagem que vimos at\u00e9 o momento em nosso curso.</p>"},{"location":"aulas/PDI/lab03/sol_atividade3.html","title":"Sol atividade3","text":"<p>Objetivos da aula:</p> <ul> <li>Histograma e equaliza\u00e7\u00e3o de histograma</li> <li>Seguimenta\u00e7\u00e3o com auxilio do histograma</li> <li>Webcam opencv</li> </ul> In\u00a0[1]: Copied! <pre>%matplotlib inline\nimport cv2\nfrom matplotlib import pyplot as plt\nimport numpy as np\n\nprint (\"OpenCV Version : %s \" % cv2.__version__)\n</pre> %matplotlib inline import cv2 from matplotlib import pyplot as plt import numpy as np  print (\"OpenCV Version : %s \" % cv2.__version__) <pre>OpenCV Version : 4.9.0 \n</pre> In\u00a0[\u00a0]: Copied! <pre>!wget \"https://raw.githubusercontent.com/arnaldojr/cognitivecomputing/master/material/aulas/PDI/lab03/bola.png\" /content\n!wget \"https://raw.githubusercontent.com/arnaldojr/cognitivecomputing/master/material/aulas/PDI/lab03/bolinha.png\" /content\n!wget \"https://raw.githubusercontent.com/arnaldojr/cognitivecomputing/master/material/aulas/PDI/lab03/fuca.png\" /content\n</pre> !wget \"https://raw.githubusercontent.com/arnaldojr/cognitivecomputing/master/material/aulas/PDI/lab03/bola.png\" /content !wget \"https://raw.githubusercontent.com/arnaldojr/cognitivecomputing/master/material/aulas/PDI/lab03/bolinha.png\" /content !wget \"https://raw.githubusercontent.com/arnaldojr/cognitivecomputing/master/material/aulas/PDI/lab03/fuca.png\" /content   In\u00a0[2]: Copied! <pre>img = cv2.imread(\"fuca.png\", cv2.IMREAD_GRAYSCALE)\nplt.imshow(img, cmap=\"Greys_r\", vmin=0, vmax=255)\n</pre> img = cv2.imread(\"fuca.png\", cv2.IMREAD_GRAYSCALE) plt.imshow(img, cmap=\"Greys_r\", vmin=0, vmax=255)  Out[2]: <pre>&lt;matplotlib.image.AxesImage at 0x15eff6460&gt;</pre> In\u00a0[3]: Copied! <pre>plt.hist(img.ravel(),256,[0,256]); plt.show()\n</pre> plt.hist(img.ravel(),256,[0,256]); plt.show() In\u00a0[4]: Copied! <pre># normaliza\u00e7\u00e3o de histograma\n\nimg_eq = cv2.equalizeHist(img)\nplt.imshow(3*img_eq, cmap=\"Greys_r\", vmin=0, vmax=255)\n</pre> # normaliza\u00e7\u00e3o de histograma  img_eq = cv2.equalizeHist(img) plt.imshow(3*img_eq, cmap=\"Greys_r\", vmin=0, vmax=255) Out[4]: <pre>&lt;matplotlib.image.AxesImage at 0x15f9cf370&gt;</pre> In\u00a0[5]: Copied! <pre>plt.hist(3*img_eq.ravel(),256,[0,256]); plt.show()\n</pre> plt.hist(3*img_eq.ravel(),256,[0,256]); plt.show() <p>Podemos fazer o mesmo para uma imgem colorida</p> In\u00a0[6]: Copied! <pre>imagem = cv2.imread(\"bola.png\")\nimage = cv2.cvtColor(imagem, cv2.COLOR_BGR2RGB)\nplt.imshow(image, vmin=0, vmax=255); plt.show()\nplt.hist(image.ravel(),256,[0,256]); plt.show()\n</pre> imagem = cv2.imread(\"bola.png\") image = cv2.cvtColor(imagem, cv2.COLOR_BGR2RGB) plt.imshow(image, vmin=0, vmax=255); plt.show() plt.hist(image.ravel(),256,[0,256]); plt.show() In\u00a0[7]: Copied! <pre>#histograma Vermelho\nplt.imshow(image[:,:,0], cmap=\"gray\", vmin=0, vmax=255); plt.show()\nplt.hist(image[:,:,0].ravel(),256,[0,256]); plt.show()\n</pre> #histograma Vermelho plt.imshow(image[:,:,0], cmap=\"gray\", vmin=0, vmax=255); plt.show() plt.hist(image[:,:,0].ravel(),256,[0,256]); plt.show() In\u00a0[8]: Copied! <pre># Histogrma Verde\nplt.imshow(image[:,:,1], cmap=\"Greys_r\", vmin=0, vmax=255); plt.show()\nplt.hist(image[:,:,1].ravel(),256,[0,256]); plt.show()\n</pre> # Histogrma Verde plt.imshow(image[:,:,1], cmap=\"Greys_r\", vmin=0, vmax=255); plt.show() plt.hist(image[:,:,1].ravel(),256,[0,256]); plt.show() In\u00a0[9]: Copied! <pre># Histograma Azul\nplt.imshow(image[:,:,2], cmap=\"Greys_r\", vmin=0, vmax=255); plt.show()\nplt.hist(image[:,:,2].ravel(),256,[0,256]); plt.show()\n</pre> # Histograma Azul plt.imshow(image[:,:,2], cmap=\"Greys_r\", vmin=0, vmax=255); plt.show() plt.hist(image[:,:,2].ravel(),256,[0,256]); plt.show() In\u00a0[10]: Copied! <pre>image2 = image.copy()\ngray_r = image2[:,:,0]\ngray_g = image2[:,:,1]\ngray_b = image2[:,:,2]\n\nimg_bola = image2.copy()\n\nfor y in range(0, image2.shape[0]):\n    for x in range(0, image2.shape[1]):\n        \n        if gray_g[y][x] &lt;= 230:\n            img_bola[y][x]= 0\n        if gray_b[y][x] &gt;= 240:\n            img_bola[y][x]= 0    \n\n    \n\nplt.imshow(img_bola, interpolation=\"none\")\nplt.show()\n</pre> image2 = image.copy() gray_r = image2[:,:,0] gray_g = image2[:,:,1] gray_b = image2[:,:,2]  img_bola = image2.copy()  for y in range(0, image2.shape[0]):     for x in range(0, image2.shape[1]):                  if gray_g[y][x] &lt;= 230:             img_bola[y][x]= 0         if gray_b[y][x] &gt;= 240:             img_bola[y][x]= 0            plt.imshow(img_bola, interpolation=\"none\") plt.show() In\u00a0[13]: Copied! <pre># Implemente seu c\u00f3digo\n\n# para encontrar a bolinha laranja na imagem, \u00e9 necess\u00e1rio encontrar a cor laranja, que \u00e9 uma mistura de vermelho e verde\n# para isso, \u00e9 necess\u00e1rio encontrar os valores de vermelho e verde que comp\u00f5em a cor laranja\n\n# n\u00e3o existe um valor exato para a cor laranja, ent\u00e3o \u00e9 necess\u00e1rio testar valores para encontrar a cor laranja\n# no caso, o vermelho \u00e9 menor que 240 e o verde \u00e9 maior que 240 para a cor laranja da bolinha na imagem\n\n\nimg_bola_laranja = image.copy()\n\ngray_r = image[:,:,0]\ngray_g = image[:,:,1]\n\n\nfor y in range(0, image.shape[0]):\n    for x in range(0, image.shape[1]):\n        \n        if gray_r[y][x] &lt;= 240:\n            img_bola_laranja[y][x]= 0\n        if gray_g[y][x] &gt;= 240:\n            img_bola_laranja[y][x]= 0    \n\n\nplt.imshow(img_bola_laranja)\nplt.show()\n</pre> # Implemente seu c\u00f3digo  # para encontrar a bolinha laranja na imagem, \u00e9 necess\u00e1rio encontrar a cor laranja, que \u00e9 uma mistura de vermelho e verde # para isso, \u00e9 necess\u00e1rio encontrar os valores de vermelho e verde que comp\u00f5em a cor laranja  # n\u00e3o existe um valor exato para a cor laranja, ent\u00e3o \u00e9 necess\u00e1rio testar valores para encontrar a cor laranja # no caso, o vermelho \u00e9 menor que 240 e o verde \u00e9 maior que 240 para a cor laranja da bolinha na imagem   img_bola_laranja = image.copy()  gray_r = image[:,:,0] gray_g = image[:,:,1]   for y in range(0, image.shape[0]):     for x in range(0, image.shape[1]):                  if gray_r[y][x] &lt;= 240:             img_bola_laranja[y][x]= 0         if gray_g[y][x] &gt;= 240:             img_bola_laranja[y][x]= 0       plt.imshow(img_bola_laranja) plt.show() In\u00a0[14]: Copied! <pre>imagem = cv2.imread(\"bolinha.png\")\nimage = cv2.cvtColor(imagem, cv2.COLOR_BGR2RGB)\nplt.imshow(image, vmin=0, vmax=255); plt.show()\n</pre> imagem = cv2.imread(\"bolinha.png\") image = cv2.cvtColor(imagem, cv2.COLOR_BGR2RGB) plt.imshow(image, vmin=0, vmax=255); plt.show() In\u00a0[30]: Copied! <pre># Implemente seu c\u00f3digo\n\n# para encontrar a bolinha magenta na imagem, \u00e9 necess\u00e1rio encontrar a cor magenta, \n# que \u00e9 uma mistura de vermelho e azul\n\nimg_entrada = cv2.imread(\"bolinha.png\")\nimg_entrada = cv2.cvtColor(img_entrada, cv2.COLOR_BGR2RGB)\n\n# Criando uma figura com subplots para exibir a imagem e o histograma\nfig, axs = plt.subplots(2, 3, figsize=(10, 8))\nnomes_canais = [\"Vermelho\", \"Verde\", \"Azul\"]\n\n# Iterando sobre os canais de cores\nfor i, (canal, nome) in enumerate(zip([0, 1, 2], nomes_canais)):\n    # Exibindo o canal de cor\n    axs[0, i].imshow(img_entrada[:, :, canal], cmap=\"Greys_r\", vmin=0, vmax=255)\n    axs[0, i].set_title(f\"Canal {nome}\")\n    # Exibindo o histograma do canal de cor\n    axs[1, i].hist(img_entrada[:, :, canal].ravel(), 256, [0, 256])\n    axs[1, i].set_title(f\"Histograma {nome}\")\n\n#  Exibindo a figura\nplt.tight_layout()\nplt.show()\n\n# agora \u00e9 analisar os valores de vermelho e azul para encontrar a cor magenta da bolinha na imagem \n\nbolinha_magenta = image.copy()\ngray_r = img_entrada[:,:,0]\ngray_b = img_entrada[:,:,2]\n\nfor y in range(0, img_entrada.shape[0]):\n    for x in range(0, img_entrada.shape[1]):\n        \n        if gray_r[y][x] &lt;= 251:\n            bolinha_magenta[y][x]= 0\n        if gray_b[y][x] &gt;= 252:\n            bolinha_magenta[y][x]= 0    \n\nplt.subplot(1,2,1), plt.imshow(img_entrada)\nplt.subplot(1,2,2), plt.imshow(bolinha_magenta)\nplt.show()\n\n# Dificilmente encontraremos um valor exato para a cor magenta, mas com um pouco de paci\u00eancia,\n# \u00e9 poss\u00edvel encontrar a cor magenta da bolinha na imagem\n</pre> # Implemente seu c\u00f3digo  # para encontrar a bolinha magenta na imagem, \u00e9 necess\u00e1rio encontrar a cor magenta,  # que \u00e9 uma mistura de vermelho e azul  img_entrada = cv2.imread(\"bolinha.png\") img_entrada = cv2.cvtColor(img_entrada, cv2.COLOR_BGR2RGB)  # Criando uma figura com subplots para exibir a imagem e o histograma fig, axs = plt.subplots(2, 3, figsize=(10, 8)) nomes_canais = [\"Vermelho\", \"Verde\", \"Azul\"]  # Iterando sobre os canais de cores for i, (canal, nome) in enumerate(zip([0, 1, 2], nomes_canais)):     # Exibindo o canal de cor     axs[0, i].imshow(img_entrada[:, :, canal], cmap=\"Greys_r\", vmin=0, vmax=255)     axs[0, i].set_title(f\"Canal {nome}\")     # Exibindo o histograma do canal de cor     axs[1, i].hist(img_entrada[:, :, canal].ravel(), 256, [0, 256])     axs[1, i].set_title(f\"Histograma {nome}\")  #  Exibindo a figura plt.tight_layout() plt.show()  # agora \u00e9 analisar os valores de vermelho e azul para encontrar a cor magenta da bolinha na imagem   bolinha_magenta = image.copy() gray_r = img_entrada[:,:,0] gray_b = img_entrada[:,:,2]  for y in range(0, img_entrada.shape[0]):     for x in range(0, img_entrada.shape[1]):                  if gray_r[y][x] &lt;= 251:             bolinha_magenta[y][x]= 0         if gray_b[y][x] &gt;= 252:             bolinha_magenta[y][x]= 0      plt.subplot(1,2,1), plt.imshow(img_entrada) plt.subplot(1,2,2), plt.imshow(bolinha_magenta) plt.show()  # Dificilmente encontraremos um valor exato para a cor magenta, mas com um pouco de paci\u00eancia, # \u00e9 poss\u00edvel encontrar a cor magenta da bolinha na imagem  In\u00a0[\u00a0]: Copied! <pre>%matplotlib inline\nimport cv2\nfrom matplotlib import pyplot as plt\nimport numpy as np\nimport time as t\nprint (\"OpenCV Version : %s \" % cv2.__version__)\n</pre> %matplotlib inline import cv2 from matplotlib import pyplot as plt import numpy as np import time as t print (\"OpenCV Version : %s \" % cv2.__version__) <pre>OpenCV Version : 4.5.5 \n</pre> In\u00a0[\u00a0]: Copied! <pre>webcam = cv2.VideoCapture(0) # pode acontecer do ID da camera n\u00e3o ser 0, ai precisa testar com outros numeros \n</pre>  webcam = cv2.VideoCapture(0) # pode acontecer do ID da camera n\u00e3o ser 0, ai precisa testar com outros numeros  In\u00a0[\u00a0]: Copied! <pre>t.sleep(3) # Espera a webcam ficar pronta\n</pre> t.sleep(3) # Espera a webcam ficar pronta In\u00a0[\u00a0]: Copied! <pre>val, image = webcam.read()\n</pre> val, image = webcam.read() In\u00a0[\u00a0]: Copied! <pre>val  # Checa se um frame chegou\n</pre> val  # Checa se um frame chegou Out[\u00a0]: <pre>True</pre> In\u00a0[\u00a0]: Copied! <pre>webcam.release() # fecha a webcam\n</pre> webcam.release() # fecha a webcam In\u00a0[\u00a0]: Copied! <pre>plt.imshow(image)\n</pre> plt.imshow(image) Out[\u00a0]: <pre>&lt;matplotlib.image.AxesImage at 0x252ed548df0&gt;</pre> In\u00a0[\u00a0]: Copied! <pre>%matplotlib inline\nimport cv2\nfrom matplotlib import pyplot as plt\nimport time as t\n\n## aqui n\u00e3o tem segredo, \u00e9 copiar, colar e rodar o c\u00f3digo dado no enunciado.\n\n# Iniciando a captura de v\u00eddeo\nwebcam = cv2.VideoCapture(0)\n\n# Aguardando 3 segundos para a c\u00e2mera se ajustar\nt.sleep(3)\n\n# Capturando uma imagem\nval, image = webcam.read()\n\n# Liberando a c\u00e2mera\nwebcam.release()\n\n# Convertendo a imagem de BGR para RGB\nimage_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n\n# Exibindo a imagem\nplt.imshow(image_rgb)\nplt.axis('off')  # Ocultando os eixos\nplt.show()\n</pre> %matplotlib inline import cv2 from matplotlib import pyplot as plt import time as t  ## aqui n\u00e3o tem segredo, \u00e9 copiar, colar e rodar o c\u00f3digo dado no enunciado.  # Iniciando a captura de v\u00eddeo webcam = cv2.VideoCapture(0)  # Aguardando 3 segundos para a c\u00e2mera se ajustar t.sleep(3)  # Capturando uma imagem val, image = webcam.read()  # Liberando a c\u00e2mera webcam.release()  # Convertendo a imagem de BGR para RGB image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)  # Exibindo a imagem plt.imshow(image_rgb) plt.axis('off')  # Ocultando os eixos plt.show()  In\u00a0[\u00a0]: Copied! <pre>## para captura um video, \u00e9 necess\u00e1rio usar um loop para capturar os frames da c\u00e2mera e exibir os frames capturados \n## em tempo real na tela do computador \n\n## fa\u00e7a o teste em seu computador, copie e cole o c\u00f3digo abaixo e veja o que acontece \n\nimport cv2\n\n# Iniciando a captura de v\u00eddeo\nwebcam = cv2.VideoCapture(0)\n\n# Definindo o tamanho da janela\nwebcam.set(cv2.CAP_PROP_FRAME_WIDTH, 640)\nwebcam.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)\n\n# Loop para capturar e exibir os frames\nwhile True:\n    # Capturando um frame\n    ret, frame = webcam.read()\n\n    # Verificando se o frame foi capturado corretamente\n    if not ret:\n        print(\"Falha ao capturar o frame. Saindo...\")\n        break\n\n    # Exibindo o frame\n    cv2.imshow(\"Video da Webcam\", frame)\n\n    # Aguardando por 1 milissegundo e verificando se a tecla 'q' foi pressionada\n    if cv2.waitKey(1) &amp; 0xFF == ord('q'):\n        break\n\n# Liberando a c\u00e2mera e fechando todas as janelas\nwebcam.release()\ncv2.destroyAllWindows()\n</pre> ## para captura um video, \u00e9 necess\u00e1rio usar um loop para capturar os frames da c\u00e2mera e exibir os frames capturados  ## em tempo real na tela do computador   ## fa\u00e7a o teste em seu computador, copie e cole o c\u00f3digo abaixo e veja o que acontece   import cv2  # Iniciando a captura de v\u00eddeo webcam = cv2.VideoCapture(0)  # Definindo o tamanho da janela webcam.set(cv2.CAP_PROP_FRAME_WIDTH, 640) webcam.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)  # Loop para capturar e exibir os frames while True:     # Capturando um frame     ret, frame = webcam.read()      # Verificando se o frame foi capturado corretamente     if not ret:         print(\"Falha ao capturar o frame. Saindo...\")         break      # Exibindo o frame     cv2.imshow(\"Video da Webcam\", frame)      # Aguardando por 1 milissegundo e verificando se a tecla 'q' foi pressionada     if cv2.waitKey(1) &amp; 0xFF == ord('q'):         break  # Liberando a c\u00e2mera e fechando todas as janelas webcam.release() cv2.destroyAllWindows()"},{"location":"aulas/PDI/lab03/sol_atividade3.html#histograma","title":"Histograma\u00b6","text":"<p>Na ultima aula, tentamos fazer a segmenta\u00e7\u00e3o de um objeto da imagem pelo metodo for\u00e7a bruta #GoHorse, pode ser que funcione mas n\u00e3o \u00e9 a forma mais intessnte de ser feita. Um histograma pode nos ajudar, ele plota em um gr\u00e1fico de frequ\u00eancia as componentes de cores (r,g,b ou gray) da imagem.</p>"},{"location":"aulas/PDI/lab03/sol_atividade3.html#desafio-1","title":"Desafio 1\u00b6","text":"<p>Fa\u00e7a a seguimenta\u00e7\u00e3o da bolinha de cor laranja. Dica use 2 canais de cores para conseguir seguimentar.</p>"},{"location":"aulas/PDI/lab03/sol_atividade3.html#desafio-2","title":"Desafio 2\u00b6","text":"<p>Fa\u00e7a a seguimenta\u00e7\u00e3o da bolinha para a imagem \"bolinha.png\".</p>"},{"location":"aulas/PDI/lab03/sol_atividade3.html#webcam-e-opencv","title":"Webcam e opencv\u00b6","text":""},{"location":"aulas/PDI/lab03/sol_atividade3.html#este-recurso-nao-vai-funcionar-no-google-colab","title":"Este recurso n\u00e3o vai funcionar no google colab\u00b6","text":"<p>Podemos usar a nossa webcam para registrar imagens e videos, para isso usamos a fun\u00e7\u00e3o cv2.VideoCapture.</p>"},{"location":"aulas/PDI/lab03/sol_atividade3.html#desafio-3","title":"Desafio 3\u00b6","text":"<p>Fa\u00e7a uma foto sua.</p>"},{"location":"aulas/PDI/lab03/webcam.html","title":"Webcam","text":"In\u00a0[\u00a0]: Copied! <p>Programa simples com camera webcam e opencv</p> In\u00a0[\u00a0]: Copied! <pre>import cv2\nimport os,sys, os.path\nimport numpy as np\n</pre> import cv2 import os,sys, os.path import numpy as np In\u00a0[\u00a0]: Copied! <pre>def image_da_webcam(img):\n    \"\"\"\n    -&gt;&gt;&gt; !!!! FECHE A JANELA COM A TECLA ESC !!!! &lt;&lt;&lt;&lt;-\n        deve receber a imagem da camera e retornar uma imagems filtrada.\n    \"\"\"\n    img = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n     # Detect edges in the image and threshold it\n    edges = cv2.Laplacian(img, cv2.CV_8U, ksize=5)\n    ret, mask = cv2.threshold(edges, 100, 255, cv2.THRESH_BINARY_INV)\n\n    return mask\n</pre> def image_da_webcam(img):     \"\"\"     -&gt;&gt;&gt; !!!! FECHE A JANELA COM A TECLA ESC !!!! &lt;&lt;&lt;&lt;-         deve receber a imagem da camera e retornar uma imagems filtrada.     \"\"\"     img = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)      # Detect edges in the image and threshold it     edges = cv2.Laplacian(img, cv2.CV_8U, ksize=5)     ret, mask = cv2.threshold(edges, 100, 255, cv2.THRESH_BINARY_INV)      return mask In\u00a0[\u00a0]: Copied! <pre>cv2.namedWindow(\"preview\")\nvc = cv2.VideoCapture(0)\n</pre> cv2.namedWindow(\"preview\") vc = cv2.VideoCapture(0) In\u00a0[\u00a0]: Copied! <pre>if vc.isOpened(): # try to get the first frame\n    rval, frame = vc.read()\nelse:\n    rval = False\n</pre> if vc.isOpened(): # try to get the first frame     rval, frame = vc.read() else:     rval = False In\u00a0[\u00a0]: Copied! <pre>while rval:\n    \n    img = image_da_webcam(frame)\n\n    cv2.imshow(\"preview\", img)\n    rval, frame = vc.read()\n    key = cv2.waitKey(20)\n    if key == 27: # exit on ESC\n        break\n</pre> while rval:          img = image_da_webcam(frame)      cv2.imshow(\"preview\", img)     rval, frame = vc.read()     key = cv2.waitKey(20)     if key == 27: # exit on ESC         break In\u00a0[\u00a0]: Copied! <pre>cv2.destroyWindow(\"preview\")\nvc.release()\n</pre> cv2.destroyWindow(\"preview\") vc.release()"},{"location":"aulas/PDI/lab04/Filtros_de_Convolu%C3%A7%C3%A3o.html","title":"Lab04 - Filtros de Convolu\u00e7\u00e3o","text":"<p>Objetivos da aula:</p> <ul> <li>Conhecer processo generico de filtro de convolu\u00e7\u00e3o</li> <li>conhecer os filtros de blurring (suaviza\u00e7\u00e3o)</li> <li>conhecer o filtro de sharpening (realce)</li> <li>conhecer o filtro de limiar e suas varia\u00e7\u00f5es</li> <li>conhecer o detetor linhas de canny</li> </ul> In\u00a0[1]: Copied! <pre>## Vou fazer o download das imagens do laborat\u00f3rio diretamente do reposit\u00f3rio para ficar mais facil....\n\nimport requests\nimport os\n\n# Define o laborat\u00f3rio\nlaboratorio = 'lab04'  ### altere para o laborat\u00f3rio desejado\ndiretorio = 'lab_images'  ### altere para o diret\u00f3rio que deseja salvar as imagens\n\n# Download de um arquivo\ndef download_file(url, destination):\n    response = requests.get(url, stream=True)\n    if response.status_code == 200:\n        with open(destination, 'wb') as file:\n            for chunk in response.iter_content(chunk_size=8192):\n                file.write(chunk)\n        print(f\"Baixado: {destination}\")\n    else:\n        print(f\"Erro ao baixar {url}\")\n\n# Monta a URL completa\napi_url = \"https://api.github.com/repos/arnaldojr/cognitivecomputing/contents/material/aulas/PDI/\"\nurl_completa = api_url + laboratorio\nprint(f\"Fazendo o download de: {url_completa}\")\n\n# checa se a URL est\u00e1 acess\u00edvel\nresponse = requests.get(url_completa)\nif response.status_code != 200:\n    raise Exception(f\"Erro ao acessar o reposit\u00f3rio: {response.status_code}\")\nfiles = response.json()\n\n\n# Faz o download de cada arquivo\nos.makedirs(diretorio, exist_ok=True) # Cria a pasta downloads\nfor file in files:\n    file_name = file['name']\n    if file_name.endswith(('.png', '.jpg', '.jpeg', '.mp4')):  # Adicione mais extens\u00f5es se necess\u00e1rio\n        file_url = file['download_url']\n        destination = os.path.join(diretorio, file_name)\n        download_file(file_url, destination)\n\nprint(f\"Download conclu\u00eddo. Arquivos salvos na pasta {diretorio}.\")\n</pre> ## Vou fazer o download das imagens do laborat\u00f3rio diretamente do reposit\u00f3rio para ficar mais facil....  import requests import os  # Define o laborat\u00f3rio laboratorio = 'lab04'  ### altere para o laborat\u00f3rio desejado diretorio = 'lab_images'  ### altere para o diret\u00f3rio que deseja salvar as imagens  # Download de um arquivo def download_file(url, destination):     response = requests.get(url, stream=True)     if response.status_code == 200:         with open(destination, 'wb') as file:             for chunk in response.iter_content(chunk_size=8192):                 file.write(chunk)         print(f\"Baixado: {destination}\")     else:         print(f\"Erro ao baixar {url}\")  # Monta a URL completa api_url = \"https://api.github.com/repos/arnaldojr/cognitivecomputing/contents/material/aulas/PDI/\" url_completa = api_url + laboratorio print(f\"Fazendo o download de: {url_completa}\")  # checa se a URL est\u00e1 acess\u00edvel response = requests.get(url_completa) if response.status_code != 200:     raise Exception(f\"Erro ao acessar o reposit\u00f3rio: {response.status_code}\") files = response.json()   # Faz o download de cada arquivo os.makedirs(diretorio, exist_ok=True) # Cria a pasta downloads for file in files:     file_name = file['name']     if file_name.endswith(('.png', '.jpg', '.jpeg', '.mp4')):  # Adicione mais extens\u00f5es se necess\u00e1rio         file_url = file['download_url']         destination = os.path.join(diretorio, file_name)         download_file(file_url, destination)  print(f\"Download conclu\u00eddo. Arquivos salvos na pasta {diretorio}.\") <pre>Fazendo o download de: https://api.github.com/repos/arnaldojr/cognitivecomputing/contents/material/aulas/PDI/lab04\nBaixado: lab_images/convolution.png\nBaixado: lab_images/lena.png\nBaixado: lab_images/people-walking.mp4\nBaixado: lab_images/saida.png\nBaixado: lab_images/sudoku.png\nBaixado: lab_images/tux.png\nDownload conclu\u00eddo. Arquivos salvos na pasta lab_images.\n</pre> In\u00a0[\u00a0]: Copied! <pre>%matplotlib inline\nimport cv2\nfrom matplotlib import pyplot as plt\nimport numpy as np\n\nimg = cv2.imread('convolution.png')\nplt.imshow(img); plt.show()\n</pre> %matplotlib inline import cv2 from matplotlib import pyplot as plt import numpy as np  img = cv2.imread('convolution.png') plt.imshow(img); plt.show() In\u00a0[\u00a0]: Copied! <pre>from IPython.display import Image\nImage(open('same_padding_no_strides.gif','rb').read())\n</pre> from IPython.display import Image Image(open('same_padding_no_strides.gif','rb').read()) Out[\u00a0]: <p>Observa\u00e7\u00e3o</p> <p>Embora o nome convolu\u00e7\u00e3o seja muito usado, na pr\u00e1tica realizamos o processo de correla\u00e7\u00e3o, para realizar a convolu\u00e7\u00e3o \u00e9 necess\u00e1rio realizar a invers\u00e3o da mascara (matriz), o que n\u00e3o \u00e9 um problema pois em processamento de imagem, tipicamente os kernels s\u00e3o sim\u00e9tricos, logo os resultados de convolu\u00e7\u00e3o e correla\u00e7\u00e3o n\u00e3o mudam.</p> In\u00a0[\u00a0]: Copied! <pre>import numpy as np\nimport cv2\n\n\n#carrega imagem\nimg = cv2.imread('lena.png')\nplt.imshow(img, cmap=\"Greys_r\", vmin=0, vmax=255); plt.show()\n\n# Define o kernel\nkernel = np.array([[1, 1, 1, 1, 1], \n                   [1, 1, 1, 1, 1],\n                   [1, 1, 1, 1, 1],\n                   [1, 1, 1, 1, 1],\n                   [1, 1, 1, 1 ,1]])\nkernel = kernel/(np.sum(kernel) if np.sum(kernel)!=0 else 1)\n\n# Realiza o produto de convolu\u00e7\u00e3o\nimgf = cv2.filter2D(img,-1,kernel)\n\n#exibe resultado filtrado\nplt.imshow(imgf, cmap=\"Greys_r\", vmin=0, vmax=255); plt.show()\n</pre> import numpy as np import cv2   #carrega imagem img = cv2.imread('lena.png') plt.imshow(img, cmap=\"Greys_r\", vmin=0, vmax=255); plt.show()  # Define o kernel kernel = np.array([[1, 1, 1, 1, 1],                     [1, 1, 1, 1, 1],                    [1, 1, 1, 1, 1],                    [1, 1, 1, 1, 1],                    [1, 1, 1, 1 ,1]]) kernel = kernel/(np.sum(kernel) if np.sum(kernel)!=0 else 1)  # Realiza o produto de convolu\u00e7\u00e3o imgf = cv2.filter2D(img,-1,kernel)  #exibe resultado filtrado plt.imshow(imgf, cmap=\"Greys_r\", vmin=0, vmax=255); plt.show() <p>FILTROS PARA BLURRING</p> <p>O filtro de blurring (borramento) consiste na  perda gradual de foco da imagem, produzindo a sensa\u00e7\u00e3o que ela est\u00e1 borrada. Em outras palavras s\u00e3o filtros passa-baixa.</p> <p>Existem diversos m\u00e9todos para constru\u00e7\u00f5es de kernels para blurring:</p> <ul> <li>filtro da m\u00e9dia (box filter): blur = cv.blur(img,(5,5))</li> <li>filtro gaussiano: blur = cv.GaussianBlur(img,(5,5),0)</li> <li>filtro da mediana: blur = cv.medianBlur(img,5)</li> <li>filtro bilateral: blur = cv.bilateralFilter(img,9,75,75)</li> </ul> In\u00a0[4]: Copied! <pre>import numpy as np\nimport cv2 \n\n#carrega imagem\nimg = cv2.imread('lena.png')\n\n# Realiza o blur\nimgf = cv2.blur(img,(51,51),0)\n\n# Exibir as imagens\nplt.figure(figsize=(15, 5))\nplt.subplot(1, 3, 1)\nplt.title('Imagem Original')\nplt.imshow(img, cmap='gray')\n\nplt.subplot(1, 3, 2)\nplt.title('Suavizada (Blurring)')\nplt.imshow(imgf, cmap='gray')\n</pre> import numpy as np import cv2   #carrega imagem img = cv2.imread('lena.png')  # Realiza o blur imgf = cv2.blur(img,(51,51),0)  # Exibir as imagens plt.figure(figsize=(15, 5)) plt.subplot(1, 3, 1) plt.title('Imagem Original') plt.imshow(img, cmap='gray')  plt.subplot(1, 3, 2) plt.title('Suavizada (Blurring)') plt.imshow(imgf, cmap='gray') Out[4]: <pre>&lt;matplotlib.image.AxesImage at 0x1511ee310&gt;</pre> In\u00a0[\u00a0]: Copied! <pre>#Implemente seu c\u00f3digo aqui.\n</pre> #Implemente seu c\u00f3digo aqui. <p>FILTRO DE SHARPENING</p> <p>O filtro de sharpening consiste no ganho gradual de foco de uma imagem, produzindo a sensa\u00e7\u00e3o que ela est\u00e1 cada vez mais bem definida. \u00c9 uma aproxima\u00e7\u00e3o da inversa do filtro de blurring.</p> <p>Existem diversos m\u00e9todos para constru\u00e7\u00f5es de kernels para blurring:</p> <ul> <li>filtro Sobel X: imgf = cv.Sobel(img,cv.CV_64F,1,0,ksize=5)</li> <li>filtro Sobel Y: imgf = cv.Sobel(img,cv.CV_64F,0,1,ksize=5)</li> <li>filtro Laplaciano: imgf = cv.Laplacian(img,cv.CV_64F)</li> </ul> <p>Abaixo, temos as formas matriciais do filtro de sharpening.</p> In\u00a0[\u00a0]: Copied! <pre>#Filtro Laplaciano\nkernel = np.array([[0, -1, 0], \n                   [-1, 4, -1], \n                   [0, -1, 0]])\n\nkernel = np.array([[-1, -1, -1], \n                   [-1, 8, -1], \n                   [-1, -1, -1]])\n#filtro de Sobel X\nkernel = np.array([[-1, 0, 1], \n                   [-2, 0, 2], \n                   [-1, 0, 1]])\nkernel = np.array([[-1, -2, -1], \n                   [ 0, 0, 0], \n                   [-1, 0, 1]])\n</pre> #Filtro Laplaciano kernel = np.array([[0, -1, 0],                     [-1, 4, -1],                     [0, -1, 0]])  kernel = np.array([[-1, -1, -1],                     [-1, 8, -1],                     [-1, -1, -1]]) #filtro de Sobel X kernel = np.array([[-1, 0, 1],                     [-2, 0, 2],                     [-1, 0, 1]]) kernel = np.array([[-1, -2, -1],                     [ 0, 0, 0],                     [-1, 0, 1]]) In\u00a0[\u00a0]: Copied! <pre>import numpy as np\nimport cv2\n\n\n#carrega imagem\nimg = cv2.imread('lena.png')\nplt.imshow(img, cmap=\"Greys_r\", vmin=0, vmax=255); plt.show()\n\n\n\nimgf = cv2.Sobel(img,cv2.CV_64F,1,0,ksize=3)\nimgf2 = cv2.Sobel(img,cv2.CV_64F,0,1,ksize=3)\n\n# Monta o kernel filtro \n#kernel = np.array([[-1, -1, -1], \n#                   [-1, 8, -1], \n#                   [-1, -1, -1]])\n# Realiza o produto de convolu\u00e7\u00e3o\n#imgf = cv2.filter2D(img,-1,kernel)\n\n#exibe resultado filtrado\nplt.imshow(imgf, cmap=\"Greys_r\", vmin=0, vmax=255);plt.show()\nplt.imshow(imgf2, cmap=\"Greys_r\", vmin=0, vmax=255); plt.show()\n</pre> import numpy as np import cv2   #carrega imagem img = cv2.imread('lena.png') plt.imshow(img, cmap=\"Greys_r\", vmin=0, vmax=255); plt.show()    imgf = cv2.Sobel(img,cv2.CV_64F,1,0,ksize=3) imgf2 = cv2.Sobel(img,cv2.CV_64F,0,1,ksize=3)  # Monta o kernel filtro  #kernel = np.array([[-1, -1, -1],  #                   [-1, 8, -1],  #                   [-1, -1, -1]]) # Realiza o produto de convolu\u00e7\u00e3o #imgf = cv2.filter2D(img,-1,kernel)  #exibe resultado filtrado plt.imshow(imgf, cmap=\"Greys_r\", vmin=0, vmax=255);plt.show() plt.imshow(imgf2, cmap=\"Greys_r\", vmin=0, vmax=255); plt.show() <pre>WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n</pre> <pre>WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n</pre> In\u00a0[\u00a0]: Copied! <pre>#implemente seu c\u00f3digo aqui.\n</pre> #implemente seu c\u00f3digo aqui. <p>FILTRO DE BORDAS DE CANNY</p> <p>O filtro de canny \u00e9 um detector de linhas e bordas que combina de forma mais sofisticada opera\u00e7\u00f5es lineares.</p> In\u00a0[2]: Copied! <pre>import cv2\nimport matplotlib.pyplot as plt\n\n# Carregar a imagem\nimage = cv2.imread('lab_images/lena.png', cv2.IMREAD_GRAYSCALE)\n\n\nthreshold_min = 100\nthreshold_max = 200\n# Aplicar o detector de bordas de Canny\nedges = cv2.Canny(image, threshold1=threshold_min, threshold2=threshold_max)\n\n# Exibir a imagem original e a imagem com bordas detectadas\nplt.figure(figsize=(10, 5))\nplt.subplot(1, 2, 1)\nplt.title('Imagem Original')\nplt.imshow(image, cmap='gray')\n\nplt.subplot(1, 2, 2)\nplt.title('Bordas Detectadas (Canny)')\nplt.imshow(edges, cmap='gray')\nplt.show()\n</pre> import cv2 import matplotlib.pyplot as plt  # Carregar a imagem image = cv2.imread('lab_images/lena.png', cv2.IMREAD_GRAYSCALE)   threshold_min = 100 threshold_max = 200 # Aplicar o detector de bordas de Canny edges = cv2.Canny(image, threshold1=threshold_min, threshold2=threshold_max)  # Exibir a imagem original e a imagem com bordas detectadas plt.figure(figsize=(10, 5)) plt.subplot(1, 2, 1) plt.title('Imagem Original') plt.imshow(image, cmap='gray')  plt.subplot(1, 2, 2) plt.title('Bordas Detectadas (Canny)') plt.imshow(edges, cmap='gray') plt.show() In\u00a0[\u00a0]: Copied! <pre>#Seu c\u00f3digo\n</pre> #Seu c\u00f3digo In\u00a0[\u00a0]: Copied! <pre>import cv2\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# Carregar imagem em escala de cinza\nimg_original = cv2.imread('lena.png')\nimg = cv2.cvtColor(img_original, cv2.COLOR_BGR2GRAY)\n\n\n# Definir um valor de limiar\nthreshold_value = 127\n\n# Aplicando Filtro de Limiariza\u00e7\u00e3o\n_, thresh_binary = cv2.threshold(img, threshold_value, 255, cv2.THRESH_BINARY)\n_, thresh_binary_inv = cv2.threshold(img, threshold_value, 255, cv2.THRESH_BINARY_INV)\n_, thresh_trunc = cv2.threshold(img, threshold_value, 255, cv2.THRESH_TRUNC)\n_, thresh_tozero = cv2.threshold(img, threshold_value, 255, cv2.THRESH_TOZERO)\n_, thresh_tozero_inv = cv2.threshold(img, threshold_value, 255, cv2.THRESH_TOZERO_INV)\n_, thresh_otsu = cv2.threshold(img, 0, 255, cv2.THRESH_OTSU)\n\ntitles = ['Original','Gray', 'THRESH_BINARY', 'THRESH_BINARY_INV', 'THRESH_TRUNC', 'THRESH_TOZERO', 'THRESH_TOZERO_INV', 'THRESH_OTSU']\nimages = [img_original, img, thresh_binary, thresh_binary_inv, thresh_trunc, thresh_tozero, thresh_tozero_inv, thresh_otsu]\n\nfig, axes = plt.subplots(2, 4, figsize=(12, 6))\nfor ax, title, image in zip(axes.flat, titles, images):\n    ax.imshow(image, cmap='gray')\n    ax.set_title(title)\n    ax.axis('off')\n\nplt.tight_layout()\nplt.show()\n</pre> import cv2 import numpy as np import matplotlib.pyplot as plt  # Carregar imagem em escala de cinza img_original = cv2.imread('lena.png') img = cv2.cvtColor(img_original, cv2.COLOR_BGR2GRAY)   # Definir um valor de limiar threshold_value = 127  # Aplicando Filtro de Limiariza\u00e7\u00e3o _, thresh_binary = cv2.threshold(img, threshold_value, 255, cv2.THRESH_BINARY) _, thresh_binary_inv = cv2.threshold(img, threshold_value, 255, cv2.THRESH_BINARY_INV) _, thresh_trunc = cv2.threshold(img, threshold_value, 255, cv2.THRESH_TRUNC) _, thresh_tozero = cv2.threshold(img, threshold_value, 255, cv2.THRESH_TOZERO) _, thresh_tozero_inv = cv2.threshold(img, threshold_value, 255, cv2.THRESH_TOZERO_INV) _, thresh_otsu = cv2.threshold(img, 0, 255, cv2.THRESH_OTSU)  titles = ['Original','Gray', 'THRESH_BINARY', 'THRESH_BINARY_INV', 'THRESH_TRUNC', 'THRESH_TOZERO', 'THRESH_TOZERO_INV', 'THRESH_OTSU'] images = [img_original, img, thresh_binary, thresh_binary_inv, thresh_trunc, thresh_tozero, thresh_tozero_inv, thresh_otsu]  fig, axes = plt.subplots(2, 4, figsize=(12, 6)) for ax, title, image in zip(axes.flat, titles, images):     ax.imshow(image, cmap='gray')     ax.set_title(title)     ax.axis('off')  plt.tight_layout() plt.show() In\u00a0[18]: Copied! <pre>import cv2\nimport matplotlib.pyplot as plt\n\n# Carregar duas imagens\nimage1 = cv2.imread('lab_images/lena.png')\nimage2 = cv2.imread('lab_images/tux.png')\n\n# Redimensionar as imagens para o mesmo tamanho (se necess\u00e1rio)\nimage2 = cv2.resize(image2, (image1.shape[1], image1.shape[0]))\n\n# Definir o valor de alpha (transpar\u00eancia)\nalpha = 0.5  # 50% de cada imagem\n\n# Aplicar a sobreposi\u00e7\u00e3o\nblended_image = cv2.addWeighted(image1, 1 - alpha, image2, alpha, 0)\n\n# Exibir as imagens\nplt.figure(figsize=(15, 5))\nplt.subplot(1, 3, 1)\nplt.title('Imagem 1 (Lena)')\nplt.imshow(cv2.cvtColor(image1, cv2.COLOR_BGR2RGB))\n\nplt.subplot(1, 3, 2)\nplt.title('Imagem 2 (Tux)')\nplt.imshow(cv2.cvtColor(image2, cv2.COLOR_BGR2RGB))\n\nplt.subplot(1, 3, 3)\nplt.title(f'Sobreposi\u00e7\u00e3o (\u03b1 = {alpha})')\nplt.imshow(cv2.cvtColor(blended_image, cv2.COLOR_BGR2RGB))\nplt.show()\n</pre> import cv2 import matplotlib.pyplot as plt  # Carregar duas imagens image1 = cv2.imread('lab_images/lena.png') image2 = cv2.imread('lab_images/tux.png')  # Redimensionar as imagens para o mesmo tamanho (se necess\u00e1rio) image2 = cv2.resize(image2, (image1.shape[1], image1.shape[0]))  # Definir o valor de alpha (transpar\u00eancia) alpha = 0.5  # 50% de cada imagem  # Aplicar a sobreposi\u00e7\u00e3o blended_image = cv2.addWeighted(image1, 1 - alpha, image2, alpha, 0)  # Exibir as imagens plt.figure(figsize=(15, 5)) plt.subplot(1, 3, 1) plt.title('Imagem 1 (Lena)') plt.imshow(cv2.cvtColor(image1, cv2.COLOR_BGR2RGB))  plt.subplot(1, 3, 2) plt.title('Imagem 2 (Tux)') plt.imshow(cv2.cvtColor(image2, cv2.COLOR_BGR2RGB))  plt.subplot(1, 3, 3) plt.title(f'Sobreposi\u00e7\u00e3o (\u03b1 = {alpha})') plt.imshow(cv2.cvtColor(blended_image, cv2.COLOR_BGR2RGB)) plt.show() In\u00a0[\u00a0]: Copied! <pre>#Seu c\u00f3digo aqui.\n</pre> #Seu c\u00f3digo aqui."},{"location":"aulas/PDI/lab04/Filtros_de_Convolu%C3%A7%C3%A3o.html#introducao-aos-filtros-de-convolucao","title":"Introdu\u00e7\u00e3o aos Filtros de Convolu\u00e7\u00e3o\u00b6","text":"<p>O filtro de convolu\u00e7\u00e3o \u00e9 um nomes dados para filtragem no dom\u00ednio espacial. Esse processo ocorre com a aplica\u00e7\u00e3o de filtros (pequenas matrizes), posicionados sob cada pixel da imagem. Estes filtros, normalmente, s\u00e3o chamados de kernels (ou n\u00facleos). O resultado final do valor do pixel \u00e9 calculado atrav\u00e9s de um produto de convolu\u00e7\u00e3o.</p> <p>Normalmente os kernels s\u00e3o matrizes 3x3, 5x5 ou 7x7.</p>"},{"location":"aulas/PDI/lab04/Filtros_de_Convolu%C3%A7%C3%A3o.html#desafio-0","title":"Desafio 0\u00b6","text":"<p>Abra o link https://setosa.io/ev/image-kernels/ e de forma intuitiva altere o valor do filtro/kernel e descubra efeitos resultantes.</p>"},{"location":"aulas/PDI/lab04/Filtros_de_Convolu%C3%A7%C3%A3o.html#implementacao-na-opencv","title":"Implementa\u00e7\u00e3o na OpenCV\u00b6","text":"<p>Podemos implementar o produto de convolu\u00e7\u00e3o montando uma estrutura com dois for para varrer a imagem toda, pixel-a-pixel.N\u00e3o \u00e9 a forma mais eficiente, pois Na OpenCV tem uma fun\u00e7\u00e3o built-in para implementa\u00e7\u00e3o de filtro de convolu\u00e7\u00e3o a cv2.filter2D()</p>"},{"location":"aulas/PDI/lab04/Filtros_de_Convolu%C3%A7%C3%A3o.html#desafio-1","title":"Desafio 1\u00b6","text":"<p>Escolha uma imagem da sua prefer\u00eancia e fa\u00e7a um estudo sobre os diferentes tipos de filtros de borramento, analise tamb\u00e9m o que acontece quando \u00e9 alterado o tamanho do kernel.</p>"},{"location":"aulas/PDI/lab04/Filtros_de_Convolu%C3%A7%C3%A3o.html#desafio-2","title":"Desafio 2\u00b6","text":"<p>Escolha uma imagem da sua prefer\u00eancia e fa\u00e7a um estudo sobre os diferentes tipos de filtros de contraste, analise tamb\u00e9m o que acontece quando \u00e9 alterado o tamanho do kernel.</p>"},{"location":"aulas/PDI/lab04/Filtros_de_Convolu%C3%A7%C3%A3o.html#desafio-3","title":"Desafio 3\u00b6","text":"<p>O Filtro de Canny \u00e9 um dos mais utilizados at\u00e9 hoje, por ser robusto e apresentar bons resultados.</p> <p>Ajuste os valores de threshold1 e threshold2 no detector de Canny e observe como os limiares afetam a detec\u00e7\u00e3o de bordas. Tente encontrar os valores ideais para diferentes imagens.</p>"},{"location":"aulas/PDI/lab04/Filtros_de_Convolu%C3%A7%C3%A3o.html#filtro-de-limiarizacao","title":"FILTRO DE LIMIARIZA\u00c7\u00c3O\u00b6","text":"<p>O filtro de limiariza\u00e7\u00e3o \u00e9 uma t\u00e9cnica que converte uma imagem em tons de cinza em uma imagem bin\u00e1ria, onde os pixels s\u00e3o classificados como preto ou branco com base em um valor de limiar. Essa t\u00e9cnica \u00e9 utilizada em tarefas como segmenta\u00e7\u00e3o de objetos, detec\u00e7\u00e3o de bordas e pr\u00e9-processamento de imagens.</p> <p>O OpenCV oferece v\u00e1rias t\u00e9cnicas de limiariza\u00e7\u00e3o, cada uma com suas particularidades. Abaixo est\u00e3o as principais:</p> <ul> <li>cv2.THRESH_BINARY: Pixels acima do limiar s\u00e3o definidos como branco (255), e os abaixo, como preto (0).</li> <li>cv2.THRESH_BINARY_INV: Inverso do THRESH_BINARY. Pixels acima do limiar s\u00e3o definidos como preto, e os abaixo, como branco.</li> <li>cv2.THRESH_TRUNC: Pixels acima do limiar s\u00e3o truncados ao valor do limiar, enquanto os abaixo permanecem inalterados.</li> <li>cv2.THRESH_TOZERO: Pixels abaixo do limiar s\u00e3o definidos como preto, e os acima permanecem inalterados.</li> <li>cv2.THRESH_TOZERO_INV: Inverso do THRESH_TOZERO. Pixels acima do limiar s\u00e3o definidos como preto, e os abaixo permanecem inalterados.</li> <li>cv2.THRESH_OTSU: M\u00e9todo autom\u00e1tico para determinar o limiar ideal, especialmente \u00fatil para imagens com histogramas bimodais</li> </ul> <p>DICA</p> <ul> <li>cv2.threshold(): Fun\u00e7\u00e3o usada para aplicar a limiariza\u00e7\u00e3o. Recebe a imagem, o valor do limiar, o valor m\u00e1ximo (geralmente 255) e o tipo de limiariza\u00e7\u00e3o.</li> <li>cv2.THRESH_OTSU: M\u00e9todo autom\u00e1tico que calcula o limiar ideal com base no histograma da imagem. N\u00e3o \u00e9 necess\u00e1rio fornecer um valor de limiar manualmente.</li> </ul>"},{"location":"aulas/PDI/lab04/Filtros_de_Convolu%C3%A7%C3%A3o.html#filtro-de-sobreposicao-de-imagens","title":"FILTRO DE SOBREPOSI\u00c7\u00c3O DE IMAGENS\u00b6","text":"<p>O filtro de sobreposi\u00e7\u00e3o (ou blending) mescla duas imagens, gerando um efeito de transpar\u00eancia ou combina\u00e7\u00e3o. A opera\u00e7\u00e3o matem\u00e1tica para a imagem de sa\u00edda \u00e9 dada por:</p> <p>A opera\u00e7\u00e3o da imagem de saida \u00e9 a seguinte: g(x)=(1\u2212\u03b1)\u2217f0(x)+\u03b1\u2217f1(x)</p>"},{"location":"aulas/PDI/lab04/Filtros_de_Convolu%C3%A7%C3%A3o.html#desafio-4","title":"Desafio 4\u00b6","text":"<p>Combine a sobreposi\u00e7\u00e3o com outros filtros, como suaviza\u00e7\u00e3o ou realce, e observe os efeitos.</p>"},{"location":"aulas/PDI/lab04/Filtros_de_Convolu%C3%A7%C3%A3o.html#desafio-5","title":"Desafio 5\u00b6","text":"<p>Fa\u00e7a um script python (.py) que processa um video (webcam ou .mp4) e processe cada frame aplicando uma opera\u00e7\u00e3o de convolu\u00e7\u00e3o (por exemplo, para detec\u00e7\u00e3o de bordas ou desfoque) e exiba o resultado em tempo real.</p> <p>Defini\u00e7\u00e3o da M\u00e1scara de Convolu\u00e7\u00e3o:</p> <ul> <li>Escolha e implemente pelo menos uma m\u00e1scara de convolu\u00e7\u00e3o.</li> <li>Exemplos:<ul> <li>Detec\u00e7\u00e3o de Bordas: M\u00e1scara de Sobel ou Laplaciano.</li> <li>Desfoque: M\u00e1scara m\u00e9dia ou gaussiana.</li> </ul> </li> <li>Explique brevemente no c\u00f3digo o efeito de cada m\u00e1scara.</li> </ul> <p>Organiza\u00e7\u00e3o de c\u00f3digo</p> <ul> <li>C\u00f3digo bem comentado, com fun\u00e7\u00f5es (separando as responsabilidades) e estrutura clara.</li> </ul>"},{"location":"aulas/PDI/lab04/sol_Filtros_de_Convolu%C3%A7%C3%A3o.html","title":"sol Filtros de Convolu\u00e7\u00e3o","text":"<p>Objetivos da aula:</p> <ul> <li>Conhecer processo generico de filtro de convolu\u00e7\u00e3o</li> <li>conhecer os filtros de blurring (suaviza\u00e7\u00e3o)</li> <li>conhecer o filtro de sharpening (realce)</li> <li>conhecer o detetor linhas de canny</li> </ul> <p>Filtro de convolu\u00e7\u00e3o</p> <p>O filtro de convolu\u00e7\u00e3o \u00e9 um nomes dados para filtragem no dom\u00ednio espacial. Esse processo ocorre com a aplica\u00e7\u00e3o de filtros (pequenas matrizes), posicionados sob cada pixel da imagem. Estes filtros, normalmente, s\u00e3o chamados de kernels (ou n\u00facleos). O resultado final do valor do pixel \u00e9 calculado atrav\u00e9s de um produto de convolu\u00e7\u00e3o.</p> <p>Normalmente os kernels s\u00e3o matrizes 3x3, 5x5 ou 7x7.</p> In\u00a0[\u00a0]: Copied! <pre># fazendo o download das imagens necess\u00e1rias para o lab\n\n!wget https://raw.githubusercontent.com/arnaldojr/cognitivecomputing/master/material/aulas/PDI/lab04/convolution.png /content\n!wget https://raw.githubusercontent.com/arnaldojr/cognitivecomputing/master/material/aulas/PDI/lab04/lena.png /content\n!wget https://raw.githubusercontent.com/arnaldojr/cognitivecomputing/master/material/aulas/PDI/lab04/saida.png /content\n!wget https://raw.githubusercontent.com/arnaldojr/cognitivecomputing/master/material/aulas/PDI/lab04/same_padding_no_strides.gif /content\n!wget https://raw.githubusercontent.com/arnaldojr/cognitivecomputing/master/material/aulas/PDI/lab04/tux.png /content\n</pre> # fazendo o download das imagens necess\u00e1rias para o lab  !wget https://raw.githubusercontent.com/arnaldojr/cognitivecomputing/master/material/aulas/PDI/lab04/convolution.png /content !wget https://raw.githubusercontent.com/arnaldojr/cognitivecomputing/master/material/aulas/PDI/lab04/lena.png /content !wget https://raw.githubusercontent.com/arnaldojr/cognitivecomputing/master/material/aulas/PDI/lab04/saida.png /content !wget https://raw.githubusercontent.com/arnaldojr/cognitivecomputing/master/material/aulas/PDI/lab04/same_padding_no_strides.gif /content !wget https://raw.githubusercontent.com/arnaldojr/cognitivecomputing/master/material/aulas/PDI/lab04/tux.png /content In\u00a0[1]: Copied! <pre>%matplotlib inline\nimport cv2\nfrom matplotlib import pyplot as plt\nimport numpy as np\n\nimg = cv2.imread('convolution.png')\nplt.imshow(img); plt.show()\n</pre> %matplotlib inline import cv2 from matplotlib import pyplot as plt import numpy as np  img = cv2.imread('convolution.png') plt.imshow(img); plt.show() In\u00a0[2]: Copied! <pre>from IPython.display import Image\nImage(open('same_padding_no_strides.gif','rb').read())\n</pre> from IPython.display import Image Image(open('same_padding_no_strides.gif','rb').read()) Out[2]: <p>Observa\u00e7\u00e3o</p> <p>Embora o nome convolu\u00e7\u00e3o seja muito usado, na pr\u00e1tica realizamos o processo de correla\u00e7\u00e3o, para realizar a convolu\u00e7\u00e3o \u00e9 necess\u00e1rio realizar a invers\u00e3o da mascara (matriz), o que n\u00e3o \u00e9 um problema pois em processamento de imagem, tipicamente os kernels s\u00e3o sim\u00e9tricos, logo os resultados de convolu\u00e7\u00e3o e correla\u00e7\u00e3o n\u00e3o mudam.</p> In\u00a0[3]: Copied! <pre>import numpy as np\nimport cv2\n\n\n#carrega imagem\nimg = cv2.imread('lena.png')\nplt.imshow(img, cmap=\"Greys_r\", vmin=0, vmax=255); plt.show()\n\n# Define o kernel\nkernel = np.array([[1, 1, 1, 1, 1], \n                   [1, 1, 1, 1, 1],\n                   [1, 1, 1, 1, 1],\n                   [1, 1, 1, 1, 1],\n                   [1, 1, 1, 1 ,1]])\nkernel = kernel/(np.sum(kernel) if np.sum(kernel)!=0 else 1)\n\n# Realiza o produto de convolu\u00e7\u00e3o\nimgf = cv2.filter2D(img,-1,kernel)\n\n#exibe resultado filtrado\nplt.imshow(imgf, cmap=\"Greys_r\", vmin=0, vmax=255); plt.show()\n</pre> import numpy as np import cv2   #carrega imagem img = cv2.imread('lena.png') plt.imshow(img, cmap=\"Greys_r\", vmin=0, vmax=255); plt.show()  # Define o kernel kernel = np.array([[1, 1, 1, 1, 1],                     [1, 1, 1, 1, 1],                    [1, 1, 1, 1, 1],                    [1, 1, 1, 1, 1],                    [1, 1, 1, 1 ,1]]) kernel = kernel/(np.sum(kernel) if np.sum(kernel)!=0 else 1)  # Realiza o produto de convolu\u00e7\u00e3o imgf = cv2.filter2D(img,-1,kernel)  #exibe resultado filtrado plt.imshow(imgf, cmap=\"Greys_r\", vmin=0, vmax=255); plt.show() <p>FILTROS PARA BLURRING</p> <p>O filtro de blurring (borramento) consiste na  perda gradual de foco da imagem, produzindo a sensa\u00e7\u00e3o que ela est\u00e1 borrada. Em outras palavras s\u00e3o filtros passa-baixa.</p> <p>Existem diversos m\u00e9todos para constru\u00e7\u00f5es de kernels para blurring:</p> <ul> <li>filtro da m\u00e9dia (box filter): blur = cv.blur(img,(5,5))</li> <li>filtro gaussiano: blur = cv.GaussianBlur(img,(5,5),0)</li> <li>filtro da mediana: blur = cv.medianBlur(img,5)</li> <li>filtro bilateral: blur = cv.bilateralFilter(img,9,75,75)</li> </ul> In\u00a0[4]: Copied! <pre>import numpy as np\nimport cv2 \n\n#carrega imagem\nimg = cv2.imread('lena.png')\nplt.imshow(img, cmap=\"Greys_r\", vmin=0, vmax=255); plt.show()\n\n# Realiza o blur\nimgf = cv2.blur(img,(51,51),0)\n\n#exibe resultado filtrado\nplt.imshow(imgf, cmap=\"Greys_r\", vmin=0, vmax=255); plt.show()\n</pre> import numpy as np import cv2   #carrega imagem img = cv2.imread('lena.png') plt.imshow(img, cmap=\"Greys_r\", vmin=0, vmax=255); plt.show()  # Realiza o blur imgf = cv2.blur(img,(51,51),0)  #exibe resultado filtrado plt.imshow(imgf, cmap=\"Greys_r\", vmin=0, vmax=255); plt.show() In\u00a0[5]: Copied! <pre>#Implemente seu c\u00f3digo aqui.\n\n# Como a ideia \u00e9 realizar um estudo para entender o efeito de diferentes filtros, vou realizar a mesma opera\u00e7\u00e3o para diferentes tamanhos de kernel.\n# Vou utilizar um filtro de m\u00e9dia, um filtro gaussiano, um filtro de mediana e um filtro bilateral. \n# Vou exibir os resultados para cada tamanho de kernel. \n# Por essa raz\u00e3o, vou criar uma figura com subplots para exibir os resultados e varrer os diferentes tamanhos de kernel utilizando um loop for.\n\n# \u00c9 apenas uma sugest\u00e3o de abordagem, voc\u00ea pode implementar de outra forma se preferir.\n\n\nimport cv2\nfrom matplotlib import pyplot as plt\n\n# Carrega a imagem\nimg = cv2.imread('lena.png')\nimg = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n\n# Define os tamanhos de kernel para experimenta\u00e7\u00e3o\nkernels = [(5, 5), (15, 15), (51, 51)]\n\n# Cria uma figura com subplots\nfig, axs = plt.subplots(len(kernels) + 1, 4, figsize=(20, 15))\n\n# Exibe a imagem original\naxs[0, 0].imshow(img)\naxs[0, 0].set_title('Imagem Original')\nfor i in range(1, 4):\n    axs[0, i].axis('off')\n\n# Aplica e exibe os diferentes filtros para cada tamanho de kernel\nfor i, kernel in enumerate(kernels, 1):\n    # Filtro de M\u00e9dia\n    img_blur = cv2.blur(img, kernel)\n    axs[i, 0].imshow(img_blur)\n    axs[i, 0].set_title(f'Filtro de M\u00e9dia - Kernel {kernel}')\n\n    # Filtro Gaussiano\n    img_gaussian = cv2.GaussianBlur(img, kernel, 0)\n    axs[i, 1].imshow(img_gaussian)\n    axs[i, 1].set_title(f'Filtro Gaussiano - Kernel {kernel}')\n\n    # Filtro de Mediana\n    img_median = cv2.medianBlur(img, kernel[0])  # O kernel \u00e9 um \u00fanico valor para o filtro de mediana\n    axs[i, 2].imshow(img_median)\n    axs[i, 2].set_title(f'Filtro de Mediana - Kernel {kernel[0]}')\n\n    # Filtro Bilateral\n    img_bilateral = cv2.bilateralFilter(img, 9, 75, 75)\n    axs[i, 3].imshow(img_bilateral)\n    axs[i, 3].set_title(f'Filtro Bilateral - D=9, SigmaColor=75, SigmaSpace=75')\n\n# Ajusta o layout e exibe a figura\nplt.tight_layout()\nplt.show()\n</pre> #Implemente seu c\u00f3digo aqui.  # Como a ideia \u00e9 realizar um estudo para entender o efeito de diferentes filtros, vou realizar a mesma opera\u00e7\u00e3o para diferentes tamanhos de kernel. # Vou utilizar um filtro de m\u00e9dia, um filtro gaussiano, um filtro de mediana e um filtro bilateral.  # Vou exibir os resultados para cada tamanho de kernel.  # Por essa raz\u00e3o, vou criar uma figura com subplots para exibir os resultados e varrer os diferentes tamanhos de kernel utilizando um loop for.  # \u00c9 apenas uma sugest\u00e3o de abordagem, voc\u00ea pode implementar de outra forma se preferir.   import cv2 from matplotlib import pyplot as plt  # Carrega a imagem img = cv2.imread('lena.png') img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)  # Define os tamanhos de kernel para experimenta\u00e7\u00e3o kernels = [(5, 5), (15, 15), (51, 51)]  # Cria uma figura com subplots fig, axs = plt.subplots(len(kernels) + 1, 4, figsize=(20, 15))  # Exibe a imagem original axs[0, 0].imshow(img) axs[0, 0].set_title('Imagem Original') for i in range(1, 4):     axs[0, i].axis('off')  # Aplica e exibe os diferentes filtros para cada tamanho de kernel for i, kernel in enumerate(kernels, 1):     # Filtro de M\u00e9dia     img_blur = cv2.blur(img, kernel)     axs[i, 0].imshow(img_blur)     axs[i, 0].set_title(f'Filtro de M\u00e9dia - Kernel {kernel}')      # Filtro Gaussiano     img_gaussian = cv2.GaussianBlur(img, kernel, 0)     axs[i, 1].imshow(img_gaussian)     axs[i, 1].set_title(f'Filtro Gaussiano - Kernel {kernel}')      # Filtro de Mediana     img_median = cv2.medianBlur(img, kernel[0])  # O kernel \u00e9 um \u00fanico valor para o filtro de mediana     axs[i, 2].imshow(img_median)     axs[i, 2].set_title(f'Filtro de Mediana - Kernel {kernel[0]}')      # Filtro Bilateral     img_bilateral = cv2.bilateralFilter(img, 9, 75, 75)     axs[i, 3].imshow(img_bilateral)     axs[i, 3].set_title(f'Filtro Bilateral - D=9, SigmaColor=75, SigmaSpace=75')  # Ajusta o layout e exibe a figura plt.tight_layout() plt.show()  <p>FILTRO DE SHARPENING</p> <p>O filtro de sharpening consiste no ganho gradual de foco de uma imagem, produzindo a sensa\u00e7\u00e3o que ela est\u00e1 cada vez mais bem definida. \u00c9 uma aproxima\u00e7\u00e3o da inversa do filtro de blurring.</p> <p>Existem diversos m\u00e9todos para constru\u00e7\u00f5es de kernels para blurring:</p> <ul> <li>filtro Sobel X: imgf = cv.Sobel(img,cv.CV_64F,1,0,ksize=5)</li> <li>filtro Sobel Y: imgf = cv.Sobel(img,cv.CV_64F,0,1,ksize=5)</li> <li>filtro Laplaciano: imgf = cv.Laplacian(img,cv.CV_64F)</li> </ul> <p>Abaixo, temos as formas matriciais do filtro de sharpening.</p> In\u00a0[6]: Copied! <pre>#Filtro Laplaciano\nkernel = np.array([[0, -1, 0], \n                   [-1, 4, -1], \n                   [0, -1, 0]])\n\nkernel = np.array([[-1, -1, -1], \n                   [-1, 8, -1], \n                   [-1, -1, -1]])\n#filtro de Sobel X\nkernel = np.array([[-1, 0, 1], \n                   [-2, 0, 2], \n                   [-1, 0, 1]])\nkernel = np.array([[-1, -2, -1], \n                   [ 0, 0, 0], \n                   [-1, 0, 1]])\n</pre> #Filtro Laplaciano kernel = np.array([[0, -1, 0],                     [-1, 4, -1],                     [0, -1, 0]])  kernel = np.array([[-1, -1, -1],                     [-1, 8, -1],                     [-1, -1, -1]]) #filtro de Sobel X kernel = np.array([[-1, 0, 1],                     [-2, 0, 2],                     [-1, 0, 1]]) kernel = np.array([[-1, -2, -1],                     [ 0, 0, 0],                     [-1, 0, 1]]) In\u00a0[7]: Copied! <pre>import numpy as np\nimport cv2\n\n\n#carrega imagem\nimg = cv2.imread('lena.png')\nplt.imshow(img, cmap=\"Greys_r\", vmin=0, vmax=255); plt.show()\n\n\n\nimgf = cv2.Sobel(img,cv2.CV_64F,1,0,ksize=3)\nimgf2 = cv2.Sobel(img,cv2.CV_64F,0,1,ksize=3)\n\n# Monta o kernel filtro \n#kernel = np.array([[-1, -1, -1], \n#                   [-1, 8, -1], \n#                   [-1, -1, -1]])\n# Realiza o produto de convolu\u00e7\u00e3o\n#imgf = cv2.filter2D(img,-1,kernel)\n\n#exibe resultado filtrado\nplt.imshow(imgf, cmap=\"Greys_r\", vmin=0, vmax=255);plt.show()\nplt.imshow(imgf2, cmap=\"Greys_r\", vmin=0, vmax=255); plt.show()\n</pre> import numpy as np import cv2   #carrega imagem img = cv2.imread('lena.png') plt.imshow(img, cmap=\"Greys_r\", vmin=0, vmax=255); plt.show()    imgf = cv2.Sobel(img,cv2.CV_64F,1,0,ksize=3) imgf2 = cv2.Sobel(img,cv2.CV_64F,0,1,ksize=3)  # Monta o kernel filtro  #kernel = np.array([[-1, -1, -1],  #                   [-1, 8, -1],  #                   [-1, -1, -1]]) # Realiza o produto de convolu\u00e7\u00e3o #imgf = cv2.filter2D(img,-1,kernel)  #exibe resultado filtrado plt.imshow(imgf, cmap=\"Greys_r\", vmin=0, vmax=255);plt.show() plt.imshow(imgf2, cmap=\"Greys_r\", vmin=0, vmax=255); plt.show() <pre>Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n</pre> <pre>Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n</pre> In\u00a0[10]: Copied! <pre>#implemente seu c\u00f3digo aqui.\n\n# Aqui, a ideia \u00e9 realizar um estudo para entender o efeito de diferentes filtros.\n# Vou aplicar o filtro Sobel e o filtro Laplaciano para diferentes tamanhos de kernel.\n# Vou exibir os resultados para cada tamanho de kernel.\n# Por essa raz\u00e3o, vou criar uma figura com subplots para exibir os resultados e varrer os diferentes tamanhos de kernel utilizando um loop for.\n\n# \u00c9 apenas uma sugest\u00e3o de abordagem, voc\u00ea pode implementar de outra forma se preferir.\n\n\nimport cv2\nimport numpy as np\nfrom matplotlib import pyplot as plt\n\n# Carrega a imagem\nimg = cv2.imread('lena.png', cv2.IMREAD_GRAYSCALE)\n\n# Define os tamanhos de kernel para experimenta\u00e7\u00e3o\nkernels = [3, 13, 21]\n\n# Cria uma figura com subplots\nfig, axs = plt.subplots(len(kernels), 2, figsize=(10, len(kernels) * 5))\n\n# Aplica e exibe os diferentes filtros para cada tamanho de kernel\nfor i, kernel_size in enumerate(kernels):\n    # Filtro Sobel\n    sobel_x = cv2.Sobel(img, cv2.CV_64F, 1, 0, ksize=kernel_size)\n    sobel_y = cv2.Sobel(img, cv2.CV_64F, 0, 1, ksize=kernel_size)\n    sobel = np.sqrt(sobel_x**2 + sobel_y**2) # Sugest\u00e3o, combinar as respostas dos filtros em x e y para obter o m\u00f3dulo do gradiente da imagem, que \u00e9 mais informativo que as respostas individuais dos filtros em x e y \n    axs[i, 0].imshow(sobel, cmap='gray')\n    axs[i, 0].set_title(f'Filtro Sobel - Kernel {kernel_size}x{kernel_size}')\n\n    # Filtro Laplaciano\n    laplacian = cv2.Laplacian(img, cv2.CV_64F, ksize=kernel_size)\n    axs[i, 1].imshow(laplacian, cmap='gray')\n    axs[i, 1].set_title(f'Filtro Laplaciano - Kernel {kernel_size}x{kernel_size}')\n\n# Ajusta o layout e exibe a figura\nplt.tight_layout()\nplt.show()\n</pre> #implemente seu c\u00f3digo aqui.  # Aqui, a ideia \u00e9 realizar um estudo para entender o efeito de diferentes filtros. # Vou aplicar o filtro Sobel e o filtro Laplaciano para diferentes tamanhos de kernel. # Vou exibir os resultados para cada tamanho de kernel. # Por essa raz\u00e3o, vou criar uma figura com subplots para exibir os resultados e varrer os diferentes tamanhos de kernel utilizando um loop for.  # \u00c9 apenas uma sugest\u00e3o de abordagem, voc\u00ea pode implementar de outra forma se preferir.   import cv2 import numpy as np from matplotlib import pyplot as plt  # Carrega a imagem img = cv2.imread('lena.png', cv2.IMREAD_GRAYSCALE)  # Define os tamanhos de kernel para experimenta\u00e7\u00e3o kernels = [3, 13, 21]  # Cria uma figura com subplots fig, axs = plt.subplots(len(kernels), 2, figsize=(10, len(kernels) * 5))  # Aplica e exibe os diferentes filtros para cada tamanho de kernel for i, kernel_size in enumerate(kernels):     # Filtro Sobel     sobel_x = cv2.Sobel(img, cv2.CV_64F, 1, 0, ksize=kernel_size)     sobel_y = cv2.Sobel(img, cv2.CV_64F, 0, 1, ksize=kernel_size)     sobel = np.sqrt(sobel_x**2 + sobel_y**2) # Sugest\u00e3o, combinar as respostas dos filtros em x e y para obter o m\u00f3dulo do gradiente da imagem, que \u00e9 mais informativo que as respostas individuais dos filtros em x e y      axs[i, 0].imshow(sobel, cmap='gray')     axs[i, 0].set_title(f'Filtro Sobel - Kernel {kernel_size}x{kernel_size}')      # Filtro Laplaciano     laplacian = cv2.Laplacian(img, cv2.CV_64F, ksize=kernel_size)     axs[i, 1].imshow(laplacian, cmap='gray')     axs[i, 1].set_title(f'Filtro Laplaciano - Kernel {kernel_size}x{kernel_size}')  # Ajusta o layout e exibe a figura plt.tight_layout() plt.show()  <p>FILTRO DE BORDAS DE CANNY</p> <p>O filtro de canny \u00e9 um detector de linhas e bordas que combina de forma mais sofisticada opera\u00e7\u00f5es lineares.</p> In\u00a0[\u00a0]: Copied! <pre>import numpy as np\nimport cv2\n\n\n#carrega imagem\nimg = cv2.imread('lena.png')\nplt.imshow(img, cmap=\"Greys_r\", vmin=0, vmax=255); plt.show()\n\nmin_contrast = 50\nmax_contrast = 200\n\nimgfb = cv2.GaussianBlur(img,(5,5),0)\nimgf = cv2.Canny(imgfb, min_contrast, max_contrast )\n\nplt.imshow(imgf,cmap=\"Greys_r\", vmin=0, vmax=255); plt.show()\n</pre> import numpy as np import cv2   #carrega imagem img = cv2.imread('lena.png') plt.imshow(img, cmap=\"Greys_r\", vmin=0, vmax=255); plt.show()  min_contrast = 50 max_contrast = 200  imgfb = cv2.GaussianBlur(img,(5,5),0) imgf = cv2.Canny(imgfb, min_contrast, max_contrast )  plt.imshow(imgf,cmap=\"Greys_r\", vmin=0, vmax=255); plt.show() In\u00a0[11]: Copied! <pre>#Seu c\u00f3digo\n\nimport cv2\nimport numpy as np\nfrom matplotlib import pyplot as plt\n\n# Carrega a imagem\nimg = cv2.imread('lena.png', cv2.IMREAD_GRAYSCALE)\n\n# Define os pares de valores de threshold para experimenta\u00e7\u00e3o no detector de bordas de Canny, \n# onde cada par \u00e9 um conjunto de valores para os thresholds m\u00ednimo e m\u00e1ximo\n# A ideia \u00e9 experimentar diferentes valores para os thresholds e observar o efeito no resultado\nthresholds = [(50, 100), (100, 150), (150, 200)]\n\n# Cria uma figura com subplots\nfig, axs = plt.subplots(1, len(thresholds), figsize=(15, 5))\n\n# Aplica e exibe o detector de bordas de Canny para cada par de thresholds\nfor i, (low_threshold, high_threshold) in enumerate(thresholds):\n    # Detector de bordas de Canny\n    edges = cv2.Canny(img, low_threshold, high_threshold)\n    axs[i].imshow(edges, cmap='gray')\n    axs[i].set_title(f'Canny - Thresholds: ({low_threshold}, {high_threshold})')\n\n# Ajusta o layout e exibe a figura\nplt.tight_layout()\nplt.show()\n</pre> #Seu c\u00f3digo  import cv2 import numpy as np from matplotlib import pyplot as plt  # Carrega a imagem img = cv2.imread('lena.png', cv2.IMREAD_GRAYSCALE)  # Define os pares de valores de threshold para experimenta\u00e7\u00e3o no detector de bordas de Canny,  # onde cada par \u00e9 um conjunto de valores para os thresholds m\u00ednimo e m\u00e1ximo # A ideia \u00e9 experimentar diferentes valores para os thresholds e observar o efeito no resultado thresholds = [(50, 100), (100, 150), (150, 200)]  # Cria uma figura com subplots fig, axs = plt.subplots(1, len(thresholds), figsize=(15, 5))  # Aplica e exibe o detector de bordas de Canny para cada par de thresholds for i, (low_threshold, high_threshold) in enumerate(thresholds):     # Detector de bordas de Canny     edges = cv2.Canny(img, low_threshold, high_threshold)     axs[i].imshow(edges, cmap='gray')     axs[i].set_title(f'Canny - Thresholds: ({low_threshold}, {high_threshold})')  # Ajusta o layout e exibe a figura plt.tight_layout() plt.show()  <p>FILTRO DE LIMIARIZA\u00c7\u00c3O</p> <p>O filtro de limiariaza\u00e7\u00e3o \u00e9 converte uma imagem em tons de ciza para uma imagem binaria.</p> <p>Podemos utilizar diversas tecnicas de limiariza\u00e7\u00e3o, cada um com sua particularidade, leia a documenta\u00e7\u00e3o para mais detalhes:</p> <p>cv2.THRESH_BINARY cv2.THRESH_BINARY_INV cv2.THRESH_TRUNC cv2.THRESH_TOZERO cv2.THRESH_TOZERO_INV cv2.THRESH_OTSU</p> In\u00a0[12]: Copied! <pre>import numpy as np\nimport cv2\n\n\n#carrega imagem\nimage = cv2.imread('lena.png')\nimg = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\nplt.imshow(img,cmap=\"Greys_r\", vmin=0, vmax=255); plt.show()\n\n\nret3,th3 = cv2.threshold(img,0,255,cv2.THRESH_OTSU)\n\nplt.imshow(th3,cmap=\"Greys_r\", vmin=0, vmax=255); plt.show()\n</pre> import numpy as np import cv2   #carrega imagem image = cv2.imread('lena.png') img = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY) plt.imshow(img,cmap=\"Greys_r\", vmin=0, vmax=255); plt.show()   ret3,th3 = cv2.threshold(img,0,255,cv2.THRESH_OTSU)  plt.imshow(th3,cmap=\"Greys_r\", vmin=0, vmax=255); plt.show()   <p>FILTRO DE SOBREPOSI\u00c7\u00c3O DE IMAGENS</p> <p>O filtro de sobreposi\u00e7\u00e3o mescla duas imagens gerando efeito de sobreposi\u00e7\u00e3o, ou Blending.</p> <p>A opera\u00e7\u00e3o da imagem de saida \u00e9 a seguinte: g(x)=(1\u2212\u03b1)\u2217f0(x)+\u03b1\u2217f1(x)</p> In\u00a0[\u00a0]: Copied! <pre>import numpy as np\nimport cv2\n\nalpha = 0.8\nbeta = (1.0 - alpha)\n\nsrc1 = cv2.imread(\"lena.png\")\nsrc2 = cv2.imread(\"tux.png\")\nsrc2= cv2.cvtColor(src2, cv2.COLOR_BGR2RGB )\n\nsrc2 = cv2.resize(src2, src1.shape[1::-1])\nprint(src1.shape, src2.shape)\n\n\ndst = cv2.addWeighted(src1, alpha, src2, beta, 0.0)\n\n\nplt.imshow(src1); plt.show()\nplt.imshow(src2); plt.show()\nplt.imshow(dst); plt.show()\n</pre> import numpy as np import cv2  alpha = 0.8 beta = (1.0 - alpha)  src1 = cv2.imread(\"lena.png\") src2 = cv2.imread(\"tux.png\") src2= cv2.cvtColor(src2, cv2.COLOR_BGR2RGB )  src2 = cv2.resize(src2, src1.shape[1::-1]) print(src1.shape, src2.shape)   dst = cv2.addWeighted(src1, alpha, src2, beta, 0.0)   plt.imshow(src1); plt.show() plt.imshow(src2); plt.show() plt.imshow(dst); plt.show() <pre>(512, 512, 3) (512, 512, 3)\n</pre> In\u00a0[13]: Copied! <pre>#Seu c\u00f3digo aqui.\n\n# No desafio 2 do lab, eu sugeri a aplica\u00e7\u00e3o do filtro de sobel com essa jun\u00e7\u00e3o de respostas para obter o m\u00f3dulo do gradiente da imagem.\n# Vou aplicar o filtro de sobel e exibir o resultado para a imagem lena.png.\n\nimport cv2\nimport numpy as np\nfrom matplotlib import pyplot as plt\n\n# Carrega a imagem\nimg = cv2.imread('lena.png', cv2.IMREAD_GRAYSCALE)\n\n# Filtro Sobel\nsobel_x = cv2.Sobel(img, cv2.CV_64F, 1, 0, ksize=3)\nsobel_y = cv2.Sobel(img, cv2.CV_64F, 0, 1, ksize=3)\nsobel = np.sqrt(sobel_x**2 + sobel_y**2)\n\n# Exibe o resultado\nplt.imshow(sobel, cmap='gray')\nplt.title('Filtro Sobel - M\u00f3dulo do Gradiente')\nplt.show()\n</pre> #Seu c\u00f3digo aqui.  # No desafio 2 do lab, eu sugeri a aplica\u00e7\u00e3o do filtro de sobel com essa jun\u00e7\u00e3o de respostas para obter o m\u00f3dulo do gradiente da imagem. # Vou aplicar o filtro de sobel e exibir o resultado para a imagem lena.png.  import cv2 import numpy as np from matplotlib import pyplot as plt  # Carrega a imagem img = cv2.imread('lena.png', cv2.IMREAD_GRAYSCALE)  # Filtro Sobel sobel_x = cv2.Sobel(img, cv2.CV_64F, 1, 0, ksize=3) sobel_y = cv2.Sobel(img, cv2.CV_64F, 0, 1, ksize=3) sobel = np.sqrt(sobel_x**2 + sobel_y**2)  # Exibe o resultado plt.imshow(sobel, cmap='gray') plt.title('Filtro Sobel - M\u00f3dulo do Gradiente') plt.show()"},{"location":"aulas/PDI/lab04/sol_Filtros_de_Convolu%C3%A7%C3%A3o.html#desafio-0","title":"Desafio 0\u00b6","text":"<p>Abra o link https://setosa.io/ev/image-kernels/ e de forma intuitiva altere o valor do filtro/kernel e descubra efeitos resultantes.</p>"},{"location":"aulas/PDI/lab04/sol_Filtros_de_Convolu%C3%A7%C3%A3o.html#implementacao-na-opencv","title":"Implementa\u00e7\u00e3o na OpenCV\u00b6","text":"<p>Podemos implementar o produto de convolu\u00e7\u00e3o montando uma estrutura com dois for para varrer a imagem toda, pixel-a-pixel.N\u00e3o \u00e9 a forma mais eficiente, pois Na OpenCV tem uma fun\u00e7\u00e3o built-in para implementa\u00e7\u00e3o de filtro de convolu\u00e7\u00e3o a cv2.filter2D()</p>"},{"location":"aulas/PDI/lab04/sol_Filtros_de_Convolu%C3%A7%C3%A3o.html#desafio-1","title":"Desafio 1\u00b6","text":"<p>Escolha uma imagem da sua prefer\u00eancia e fa\u00e7a um estudo sobre os diferentes tipos de filtros de borramento, analise tamb\u00e9m o que acontece quando \u00e9 alterado o tamanho do kernel.</p>"},{"location":"aulas/PDI/lab04/sol_Filtros_de_Convolu%C3%A7%C3%A3o.html#desafio-2","title":"Desafio 2\u00b6","text":"<p>Escolha uma imagem da sua prefer\u00eancia e fa\u00e7a um estudo sobre os diferentes tipos de filtros de contraste, analise tamb\u00e9m o que acontece quando \u00e9 alterado o tamanho do kernel.</p>"},{"location":"aulas/PDI/lab04/sol_Filtros_de_Convolu%C3%A7%C3%A3o.html#desafio-3","title":"Desafio 3\u00b6","text":"<p>O Filtro de Canny \u00e9 um dos mais utilizados at\u00e9 hoje, por ser robusto e apresentar bons resultados. Implemente o detector de bordas de canny e analise os efeitos alterandos os valores de threshold.</p>"},{"location":"aulas/PDI/lab04/sol_Filtros_de_Convolu%C3%A7%C3%A3o.html#desafio-4","title":"Desafio 4\u00b6","text":"<p>O filtro de sobel calcula a primeira derivada, isso pode ser feito na dire\u00e7\u00e3o de X ou em Y. Fa\u00e7a uma implementa\u00e7\u00e3o que junta os efeitos das duas derivadas de sobel</p>"},{"location":"aulas/PDI/lab04/webcam.html","title":"Webcam","text":"In\u00a0[\u00a0]: Copied! <p>Programa simples com camera webcam e opencv</p> In\u00a0[\u00a0]: Copied! <pre>import cv2\nimport os,sys, os.path\nimport numpy as np\n</pre> import cv2 import os,sys, os.path import numpy as np In\u00a0[\u00a0]: Copied! <pre>def image_da_webcam(img):\n    \"\"\"\n    -&gt;&gt;&gt; !!!! FECHE A JANELA COM A TECLA ESC !!!! &lt;&lt;&lt;&lt;-\n        deve receber a imagem da camera e retornar uma imagems filtrada.\n    \"\"\"\n    img = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n     # Detect edges in the image and threshold it\n    edges = cv2.Laplacian(img, cv2.CV_8U, ksize=5)\n    \n    ret, mask = cv2.threshold(edges, 100, 255, cv2.THRESH_BINARY_INV)\n\n    return mask\n</pre> def image_da_webcam(img):     \"\"\"     -&gt;&gt;&gt; !!!! FECHE A JANELA COM A TECLA ESC !!!! &lt;&lt;&lt;&lt;-         deve receber a imagem da camera e retornar uma imagems filtrada.     \"\"\"     img = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)      # Detect edges in the image and threshold it     edges = cv2.Laplacian(img, cv2.CV_8U, ksize=5)          ret, mask = cv2.threshold(edges, 100, 255, cv2.THRESH_BINARY_INV)      return mask In\u00a0[\u00a0]: Copied! <pre>vc = cv2.VideoCapture(0) ### significa que vou usar a minha webcam, 1,2,3\n</pre> vc = cv2.VideoCapture(0) ### significa que vou usar a minha webcam, 1,2,3 <p>vc = cv2.VideoCapture(\"people-walking.mp4\") ### suport video mp4. .avi  .mkv</p> <p>vc = cv2.VideoCapture(\"rtsp://192.168.52.25:800\") ### significa que vou usar a minha webcam, 1,2,3</p> In\u00a0[\u00a0]: Copied! <pre>if vc.isOpened(): # try to get the first frame\n    rval, frame = vc.read()\nelse:\n    rval = False\n</pre> if vc.isOpened(): # try to get the first frame     rval, frame = vc.read() else:     rval = False In\u00a0[\u00a0]: Copied! <pre>while rval:\n    \n    img = image_da_webcam(frame)\n\n    cv2.imshow(\"preview\", img)\n    cv2.imshow(\"original\", frame)\n\n    rval, frame = vc.read()\n    key = cv2.waitKey(20)\n    if key == 27: # exit on ESC\n        break\n</pre> while rval:          img = image_da_webcam(frame)      cv2.imshow(\"preview\", img)     cv2.imshow(\"original\", frame)      rval, frame = vc.read()     key = cv2.waitKey(20)     if key == 27: # exit on ESC         break In\u00a0[\u00a0]: Copied! <pre>cv2.destroyWindow(\"preview\")\nvc.release()\n</pre> cv2.destroyWindow(\"preview\") vc.release()"},{"location":"aulas/PDI/lab05/Espa%C3%A7o-cor-contorno.html","title":"Lab05 - Espa\u00e7o de cor e contorno","text":"<p>Objetivos da aula:</p> <ul> <li>Conhecer o espa\u00e7o de cor HSV</li> <li>Conhecer o processo de mascara</li> <li>conhecer o processo de detec\u00e7\u00e3o de contornos</li> <li>conhecer o processo de calculo do centro de massa</li> <li>conhecer o processo para desenar e escrever na imagem</li> </ul> In\u00a0[1]: Copied! <pre>## Vou fazer o download das imagens do laborat\u00f3rio diretamente do reposit\u00f3rio para ficar mais facil....\n\nimport requests\nimport os\n\n# Define o laborat\u00f3rio\nlaboratorio = 'lab05'  ### altere para o laborat\u00f3rio desejado\ndiretorio = 'lab_images'  ### altere para o diret\u00f3rio que deseja salvar as imagens\n\n# Download de um arquivo\ndef download_file(url, destination):\n    response = requests.get(url, stream=True)\n    if response.status_code == 200:\n        with open(destination, 'wb') as file:\n            for chunk in response.iter_content(chunk_size=8192):\n                file.write(chunk)\n        print(f\"Baixado: {destination}\")\n    else:\n        print(f\"Erro ao baixar {url}\")\n\n# Monta a URL completa\napi_url = \"https://api.github.com/repos/arnaldojr/cognitivecomputing/contents/material/aulas/PDI/\"\nurl_completa = api_url + laboratorio\nprint(f\"Fazendo o download de: {url_completa}\")\n\n# checa se a URL est\u00e1 acess\u00edvel\nresponse = requests.get(url_completa)\nif response.status_code != 200:\n    raise Exception(f\"Erro ao acessar o reposit\u00f3rio: {response.status_code}\")\nfiles = response.json()\n\n\n# Faz o download de cada arquivo\nos.makedirs(diretorio, exist_ok=True) # Cria a pasta downloads\nfor file in files:\n    file_name = file['name']\n    if file_name.endswith(('.png', '.jpg', '.jpeg', '.mp4')):  # Adicione mais extens\u00f5es se necess\u00e1rio\n        file_url = file['download_url']\n        destination = os.path.join(diretorio, file_name)\n        download_file(file_url, destination)\n\nprint(f\"Download conclu\u00eddo. Arquivos salvos na pasta {diretorio}.\")\n</pre> ## Vou fazer o download das imagens do laborat\u00f3rio diretamente do reposit\u00f3rio para ficar mais facil....  import requests import os  # Define o laborat\u00f3rio laboratorio = 'lab05'  ### altere para o laborat\u00f3rio desejado diretorio = 'lab_images'  ### altere para o diret\u00f3rio que deseja salvar as imagens  # Download de um arquivo def download_file(url, destination):     response = requests.get(url, stream=True)     if response.status_code == 200:         with open(destination, 'wb') as file:             for chunk in response.iter_content(chunk_size=8192):                 file.write(chunk)         print(f\"Baixado: {destination}\")     else:         print(f\"Erro ao baixar {url}\")  # Monta a URL completa api_url = \"https://api.github.com/repos/arnaldojr/cognitivecomputing/contents/material/aulas/PDI/\" url_completa = api_url + laboratorio print(f\"Fazendo o download de: {url_completa}\")  # checa se a URL est\u00e1 acess\u00edvel response = requests.get(url_completa) if response.status_code != 200:     raise Exception(f\"Erro ao acessar o reposit\u00f3rio: {response.status_code}\") files = response.json()   # Faz o download de cada arquivo os.makedirs(diretorio, exist_ok=True) # Cria a pasta downloads for file in files:     file_name = file['name']     if file_name.endswith(('.png', '.jpg', '.jpeg', '.mp4')):  # Adicione mais extens\u00f5es se necess\u00e1rio         file_url = file['download_url']         destination = os.path.join(diretorio, file_name)         download_file(file_url, destination)  print(f\"Download conclu\u00eddo. Arquivos salvos na pasta {diretorio}.\") <pre>Fazendo o download de: https://api.github.com/repos/arnaldojr/cognitivecomputing/contents/material/aulas/PDI/lab05\nBaixado: lab_images/HSV_colorspace.jpg\nBaixado: lab_images/bolinha.png\nBaixado: lab_images/convolution.png\nBaixado: lab_images/formas.png\nBaixado: lab_images/formas_contorno.png\nBaixado: lab_images/formas_contornor.png\nBaixado: lab_images/hsv_colorspace.png\nBaixado: lab_images/lena.png\nBaixado: lab_images/melancia.png\nBaixado: lab_images/melancia_filtrada.png\nBaixado: lab_images/melancia_filtrada_rgb.png\nBaixado: lab_images/saida.png\nBaixado: lab_images/segmenta_melancia.mp4\nBaixado: lab_images/sudoku.png\nBaixado: lab_images/tux.png\nDownload conclu\u00eddo. Arquivos salvos na pasta lab_images.\n</pre> In\u00a0[\u00a0]: Copied! <pre>%matplotlib inline\nimport cv2\nfrom matplotlib import pyplot as plt\nimport numpy as np\n\nimg = cv2.imread('hsv_colorspace.png')\nimg = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n\nplt.figure(figsize = (20,20))\nplt.imshow(img); plt.show()\n</pre> %matplotlib inline import cv2 from matplotlib import pyplot as plt import numpy as np  img = cv2.imread('hsv_colorspace.png') img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)  plt.figure(figsize = (20,20)) plt.imshow(img); plt.show() <p>A matiz descreve o pigmento de uma cor e \u00e9 medido em graus de 0 a 359 graus.</p> <p>A satura\u00e7\u00e3o descreve a vivacidade ou o esmaecimento de uma cor e \u00e9 medida em porcentagem de 0 a 100 (0 = cor \"diluida\" 100 = cor pura).</p> <p>O brilho determina a intensidade percebida (0 = preto 100 = brilho maximo);</p> <p>Dica: Pra entender bem o que \u00e9 cada componente, da uma olhada neste link ou digita no google \"colorpicker\"</p> <p>lembrete super importante!! a OpenCV trabalha com valores de 8bits (0-255), ou seja o valor da matriz tem que ser divido por 2</p> <p>Convers\u00e3o para HSV</p> <p>Na OpenCV a convers\u00e3o de BGR para RGB \u00e9 muito simples, podemos converter diretamete da imagem em BGR usando o cv2.COLOR_BGR2HSV.</p> In\u00a0[\u00a0]: Copied! <pre>img = cv2.imread('bolinha.png')\n\nimg_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\nimg_hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n\nplt.subplot(1, 2, 1)\nplt.imshow(img_rgb)\nplt.subplot(1, 2, 2)\nplt.imshow(img_hsv)\nplt.show()\n</pre> img = cv2.imread('bolinha.png')  img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB) img_hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)  plt.subplot(1, 2, 1) plt.imshow(img_rgb) plt.subplot(1, 2, 2) plt.imshow(img_hsv) plt.show() <p>mascara de cor</p> <p>Para realizar uma marcara de cor, nos usamos a fun\u00e7\u00e3o cv2.inrange para escolher o intervalo de cor ( o valor minimo e o valor maximo).</p> In\u00a0[\u00a0]: Copied! <pre>%matplotlib inline\nimport cv2\nfrom matplotlib import pyplot as plt\nimport numpy as np\n\nimg = cv2.imread('bolinha.png')\n\nimg_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\nimg_hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n\n\n# Defini\u00e7\u00e3o dos valores minimo e max da mascara\n# o magenta tem h=300 mais ou menos ou 150 para a OpenCV\nimage_lower_hsv = np.array([140, 100, 40])  \nimage_upper_hsv = np.array([175, 255, 255])\n\n\nmask_hsv = cv2.inRange(img_hsv, image_lower_hsv, image_upper_hsv)\n\n\n\nplt.subplot(1, 2, 1)\nplt.imshow(img_rgb)\nplt.subplot(1, 2, 2)\nplt.imshow(mask_hsv, cmap=\"Greys_r\", vmin=0, vmax=255)\nplt.show()\n</pre> %matplotlib inline import cv2 from matplotlib import pyplot as plt import numpy as np  img = cv2.imread('bolinha.png')  img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB) img_hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)   # Defini\u00e7\u00e3o dos valores minimo e max da mascara # o magenta tem h=300 mais ou menos ou 150 para a OpenCV image_lower_hsv = np.array([140, 100, 40])   image_upper_hsv = np.array([175, 255, 255])   mask_hsv = cv2.inRange(img_hsv, image_lower_hsv, image_upper_hsv)    plt.subplot(1, 2, 1) plt.imshow(img_rgb) plt.subplot(1, 2, 2) plt.imshow(mask_hsv, cmap=\"Greys_r\", vmin=0, vmax=255) plt.show()   In\u00a0[\u00a0]: Copied! <pre>%matplotlib inline\nimport cv2\nfrom matplotlib import pyplot as plt\nimport numpy as np\n\nimg = cv2.imread('melancia.png')\nimg_res = cv2.imread('melancia_filtrada.png')\n\nimg_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\nimg_res_rgb = cv2.cvtColor(img_res, cv2.COLOR_BGR2RGB)\n\nfig = plt.figure(figsize=(20,20))\nplt.subplot(1, 2, 1)\nplt.imshow(img_rgb)\nplt.subplot(1, 2, 2)\nplt.imshow(img_res_rgb)\nplt.show()\n</pre> %matplotlib inline import cv2 from matplotlib import pyplot as plt import numpy as np  img = cv2.imread('melancia.png') img_res = cv2.imread('melancia_filtrada.png')  img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB) img_res_rgb = cv2.cvtColor(img_res, cv2.COLOR_BGR2RGB)  fig = plt.figure(figsize=(20,20)) plt.subplot(1, 2, 1) plt.imshow(img_rgb) plt.subplot(1, 2, 2) plt.imshow(img_res_rgb) plt.show()  In\u00a0[\u00a0]: Copied! <pre>#Implemente seu c\u00f3digo\n</pre> #Implemente seu c\u00f3digo      In\u00a0[\u00a0]: Copied! <pre>%matplotlib inline\nimport cv2\nfrom matplotlib import pyplot as plt\nimport numpy as np\n\nimg = cv2.imread('melancia_filtrada.png')\nimg_res = cv2.imread('melancia_filtrada_rgb.png')\n\nimg_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\nimg_res_rgb = cv2.cvtColor(img_res, cv2.COLOR_BGR2RGB)\n\nfig = plt.figure(figsize=(20,20))\nplt.subplot(1, 2, 1)\nplt.imshow(img_rgb)\nplt.subplot(1, 2, 2)\nplt.imshow(img_res_rgb)\nplt.show()\n</pre> %matplotlib inline import cv2 from matplotlib import pyplot as plt import numpy as np  img = cv2.imread('melancia_filtrada.png') img_res = cv2.imread('melancia_filtrada_rgb.png')  img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB) img_res_rgb = cv2.cvtColor(img_res, cv2.COLOR_BGR2RGB)  fig = plt.figure(figsize=(20,20)) plt.subplot(1, 2, 1) plt.imshow(img_rgb) plt.subplot(1, 2, 2) plt.imshow(img_res_rgb) plt.show() In\u00a0[\u00a0]: Copied! <pre>#Implemente seu c\u00f3digo\n</pre> #Implemente seu c\u00f3digo      In\u00a0[\u00a0]: Copied! <pre>#recarregando o nosso exemplo...\n\n%matplotlib inline\nimport cv2\nfrom matplotlib import pyplot as plt\nimport numpy as np\n\nimg = cv2.imread('bolinha.png')\n\nimg_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\nimg_hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n\n\n# Defini\u00e7\u00e3o dos valores minimo e max da mascara\n# o magenta tem h=300 mais ou menos ou 150 para a OpenCV\nimage_lower_hsv = np.array([140, 50, 100])  \nimage_upper_hsv = np.array([170, 255, 255])\n\n\nmask_hsv = cv2.inRange(img_hsv, image_lower_hsv, image_upper_hsv)\n\n\n\nplt.subplot(1, 2, 1)\nplt.imshow(img_rgb)\nplt.subplot(1, 2, 2)\nplt.imshow(mask_hsv, cmap=\"Greys_r\", vmin=0, vmax=255)\nplt.show()\n</pre> #recarregando o nosso exemplo...  %matplotlib inline import cv2 from matplotlib import pyplot as plt import numpy as np  img = cv2.imread('bolinha.png')  img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB) img_hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)   # Defini\u00e7\u00e3o dos valores minimo e max da mascara # o magenta tem h=300 mais ou menos ou 150 para a OpenCV image_lower_hsv = np.array([140, 50, 100])   image_upper_hsv = np.array([170, 255, 255])   mask_hsv = cv2.inRange(img_hsv, image_lower_hsv, image_upper_hsv)    plt.subplot(1, 2, 1) plt.imshow(img_rgb) plt.subplot(1, 2, 2) plt.imshow(mask_hsv, cmap=\"Greys_r\", vmin=0, vmax=255) plt.show()  In\u00a0[\u00a0]: Copied! <pre># realizando o contorno da imagem\n\ncontornos, _ = cv2.findContours(mask_hsv, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE) \n</pre> # realizando o contorno da imagem  contornos, _ = cv2.findContours(mask_hsv, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)   In\u00a0[\u00a0]: Copied! <pre># para desenhar o contorno primeiro faz uma copia da imagem \n\nmask_rgb = cv2.cvtColor(mask_hsv, cv2.COLOR_GRAY2RGB) \ncontornos_img = mask_rgb.copy() # C\u00f3pia da m\u00e1scara para ser desenhada \"por cima\"\n\ncv2.drawContours(contornos_img, contornos, -1, [255, 0, 0], 5);\n\nplt.figure(figsize=(8,6))\nplt.imshow(contornos_img);\n</pre> # para desenhar o contorno primeiro faz uma copia da imagem   mask_rgb = cv2.cvtColor(mask_hsv, cv2.COLOR_GRAY2RGB)  contornos_img = mask_rgb.copy() # C\u00f3pia da m\u00e1scara para ser desenhada \"por cima\"  cv2.drawContours(contornos_img, contornos, -1, [255, 0, 0], 5);  plt.figure(figsize=(8,6)) plt.imshow(contornos_img); In\u00a0[\u00a0]: Copied! <pre># para desenhar o contorno primeiro faz uma copia da imagem \n\nmask_rgb = cv2.cvtColor(mask_hsv, cv2.COLOR_GRAY2RGB) \ncontornos_img = mask_rgb.copy() # C\u00f3pia da m\u00e1scara para ser desenhada \"por cima\"\n\ncv2.drawContours(img_rgb, contornos, -1, [0, 0, 255], 10);\n\nplt.figure(figsize=(8,6))\nplt.imshow(img_rgb);\n</pre> # para desenhar o contorno primeiro faz uma copia da imagem   mask_rgb = cv2.cvtColor(mask_hsv, cv2.COLOR_GRAY2RGB)  contornos_img = mask_rgb.copy() # C\u00f3pia da m\u00e1scara para ser desenhada \"por cima\"  cv2.drawContours(img_rgb, contornos, -1, [0, 0, 255], 10);  plt.figure(figsize=(8,6)) plt.imshow(img_rgb); <p>Note que a fun\u00e7\u00e3o findContours devolve uma lista com os contornos detectados.</p> In\u00a0[\u00a0]: Copied! <pre>print(\"Quantidade de contornos encontrado: \", len(contornos))\n</pre> print(\"Quantidade de contornos encontrado: \", len(contornos)) <pre>Quantidade de contornos encontrado:  1\n</pre> In\u00a0[\u00a0]: Copied! <pre>%matplotlib inline\nimport cv2\nfrom matplotlib import pyplot as plt\nimport numpy as np\n\nimg = cv2.imread('formas.png')\nimg_res = cv2.imread('formas_contorno.png')\n\nimg_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\nimg_res_rgb = cv2.cvtColor(img_res, cv2.COLOR_BGR2RGB)\n\n\n# Defini\u00e7\u00e3o dos valores minimo e max da mascara\n\nimage_lower_hsv = np.array([0, 1, 0])  \nimage_upper_hsv = np.array([180, 255, 255])\n\nfig = plt.figure(figsize=(20,20))\nplt.subplot(1, 2, 1)\nplt.imshow(img_rgb)\nplt.subplot(1, 2, 2)\nplt.imshow(img_res_rgb)\nplt.show()\n</pre>  %matplotlib inline import cv2 from matplotlib import pyplot as plt import numpy as np  img = cv2.imread('formas.png') img_res = cv2.imread('formas_contorno.png')  img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB) img_res_rgb = cv2.cvtColor(img_res, cv2.COLOR_BGR2RGB)   # Defini\u00e7\u00e3o dos valores minimo e max da mascara  image_lower_hsv = np.array([0, 1, 0])   image_upper_hsv = np.array([180, 255, 255])  fig = plt.figure(figsize=(20,20)) plt.subplot(1, 2, 1) plt.imshow(img_rgb) plt.subplot(1, 2, 2) plt.imshow(img_res_rgb) plt.show() In\u00a0[\u00a0]: Copied! <pre>#Implemente seu c\u00f3digo\n</pre> #Implemente seu c\u00f3digo     In\u00a0[\u00a0]: Copied! <pre>## Implemente seu c\u00f3digo\n</pre> ## Implemente seu c\u00f3digo     In\u00a0[\u00a0]: Copied! <pre>cv2.__version__\n</pre> cv2.__version__ Out[\u00a0]: <pre>'4.5.5'</pre> In\u00a0[\u00a0]: Copied! <pre>#recarregando o nosso exemplo...\n\n%matplotlib inline\nimport cv2\nfrom matplotlib import pyplot as plt\nimport numpy as np\n\nimg = cv2.imread('bolinha.png')\n\nimg_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\nimg_hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n\n\n# Defini\u00e7\u00e3o dos valores minimo e max da mascara\n# o magenta tem h=300 mais ou menos ou 150 para a OpenCV\nimage_lower_hsv = np.array([140, 50, 100])  \nimage_upper_hsv = np.array([170, 255, 255])\n\n\nmask_hsv = cv2.inRange(img_hsv, image_lower_hsv, image_upper_hsv)\n\ncontornos, _ = cv2.findContours(mask_hsv, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE) \n\nmask_rgb = cv2.cvtColor(mask_hsv, cv2.COLOR_GRAY2RGB) \ncontornos_img = mask_rgb.copy() # C\u00f3pia da m\u00e1scara para ser desenhada \"por cima\"\n\ncv2.drawContours(contornos_img, contornos, -1, [255, 0, 0], 5);\n\nplt.figure(figsize=(8,6))\nplt.imshow(contornos_img);\n</pre> #recarregando o nosso exemplo...  %matplotlib inline import cv2 from matplotlib import pyplot as plt import numpy as np  img = cv2.imread('bolinha.png')  img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB) img_hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)   # Defini\u00e7\u00e3o dos valores minimo e max da mascara # o magenta tem h=300 mais ou menos ou 150 para a OpenCV image_lower_hsv = np.array([140, 50, 100])   image_upper_hsv = np.array([170, 255, 255])   mask_hsv = cv2.inRange(img_hsv, image_lower_hsv, image_upper_hsv)  contornos, _ = cv2.findContours(mask_hsv, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)   mask_rgb = cv2.cvtColor(mask_hsv, cv2.COLOR_GRAY2RGB)  contornos_img = mask_rgb.copy() # C\u00f3pia da m\u00e1scara para ser desenhada \"por cima\"  cv2.drawContours(contornos_img, contornos, -1, [255, 0, 0], 5);  plt.figure(figsize=(8,6)) plt.imshow(contornos_img); In\u00a0[\u00a0]: Copied! <pre># usando o exemplo da documenta\u00e7\u00e3o https://docs.opencv.org/master/dd/d49/tutorial_py_contour_features.html\n# notamos que a fun\u00e7\u00e3o devolve um dicionario. \n\ncnt = contornos[0]\n\nM = cv2.moments(cnt)\nprint( M )\n</pre> # usando o exemplo da documenta\u00e7\u00e3o https://docs.opencv.org/master/dd/d49/tutorial_py_contour_features.html # notamos que a fun\u00e7\u00e3o devolve um dicionario.   cnt = contornos[0]  M = cv2.moments(cnt) print( M ) <pre>{'m00': 20954.5, 'm10': 8414785.5, 'm01': 4813317.5, 'm20': 3414210172.083333, 'm11': 1932427931.625, 'm02': 1140509199.0833333, 'm30': 1399201096317.6501, 'm21': 783868070420.7833, 'm12': 457787216119.7167, 'm03': 278003040454.85004, 'mu20': 35049847.99971104, 'mu11': -475946.1051416397, 'mu02': 34874354.26211333, 'mu30': -7672941.9208984375, 'mu21': -4968840.380795479, 'mu12': 6858123.621509552, 'mu03': 2822544.575317383, 'nu20': 0.07982364109512664, 'nu11': -0.0010839348312655414, 'nu02': 0.07942396606302501, 'nu30': -0.00012071706132489804, 'nu21': -7.817390189392743e-05, 'nu12': 0.00010789766667418762, 'nu03': 4.4406603113053444e-05}\n</pre> In\u00a0[\u00a0]: Copied! <pre># Calculo das coordenadas do centro de massa\n\ncx = int(M['m10']/M['m00'])\ncy = int(M['m01']/M['m00'])\n\nprint(\"centro de massa na possi\u00e7\u00e3o: \",cx, cy)\n</pre> # Calculo das coordenadas do centro de massa  cx = int(M['m10']/M['m00']) cy = int(M['m01']/M['m00'])  print(\"centro de massa na possi\u00e7\u00e3o: \",cx, cy) <pre>centro de massa na possi\u00e7\u00e3o:  401 229\n</pre> <p>Vamos plotar isso na imagem para saber se esta correto. A fun\u00e7\u00e3o \"cv2.line\" vai nos ajudar a desenhar uma cruz. e fun\u00e7\u00e3o \"cv2.putText\" a escrever na imagem as coordenadas.</p> In\u00a0[\u00a0]: Copied! <pre>## para desenhar a cruz vamos passar a cor e o tamanho em pixel\nsize = 20\ncolor = (128,128,0)\n\n\ncv2.line(contornos_img,(cx - size,cy),(cx + size,cy),color,5)\ncv2.line(contornos_img,(cx,cy - size),(cx, cy + size),color,5)\n\n# Para escrever vamos definir uma fonte \n\nfont = cv2.FONT_HERSHEY_SIMPLEX\ntext = cy , cx\norigem = (0,50)\n\ncv2.putText(contornos_img, str(text), origem, font,1,(200,50,0),2,cv2.LINE_AA)\n\n\nplt.imshow(contornos_img);\n</pre> ## para desenhar a cruz vamos passar a cor e o tamanho em pixel size = 20 color = (128,128,0)   cv2.line(contornos_img,(cx - size,cy),(cx + size,cy),color,5) cv2.line(contornos_img,(cx,cy - size),(cx, cy + size),color,5)  # Para escrever vamos definir uma fonte   font = cv2.FONT_HERSHEY_SIMPLEX text = cy , cx origem = (0,50)  cv2.putText(contornos_img, str(text), origem, font,1,(200,50,0),2,cv2.LINE_AA)   plt.imshow(contornos_img); In\u00a0[\u00a0]: Copied! <pre>#### seu c\u00f3digo aqui...\n</pre> #### seu c\u00f3digo aqui... In\u00a0[\u00a0]: Copied! <pre>\n</pre>"},{"location":"aulas/PDI/lab05/Espa%C3%A7o-cor-contorno.html#espaco-de-cor-hsv","title":"Espa\u00e7o de cor HSV\u00b6","text":"<p>At\u00e9 o momento trabalhamos com imagens em escala de cinza, BGR, RGB e binaria. Agora vamos conhecer e trabalhar com HSV ou HSB.</p> <pre><code>H - hue (matriz)\nS - saturation (satura\u00e7\u00e3o)\nV - value (Value) ou B - brightness (brilho)</code></pre> <p>Utilizar esse espa\u00e7o possui algumas vantagens vamos ver no exemplo abaixo.</p>"},{"location":"aulas/PDI/lab05/Espa%C3%A7o-cor-contorno.html#desafio-1","title":"DESAFIO 1\u00b6","text":"<p>Fa\u00e7a a segmenta\u00e7\u00e3o da meia lua da imagem \"melancia.png\". O seu resultado deve ser proximo/parecido com a imagem \"melancia_filtrada.png\".</p> <p>Dica: talvez voc\u00ea precise usar mais que uma faixa de valores, se necess\u00e1rio use a fun\u00e7\u00e3o \"cv2.bitwise_or\" para juntar as partes.</p>"},{"location":"aulas/PDI/lab05/Espa%C3%A7o-cor-contorno.html#desafio-2","title":"DESAFIO 2\u00b6","text":"<p>Usando a imagem \"melancia_filtrada.png\", devolva a cor original que era antes da filtragem.</p> <p>Dica: Use as fun\u00e7\u00f5es de \"cv2.bitwise_and\" para juntar.</p>"},{"location":"aulas/PDI/lab05/Espa%C3%A7o-cor-contorno.html#deteccao-de-contornos","title":"DETEC\u00c7\u00c3O DE CONTORNOS\u00b6","text":"<p>Para realizar a detec\u00e7\u00e3o dos contornos, ou bordas de um objeto, usamos a fun\u00e7\u00e3o cv2.findontours</p>"},{"location":"aulas/PDI/lab05/Espa%C3%A7o-cor-contorno.html#desafio-3","title":"DESAFIO 3\u00b6","text":"<p>Usando a imagem \"formas.png\", fa\u00e7a um c\u00f3digo que detecta todos os contornos da imagem. O resultado deve ser parecido com \"formas_contorno.png\"</p> <p>Dica: Neste desafio, basicamente tem que ajustar a a mascara, o resto n\u00e3o muda.</p>"},{"location":"aulas/PDI/lab05/Espa%C3%A7o-cor-contorno.html#desafio-4","title":"DESAFIO 4\u00b6","text":"<p>Altere o seu codigo para desenhar o contorno de maior area da imagem. Use a fun\u00e7\u00e3o \"cv2.contourArea()\".</p> <p>Refer\u00eancia da documenta\u00e7\u00e3o: https://docs.opencv.org/master/dd/d49/tutorial_py_contour_features.html</p> <p>Dica: Use um for para varrer a lista e armazene o indice do maior valor e passe esse valor para desenhar o contorno.</p>"},{"location":"aulas/PDI/lab05/Espa%C3%A7o-cor-contorno.html#centro-de-massa-de-um-objeto","title":"CENTRO DE MASSA DE UM OBJETO\u00b6","text":"<p>O calculo para o centro de massa \u00e9 feito atr\u00e1ves da fun\u00e7\u00e3o cv2.findontours</p>"},{"location":"aulas/PDI/lab05/Espa%C3%A7o-cor-contorno.html#desafio-5","title":"DESAFIO 5\u00b6","text":"<p>O desafio \u00e9 juntar o que aprendemos em um video, use como base \"webcam.py\". Voc\u00ea deve seguimentar a cor de um objeto, encontrar seu contorno e montar a imagem segmentada com o centro de massa e suas coordenadas. Video de refer\u00eancia \"segmenta_melancia.mp4\"</p>"},{"location":"aulas/PDI/lab05/sol_Espa%C3%A7o-cor-contorno.html","title":"sol Espa\u00e7o cor contorno","text":"<p>Objetivos da aula:</p> <ul> <li>Conhecer o espa\u00e7o de cor HSV</li> <li>Conhecer o processo de mascara</li> <li>conhecer o processo de detec\u00e7\u00e3o de contornos</li> <li>conhecer o processo de calculo do centro de massa</li> <li>conhecer o processo para desenar e escrever na imagem</li> </ul> In\u00a0[\u00a0]: Copied! <pre>!wget https://raw.githubusercontent.com/arnaldojr/cognitivecomputing/master/material/aulas/PDI/lab05/HSV_colorspace.jpg /content \n!wget https://raw.githubusercontent.com/arnaldojr/cognitivecomputing/master/material/aulas/PDI/lab05/bolinha.png /content\n!wget https://raw.githubusercontent.com/arnaldojr/cognitivecomputing/master/material/aulas/PDI/lab05/convolution.png /content\n!wget https://raw.githubusercontent.com/arnaldojr/cognitivecomputing/master/material/aulas/PDI/lab05/formas.png /content\n!wget https://raw.githubusercontent.com/arnaldojr/cognitivecomputing/master/material/aulas/PDI/lab05/formas_contorno.png /content\n!wget https://raw.githubusercontent.com/arnaldojr/cognitivecomputing/master/material/aulas/PDI/lab05/formas_contornor.png /content\n!wget https://raw.githubusercontent.com/arnaldojr/cognitivecomputing/master/material/aulas/PDI/lab05/lena.png /content\n!wget https://raw.githubusercontent.com/arnaldojr/cognitivecomputing/master/material/aulas/PDI/lab05/melancia.png /content\n!wget https://raw.githubusercontent.com/arnaldojr/cognitivecomputing/master/material/aulas/PDI/lab05/melancia_filtrada.png /content\n!wget https://raw.githubusercontent.com/arnaldojr/cognitivecomputing/master/material/aulas/PDI/lab05/HSV_colorspace.jpg /content\n!wget https://raw.githubusercontent.com/arnaldojr/cognitivecomputing/master/material/aulas/PDI/lab05/melancia_filtrada_rgb.png /content\n!wget https://raw.githubusercontent.com/arnaldojr/cognitivecomputing/master/material/aulas/PDI/lab05/same_padding_no_strides.gif /content\n!wget https://raw.githubusercontent.com/arnaldojr/cognitivecomputing/master/material/aulas/PDI/lab05/sudoku.png /content\n!wget https://raw.githubusercontent.com/arnaldojr/cognitivecomputing/master/material/aulas/PDI/lab05/tux.png /content\n</pre> !wget https://raw.githubusercontent.com/arnaldojr/cognitivecomputing/master/material/aulas/PDI/lab05/HSV_colorspace.jpg /content  !wget https://raw.githubusercontent.com/arnaldojr/cognitivecomputing/master/material/aulas/PDI/lab05/bolinha.png /content !wget https://raw.githubusercontent.com/arnaldojr/cognitivecomputing/master/material/aulas/PDI/lab05/convolution.png /content !wget https://raw.githubusercontent.com/arnaldojr/cognitivecomputing/master/material/aulas/PDI/lab05/formas.png /content !wget https://raw.githubusercontent.com/arnaldojr/cognitivecomputing/master/material/aulas/PDI/lab05/formas_contorno.png /content !wget https://raw.githubusercontent.com/arnaldojr/cognitivecomputing/master/material/aulas/PDI/lab05/formas_contornor.png /content !wget https://raw.githubusercontent.com/arnaldojr/cognitivecomputing/master/material/aulas/PDI/lab05/lena.png /content !wget https://raw.githubusercontent.com/arnaldojr/cognitivecomputing/master/material/aulas/PDI/lab05/melancia.png /content !wget https://raw.githubusercontent.com/arnaldojr/cognitivecomputing/master/material/aulas/PDI/lab05/melancia_filtrada.png /content !wget https://raw.githubusercontent.com/arnaldojr/cognitivecomputing/master/material/aulas/PDI/lab05/HSV_colorspace.jpg /content !wget https://raw.githubusercontent.com/arnaldojr/cognitivecomputing/master/material/aulas/PDI/lab05/melancia_filtrada_rgb.png /content !wget https://raw.githubusercontent.com/arnaldojr/cognitivecomputing/master/material/aulas/PDI/lab05/same_padding_no_strides.gif /content !wget https://raw.githubusercontent.com/arnaldojr/cognitivecomputing/master/material/aulas/PDI/lab05/sudoku.png /content !wget https://raw.githubusercontent.com/arnaldojr/cognitivecomputing/master/material/aulas/PDI/lab05/tux.png /content In\u00a0[1]: Copied! <pre>%matplotlib inline\nimport cv2\nfrom matplotlib import pyplot as plt\nimport numpy as np\n\nimg = cv2.imread('hsv_colorspace.png')\nimg = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n\nplt.figure(figsize = (20,20))\nplt.imshow(img); plt.show()\n</pre> %matplotlib inline import cv2 from matplotlib import pyplot as plt import numpy as np  img = cv2.imread('hsv_colorspace.png') img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)  plt.figure(figsize = (20,20)) plt.imshow(img); plt.show() <p>A matiz descreve o pigmento de uma cor e \u00e9 medido em graus de 0 a 359 graus.</p> <p>A satura\u00e7\u00e3o descreve a vivacidade ou o esmaecimento de uma cor e \u00e9 medida em porcentagem de 0 a 100 (0 = cor \"diluida\" 100 = cor pura).</p> <p>O brilho determina a intensidade percebida (0 = preto 100 = brilho maximo);</p> <p>Dica: Pra entender bem o que \u00e9 cada componente, da uma olhada neste link ou digita no google \"colorpicker\"</p> <p>lembrete super importante!! a OpenCV trabalha com valores de 8bits (0-255), ou seja o valor da matriz tem que ser divido por 2</p> <p>Convers\u00e3o para HSV</p> <p>Na OpenCV a convers\u00e3o de BGR para RGB \u00e9 muito simples, podemos converter diretamete da imagem em BGR usando o cv2.COLOR_BGR2HSV.</p> In\u00a0[\u00a0]: Copied! <pre>img = cv2.imread('bolinha.png')\n\nimg_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\nimg_hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n\nplt.subplot(1, 2, 1)\nplt.imshow(img_rgb)\nplt.subplot(1, 2, 2)\nplt.imshow(img_hsv)\nplt.show()\n</pre> img = cv2.imread('bolinha.png')  img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB) img_hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)  plt.subplot(1, 2, 1) plt.imshow(img_rgb) plt.subplot(1, 2, 2) plt.imshow(img_hsv) plt.show() <p>mascara de cor</p> <p>Para realizar uma marcara de cor, nos usamos a fun\u00e7\u00e3o cv2.inrange para escolher o intervalo de cor ( o valor minimo e o valor maximo).</p> In\u00a0[\u00a0]: Copied! <pre>%matplotlib inline\nimport cv2\nfrom matplotlib import pyplot as plt\nimport numpy as np\n\nimg = cv2.imread('bolinha.png')\n\nimg_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\nimg_hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n\n\n# Defini\u00e7\u00e3o dos valores minimo e max da mascara\n# o magenta tem h=300 mais ou menos ou 150 para a OpenCV\nimage_lower_hsv = np.array([140, 100, 40])  \nimage_upper_hsv = np.array([175, 255, 255])\n\n\nmask_hsv = cv2.inRange(img_hsv, image_lower_hsv, image_upper_hsv)\n\n\n\nplt.subplot(1, 2, 1)\nplt.imshow(img_rgb)\nplt.subplot(1, 2, 2)\nplt.imshow(mask_hsv, cmap=\"Greys_r\", vmin=0, vmax=255)\nplt.show()\n</pre> %matplotlib inline import cv2 from matplotlib import pyplot as plt import numpy as np  img = cv2.imread('bolinha.png')  img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB) img_hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)   # Defini\u00e7\u00e3o dos valores minimo e max da mascara # o magenta tem h=300 mais ou menos ou 150 para a OpenCV image_lower_hsv = np.array([140, 100, 40])   image_upper_hsv = np.array([175, 255, 255])   mask_hsv = cv2.inRange(img_hsv, image_lower_hsv, image_upper_hsv)    plt.subplot(1, 2, 1) plt.imshow(img_rgb) plt.subplot(1, 2, 2) plt.imshow(mask_hsv, cmap=\"Greys_r\", vmin=0, vmax=255) plt.show()   In\u00a0[\u00a0]: Copied! <pre>%matplotlib inline\nimport cv2\nfrom matplotlib import pyplot as plt\nimport numpy as np\n\nimg = cv2.imread('melancia.png')\nimg_res = cv2.imread('melancia_filtrada.png')\n\nimg_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\nimg_res_rgb = cv2.cvtColor(img_res, cv2.COLOR_BGR2RGB)\n\nfig = plt.figure(figsize=(20,20))\nplt.subplot(1, 2, 1)\nplt.imshow(img_rgb)\nplt.subplot(1, 2, 2)\nplt.imshow(img_res_rgb)\nplt.show()\n</pre> %matplotlib inline import cv2 from matplotlib import pyplot as plt import numpy as np  img = cv2.imread('melancia.png') img_res = cv2.imread('melancia_filtrada.png')  img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB) img_res_rgb = cv2.cvtColor(img_res, cv2.COLOR_BGR2RGB)  fig = plt.figure(figsize=(20,20)) plt.subplot(1, 2, 1) plt.imshow(img_rgb) plt.subplot(1, 2, 2) plt.imshow(img_res_rgb) plt.show()  In\u00a0[23]: Copied! <pre>#Implemente seu c\u00f3digo\n\n%matplotlib inline\nimport cv2\nfrom matplotlib import pyplot as plt\nimport numpy as np\n\nimg = cv2.imread('melancia.png')\n\nimg_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\nimg_hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n\nprint(img_hsv.shape)\nprint(img_hsv[220,700])\n\n# Defini\u00e7\u00e3o dos valores minimo e max da mascara para a melancia\n# use o color picker para pegar os valores aproximados de h, s e v para a melancia \nmelancia_lower1 = np.array([175, 120, 150])  \nmelancia_upper1 = np.array([180, 255, 255])\n\nmelancia_lower2 = np.array([0, 140, 160])  \nmelancia_upper2 = np.array([15, 255, 255])\n\n# Cria as m\u00e1scaras para as faixas de vermelho\nmask_1 = cv2.inRange(img_hsv, melancia_lower1, melancia_upper1)\nmask_2 = cv2.inRange(img_hsv, melancia_lower2, melancia_upper2)\n\n# Combina as duas m\u00e1scaras com uma opera\u00e7\u00e3o bitwise_or\nmask_melancia = cv2.bitwise_or(mask_1, mask_2)\n\n\nplt.subplot(2, 2, 1)\nplt.imshow(img_rgb)\nplt.subplot(2, 2, 2)\nplt.imshow(mask_melancia, cmap=\"Greys_r\")\nplt.subplot(2, 2, 3)\nplt.imshow(mask_1, cmap=\"Greys_r\")\nplt.subplot(2, 2, 4)\nplt.imshow(mask_2, cmap=\"Greys_r\")\nplt.show()\n\n# Com um pouco mais de trabalho, podemos melhorar um pouco mais a m\u00e1scara\n# mas ja est\u00e1 bom para o que precisamos, e \u00e9 um bom exemplo de como podemos\n# manipular as m\u00e1scaras para obter o resultado desejado\n</pre> #Implemente seu c\u00f3digo  %matplotlib inline import cv2 from matplotlib import pyplot as plt import numpy as np  img = cv2.imread('melancia.png')  img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB) img_hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)  print(img_hsv.shape) print(img_hsv[220,700])  # Defini\u00e7\u00e3o dos valores minimo e max da mascara para a melancia # use o color picker para pegar os valores aproximados de h, s e v para a melancia  melancia_lower1 = np.array([175, 120, 150])   melancia_upper1 = np.array([180, 255, 255])  melancia_lower2 = np.array([0, 140, 160])   melancia_upper2 = np.array([15, 255, 255])  # Cria as m\u00e1scaras para as faixas de vermelho mask_1 = cv2.inRange(img_hsv, melancia_lower1, melancia_upper1) mask_2 = cv2.inRange(img_hsv, melancia_lower2, melancia_upper2)  # Combina as duas m\u00e1scaras com uma opera\u00e7\u00e3o bitwise_or mask_melancia = cv2.bitwise_or(mask_1, mask_2)   plt.subplot(2, 2, 1) plt.imshow(img_rgb) plt.subplot(2, 2, 2) plt.imshow(mask_melancia, cmap=\"Greys_r\") plt.subplot(2, 2, 3) plt.imshow(mask_1, cmap=\"Greys_r\") plt.subplot(2, 2, 4) plt.imshow(mask_2, cmap=\"Greys_r\") plt.show()  # Com um pouco mais de trabalho, podemos melhorar um pouco mais a m\u00e1scara # mas ja est\u00e1 bom para o que precisamos, e \u00e9 um bom exemplo de como podemos # manipular as m\u00e1scaras para obter o resultado desejado  <pre>(723, 1280, 3)\n[179 172 231]\n</pre> In\u00a0[24]: Copied! <pre>%matplotlib inline\nimport cv2\nfrom matplotlib import pyplot as plt\nimport numpy as np\n\nimg = cv2.imread('melancia_filtrada.png')\nimg_res = cv2.imread('melancia_filtrada_rgb.png')\n\nimg_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\nimg_res_rgb = cv2.cvtColor(img_res, cv2.COLOR_BGR2RGB)\n\nfig = plt.figure(figsize=(20,20))\nplt.subplot(1, 2, 1)\nplt.imshow(img_rgb)\nplt.subplot(1, 2, 2)\nplt.imshow(img_res_rgb)\nplt.show()\n</pre> %matplotlib inline import cv2 from matplotlib import pyplot as plt import numpy as np  img = cv2.imread('melancia_filtrada.png') img_res = cv2.imread('melancia_filtrada_rgb.png')  img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB) img_res_rgb = cv2.cvtColor(img_res, cv2.COLOR_BGR2RGB)  fig = plt.figure(figsize=(20,20)) plt.subplot(1, 2, 1) plt.imshow(img_rgb) plt.subplot(1, 2, 2) plt.imshow(img_res_rgb) plt.show() In\u00a0[25]: Copied! <pre>#Implemente seu c\u00f3digo\n\n\n# Aplica a m\u00e1scara combinada \u00e0 imagem original\nimg_red = cv2.bitwise_and(img_rgb, img_rgb, mask=mask_melancia)\n\n# Mostra a imagem\nplt.imshow(img_red)\nplt.show()\n\ncontornos, _ = cv2.findContours(mask_melancia, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE) \nprint(len(contornos))\n</pre> #Implemente seu c\u00f3digo   # Aplica a m\u00e1scara combinada \u00e0 imagem original img_red = cv2.bitwise_and(img_rgb, img_rgb, mask=mask_melancia)  # Mostra a imagem plt.imshow(img_red) plt.show()  contornos, _ = cv2.findContours(mask_melancia, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)  print(len(contornos))  <pre>159\n</pre> In\u00a0[26]: Copied! <pre>#recarregando o nosso exemplo...\n\n%matplotlib inline\nimport cv2\nfrom matplotlib import pyplot as plt\nimport numpy as np\n\nimg = cv2.imread('bolinha.png')\n\nimg_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\nimg_hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n\n\n# Defini\u00e7\u00e3o dos valores minimo e max da mascara\n# o magenta tem h=300 mais ou menos ou 150 para a OpenCV\nimage_lower_hsv = np.array([110, 50, 100])  \nimage_upper_hsv = np.array([170, 255, 255])\n\n\nmask_hsv = cv2.inRange(img_hsv, image_lower_hsv, image_upper_hsv)\n\n\n\nplt.subplot(1, 2, 1)\nplt.imshow(img_rgb)\nplt.subplot(1, 2, 2)\nplt.imshow(mask_hsv, cmap=\"Greys_r\", vmin=0, vmax=255)\nplt.show()\n</pre> #recarregando o nosso exemplo...  %matplotlib inline import cv2 from matplotlib import pyplot as plt import numpy as np  img = cv2.imread('bolinha.png')  img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB) img_hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)   # Defini\u00e7\u00e3o dos valores minimo e max da mascara # o magenta tem h=300 mais ou menos ou 150 para a OpenCV image_lower_hsv = np.array([110, 50, 100])   image_upper_hsv = np.array([170, 255, 255])   mask_hsv = cv2.inRange(img_hsv, image_lower_hsv, image_upper_hsv)    plt.subplot(1, 2, 1) plt.imshow(img_rgb) plt.subplot(1, 2, 2) plt.imshow(mask_hsv, cmap=\"Greys_r\", vmin=0, vmax=255) plt.show()   In\u00a0[29]: Copied! <pre># realizando o contorno da imagem\n\ncontornos, _ = cv2.findContours(mask_hsv, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE) \nprint(len(contornos))\n</pre> # realizando o contorno da imagem  contornos, _ = cv2.findContours(mask_hsv, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)  print(len(contornos))  <pre>1\n</pre> In\u00a0[30]: Copied! <pre># para desenhar o contorno primeiro faz uma copia da imagem \n\nmask_rgb = cv2.cvtColor(mask_hsv, cv2.COLOR_GRAY2RGB) \ncontornos_img = mask_rgb.copy() # C\u00f3pia da m\u00e1scara para ser desenhada \"por cima\"\n\ncv2.drawContours(contornos_img, contornos, -1, [255, 0, 0], 5);\n\nplt.figure(figsize=(8,6))\nplt.imshow(contornos_img);\n</pre> # para desenhar o contorno primeiro faz uma copia da imagem   mask_rgb = cv2.cvtColor(mask_hsv, cv2.COLOR_GRAY2RGB)  contornos_img = mask_rgb.copy() # C\u00f3pia da m\u00e1scara para ser desenhada \"por cima\"  cv2.drawContours(contornos_img, contornos, -1, [255, 0, 0], 5);  plt.figure(figsize=(8,6)) plt.imshow(contornos_img); In\u00a0[31]: Copied! <pre># para desenhar o contorno primeiro faz uma copia da imagem \n\nmask_rgb = cv2.cvtColor(mask_hsv, cv2.COLOR_GRAY2RGB) \ncontornos_img = mask_rgb.copy() # C\u00f3pia da m\u00e1scara para ser desenhada \"por cima\"\n\ncv2.drawContours(img_rgb, contornos, -1, [0, 0, 255], 10);\n\nplt.figure(figsize=(8,6))\nplt.imshow(img_rgb);\n</pre> # para desenhar o contorno primeiro faz uma copia da imagem   mask_rgb = cv2.cvtColor(mask_hsv, cv2.COLOR_GRAY2RGB)  contornos_img = mask_rgb.copy() # C\u00f3pia da m\u00e1scara para ser desenhada \"por cima\"  cv2.drawContours(img_rgb, contornos, -1, [0, 0, 255], 10);  plt.figure(figsize=(8,6)) plt.imshow(img_rgb); <p>Note que a fun\u00e7\u00e3o findContours devolve uma lista com os contornos detectados.</p> In\u00a0[32]: Copied! <pre>print(\"Quantidade de contornos encontrado: \", len(contornos))\n</pre> print(\"Quantidade de contornos encontrado: \", len(contornos)) <pre>Quantidade de contornos encontrado:  1\n</pre> In\u00a0[\u00a0]: Copied! <pre>%matplotlib inline\nimport cv2\nfrom matplotlib import pyplot as plt\nimport numpy as np\n\nimg = cv2.imread('formas.png')\nimg_res = cv2.imread('formas_contorno.png')\n\nimg_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\nimg_res_rgb = cv2.cvtColor(img_res, cv2.COLOR_BGR2RGB)\n\n\n# Defini\u00e7\u00e3o dos valores minimo e max da mascara\n\nimage_lower_hsv = np.array([0, 1, 0])  \nimage_upper_hsv = np.array([180, 255, 255])\n\nfig = plt.figure(figsize=(20,20))\nplt.subplot(1, 2, 1)\nplt.imshow(img_rgb)\nplt.subplot(1, 2, 2)\nplt.imshow(img_res_rgb)\nplt.show()\n</pre>  %matplotlib inline import cv2 from matplotlib import pyplot as plt import numpy as np  img = cv2.imread('formas.png') img_res = cv2.imread('formas_contorno.png')  img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB) img_res_rgb = cv2.cvtColor(img_res, cv2.COLOR_BGR2RGB)   # Defini\u00e7\u00e3o dos valores minimo e max da mascara  image_lower_hsv = np.array([0, 1, 0])   image_upper_hsv = np.array([180, 255, 255])  fig = plt.figure(figsize=(20,20)) plt.subplot(1, 2, 1) plt.imshow(img_rgb) plt.subplot(1, 2, 2) plt.imshow(img_res_rgb) plt.show() In\u00a0[50]: Copied! <pre>#Implemente seu c\u00f3digo\n\n# para desenhar o contorno podemos fazer uma imagem em escala de cinza e depois desenhar o contorno\n# ou podemos usar a imagem original e desenhar o contorno por cima\n\n\nimport cv2\nfrom matplotlib import pyplot as plt\n\nimg = cv2.imread('formas.png')\nimg_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\nimg_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\nimg_hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n\n# Define as faixas de cor para o vermelho no espa\u00e7o HSV\nlower_hsv = np.array([0, 1, 1])\nupper_hsv = np.array([180, 255, 255])\n\n# Cria as m\u00e1scaras\nedges = cv2.inRange(img_hsv, lower_hsv, upper_hsv)\n\n# Encontra os contornos na imagem\ncontours, _ = cv2.findContours(edges, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n\n# Desenha os contornos na imagem em escala de cinza\nedges_copy = edges.copy()\nimg_gray_contours = cv2.cvtColor(edges_copy, cv2.COLOR_GRAY2RGB)\ncv2.drawContours(img_gray_contours, contours, -1, (255, 0, 0), 5)\n\n# Desenha os contornos na imagem original\nimg_contours = img_rgb.copy()\ncv2.drawContours(img_contours, contours, -1, (255, 0, 0), 2)\n\n# Exibe a imagem original e a imagem com os contornos\nplt.figure(figsize=(10, 5))\nplt.subplot(1, 3, 1)\nplt.imshow(img_rgb)\nplt.title('Imagem Original')\nplt.axis('off')\n\nplt.subplot(1, 3, 2)\nplt.imshow(img_gray_contours)\nplt.title('Contornos gray')\nplt.axis('off')\n\nplt.subplot(1, 3, 3)\nplt.imshow(img_contours)\nplt.title('Contornos RGB')\nplt.axis('off')\n\nplt.show()\n</pre> #Implemente seu c\u00f3digo  # para desenhar o contorno podemos fazer uma imagem em escala de cinza e depois desenhar o contorno # ou podemos usar a imagem original e desenhar o contorno por cima   import cv2 from matplotlib import pyplot as plt  img = cv2.imread('formas.png') img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB) img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY) img_hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)  # Define as faixas de cor para o vermelho no espa\u00e7o HSV lower_hsv = np.array([0, 1, 1]) upper_hsv = np.array([180, 255, 255])  # Cria as m\u00e1scaras edges = cv2.inRange(img_hsv, lower_hsv, upper_hsv)  # Encontra os contornos na imagem contours, _ = cv2.findContours(edges, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)  # Desenha os contornos na imagem em escala de cinza edges_copy = edges.copy() img_gray_contours = cv2.cvtColor(edges_copy, cv2.COLOR_GRAY2RGB) cv2.drawContours(img_gray_contours, contours, -1, (255, 0, 0), 5)  # Desenha os contornos na imagem original img_contours = img_rgb.copy() cv2.drawContours(img_contours, contours, -1, (255, 0, 0), 2)  # Exibe a imagem original e a imagem com os contornos plt.figure(figsize=(10, 5)) plt.subplot(1, 3, 1) plt.imshow(img_rgb) plt.title('Imagem Original') plt.axis('off')  plt.subplot(1, 3, 2) plt.imshow(img_gray_contours) plt.title('Contornos gray') plt.axis('off')  plt.subplot(1, 3, 3) plt.imshow(img_contours) plt.title('Contornos RGB') plt.axis('off')  plt.show()   In\u00a0[65]: Copied! <pre>## Implemente seu c\u00f3digo\nimport cv2\nfrom matplotlib import pyplot as plt\n\nimg = cv2.imread('formas.png')\nimg_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\nimg_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\nimg_hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n\n# Define as faixas de cor para o vermelho no espa\u00e7o HSV\nlower_hsv = np.array([0, 1, 1])\nupper_hsv = np.array([180, 255, 255])\n\n# Cria as m\u00e1scaras\nedges = cv2.inRange(img_hsv, lower_hsv, upper_hsv)\n\n# Encontra os contornos na imagem\ncontours, _ = cv2.findContours(edges, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n\n### o findContours devolve uma lista de contornos, a ideia \u00e9 varrer esses contornos e encontrar a maior area e maior index\n \nmax_area = 0\nmax_index = -1\nfor i, contour in enumerate(contours):\n    area = cv2.contourArea(contour)\n    if area &gt; max_area:\n        max_area = area\n        max_index = i\n\nprint(f'Foram detectados {len(contours)} contornos.\\nO maior contorno \u00e9 o de indice {max_index} com a \u00e1rea de {max_area}')\n\n# Desenha o contorno de maior \u00e1rea na imagem original\nimg_contour_max = img_rgb.copy()\nif max_index != -1:\n    cv2.drawContours(img_contour_max, [contours[max_index]], -1, (0, 0, 0), 10)\n\n# Exibe a imagem original e a imagem com o contorno de maior \u00e1rea\nplt.figure(figsize=(10, 5))\nplt.subplot(1, 2, 1)\nplt.imshow(img_contour_max)\nplt.title('Maior Contorno')\nplt.axis('off')\n\n\nplt.show()\n</pre> ## Implemente seu c\u00f3digo import cv2 from matplotlib import pyplot as plt  img = cv2.imread('formas.png') img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB) img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY) img_hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)  # Define as faixas de cor para o vermelho no espa\u00e7o HSV lower_hsv = np.array([0, 1, 1]) upper_hsv = np.array([180, 255, 255])  # Cria as m\u00e1scaras edges = cv2.inRange(img_hsv, lower_hsv, upper_hsv)  # Encontra os contornos na imagem contours, _ = cv2.findContours(edges, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)  ### o findContours devolve uma lista de contornos, a ideia \u00e9 varrer esses contornos e encontrar a maior area e maior index   max_area = 0 max_index = -1 for i, contour in enumerate(contours):     area = cv2.contourArea(contour)     if area &gt; max_area:         max_area = area         max_index = i  print(f'Foram detectados {len(contours)} contornos.\\nO maior contorno \u00e9 o de indice {max_index} com a \u00e1rea de {max_area}')  # Desenha o contorno de maior \u00e1rea na imagem original img_contour_max = img_rgb.copy() if max_index != -1:     cv2.drawContours(img_contour_max, [contours[max_index]], -1, (0, 0, 0), 10)  # Exibe a imagem original e a imagem com o contorno de maior \u00e1rea plt.figure(figsize=(10, 5)) plt.subplot(1, 2, 1) plt.imshow(img_contour_max) plt.title('Maior Contorno') plt.axis('off')   plt.show()  <pre>Foram detectados 11 contornos.\nO maior contorno \u00e9 o de indice 1 com a \u00e1rea de 42784.0\n</pre> In\u00a0[\u00a0]: Copied! <pre>cv2.__version__\n</pre> cv2.__version__ Out[\u00a0]: <pre>'4.5.5'</pre> In\u00a0[\u00a0]: Copied! <pre>#recarregando o nosso exemplo...\n\n%matplotlib inline\nimport cv2\nfrom matplotlib import pyplot as plt\nimport numpy as np\n\nimg = cv2.imread('bolinha.png')\n\nimg_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\nimg_hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n\n\n# Defini\u00e7\u00e3o dos valores minimo e max da mascara\n# o magenta tem h=300 mais ou menos ou 150 para a OpenCV\nimage_lower_hsv = np.array([140, 50, 100])  \nimage_upper_hsv = np.array([170, 255, 255])\n\n\nmask_hsv = cv2.inRange(img_hsv, image_lower_hsv, image_upper_hsv)\n\ncontornos, _ = cv2.findContours(mask_hsv, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE) \n\nmask_rgb = cv2.cvtColor(mask_hsv, cv2.COLOR_GRAY2RGB) \ncontornos_img = mask_rgb.copy() # C\u00f3pia da m\u00e1scara para ser desenhada \"por cima\"\n\ncv2.drawContours(contornos_img, contornos, -1, [255, 0, 0], 5);\n\nplt.figure(figsize=(8,6))\nplt.imshow(contornos_img);\n</pre> #recarregando o nosso exemplo...  %matplotlib inline import cv2 from matplotlib import pyplot as plt import numpy as np  img = cv2.imread('bolinha.png')  img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB) img_hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)   # Defini\u00e7\u00e3o dos valores minimo e max da mascara # o magenta tem h=300 mais ou menos ou 150 para a OpenCV image_lower_hsv = np.array([140, 50, 100])   image_upper_hsv = np.array([170, 255, 255])   mask_hsv = cv2.inRange(img_hsv, image_lower_hsv, image_upper_hsv)  contornos, _ = cv2.findContours(mask_hsv, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)   mask_rgb = cv2.cvtColor(mask_hsv, cv2.COLOR_GRAY2RGB)  contornos_img = mask_rgb.copy() # C\u00f3pia da m\u00e1scara para ser desenhada \"por cima\"  cv2.drawContours(contornos_img, contornos, -1, [255, 0, 0], 5);  plt.figure(figsize=(8,6)) plt.imshow(contornos_img); In\u00a0[\u00a0]: Copied! <pre># usando o exemplo da documenta\u00e7\u00e3o https://docs.opencv.org/master/dd/d49/tutorial_py_contour_features.html\n# notamos que a fun\u00e7\u00e3o devolve um dicionario. \n\ncnt = contornos[0]\n\nM = cv2.moments(cnt)\nprint( M )\n</pre> # usando o exemplo da documenta\u00e7\u00e3o https://docs.opencv.org/master/dd/d49/tutorial_py_contour_features.html # notamos que a fun\u00e7\u00e3o devolve um dicionario.   cnt = contornos[0]  M = cv2.moments(cnt) print( M ) <pre>{'m00': 20954.5, 'm10': 8414785.5, 'm01': 4813317.5, 'm20': 3414210172.083333, 'm11': 1932427931.625, 'm02': 1140509199.0833333, 'm30': 1399201096317.6501, 'm21': 783868070420.7833, 'm12': 457787216119.7167, 'm03': 278003040454.85004, 'mu20': 35049847.99971104, 'mu11': -475946.1051416397, 'mu02': 34874354.26211333, 'mu30': -7672941.9208984375, 'mu21': -4968840.380795479, 'mu12': 6858123.621509552, 'mu03': 2822544.575317383, 'nu20': 0.07982364109512664, 'nu11': -0.0010839348312655414, 'nu02': 0.07942396606302501, 'nu30': -0.00012071706132489804, 'nu21': -7.817390189392743e-05, 'nu12': 0.00010789766667418762, 'nu03': 4.4406603113053444e-05}\n</pre> In\u00a0[\u00a0]: Copied! <pre># Calculo das coordenadas do centro de massa\n\ncx = int(M['m10']/M['m00'])\ncy = int(M['m01']/M['m00'])\n\nprint(\"centro de massa na possi\u00e7\u00e3o: \",cx, cy)\n</pre> # Calculo das coordenadas do centro de massa  cx = int(M['m10']/M['m00']) cy = int(M['m01']/M['m00'])  print(\"centro de massa na possi\u00e7\u00e3o: \",cx, cy) <pre>centro de massa na possi\u00e7\u00e3o:  401 229\n</pre> <p>Vamos plotar isso na imagem para saber se esta correto. A fun\u00e7\u00e3o \"cv2.line\" vai nos ajudar a desenhar uma cruz. e fun\u00e7\u00e3o \"cv2.putText\" a escrever na imagem as coordenadas.</p> In\u00a0[\u00a0]: Copied! <pre>## para desenhar a cruz vamos passar a cor e o tamanho em pixel\nsize = 20\ncolor = (128,128,0)\n\n\ncv2.line(contornos_img,(cx - size,cy),(cx + size,cy),color,5)\ncv2.line(contornos_img,(cx,cy - size),(cx, cy + size),color,5)\n\n# Para escrever vamos definir uma fonte \n\nfont = cv2.FONT_HERSHEY_SIMPLEX\ntext = cy , cx\norigem = (0,50)\n\ncv2.putText(contornos_img, str(text), origem, font,1,(200,50,0),2,cv2.LINE_AA)\n\n\nplt.imshow(contornos_img);\n</pre> ## para desenhar a cruz vamos passar a cor e o tamanho em pixel size = 20 color = (128,128,0)   cv2.line(contornos_img,(cx - size,cy),(cx + size,cy),color,5) cv2.line(contornos_img,(cx,cy - size),(cx, cy + size),color,5)  # Para escrever vamos definir uma fonte   font = cv2.FONT_HERSHEY_SIMPLEX text = cy , cx origem = (0,50)  cv2.putText(contornos_img, str(text), origem, font,1,(200,50,0),2,cv2.LINE_AA)   plt.imshow(contornos_img); In\u00a0[70]: Copied! <pre>#### seu c\u00f3digo aqui...\n\n## Vamos fazer por partes, primeiro vamos achar o centro de massa para a imagem que estamos utilizando da melancia\n%matplotlib inline\nimport cv2\nfrom matplotlib import pyplot as plt\nimport numpy as np\n\nimg = cv2.imread('melancia.png')\n\nimg_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\nimg_hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n\nprint(img_hsv.shape)\nprint(img_hsv[220,700])\n\n# Defini\u00e7\u00e3o dos valores minimo e max da mascara para a melancia\n# use o color picker para pegar os valores aproximados de h, s e v para a melancia \nmelancia_lower1 = np.array([175, 120, 150])  \nmelancia_upper1 = np.array([180, 255, 255])\nmelancia_lower2 = np.array([0, 140, 160])  \nmelancia_upper2 = np.array([15, 255, 255])\n\n# Cria as m\u00e1scaras para as faixas de vermelho\nmask_1 = cv2.inRange(img_hsv, melancia_lower1, melancia_upper1)\nmask_2 = cv2.inRange(img_hsv, melancia_lower2, melancia_upper2)\n\n# Combina as duas m\u00e1scaras com uma opera\u00e7\u00e3o bitwise_or\nmask_melancia = cv2.bitwise_or(mask_1, mask_2)\n\n# Encontra os contornos na imagem\ncontours, _ = cv2.findContours(mask_melancia, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n\n### o findContours devolve uma lista de contornos, a ideia \u00e9 varrer esses contornos e encontrar a maior area e maior index\n \nmax_area = 0\nmax_index = -1\nfor i, contour in enumerate(contours):\n    area = cv2.contourArea(contour)\n    if area &gt; max_area:\n        max_area = area\n        max_index = i\n\nprint(f'Foram detectados {len(contours)} contornos.\\nO maior contorno \u00e9 o de indice {max_index} com a \u00e1rea de {max_area}')\n## para desenhar a cruz vamos passar a cor e o tamanho em pixel\nsize = 20\ncolor = (128,128,0)\n# Desenha o contorno de maior \u00e1rea na imagem original\nimg_contour_max = img_rgb.copy()\nif max_index != -1:\n    cv2.drawContours(img_contour_max, [contours[max_index]], -1, (0, 255, 0), 10)\n\n    # Calcula o centro de massa\n    M = cv2.moments(contours[max_index])\n    if M[\"m00\"] != 0:\n        cx = int(M[\"m10\"] / M[\"m00\"])\n        cy = int(M[\"m01\"] / M[\"m00\"])\n        # Desenha o centro de massa\n        cv2.line(img_contour_max,(cx - size,cy),(cx + size,cy),color,5)\n        cv2.line(img_contour_max,(cx,cy - size),(cx, cy + size),color,5)\n        cv2.putText(img, f'({cy}, {cx})', (0, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (200, 50, 0), 2, cv2.LINE_AA)\n\n# Exibe a imagem original e a imagem com o contorno de maior \u00e1rea\nplt.figure(figsize=(10, 5))\nplt.subplot(1, 2, 1)\nplt.imshow(img_contour_max)\nplt.title('Achei voc\u00ea!')\nplt.axis('off')\n\n\nplt.show()\n</pre> #### seu c\u00f3digo aqui...  ## Vamos fazer por partes, primeiro vamos achar o centro de massa para a imagem que estamos utilizando da melancia %matplotlib inline import cv2 from matplotlib import pyplot as plt import numpy as np  img = cv2.imread('melancia.png')  img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB) img_hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)  print(img_hsv.shape) print(img_hsv[220,700])  # Defini\u00e7\u00e3o dos valores minimo e max da mascara para a melancia # use o color picker para pegar os valores aproximados de h, s e v para a melancia  melancia_lower1 = np.array([175, 120, 150])   melancia_upper1 = np.array([180, 255, 255]) melancia_lower2 = np.array([0, 140, 160])   melancia_upper2 = np.array([15, 255, 255])  # Cria as m\u00e1scaras para as faixas de vermelho mask_1 = cv2.inRange(img_hsv, melancia_lower1, melancia_upper1) mask_2 = cv2.inRange(img_hsv, melancia_lower2, melancia_upper2)  # Combina as duas m\u00e1scaras com uma opera\u00e7\u00e3o bitwise_or mask_melancia = cv2.bitwise_or(mask_1, mask_2)  # Encontra os contornos na imagem contours, _ = cv2.findContours(mask_melancia, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)  ### o findContours devolve uma lista de contornos, a ideia \u00e9 varrer esses contornos e encontrar a maior area e maior index   max_area = 0 max_index = -1 for i, contour in enumerate(contours):     area = cv2.contourArea(contour)     if area &gt; max_area:         max_area = area         max_index = i  print(f'Foram detectados {len(contours)} contornos.\\nO maior contorno \u00e9 o de indice {max_index} com a \u00e1rea de {max_area}') ## para desenhar a cruz vamos passar a cor e o tamanho em pixel size = 20 color = (128,128,0) # Desenha o contorno de maior \u00e1rea na imagem original img_contour_max = img_rgb.copy() if max_index != -1:     cv2.drawContours(img_contour_max, [contours[max_index]], -1, (0, 255, 0), 10)      # Calcula o centro de massa     M = cv2.moments(contours[max_index])     if M[\"m00\"] != 0:         cx = int(M[\"m10\"] / M[\"m00\"])         cy = int(M[\"m01\"] / M[\"m00\"])         # Desenha o centro de massa         cv2.line(img_contour_max,(cx - size,cy),(cx + size,cy),color,5)         cv2.line(img_contour_max,(cx,cy - size),(cx, cy + size),color,5)         cv2.putText(img, f'({cy}, {cx})', (0, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (200, 50, 0), 2, cv2.LINE_AA)  # Exibe a imagem original e a imagem com o contorno de maior \u00e1rea plt.figure(figsize=(10, 5)) plt.subplot(1, 2, 1) plt.imshow(img_contour_max) plt.title('Achei voc\u00ea!') plt.axis('off')   plt.show()  <pre>(723, 1280, 3)\n[179 172 231]\nForam detectados 116 contornos.\nO maior contorno \u00e9 o de indice 98 com a \u00e1rea de 53061.0\n</pre> In\u00a0[\u00a0]: Copied! <pre>import cv2\nimport numpy as np\n\n# Inicializa a captura de v\u00eddeo da webcam\ncap = cv2.VideoCapture(0)\n\n# Defini\u00e7\u00e3o dos valores m\u00ednimo e m\u00e1ximo da m\u00e1scara para a melancia\nmelancia_lower1 = np.array([175, 120, 150])\nmelancia_upper1 = np.array([180, 255, 255])\nmelancia_lower2 = np.array([0, 140, 160])\nmelancia_upper2 = np.array([15, 255, 255])\n\n# Loop para ler os frames da webcam\nwhile True:\n    ret, img = cap.read()\n    if not ret:\n        break\n\n    img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n    img_hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n\n    # Cria as m\u00e1scaras para as faixas de vermelho\n    mask_1 = cv2.inRange(img_hsv, melancia_lower1, melancia_upper1)\n    mask_2 = cv2.inRange(img_hsv, melancia_lower2, melancia_upper2)\n\n    # Combina as duas m\u00e1scaras com uma opera\u00e7\u00e3o bitwise_or\n    mask_melancia = cv2.bitwise_or(mask_1, mask_2)\n\n    # Encontra os contornos na imagem\n    contours, _ = cv2.findContours(mask_melancia, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n\n    # Encontra o contorno de maior \u00e1rea\n    max_area = 0\n    max_index = -1\n    for i, contour in enumerate(contours):\n        area = cv2.contourArea(contour)\n        if area &gt; max_area:\n            max_area = area\n            max_index = i\n\n    # Desenha o contorno de maior \u00e1rea na imagem original\n    if max_index != -1:\n        cv2.drawContours(img, [contours[max_index]], -1, (0, 255, 0), 10)\n\n        # Calcula o centro de massa\n        M = cv2.moments(contours[max_index])\n        if M[\"m00\"] != 0:\n            cx = int(M[\"m10\"] / M[\"m00\"])\n            cy = int(M[\"m01\"] / M[\"m00\"])\n            # Desenha o centro de massa\n            cv2.line(img, (cx - 20, cy), (cx + 20, cy), (128, 128, 0), 5)\n            cv2.line(img, (cx, cy - 20), (cx, cy + 20), (128, 128, 0), 5)\n            cv2.putText(img, f'({cy}, {cx})', (0, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (200, 50, 0), 2, cv2.LINE_AA)\n\n    # Exibe a imagem com o contorno de maior \u00e1rea\n    cv2.imshow('Achei voc\u00ea!', img)\n\n    # Sai do loop se a tecla 'q' for pressionada\n    if cv2.waitKey(1) &amp; 0xFF == ord('q'):\n        break\n\n# Libera a captura e fecha todas as janelas\ncap.release()\ncv2.destroyAllWindows()\n</pre> import cv2 import numpy as np  # Inicializa a captura de v\u00eddeo da webcam cap = cv2.VideoCapture(0)  # Defini\u00e7\u00e3o dos valores m\u00ednimo e m\u00e1ximo da m\u00e1scara para a melancia melancia_lower1 = np.array([175, 120, 150]) melancia_upper1 = np.array([180, 255, 255]) melancia_lower2 = np.array([0, 140, 160]) melancia_upper2 = np.array([15, 255, 255])  # Loop para ler os frames da webcam while True:     ret, img = cap.read()     if not ret:         break      img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)     img_hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)      # Cria as m\u00e1scaras para as faixas de vermelho     mask_1 = cv2.inRange(img_hsv, melancia_lower1, melancia_upper1)     mask_2 = cv2.inRange(img_hsv, melancia_lower2, melancia_upper2)      # Combina as duas m\u00e1scaras com uma opera\u00e7\u00e3o bitwise_or     mask_melancia = cv2.bitwise_or(mask_1, mask_2)      # Encontra os contornos na imagem     contours, _ = cv2.findContours(mask_melancia, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)      # Encontra o contorno de maior \u00e1rea     max_area = 0     max_index = -1     for i, contour in enumerate(contours):         area = cv2.contourArea(contour)         if area &gt; max_area:             max_area = area             max_index = i      # Desenha o contorno de maior \u00e1rea na imagem original     if max_index != -1:         cv2.drawContours(img, [contours[max_index]], -1, (0, 255, 0), 10)          # Calcula o centro de massa         M = cv2.moments(contours[max_index])         if M[\"m00\"] != 0:             cx = int(M[\"m10\"] / M[\"m00\"])             cy = int(M[\"m01\"] / M[\"m00\"])             # Desenha o centro de massa             cv2.line(img, (cx - 20, cy), (cx + 20, cy), (128, 128, 0), 5)             cv2.line(img, (cx, cy - 20), (cx, cy + 20), (128, 128, 0), 5)             cv2.putText(img, f'({cy}, {cx})', (0, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (200, 50, 0), 2, cv2.LINE_AA)      # Exibe a imagem com o contorno de maior \u00e1rea     cv2.imshow('Achei voc\u00ea!', img)      # Sai do loop se a tecla 'q' for pressionada     if cv2.waitKey(1) &amp; 0xFF == ord('q'):         break  # Libera a captura e fecha todas as janelas cap.release() cv2.destroyAllWindows()"},{"location":"aulas/PDI/lab05/sol_Espa%C3%A7o-cor-contorno.html#espaco-de-cor-hsv","title":"Espa\u00e7o de cor HSV\u00b6","text":"<p>At\u00e9 o momento trabalhamos com imagens em escala de cinza, BGR, RGB e binaria. Agora vamos conhecer e trabalhar com HSV ou HSB.</p> <pre><code>H - hue (matriz)\nS - saturation (satura\u00e7\u00e3o)\nV - value (Value) ou B - brightness (brilho)</code></pre> <p>Utilizar esse espa\u00e7o possui algumas vantagens vamos ver no exemplo abaixo.</p>"},{"location":"aulas/PDI/lab05/sol_Espa%C3%A7o-cor-contorno.html#desafio-1","title":"DESAFIO 1\u00b6","text":"<p>Fa\u00e7a a segmenta\u00e7\u00e3o da meia lua da imagem \"melancia.png\". O seu resultado deve ser proximo/parecido com a imagem \"melancia_filtrada.png\".</p> <p>Dica: talvez voc\u00ea precise usar mais que uma faixa de valores, se necess\u00e1rio use a fun\u00e7\u00e3o \"cv2.bitwise_or\" para juntar as partes.</p>"},{"location":"aulas/PDI/lab05/sol_Espa%C3%A7o-cor-contorno.html#desafio-2","title":"DESAFIO 2\u00b6","text":"<p>Usando a imagem \"melancia_filtrada.png\", devolva a cor original que era antes da filtragem.</p> <p>Dica: Use as fun\u00e7\u00f5es de \"cv2.bitwise_and\" para juntar.</p>"},{"location":"aulas/PDI/lab05/sol_Espa%C3%A7o-cor-contorno.html#deteccao-de-contornos","title":"DETEC\u00c7\u00c3O DE CONTORNOS\u00b6","text":"<p>Para realizar a detec\u00e7\u00e3o dos contornos, ou bordas de um objeto, usamos a fun\u00e7\u00e3o cv2.findontours</p>"},{"location":"aulas/PDI/lab05/sol_Espa%C3%A7o-cor-contorno.html#desafio-3","title":"DESAFIO 3\u00b6","text":"<p>Usando a imagem \"formas.png\", fa\u00e7a um c\u00f3digo que detecta todos os contornos da imagem. O resultado deve ser parecido com \"formas_contorno.png\"</p> <p>Dica: Neste desafio, basicamente tem que ajustar a a mascara, o resto n\u00e3o muda.</p>"},{"location":"aulas/PDI/lab05/sol_Espa%C3%A7o-cor-contorno.html#desafio-4","title":"DESAFIO 4\u00b6","text":"<p>Altere o seu codigo para desenhar o contorno de maior area da imagem. Use a fun\u00e7\u00e3o \"cv2.contourArea()\".</p> <p>Refer\u00eancia da documenta\u00e7\u00e3o: https://docs.opencv.org/master/dd/d49/tutorial_py_contour_features.html</p> <p>Dica: Use um for para varrer a lista e armazene o indice do maior valor e passe esse valor para desenhar o contorno.</p>"},{"location":"aulas/PDI/lab05/sol_Espa%C3%A7o-cor-contorno.html#centro-de-massa-de-um-objeto","title":"CENTRO DE MASSA DE UM OBJETO\u00b6","text":"<p>O calculo para o centro de massa \u00e9 feito atr\u00e1ves da fun\u00e7\u00e3o cv2.findontours</p>"},{"location":"aulas/PDI/lab05/sol_Espa%C3%A7o-cor-contorno.html#desafio-5","title":"DESAFIO 5\u00b6","text":"<p>O desafio \u00e9 juntar o que aprendemos em um video, use como base \"webcam.py\". Voc\u00ea deve seguimentar a cor de um objeto, encontrar seu contorno e montar a imagem segmentada com o centro de massa e suas coordenadas. Video de refer\u00eancia \"segmenta_melancia.mp4\"</p>"},{"location":"aulas/PDI/lab05/webcam.html","title":"Webcam","text":"In\u00a0[\u00a0]: Copied! <p>Programa simples com camera webcam e opencv</p> In\u00a0[\u00a0]: Copied! <pre>import cv2\nimport os,sys, os.path\nimport numpy as np\n</pre> import cv2 import os,sys, os.path import numpy as np In\u00a0[\u00a0]: Copied! <pre>def image_da_webcam(img):\n    \"\"\"\n    -&gt;&gt;&gt; !!!! FECHE A JANELA COM A TECLA ESC !!!! &lt;&lt;&lt;&lt;-\n        deve receber a imagem da camera e retornar uma imagems filtrada.\n    \"\"\"\n    img = cv2.cvtColor(img,cv2.COLOR_BGR2RGB)\n\n    return img\n</pre> def image_da_webcam(img):     \"\"\"     -&gt;&gt;&gt; !!!! FECHE A JANELA COM A TECLA ESC !!!! &lt;&lt;&lt;&lt;-         deve receber a imagem da camera e retornar uma imagems filtrada.     \"\"\"     img = cv2.cvtColor(img,cv2.COLOR_BGR2RGB)      return img In\u00a0[\u00a0]: Copied! <pre>cv2.namedWindow(\"preview\")\nvc = cv2.VideoCapture(0)\n</pre> cv2.namedWindow(\"preview\") vc = cv2.VideoCapture(0) In\u00a0[\u00a0]: Copied! <pre>if vc.isOpened(): # try to get the first frame\n    rval, frame = vc.read()\nelse:\n    rval = False\n</pre> if vc.isOpened(): # try to get the first frame     rval, frame = vc.read() else:     rval = False In\u00a0[\u00a0]: Copied! <pre>while rval:\n    \n    img = image_da_webcam(frame)\n\n\n    cv2.imshow(\"preview\", img)\n\n    rval, frame = vc.read()\n    key = cv2.waitKey(20)\n    if key == 27: # exit on ESC\n        break\n</pre> while rval:          img = image_da_webcam(frame)       cv2.imshow(\"preview\", img)      rval, frame = vc.read()     key = cv2.waitKey(20)     if key == 27: # exit on ESC         break In\u00a0[\u00a0]: Copied! <pre>cv2.destroyWindow(\"preview\")\nvc.release()\n</pre> cv2.destroyWindow(\"preview\") vc.release()"},{"location":"aulas/PDI/lab06/Transformada-Hough-morfologia.html","title":"Lab06 - Transformada de Hough e morfologia","text":"<p>Objetivos da aula:</p> <ul> <li>Conhecer e praticar a Transformada de Hough para linhas e circulos</li> <li>conhecer e praticar com os operadores de dilata\u00e7\u00e3o e eros\u00e3o</li> <li>conhecer e praticar com os operadores de abertura e fechamento</li> </ul> In\u00a0[\u00a0]: Copied! <pre>## Vou fazer o download das imagens do laborat\u00f3rio diretamente do reposit\u00f3rio para ficar mais facil....\n\nimport requests\nimport os\n\n# Define o laborat\u00f3rio\nlaboratorio = 'lab06'  ### altere para o laborat\u00f3rio desejado\ndiretorio = 'lab_images'  ### altere para o diret\u00f3rio que deseja salvar as imagens\n\n# Download de um arquivo\ndef download_file(url, destination):\n    response = requests.get(url, stream=True)\n    if response.status_code == 200:\n        with open(destination, 'wb') as file:\n            for chunk in response.iter_content(chunk_size=8192):\n                file.write(chunk)\n        print(f\"Baixado: {destination}\")\n    else:\n        print(f\"Erro ao baixar {url}\")\n\n# Monta a URL completa\napi_url = \"https://api.github.com/repos/arnaldojr/cognitivecomputing/contents/material/aulas/PDI/\"\nurl_completa = api_url + laboratorio\nprint(f\"Fazendo o download de: {url_completa}\")\n\n# checa se a URL est\u00e1 acess\u00edvel\nresponse = requests.get(url_completa)\nif response.status_code != 200:\n    raise Exception(f\"Erro ao acessar o reposit\u00f3rio: {response.status_code}\")\nfiles = response.json()\n\n\n# Faz o download de cada arquivo\nos.makedirs(diretorio, exist_ok=True) # Cria a pasta downloads\nfor file in files:\n    file_name = file['name']\n    if file_name.endswith(('.png', '.jpg', '.jpeg', '.mp4')):  # Adicione mais extens\u00f5es se necess\u00e1rio\n        file_url = file['download_url']\n        destination = os.path.join(diretorio, file_name)\n        download_file(file_url, destination)\n\nprint(f\"Download conclu\u00eddo. Arquivos salvos na pasta {diretorio}.\")\n</pre> ## Vou fazer o download das imagens do laborat\u00f3rio diretamente do reposit\u00f3rio para ficar mais facil....  import requests import os  # Define o laborat\u00f3rio laboratorio = 'lab06'  ### altere para o laborat\u00f3rio desejado diretorio = 'lab_images'  ### altere para o diret\u00f3rio que deseja salvar as imagens  # Download de um arquivo def download_file(url, destination):     response = requests.get(url, stream=True)     if response.status_code == 200:         with open(destination, 'wb') as file:             for chunk in response.iter_content(chunk_size=8192):                 file.write(chunk)         print(f\"Baixado: {destination}\")     else:         print(f\"Erro ao baixar {url}\")  # Monta a URL completa api_url = \"https://api.github.com/repos/arnaldojr/cognitivecomputing/contents/material/aulas/PDI/\" url_completa = api_url + laboratorio print(f\"Fazendo o download de: {url_completa}\")  # checa se a URL est\u00e1 acess\u00edvel response = requests.get(url_completa) if response.status_code != 200:     raise Exception(f\"Erro ao acessar o reposit\u00f3rio: {response.status_code}\") files = response.json()   # Faz o download de cada arquivo os.makedirs(diretorio, exist_ok=True) # Cria a pasta downloads for file in files:     file_name = file['name']     if file_name.endswith(('.png', '.jpg', '.jpeg', '.mp4')):  # Adicione mais extens\u00f5es se necess\u00e1rio         file_url = file['download_url']         destination = os.path.join(diretorio, file_name)         download_file(file_url, destination)  print(f\"Download conclu\u00eddo. Arquivos salvos na pasta {diretorio}.\") In\u00a0[15]: Copied! <pre>%matplotlib inline\nimport cv2\nfrom matplotlib import pyplot as plt\nimport numpy as np\n\nimg = cv2.imread('formas.png')\nimg = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n\nplt.figure(figsize = (10,10))\nplt.imshow(img); plt.show()\n</pre> %matplotlib inline import cv2 from matplotlib import pyplot as plt import numpy as np  img = cv2.imread('formas.png') img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)  plt.figure(figsize = (10,10)) plt.imshow(img); plt.show() In\u00a0[21]: Copied! <pre>img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n\nedges = cv2.Canny(img_gray,50,150)\n\n\"\"\"\nDetecta c\u00edrculos em uma imagem usando a Transformada de Hough\n\nPar\u00e2metros:\nimagem (ndarray): Imagem de entrada\ndp (float): Resolu\u00e7\u00e3o do acumulador\nminDist (int): Dist\u00e2ncia m\u00ednima entre os centros dos c\u00edrculos detectados\nparam1 (int): Limiar superior para o detector de bordas Canny\nparam2 (int): Limiar do acumulador para centros de c\u00edrculos\nminRadius (int): Raio m\u00ednimo dos c\u00edrculos\nmaxRadius (int): Raio m\u00e1ximo dos c\u00edrculos\n\nRetorno:\nndarray: Imagem com c\u00edrculos detectados\n\"\"\"\ncircles=cv2.HoughCircles(edges,cv2.HOUGH_GRADIENT,dp=2,minDist=10,param1=200,param2=100,minRadius=5,maxRadius=150)\n\nbordas_rgb = cv2.cvtColor(edges, cv2.COLOR_GRAY2RGB)\noutput = bordas_rgb\n\n\nif circles is not None:        \n    circles = np.uint16(np.around(circles))\n    for i in circles[0,:]:\n        # desenha o contorno do circulo\n        cv2.circle(output,(i[0],i[1]),i[2],(0,255,0),2)\n        # desenha no centro do circulo\n        cv2.circle(output,(i[0],i[1]),2,(0,0,255),3)\n        \nplt.figure(figsize = (10,10))\nplt.imshow(output, cmap=\"Greys_r\", vmin=0, vmax=255); plt.show()\n</pre> img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)  edges = cv2.Canny(img_gray,50,150)  \"\"\" Detecta c\u00edrculos em uma imagem usando a Transformada de Hough  Par\u00e2metros: imagem (ndarray): Imagem de entrada dp (float): Resolu\u00e7\u00e3o do acumulador minDist (int): Dist\u00e2ncia m\u00ednima entre os centros dos c\u00edrculos detectados param1 (int): Limiar superior para o detector de bordas Canny param2 (int): Limiar do acumulador para centros de c\u00edrculos minRadius (int): Raio m\u00ednimo dos c\u00edrculos maxRadius (int): Raio m\u00e1ximo dos c\u00edrculos  Retorno: ndarray: Imagem com c\u00edrculos detectados \"\"\" circles=cv2.HoughCircles(edges,cv2.HOUGH_GRADIENT,dp=2,minDist=10,param1=200,param2=100,minRadius=5,maxRadius=150)  bordas_rgb = cv2.cvtColor(edges, cv2.COLOR_GRAY2RGB) output = bordas_rgb   if circles is not None:             circles = np.uint16(np.around(circles))     for i in circles[0,:]:         # desenha o contorno do circulo         cv2.circle(output,(i[0],i[1]),i[2],(0,255,0),2)         # desenha no centro do circulo         cv2.circle(output,(i[0],i[1]),2,(0,0,255),3)          plt.figure(figsize = (10,10)) plt.imshow(output, cmap=\"Greys_r\", vmin=0, vmax=255); plt.show() In\u00a0[6]: Copied! <pre># Implemente sua solu\u00e7\u00e3o aqui...\n</pre> # Implemente sua solu\u00e7\u00e3o aqui...   In\u00a0[8]: Copied! <pre>#Implemente seu c\u00f3digo\n</pre> #Implemente seu c\u00f3digo      In\u00a0[22]: Copied! <pre>%matplotlib inline\nimport cv2\nfrom matplotlib import pyplot as plt\nimport numpy as np\nimport math\n\nimg = cv2.imread('formas.png')\nimg = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n\nplt.figure(figsize = (10,10))\nplt.imshow(img); plt.show()\n</pre> %matplotlib inline import cv2 from matplotlib import pyplot as plt import numpy as np import math  img = cv2.imread('formas.png') img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)  plt.figure(figsize = (10,10)) plt.imshow(img); plt.show() In\u00a0[28]: Copied! <pre>img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n\nedges = cv2.Canny(img_gray,50,150)\n\n\nlines = cv2.HoughLinesP(edges, 1, np.pi/180, 200, minLineLength=100, maxLineGap=10)\n\nhough_img_rgb = cv2.cvtColor(edges, cv2.COLOR_GRAY2BGR)\n\nfor line in lines:\n    x1, y1, x2, y2 = line[0]\n    cv2.line(hough_img_rgb, (x1, y1), (x2, y2), (255, 0, 255), 5)\n\n\nplt.figure(figsize = (10,10))\nplt.imshow(hough_img_rgb); plt.show()\n</pre> img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)  edges = cv2.Canny(img_gray,50,150)   lines = cv2.HoughLinesP(edges, 1, np.pi/180, 200, minLineLength=100, maxLineGap=10)  hough_img_rgb = cv2.cvtColor(edges, cv2.COLOR_GRAY2BGR)  for line in lines:     x1, y1, x2, y2 = line[0]     cv2.line(hough_img_rgb, (x1, y1), (x2, y2), (255, 0, 255), 5)   plt.figure(figsize = (10,10)) plt.imshow(hough_img_rgb); plt.show() In\u00a0[11]: Copied! <pre>#Implemente seu c\u00f3digo\n</pre> #Implemente seu c\u00f3digo      In\u00a0[34]: Copied! <pre>#Implemente seu c\u00f3digo\n</pre> #Implemente seu c\u00f3digo      In\u00a0[14]: Copied! <pre>from IPython.display import Image\nImage(open('dilata\u00e7\u00e3o.gif','rb').read())\n</pre> from IPython.display import Image Image(open('dilata\u00e7\u00e3o.gif','rb').read()) Out[14]: In\u00a0[58]: Copied! <pre>img = cv2.imread('j.png',0)\n\n\nkernel = np.ones((5,5),np.uint8)\n\ndilation = cv2.dilate(img,kernel,iterations = 1)\n\n\n\nplt.subplot(121),plt.imshow(img, cmap=\"gray\", vmin=0, vmax=255)\nplt.subplot(122),plt.imshow(dilation, cmap=\"gray\", vmin=0, vmax=255)\nplt.show()\n</pre>  img = cv2.imread('j.png',0)   kernel = np.ones((5,5),np.uint8)  dilation = cv2.dilate(img,kernel,iterations = 1)    plt.subplot(121),plt.imshow(img, cmap=\"gray\", vmin=0, vmax=255) plt.subplot(122),plt.imshow(dilation, cmap=\"gray\", vmin=0, vmax=255) plt.show() In\u00a0[59]: Copied! <pre>img = cv2.imread('j.png',0)\n\ndst = img.copy()\nkernel = np.ones((5,5),np.uint8)\n\ndilation = cv2.dilate(img,kernel,iterations = 1)\n\ndst = dilation - img\n\nplt.subplot(121),plt.imshow(img, cmap=\"gray\", vmin=0, vmax=255)\nplt.subplot(122),plt.imshow(dst, cmap=\"gray\", vmin=0, vmax=255)\nplt.show()\n</pre>  img = cv2.imread('j.png',0)  dst = img.copy() kernel = np.ones((5,5),np.uint8)  dilation = cv2.dilate(img,kernel,iterations = 1)  dst = dilation - img  plt.subplot(121),plt.imshow(img, cmap=\"gray\", vmin=0, vmax=255) plt.subplot(122),plt.imshow(dst, cmap=\"gray\", vmin=0, vmax=255) plt.show() In\u00a0[60]: Copied! <pre>img = cv2.imread('j.png',0)\n\n# Criar e visualizar elementos estruturantes de tamanho 5x5\ntamanho = (5, 5)\n\n# 1. Elemento estruturante retangular\nkernel_retangular = cv2.getStructuringElement(cv2.MORPH_RECT, tamanho)\n\n# 2. Elemento estruturante el\u00edptico\nkernel_eliptico = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, tamanho)\n\n# 3. Elemento estruturante em forma de cruz\nkernel_cruz = cv2.getStructuringElement(cv2.MORPH_CROSS, tamanho)\n\n\n# Aplicar opera\u00e7\u00f5es morfol\u00f3gicas\nimg_dilated_rect = cv2.dilate(img, kernel_retangular, iterations=1)\nimg_dilated_ellipse = cv2.dilate(img, kernel_eliptico, iterations=1)\nimg_dilated_cross = cv2.dilate(img, kernel_cruz, iterations=1)\n# contorno da imagem\nborder_diff_rect = img_dilated_rect - img\nborder_diff_ellipse = img_dilated_ellipse - img\nborder_diff_cross = img_dilated_cross - img\n\n\n\nplt.subplot(131), plt.imshow(border_diff_rect, cmap=\"gray\", vmin=0, vmax=255)\nplt.subplot(132), plt.imshow(border_diff_ellipse, cmap=\"gray\", vmin=0, vmax=255)\nplt.subplot(133), plt.imshow(border_diff_cross, cmap=\"gray\", vmin=0, vmax=255)\nplt.show()\n</pre>  img = cv2.imread('j.png',0)  # Criar e visualizar elementos estruturantes de tamanho 5x5 tamanho = (5, 5)  # 1. Elemento estruturante retangular kernel_retangular = cv2.getStructuringElement(cv2.MORPH_RECT, tamanho)  # 2. Elemento estruturante el\u00edptico kernel_eliptico = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, tamanho)  # 3. Elemento estruturante em forma de cruz kernel_cruz = cv2.getStructuringElement(cv2.MORPH_CROSS, tamanho)   # Aplicar opera\u00e7\u00f5es morfol\u00f3gicas img_dilated_rect = cv2.dilate(img, kernel_retangular, iterations=1) img_dilated_ellipse = cv2.dilate(img, kernel_eliptico, iterations=1) img_dilated_cross = cv2.dilate(img, kernel_cruz, iterations=1) # contorno da imagem border_diff_rect = img_dilated_rect - img border_diff_ellipse = img_dilated_ellipse - img border_diff_cross = img_dilated_cross - img    plt.subplot(131), plt.imshow(border_diff_rect, cmap=\"gray\", vmin=0, vmax=255) plt.subplot(132), plt.imshow(border_diff_ellipse, cmap=\"gray\", vmin=0, vmax=255) plt.subplot(133), plt.imshow(border_diff_cross, cmap=\"gray\", vmin=0, vmax=255) plt.show()  In\u00a0[17]: Copied! <pre>from IPython.display import Image\nImage(open('erosao.gif','rb').read())\n</pre> from IPython.display import Image Image(open('erosao.gif','rb').read()) Out[17]: In\u00a0[61]: Copied! <pre>img = cv2.imread('j.png',0)\n\n\ndst = img.copy()\nkernel = cv2.getStructuringElement(cv2.MORPH_RECT, (5,5))\n\nerode = cv2.erode(img,kernel,iterations = 1)\n\nplt.subplot(121),plt.imshow(img, cmap=\"gray\", vmin=0, vmax=255)\nplt.subplot(122),plt.imshow(erode, cmap=\"gray\", vmin=0, vmax=255)\nplt.show()\n</pre>  img = cv2.imread('j.png',0)   dst = img.copy() kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (5,5))  erode = cv2.erode(img,kernel,iterations = 1)  plt.subplot(121),plt.imshow(img, cmap=\"gray\", vmin=0, vmax=255) plt.subplot(122),plt.imshow(erode, cmap=\"gray\", vmin=0, vmax=255) plt.show() In\u00a0[62]: Copied! <pre>img = cv.imread('j-noise.png',0)\n\nkernel = cv2.getStructuringElement(cv2.MORPH_RECT, (5,5))\n\nopening = cv2.morphologyEx(img, cv2.MORPH_OPEN, kernel)\n\n\n\nplt.subplot(121),plt.imshow(img, cmap=\"gray\", vmin=0, vmax=255)\nplt.subplot(122),plt.imshow(opening, cmap=\"gray\", vmin=0, vmax=255)\nplt.show()\n</pre>  img = cv.imread('j-noise.png',0)  kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (5,5))  opening = cv2.morphologyEx(img, cv2.MORPH_OPEN, kernel)    plt.subplot(121),plt.imshow(img, cmap=\"gray\", vmin=0, vmax=255) plt.subplot(122),plt.imshow(opening, cmap=\"gray\", vmin=0, vmax=255) plt.show()  In\u00a0[63]: Copied! <pre>img = cv2.imread('holes.png',0)\n\n\nkernel = cv2.getStructuringElement(cv2.MORPH_RECT, (5,5))\n\nclosing = cv2.morphologyEx(img, cv2.MORPH_CLOSE, kernel)\n\n\nplt.subplot(121),plt.imshow(img, cmap=\"gray\", vmin=0, vmax=255)\nplt.subplot(122),plt.imshow(closing, cmap=\"gray\", vmin=0, vmax=255)\nplt.show()\n</pre>  img = cv2.imread('holes.png',0)   kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (5,5))  closing = cv2.morphologyEx(img, cv2.MORPH_CLOSE, kernel)   plt.subplot(121),plt.imshow(img, cmap=\"gray\", vmin=0, vmax=255) plt.subplot(122),plt.imshow(closing, cmap=\"gray\", vmin=0, vmax=255) plt.show() In\u00a0[\u00a0]: Copied! <pre>### seu c\u00f3digo ###\n</pre> ### seu c\u00f3digo ###"},{"location":"aulas/PDI/lab06/Transformada-Hough-morfologia.html#transformada-de-hough","title":"Transformada de Hough\u00b6","text":"<p>A Transformada de Hough \u00e9 uma t\u00e9cnica poderosa para detec\u00e7\u00e3o de padr\u00f5es geom\u00e9tricos em imagens, como linhas e c\u00edrculos. Esta t\u00e9cnica \u00e9 particularmente \u00fatil quando:</p> <ul> <li>Os padr\u00f5es est\u00e3o parcialmente oclusos ou fragmentados</li> <li>H\u00e1 ru\u00eddo significativo na imagem</li> <li>Existem outros objetos ou caracter\u00edsticas na imagem</li> </ul> <p>A transformada funciona mapeando pontos da imagem para um espa\u00e7o de par\u00e2metros, onde os padr\u00f5es podem ser identificados como picos em um acumulador.</p>"},{"location":"aulas/PDI/lab06/Transformada-Hough-morfologia.html#deteccao-de-circulos","title":"DETEC\u00c7\u00c3O DE CIRCULOS\u00b6","text":"<p>Vamos fazer a dete\u00e7\u00e3o de circulos da imagem forma.</p>"},{"location":"aulas/PDI/lab06/Transformada-Hough-morfologia.html#parametros-da-transformada-de-hough-para-circulos","title":"Par\u00e2metros da Transformada de Hough para C\u00edrculos\u00b6","text":"<p>O resultado n\u00e3o ficou bom, pois h\u00e1 muitos falsos positivos detectados, neste caso precisamos alterar os parametros da transformada de hough.</p> <p>Vamos ver o que \u00e9 cada um deles.</p>"},{"location":"aulas/PDI/lab06/Transformada-Hough-morfologia.html#sintaxe","title":"Sintaxe:\u00b6","text":"<p><code>circles=cv2.HoughCircles(image,method=cv2.HOUGH_GRADIENT,dp,minDist,param1,param2,minRadius,maxRadius)</code></p>"},{"location":"aulas/PDI/lab06/Transformada-Hough-morfologia.html#parametros","title":"Par\u00e2metros:\u00b6","text":"<ul> <li>dp: Rela\u00e7\u00e3o entre o tamanho da imagem e o tamanho do acumulador. Um valor maior de dp detecta bordas mais t\u00eanues.</li> <li>minDist: Dist\u00e2ncia m\u00ednima entre os centros dos c\u00edrculos detectados.</li> <li>param1: Valor do gradiente usado para detec\u00e7\u00e3o de bordas (limiar superior para o detector Canny).</li> <li>param2: Limiar do acumulador. Valores mais baixos detectam mais c\u00edrculos (incluindo falsos positivos).</li> <li>minRadius: Raio m\u00ednimo dos c\u00edrculos a serem detectados (em pixels).</li> <li>maxRadius: Raio m\u00e1ximo dos c\u00edrculos a serem detectados (em pixels).</li> </ul>"},{"location":"aulas/PDI/lab06/Transformada-Hough-morfologia.html#desafio-1","title":"DESAFIO 1\u00b6","text":"<p>Fa\u00e7a a altera\u00e7\u00e3o dos parametros para a transformada de Hough afim de detectar apenas os circulos da imagem.</p> <p>Dica: Altere um parametro por vez e analise o resultado.</p>"},{"location":"aulas/PDI/lab06/Transformada-Hough-morfologia.html#desafio-2","title":"DESAFIO 2\u00b6","text":"<p>Desenvolva um pipeline de processamento digital de imagens incluindo Transformada de Hough Circles para detectar moedas espalhadas sobre mesa. Note que o seu sistema deve ser capaz de diferenciar o valor da moeda por sua dimens\u00e3o e contar quantas imagens de cada valor est\u00e3o expostas.</p> <p></p>"},{"location":"aulas/PDI/lab06/Transformada-Hough-morfologia.html#deteccao-de-retas","title":"DETEC\u00c7\u00c3O DE RETAS\u00b6","text":"<p>A detec\u00e7\u00e3o de retas pode ser realizada utilizando a Transformada de Hough para Linhas, implementada nas fun\u00e7\u00f5es cv2.HoughLines() e cv2.HoughLinesP(). A vers\u00e3o probabil\u00edstica (HoughLinesP) melhora a estimativa das linhas detectadas ao considerar apenas pontos significativos.</p>"},{"location":"aulas/PDI/lab06/Transformada-Hough-morfologia.html#sintaxe","title":"Sintaxe:\u00b6","text":"<pre>cv2.HoughLinesP(image, rho, theta, threshold, minLineLength=None, maxLineGap=None)\n</pre>"},{"location":"aulas/PDI/lab06/Transformada-Hough-morfologia.html#parametros","title":"Par\u00e2metros:\u00b6","text":"<ul> <li>image: Imagem de entrada em escala de cinza.</li> <li>rho: Resolu\u00e7\u00e3o da dist\u00e2ncia no acumulador, em pixels.</li> <li>theta: Resolu\u00e7\u00e3o angular no acumulador, em radianos (normalmente 1 grau = \u03c0/180).</li> <li>threshold: Limiar m\u00ednimo de votos no acumulador para validar uma linha.</li> <li>minLineLength: Comprimento m\u00ednimo para considerar um segmento como linha.</li> <li>maxLineGap: Dist\u00e2ncia m\u00e1xima entre pontos para serem considerados na mesma linha.</li> </ul>"},{"location":"aulas/PDI/lab06/Transformada-Hough-morfologia.html#desafio-3","title":"DESAFIO 3\u00b6","text":"<p>Fa\u00e7a a altera\u00e7\u00e3o dos parametros para a transformada de Hough afim de detectar todas as linhas da imagem.</p> <p>Dica: Altere um parametro por vez e analise o resultado.</p>"},{"location":"aulas/PDI/lab06/Transformada-Hough-morfologia.html#transformada-de-hough-e-filtragem-por-angulo","title":"Transformada de Hough e Filtragem por \u00c2ngulo\u00b6","text":"<p>Para aplica\u00e7\u00f5es avan\u00e7adas, podemos filtrar os resultados com base no \u00e2ngulo das linhas detectadas.</p>"},{"location":"aulas/PDI/lab06/Transformada-Hough-morfologia.html#calculo-do-angulo-de-uma-reta","title":"C\u00e1lculo do \u00c2ngulo de uma Reta\u00b6","text":"<p>A Transformada de Hough detecta linhas retas identificando pontos alinhados em uma imagem de bordas. Cada linha detectada \u00e9 representada por dois pontos:</p> <ul> <li>$ (x_1, y_1) $ - Primeiro ponto da linha</li> <li>$ (x_2, y_2) $ - Segundo ponto da linha</li> </ul> <p>A partir desses pontos, podemos calcular o \u00e2ngulo da linha usando a seguinte f\u00f3rmula:</p> <p>Cada linha detectada em <code>HoughLinesP</code> \u00e9 representada por dois pontos $(x_1, y_1)$ e $(x_2, y_2)$. O \u00e2ngulo $\\theta$  da reta pode ser calculado com:</p> <p>$$ \\theta = \\arctan \\left( \\frac{y_2 - y_1}{x_2 - x_1} \\right) $$</p> <p>Para converter para graus:</p> <p>$$ \\theta_{graus} = \\theta \\times \\frac{180}{\\pi} $$</p>"},{"location":"aulas/PDI/lab06/Transformada-Hough-morfologia.html#filtro-de-linhas-por-angulo","title":"Filtro de Linhas por \u00c2ngulo\u00b6","text":"<p>Podemos definir um intervalo de \u00e2ngulos desejado para filtrar as linhas:</p> <ul> <li>Linhas verticais: $\\theta \\approx 90^\\circ$</li> <li>Linhas horizontais: $\\theta \\approx 0^\\circ$ ou $180^\\circ$</li> <li>Linhas inclinadas: qualquer outro intervalo necess\u00e1rio.</li> </ul>"},{"location":"aulas/PDI/lab06/Transformada-Hough-morfologia.html#pseudocodigo","title":"pseudoc\u00f3digo\u00b6","text":"<pre>    for line in lines:\n        x1, y1, x2, y2 = line[0]\n        \n        # Calcular o \u00e2ngulo da linha\n        angle_radianos = np.arctan2(y2 - y1, x2 - x1)\n        angle_graus = np.degrees(angle_radianos)\n\n    \n</pre>"},{"location":"aulas/PDI/lab06/Transformada-Hough-morfologia.html#desafio-4","title":"DESAFIO 4\u00b6","text":"<p>Voc\u00ea recebeu a imagem de uma rodovia e precisa detectar as linhas das faixas de tr\u00e2nsito usando t\u00e9cnicas de processamento de imagem com a Transformada de Hough.</p> <p>Note que o seu sistema deve ser inteligente o suficiente para detectar apenas as faixas de tr\u00e2nsito, ignorando outros segmentos de reta que possam aparecer na imagem. Para isso, ser\u00e1 necess\u00e1rio um pipeline de processamento de imagem adequado. Crie e aplique uma m\u00e1scara para isolar a estrada.</p>"},{"location":"aulas/PDI/lab06/Transformada-Hough-morfologia.html#morfologia-matematica","title":"MORFOLOGIA MATEM\u00c1TICA\u00b6","text":"<p>A morfologia matem\u00e1tica \u00e9 um conjunto de t\u00e9cnicas de processamento de imagens baseadas na teoria dos conjuntos. Estas opera\u00e7\u00f5es s\u00e3o fundamentais para:</p> <ul> <li>Extra\u00e7\u00e3o de componentes de imagens \u00fateis para representa\u00e7\u00e3o e descri\u00e7\u00e3o de formas</li> <li>Pr\u00e9-processamento e p\u00f3s-processamento em tarefas de vis\u00e3o computacional</li> <li>Filtragem, afinamento e poda de regi\u00f5es</li> </ul> <p>As opera\u00e7\u00f5es morfol\u00f3gicas trabalham com dois elementos principais:</p> <ol> <li>Imagem: Geralmente bin\u00e1ria (0s e 1s) ou em escala de cinza</li> <li>Elemento Estruturante: Uma pequena matriz que define como a opera\u00e7\u00e3o afetar\u00e1 a imagem</li> </ol>"},{"location":"aulas/PDI/lab06/Transformada-Hough-morfologia.html#operacoes-basicas","title":"Opera\u00e7\u00f5es B\u00e1sicas\u00b6","text":"<p>As duas opera\u00e7\u00f5es fundamentais da morfologia matem\u00e1tica s\u00e3o:</p> <ul> <li>Dilata\u00e7\u00e3o: Expande as regi\u00f5es claras (1s) da imagem</li> <li>Eros\u00e3o: Reduz as regi\u00f5es claras da imagem</li> </ul> <p>A partir destas opera\u00e7\u00f5es b\u00e1sicas, podemos criar opera\u00e7\u00f5es compostas como:</p> <ul> <li>Abertura: Eros\u00e3o seguida de dilata\u00e7\u00e3o (remove pequenos objetos)</li> <li>Fechamento: Dilata\u00e7\u00e3o seguida de eros\u00e3o (preenche pequenos buracos)</li> </ul>"},{"location":"aulas/PDI/lab06/Transformada-Hough-morfologia.html#dilatacao-binaria","title":"DILATA\u00c7\u00c3O BIN\u00c1RIA\u00b6","text":"<p>\u00c9 uma transforma\u00e7\u00e3o morfol\u00f3gica que combina dois conjuntos usando adi\u00e7\u00e3o vetorial. Como o nome diz, o resultado ser\u00e1 uma imagem \u201cengordada\u201d.</p>"},{"location":"aulas/PDI/lab06/Transformada-Hough-morfologia.html#detectando-contorno-com-dilatacao","title":"Detectando contorno com dilata\u00e7\u00e3o\u00b6","text":""},{"location":"aulas/PDI/lab06/Transformada-Hough-morfologia.html#elementos-estruturantes","title":"Elementos Estruturantes\u00b6","text":"<p>O elemento estruturante (tamb\u00e9m chamado de kernel ou m\u00e1scara) \u00e9 uma matriz pequena que define como as opera\u00e7\u00f5es morfol\u00f3gicas afetar\u00e3o a imagem. Ele funciona como uma \"sonda\" que examina cada pixel da imagem e sua vizinhan\u00e7a para determinar o valor do pixel na imagem de sa\u00edda.</p> <p>Caracter\u00edsticas importantes:</p> <ul> <li>Possui uma origem (ponto central)</li> <li>Tem uma forma espec\u00edfica (ret\u00e2ngulo, c\u00edrculo, cruz, etc.)</li> <li>Possui um tamanho que determina sua \u00e1rea de influ\u00eancia</li> </ul> <p>A escolha do elemento estruturante \u00e9 impacta o resultado da opera\u00e7\u00e3o morfol\u00f3gica:</p> <ul> <li>Forma: Influencia a dire\u00e7\u00e3o e o padr\u00e3o da transforma\u00e7\u00e3o</li> <li>Tamanho: Determina a escala da transforma\u00e7\u00e3o (objetos menores que o elemento estruturante podem ser removidos)</li> <li>Orienta\u00e7\u00e3o: Pode ser usado para detectar caracter\u00edsticas direcionais</li> </ul>"},{"location":"aulas/PDI/lab06/Transformada-Hough-morfologia.html#dicas-para-escolher-o-elemento-estruturante","title":"Dicas para escolher o Elemento Estruturante\u00b6","text":"<p>OpenCV oferece tr\u00eas formas b\u00e1sicas:</p> <ul> <li><p>Retangular: <code>cv2.MORPH_RECT</code></p> </li> <li><p>El\u00edptico: <code>cv2.MORPH_ELLIPSE</code></p> </li> <li><p>Cruz: <code>cv2.MORPH_CROSS</code></p> </li> <li><p>Retangular: Bom para opera\u00e7\u00f5es gerais, preserva bordas horizontais e verticais</p> </li> <li><p>El\u00edptico: Produz resultados mais suaves, sem cantos acentuados</p> </li> <li><p>Cruz: Preserva linhas finas horizontais e verticais</p> </li> </ul> <p>Experimenta\u00e7\u00e3o \u00e9 fundamental para encontrar o elemento estruturante ideal para cada aplica\u00e7\u00e3o</p>"},{"location":"aulas/PDI/lab06/Transformada-Hough-morfologia.html#erosao-binaria","title":"EROS\u00c3O BIN\u00c1RIA\u00b6","text":"<p>A eros\u00e3o basicamente encolhe uma imagem e pode ser vista como uma transforma\u00e7\u00e3o morfol\u00f3gica que combina dois conjuntos usando vetores de subtra\u00e7\u00e3o. Ela \u00e9 expressa como a interse\u00e7\u00e3o de A e B.</p>"},{"location":"aulas/PDI/lab06/Transformada-Hough-morfologia.html#abertura-binaria","title":"ABERTURA BIN\u00c1RIA\u00b6","text":"<p>A abertura em geral suaviza o contorno de uma imagem, quebra estreitos e elimina proemin\u00eancias delgadas, a opera\u00e7\u00e3o de abertura e usada tamb\u00e9m para remover ru\u00eddos da imagem.</p>"},{"location":"aulas/PDI/lab06/Transformada-Hough-morfologia.html#fechamento-binario","title":"FECHAMENTO BIN\u00c1RIO\u00b6","text":"<p>O fechamento funde pequenos quebras e alargas golfos estreitos elimina pequenos orif\u00edcios. Se uma abertura cria pequenos vazios na imagem, um fechamento ir\u00e1 preencher ou fechar os vazios, estas opera\u00e7\u00f5es podem remover muitos dos pixels brancos com ru\u00eddos, ou seja basicamente ele e igual a abertura s\u00f3 que primeiramente e feita a dilata\u00e7\u00e3o e ap\u00f3s e feita a eros\u00e3o.</p>"},{"location":"aulas/PDI/lab06/Transformada-Hough-morfologia.html#desafio-5","title":"DESAFIO 5\u00b6","text":"<p>Utilizando a opera\u00e7\u00e3o abertura e depois a opera\u00e7\u00e3o de fechamento bin\u00e1rio, \u00e9 esperado que a imagem volte ao original? Por que?</p>"},{"location":"aulas/PDI/lab06/emulatecla%20-%20Copia.html","title":"emulatecla   Copia","text":"In\u00a0[\u00a0]: Copied! <pre># Programa simples com camera webcam e opencv\\n\nimport math\nimport cv2\nimport os.path\nimport numpy as np\n</pre> # Programa simples com camera webcam e opencv\\n import math import cv2 import os.path import numpy as np In\u00a0[\u00a0]: Copied! <pre>def image_da_webcam(img):\n    #-&gt;&gt;&gt; !!!! FECHE A JANELA COM A TECLA ESC !!!! &lt;&lt;&lt;&lt;-\n    #deve receber a imagem da camera e retornar uma imagems filtrada.\n\n    gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n    gray = cv2.medianBlur(gray,5)\n    saida = cv2.cvtColor(img,cv2.COLOR_BGR2RGB)\n    img_hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n    \n    #detecta os circulos maiores e circula eles\n    circles = cv2.HoughCircles(gray,cv2.HOUGH_GRADIENT,1,20,param1=30,param2=80,minRadius=100,maxRadius=0)\n    circulosDetectados = np.uint16(np.around(circles))\n    for (x, y, r) in circulosDetectados[0,:]:\n        cv2.circle(saida,(x, y), r,(0,0,0),3)\n    \n    # Defini\u00e7\u00e3o dos valores minimo e max da mascara azul\n    blue_lower_hsv = np.array([70, 150, 210])\n    blue_upper_hsv = np.array([100, 255, 240])\n    \n    # Defini\u00e7\u00e3o dos valores minimo e max da mascara vermelha\n    red_lower_hsv = np.array([0, 220, 160])\n    red_upper_hsv = np.array([20, 255, 255])\n\n    # Aplicando a m\u00e1scara azul e vermelha na imagem\n    blue_mask_hsv = cv2.inRange(img_hsv, blue_lower_hsv, blue_upper_hsv)\n    red_mask_hsv = cv2.inRange(img_hsv, red_lower_hsv, red_upper_hsv)\n    both_mask_hsv = cv2.bitwise_or(blue_mask_hsv, red_mask_hsv)\n    \n    # Identificando os contornos para uso posterior de calculo da \u00e1rea\n    contornos, _ = cv2.findContours(both_mask_hsv, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n    mascara_rgb = cv2.cvtColor(both_mask_hsv, cv2.COLOR_GRAY2RGB)\n    \n    # For para calcular a \u00e1rea e o CM, e imprimir na imagem de acordo com a posi\u00e7\u00e3o do eixo X do CM,\\n\",\n    # para que cada informa\u00e7\u00e3o fique do lado do circulo correspondente\\n\",\n    cxV = []\n    cyV = []\n    for i in contornos:\n        area = cv2.contourArea(i)\n        M = cv2.moments(i)\n        cx = int(M['m10']/M['m00'])\n        cy = int(M['m01']/M['m00'])\n        cxV.append(cx)\n        cyV.append(cy)\n\n        tamnho = 20\n        cor = (0,0,0)\n        cv2.line(saida,(cx - tamnho,cy),(cx + tamnho,cy),cor,5)\n        cv2.line(saida,(cx,cy - tamnho),(cx, cy + tamnho),cor,5)\n        fonte = cv2.FONT_HERSHEY_SIMPLEX\n        texto = cx, cy, area\n        if cx &lt;200:\n              origem = (cx+150,cy)\n        else:\n              origem = (cx-470,cy)\n    \n        cv2.putText(saida, str(texto), origem, fonte,1,(0,0,0),2,cv2.LINE_AA)\n   \n        # Tra\u00e7a a reta\n        cor = (0, 0, 0)\n        vetorTamanho = len(cxV)\n        cv2.line(saida,(cxV[0],cyV[0]), (cxV[vetorTamanho-1], cyV[vetorTamanho-1]),cor,5)\n    \n        # Calcula e imprime o \u00e2ngulo da reta\\n\",\n        fonte = cv2.FONT_HERSHEY_SIMPLEX\n        cxT = cxV[0]-cxV[vetorTamanho-1]\n        cyT = cyV[0]-cyV[vetorTamanho-1]\n\n        angulo = math.atan2(cyV[0], cyV[vetorTamanho-1]) - math.atan2(cxV[0], cxV[vetorTamanho-1])\n        texto = str(round(math.degrees(angulo), 2))\n        origem = (cxT-100,cyT-80)\n        cv2.putText(saida, texto, origem, fonte,1,(0,0,0),2,cv2.LINE_AA)\n    \n        return saida\n</pre> def image_da_webcam(img):     #-&gt;&gt;&gt; !!!! FECHE A JANELA COM A TECLA ESC !!!! &lt;&lt;&lt;&lt;-     #deve receber a imagem da camera e retornar uma imagems filtrada.      gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)     gray = cv2.medianBlur(gray,5)     saida = cv2.cvtColor(img,cv2.COLOR_BGR2RGB)     img_hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)          #detecta os circulos maiores e circula eles     circles = cv2.HoughCircles(gray,cv2.HOUGH_GRADIENT,1,20,param1=30,param2=80,minRadius=100,maxRadius=0)     circulosDetectados = np.uint16(np.around(circles))     for (x, y, r) in circulosDetectados[0,:]:         cv2.circle(saida,(x, y), r,(0,0,0),3)          # Defini\u00e7\u00e3o dos valores minimo e max da mascara azul     blue_lower_hsv = np.array([70, 150, 210])     blue_upper_hsv = np.array([100, 255, 240])          # Defini\u00e7\u00e3o dos valores minimo e max da mascara vermelha     red_lower_hsv = np.array([0, 220, 160])     red_upper_hsv = np.array([20, 255, 255])      # Aplicando a m\u00e1scara azul e vermelha na imagem     blue_mask_hsv = cv2.inRange(img_hsv, blue_lower_hsv, blue_upper_hsv)     red_mask_hsv = cv2.inRange(img_hsv, red_lower_hsv, red_upper_hsv)     both_mask_hsv = cv2.bitwise_or(blue_mask_hsv, red_mask_hsv)          # Identificando os contornos para uso posterior de calculo da \u00e1rea     contornos, _ = cv2.findContours(both_mask_hsv, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)     mascara_rgb = cv2.cvtColor(both_mask_hsv, cv2.COLOR_GRAY2RGB)          # For para calcular a \u00e1rea e o CM, e imprimir na imagem de acordo com a posi\u00e7\u00e3o do eixo X do CM,\\n\",     # para que cada informa\u00e7\u00e3o fique do lado do circulo correspondente\\n\",     cxV = []     cyV = []     for i in contornos:         area = cv2.contourArea(i)         M = cv2.moments(i)         cx = int(M['m10']/M['m00'])         cy = int(M['m01']/M['m00'])         cxV.append(cx)         cyV.append(cy)          tamnho = 20         cor = (0,0,0)         cv2.line(saida,(cx - tamnho,cy),(cx + tamnho,cy),cor,5)         cv2.line(saida,(cx,cy - tamnho),(cx, cy + tamnho),cor,5)         fonte = cv2.FONT_HERSHEY_SIMPLEX         texto = cx, cy, area         if cx &lt;200:               origem = (cx+150,cy)         else:               origem = (cx-470,cy)              cv2.putText(saida, str(texto), origem, fonte,1,(0,0,0),2,cv2.LINE_AA)             # Tra\u00e7a a reta         cor = (0, 0, 0)         vetorTamanho = len(cxV)         cv2.line(saida,(cxV[0],cyV[0]), (cxV[vetorTamanho-1], cyV[vetorTamanho-1]),cor,5)              # Calcula e imprime o \u00e2ngulo da reta\\n\",         fonte = cv2.FONT_HERSHEY_SIMPLEX         cxT = cxV[0]-cxV[vetorTamanho-1]         cyT = cyV[0]-cyV[vetorTamanho-1]          angulo = math.atan2(cyV[0], cyV[vetorTamanho-1]) - math.atan2(cxV[0], cxV[vetorTamanho-1])         texto = str(round(math.degrees(angulo), 2))         origem = (cxT-100,cyT-80)         cv2.putText(saida, texto, origem, fonte,1,(0,0,0),2,cv2.LINE_AA)              return saida In\u00a0[\u00a0]: Copied! <pre>cv2.namedWindow(\"\\preview\")\nvc = cv2.VideoCapture(0)\n</pre> cv2.namedWindow(\"\\preview\") vc = cv2.VideoCapture(0) In\u00a0[\u00a0]: Copied! <pre>if vc.isOpened(): # try to get the first frame\n    rval, frame = vc.read()\nelse:\n    rval = False\n</pre> if vc.isOpened(): # try to get the first frame     rval, frame = vc.read() else:     rval = False In\u00a0[\u00a0]: Copied! <pre>while rval:\n    img = image_da_webcam(frame)\n    \n    cv2.imshow(\"\\preview\", img)\n    rval, frame = vc.read()\n    key = cv2.waitKey(20)\n    if key == 27: # exit on ESC\n        break\n</pre> while rval:     img = image_da_webcam(frame)          cv2.imshow(\"\\preview\", img)     rval, frame = vc.read()     key = cv2.waitKey(20)     if key == 27: # exit on ESC         break In\u00a0[\u00a0]: Copied! <pre>cv2.destroyWindow(\"\\preview\")\nvc.release()\n</pre> cv2.destroyWindow(\"\\preview\") vc.release()"},{"location":"aulas/PDI/lab06/emulatecla.html","title":"Emulatecla","text":"In\u00a0[\u00a0]: Copied! <p>Programa simples com camera webcam e opencv que emula precionamento de teclas</p> In\u00a0[\u00a0]: Copied! <pre>import cv2\nimport os,sys, os.path\nimport numpy as np\n</pre> import cv2 import os,sys, os.path import numpy as np In\u00a0[\u00a0]: Copied! <pre>#importes para emular precionamento de teclas\nfrom pynput.keyboard import Key, Controller\nimport pynput\nimport time\nimport random\n</pre> #importes para emular precionamento de teclas from pynput.keyboard import Key, Controller import pynput import time import random In\u00a0[\u00a0]: Copied! <pre>keys = [\n    #Key.up,                                 # UP\n    #Key.down,                               # DOWN\n    #Key.left,                               # LEFT\n    #Key.right,                              # RIGHT\n    pynput.keyboard.KeyCode.from_char('S'),  # A\n    pynput.keyboard.KeyCode.from_char('W'),  # B\n    pynput.keyboard.KeyCode.from_char('a'),  # X\n    #Key.enter,                              # START\n    #Key.shift_r,                            # SELECT\n]\n</pre> keys = [     #Key.up,                                 # UP     #Key.down,                               # DOWN     #Key.left,                               # LEFT     #Key.right,                              # RIGHT     pynput.keyboard.KeyCode.from_char('S'),  # A     pynput.keyboard.KeyCode.from_char('W'),  # B     pynput.keyboard.KeyCode.from_char('a'),  # X     #Key.enter,                              # START     #Key.shift_r,                            # SELECT ] In\u00a0[\u00a0]: Copied! <pre>\n</pre> In\u00a0[\u00a0]: Copied! <pre>#Inicializa o controle \nkeyboard = Controller()\n</pre> #Inicializa o controle  keyboard = Controller() In\u00a0[\u00a0]: Copied! <pre>\n</pre> In\u00a0[\u00a0]: Copied! <pre>#filtro baixo\nimage_lower_hsv1 = np.array([120,130,10])\nimage_upper_hsv1 = np.array([180,255,255])\n#filtro alto\nimage_lower_hsv2 = np.array([0,130,100])\nimage_upper_hsv2 = np.array([30,255,255])\n</pre> #filtro baixo image_lower_hsv1 = np.array([120,130,10]) image_upper_hsv1 = np.array([180,255,255]) #filtro alto image_lower_hsv2 = np.array([0,130,100]) image_upper_hsv2 = np.array([30,255,255]) In\u00a0[\u00a0]: Copied! <pre>\n</pre> In\u00a0[\u00a0]: Copied! <pre>def filtro_de_cor(img_bgr, low_hsv, high_hsv):\n    \"\"\" retorna a imagem filtrada\"\"\"\n    img = cv2.cvtColor(img_bgr,cv2.COLOR_BGR2HSV)\n    mask = cv2.inRange(img, low_hsv, high_hsv)\n    return mask \n</pre> def filtro_de_cor(img_bgr, low_hsv, high_hsv):     \"\"\" retorna a imagem filtrada\"\"\"     img = cv2.cvtColor(img_bgr,cv2.COLOR_BGR2HSV)     mask = cv2.inRange(img, low_hsv, high_hsv)     return mask  In\u00a0[\u00a0]: Copied! <pre>def mascara_or(mask1, mask2):\n\n    \"\"\" retorna a mascara or\"\"\"\n    mask = cv2.bitwise_or(mask1, mask2)\n    return mask\n</pre> def mascara_or(mask1, mask2):      \"\"\" retorna a mascara or\"\"\"     mask = cv2.bitwise_or(mask1, mask2)     return mask In\u00a0[\u00a0]: Copied! <pre>def mascara_and(mask1, mask2):\n     \"\"\" retorna a mascara and\"\"\"\n     mask = cv2.bitwise_and(mask1, mask2)\n     \n     return mask\n</pre> def mascara_and(mask1, mask2):      \"\"\" retorna a mascara and\"\"\"      mask = cv2.bitwise_and(mask1, mask2)            return mask In\u00a0[\u00a0]: Copied! <pre>def desenha_cruz(img, cX,cY, size, color):\n     \"\"\" faz a cruz no ponto cx cy\"\"\"\n     cv2.line(img,(cX - size,cY),(cX + size,cY),color,5)\n     cv2.line(img,(cX,cY - size),(cX, cY + size),color,5)    \n</pre> def desenha_cruz(img, cX,cY, size, color):      \"\"\" faz a cruz no ponto cx cy\"\"\"      cv2.line(img,(cX - size,cY),(cX + size,cY),color,5)      cv2.line(img,(cX,cY - size),(cX, cY + size),color,5)     In\u00a0[\u00a0]: Copied! <pre>def escreve_texto(img, text, origem, color):\n     \"\"\" faz a cruz no ponto cx cy\"\"\"\n \n     font = cv2.FONT_HERSHEY_SIMPLEX\n     \n     cv2.putText(img, str(text), origem, font,1,color,2,cv2.LINE_AA)\n</pre> def escreve_texto(img, text, origem, color):      \"\"\" faz a cruz no ponto cx cy\"\"\"        font = cv2.FONT_HERSHEY_SIMPLEX            cv2.putText(img, str(text), origem, font,1,color,2,cv2.LINE_AA) In\u00a0[\u00a0]: Copied! <pre>\n</pre> In\u00a0[\u00a0]: Copied! <pre>def image_da_webcam(img):\n    \"\"\"\n    -&gt;&gt;&gt; !!!! FECHE A JANELA COM A TECLA ESC !!!! &lt;&lt;&lt;&lt;-\n        deve receber a imagem da camera e retornar uma imagems filtrada.\n    \"\"\"  \n    mask_hsv1 = filtro_de_cor(img, image_lower_hsv1, image_upper_hsv1)\n    mask_hsv2 = filtro_de_cor(img, image_lower_hsv2, image_upper_hsv2)\n    \n    mask_hsv = mascara_or(mask_hsv1, mask_hsv2)\n    \n    contornos, _ = cv2.findContours(mask_hsv, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE) \n\n    mask_rgb = cv2.cvtColor(mask_hsv, cv2.COLOR_GRAY2RGB) \n    contornos_img = mask_rgb.copy()\n    \n    maior = None\n    maior_area = 0\n    for c in contornos:\n        area = cv2.contourArea(c)\n        \n        if area &gt; maior_area:\n            maior_area = area\n            maior = c\n            \n    escreve_texto(contornos_img, maior_area, (250,250), (255,255,0))\n    if maior_area &gt;=20000:\n        #escreve no teclado\n        texto = 'Perto W'\n        origem = (200,50)\n        escreve_texto(contornos_img, texto, origem, (0,0,255))\n        print('Tecla: ', keys[1])\n        keyboard.press(keys[1])\n        time.sleep(0.1)\n        keyboard.release(keys[1])\n    elif maior_area &lt;= 2000:\n        texto = 'Muito longe nao escreve'\n        origem = (200,50)\n        escreve_texto(contornos_img, texto, origem, (0,0,255))\n    else:\n        texto = 'Longe S'\n        origem = (200,50)\n        escreve_texto(contornos_img, texto, origem, (0,0,255))\n        print('Tecla: ', keys[0])\n        keyboard.press(keys[0])\n        time.sleep(0.1)\n        keyboard.release(keys[0])\n    \n    M = cv2.moments(maior)\n\n    # Verifica se existe alguma para calcular, se sim calcula e exibe no display\n    if M[\"m00\"] != 0:\n        cX = int(M[\"m10\"] / M[\"m00\"])\n        cY = int(M[\"m01\"] / M[\"m00\"])\n        \n        cv2.drawContours(contornos_img, [maior], -1, [255, 0, 0], 5)\n       \n        #faz a cruz no centro de massa\n        desenha_cruz(contornos_img, cX,cY, 20, (0,0,255))\n\n        \n        # Para escrever vamos definir uma fonte \n        texto = cY , cX\n        origem = (0,50)\n        escreve_texto(contornos_img, texto, origem, (0,255,0))\n            \n    else:\n    # se n\u00e3o existe nada para segmentar\n        cX, cY = 0, 0\n        # Para escrever vamos definir uma fonte \n        texto = ' '\n        origem = (0,50)\n        escreve_texto(contornos_img, texto, origem, (0,0,255))\n    \n\n\n    return contornos_img\n</pre> def image_da_webcam(img):     \"\"\"     -&gt;&gt;&gt; !!!! FECHE A JANELA COM A TECLA ESC !!!! &lt;&lt;&lt;&lt;-         deve receber a imagem da camera e retornar uma imagems filtrada.     \"\"\"       mask_hsv1 = filtro_de_cor(img, image_lower_hsv1, image_upper_hsv1)     mask_hsv2 = filtro_de_cor(img, image_lower_hsv2, image_upper_hsv2)          mask_hsv = mascara_or(mask_hsv1, mask_hsv2)          contornos, _ = cv2.findContours(mask_hsv, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)       mask_rgb = cv2.cvtColor(mask_hsv, cv2.COLOR_GRAY2RGB)      contornos_img = mask_rgb.copy()          maior = None     maior_area = 0     for c in contornos:         area = cv2.contourArea(c)                  if area &gt; maior_area:             maior_area = area             maior = c                  escreve_texto(contornos_img, maior_area, (250,250), (255,255,0))     if maior_area &gt;=20000:         #escreve no teclado         texto = 'Perto W'         origem = (200,50)         escreve_texto(contornos_img, texto, origem, (0,0,255))         print('Tecla: ', keys[1])         keyboard.press(keys[1])         time.sleep(0.1)         keyboard.release(keys[1])     elif maior_area &lt;= 2000:         texto = 'Muito longe nao escreve'         origem = (200,50)         escreve_texto(contornos_img, texto, origem, (0,0,255))     else:         texto = 'Longe S'         origem = (200,50)         escreve_texto(contornos_img, texto, origem, (0,0,255))         print('Tecla: ', keys[0])         keyboard.press(keys[0])         time.sleep(0.1)         keyboard.release(keys[0])          M = cv2.moments(maior)      # Verifica se existe alguma para calcular, se sim calcula e exibe no display     if M[\"m00\"] != 0:         cX = int(M[\"m10\"] / M[\"m00\"])         cY = int(M[\"m01\"] / M[\"m00\"])                  cv2.drawContours(contornos_img, [maior], -1, [255, 0, 0], 5)                 #faz a cruz no centro de massa         desenha_cruz(contornos_img, cX,cY, 20, (0,0,255))                   # Para escrever vamos definir uma fonte          texto = cY , cX         origem = (0,50)         escreve_texto(contornos_img, texto, origem, (0,255,0))                  else:     # se n\u00e3o existe nada para segmentar         cX, cY = 0, 0         # Para escrever vamos definir uma fonte          texto = ' '         origem = (0,50)         escreve_texto(contornos_img, texto, origem, (0,0,255))            return contornos_img In\u00a0[\u00a0]: Copied! <pre>cv2.namedWindow(\"preview\")\n# define a entrada de video para webcam\nvc = cv2.VideoCapture(0)\n</pre> cv2.namedWindow(\"preview\") # define a entrada de video para webcam vc = cv2.VideoCapture(0) <p>vc = cv2.VideoCapture(\"video.mp4\") # para ler um video mp4</p> In\u00a0[\u00a0]: Copied! <pre>#configura o tamanho da janela \nvc.set(cv2.CAP_PROP_FRAME_WIDTH, 640)\nvc.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)\n</pre> #configura o tamanho da janela  vc.set(cv2.CAP_PROP_FRAME_WIDTH, 640) vc.set(cv2.CAP_PROP_FRAME_HEIGHT, 480) In\u00a0[\u00a0]: Copied! <pre>if vc.isOpened(): # try to get the first frame\n    rval, frame = vc.read()\nelse:\n    rval = False\n</pre> if vc.isOpened(): # try to get the first frame     rval, frame = vc.read() else:     rval = False In\u00a0[\u00a0]: Copied! <pre>while rval:\n    \n    img = image_da_webcam(frame) # passa o frame para a fun\u00e7\u00e3o imagem_da_webcam e recebe em img imagem tratada\n\n\n\n    cv2.imshow(\"preview\", img)\n    cv2.imshow(\"original\", frame)\n    rval, frame = vc.read()\n    key = cv2.waitKey(20)\n    if key == 27: # exit on ESC\n        break\n</pre> while rval:          img = image_da_webcam(frame) # passa o frame para a fun\u00e7\u00e3o imagem_da_webcam e recebe em img imagem tratada        cv2.imshow(\"preview\", img)     cv2.imshow(\"original\", frame)     rval, frame = vc.read()     key = cv2.waitKey(20)     if key == 27: # exit on ESC         break In\u00a0[\u00a0]: Copied! <pre>cv2.destroyWindow(\"preview\")\nvc.release()\n</pre> cv2.destroyWindow(\"preview\") vc.release()"},{"location":"aulas/PDI/lab06/motion.html","title":"Motion","text":"In\u00a0[\u00a0]: Copied! In\u00a0[\u00a0]: Copied! <pre>import cv2\nfrom datetime import datetime\n</pre> import cv2 from datetime import datetime In\u00a0[\u00a0]: Copied! <pre>BLUR_KERNEL_P0 = (21, 21)\nBLUR_KERNEL_P1 = (11, 11)\nLEARNING_RATE = 0.001\nMIN_CONTOUR_AREA = 625\n</pre> BLUR_KERNEL_P0 = (21, 21) BLUR_KERNEL_P1 = (11, 11) LEARNING_RATE = 0.001 MIN_CONTOUR_AREA = 625 In\u00a0[\u00a0]: Copied! <pre>feed = cv2.VideoCapture(\"people-walking.mp4\")\n</pre> feed = cv2.VideoCapture(\"people-walking.mp4\") In\u00a0[\u00a0]: Copied! <pre>backSub = cv2.createBackgroundSubtractorKNN()\n#backSub = cv.createBackgroundSubtractorMOG2()\n</pre> backSub = cv2.createBackgroundSubtractorKNN() #backSub = cv.createBackgroundSubtractorMOG2() In\u00a0[\u00a0]: Copied! <pre>while True:\n    (grabbed, frame) = feed.read()\n\n    if not grabbed:\n        break\n\n    frame_blured = cv2.GaussianBlur(frame, BLUR_KERNEL_P0, 0)\n#    backSubmask = backSub.apply(frame_blured, learningRate=LEARNING_RATE)\n    backSubmask = backSub.apply(frame_blured)\n\n    thresh = cv2.GaussianBlur(backSubmask, BLUR_KERNEL_P1, 0)\n    thresh = cv2.dilate(thresh, None, iterations=2)\n\n    (cnts, _) = cv2.findContours(\n        thresh.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE\n    )\n\n    area_in_motion = 0\n    for cnt in cnts:\n        area = cv2.contourArea(cnt)\n        if  area &lt; MIN_CONTOUR_AREA:\n            continue\n\n        area_in_motion += area\n        (x, y, w, h) = cv2.boundingRect(cnt)\n        cv2.rectangle(frame, (x, y), (x+w, y+h), (128, 255, 255), 2)\n\n    cv2.putText(\n        frame, datetime.now().strftime(\"%A %d %B %Y %I:%M:%S%p\"),\n        (10, frame.shape[0] - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.35, (0, 0, 255), 1\n    )\n    # Show results\n    cv2.imshow(\"Feed\", frame)\n    cv2.imshow(\"Thresh\", thresh)\n\n    # Wait for key 'ESC' to quit\n    key = cv2.waitKey(1) &amp; 0xFF\n    if key == 27:\n        break\n</pre> while True:     (grabbed, frame) = feed.read()      if not grabbed:         break      frame_blured = cv2.GaussianBlur(frame, BLUR_KERNEL_P0, 0) #    backSubmask = backSub.apply(frame_blured, learningRate=LEARNING_RATE)     backSubmask = backSub.apply(frame_blured)      thresh = cv2.GaussianBlur(backSubmask, BLUR_KERNEL_P1, 0)     thresh = cv2.dilate(thresh, None, iterations=2)      (cnts, _) = cv2.findContours(         thresh.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE     )      area_in_motion = 0     for cnt in cnts:         area = cv2.contourArea(cnt)         if  area &lt; MIN_CONTOUR_AREA:             continue          area_in_motion += area         (x, y, w, h) = cv2.boundingRect(cnt)         cv2.rectangle(frame, (x, y), (x+w, y+h), (128, 255, 255), 2)      cv2.putText(         frame, datetime.now().strftime(\"%A %d %B %Y %I:%M:%S%p\"),         (10, frame.shape[0] - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.35, (0, 0, 255), 1     )     # Show results     cv2.imshow(\"Feed\", frame)     cv2.imshow(\"Thresh\", thresh)      # Wait for key 'ESC' to quit     key = cv2.waitKey(1) &amp; 0xFF     if key == 27:         break In\u00a0[\u00a0]: Copied! <pre># That's how you exit\nfeed.release()\ncv2.destroyAllWindows()\n</pre> # That's how you exit feed.release() cv2.destroyAllWindows()"},{"location":"aulas/PDI/lab06/sol_Transformada-Hough-morfologia.html","title":"sol Transformada Hough morfologia","text":"<p>Objetivos da aula:</p> <ul> <li>Conhecer e praticar a Transformada de Hough para linhas e circulos</li> <li>conhecer e praticar com os operadores de dilata\u00e7\u00e3o e eros\u00e3o</li> <li>conhecer e praticar com os operadores de abertura e fechamento</li> </ul> In\u00a0[\u00a0]: Copied! <pre>####----- FAZENDO O DOWNLOAD DAS IMAGENS DO RESPOSIT\u00d3RIO, APENAS PARA FACILITAR -----#####\n## SE ESTIVER RODANDO EM SUA M\u00c1QUINA LOCAL N\u00c3O PRECISA RODAR ESSA CELULA ##\n\n\n!wget https://raw.githubusercontent.com/arnaldojr/cognitivecomputing/master/material/aulas/PDI/lab06/coins.png /content\n!wget https://raw.githubusercontent.com/arnaldojr/cognitivecomputing/master/material/aulas/PDI/lab06/corredor.png /content\n!wget https://raw.githubusercontent.com/arnaldojr/cognitivecomputing/master/material/aulas/PDI/lab06/dilata\u00e7\u00e3o.gif /content\n!wget https://raw.githubusercontent.com/arnaldojr/cognitivecomputing/master/material/aulas/PDI/lab06/erosao.gif /content\n!wget https://raw.githubusercontent.com/arnaldojr/cognitivecomputing/master/material/aulas/PDI/lab06/formas.png /content\n!wget https://raw.githubusercontent.com/arnaldojr/cognitivecomputing/master/material/aulas/PDI/lab06/formas_contorno.png /content\n!wget https://raw.githubusercontent.com/arnaldojr/cognitivecomputing/master/material/aulas/PDI/lab06/formas_contornor.png /content\n!wget https://raw.githubusercontent.com/arnaldojr/cognitivecomputing/master/material/aulas/PDI/lab06/j-noise.png /content\n!wget https://raw.githubusercontent.com/arnaldojr/cognitivecomputing/master/material/aulas/PDI/lab06/j.png /content\n!wget https://raw.githubusercontent.com/arnaldojr/cognitivecomputing/master/material/aulas/PDI/lab06/holes.png /content\n!wget https://raw.githubusercontent.com/arnaldojr/cognitivecomputing/master/material/aulas/PDI/lab06/melancia_filtrada.png /content\n!wget https://raw.githubusercontent.com/arnaldojr/cognitivecomputing/master/material/aulas/PDI/lab06/melancia_filtrada_rgb.png /content\n!wget https://raw.githubusercontent.com/arnaldojr/cognitivecomputing/master/material/aulas/PDI/lab06/moeda1.jpg /content\n!wget https://raw.githubusercontent.com/arnaldojr/cognitivecomputing/master/material/aulas/PDI/lab06/pessoas-gif.gif /content\n!wget https://raw.githubusercontent.com/arnaldojr/cognitivecomputing/master/material/aulas/PDI/lab06/rua.png /content\n!wget https://raw.githubusercontent.com/arnaldojr/cognitivecomputing/master/material/aulas/PDI/lab06/sala.jpg /content\n!wget https://raw.githubusercontent.com/arnaldojr/cognitivecomputing/master/material/aulas/PDI/lab06/sala1.jpg /content\n!wget https://raw.githubusercontent.com/arnaldojr/cognitivecomputing/master/material/aulas/PDI/lab06/sala2.jpg /content\n!wget https://raw.githubusercontent.com/arnaldojr/cognitivecomputing/master/material/aulas/PDI/lab06/sala3.jpg /content\n!wget https://raw.githubusercontent.com/arnaldojr/cognitivecomputing/master/material/aulas/PDI/lab06/sala_res.png /content\n!wget https://raw.githubusercontent.com/arnaldojr/cognitivecomputing/master/material/aulas/PDI/lab06/people-walking.mp4 /content\n</pre>   ####----- FAZENDO O DOWNLOAD DAS IMAGENS DO RESPOSIT\u00d3RIO, APENAS PARA FACILITAR -----##### ## SE ESTIVER RODANDO EM SUA M\u00c1QUINA LOCAL N\u00c3O PRECISA RODAR ESSA CELULA ##   !wget https://raw.githubusercontent.com/arnaldojr/cognitivecomputing/master/material/aulas/PDI/lab06/coins.png /content !wget https://raw.githubusercontent.com/arnaldojr/cognitivecomputing/master/material/aulas/PDI/lab06/corredor.png /content !wget https://raw.githubusercontent.com/arnaldojr/cognitivecomputing/master/material/aulas/PDI/lab06/dilata\u00e7\u00e3o.gif /content !wget https://raw.githubusercontent.com/arnaldojr/cognitivecomputing/master/material/aulas/PDI/lab06/erosao.gif /content !wget https://raw.githubusercontent.com/arnaldojr/cognitivecomputing/master/material/aulas/PDI/lab06/formas.png /content !wget https://raw.githubusercontent.com/arnaldojr/cognitivecomputing/master/material/aulas/PDI/lab06/formas_contorno.png /content !wget https://raw.githubusercontent.com/arnaldojr/cognitivecomputing/master/material/aulas/PDI/lab06/formas_contornor.png /content !wget https://raw.githubusercontent.com/arnaldojr/cognitivecomputing/master/material/aulas/PDI/lab06/j-noise.png /content !wget https://raw.githubusercontent.com/arnaldojr/cognitivecomputing/master/material/aulas/PDI/lab06/j.png /content !wget https://raw.githubusercontent.com/arnaldojr/cognitivecomputing/master/material/aulas/PDI/lab06/holes.png /content !wget https://raw.githubusercontent.com/arnaldojr/cognitivecomputing/master/material/aulas/PDI/lab06/melancia_filtrada.png /content !wget https://raw.githubusercontent.com/arnaldojr/cognitivecomputing/master/material/aulas/PDI/lab06/melancia_filtrada_rgb.png /content !wget https://raw.githubusercontent.com/arnaldojr/cognitivecomputing/master/material/aulas/PDI/lab06/moeda1.jpg /content !wget https://raw.githubusercontent.com/arnaldojr/cognitivecomputing/master/material/aulas/PDI/lab06/pessoas-gif.gif /content !wget https://raw.githubusercontent.com/arnaldojr/cognitivecomputing/master/material/aulas/PDI/lab06/rua.png /content !wget https://raw.githubusercontent.com/arnaldojr/cognitivecomputing/master/material/aulas/PDI/lab06/sala.jpg /content !wget https://raw.githubusercontent.com/arnaldojr/cognitivecomputing/master/material/aulas/PDI/lab06/sala1.jpg /content !wget https://raw.githubusercontent.com/arnaldojr/cognitivecomputing/master/material/aulas/PDI/lab06/sala2.jpg /content !wget https://raw.githubusercontent.com/arnaldojr/cognitivecomputing/master/material/aulas/PDI/lab06/sala3.jpg /content !wget https://raw.githubusercontent.com/arnaldojr/cognitivecomputing/master/material/aulas/PDI/lab06/sala_res.png /content !wget https://raw.githubusercontent.com/arnaldojr/cognitivecomputing/master/material/aulas/PDI/lab06/people-walking.mp4 /content  In\u00a0[1]: Copied! <pre>%matplotlib inline\nimport cv2\nfrom matplotlib import pyplot as plt\nimport numpy as np\n\nimg = cv2.imread('formas.png')\nimg = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n\nplt.figure(figsize = (10,10))\nplt.imshow(img); plt.show()\n</pre> %matplotlib inline import cv2 from matplotlib import pyplot as plt import numpy as np  img = cv2.imread('formas.png') img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)  plt.figure(figsize = (10,10)) plt.imshow(img); plt.show() In\u00a0[2]: Copied! <pre>img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\nedges = cv2.Canny(img_gray,50,150)\ncircles=cv2.HoughCircles(edges,cv2.HOUGH_GRADIENT,dp=160,minDist=100,param1=200,param2=100,minRadius=50,maxRadius=150)\n\nbordas_rgb = cv2.cvtColor(edges, cv2.COLOR_GRAY2RGB)\noutput = bordas_rgb\n\n\nif circles is not None:        \n    circles = np.uint16(np.around(circles))\n    for i in circles[0,:]:\n        # desenha o contorno do circulo\n        cv2.circle(output,(i[0],i[1]),i[2],(0,255,0),2)\n        # desenha no centro do circulo\n        cv2.circle(output,(i[0],i[1]),2,(0,0,255),3)\n        \nplt.figure(figsize = (10,10))\nplt.imshow(output, cmap=\"Greys_r\", vmin=0, vmax=255); plt.show()\n</pre> img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY) edges = cv2.Canny(img_gray,50,150) circles=cv2.HoughCircles(edges,cv2.HOUGH_GRADIENT,dp=160,minDist=100,param1=200,param2=100,minRadius=50,maxRadius=150)  bordas_rgb = cv2.cvtColor(edges, cv2.COLOR_GRAY2RGB) output = bordas_rgb   if circles is not None:             circles = np.uint16(np.around(circles))     for i in circles[0,:]:         # desenha o contorno do circulo         cv2.circle(output,(i[0],i[1]),i[2],(0,255,0),2)         # desenha no centro do circulo         cv2.circle(output,(i[0],i[1]),2,(0,0,255),3)          plt.figure(figsize = (10,10)) plt.imshow(output, cmap=\"Greys_r\", vmin=0, vmax=255); plt.show() <p>O resultado n\u00e3o ficou bom, pois h\u00e1 muitos falsos positivos detectados, neste caso precisamos alterar os parametros da transformada de hough. Vamos ver o que \u00e9 cada um deles.</p> <p><code>circles=cv2.HoughCircles(image,method=cv2.HOUGH_GRADIENT,dp,minDist,param1,param2,minRadius,maxRadius)</code></p> <ul> <li>image: imagem de entrada na escala de ciza.</li> <li>method: Define o met\u00f3do de detec\u00e7\u00e3o de circulos.</li> <li>dp: rela\u00e7\u00e3o entre o tamanho da imagem e o tamanho do acumulador. Um dp grande \"pega\" bordas mais t\u00eanues.</li> <li>minDist: Dist\u00e2ncia minima entre centros (x,y) dos circulos detectados</li> <li>param1: Valor do gradiente usado para lidar com a detec\u00e7\u00e3o de bordas</li> <li>param2: Limiar do Acumulador usado pelo met\u00f3do. Se muito baixo, retorna mais circulos (incluindo c\u00edrculos falsos). Se mais alto, mais c\u00edrculos ser\u00e3o potencialmente retornados.</li> <li>minRadius: Raio minimo (em pixels).</li> <li>maxRadius: Raio m\u00e1ximo (em pixels).</li> </ul> In\u00a0[22]: Copied! <pre># Implemente sua solu\u00e7\u00e3o aqui...\nimport cv2\nfrom matplotlib import pyplot as plt\nimport numpy as np\n\nimg = cv2.imread('formas.png')\nimg = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\nimg_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n\nedges = cv2.Canny(img_gray,50,150) # O detector de bordas de Canny na imagem em escala de cinza para encontrar as bordas\n\n# A transformada de Hough para encontrar os c\u00edrculos na imagem com valores de dp=2 esse valor tem que testar, nao existe um valor padr\u00e3o\ncircles=cv2.HoughCircles(edges,cv2.HOUGH_GRADIENT,dp=2,minDist=100,param1=200,param2=100,minRadius=50,maxRadius=150)\n\nbordas_rgb = cv2.cvtColor(edges, cv2.COLOR_GRAY2RGB)\noutput = bordas_rgb\n\n\nif circles is not None:        \n    circles = np.uint16(np.around(circles))\n    for i in circles[0,:]:\n        # desenha o contorno do circulo\n        cv2.circle(output,(i[0],i[1]),i[2],(0,255,0),2)\n        # desenha no centro do circulo\n        cv2.circle(output,(i[0],i[1]),2,(0,0,255),3)\n        \nplt.figure(figsize = (10,10))\nplt.imshow(output, cmap=\"Greys_r\", vmin=0, vmax=255); plt.show()\n\n\n#### vamos aproveitar para entender melhor o que o HoughCircles est\u00e1 retornando ####\n\nprint(circles) # retorno do HoughCircles\nprint(f'O shape de cicles \u00e9: {circles.shape}')\nprint(f'Acessando o primeiro indice, conseguimos acessar os valores da submatriz {circles[0]}, repare que nao tem como acessar o circles[1]')\nprint(f'Essa matriz tem shape igual a {circles[0].shape}') \nprint(f'O primeiro circulo detectado \u00e9 {circles[0][0]}') # o raio, x e y do circulo\nprint(f'Raio: {circles[0][0][0]}') # raio\nprint(f'Centro x: {circles[0][0][1]}') # x\nprint(f'Centro y: {circles[0][0][2]}') # y\n\n\n \n</pre> # Implemente sua solu\u00e7\u00e3o aqui... import cv2 from matplotlib import pyplot as plt import numpy as np  img = cv2.imread('formas.png') img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB) img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)  edges = cv2.Canny(img_gray,50,150) # O detector de bordas de Canny na imagem em escala de cinza para encontrar as bordas  # A transformada de Hough para encontrar os c\u00edrculos na imagem com valores de dp=2 esse valor tem que testar, nao existe um valor padr\u00e3o circles=cv2.HoughCircles(edges,cv2.HOUGH_GRADIENT,dp=2,minDist=100,param1=200,param2=100,minRadius=50,maxRadius=150)  bordas_rgb = cv2.cvtColor(edges, cv2.COLOR_GRAY2RGB) output = bordas_rgb   if circles is not None:             circles = np.uint16(np.around(circles))     for i in circles[0,:]:         # desenha o contorno do circulo         cv2.circle(output,(i[0],i[1]),i[2],(0,255,0),2)         # desenha no centro do circulo         cv2.circle(output,(i[0],i[1]),2,(0,0,255),3)          plt.figure(figsize = (10,10)) plt.imshow(output, cmap=\"Greys_r\", vmin=0, vmax=255); plt.show()   #### vamos aproveitar para entender melhor o que o HoughCircles est\u00e1 retornando ####  print(circles) # retorno do HoughCircles print(f'O shape de cicles \u00e9: {circles.shape}') print(f'Acessando o primeiro indice, conseguimos acessar os valores da submatriz {circles[0]}, repare que nao tem como acessar o circles[1]') print(f'Essa matriz tem shape igual a {circles[0].shape}')  print(f'O primeiro circulo detectado \u00e9 {circles[0][0]}') # o raio, x e y do circulo print(f'Raio: {circles[0][0][0]}') # raio print(f'Centro x: {circles[0][0][1]}') # x print(f'Centro y: {circles[0][0][2]}') # y        <pre>[[[1281  493  112]\n  [ 609  601   56]\n  [ 733  189   85]\n  [ 187  459   87]]]\nO shape de cicles \u00e9: (1, 4, 3)\nAcessando o primeiro indice, conseguimos acessar os valores da submatriz [[1281  493  112]\n [ 609  601   56]\n [ 733  189   85]\n [ 187  459   87]], repare que nao tem como acessar o circles[1]\nEssa matriz tem shape igual a (4, 3)\nO primeiro circulo detectado \u00e9 [1281  493  112]\nRaio: 1281\nCentro x: 493\nCentro y: 112\n</pre> In\u00a0[7]: Copied! <pre>import cv2 as cv\nimport numpy as np\n\nimg = cv.imread('coins.png',0)\nimg = cv.medianBlur(img,5)\ncimg = cv.cvtColor(img,cv.COLOR_GRAY2BGR)\n\ncircles = cv.HoughCircles(img,cv.HOUGH_GRADIENT,1,20,param1=50,param2=40,minRadius=45,maxRadius=60)\n\ncircles = np.uint16(np.around(circles))\nfor i in circles[0,:]:\n    cv.circle(cimg,(i[0],i[1]),i[2],(0,255,0),2)\n    \nplt.figure(figsize = (10,10))   \nplt.imshow(cimg)\n</pre> import cv2 as cv import numpy as np  img = cv.imread('coins.png',0) img = cv.medianBlur(img,5) cimg = cv.cvtColor(img,cv.COLOR_GRAY2BGR)  circles = cv.HoughCircles(img,cv.HOUGH_GRADIENT,1,20,param1=50,param2=40,minRadius=45,maxRadius=60)  circles = np.uint16(np.around(circles)) for i in circles[0,:]:     cv.circle(cimg,(i[0],i[1]),i[2],(0,255,0),2)      plt.figure(figsize = (10,10))    plt.imshow(cimg) Out[7]: <pre>&lt;matplotlib.image.AxesImage at 0x7f6c31b2ea60&gt;</pre> In\u00a0[11]: Copied! <pre>#Implemente seu c\u00f3digo\n\nimport cv2 as cv\nimport numpy as np\n\nimg = cv.imread('coins.png',0)\nimg = cv.medianBlur(img,5)\ncimg = cv.cvtColor(img,cv.COLOR_GRAY2BGR)\n\n# fica facil de alterar os parametros de minRadius e maxRadius para encontrar os circulos maiores que no caso sao as moedas de 1 Dolar\ncircles = cv.HoughCircles(img,cv.HOUGH_GRADIENT,1,20,param1=50,param2=40,minRadius=75,maxRadius=100)\n\n\n# aqui eu desenho os circulos encontrados\ncircles = np.uint16(np.around(circles))\nfor i in circles[0,:]:\n    cv.circle(cimg,(i[0],i[1]),i[2],(0,255,0),2)\n\n\nplt.figure(figsize = (10,10))   \nplt.imshow(cimg)\n\nprint(f'foram encontrados {len(circles[0])} moedas de 1 Dolar')\n</pre> #Implemente seu c\u00f3digo  import cv2 as cv import numpy as np  img = cv.imread('coins.png',0) img = cv.medianBlur(img,5) cimg = cv.cvtColor(img,cv.COLOR_GRAY2BGR)  # fica facil de alterar os parametros de minRadius e maxRadius para encontrar os circulos maiores que no caso sao as moedas de 1 Dolar circles = cv.HoughCircles(img,cv.HOUGH_GRADIENT,1,20,param1=50,param2=40,minRadius=75,maxRadius=100)   # aqui eu desenho os circulos encontrados circles = np.uint16(np.around(circles)) for i in circles[0,:]:     cv.circle(cimg,(i[0],i[1]),i[2],(0,255,0),2)   plt.figure(figsize = (10,10))    plt.imshow(cimg)  print(f'foram encontrados {len(circles[0])} moedas de 1 Dolar')  <pre>foram encontrados 4 moedas de 1 Dolar\n</pre> In\u00a0[9]: Copied! <pre>%matplotlib inline\nimport cv2\nfrom matplotlib import pyplot as plt\nimport numpy as np\nimport math\n\nimg = cv2.imread('formas.png')\nimg = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n\nplt.figure(figsize = (10,10))\nplt.imshow(img); plt.show()\n</pre> %matplotlib inline import cv2 from matplotlib import pyplot as plt import numpy as np import math  img = cv2.imread('formas.png') img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)  plt.figure(figsize = (10,10)) plt.imshow(img); plt.show() In\u00a0[25]: Copied! <pre>img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\nedges = cv2.Canny(img_gray,50,150)\n\nlines = cv2.HoughLinesP(edges, 1, math.pi/180.0, 100, np.array([]), 180, 5)\n\nhough_img_rgb = cv2.cvtColor(edges, cv2.COLOR_GRAY2BGR)\n\nfor line in lines:\n    x1, y1, x2, y2 = line[0]\n    cv2.line(hough_img_rgb, (x1, y1), (x2, y2), (255, 0, 255), 5)\n\n\nplt.figure(figsize = (10,10))\nplt.imshow(hough_img_rgb); plt.show()\n</pre> img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY) edges = cv2.Canny(img_gray,50,150)  lines = cv2.HoughLinesP(edges, 1, math.pi/180.0, 100, np.array([]), 180, 5)  hough_img_rgb = cv2.cvtColor(edges, cv2.COLOR_GRAY2BGR)  for line in lines:     x1, y1, x2, y2 = line[0]     cv2.line(hough_img_rgb, (x1, y1), (x2, y2), (255, 0, 255), 5)   plt.figure(figsize = (10,10)) plt.imshow(hough_img_rgb); plt.show() In\u00a0[64]: Copied! <pre>#Implemente seu c\u00f3digo\n\nimport cv2\nfrom matplotlib import pyplot as plt\nimport numpy as np\nimport math\n\nimg = cv2.imread('formas.png')\nimg = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n\nimg_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\nimg_gray = cv2.Canny(img_gray,100,200)\n\n# O detector de linhas de Hough na imagem em escala de cinza para encontrar as linhas, os valores devem ser testados\nlines = cv2.HoughLinesP(img_gray, 1.5, math.pi/180.0, 100, np.array([]), 10, 5)\n\n\nhough_img_rgb = cv2.cvtColor(img_gray, cv2.COLOR_GRAY2BGR)\n\nfor line in lines:\n    x1, y1, x2, y2 = line[0]\n    cv2.line(hough_img_rgb, (x1, y1), (x2, y2), (255, 0, 255), 10)\n\n\nplt.figure(figsize = (10,10))\nplt.imshow(hough_img_rgb); plt.show()\n</pre> #Implemente seu c\u00f3digo  import cv2 from matplotlib import pyplot as plt import numpy as np import math  img = cv2.imread('formas.png') img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)  img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY) img_gray = cv2.Canny(img_gray,100,200)  # O detector de linhas de Hough na imagem em escala de cinza para encontrar as linhas, os valores devem ser testados lines = cv2.HoughLinesP(img_gray, 1.5, math.pi/180.0, 100, np.array([]), 10, 5)   hough_img_rgb = cv2.cvtColor(img_gray, cv2.COLOR_GRAY2BGR)  for line in lines:     x1, y1, x2, y2 = line[0]     cv2.line(hough_img_rgb, (x1, y1), (x2, y2), (255, 0, 255), 10)   plt.figure(figsize = (10,10)) plt.imshow(hough_img_rgb); plt.show()   <p>Exemplo mais pr\u00e1tico, detec\u00e7\u00e3o de faixa por veiculos auton\u00f4mos.</p> In\u00a0[65]: Copied! <pre>%matplotlib inline\nimport cv2\nfrom matplotlib import pyplot as plt\nimport numpy as np\nimport math\n\nimg = cv2.imread('rua.png')\nimg = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n\nplt.figure(figsize = (10,10))\nplt.imshow(img); plt.show()\n</pre> %matplotlib inline import cv2 from matplotlib import pyplot as plt import numpy as np import math  img = cv2.imread('rua.png') img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)  plt.figure(figsize = (10,10)) plt.imshow(img); plt.show() In\u00a0[66]: Copied! <pre>img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\nedges = cv2.Canny(img_gray,50,200)\n\nlines = cv2.HoughLinesP(edges, 1, math.pi/180.0, 120, np.array([]), 10, 100)\n\n\nhough_img_rgb = cv2.cvtColor(edges, cv2.COLOR_GRAY2BGR)\n\nfor line in lines:\n    x1, y1, x2, y2 = line[0]\n    cv2.line(hough_img_rgb, (x1, y1), (x2, y2), (255, 0, 255), 5)\n\n\nplt.figure(figsize = (10,10))\nplt.imshow(hough_img_rgb); plt.show()\n</pre> img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY) edges = cv2.Canny(img_gray,50,200)  lines = cv2.HoughLinesP(edges, 1, math.pi/180.0, 120, np.array([]), 10, 100)   hough_img_rgb = cv2.cvtColor(edges, cv2.COLOR_GRAY2BGR)  for line in lines:     x1, y1, x2, y2 = line[0]     cv2.line(hough_img_rgb, (x1, y1), (x2, y2), (255, 0, 255), 5)   plt.figure(figsize = (10,10)) plt.imshow(hough_img_rgb); plt.show() In\u00a0[14]: Copied! <pre>from IPython.display import Image\nImage(open('dilata\u00e7\u00e3o.gif','rb').read())\n</pre> from IPython.display import Image Image(open('dilata\u00e7\u00e3o.gif','rb').read()) Out[14]: In\u00a0[15]: Copied! <pre>import cv2 as cv\nimport numpy as np\nimg = cv.imread('j.png',0)\nplt.imshow(img, cmap=\"Greys_r\", vmin=0, vmax=255); plt.show()\n\nkernel = np.ones((5,5),np.uint8)\n\ndilation = cv.dilate(img,kernel,iterations = 1)\n\n\nplt.imshow(dilation, cmap=\"Greys_r\", vmin=0, vmax=255); plt.show()\n</pre> import cv2 as cv import numpy as np img = cv.imread('j.png',0) plt.imshow(img, cmap=\"Greys_r\", vmin=0, vmax=255); plt.show()  kernel = np.ones((5,5),np.uint8)  dilation = cv.dilate(img,kernel,iterations = 1)   plt.imshow(dilation, cmap=\"Greys_r\", vmin=0, vmax=255); plt.show() In\u00a0[16]: Copied! <pre>import cv2 as cv\nimport numpy as np\n\nimg = cv.imread('j.png',0)\n\nplt.imshow(img, cmap=\"Greys_r\", vmin=0, vmax=255); plt.show()\n\ndst = img.copy()\nkernel = np.ones((5,5),np.uint8)\n\ndilation = cv.dilate(img,kernel,iterations = 1)\n\ndst = dilation - img\n\n\nplt.imshow(dst, cmap=\"Greys_r\", vmin=0, vmax=255); plt.show()\n</pre> import cv2 as cv import numpy as np  img = cv.imread('j.png',0)  plt.imshow(img, cmap=\"Greys_r\", vmin=0, vmax=255); plt.show()  dst = img.copy() kernel = np.ones((5,5),np.uint8)  dilation = cv.dilate(img,kernel,iterations = 1)  dst = dilation - img   plt.imshow(dst, cmap=\"Greys_r\", vmin=0, vmax=255); plt.show() In\u00a0[17]: Copied! <pre>from IPython.display import Image\nImage(open('erosao.gif','rb').read())\n</pre> from IPython.display import Image Image(open('erosao.gif','rb').read()) Out[17]: In\u00a0[18]: Copied! <pre>import cv2 as cv\nimport numpy as np\nimg = cv.imread('j.png',0)\nplt.imshow(img, cmap=\"Greys_r\", vmin=0, vmax=255); plt.show()\n\ndst = img.copy()\nkernel = np.ones((5,5),np.uint8)\n\nerode = cv.erode(img,kernel,iterations = 1)\n\nplt.imshow(erode, cmap=\"Greys_r\", vmin=0, vmax=255); plt.show()\n</pre> import cv2 as cv import numpy as np img = cv.imread('j.png',0) plt.imshow(img, cmap=\"Greys_r\", vmin=0, vmax=255); plt.show()  dst = img.copy() kernel = np.ones((5,5),np.uint8)  erode = cv.erode(img,kernel,iterations = 1)  plt.imshow(erode, cmap=\"Greys_r\", vmin=0, vmax=255); plt.show() In\u00a0[72]: Copied! <pre>#implemente seu c\u00f3digo...\n\n\nimport cv2 as cv\nimport numpy as np\nimg = cv.imread('j.png',0)\n\ndst = img.copy()\nkernel = np.ones((5,5),np.uint8)\n\nerode = cv.erode(img,kernel,iterations = 1)\n\ncontorno = img - erode\n\nplt.subplot(131), plt.imshow(img, cmap=\"Greys_r\", vmin=0, vmax=255)\nplt.subplot(132), plt.imshow(erode, cmap=\"Greys_r\", vmin=0, vmax=255)\nplt.subplot(133), plt.imshow(contorno, cmap=\"Greys_r\", vmin=0, vmax=255); plt.show()\n</pre> #implemente seu c\u00f3digo...   import cv2 as cv import numpy as np img = cv.imread('j.png',0)  dst = img.copy() kernel = np.ones((5,5),np.uint8)  erode = cv.erode(img,kernel,iterations = 1)  contorno = img - erode  plt.subplot(131), plt.imshow(img, cmap=\"Greys_r\", vmin=0, vmax=255) plt.subplot(132), plt.imshow(erode, cmap=\"Greys_r\", vmin=0, vmax=255) plt.subplot(133), plt.imshow(contorno, cmap=\"Greys_r\", vmin=0, vmax=255); plt.show()    In\u00a0[19]: Copied! <pre>import cv2 as cv\nimport numpy as np\nimg = cv.imread('j-noise.png',0)\nplt.imshow(img, cmap=\"Greys_r\", vmin=0, vmax=255); plt.show()\n\ndst = img.copy()\nkernel = np.ones((5,5),np.uint8)\n\nopening = cv.morphologyEx(img, cv.MORPH_OPEN, kernel)\n\nplt.imshow(opening, cmap=\"Greys_r\", vmin=0, vmax=255); plt.show()\n</pre> import cv2 as cv import numpy as np img = cv.imread('j-noise.png',0) plt.imshow(img, cmap=\"Greys_r\", vmin=0, vmax=255); plt.show()  dst = img.copy() kernel = np.ones((5,5),np.uint8)  opening = cv.morphologyEx(img, cv.MORPH_OPEN, kernel)  plt.imshow(opening, cmap=\"Greys_r\", vmin=0, vmax=255); plt.show() In\u00a0[22]: Copied! <pre>import cv2 as cv\nimport numpy as np\nimg = cv.imread('holes.png',0)\nplt.imshow(img, cmap=\"Greys_r\", vmin=0, vmax=255); plt.show()\n\ndst = img.copy()\nkernel = np.ones((5,5),np.uint8)\n\nclosing = cv.morphologyEx(img, cv.MORPH_CLOSE, kernel)\n\nplt.imshow(closing, cmap=\"Greys_r\", vmin=0, vmax=255); plt.show()\n</pre> import cv2 as cv import numpy as np img = cv.imread('holes.png',0) plt.imshow(img, cmap=\"Greys_r\", vmin=0, vmax=255); plt.show()  dst = img.copy() kernel = np.ones((5,5),np.uint8)  closing = cv.morphologyEx(img, cv.MORPH_CLOSE, kernel)  plt.imshow(closing, cmap=\"Greys_r\", vmin=0, vmax=255); plt.show() In\u00a0[75]: Copied! <pre>### seu c\u00f3digo ###\n\n# a resposta \u00e9 n\u00e3o, pois a morfologia modifica a estrutura da imagem, e a opera\u00e7ao de fechamento pode preencher os buracos, mas nao vai conseguir recuperar a informa\u00e7\u00e3o perdida\n\n\nimport cv2 as cv\nimport numpy as np\n\nimg = cv.imread('holes.png',0)\n\nkernel = np.ones((5,5),np.uint8)\n\nopening = cv.morphologyEx(img, cv.MORPH_OPEN, kernel)\nclosing = cv.morphologyEx(opening, cv.MORPH_CLOSE, kernel)\n\ndiferenca = closing - img\n\nplt.subplot(141), plt.imshow(img, cmap=\"Greys_r\", vmin=0, vmax=255)\nplt.subplot(142), plt.imshow(opening, cmap=\"Greys_r\", vmin=0, vmax=255)\nplt.subplot(143), plt.imshow(closing, cmap=\"Greys_r\", vmin=0, vmax=255)\nplt.subplot(144), plt.imshow(diferenca, cmap=\"Greys_r\", vmin=0, vmax=255); plt.show()\n</pre> ### seu c\u00f3digo ###  # a resposta \u00e9 n\u00e3o, pois a morfologia modifica a estrutura da imagem, e a opera\u00e7ao de fechamento pode preencher os buracos, mas nao vai conseguir recuperar a informa\u00e7\u00e3o perdida   import cv2 as cv import numpy as np  img = cv.imread('holes.png',0)  kernel = np.ones((5,5),np.uint8)  opening = cv.morphologyEx(img, cv.MORPH_OPEN, kernel) closing = cv.morphologyEx(opening, cv.MORPH_CLOSE, kernel)  diferenca = closing - img  plt.subplot(141), plt.imshow(img, cmap=\"Greys_r\", vmin=0, vmax=255) plt.subplot(142), plt.imshow(opening, cmap=\"Greys_r\", vmin=0, vmax=255) plt.subplot(143), plt.imshow(closing, cmap=\"Greys_r\", vmin=0, vmax=255) plt.subplot(144), plt.imshow(diferenca, cmap=\"Greys_r\", vmin=0, vmax=255); plt.show()"},{"location":"aulas/PDI/lab06/sol_Transformada-Hough-morfologia.html#transformada-de-hough","title":"Transformada de Hough\u00b6","text":"<p>A transformada de Hough \u00e9 um metodo utilizado para reconhecimento de padr\u00f5es simples como retas e circulos. a aplica\u00e7\u00e3o da t\u00e9cnica \u00e9 feita em contornos de imagem. \u00c9 uma t\u00e9cnica muito popular e muito poderosa, pois possibilita detectar linhas e circulos em imagens com pouco vis\u00edvel ou muito ruidosa.</p>"},{"location":"aulas/PDI/lab06/sol_Transformada-Hough-morfologia.html#deteccao-de-circulos","title":"DETEC\u00c7\u00c3O DE CIRCULOS\u00b6","text":"<p>Vamos fazer a dete\u00e7\u00e3o de circulos da imagem forma.</p>"},{"location":"aulas/PDI/lab06/sol_Transformada-Hough-morfologia.html#desafio-1","title":"DESAFIO 1\u00b6","text":"<p>Fa\u00e7a a altera\u00e7\u00e3o dos parametros para a transformada de Hough afim de detectar apenas os circulos da imagem.</p> <p>Dica: Altere um parametro por vez e analise o resultado.</p>"},{"location":"aulas/PDI/lab06/sol_Transformada-Hough-morfologia.html#desafio-2","title":"DESAFIO 2\u00b6","text":"<p>Modifique este c\u00f3digo para detectar, segmentar e exibir a quantidade de moedas de 1 d\u00f3lar. Neste imagem, temos quatro moedas de 1 d\u00f3lar.</p>"},{"location":"aulas/PDI/lab06/sol_Transformada-Hough-morfologia.html#deteccao-de-retas","title":"DETEC\u00c7\u00c3O DE RETAS\u00b6","text":"<p>De forma semelhante ao CV2.HOUGHCIRCLE(), para detec\u00e7\u00e3o de retas usamos o cv2.HoughLines() ou cv2.HoughLinesP() o segundo faz uma estimativa probabilistica.</p> <p><code>cv.HoughLinesP( image, rho, theta, threshold[, lines[, minLineLength[, maxLineGap]]])</code></p> <ul> <li>imagem: Imagem de entrada em escala de cinza.</li> <li>rho: Resolu\u00e7\u00e3o da dist\u00e2ncia do acumulador em pixeis.</li> <li>teta: Resolu\u00e7\u00e3o do \u00e2ngulo de rota\u00e7\u00e3o do acumulador em radianos, normalmente 1 Grau.</li> <li>threshold: Limiar do acumulador. S\u00f3 s\u00e3o devolvidas as linhas que obt\u00eam votos suficientes ( &gt;threshold ).</li> <li>minLineLineLength: Comprimento m\u00ednimo da linha. Segmentos de linha mais curtos do que isso s\u00e3o rejeitados.</li> <li>maxLineGap: Dist\u00e2ncia m\u00e1xima permitida entre pontos considerados na mesma linha.</li> </ul>"},{"location":"aulas/PDI/lab06/sol_Transformada-Hough-morfologia.html#desafio-3","title":"DESAFIO 3\u00b6","text":"<p>Fa\u00e7a a altera\u00e7\u00e3o dos parametros para a transformada de Hough afim de detectar apenas todas as linhas da imagem.</p> <p>Dica: Altere um parametro por vez e analise o resultado.</p>"},{"location":"aulas/PDI/lab06/sol_Transformada-Hough-morfologia.html#morfologia-matematica","title":"MORFOLOGIA MATEM\u00c1TICA\u00b6","text":"<p>A Morfologia Matem\u00e1tica (MM) \u00e9 um modelo te\u00f3rico para as imagens digitais constru\u00eddas em cima da teoria dos reticulados e da topologia . \u00c9 o fundamento do processamento de imagem morfol\u00f3gico, que \u00e9 baseado nos operadores de deslocamento-invariante (transla\u00e7\u00e3o invariante) baseados principalmente na adi\u00e7\u00e3o de Minkowski.</p>"},{"location":"aulas/PDI/lab06/sol_Transformada-Hough-morfologia.html#dilatacao-binaria","title":"DILATA\u00c7\u00c3O BIN\u00c1RIA\u00b6","text":"<p>\u00c9 uma transforma\u00e7\u00e3o morfol\u00f3gica que combina dois conjuntos usando adi\u00e7\u00e3o vetorial. Como o nome diz, o resultado ser\u00e1 uma imagem \u201cengordada\u201d.</p>"},{"location":"aulas/PDI/lab06/sol_Transformada-Hough-morfologia.html#detectando-contorno-com-dilatacao","title":"Detectando contorno com dilata\u00e7\u00e3o\u00b6","text":""},{"location":"aulas/PDI/lab06/sol_Transformada-Hough-morfologia.html#erosao-binaria","title":"EROS\u00c3O BIN\u00c1RIA\u00b6","text":"<p>A eros\u00e3o basicamente encolhe uma imagem e pode ser vista como uma transforma\u00e7\u00e3o morfol\u00f3gica que combina dois conjuntos usando vetores de subtra\u00e7\u00e3o. Ela \u00e9 expressa como a interse\u00e7\u00e3o de A e B.</p>"},{"location":"aulas/PDI/lab06/sol_Transformada-Hough-morfologia.html#desafio-4","title":"DESAFIO 4\u00b6","text":"<p>Utilizando a opera\u00e7\u00e3o de eros\u00e3o, calcule o contorno da imagem \"j.png\":</p>"},{"location":"aulas/PDI/lab06/sol_Transformada-Hough-morfologia.html#abertura-binaria","title":"ABERTURA BIN\u00c1RIA\u00b6","text":"<p>A abertura em geral suaviza o contorno de uma imagem, quebra estreitos e elimina proemin\u00eancias delgadas, a opera\u00e7\u00e3o de abertura e usada tamb\u00e9m para remover ru\u00eddos da imagem.</p>"},{"location":"aulas/PDI/lab06/sol_Transformada-Hough-morfologia.html#fechamento-binario","title":"FECHAMENTO BIN\u00c1RIO\u00b6","text":"<p>O fechamento funde pequenos quebras e alargas golfos estreitos elimina pequenos orif\u00edcios. Se uma abertura cria pequenos vazios na imagem, um fechamento ir\u00e1 preencher ou fechar os vazios, estas opera\u00e7\u00f5es podem remover muitos dos pixels brancos com ru\u00eddos, ou seja basicamente ele e igual a abertura s\u00f3 que primeiramente e feita a dilata\u00e7\u00e3o e ap\u00f3s e feita a eros\u00e3o.</p>"},{"location":"aulas/PDI/lab06/sol_Transformada-Hough-morfologia.html#desafio-5","title":"DESAFIO 5\u00b6","text":"<p>Utilizando a opera\u00e7\u00e3o abertura e depois a opera\u00e7\u00e3o de fechamento bin\u00e1rio, \u00e9 esperado que a imagem volte ao original? Por que?</p>"},{"location":"aulas/PDI/lab07/motion.html","title":"Motion","text":"In\u00a0[\u00a0]: Copied! In\u00a0[\u00a0]: Copied! <pre>import cv2\nfrom datetime import datetime\n</pre> import cv2 from datetime import datetime In\u00a0[\u00a0]: Copied! <pre>BLUR_KERNEL_P0 = (21, 21)\nBLUR_KERNEL_P1 = (11, 11)\nLEARNING_RATE = 0.001\nMIN_CONTOUR_AREA = 625\n</pre> BLUR_KERNEL_P0 = (21, 21) BLUR_KERNEL_P1 = (11, 11) LEARNING_RATE = 0.001 MIN_CONTOUR_AREA = 625 In\u00a0[\u00a0]: Copied! <pre>cap = cv2.VideoCapture(\"people-walking.mp4\")\n</pre> cap = cv2.VideoCapture(\"people-walking.mp4\") In\u00a0[\u00a0]: Copied! <pre>#backSub = cv2.createBackgroundSubtractorKNN()\nbackSub = cv2.createBackgroundSubtractorMOG2()\n</pre> #backSub = cv2.createBackgroundSubtractorKNN() backSub = cv2.createBackgroundSubtractorMOG2() In\u00a0[\u00a0]: Copied! <pre>while True:\n    ret, frame = cap.read()\n\n    if not ret:\n        break\n\n    frame_blured = cv2.GaussianBlur(frame, BLUR_KERNEL_P0, 0)\n    #backSubmask = backSub.apply(frame_blured, learningRate=LEARNING_RATE)\n    backSubmask = backSub.apply(frame_blured)\n\n    thresh = cv2.GaussianBlur(backSubmask, BLUR_KERNEL_P1, 0)\n    thresh = cv2.dilate(thresh, None, iterations=2)\n\n    cnts, _ = cv2.findContours(thresh.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n\n    area_movimento = 0\n    for cnt in cnts:\n        area = cv2.contourArea(cnt)\n        if  area &lt; MIN_CONTOUR_AREA:\n            continue\n\n        area_movimento += area\n        (x, y, w, h) = cv2.boundingRect(cnt)\n        cv2.rectangle(frame, (x, y), (x+w, y+h), (128, 255, 255), 2)\n\n    cv2.putText(\n        frame, datetime.now().strftime(\"%A %d %B %Y %I:%M:%S%p\"),\n        (10, frame.shape[0] - 10), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)\n    # Show results\n    cv2.imshow(\"Feed\", frame)\n    cv2.imshow(\"Thresh\", thresh)\n\n    # Wait for key 'ESC' to quit\n    key = cv2.waitKey(1) &amp; 0xFF\n    if key == 27:\n        break\n</pre> while True:     ret, frame = cap.read()      if not ret:         break      frame_blured = cv2.GaussianBlur(frame, BLUR_KERNEL_P0, 0)     #backSubmask = backSub.apply(frame_blured, learningRate=LEARNING_RATE)     backSubmask = backSub.apply(frame_blured)      thresh = cv2.GaussianBlur(backSubmask, BLUR_KERNEL_P1, 0)     thresh = cv2.dilate(thresh, None, iterations=2)      cnts, _ = cv2.findContours(thresh.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)      area_movimento = 0     for cnt in cnts:         area = cv2.contourArea(cnt)         if  area &lt; MIN_CONTOUR_AREA:             continue          area_movimento += area         (x, y, w, h) = cv2.boundingRect(cnt)         cv2.rectangle(frame, (x, y), (x+w, y+h), (128, 255, 255), 2)      cv2.putText(         frame, datetime.now().strftime(\"%A %d %B %Y %I:%M:%S%p\"),         (10, frame.shape[0] - 10), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)     # Show results     cv2.imshow(\"Feed\", frame)     cv2.imshow(\"Thresh\", thresh)      # Wait for key 'ESC' to quit     key = cv2.waitKey(1) &amp; 0xFF     if key == 27:         break In\u00a0[\u00a0]: Copied! <pre># That's how you exit\ncap.release()\ncv2.destroyAllWindows()\n</pre> # That's how you exit cap.release() cv2.destroyAllWindows()"},{"location":"aulas/PDI/lab07/Aula09/mot.html","title":"Mot","text":"In\u00a0[\u00a0]: Copied! <pre>import numpy as np\nimport cv2\n</pre> import numpy as np import cv2 In\u00a0[\u00a0]: Copied! <pre>#carrega o video \ncap = cv2.VideoCapture(0)\n</pre> #carrega o video  cap = cv2.VideoCapture(0) In\u00a0[\u00a0]: Copied! <pre># Cria a subtra\u00e7\u00e3o do fundo\nfgbg = cv2.createBackgroundSubtractorMOG2()\n#fgbg = cv2.createBackgroundSubtractorKNN()\n</pre> # Cria a subtra\u00e7\u00e3o do fundo fgbg = cv2.createBackgroundSubtractorMOG2() #fgbg = cv2.createBackgroundSubtractorKNN() In\u00a0[\u00a0]: Copied! <pre>kernel = np.ones((5,5),np.uint8)\n</pre> kernel = np.ones((5,5),np.uint8) In\u00a0[\u00a0]: Copied! <pre>while(1):\n    ret, frame = cap.read()\n    \n    if not ret:\n        break\n    \n    # Aplica a mascara no frame recebido\n    fgmask = fgbg.apply(frame)\n\n\n    ## vou testar a eros\u00e3o, forma 1\n   # kernel = np.ones((3,3),np.uint8)\n\n    #erode = cv2.erode(fgmask,kernel,iterations = 2)\n\n    #dilation = cv2.dilate(erode,kernel,iterations = 7)\n \n    ## vou testar a forma 2\n   \n    opening = cv2.morphologyEx(fgmask, cv2.MORPH_OPEN, kernel)\n    dilation = cv2.dilate(opening,kernel,iterations = 7) \n #   closing = cv2.morphologyEx(opening, cv2.MORPH_CLOSE, kernel)\n    #opening = cv2.morphologyEx(opening, cv2.MORPH_OPEN, kernel)\n\n\n    ## acha contornos\n    contours,hierarchy = cv2.findContours(dilation, 1, 2)\n    if len(contours)&gt;0:\n        cnt = contours[0]\n    \n        ## desenha retangulo \n        x,y,w,h = cv2.boundingRect(cnt)\n        frame = cv2.rectangle(frame,(x,y),(x+w,y+h),(0,255,0),2)\n\n\n    ### exibo o resultado\n    cv2.imshow('frame',frame)\n\n    cv2.imshow('processado',dilation)\n\n    \n    k = cv2.waitKey(30) &amp; 0xff\n    if k == 27:\n        break\n</pre> while(1):     ret, frame = cap.read()          if not ret:         break          # Aplica a mascara no frame recebido     fgmask = fgbg.apply(frame)       ## vou testar a eros\u00e3o, forma 1    # kernel = np.ones((3,3),np.uint8)      #erode = cv2.erode(fgmask,kernel,iterations = 2)      #dilation = cv2.dilate(erode,kernel,iterations = 7)       ## vou testar a forma 2         opening = cv2.morphologyEx(fgmask, cv2.MORPH_OPEN, kernel)     dilation = cv2.dilate(opening,kernel,iterations = 7)   #   closing = cv2.morphologyEx(opening, cv2.MORPH_CLOSE, kernel)     #opening = cv2.morphologyEx(opening, cv2.MORPH_OPEN, kernel)       ## acha contornos     contours,hierarchy = cv2.findContours(dilation, 1, 2)     if len(contours)&gt;0:         cnt = contours[0]              ## desenha retangulo          x,y,w,h = cv2.boundingRect(cnt)         frame = cv2.rectangle(frame,(x,y),(x+w,y+h),(0,255,0),2)       ### exibo o resultado     cv2.imshow('frame',frame)      cv2.imshow('processado',dilation)           k = cv2.waitKey(30) &amp; 0xff     if k == 27:         break In\u00a0[\u00a0]: Copied! <pre>cap.release()\ncv2.destroyAllWindows()\n</pre> cap.release() cv2.destroyAllWindows()"},{"location":"aulas/PDI/lab07/Aula09/motion.html","title":"Lab07 - Traking de objetos e movimento","text":"<p>Objetivos da aula:</p> <ul> <li>Conhecer e praticar tracking de objetos em movimento</li> </ul> In\u00a0[\u00a0]: Copied! <pre>####----- FAZENDO O DOWNLOAD DAS IMAGENS DO RESPOSIT\u00d3RIO, APENAS PARA FACILITAR -----#####\n## SE ESTIVER RODANDO EM SUA M\u00c1QUINA LOCAL N\u00c3O PRECISA RODAR ESSA CELULA ##\n\n\n!wget https://raw.githubusercontent.com/arnaldojr/cognitivecomputing/master/material/aulas/lab07/Aula09/pessoas-gif.gif /content\n!wget https://raw.githubusercontent.com/arnaldojr/cognitivecomputing/master/material/aulas/lab07/Aula09/sala.jpg /content\n!wget https://raw.githubusercontent.com/arnaldojr/cognitivecomputing/master/material/aulas/lab07/Aula09/sala1.jpg /content\n!wget https://raw.githubusercontent.com/arnaldojr/cognitivecomputing/master/material/aulas/lab07/Aula09/sala2.jpg /content\n!wget https://raw.githubusercontent.com/arnaldojr/cognitivecomputing/master/material/aulas/lab07/Aula09/sala3.jpg /content\n!wget https://raw.githubusercontent.com/arnaldojr/cognitivecomputing/master/material/aulas/lab07/Aula09/sala_res.png /content\n!wget https://raw.githubusercontent.com/arnaldojr/cognitivecomputing/master/material/aulas/lab07/Aula09/people-walking.mp4 /content\n</pre> ####----- FAZENDO O DOWNLOAD DAS IMAGENS DO RESPOSIT\u00d3RIO, APENAS PARA FACILITAR -----##### ## SE ESTIVER RODANDO EM SUA M\u00c1QUINA LOCAL N\u00c3O PRECISA RODAR ESSA CELULA ##   !wget https://raw.githubusercontent.com/arnaldojr/cognitivecomputing/master/material/aulas/lab07/Aula09/pessoas-gif.gif /content !wget https://raw.githubusercontent.com/arnaldojr/cognitivecomputing/master/material/aulas/lab07/Aula09/sala.jpg /content !wget https://raw.githubusercontent.com/arnaldojr/cognitivecomputing/master/material/aulas/lab07/Aula09/sala1.jpg /content !wget https://raw.githubusercontent.com/arnaldojr/cognitivecomputing/master/material/aulas/lab07/Aula09/sala2.jpg /content !wget https://raw.githubusercontent.com/arnaldojr/cognitivecomputing/master/material/aulas/lab07/Aula09/sala3.jpg /content !wget https://raw.githubusercontent.com/arnaldojr/cognitivecomputing/master/material/aulas/lab07/Aula09/sala_res.png /content !wget https://raw.githubusercontent.com/arnaldojr/cognitivecomputing/master/material/aulas/lab07/Aula09/people-walking.mp4 /content  In\u00a0[2]: Copied! <pre>%matplotlib inline\nimport cv2\nfrom matplotlib import pyplot as plt\nimport numpy as np\n\nimg = cv2.imread('sala_res.png')\n\nplt.figure(figsize = (10,10))\nplt.imshow(img); plt.show();\n</pre> %matplotlib inline import cv2 from matplotlib import pyplot as plt import numpy as np  img = cv2.imread('sala_res.png')  plt.figure(figsize = (10,10)) plt.imshow(img); plt.show();  In\u00a0[\u00a0]: Copied! <pre># Implemente seu c\u00f3digo.....\n</pre> # Implemente seu c\u00f3digo.....       In\u00a0[\u00a0]: Copied! <pre>###### leia com aten\u00e7\u00e3o!!! este c\u00f3digo roda em sua m\u00e1quina local.\n\nimport numpy as np\nimport cv2\n\n#carrega o video \ncap = cv2.VideoCapture('people-walking.mp4')\n\n# Cria a subtra\u00e7\u00e3o do fundo\n#fgbg = cv2.createBackgroundSubtractorMOG2()\nfgbg = cv2.createBackgroundSubtractorKNN()\n\nwhile(1):\n    ret, frame = cap.read()\n    \n    if not ret:\n        break\n    \n    # Aplica a mascara no frame recebido\n    fgmask = fgbg.apply(frame)\n   \n   cv2.imshow('fgmask',frame)\n    cv2.imshow('frame',fgmask)\n\n    \n    k = cv2.waitKey(30) &amp; 0xff\n    if k == 27:\n        break\n    \n\ncap.release()\ncv2.destroyAllWindows()\n</pre>  ###### leia com aten\u00e7\u00e3o!!! este c\u00f3digo roda em sua m\u00e1quina local.  import numpy as np import cv2  #carrega o video  cap = cv2.VideoCapture('people-walking.mp4')  # Cria a subtra\u00e7\u00e3o do fundo #fgbg = cv2.createBackgroundSubtractorMOG2() fgbg = cv2.createBackgroundSubtractorKNN()  while(1):     ret, frame = cap.read()          if not ret:         break          # Aplica a mascara no frame recebido     fgmask = fgbg.apply(frame)        cv2.imshow('fgmask',frame)     cv2.imshow('frame',fgmask)           k = cv2.waitKey(30) &amp; 0xff     if k == 27:         break       cap.release() cv2.destroyAllWindows() In\u00a0[\u00a0]: Copied! <pre>\n</pre> In\u00a0[6]: Copied! <pre>from IPython.display import Image\nImage(open('pessoas-gif.gif','rb').read())\n</pre> from IPython.display import Image Image(open('pessoas-gif.gif','rb').read()) Out[6]: In\u00a0[1]: Copied! <pre>##### Implemente seu c\u00f3digo aqui......\n</pre> ##### Implemente seu c\u00f3digo aqui......   In\u00a0[\u00a0]: Copied! <pre>\n</pre>"},{"location":"aulas/PDI/lab07/Aula09/motion.html#background-subtraction","title":"Background Subtraction\u00b6","text":"<p>A intui\u00e7\u00e3o de como realizar essa tarefa n\u00f3s j\u00e1 sabemso, basicamente iremos comparar duas imagem: a de refer\u00eancia do fundo com uma segunda imagem de teste. O resultado ir\u00e1 ressaltar a diferen\u00e7a da imagem.</p>"},{"location":"aulas/PDI/lab07/Aula09/motion.html#desafio-1","title":"DESAFIO 1\u00b6","text":"<p>Implemente um c\u00f3digo (simples) que seja capaz de realizar a subtra\u00e7\u00e3o das imagens e detectar movimento.</p> <p>Dica: voc\u00ea pode usar opera\u00e7\u00f5es <code>cv2.absdiff(img1, img2)</code> e se necess\u00e1rio realizar uma opera\u00e7\u00e3o morfologia (abertura/ fechamento, dilata\u00e7\u00e3o/eros\u00e3o) para reduzir o ruido. O resultado deve ser parecido com a imagem \"sala_res.png\".</p>"},{"location":"aulas/PDI/lab07/Aula09/motion.html#use-como-imagens-de-entrada-as-opcoes","title":"USE COMO IMAGENS DE ENTRADA AS OP\u00c7\u00d5ES:\u00b6","text":"<ul> <li>SALA, SALA1, SALA2, SALA3</li> </ul>"},{"location":"aulas/PDI/lab07/Aula09/motion.html#background-subtraction-em-videos","title":"Background Subtraction em videos\u00b6","text":"<p>O desafio acima foi f\u00e1cil! pois existe uma imagem de fundo sozinha, como uma imagem da sala sem vazia. Basta subtrair a nova imagem do plano de fundo. Voc\u00ea obt\u00e9m os objetos de primeiro plano sozinhos.</p> <p>Mas, na maioria dos casos, voc\u00ea pode n\u00e3o ter essa imagem, ent\u00e3o precisamos extrair o plano de fundo de qualquer imagem que tenhamos. Aiiiiii complica as coisas.</p> <p>Na OpenCV podemos implementar isso por meio de dois algoritmos. O primeiro \u00e9 createBackgroundSubtractorKNN() ou createBackgroundSubtractorMOG2(). Isso cria um objeto subtrator de fundo por K-Nearest Neighbor (KNN) ou Mixture of Gaussians (MOG2) . Ent\u00e3o, podemos chamar a fun\u00e7\u00e3o <code>apply()</code> com o objeto para obter a m\u00e1scara do primeiro plano. Podemos exibir diretamente a m\u00e1scara de primeiro plano em tempo real (com video :)).</p> <p>Refer\u00eancia da documenta\u00e7\u00e3o: https://docs.opencv.org/master/de/de1/group__video__motion.html#gac9be925771f805b6fdb614ec2292006d</p>"},{"location":"aulas/PDI/lab07/Aula09/motion.html#executar-video-no-jupyter-notebook-normalmente-da-problema","title":"Executar video no jupyter notebook normalmente da problema.\u00b6","text":"<p>Existem algumas formas de rodar, mas pode ficar delay.</p> <p>Sugest\u00e3o: Escreva um script e execute direto pelo terminal.</p>"},{"location":"aulas/PDI/lab07/Aula09/motion.html#desafio-2","title":"DESAFIO 2\u00b6","text":"<p>Crie um programa python e execute o c\u00f3digo acima. O objetivo, nesse primeiro momento, \u00e9 se familiarizar com a estrutura do c\u00f3digo, para isso, explore os metodos <code>MOG2</code> e <code>KNN</code> e observe os resultados.</p> <p>Explore os parametros da fun\u00e7\u00e3o:</p> <pre><code>history: O numero de frames usado para construir o modelo estatisco da fundo. Quando menor mais rapido.\n\ndist2Threshold: \u00e9 o limiar definido para saber se o pixel pertence ao fundo ou n\u00e3o da imagem. Quando menor mais sensivel.\n\ndetectShadows : Se True, a sombra (shadows) vai aparecer em cinza na imagem.</code></pre>"},{"location":"aulas/PDI/lab07/Aula09/motion.html#desafio-3","title":"DESAFIO 3\u00b6","text":"<p>Fa\u00e7a um programa que detecta o movimento das pessoas andando na rua e marca com um boundBox (retangulo) o que foi detectado.</p> <p>Instru\u00e7\u00f5es/Dicas:</p> <ul> <li><p>Use 'people-walking.mp4' como video para os testes.</p> </li> <li><p>Lembre-se do que j\u00e1 estudamos para remover ruido, real\u00e7ar contorno, detectar bordas....</p> </li> <li><p>Sempre <code>Leia a documenta\u00e7\u00e3o</code>: https://opencv-python-tutroals.readthedocs.io/en/latest/py_tutorials/py_imgproc/py_contours/py_contour_features/py_contour_features.html</p> </li> <li><p>Use a fun\u00e7\u00e3o cv2.boundingRect() para desenhar o retangulo.</p> </li> </ul> <p>O resultado dever ser semelhante ao do video.</p>"},{"location":"aulas/PDI/lab07/Aula09/motion.html#desafio-4-extra-top-das-galaxias","title":"Desafio 4 - Extra top das galaxias!\u00b6","text":"<p>A \u00e1rea de seguran\u00e7a tornou-se um grande mercado, onde empresas desenvolvem e vendem seus produtos. A vigilancia por c\u00e2meras \u00e9 um grande alindo nesse mercado, por v\u00e1rios motivos. Nesse sentido, voc\u00ea foi contratado para desenvolver um sistema de seguran\u00e7a remoto que ir\u00e1 capturar um video remotamente (c\u00e2mera IP) realizar o processamento para detec\u00e7\u00e3o de movimento.</p> <p>Dicas/Instru\u00e7\u00f5es:</p> <ul> <li>Fa\u00e7a uma aplica\u00e7\u00e3o web em <code>Flask</code></li> <li>https://www.youtube.com/watch?v=EkqhIeSZGN8 esse video pode ajudar um pouco</li> <li>https://github.com/arnaldojr/videostream</li> </ul> <p>Se topar o desafio, vamos fazer um projeto IC?</p>"},{"location":"aulas/PDI/lab07/Aula09/sol_motion.html","title":"Sol motion","text":"<p>Objetivos da aula:</p> <ul> <li>Conhecer e praticar tracking de objetos em movimento</li> </ul> In\u00a0[\u00a0]: Copied! <pre>####----- FAZENDO O DOWNLOAD DAS IMAGENS DO RESPOSIT\u00d3RIO, APENAS PARA FACILITAR -----#####\n## SE ESTIVER RODANDO EM SUA M\u00c1QUINA LOCAL N\u00c3O PRECISA RODAR ESSA CELULA ##\n\n\n!wget https://raw.githubusercontent.com/arnaldojr/cognitivecomputing/master/material/aulas/lab07/Aula09/pessoas-gif.gif /content\n!wget https://raw.githubusercontent.com/arnaldojr/cognitivecomputing/master/material/aulas/lab07/Aula09/sala.jpg /content\n!wget https://raw.githubusercontent.com/arnaldojr/cognitivecomputing/master/material/aulas/lab07/Aula09/sala1.jpg /content\n!wget https://raw.githubusercontent.com/arnaldojr/cognitivecomputing/master/material/aulas/lab07/Aula09/sala2.jpg /content\n!wget https://raw.githubusercontent.com/arnaldojr/cognitivecomputing/master/material/aulas/lab07/Aula09/sala3.jpg /content\n!wget https://raw.githubusercontent.com/arnaldojr/cognitivecomputing/master/material/aulas/lab07/Aula09/sala_res.png /content\n!wget https://raw.githubusercontent.com/arnaldojr/cognitivecomputing/master/material/aulas/lab07/Aula09/people-walking.mp4 /content\n</pre> ####----- FAZENDO O DOWNLOAD DAS IMAGENS DO RESPOSIT\u00d3RIO, APENAS PARA FACILITAR -----##### ## SE ESTIVER RODANDO EM SUA M\u00c1QUINA LOCAL N\u00c3O PRECISA RODAR ESSA CELULA ##   !wget https://raw.githubusercontent.com/arnaldojr/cognitivecomputing/master/material/aulas/lab07/Aula09/pessoas-gif.gif /content !wget https://raw.githubusercontent.com/arnaldojr/cognitivecomputing/master/material/aulas/lab07/Aula09/sala.jpg /content !wget https://raw.githubusercontent.com/arnaldojr/cognitivecomputing/master/material/aulas/lab07/Aula09/sala1.jpg /content !wget https://raw.githubusercontent.com/arnaldojr/cognitivecomputing/master/material/aulas/lab07/Aula09/sala2.jpg /content !wget https://raw.githubusercontent.com/arnaldojr/cognitivecomputing/master/material/aulas/lab07/Aula09/sala3.jpg /content !wget https://raw.githubusercontent.com/arnaldojr/cognitivecomputing/master/material/aulas/lab07/Aula09/sala_res.png /content !wget https://raw.githubusercontent.com/arnaldojr/cognitivecomputing/master/material/aulas/lab07/Aula09/people-walking.mp4 /content  In\u00a0[1]: Copied! <pre>%matplotlib inline\nimport cv2\nfrom matplotlib import pyplot as plt\nimport numpy as np\n\nimg = cv2.imread('sala_res.png')\n\nplt.figure(figsize = (10,10))\nplt.imshow(img); plt.show();\n</pre> %matplotlib inline import cv2 from matplotlib import pyplot as plt import numpy as np  img = cv2.imread('sala_res.png')  plt.figure(figsize = (10,10)) plt.imshow(img); plt.show();  In\u00a0[6]: Copied! <pre># Implemente seu c\u00f3digo.....\n\n%matplotlib inline\nimport cv2\nfrom matplotlib import pyplot as plt\nimport numpy as np\n\nimg = cv2.imread('sala.jpg',0)\nimg2 = cv2.imread('sala1.jpg',0)\n\n\nres1 = cv2.absdiff(img, img2)\n\nplt.subplot(1,3,1)\nplt.imshow(img, cmap='gray')\nplt.title('sala')\nplt.subplot(1,3,2)\nplt.imshow(img2, cmap='gray')\nplt.title('sala 1')\nplt.subplot(1,3,3)\nplt.imshow(res1, cmap='gray')\nplt.title('resultado')\nplt.show()\n\n# vamos tentar melhorar o resultado aplicando morfologia matem\u00e1tica\n\nopening = cv2.morphologyEx(res1, cv2.MORPH_OPEN, np.ones((3,3),np.uint8))\n\nclossing = cv2.morphologyEx(res1, cv2.MORPH_CLOSE, np.ones((3,3),np.uint8))\n\nerode = cv2.erode(res1, np.ones((3,3),np.uint8), iterations=1)\n\ndilate = cv2.dilate(res1, np.ones((3,3),np.uint8), iterations=1)\n\nplt.figure(figsize=(10,10))\nplt.subplot(2,2,1)\nplt.imshow(opening, cmap='gray')\nplt.title('opening')\nplt.subplot(2,2,2)\nplt.imshow(clossing, cmap='gray')\nplt.title('clossing')\nplt.subplot(2,2,3)\nplt.imshow(erode, cmap='gray')\nplt.title('erode')\nplt.subplot(2,2,4)\nplt.imshow(dilate, cmap='gray')\nplt.title('dilate')\nplt.show()\n\n# o erode ficou bacana, podemos tentar melhorar o resultado aplicando novamente o erode\n\nerode2 = cv2.erode(erode, np.ones((3,3),np.uint8), iterations=1) # como sugest\u00e3o pode alterar o valor de iterations para tentar melhorar o resultado\n\nplt.figure(figsize=(10,10))\nplt.subplot(1,2,1)\nplt.imshow(erode, cmap='gray')\nplt.title('erode')\nplt.subplot(1,2,2)\nplt.imshow(erode2, cmap='gray')\nplt.title('erode2')\nplt.show()\n</pre> # Implemente seu c\u00f3digo.....  %matplotlib inline import cv2 from matplotlib import pyplot as plt import numpy as np  img = cv2.imread('sala.jpg',0) img2 = cv2.imread('sala1.jpg',0)   res1 = cv2.absdiff(img, img2)  plt.subplot(1,3,1) plt.imshow(img, cmap='gray') plt.title('sala') plt.subplot(1,3,2) plt.imshow(img2, cmap='gray') plt.title('sala 1') plt.subplot(1,3,3) plt.imshow(res1, cmap='gray') plt.title('resultado') plt.show()  # vamos tentar melhorar o resultado aplicando morfologia matem\u00e1tica  opening = cv2.morphologyEx(res1, cv2.MORPH_OPEN, np.ones((3,3),np.uint8))  clossing = cv2.morphologyEx(res1, cv2.MORPH_CLOSE, np.ones((3,3),np.uint8))  erode = cv2.erode(res1, np.ones((3,3),np.uint8), iterations=1)  dilate = cv2.dilate(res1, np.ones((3,3),np.uint8), iterations=1)  plt.figure(figsize=(10,10)) plt.subplot(2,2,1) plt.imshow(opening, cmap='gray') plt.title('opening') plt.subplot(2,2,2) plt.imshow(clossing, cmap='gray') plt.title('clossing') plt.subplot(2,2,3) plt.imshow(erode, cmap='gray') plt.title('erode') plt.subplot(2,2,4) plt.imshow(dilate, cmap='gray') plt.title('dilate') plt.show()  # o erode ficou bacana, podemos tentar melhorar o resultado aplicando novamente o erode  erode2 = cv2.erode(erode, np.ones((3,3),np.uint8), iterations=1) # como sugest\u00e3o pode alterar o valor de iterations para tentar melhorar o resultado  plt.figure(figsize=(10,10)) plt.subplot(1,2,1) plt.imshow(erode, cmap='gray') plt.title('erode') plt.subplot(1,2,2) plt.imshow(erode2, cmap='gray') plt.title('erode2') plt.show()    In\u00a0[\u00a0]: Copied! <pre>###### leia com aten\u00e7\u00e3o!!! este c\u00f3digo roda em sua m\u00e1quina local.\n\nimport numpy as np\nimport cv2\n\n#carrega o video \ncap = cv2.VideoCapture('people-walking.mp4')\n\n# Cria a subtra\u00e7\u00e3o do fundo\n#fgbg = cv2.createBackgroundSubtractorMOG2()\nfgbg = cv2.createBackgroundSubtractorKNN()\n\nwhile(1):\n    ret, frame = cap.read()\n    \n    if not ret:\n        break\n    \n    # Aplica a mascara no frame recebido\n    fgmask = fgbg.apply(frame)\n   \n    cv2.imshow('fgmask',frame)\n    cv2.imshow('frame',fgmask)\n\n    \n    k = cv2.waitKey(30) &amp; 0xff\n    if k == 27:\n        break\n    \n\ncap.release()\ncv2.destroyAllWindows()\n</pre>  ###### leia com aten\u00e7\u00e3o!!! este c\u00f3digo roda em sua m\u00e1quina local.  import numpy as np import cv2  #carrega o video  cap = cv2.VideoCapture('people-walking.mp4')  # Cria a subtra\u00e7\u00e3o do fundo #fgbg = cv2.createBackgroundSubtractorMOG2() fgbg = cv2.createBackgroundSubtractorKNN()  while(1):     ret, frame = cap.read()          if not ret:         break          # Aplica a mascara no frame recebido     fgmask = fgbg.apply(frame)         cv2.imshow('fgmask',frame)     cv2.imshow('frame',fgmask)           k = cv2.waitKey(30) &amp; 0xff     if k == 27:         break       cap.release() cv2.destroyAllWindows() In\u00a0[\u00a0]: Copied! <pre>## insira seu c\u00f3digo aqui\n\n# como vou abrir algums telas para observar a diferen\u00e7a entre os metodos, vou diminuir o tamanho da tela para n\u00e3o ficar muito grande e atrapalhar a visualiza\u00e7\u00e3o\n\n\nimport numpy as np\nimport cv2\n\n#carrega o video \ncap = cv2.VideoCapture('people-walking.mp4')\n\n# Reduzindo a resolu\u00e7\u00e3o do v\u00eddeo (opcional)\nscale_factor = 0.5\n\n# Cria\u00e7\u00e3o do objeto de subtra\u00e7\u00e3o de fundo MOG2\nmog2 = cv2.createBackgroundSubtractorMOG2(history=500, varThreshold=16, detectShadows=True)\n\n# Cria\u00e7\u00e3o do objeto de subtra\u00e7\u00e3o de fundo KNN\nknn = cv2.createBackgroundSubtractorKNN(history=350, dist2Threshold=400, detectShadows=True)\n\n\nwhile(1):\n    ret, frame = cap.read()\n    \n    if not ret:\n        break\n     # Redimensionamento do frame (opcional)\n    frame = cv2.resize(frame, None, fx=scale_factor, fy=scale_factor, interpolation=cv2.INTER_AREA)\n\n    # Aplica\u00e7\u00e3o dos m\u00e9todos de subtra\u00e7\u00e3o de fundo\n    fgmask_mog2 = mog2.apply(frame)\n    fgmask_knn = knn.apply(frame)\n\n    # Exibi\u00e7\u00e3o dos resultados\n    cv2.imshow('Original', frame)\n    cv2.imshow('MOG2', fgmask_mog2)\n    cv2.imshow('KNN', fgmask_knn)\n\n    if cv2.waitKey(0) &amp; 0xFF == ord('q'):\n        print(\"Encerrando a execu\u00e7\u00e3o.\")\n        break\n    \n\ncap.release()\ncv2.destroyAllWindows()\n</pre> ## insira seu c\u00f3digo aqui  # como vou abrir algums telas para observar a diferen\u00e7a entre os metodos, vou diminuir o tamanho da tela para n\u00e3o ficar muito grande e atrapalhar a visualiza\u00e7\u00e3o   import numpy as np import cv2  #carrega o video  cap = cv2.VideoCapture('people-walking.mp4')  # Reduzindo a resolu\u00e7\u00e3o do v\u00eddeo (opcional) scale_factor = 0.5  # Cria\u00e7\u00e3o do objeto de subtra\u00e7\u00e3o de fundo MOG2 mog2 = cv2.createBackgroundSubtractorMOG2(history=500, varThreshold=16, detectShadows=True)  # Cria\u00e7\u00e3o do objeto de subtra\u00e7\u00e3o de fundo KNN knn = cv2.createBackgroundSubtractorKNN(history=350, dist2Threshold=400, detectShadows=True)   while(1):     ret, frame = cap.read()          if not ret:         break      # Redimensionamento do frame (opcional)     frame = cv2.resize(frame, None, fx=scale_factor, fy=scale_factor, interpolation=cv2.INTER_AREA)      # Aplica\u00e7\u00e3o dos m\u00e9todos de subtra\u00e7\u00e3o de fundo     fgmask_mog2 = mog2.apply(frame)     fgmask_knn = knn.apply(frame)      # Exibi\u00e7\u00e3o dos resultados     cv2.imshow('Original', frame)     cv2.imshow('MOG2', fgmask_mog2)     cv2.imshow('KNN', fgmask_knn)      if cv2.waitKey(0) &amp; 0xFF == ord('q'):         print(\"Encerrando a execu\u00e7\u00e3o.\")         break       cap.release() cv2.destroyAllWindows()  In\u00a0[6]: Copied! <pre>from IPython.display import Image\nImage(open('pessoas-gif.gif','rb').read())\n</pre> from IPython.display import Image Image(open('pessoas-gif.gif','rb').read()) Out[6]: In\u00a0[1]: Copied! <pre>##### Implemente seu c\u00f3digo aqui......\n\n\n#!/usr/bin/env python3\n# -*- coding: utf-8 -*-\n\nimport cv2\nfrom datetime import datetime\n\n\nBLUR_KERNEL_P0 = (21, 21)\nBLUR_KERNEL_P1 = (11, 11)\nLEARNING_RATE = 0.001\nMIN_CONTOUR_AREA = 625\n\ncap = cv2.VideoCapture(\"people-walking.mp4\")\n\n#backSub = cv2.createBackgroundSubtractorKNN()\nbackSub = cv2.createBackgroundSubtractorMOG2()\n\nwhile True:\n    ret, frame = cap.read()\n\n    if not ret:\n        break\n\n    frame_blured = cv2.GaussianBlur(frame, BLUR_KERNEL_P0, 0)\n    #backSubmask = backSub.apply(frame_blured, learningRate=LEARNING_RATE)\n    backSubmask = backSub.apply(frame_blured)\n\n    thresh = cv2.GaussianBlur(backSubmask, BLUR_KERNEL_P1, 0)\n    thresh = cv2.dilate(thresh, None, iterations=2)\n\n    cnts, _ = cv2.findContours(thresh.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n\n    area_movimento = 0\n    for cnt in cnts:\n        area = cv2.contourArea(cnt)\n        if  area &lt; MIN_CONTOUR_AREA:\n            continue\n\n        area_movimento += area\n        (x, y, w, h) = cv2.boundingRect(cnt)\n        cv2.rectangle(frame, (x, y), (x+w, y+h), (128, 255, 255), 2)\n\n    cv2.putText(\n        frame, datetime.now().strftime(\"%A %d %B %Y %I:%M:%S%p\"),\n        (10, frame.shape[0] - 10), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)\n    # Show results\n    cv2.imshow(\"Feed\", frame)\n    cv2.imshow(\"Thresh\", thresh)\n\n    # Wait for key 'ESC' to quit\n    key = cv2.waitKey(1) &amp; 0xFF\n    if key == 27:\n        break\n\n# That's how you exit\ncap.release()\ncv2.destroyAllWindows()\n</pre> ##### Implemente seu c\u00f3digo aqui......   #!/usr/bin/env python3 # -*- coding: utf-8 -*-  import cv2 from datetime import datetime   BLUR_KERNEL_P0 = (21, 21) BLUR_KERNEL_P1 = (11, 11) LEARNING_RATE = 0.001 MIN_CONTOUR_AREA = 625  cap = cv2.VideoCapture(\"people-walking.mp4\")  #backSub = cv2.createBackgroundSubtractorKNN() backSub = cv2.createBackgroundSubtractorMOG2()  while True:     ret, frame = cap.read()      if not ret:         break      frame_blured = cv2.GaussianBlur(frame, BLUR_KERNEL_P0, 0)     #backSubmask = backSub.apply(frame_blured, learningRate=LEARNING_RATE)     backSubmask = backSub.apply(frame_blured)      thresh = cv2.GaussianBlur(backSubmask, BLUR_KERNEL_P1, 0)     thresh = cv2.dilate(thresh, None, iterations=2)      cnts, _ = cv2.findContours(thresh.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)      area_movimento = 0     for cnt in cnts:         area = cv2.contourArea(cnt)         if  area &lt; MIN_CONTOUR_AREA:             continue          area_movimento += area         (x, y, w, h) = cv2.boundingRect(cnt)         cv2.rectangle(frame, (x, y), (x+w, y+h), (128, 255, 255), 2)      cv2.putText(         frame, datetime.now().strftime(\"%A %d %B %Y %I:%M:%S%p\"),         (10, frame.shape[0] - 10), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)     # Show results     cv2.imshow(\"Feed\", frame)     cv2.imshow(\"Thresh\", thresh)      # Wait for key 'ESC' to quit     key = cv2.waitKey(1) &amp; 0xFF     if key == 27:         break  # That's how you exit cap.release() cv2.destroyAllWindows()    <pre>2024-03-13 18:19:45.703 Python[38035:1992601] WARNING: Secure coding is automatically enabled for restorable state! However, not on all supported macOS versions of this application. Opt-in to secure coding explicitly by implementing NSApplicationDelegate.applicationSupportsSecureRestorableState:.\n</pre> In\u00a0[\u00a0]: Copied! <pre># esse \u00e9 bonus, para quem quiser tentar fazer \n</pre> # esse \u00e9 bonus, para quem quiser tentar fazer"},{"location":"aulas/PDI/lab07/Aula09/sol_motion.html#background-subtraction","title":"Background Subtraction\u00b6","text":"<p>A intui\u00e7\u00e3o de como realizar essa tarefa n\u00f3s j\u00e1 sabemso, basicamente iremos comparar duas imagem: a de refer\u00eancia do fundo com uma segunda imagem de teste. O resultado ir\u00e1 ressaltar a diferen\u00e7a da imagem.</p>"},{"location":"aulas/PDI/lab07/Aula09/sol_motion.html#desafio-1","title":"DESAFIO 1\u00b6","text":"<p>Implemente um c\u00f3digo (simples) que seja capaz de realizar a subtra\u00e7\u00e3o das imagens e detectar movimento.</p> <p>Dica: voc\u00ea pode usar opera\u00e7\u00f5es <code>cv2.absdiff(img1, img2)</code> e se necess\u00e1rio realizar uma opera\u00e7\u00e3o morfologia (abertura/ fechamento, dilata\u00e7\u00e3o/eros\u00e3o) para reduzir o ruido. O resultado deve ser parecido com a imagem \"sala_res.png\".</p>"},{"location":"aulas/PDI/lab07/Aula09/sol_motion.html#use-como-imagens-de-entrada-as-opcoes","title":"USE COMO IMAGENS DE ENTRADA AS OP\u00c7\u00d5ES:\u00b6","text":"<ul> <li>SALA, SALA1, SALA2, SALA3</li> </ul>"},{"location":"aulas/PDI/lab07/Aula09/sol_motion.html#background-subtraction-em-videos","title":"Background Subtraction em videos\u00b6","text":"<p>O desafio acima foi f\u00e1cil! pois existe uma imagem de fundo sozinha, como uma imagem da sala sem vazia. Basta subtrair a nova imagem do plano de fundo. Voc\u00ea obt\u00e9m os objetos de primeiro plano sozinhos.</p> <p>Mas, na maioria dos casos, voc\u00ea pode n\u00e3o ter essa imagem, ent\u00e3o precisamos extrair o plano de fundo de qualquer imagem que tenhamos. Aiiiiii complica as coisas.</p> <p>Na OpenCV podemos implementar isso por meio de dois algoritmos. O primeiro \u00e9 createBackgroundSubtractorKNN() ou createBackgroundSubtractorMOG2(). Isso cria um objeto subtrator de fundo por K-Nearest Neighbor (KNN) ou Mixture of Gaussians (MOG2) . Ent\u00e3o, podemos chamar a fun\u00e7\u00e3o <code>apply()</code> com o objeto para obter a m\u00e1scara do primeiro plano. Podemos exibir diretamente a m\u00e1scara de primeiro plano em tempo real (com video :)).</p> <p>Refer\u00eancia da documenta\u00e7\u00e3o: https://docs.opencv.org/master/de/de1/group__video__motion.html#gac9be925771f805b6fdb614ec2292006d</p>"},{"location":"aulas/PDI/lab07/Aula09/sol_motion.html#executar-video-no-jupyter-notebook-normalmente-da-problema","title":"Executar video no jupyter notebook normalmente da problema.\u00b6","text":"<p>Existem algumas formas de rodar, mas pode ficar delay.</p> <p>Sugest\u00e3o: Escreva um script e execute direto pelo terminal.</p>"},{"location":"aulas/PDI/lab07/Aula09/sol_motion.html#desafio-2","title":"DESAFIO 2\u00b6","text":"<p>Crie um programa python e execute o c\u00f3digo acima. O objetivo, nesse primeiro momento, \u00e9 se familiarizar com a estrutura do c\u00f3digo, para isso, explore os metodos <code>MOG2</code> e <code>KNN</code> e observe os resultados.</p> <p>Explore os parametros da fun\u00e7\u00e3o:</p> <pre><code>history: O numero de frames usado para construir o modelo estatisco da fundo. Quando menor mais rapido.\n\ndist2Threshold: \u00e9 o limiar definido para saber se o pixel pertence ao fundo ou n\u00e3o da imagem. Quando menor mais sensivel.\n\ndetectShadows : Se True, a sombra (shadows) vai aparecer em cinza na imagem.</code></pre>"},{"location":"aulas/PDI/lab07/Aula09/sol_motion.html#desafio-3","title":"DESAFIO 3\u00b6","text":"<p>Fa\u00e7a um programa que detecta o movimento das pessoas andando na rua e marca com um boundBox (retangulo) o que foi detectado.</p> <p>Instru\u00e7\u00f5es/Dicas:</p> <ul> <li><p>Use 'people-walking.mp4' como video para os testes.</p> </li> <li><p>Lembre-se do que j\u00e1 estudamos para remover ruido, real\u00e7ar contorno, detectar bordas....</p> </li> <li><p>Sempre <code>Leia a documenta\u00e7\u00e3o</code>: https://opencv-python-tutroals.readthedocs.io/en/latest/py_tutorials/py_imgproc/py_contours/py_contour_features/py_contour_features.html</p> </li> <li><p>Use a fun\u00e7\u00e3o cv2.boundingRect() para desenhar o retangulo.</p> </li> </ul> <p>O resultado dever ser semelhante ao do video.</p>"},{"location":"aulas/PDI/lab07/Aula09/sol_motion.html#desafio-4-extra-top-das-galaxias","title":"Desafio 4 - Extra top das galaxias!\u00b6","text":"<p>A \u00e1rea de seguran\u00e7a tornou-se um grande mercado, onde empresas desenvolvem e vendem seus produtos. A vigilancia por c\u00e2meras \u00e9 um grande alindo nesse mercado, por v\u00e1rios motivos. Nesse sentido, voc\u00ea foi contratado para desenvolver um sistema de seguran\u00e7a remoto que ir\u00e1 capturar um video remotamente (c\u00e2mera IP) realizar o processamento para detec\u00e7\u00e3o de movimento.</p> <p>Dicas/Instru\u00e7\u00f5es:</p> <ul> <li>Fa\u00e7a uma aplica\u00e7\u00e3o web em <code>Flask</code></li> <li>https://www.youtube.com/watch?v=EkqhIeSZGN8 esse video pode ajudar um pouco</li> <li>https://github.com/arnaldojr/videostream</li> </ul> <p>Se topar o desafio, vamos fazer um projeto IC?</p>"},{"location":"aulas/PDI/lab08/Aula4.html","title":"Lab08 - Relacionamento e opera\u00e7\u00f5es entre imagens","text":"In\u00a0[1]: Copied! <pre>%matplotlib inline\nimport cv2\nfrom matplotlib import pyplot as plt\nimport numpy as np\n\n\nimg = cv2.imread(\"goku.jpg\")\nimg = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n\n# cria uma matriz com o mesmo dimensional da imagem original, mas com valores 100\nmatriz = np.ones(img.shape, dtype=\"uint8\") * 150\n\n\n\nimg2 = cv2.add(img, matriz)\n\n\nplt.imshow(img);\nplt.show()\nplt.imshow(img2);\n</pre> %matplotlib inline import cv2 from matplotlib import pyplot as plt import numpy as np   img = cv2.imread(\"goku.jpg\") img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)  # cria uma matriz com o mesmo dimensional da imagem original, mas com valores 100 matriz = np.ones(img.shape, dtype=\"uint8\") * 150    img2 = cv2.add(img, matriz)   plt.imshow(img); plt.show() plt.imshow(img2); In\u00a0[2]: Copied! <pre>%matplotlib inline\nimport cv2\nfrom matplotlib import pyplot as plt\nimport numpy as np\n\n\nimg = cv2.imread(\"goku.jpg\")\nimg = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n\n# cria uma matriz com o mesmo dimensional da imagem original, mas com valores 100\nmatriz = np.ones(img.shape, dtype=\"uint8\") * 150\n\n\n\nimg2 = cv2.subtract(img, matriz)\n\n\nplt.imshow(img);\nplt.show()\nplt.imshow(img2);\n</pre> %matplotlib inline import cv2 from matplotlib import pyplot as plt import numpy as np   img = cv2.imread(\"goku.jpg\") img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)  # cria uma matriz com o mesmo dimensional da imagem original, mas com valores 100 matriz = np.ones(img.shape, dtype=\"uint8\") * 150    img2 = cv2.subtract(img, matriz)   plt.imshow(img); plt.show() plt.imshow(img2); In\u00a0[3]: Copied! <pre>%matplotlib inline\nimport cv2\nfrom matplotlib import pyplot as plt\nimport numpy as np\n\n\nimg = cv2.imread(\"jornada.png\")\nimg = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n\n# cria uma matriz com o mesmo dimensional da imagem original, mas com valores 100\nmatriz = np.ones(img.shape, dtype=\"uint8\") * 100\n\n\n\nimg2 = cv2.add(img, matriz)\n\n\nplt.imshow(img);\nplt.show()\nplt.imshow(img2);\n</pre> %matplotlib inline import cv2 from matplotlib import pyplot as plt import numpy as np   img = cv2.imread(\"jornada.png\") img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)  # cria uma matriz com o mesmo dimensional da imagem original, mas com valores 100 matriz = np.ones(img.shape, dtype=\"uint8\") * 100    img2 = cv2.add(img, matriz)   plt.imshow(img); plt.show() plt.imshow(img2); In\u00a0[4]: Copied! <pre>%matplotlib inline\nimport cv2\nfrom matplotlib import pyplot as plt\nimport numpy as np\n\n\n\nsrc1 = cv2.imread('lena.jpg')\nsrc1_rgb = cv2.cvtColor(src1, cv2.COLOR_BGR2RGB)\n\nsrc2 = cv2.imread('rocket.jpg')\nsrc2_rgb = cv2.cvtColor(src2, cv2.COLOR_BGR2RGB)\n\n# 50% de transparencia para cada imagem\ndst = cv2.addWeighted(src1_rgb, 0.5, src2_rgb, 0.5, 0)\n\nplt.imshow(dst);\nplt.show()\n</pre> %matplotlib inline import cv2 from matplotlib import pyplot as plt import numpy as np    src1 = cv2.imread('lena.jpg') src1_rgb = cv2.cvtColor(src1, cv2.COLOR_BGR2RGB)  src2 = cv2.imread('rocket.jpg') src2_rgb = cv2.cvtColor(src2, cv2.COLOR_BGR2RGB)  # 50% de transparencia para cada imagem dst = cv2.addWeighted(src1_rgb, 0.5, src2_rgb, 0.5, 0)  plt.imshow(dst); plt.show() In\u00a0[5]: Copied! <pre>import cv2\nimport numpy as np\n\nimg = cv2.imread('lena.jpg',0)\n\n\nplt.imshow(img, cmap=\"gray\")\nplt.show()\n</pre> import cv2 import numpy as np  img = cv2.imread('lena.jpg',0)   plt.imshow(img, cmap=\"gray\") plt.show()  In\u00a0[6]: Copied! <pre># Aplicando NOT\nm_not = cv2.bitwise_not(img)\n\nplt.imshow(m_not, cmap=\"gray\")\nplt.show()\n</pre> # Aplicando NOT m_not = cv2.bitwise_not(img)  plt.imshow(m_not, cmap=\"gray\") plt.show()  In\u00a0[7]: Copied! <pre># Criando uma imagen inicial preta\nmask = np.zeros((img.shape[0], img.shape[1]), dtype=\"uint8\")\n\n# Coordenada central\ncenter = (int(img.shape[1]/2), int(img.shape[0]/2))\n\n# Tamanho do raio\nradius = int((img.shape[0]/2)*0.8)\n\n# Desenhando circulo braco\ncv2.circle(mask, center, radius, 255, -1)\n\nplt.imshow(mask, cmap=\"gray\")\nplt.show()\n</pre> # Criando uma imagen inicial preta mask = np.zeros((img.shape[0], img.shape[1]), dtype=\"uint8\")  # Coordenada central center = (int(img.shape[1]/2), int(img.shape[0]/2))  # Tamanho do raio radius = int((img.shape[0]/2)*0.8)  # Desenhando circulo braco cv2.circle(mask, center, radius, 255, -1)  plt.imshow(mask, cmap=\"gray\") plt.show()   In\u00a0[8]: Copied! <pre># Aplicando AND\nm_and = cv2.bitwise_and(img,mask)\nplt.imshow(m_and, cmap=\"gray\")\nplt.show()\n</pre> # Aplicando AND m_and = cv2.bitwise_and(img,mask) plt.imshow(m_and, cmap=\"gray\") plt.show()  In\u00a0[9]: Copied! <pre># Aplicando OR\nm_or = cv2.bitwise_or(img,mask)\nplt.imshow(m_or, cmap=\"gray\")\nplt.show()\n</pre> # Aplicando OR m_or = cv2.bitwise_or(img,mask) plt.imshow(m_or, cmap=\"gray\") plt.show() In\u00a0[10]: Copied! <pre># Aplicando XOR\nm_xor = cv2.bitwise_xor(img,mask)\nplt.imshow(m_xor, cmap=\"gray\")\nplt.show()\n</pre> # Aplicando XOR m_xor = cv2.bitwise_xor(img,mask) plt.imshow(m_xor, cmap=\"gray\") plt.show() In\u00a0[\u00a0]: Copied! <pre>\n</pre>"},{"location":"aulas/PDI/lab08/Aula4.html#operacoes-aritmeticas","title":"Opera\u00e7\u00f5es aritm\u00e9ticas\u00b6","text":"<p>Objetivos: Compreender e praticar relacionamento e opera\u00e7\u00f5es entre imagens</p> <p>Sim, por que n\u00e3o?? lembre que uma imagem nada mais \u00e9 que uma matriz. Logo podemos aplicar as mais diversas opera\u00e7\u00f5es matem\u00e1ticas.</p>"},{"location":"aulas/PDI/lab08/Aula4.html#soma-e-subtracao","title":"Soma e Subtra\u00e7\u00e3o\u00b6","text":"<p>Podemos aplicar opera\u00e7\u00f5es matem\u00e1ticas para alterar o brilho e contraste de uma imagem. Na OpenCV usamos as fun\u00e7\u00f5es cv2.add() e cv2.subtract()</p>"},{"location":"aulas/PDI/lab08/Aula4.html#sobreposicao-de-imagens","title":"Sobreposi\u00e7\u00e3o de imagens\u00b6","text":"<p>Para realizar a sobreposi\u00e7\u00e3o de imagens, ou blending, a OpenCV possui a fun\u00e7\u00e3o cv2.addWeighted(). Neste caso precisamos ponderar a porcentagem de cada imagem na imagem final.</p>"},{"location":"aulas/PDI/lab08/Aula4.html#operacoes-logicas","title":"Opera\u00e7\u00f5es L\u00f3gicas\u00b6","text":"<p>Podemos executar nas imagens opera\u00e7\u00f5es l\u00f3gicas, como as mais usuais: NOT, AND, OR e XOR</p>"},{"location":"aulas/PDI/lab09/aula.html","title":"Lab09 - FFT","text":"<p>Objetivo: - Conhecer e praticar filtragem no dom\u00ednio da frequ\u00eancia.</p> In\u00a0[1]: Copied! <pre>import cv2\nfrom matplotlib import pyplot as plt\nimport numpy as np\n\n\n#carrega imagem\nimg = cv2.imread('face.png',0)\n\n# Transforma\u00e7\u00e3o discreta de Fourier\ndft = cv2.dft(np.float32(img),flags = cv2.DFT_COMPLEX_OUTPUT)\ndft = np.fft.fftshift(dft)\n\n\n# Aplicado uma fun\u00e7\u00e3o log para visualiza\u00e7\u00e3o da magnitude do espectro\nmagnitude_spectrum = np.log(cv2.magnitude(dft[:,:,0],dft[:,:,1]))\n\n\n# Visualiza\u00e7\u00e3o das imagens\nfig = plt.figure(figsize=(20,20))\nplt.subplot(1, 2, 1),plt.title('Original')\nplt.imshow(img, cmap=\"gray\")\nplt.subplot(1, 2, 2),plt.title('magnitude_spectrum')\nplt.imshow(magnitude_spectrum, cmap=\"gray\")\nplt.show()\n</pre> import cv2 from matplotlib import pyplot as plt import numpy as np   #carrega imagem img = cv2.imread('face.png',0)  # Transforma\u00e7\u00e3o discreta de Fourier dft = cv2.dft(np.float32(img),flags = cv2.DFT_COMPLEX_OUTPUT) dft = np.fft.fftshift(dft)   # Aplicado uma fun\u00e7\u00e3o log para visualiza\u00e7\u00e3o da magnitude do espectro magnitude_spectrum = np.log(cv2.magnitude(dft[:,:,0],dft[:,:,1]))   # Visualiza\u00e7\u00e3o das imagens fig = plt.figure(figsize=(20,20)) plt.subplot(1, 2, 1),plt.title('Original') plt.imshow(img, cmap=\"gray\") plt.subplot(1, 2, 2),plt.title('magnitude_spectrum') plt.imshow(magnitude_spectrum, cmap=\"gray\") plt.show()  In\u00a0[9]: Copied! <pre>import cv2\nfrom matplotlib import pyplot as plt\nimport numpy as np\n\n\n#carrega imagem\nimg = cv2.imread('face.png',0)\n\n\n# extraindo shape da imagem\nrows, cols = img.shape\nhalf_row, half_col = rows/2 , cols/2\nlimiar = 40\n\n\n# Criando a m\u00e1scara quadrada\nmask = np.zeros((rows,cols,2),np.uint8)\nmask[int(half_row-limiar):int(half_row+limiar), int(half_col-limiar):int(half_col+limiar)] = 1\n\n\n# Transformada discreta de Fourier\ndft = cv2.dft(np.float32(img),flags = cv2.DFT_COMPLEX_OUTPUT)\ndft = np.fft.fftshift(dft)\n\n# Aplicar filtro na imagem\ndft_mask = dft*mask\n\n\n# Transformada inversa de Fourier\ndft_mask = np.fft.ifftshift(dft_mask)\nimg_restored = cv2.idft(dft_mask)\nimg_restored = cv2.magnitude(img_restored[:,:,0],img_restored[:,:,1])\n\n\n# Visualiza\u00e7\u00e3o das imagens\nfig = plt.figure(figsize=(20,20))\nplt.subplot(1, 2, 1),plt.title('Original')\nplt.imshow(img, cmap=\"gray\")\nplt.subplot(1, 2, 2),plt.title('img_restored')\nplt.imshow(img_restored, cmap=\"gray\")\nplt.show()\n</pre> import cv2 from matplotlib import pyplot as plt import numpy as np   #carrega imagem img = cv2.imread('face.png',0)   # extraindo shape da imagem rows, cols = img.shape half_row, half_col = rows/2 , cols/2 limiar = 40   # Criando a m\u00e1scara quadrada mask = np.zeros((rows,cols,2),np.uint8) mask[int(half_row-limiar):int(half_row+limiar), int(half_col-limiar):int(half_col+limiar)] = 1   # Transformada discreta de Fourier dft = cv2.dft(np.float32(img),flags = cv2.DFT_COMPLEX_OUTPUT) dft = np.fft.fftshift(dft)  # Aplicar filtro na imagem dft_mask = dft*mask   # Transformada inversa de Fourier dft_mask = np.fft.ifftshift(dft_mask) img_restored = cv2.idft(dft_mask) img_restored = cv2.magnitude(img_restored[:,:,0],img_restored[:,:,1])   # Visualiza\u00e7\u00e3o das imagens fig = plt.figure(figsize=(20,20)) plt.subplot(1, 2, 1),plt.title('Original') plt.imshow(img, cmap=\"gray\") plt.subplot(1, 2, 2),plt.title('img_restored') plt.imshow(img_restored, cmap=\"gray\") plt.show() In\u00a0[3]: Copied! <pre>import cv2\nfrom matplotlib import pyplot as plt\nimport numpy as np\n\n\n#carrega imagem\nimg = cv2.imread('face.png',0)\n\n\n# extraindo shape da imagem\nrows, cols = img.shape\nhalf_row, half_col = rows/2 , cols/2\nlimiar = 10\n\n\n# Criando a m\u00e1scara quadrada\nmask = np.ones((rows,cols,2),np.uint8)\nmask[int(half_row-limiar):int(half_row+limiar), int(half_col-limiar):int(half_col+limiar)] = 0\n\n\n# Transformada discreta de Fourier\ndft = cv2.dft(np.float32(img),flags = cv2.DFT_COMPLEX_OUTPUT)\ndft = np.fft.fftshift(dft)\n\n# Aplicar filtro na imagem\ndft_mask = dft*mask\n\n\n# Transformada inversa de Fourier\ndft_mask = np.fft.ifftshift(dft_mask)\nimg_restored = cv2.idft(dft_mask)\nimg_restored = cv2.magnitude(img_restored[:,:,0],img_restored[:,:,1])\n\n\n# Visualiza\u00e7\u00e3o das imagens\nfig = plt.figure(figsize=(20,20))\nplt.subplot(1, 2, 1),plt.title('Original')\nplt.imshow(img, cmap=\"gray\")\nplt.subplot(1, 2, 2),plt.title('img_restored')\nplt.imshow(img_restored, cmap=\"gray\")\nplt.show()\n</pre> import cv2 from matplotlib import pyplot as plt import numpy as np   #carrega imagem img = cv2.imread('face.png',0)   # extraindo shape da imagem rows, cols = img.shape half_row, half_col = rows/2 , cols/2 limiar = 10   # Criando a m\u00e1scara quadrada mask = np.ones((rows,cols,2),np.uint8) mask[int(half_row-limiar):int(half_row+limiar), int(half_col-limiar):int(half_col+limiar)] = 0   # Transformada discreta de Fourier dft = cv2.dft(np.float32(img),flags = cv2.DFT_COMPLEX_OUTPUT) dft = np.fft.fftshift(dft)  # Aplicar filtro na imagem dft_mask = dft*mask   # Transformada inversa de Fourier dft_mask = np.fft.ifftshift(dft_mask) img_restored = cv2.idft(dft_mask) img_restored = cv2.magnitude(img_restored[:,:,0],img_restored[:,:,1])   # Visualiza\u00e7\u00e3o das imagens fig = plt.figure(figsize=(20,20)) plt.subplot(1, 2, 1),plt.title('Original') plt.imshow(img, cmap=\"gray\") plt.subplot(1, 2, 2),plt.title('img_restored') plt.imshow(img_restored, cmap=\"gray\") plt.show() In\u00a0[\u00a0]: Copied! <pre>\n</pre>"},{"location":"aulas/PDI/lab09/aula.html#filtros-espectrais","title":"Filtros espectrais\u00b6","text":"<p>Filtragem espectral \u00e9 uma opera\u00e7\u00e3o que tem a finalidade de refor\u00e7ar ou atenuar certas frequ\u00eancias na imagem, mudando suas caracter\u00edsticas de suaviza\u00e7\u00e3o ou refor\u00e7o das bordas dos objetos.</p>"},{"location":"aulas/PDI/lab09/aula.html#transformada-de-fourier","title":"Transformada de Fourier\u00b6","text":"<p>Da mesma forma que existe audio com grave e agudo, existe imagens com frequencias baixa e alta. A Transformada de Fourier \u00e9 usada para analisar as caracter\u00edsticas de frequ\u00eancia de v\u00e1rios filtros. Para imagens, a Transformada Discreta de Fourier 2D (DFT) \u00e9 usada para encontrar a imagem no dom\u00ednio da frequ\u00eancia. Um algoritmo r\u00e1pido chamado Fast Fourier Transform (FFT) \u00e9 usado para o c\u00e1lculo da DFT.</p>"},{"location":"aulas/PDI/lab09/aula.html#exibindo-uma-imagem-no-dominio-da-frequencia","title":"Exibindo uma imagem no dominio da frequ\u00eancia\u00b6","text":"<p>Na OpenCV usamos a fun\u00e7\u00e3o cv2.dft()</p>"},{"location":"aulas/PDI/lab09/aula.html#filtro-espectral","title":"Filtro espectral\u00b6","text":"<p>O filtro espectral (ou no dom\u00ednio das frequ\u00eancias) usa o espectro da imagem para ressaltar ou atenuar determinadas carecter\u00edsticas de frequ\u00eancias da imagem. O mais comum \u00e9 empregar filtros que manipulam diretamente a magnitude das frequ\u00eancias, que podem ser do tipo:</p> <ul> <li>Filtro passa-baixas (PB): real\u00e7a baixas frequ\u00eancias e atenua as altas, multiplicando por valores baixos a magnitude das frequ\u00eancias maiores</li> <li>Filtro passa-altas (PA): real\u00e7a altas frequ\u00eancias e atenua as baixas, multiplicando por valores baixos a magnitude das frequ\u00eancias menores</li> <li>Filtro passa-faixa (PF): real\u00e7a uma regi\u00e3o do espectro em torno de determinada frequ\u00eancia</li> </ul>"},{"location":"aulas/PDI/lab09/aula.html#filtro-passa-baixas","title":"Filtro passa-baixas\u00b6","text":""},{"location":"aulas/PDI/lab09/aula.html#filtro-passa-altas","title":"Filtro passa-altas\u00b6","text":""},{"location":"aulas/PDI/lab10/medidas.html","title":"Lab10 - Medidas aproximadas","text":"<p>O PROBLEMA</p> <p>Como obter os tamanhos dos objetos?</p> In\u00a0[5]: Copied! <pre>%matplotlib inline\nimport cv2\nfrom matplotlib import pyplot as plt\nimport numpy as np\n\nimg = cv2.imread('objects.png')\nimg = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n\nplt.figure(figsize = (10,10))\nplt.imshow(img); plt.show();\n</pre> %matplotlib inline import cv2 from matplotlib import pyplot as plt import numpy as np  img = cv2.imread('objects.png') img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)  plt.figure(figsize = (10,10)) plt.imshow(img); plt.show(); <p>EXERC\u00cdCIO</p> <p>Calcular as arestas dos objetos da imagem acima.</p> In\u00a0[2]: Copied! <pre>#carregamos a imagem, convertemos para n\u00edveis de cinza e a borramos levemente\nimage = cv2.imread('objects.png')\nimage = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\ngray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n\n# aplico um filtro gaussiano para suaviazar a imagem...\ngray = cv2.GaussianBlur(gray, (9,9), 0)\n\n#calculamos as arestas e realizamos uma dilata\u00e7\u00e3o + eros\u00e3o para fechar\n#eventuais gaps entre as arestas dos objetos\nedged = cv2.Canny(gray, 50, 250)\ndilate = cv2.dilate(edged, None, iterations=2)\nerode = cv2.erode(dilate, None, iterations=2)\n\nplt.figure(figsize = (20,15))\nplt.subplot(2, 2, 1), plt.imshow(image)\nplt.subplot(2, 2, 2), plt.imshow(gray, 'gray'), plt.title('gray')\nplt.subplot(2, 2, 3), plt.imshow(dilate, 'gray'), plt.title('dilate')\nplt.subplot(2, 2, 4), plt.imshow(erode, 'gray'), plt.title('erode')\n\nplt.show();\n</pre> #carregamos a imagem, convertemos para n\u00edveis de cinza e a borramos levemente image = cv2.imread('objects.png') image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB) gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)  # aplico um filtro gaussiano para suaviazar a imagem... gray = cv2.GaussianBlur(gray, (9,9), 0)  #calculamos as arestas e realizamos uma dilata\u00e7\u00e3o + eros\u00e3o para fechar #eventuais gaps entre as arestas dos objetos edged = cv2.Canny(gray, 50, 250) dilate = cv2.dilate(edged, None, iterations=2) erode = cv2.erode(dilate, None, iterations=2)  plt.figure(figsize = (20,15)) plt.subplot(2, 2, 1), plt.imshow(image) plt.subplot(2, 2, 2), plt.imshow(gray, 'gray'), plt.title('gray') plt.subplot(2, 2, 3), plt.imshow(dilate, 'gray'), plt.title('dilate') plt.subplot(2, 2, 4), plt.imshow(erode, 'gray'), plt.title('erode')  plt.show(); In\u00a0[3]: Copied! <pre>#uma solu\u00e7\u00e3o possivel...\n\n#carregamos a imagem, convertemos para n\u00edveis de cinza e a borramos levemente\nimage = cv2.imread('objects.png')\nimage = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\ngray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n\n# aplico um filtro gaussiano para suaviazar a imagem...\ngray = cv2.GaussianBlur(gray, (7,7), 0)\n\n#calculamos as arestas e realizamos uma dilata\u00e7\u00e3o + eros\u00e3o para fechar\n#eventuais gaps entre as arestas dos objetos\nedged = cv2.Canny(gray, 50, 150)\ndilate = cv2.dilate(edged, None, iterations=2)\nerode = cv2.erode(dilate, None, iterations=1)\n\nplt.figure(figsize = (20,15))\nplt.subplot(2, 2, 1), plt.imshow(gray, 'gray'), plt.title('gray')\nplt.subplot(2, 2, 2), plt.imshow(edged, 'gray'), plt.title('edged')\nplt.subplot(2, 2, 3), plt.imshow(dilate, 'gray'), plt.title('dilate')\nplt.subplot(2, 2, 4), plt.imshow(erode, 'gray'), plt.title('erode')\nplt.show();\n</pre> #uma solu\u00e7\u00e3o possivel...  #carregamos a imagem, convertemos para n\u00edveis de cinza e a borramos levemente image = cv2.imread('objects.png') image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB) gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)  # aplico um filtro gaussiano para suaviazar a imagem... gray = cv2.GaussianBlur(gray, (7,7), 0)  #calculamos as arestas e realizamos uma dilata\u00e7\u00e3o + eros\u00e3o para fechar #eventuais gaps entre as arestas dos objetos edged = cv2.Canny(gray, 50, 150) dilate = cv2.dilate(edged, None, iterations=2) erode = cv2.erode(dilate, None, iterations=1)  plt.figure(figsize = (20,15)) plt.subplot(2, 2, 1), plt.imshow(gray, 'gray'), plt.title('gray') plt.subplot(2, 2, 2), plt.imshow(edged, 'gray'), plt.title('edged') plt.subplot(2, 2, 3), plt.imshow(dilate, 'gray'), plt.title('dilate') plt.subplot(2, 2, 4), plt.imshow(erode, 'gray'), plt.title('erode') plt.show();  In\u00a0[4]: Copied! <pre>## pratique um pouco, rode os exemplos dos links para te ajudar a compreender o que est\u00e1 acontecendo...\n</pre> ## pratique um pouco, rode os exemplos dos links para te ajudar a compreender o que est\u00e1 acontecendo...    In\u00a0[5]: Copied! <pre>## pratique um pouco, rode os exemplos dos links para te ajudar a compreender o que est\u00e1 acontecendo...\n</pre> ## pratique um pouco, rode os exemplos dos links para te ajudar a compreender o que est\u00e1 acontecendo...   In\u00a0[6]: Copied! <pre>## pratique um pouco, rode os exemplos dos links para te ajudar a compreender o que est\u00e1 acontecendo...\n</pre> ## pratique um pouco, rode os exemplos dos links para te ajudar a compreender o que est\u00e1 acontecendo...   In\u00a0[7]: Copied! <pre>cnts, _ = cv2.findContours(erode.copy(),cv2.RETR_EXTERNAL,cv2.CHAIN_APPROX_SIMPLE)\n\n# Ordena a lista de contornos para ficar da esquerda para direita. \n# Vamos precisar disso mais tarde.  \n# https://github.com/jrosebr1/imutils/blob/master/imutils/contours.py\n\n(cnts, boundingBoxes) = zip(*sorted(zip(cnts, [cv2.boundingRect(c) for c in cnts]), key=lambda b: b[1][0], reverse=False))\n</pre> cnts, _ = cv2.findContours(erode.copy(),cv2.RETR_EXTERNAL,cv2.CHAIN_APPROX_SIMPLE)  # Ordena a lista de contornos para ficar da esquerda para direita.  # Vamos precisar disso mais tarde.   # https://github.com/jrosebr1/imutils/blob/master/imutils/contours.py  (cnts, boundingBoxes) = zip(*sorted(zip(cnts, [cv2.boundingRect(c) for c in cnts]), key=lambda b: b[1][0], reverse=False)) In\u00a0[8]: Copied! <pre># https://github.com/jrosebr1/imutils/blob/master/imutils/perspective.py\n# ordena os pontos do contorno de tal modo que eles\n# apare\u00e7am na seguinte ordem: topo-esquerda, topo-direita,\n# base-direita e base-esquerda\nimport numpy as np\nfrom scipy.spatial import distance as dist\n\n\ndef order_points(pts):\n     xSorted = pts[np.argsort(pts[:, 0]), :]\n\n    # grab the left-most and right-most points from the sorted\n    # x-roodinate points\n     leftMost = xSorted[:2, :]\n     rightMost = xSorted[2:, :]\n\n    # now, sort the left-most coordinates according to their\n    # y-coordinates so we can grab the top-left and bottom-left\n    # points, respectively\n     leftMost = leftMost[np.argsort(leftMost[:, 1]), :]\n     (tl, bl) = leftMost\n\n    # now that we have the top-left coordinate, use it as an\n    # anchor to calculate the Euclidean distance between the\n    # top-left and right-most points; by the Pythagorean\n    # theorem, the point with the largest distance will be\n    # our bottom-right point\n     D = dist.cdist(tl[np.newaxis], rightMost, \"euclidean\")[0]\n     (br, tr) = rightMost[np.argsort(D)[::-1], :]\n\n    # return the coordinates in top-left, top-right,\n    # bottom-right, and bottom-left order\n     return np.array([tl, tr, br, bl], dtype=\"float32\")   \n</pre> # https://github.com/jrosebr1/imutils/blob/master/imutils/perspective.py # ordena os pontos do contorno de tal modo que eles # apare\u00e7am na seguinte ordem: topo-esquerda, topo-direita, # base-direita e base-esquerda import numpy as np from scipy.spatial import distance as dist   def order_points(pts):      xSorted = pts[np.argsort(pts[:, 0]), :]      # grab the left-most and right-most points from the sorted     # x-roodinate points      leftMost = xSorted[:2, :]      rightMost = xSorted[2:, :]      # now, sort the left-most coordinates according to their     # y-coordinates so we can grab the top-left and bottom-left     # points, respectively      leftMost = leftMost[np.argsort(leftMost[:, 1]), :]      (tl, bl) = leftMost      # now that we have the top-left coordinate, use it as an     # anchor to calculate the Euclidean distance between the     # top-left and right-most points; by the Pythagorean     # theorem, the point with the largest distance will be     # our bottom-right point      D = dist.cdist(tl[np.newaxis], rightMost, \"euclidean\")[0]      (br, tr) = rightMost[np.argsort(D)[::-1], :]      # return the coordinates in top-left, top-right,     # bottom-right, and bottom-left order      return np.array([tl, tr, br, bl], dtype=\"float32\")    In\u00a0[9]: Copied! <pre>orig = image.copy()\n\n#Percorre todos os contornos\nfor c in cnts:\n  # se o contorno n\u00e3o \u00e9 suficientemente grande, ignor\u00e1-lo\n  if cv2.contourArea(c) &lt; 100:\n    continue\n  \n  # calcula a bounding box rotacionada do contorno\n  box = cv2.minAreaRect(c)\n  box = cv2.boxPoints(box) \n  box = np.array(box, dtype=\"int\")\n\n  #ordena os pontos do contorno de tal modo que eles\n  #apare\u00e7am na seguinte ordem: topo-esquerda, topo-direita,\n  #base-direita e base-esquerda\n  \n  box = order_points(box)\n  #print(box)\n  cv2.drawContours(orig, [box.astype(\"int\")], -1, (0, 255, 0), 2)\n  for (x, y) in box:\n    cv2.circle(orig, (int(x), int(y)), 5, (255, 0, 0), -1)\n\nplt.figure(figsize = (10,10))\nplt.imshow(orig); plt.show();\n</pre>  orig = image.copy()  #Percorre todos os contornos for c in cnts:   # se o contorno n\u00e3o \u00e9 suficientemente grande, ignor\u00e1-lo   if cv2.contourArea(c) &lt; 100:     continue      # calcula a bounding box rotacionada do contorno   box = cv2.minAreaRect(c)   box = cv2.boxPoints(box)    box = np.array(box, dtype=\"int\")    #ordena os pontos do contorno de tal modo que eles   #apare\u00e7am na seguinte ordem: topo-esquerda, topo-direita,   #base-direita e base-esquerda      box = order_points(box)   #print(box)   cv2.drawContours(orig, [box.astype(\"int\")], -1, (0, 255, 0), 2)   for (x, y) in box:     cv2.circle(orig, (int(x), int(y)), 5, (255, 0, 0), -1)  plt.figure(figsize = (10,10)) plt.imshow(orig); plt.show();  <p>OBTEN\u00c7\u00c3O DOS PONTOS M\u00c9DIOS</p> <p>Vamos, agora, obter os pontos-m\u00e9dios de cada regi\u00e3o identificada e desenh\u00e1-los:</p> In\u00a0[10]: Copied! <pre>import numpy as np\n\ndef midpoint(ptA, ptB):\n  return ((ptA[0] + ptB[0]) * 0.5, (ptA[1] + ptB[1]) * 0.5)\n\norig = image.copy()\n#Percorre todos os contornos\nfor c in cnts:\n  # ignora contornos muito pequenos\n  if cv2.contourArea(c) &lt; 100:\n    continue\n  # calcula a bounding box rotacionada do contorno\n  box = cv2.minAreaRect(c)\n  box = cv2.boxPoints(box) \n  box = np.array(box, dtype=\"int\")\n  \n  #ordena os pontos do contorno de tal modo que eles\n  #apare\u00e7am na seguinte ordem: top-left, top-right,\n  #bottom-right e bottom-left\n  box = order_points(box)\n  cv2.drawContours(orig, [box.astype(\"int\")], -1, (0, 255, 0), 2)\n  for (x, y) in box:\n    cv2.circle(orig, (int(x), int(y)), 5, (255, 0, 0), -1)\n\n    \n #-----------------------------------isso \u00e9 novidade ----------------   \n    \n  #obt\u00e9m os pontos m\u00e9dios de top-left/top-right e bottom-left e bottom-right\n  (tl, tr, br, bl) = box\n  (tltrX, tltrY) = midpoint(tl, tr)\n  (blbrX, blbrY) = midpoint(bl, br)\n  \n  #obt\u00e9m os pontos m\u00e9dios de top-left/bottom-left e top-right e bottom-right\n  (tlblX, tlblY) = midpoint(tl, bl)\n  (trbrX, trbrY) = midpoint(tr, br)\n\n  #desenha c\u00edculos nos pontos-m\u00e9dios\n  cv2.circle(orig, (int(tltrX), int(tltrY)), 5, (255, 0, 0), -1)\n  cv2.circle(orig, (int(blbrX), int(blbrY)), 5, (255, 0, 0), -1)\n  cv2.circle(orig, (int(tlblX), int(tlblY)), 5, (255, 0, 0), -1)\n  cv2.circle(orig, (int(trbrX), int(trbrY)), 5, (255, 0, 0), -1)\n  \n  #une os pontos-m\u00e9dios com segmentos de reta\n  cv2.line(orig, (int(tltrX), int(tltrY)), (int(blbrX), int(blbrY)),(255, 0, 255), 2)\n  cv2.line(orig, (int(tlblX), int(tlblY)), (int(trbrX), int(trbrY)),(255, 0, 255), 2)\n\nplt.figure(figsize = (10,10))\nplt.imshow(orig); plt.show();\n</pre> import numpy as np  def midpoint(ptA, ptB):   return ((ptA[0] + ptB[0]) * 0.5, (ptA[1] + ptB[1]) * 0.5)  orig = image.copy() #Percorre todos os contornos for c in cnts:   # ignora contornos muito pequenos   if cv2.contourArea(c) &lt; 100:     continue   # calcula a bounding box rotacionada do contorno   box = cv2.minAreaRect(c)   box = cv2.boxPoints(box)    box = np.array(box, dtype=\"int\")      #ordena os pontos do contorno de tal modo que eles   #apare\u00e7am na seguinte ordem: top-left, top-right,   #bottom-right e bottom-left   box = order_points(box)   cv2.drawContours(orig, [box.astype(\"int\")], -1, (0, 255, 0), 2)   for (x, y) in box:     cv2.circle(orig, (int(x), int(y)), 5, (255, 0, 0), -1)        #-----------------------------------isso \u00e9 novidade ----------------           #obt\u00e9m os pontos m\u00e9dios de top-left/top-right e bottom-left e bottom-right   (tl, tr, br, bl) = box   (tltrX, tltrY) = midpoint(tl, tr)   (blbrX, blbrY) = midpoint(bl, br)      #obt\u00e9m os pontos m\u00e9dios de top-left/bottom-left e top-right e bottom-right   (tlblX, tlblY) = midpoint(tl, bl)   (trbrX, trbrY) = midpoint(tr, br)    #desenha c\u00edculos nos pontos-m\u00e9dios   cv2.circle(orig, (int(tltrX), int(tltrY)), 5, (255, 0, 0), -1)   cv2.circle(orig, (int(blbrX), int(blbrY)), 5, (255, 0, 0), -1)   cv2.circle(orig, (int(tlblX), int(tlblY)), 5, (255, 0, 0), -1)   cv2.circle(orig, (int(trbrX), int(trbrY)), 5, (255, 0, 0), -1)      #une os pontos-m\u00e9dios com segmentos de reta   cv2.line(orig, (int(tltrX), int(tltrY)), (int(blbrX), int(blbrY)),(255, 0, 255), 2)   cv2.line(orig, (int(tlblX), int(tlblY)), (int(trbrX), int(trbrY)),(255, 0, 255), 2)  plt.figure(figsize = (10,10)) plt.imshow(orig); plt.show(); <p>OBTEN\u00c7\u00c3O DAS MEDIDAS</p> <p>Para obter as medidas dos objetos, precisamos tomar um objeto de refer\u00eancia (ponto de calibra\u00e7\u00e3o) de tamanho conhecido. Na imagem anterior, vamos tomar como medida de refer\u00eancia a moeda de d\u00f3lar norte-americano, cujo comprimento \u00e9 2.43 cm. A partir dela, definimos todas as outras medidas.</p> <p>\u00c9 neste ponto que vai servir ter feito a ordena\u00e7\u00e3o do <code>cnts</code> da esquerda para a direita, a nossa moeda de d\u00f3lar esta bem destacada no lado esquerdo da imagem, desta forma fica facil fazer a calibra\u00e7\u00e3o pois ser\u00e1 o primeiro item da lista.</p> In\u00a0[11]: Copied! <pre>width=2.43\npixelsPerMetric=None\n</pre> width=2.43 pixelsPerMetric=None In\u00a0[12]: Copied! <pre>def midpoint(ptA, ptB):\n  return ((ptA[0] + ptB[0]) * 0.5, (ptA[1] + ptB[1]) * 0.5)\n\norig = image.copy()\n#Percorre todos os contornos\nfor c in cnts:\n  # se o contorno n\u00e3o \u00e9 suficientemente grande, ignor\u00e1-lo\n  if cv2.contourArea(c) &lt; 100:\n    continue\n  # calcula a bounding box rotacionada do contorno\n  box = cv2.minAreaRect(c)\n  box = cv2.boxPoints(box) \n  box = np.array(box, dtype=\"int\")\n  #ordena os pontos do contorno de tal modo que eles\n  #apare\u00e7am na seguinte ordem: top-left, top-right,\n  #bottom-right e bottom-left\n  box = order_points(box)\n  cv2.drawContours(orig, [box.astype(\"int\")], -1, (0, 255, 0), 2)\n  for (x, y) in box:\n    cv2.circle(orig, (int(x), int(y)), 5, (25, 0, 0), -1)\n\n  #obt\u00e9m os pontos m\u00e9dios de top-left/top-right e bottom-left e bottom-right\n  (tl, tr, br, bl) = box\n  (tltrX, tltrY) = midpoint(tl, tr)\n  (blbrX, blbrY) = midpoint(bl, br)\n  \n  #obt\u00e9m os pontos m\u00e9dios de top-left/bottom-left e top-right e bottom-right\n  (tlblX, tlblY) = midpoint(tl, bl)\n  (trbrX, trbrY) = midpoint(tr, br)\n\n  #desenha c\u00edculos nos pontos-m\u00e9dios\n  cv2.circle(orig, (int(tltrX), int(tltrY)), 5, (255, 0, 0), -1)\n  cv2.circle(orig, (int(blbrX), int(blbrY)), 5, (255, 0, 0), -1)\n  cv2.circle(orig, (int(tlblX), int(tlblY)), 5, (255, 0, 0), -1)\n  cv2.circle(orig, (int(trbrX), int(trbrY)), 5, (255, 0, 0), -1)\n  \n  #une os pontos-m\u00e9dios com segmentos de reta\n  cv2.line(orig, (int(tltrX), int(tltrY)), (int(blbrX), int(blbrY)),(255, 0, 255), 2)\n  cv2.line(orig, (int(tlblX), int(tlblY)), (int(trbrX), int(trbrY)),(255, 0, 255), 2)\n ###-------------n\u00e3o te mnovidade  \n    \n  # C\u00e1lculo da dist\u00e2ncia entre dois pontos, dist\u00e2ncia euclidiana\n  dA = dist.euclidean((tltrX, tltrY), (blbrX, blbrY))\n  dB = dist.euclidean((tlblX, tlblY), (trbrX, trbrY))\n\n##########---------------isso \u00e9 novidade--------------------------------------------------------------------\n\n  # define a escala para relacionar pixel por centrimetro\n  if pixelsPerMetric is None:\n    pixelsPerMetric = dB / width\n  \n  dimA = dA / pixelsPerMetric\n  dimB = dB / pixelsPerMetric\n  \n  cv2.putText(orig, \"{:.2f}cm\".format(dimB),(int(tltrX - 15), int(tltrY - 10)), cv2.FONT_HERSHEY_SIMPLEX,0.50, (255, 255, 255), 1)\n  cv2.putText(orig, \"{:.2f}cm\".format(dimA),(int(trbrX + 10), int(trbrY)), cv2.FONT_HERSHEY_SIMPLEX,0.50, (255, 255, 255), 1) \n  \nplt.figure(figsize = (10,10))\nplt.imshow(orig); plt.show();\n</pre> def midpoint(ptA, ptB):   return ((ptA[0] + ptB[0]) * 0.5, (ptA[1] + ptB[1]) * 0.5)  orig = image.copy() #Percorre todos os contornos for c in cnts:   # se o contorno n\u00e3o \u00e9 suficientemente grande, ignor\u00e1-lo   if cv2.contourArea(c) &lt; 100:     continue   # calcula a bounding box rotacionada do contorno   box = cv2.minAreaRect(c)   box = cv2.boxPoints(box)    box = np.array(box, dtype=\"int\")   #ordena os pontos do contorno de tal modo que eles   #apare\u00e7am na seguinte ordem: top-left, top-right,   #bottom-right e bottom-left   box = order_points(box)   cv2.drawContours(orig, [box.astype(\"int\")], -1, (0, 255, 0), 2)   for (x, y) in box:     cv2.circle(orig, (int(x), int(y)), 5, (25, 0, 0), -1)    #obt\u00e9m os pontos m\u00e9dios de top-left/top-right e bottom-left e bottom-right   (tl, tr, br, bl) = box   (tltrX, tltrY) = midpoint(tl, tr)   (blbrX, blbrY) = midpoint(bl, br)      #obt\u00e9m os pontos m\u00e9dios de top-left/bottom-left e top-right e bottom-right   (tlblX, tlblY) = midpoint(tl, bl)   (trbrX, trbrY) = midpoint(tr, br)    #desenha c\u00edculos nos pontos-m\u00e9dios   cv2.circle(orig, (int(tltrX), int(tltrY)), 5, (255, 0, 0), -1)   cv2.circle(orig, (int(blbrX), int(blbrY)), 5, (255, 0, 0), -1)   cv2.circle(orig, (int(tlblX), int(tlblY)), 5, (255, 0, 0), -1)   cv2.circle(orig, (int(trbrX), int(trbrY)), 5, (255, 0, 0), -1)      #une os pontos-m\u00e9dios com segmentos de reta   cv2.line(orig, (int(tltrX), int(tltrY)), (int(blbrX), int(blbrY)),(255, 0, 255), 2)   cv2.line(orig, (int(tlblX), int(tlblY)), (int(trbrX), int(trbrY)),(255, 0, 255), 2)  ###-------------n\u00e3o te mnovidade          # C\u00e1lculo da dist\u00e2ncia entre dois pontos, dist\u00e2ncia euclidiana   dA = dist.euclidean((tltrX, tltrY), (blbrX, blbrY))   dB = dist.euclidean((tlblX, tlblY), (trbrX, trbrY))  ##########---------------isso \u00e9 novidade--------------------------------------------------------------------    # define a escala para relacionar pixel por centrimetro   if pixelsPerMetric is None:     pixelsPerMetric = dB / width      dimA = dA / pixelsPerMetric   dimB = dB / pixelsPerMetric      cv2.putText(orig, \"{:.2f}cm\".format(dimB),(int(tltrX - 15), int(tltrY - 10)), cv2.FONT_HERSHEY_SIMPLEX,0.50, (255, 255, 255), 1)   cv2.putText(orig, \"{:.2f}cm\".format(dimA),(int(trbrX + 10), int(trbrY)), cv2.FONT_HERSHEY_SIMPLEX,0.50, (255, 255, 255), 1)     plt.figure(figsize = (10,10)) plt.imshow(orig); plt.show(); <p>Refer\u00eancia:</p> <ul> <li>https://pyimagesearch.com/2016/03/28/measuring-size-of-objects-in-an-image-with-opencv/</li> </ul> In\u00a0[13]: Copied! <pre>%matplotlib inline\nimport cv2\nfrom matplotlib import pyplot as plt\nimport numpy as np\n\nimg = cv2.imread('objects2.png')\nimg = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n\nplt.figure(figsize = (10,10))\nplt.imshow(img); plt.show();\n</pre> %matplotlib inline import cv2 from matplotlib import pyplot as plt import numpy as np  img = cv2.imread('objects2.png') img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)  plt.figure(figsize = (10,10)) plt.imshow(img); plt.show(); In\u00a0[14]: Copied! <pre>### Seu c\u00f3digo aqui....\n</pre> ### Seu c\u00f3digo aqui....      In\u00a0[\u00a0]: Copied! <pre>\n</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre>"},{"location":"aulas/PDI/lab10/medidas.html#processamento-de-imagens","title":"PROCESSAMENTO DE IMAGENS\u00b6","text":"<p>Objetivos da aula:</p> <ul> <li>reconhecer e fazer medidas b\u00e1sicas e aproximadas de objetos</li> </ul>"},{"location":"aulas/PDI/lab10/medidas.html#desafio1","title":"desafio1\u00b6","text":"<p>Dica r\u00e1pida de python. Vamos utilizar a fun\u00e7\u00e3o <code>zip</code> do python que retorna uma sequ\u00eancia de tuplas. Pratique um pouco essa fun\u00e7\u00e3o.</p> <ul> <li>http://devfuria.com.br/python/built-in-zip/</li> <li>https://pythonhelp.wordpress.com/2013/04/16/funcao-zip-em-python/</li> <li>https://www.programiz.com/python-programming/methods/built-in/zip</li> </ul> <p>obs. O operador <code>*</code> pode ser utilizado com o zip() para descompactar (unzip) uma lista.</p>"},{"location":"aulas/PDI/lab10/medidas.html#desafio2","title":"desafio2\u00b6","text":"<p>Dica r\u00e1pida de python. Vamos utilizar <code>list comprehensions</code> que basicamente realiza de forma compacta uma manipula\u00e7\u00e3o de listas. Pratique um pouco essa fun\u00e7\u00e3o.</p> <ul> <li>https://pythonhelp.wordpress.com/2011/03/01/list-comprehension/</li> <li>https://www.w3schools.com/python/python_lists_comprehension.asp</li> <li>https://pythonacademy.com.br/blog/list-comprehensions-no-python</li> </ul>"},{"location":"aulas/PDI/lab10/medidas.html#desafio3","title":"desafio3\u00b6","text":"<p>Dica r\u00e1pida de python. Vamos utilizar a fun\u00e7\u00e3o <code>lambda</code> que basicamente realiza de forma pratica uma fun\u00e7\u00e3o an\u00f4nima. Pratique um pouco essa fun\u00e7\u00e3o.</p> <ul> <li>https://www.hashtagtreinamentos.com/funcoes-lambda-python?gclid=CjwKCAjwiuuRBhBvEiwAFXKaNF77HmSrHlWg1Tx5Okpt6x9QFZemjbINiX9sX43R-fCNnXkuy8fiTxoCkiEQAvD_BwE</li> <li>https://www.w3schools.com/python/python_lambda.asp</li> <li>https://www.codingame.com/playgrounds/52499/programacao-python-intermediario---prof--marco-vaz/funcao-lambda</li> </ul>"},{"location":"aulas/PDI/lab10/medidas.html#obtencao-dos-contornos","title":"OBTEN\u00c7\u00c3O DOS CONTORNOS\u00b6","text":"<p>A partir das arestas, podemos obter os contornos dos objetos.</p>"},{"location":"aulas/PDI/lab10/medidas.html#desafio","title":"Desafio\u00b6","text":"<p>Realize o processamento da imagem abaixo a fim de obter os dimensionais de todos os cart\u00f5es. Fa\u00e7a a escolha de um dos cart\u00f5es para ser a refer\u00eancia e servir de calibra\u00e7\u00e3o.</p> <p>O cart\u00e3o da esquerda possui 8.89 x 5.08 cm.</p>"},{"location":"aulas/PDI/lab10/medidas.html#desafio-extra-top","title":"Desafio extra top!\u00b6","text":"<p>Um grande problemada industria de manufatura est\u00e1 na determin\u00e7\u00e3o do dimensional de alguns objetos para controle de qualidade. Nesse sentido, voc\u00ea foi contratado para desenvolver um sistema que ir\u00e1 capturar um frame de um v\u00eddeo, processar e definir o seu dimenssional.</p> <p>Se topar o desafio, vamos fazer um projeto IC?</p>"},{"location":"aulas/PDI/lab10/sol_medidas.html","title":"Sol medidas","text":"<p>O PROBLEMA</p> <p>Como obter os tamanhos dos objetos?</p> In\u00a0[\u00a0]: Copied! <pre>%matplotlib inline\nimport cv2\nfrom matplotlib import pyplot as plt\nimport numpy as np\n\nimg = cv2.imread('objects.png')\nimg = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n\nplt.figure(figsize = (10,10))\nplt.imshow(img); plt.show();\n</pre> %matplotlib inline import cv2 from matplotlib import pyplot as plt import numpy as np  img = cv2.imread('objects.png') img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)  plt.figure(figsize = (10,10)) plt.imshow(img); plt.show(); <p>EXERC\u00cdCIO</p> <p>Calcular as arestas dos objetos da imagem acima.</p> In\u00a0[\u00a0]: Copied! <pre>#carregamos a imagem, convertemos para n\u00edveis de cinza e a borramos levemente\nimage = cv2.imread('objects.png')\nimage = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\ngray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n\n# aplico um filtro gaussiano para suaviazar a imagem...\ngray = cv2.GaussianBlur(gray, (9,9), 0)\n\n#calculamos as arestas e realizamos uma dilata\u00e7\u00e3o + eros\u00e3o para fechar\n#eventuais gaps entre as arestas dos objetos\nedged = cv2.Canny(gray, 50, 250)\ndilate = cv2.dilate(edged, None, iterations=2)\nerode = cv2.erode(dilate, None, iterations=2)\n\nplt.figure(figsize = (20,15))\nplt.subplot(2, 2, 1), plt.imshow(image)\nplt.subplot(2, 2, 2), plt.imshow(gray, 'gray'), plt.title('gray')\nplt.subplot(2, 2, 3), plt.imshow(dilate, 'gray'), plt.title('dilate')\nplt.subplot(2, 2, 4), plt.imshow(erode, 'gray'), plt.title('erode')\n\nplt.show();\n</pre> #carregamos a imagem, convertemos para n\u00edveis de cinza e a borramos levemente image = cv2.imread('objects.png') image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB) gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)  # aplico um filtro gaussiano para suaviazar a imagem... gray = cv2.GaussianBlur(gray, (9,9), 0)  #calculamos as arestas e realizamos uma dilata\u00e7\u00e3o + eros\u00e3o para fechar #eventuais gaps entre as arestas dos objetos edged = cv2.Canny(gray, 50, 250) dilate = cv2.dilate(edged, None, iterations=2) erode = cv2.erode(dilate, None, iterations=2)  plt.figure(figsize = (20,15)) plt.subplot(2, 2, 1), plt.imshow(image) plt.subplot(2, 2, 2), plt.imshow(gray, 'gray'), plt.title('gray') plt.subplot(2, 2, 3), plt.imshow(dilate, 'gray'), plt.title('dilate') plt.subplot(2, 2, 4), plt.imshow(erode, 'gray'), plt.title('erode')  plt.show(); In\u00a0[\u00a0]: Copied! <pre>#uma solu\u00e7\u00e3o possivel...\n\n#carregamos a imagem, convertemos para n\u00edveis de cinza e a borramos levemente\nimage = cv2.imread('objects.png')\nimage = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\ngray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n\n# aplico um filtro gaussiano para suaviazar a imagem...\ngray = cv2.GaussianBlur(gray, (7,7), 0)\n\n#calculamos as arestas e realizamos uma dilata\u00e7\u00e3o + eros\u00e3o para fechar\n#eventuais gaps entre as arestas dos objetos\nedged = cv2.Canny(gray, 50, 150)\ndilate = cv2.dilate(edged, None, iterations=2)\nerode = cv2.erode(dilate, None, iterations=1)\n\nplt.figure(figsize = (20,15))\nplt.subplot(2, 2, 1), plt.imshow(gray, 'gray'), plt.title('gray')\nplt.subplot(2, 2, 2), plt.imshow(edged, 'gray'), plt.title('edged')\nplt.subplot(2, 2, 3), plt.imshow(dilate, 'gray'), plt.title('dilate')\nplt.subplot(2, 2, 4), plt.imshow(erode, 'gray'), plt.title('erode')\nplt.show();\n</pre> #uma solu\u00e7\u00e3o possivel...  #carregamos a imagem, convertemos para n\u00edveis de cinza e a borramos levemente image = cv2.imread('objects.png') image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB) gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)  # aplico um filtro gaussiano para suaviazar a imagem... gray = cv2.GaussianBlur(gray, (7,7), 0)  #calculamos as arestas e realizamos uma dilata\u00e7\u00e3o + eros\u00e3o para fechar #eventuais gaps entre as arestas dos objetos edged = cv2.Canny(gray, 50, 150) dilate = cv2.dilate(edged, None, iterations=2) erode = cv2.erode(dilate, None, iterations=1)  plt.figure(figsize = (20,15)) plt.subplot(2, 2, 1), plt.imshow(gray, 'gray'), plt.title('gray') plt.subplot(2, 2, 2), plt.imshow(edged, 'gray'), plt.title('edged') plt.subplot(2, 2, 3), plt.imshow(dilate, 'gray'), plt.title('dilate') plt.subplot(2, 2, 4), plt.imshow(erode, 'gray'), plt.title('erode') plt.show();  In\u00a0[\u00a0]: Copied! <pre>## pratique um pouco, rode os exemplos dos links para te ajudar a compreender o que est\u00e1 acontecendo...\n\n# A fun\u00e7ao zip() \u00e9 utilizada para unir duas listas. \n\nlista_a = [6, 7, 8, 9, 1, 2, 3, 4, 5]\nlista_b = ['R', 'A', 'I', 'M', 'U', 'N', 'D', 'O','S']\n\nprint('Unindo as listas...')\nzipado = zip(lista_a, lista_b)\n# print(zipado[0]) ### essa linha vai dar erro, pois zipado \u00e9 um objeto do tipo zip, e n\u00e3o uma lista.\nprint(list(zipado)) ### para visualizar o conte\u00fado de zipado, precisamos converter para lista.\n\nfor x in zip(lista_a, lista_b):\n    print(x)\n\n\n\n# Aproveitando para mostrar a fun\u00e7ao enumerate()...\n# A fun\u00e7ao enumerate() \u00e9 utilizada para retornar o \u00edndice e o valor de um item em uma lista.\nprint('listas com enumerate...')    \nfor x,y in enumerate(zip(lista_a, lista_b)):\n    print(x,y)\n</pre> ## pratique um pouco, rode os exemplos dos links para te ajudar a compreender o que est\u00e1 acontecendo...  # A fun\u00e7ao zip() \u00e9 utilizada para unir duas listas.   lista_a = [6, 7, 8, 9, 1, 2, 3, 4, 5] lista_b = ['R', 'A', 'I', 'M', 'U', 'N', 'D', 'O','S']  print('Unindo as listas...') zipado = zip(lista_a, lista_b) # print(zipado[0]) ### essa linha vai dar erro, pois zipado \u00e9 um objeto do tipo zip, e n\u00e3o uma lista. print(list(zipado)) ### para visualizar o conte\u00fado de zipado, precisamos converter para lista.  for x in zip(lista_a, lista_b):     print(x)    # Aproveitando para mostrar a fun\u00e7ao enumerate()... # A fun\u00e7ao enumerate() \u00e9 utilizada para retornar o \u00edndice e o valor de um item em uma lista. print('listas com enumerate...')     for x,y in enumerate(zip(lista_a, lista_b)):     print(x,y)  In\u00a0[\u00a0]: Copied! <pre>## pratique um pouco, rode os exemplos dos links para te ajudar a compreender o que est\u00e1 acontecendo...\n\n# A funcao list comprehension \u00e9 uma forma de criar listas de forma mais compacta e elegante. 'Pythonica'.\n\n# A sintaxe \u00e9: [expressao for item in lista]\n\n# Exemplo 1:\n\n# da forma tradicional, teriamos que fazer algo assim:\nfruits = [\"apple\", \"banana\", \"cherry\", \"kiwi\", \"mango\"]\nnewlist = []\n\nfor x in fruits:\n  if \"a\" in x:\n    newlist.append(x)\n\nprint(newlist)\n\n# usando list comprehension, podemos fazer assim:\nfruits = [\"apple\", \"banana\", \"cherry\", \"kiwi\", \"mango\"]\nnewlist = [x for x in fruits if \"a\" in x]\nprint(newlist)\n\n# Exemplo 2:\n\n# da forma tradicional, teriamos que fazer algo assim:\nlista = [1, 2, 3, 4, 5]\nnova_lista = []\n\nfor x in lista:\n    nova_lista.append(x + 10)\n\nprint(nova_lista)\n\n# usando list comprehension, podemos fazer assim:\nlista = [1, 2, 3, 4, 5]\nnova_lista = [x + 10 for x in lista]\nprint(nova_lista)\n\n# Exemplo 3:\n# podemos usar list comprehension para somar os elementos de duas listas...\nlista1 = [1, 2, 3, 4, 5]\nlista2 = [6, 7, 8, 9, 10]\n\nsoma = [x + y for x, y in zip(lista1, lista2)]\n\nprint(soma)\n</pre> ## pratique um pouco, rode os exemplos dos links para te ajudar a compreender o que est\u00e1 acontecendo...  # A funcao list comprehension \u00e9 uma forma de criar listas de forma mais compacta e elegante. 'Pythonica'.  # A sintaxe \u00e9: [expressao for item in lista]  # Exemplo 1:  # da forma tradicional, teriamos que fazer algo assim: fruits = [\"apple\", \"banana\", \"cherry\", \"kiwi\", \"mango\"] newlist = []  for x in fruits:   if \"a\" in x:     newlist.append(x)  print(newlist)  # usando list comprehension, podemos fazer assim: fruits = [\"apple\", \"banana\", \"cherry\", \"kiwi\", \"mango\"] newlist = [x for x in fruits if \"a\" in x] print(newlist)  # Exemplo 2:  # da forma tradicional, teriamos que fazer algo assim: lista = [1, 2, 3, 4, 5] nova_lista = []  for x in lista:     nova_lista.append(x + 10)  print(nova_lista)  # usando list comprehension, podemos fazer assim: lista = [1, 2, 3, 4, 5] nova_lista = [x + 10 for x in lista] print(nova_lista)  # Exemplo 3: # podemos usar list comprehension para somar os elementos de duas listas... lista1 = [1, 2, 3, 4, 5] lista2 = [6, 7, 8, 9, 10]  soma = [x + y for x, y in zip(lista1, lista2)]  print(soma) In\u00a0[\u00a0]: Copied! <pre>## pratique um pouco, rode os exemplos dos links para te ajudar a compreender o que est\u00e1 acontecendo...\n\n# a fun\u00e7\u00e3o lambda \u00e9 uma forma de criar fun\u00e7\u00f5es an\u00f4nimas, ou seja, fun\u00e7\u00f5es que n\u00e3o tem um nome associado. \n# Elas s\u00e3o \u00fateis quando voc\u00ea precisa de uma fun\u00e7\u00e3o simples por um curto per\u00edodo de tempo e n\u00e3o quer defini-la usando a sintaxe padr\u00e3o def.\n\n# A sintaxe \u00e9: lambda arguments : expression \n\n# Exemplo 1:\nx = lambda a : a + 10\nprint(x(5))\n\n# Exemplo 2:\nx = lambda a, b : a * b\nprint(x(5, 6))\n\n# Exemplo 3:\nx = lambda a, b, c : a + b + c\nprint(x(5, 6, 2))\n\n# Exemplo 4:\n# podemos usar lambda para ordenar uma lista de tuplas...\nlista = [(1, 2), (4, 1), (9, 10), (13, -3)]\nlista.sort(key=lambda x: x[1])\nprint(lista)\n\n\n# Para avan\u00e7ar na programa\u00e7\u00e3o em linguagem python, sugiro praticar e conhecer essas fun\u00e7\u00f5es e outras tais como: 'map', 'filter' e 'sorted'.\n# A pr\u00e1tica leva a perfei\u00e7\u00e3o.\n</pre> ## pratique um pouco, rode os exemplos dos links para te ajudar a compreender o que est\u00e1 acontecendo...  # a fun\u00e7\u00e3o lambda \u00e9 uma forma de criar fun\u00e7\u00f5es an\u00f4nimas, ou seja, fun\u00e7\u00f5es que n\u00e3o tem um nome associado.  # Elas s\u00e3o \u00fateis quando voc\u00ea precisa de uma fun\u00e7\u00e3o simples por um curto per\u00edodo de tempo e n\u00e3o quer defini-la usando a sintaxe padr\u00e3o def.  # A sintaxe \u00e9: lambda arguments : expression   # Exemplo 1: x = lambda a : a + 10 print(x(5))  # Exemplo 2: x = lambda a, b : a * b print(x(5, 6))  # Exemplo 3: x = lambda a, b, c : a + b + c print(x(5, 6, 2))  # Exemplo 4: # podemos usar lambda para ordenar uma lista de tuplas... lista = [(1, 2), (4, 1), (9, 10), (13, -3)] lista.sort(key=lambda x: x[1]) print(lista)   # Para avan\u00e7ar na programa\u00e7\u00e3o em linguagem python, sugiro praticar e conhecer essas fun\u00e7\u00f5es e outras tais como: 'map', 'filter' e 'sorted'. # A pr\u00e1tica leva a perfei\u00e7\u00e3o.   In\u00a0[\u00a0]: Copied! <pre>cnts, _ = cv2.findContours(erode.copy(),cv2.RETR_EXTERNAL,cv2.CHAIN_APPROX_SIMPLE)\n\n# Ordena a lista de contornos para ficar da esquerda para direita. \n# Vamos precisar disso mais tarde.  \n# https://github.com/jrosebr1/imutils/blob/master/imutils/contours.py\n\n(cnts, boundingBoxes) = zip(*sorted(zip(cnts, [cv2.boundingRect(c) for c in cnts]), key=lambda b: b[1][0], reverse=False))\n</pre> cnts, _ = cv2.findContours(erode.copy(),cv2.RETR_EXTERNAL,cv2.CHAIN_APPROX_SIMPLE)  # Ordena a lista de contornos para ficar da esquerda para direita.  # Vamos precisar disso mais tarde.   # https://github.com/jrosebr1/imutils/blob/master/imutils/contours.py  (cnts, boundingBoxes) = zip(*sorted(zip(cnts, [cv2.boundingRect(c) for c in cnts]), key=lambda b: b[1][0], reverse=False)) In\u00a0[\u00a0]: Copied! <pre># https://github.com/jrosebr1/imutils/blob/master/imutils/perspective.py\n# ordena os pontos do contorno de tal modo que eles\n# apare\u00e7am na seguinte ordem: topo-esquerda, topo-direita,\n# base-direita e base-esquerda\nimport numpy as np\nfrom scipy.spatial import distance as dist\n\n\ndef order_points(pts):\n     xSorted = pts[np.argsort(pts[:, 0]), :]\n\n    # grab the left-most and right-most points from the sorted\n    # x-roodinate points\n     leftMost = xSorted[:2, :]\n     rightMost = xSorted[2:, :]\n\n    # now, sort the left-most coordinates according to their\n    # y-coordinates so we can grab the top-left and bottom-left\n    # points, respectively\n     leftMost = leftMost[np.argsort(leftMost[:, 1]), :]\n     (tl, bl) = leftMost\n\n    # now that we have the top-left coordinate, use it as an\n    # anchor to calculate the Euclidean distance between the\n    # top-left and right-most points; by the Pythagorean\n    # theorem, the point with the largest distance will be\n    # our bottom-right point\n     D = dist.cdist(tl[np.newaxis], rightMost, \"euclidean\")[0]\n     (br, tr) = rightMost[np.argsort(D)[::-1], :]\n\n    # return the coordinates in top-left, top-right,\n    # bottom-right, and bottom-left order\n     return np.array([tl, tr, br, bl], dtype=\"float32\")   \n</pre> # https://github.com/jrosebr1/imutils/blob/master/imutils/perspective.py # ordena os pontos do contorno de tal modo que eles # apare\u00e7am na seguinte ordem: topo-esquerda, topo-direita, # base-direita e base-esquerda import numpy as np from scipy.spatial import distance as dist   def order_points(pts):      xSorted = pts[np.argsort(pts[:, 0]), :]      # grab the left-most and right-most points from the sorted     # x-roodinate points      leftMost = xSorted[:2, :]      rightMost = xSorted[2:, :]      # now, sort the left-most coordinates according to their     # y-coordinates so we can grab the top-left and bottom-left     # points, respectively      leftMost = leftMost[np.argsort(leftMost[:, 1]), :]      (tl, bl) = leftMost      # now that we have the top-left coordinate, use it as an     # anchor to calculate the Euclidean distance between the     # top-left and right-most points; by the Pythagorean     # theorem, the point with the largest distance will be     # our bottom-right point      D = dist.cdist(tl[np.newaxis], rightMost, \"euclidean\")[0]      (br, tr) = rightMost[np.argsort(D)[::-1], :]      # return the coordinates in top-left, top-right,     # bottom-right, and bottom-left order      return np.array([tl, tr, br, bl], dtype=\"float32\")    In\u00a0[\u00a0]: Copied! <pre>orig = image.copy()\n\n#Percorre todos os contornos\nfor c in cnts:\n  # se o contorno n\u00e3o \u00e9 suficientemente grande, ignor\u00e1-lo\n  if cv2.contourArea(c) &lt; 100:\n    continue\n  \n  # calcula a bounding box rotacionada do contorno\n  box = cv2.minAreaRect(c)\n  box = cv2.boxPoints(box) \n  box = np.array(box, dtype=\"int\")\n\n  #ordena os pontos do contorno de tal modo que eles\n  #apare\u00e7am na seguinte ordem: topo-esquerda, topo-direita,\n  #base-direita e base-esquerda\n  \n  box = order_points(box)\n  #print(box)\n  cv2.drawContours(orig, [box.astype(\"int\")], -1, (0, 255, 0), 2)\n  for (x, y) in box:\n    cv2.circle(orig, (int(x), int(y)), 5, (255, 0, 0), -1)\n\nplt.figure(figsize = (10,10))\nplt.imshow(orig); plt.show();\n</pre>  orig = image.copy()  #Percorre todos os contornos for c in cnts:   # se o contorno n\u00e3o \u00e9 suficientemente grande, ignor\u00e1-lo   if cv2.contourArea(c) &lt; 100:     continue      # calcula a bounding box rotacionada do contorno   box = cv2.minAreaRect(c)   box = cv2.boxPoints(box)    box = np.array(box, dtype=\"int\")    #ordena os pontos do contorno de tal modo que eles   #apare\u00e7am na seguinte ordem: topo-esquerda, topo-direita,   #base-direita e base-esquerda      box = order_points(box)   #print(box)   cv2.drawContours(orig, [box.astype(\"int\")], -1, (0, 255, 0), 2)   for (x, y) in box:     cv2.circle(orig, (int(x), int(y)), 5, (255, 0, 0), -1)  plt.figure(figsize = (10,10)) plt.imshow(orig); plt.show();  <p>OBTEN\u00c7\u00c3O DOS PONTOS M\u00c9DIOS</p> <p>Vamos, agora, obter os pontos-m\u00e9dios de cada regi\u00e3o identificada e desenh\u00e1-los:</p> In\u00a0[\u00a0]: Copied! <pre>import numpy as np\n\ndef midpoint(ptA, ptB):\n  return ((ptA[0] + ptB[0]) * 0.5, (ptA[1] + ptB[1]) * 0.5)\n\norig = image.copy()\n#Percorre todos os contornos\nfor c in cnts:\n  # ignora contornos muito pequenos\n  if cv2.contourArea(c) &lt; 100:\n    continue\n  # calcula a bounding box rotacionada do contorno\n  box = cv2.minAreaRect(c)\n  box = cv2.boxPoints(box) \n  box = np.array(box, dtype=\"int\")\n  \n  #ordena os pontos do contorno de tal modo que eles\n  #apare\u00e7am na seguinte ordem: top-left, top-right,\n  #bottom-right e bottom-left\n  box = order_points(box)\n  cv2.drawContours(orig, [box.astype(\"int\")], -1, (0, 255, 0), 2)\n  for (x, y) in box:\n    cv2.circle(orig, (int(x), int(y)), 5, (255, 0, 0), -1)\n\n    \n #-----------------------------------isso \u00e9 novidade ----------------   \n    \n  #obt\u00e9m os pontos m\u00e9dios de top-left/top-right e bottom-left e bottom-right\n  (tl, tr, br, bl) = box\n  (tltrX, tltrY) = midpoint(tl, tr)\n  (blbrX, blbrY) = midpoint(bl, br)\n  \n  #obt\u00e9m os pontos m\u00e9dios de top-left/bottom-left e top-right e bottom-right\n  (tlblX, tlblY) = midpoint(tl, bl)\n  (trbrX, trbrY) = midpoint(tr, br)\n\n  #desenha c\u00edculos nos pontos-m\u00e9dios\n  cv2.circle(orig, (int(tltrX), int(tltrY)), 5, (255, 0, 0), -1)\n  cv2.circle(orig, (int(blbrX), int(blbrY)), 5, (255, 0, 0), -1)\n  cv2.circle(orig, (int(tlblX), int(tlblY)), 5, (255, 0, 0), -1)\n  cv2.circle(orig, (int(trbrX), int(trbrY)), 5, (255, 0, 0), -1)\n  \n  #une os pontos-m\u00e9dios com segmentos de reta\n  cv2.line(orig, (int(tltrX), int(tltrY)), (int(blbrX), int(blbrY)),(255, 0, 255), 2)\n  cv2.line(orig, (int(tlblX), int(tlblY)), (int(trbrX), int(trbrY)),(255, 0, 255), 2)\n\nplt.figure(figsize = (10,10))\nplt.imshow(orig); plt.show();\n</pre> import numpy as np  def midpoint(ptA, ptB):   return ((ptA[0] + ptB[0]) * 0.5, (ptA[1] + ptB[1]) * 0.5)  orig = image.copy() #Percorre todos os contornos for c in cnts:   # ignora contornos muito pequenos   if cv2.contourArea(c) &lt; 100:     continue   # calcula a bounding box rotacionada do contorno   box = cv2.minAreaRect(c)   box = cv2.boxPoints(box)    box = np.array(box, dtype=\"int\")      #ordena os pontos do contorno de tal modo que eles   #apare\u00e7am na seguinte ordem: top-left, top-right,   #bottom-right e bottom-left   box = order_points(box)   cv2.drawContours(orig, [box.astype(\"int\")], -1, (0, 255, 0), 2)   for (x, y) in box:     cv2.circle(orig, (int(x), int(y)), 5, (255, 0, 0), -1)        #-----------------------------------isso \u00e9 novidade ----------------           #obt\u00e9m os pontos m\u00e9dios de top-left/top-right e bottom-left e bottom-right   (tl, tr, br, bl) = box   (tltrX, tltrY) = midpoint(tl, tr)   (blbrX, blbrY) = midpoint(bl, br)      #obt\u00e9m os pontos m\u00e9dios de top-left/bottom-left e top-right e bottom-right   (tlblX, tlblY) = midpoint(tl, bl)   (trbrX, trbrY) = midpoint(tr, br)    #desenha c\u00edculos nos pontos-m\u00e9dios   cv2.circle(orig, (int(tltrX), int(tltrY)), 5, (255, 0, 0), -1)   cv2.circle(orig, (int(blbrX), int(blbrY)), 5, (255, 0, 0), -1)   cv2.circle(orig, (int(tlblX), int(tlblY)), 5, (255, 0, 0), -1)   cv2.circle(orig, (int(trbrX), int(trbrY)), 5, (255, 0, 0), -1)      #une os pontos-m\u00e9dios com segmentos de reta   cv2.line(orig, (int(tltrX), int(tltrY)), (int(blbrX), int(blbrY)),(255, 0, 255), 2)   cv2.line(orig, (int(tlblX), int(tlblY)), (int(trbrX), int(trbrY)),(255, 0, 255), 2)  plt.figure(figsize = (10,10)) plt.imshow(orig); plt.show(); <p>OBTEN\u00c7\u00c3O DAS MEDIDAS</p> <p>Para obter as medidas dos objetos, precisamos tomar um objeto de refer\u00eancia (ponto de calibra\u00e7\u00e3o) de tamanho conhecido. Na imagem anterior, vamos tomar como medida de refer\u00eancia a moeda de d\u00f3lar norte-americano, cujo comprimento \u00e9 2.43 cm. A partir dela, definimos todas as outras medidas.</p> <p>\u00c9 neste ponto que vai servir ter feito a ordena\u00e7\u00e3o do <code>cnts</code> da esquerda para a direita, a nossa moeda de d\u00f3lar esta bem destacada no lado esquerdo da imagem, desta forma fica facil fazer a calibra\u00e7\u00e3o pois ser\u00e1 o primeiro item da lista.</p> In\u00a0[\u00a0]: Copied! <pre>width=2.43\npixelsPerMetric=None\n</pre> width=2.43 pixelsPerMetric=None In\u00a0[\u00a0]: Copied! <pre>def midpoint(ptA, ptB):\n  return ((ptA[0] + ptB[0]) * 0.5, (ptA[1] + ptB[1]) * 0.5)\n\norig = image.copy()\n#Percorre todos os contornos\nfor c in cnts:\n  # se o contorno n\u00e3o \u00e9 suficientemente grande, ignor\u00e1-lo\n  if cv2.contourArea(c) &lt; 100:\n    continue\n  # calcula a bounding box rotacionada do contorno\n  box = cv2.minAreaRect(c)\n  box = cv2.boxPoints(box) \n  box = np.array(box, dtype=\"int\")\n  #ordena os pontos do contorno de tal modo que eles\n  #apare\u00e7am na seguinte ordem: top-left, top-right,\n  #bottom-right e bottom-left\n  box = order_points(box)\n  cv2.drawContours(orig, [box.astype(\"int\")], -1, (0, 255, 0), 2)\n  for (x, y) in box:\n    cv2.circle(orig, (int(x), int(y)), 5, (25, 0, 0), -1)\n\n  #obt\u00e9m os pontos m\u00e9dios de top-left/top-right e bottom-left e bottom-right\n  (tl, tr, br, bl) = box\n  (tltrX, tltrY) = midpoint(tl, tr)\n  (blbrX, blbrY) = midpoint(bl, br)\n  \n  #obt\u00e9m os pontos m\u00e9dios de top-left/bottom-left e top-right e bottom-right\n  (tlblX, tlblY) = midpoint(tl, bl)\n  (trbrX, trbrY) = midpoint(tr, br)\n\n  #desenha c\u00edculos nos pontos-m\u00e9dios\n  cv2.circle(orig, (int(tltrX), int(tltrY)), 5, (255, 0, 0), -1)\n  cv2.circle(orig, (int(blbrX), int(blbrY)), 5, (255, 0, 0), -1)\n  cv2.circle(orig, (int(tlblX), int(tlblY)), 5, (255, 0, 0), -1)\n  cv2.circle(orig, (int(trbrX), int(trbrY)), 5, (255, 0, 0), -1)\n  \n  #une os pontos-m\u00e9dios com segmentos de reta\n  cv2.line(orig, (int(tltrX), int(tltrY)), (int(blbrX), int(blbrY)),(255, 0, 255), 2)\n  cv2.line(orig, (int(tlblX), int(tlblY)), (int(trbrX), int(trbrY)),(255, 0, 255), 2)\n ###-------------n\u00e3o te mnovidade  \n    \n  # C\u00e1lculo da dist\u00e2ncia entre dois pontos, dist\u00e2ncia euclidiana\n  dA = dist.euclidean((tltrX, tltrY), (blbrX, blbrY))\n  dB = dist.euclidean((tlblX, tlblY), (trbrX, trbrY))\n\n##########---------------isso \u00e9 novidade--------------------------------------------------------------------\n\n  # define a escala para relacionar pixel por centrimetro\n  if pixelsPerMetric is None:\n    pixelsPerMetric = dB / width\n  \n  dimA = dA / pixelsPerMetric\n  dimB = dB / pixelsPerMetric\n  \n  cv2.putText(orig, \"{:.2f}cm\".format(dimB),(int(tltrX - 15), int(tltrY - 10)), cv2.FONT_HERSHEY_SIMPLEX,0.50, (255, 255, 255), 1)\n  cv2.putText(orig, \"{:.2f}cm\".format(dimA),(int(trbrX + 10), int(trbrY)), cv2.FONT_HERSHEY_SIMPLEX,0.50, (255, 255, 255), 1) \n  \nplt.figure(figsize = (10,10))\nplt.imshow(orig); plt.show();\n</pre> def midpoint(ptA, ptB):   return ((ptA[0] + ptB[0]) * 0.5, (ptA[1] + ptB[1]) * 0.5)  orig = image.copy() #Percorre todos os contornos for c in cnts:   # se o contorno n\u00e3o \u00e9 suficientemente grande, ignor\u00e1-lo   if cv2.contourArea(c) &lt; 100:     continue   # calcula a bounding box rotacionada do contorno   box = cv2.minAreaRect(c)   box = cv2.boxPoints(box)    box = np.array(box, dtype=\"int\")   #ordena os pontos do contorno de tal modo que eles   #apare\u00e7am na seguinte ordem: top-left, top-right,   #bottom-right e bottom-left   box = order_points(box)   cv2.drawContours(orig, [box.astype(\"int\")], -1, (0, 255, 0), 2)   for (x, y) in box:     cv2.circle(orig, (int(x), int(y)), 5, (25, 0, 0), -1)    #obt\u00e9m os pontos m\u00e9dios de top-left/top-right e bottom-left e bottom-right   (tl, tr, br, bl) = box   (tltrX, tltrY) = midpoint(tl, tr)   (blbrX, blbrY) = midpoint(bl, br)      #obt\u00e9m os pontos m\u00e9dios de top-left/bottom-left e top-right e bottom-right   (tlblX, tlblY) = midpoint(tl, bl)   (trbrX, trbrY) = midpoint(tr, br)    #desenha c\u00edculos nos pontos-m\u00e9dios   cv2.circle(orig, (int(tltrX), int(tltrY)), 5, (255, 0, 0), -1)   cv2.circle(orig, (int(blbrX), int(blbrY)), 5, (255, 0, 0), -1)   cv2.circle(orig, (int(tlblX), int(tlblY)), 5, (255, 0, 0), -1)   cv2.circle(orig, (int(trbrX), int(trbrY)), 5, (255, 0, 0), -1)      #une os pontos-m\u00e9dios com segmentos de reta   cv2.line(orig, (int(tltrX), int(tltrY)), (int(blbrX), int(blbrY)),(255, 0, 255), 2)   cv2.line(orig, (int(tlblX), int(tlblY)), (int(trbrX), int(trbrY)),(255, 0, 255), 2)  ###-------------n\u00e3o te mnovidade          # C\u00e1lculo da dist\u00e2ncia entre dois pontos, dist\u00e2ncia euclidiana   dA = dist.euclidean((tltrX, tltrY), (blbrX, blbrY))   dB = dist.euclidean((tlblX, tlblY), (trbrX, trbrY))  ##########---------------isso \u00e9 novidade--------------------------------------------------------------------    # define a escala para relacionar pixel por centrimetro   if pixelsPerMetric is None:     pixelsPerMetric = dB / width      dimA = dA / pixelsPerMetric   dimB = dB / pixelsPerMetric      cv2.putText(orig, \"{:.2f}cm\".format(dimB),(int(tltrX - 15), int(tltrY - 10)), cv2.FONT_HERSHEY_SIMPLEX,0.50, (255, 255, 255), 1)   cv2.putText(orig, \"{:.2f}cm\".format(dimA),(int(trbrX + 10), int(trbrY)), cv2.FONT_HERSHEY_SIMPLEX,0.50, (255, 255, 255), 1)     plt.figure(figsize = (10,10)) plt.imshow(orig); plt.show(); <p>Refer\u00eancia:</p> <ul> <li>https://pyimagesearch.com/2016/03/28/measuring-size-of-objects-in-an-image-with-opencv/</li> </ul> In\u00a0[\u00a0]: Copied! <pre>%matplotlib inline\nimport cv2\nfrom matplotlib import pyplot as plt\nimport numpy as np\n\nimg = cv2.imread('objects2.png')\nimg = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n\nplt.figure(figsize = (10,10))\nplt.imshow(img); plt.show();\n</pre> %matplotlib inline import cv2 from matplotlib import pyplot as plt import numpy as np  img = cv2.imread('objects2.png') img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)  plt.figure(figsize = (10,10)) plt.imshow(img); plt.show(); In\u00a0[8]: Copied! <pre>### Seu c\u00f3digo aqui....\n\n## uma solu\u00e7ao simples \u00e9 basicamente copiar e colar o c\u00f3digo acima e adaptar para a nova imagem.\n# funciona? sim, mas n\u00e3o \u00e9 a melhor forma de fazer. \n\n# Sugiro utilizar essa exercicio para praticar python e programa\u00e7\u00e3o, tente criar novas fun\u00e7\u00f5es para refatorar o c\u00f3digo.\n\n%matplotlib inline\nimport cv2\nfrom matplotlib import pyplot as plt\nimport numpy as np\nfrom scipy.spatial import distance as dist\n\nwidth=8.89\npixelsPerMetric=None\n\ndef order_points(pts):\n     xSorted = pts[np.argsort(pts[:, 0]), :]\n\n    # grab the left-most and right-most points from the sorted\n    # x-roodinate points\n     leftMost = xSorted[:2, :]\n     rightMost = xSorted[2:, :]\n\n    # now, sort the left-most coordinates according to their\n    # y-coordinates so we can grab the top-left and bottom-left\n    # points, respectively\n     leftMost = leftMost[np.argsort(leftMost[:, 1]), :]\n     (tl, bl) = leftMost\n\n    # now that we have the top-left coordinate, use it as an\n    # anchor to calculate the Euclidean distance between the\n    # top-left and right-most points; by the Pythagorean\n    # theorem, the point with the largest distance will be\n    # our bottom-right point\n     D = dist.cdist(tl[np.newaxis], rightMost, \"euclidean\")[0]\n     (br, tr) = rightMost[np.argsort(D)[::-1], :]\n\n    # return the coordinates in top-left, top-right,\n    # bottom-right, and bottom-left order\n     return np.array([tl, tr, br, bl], dtype=\"float32\")   \n\n\ndef midpoint(ptA, ptB):\n  return ((ptA[0] + ptB[0]) * 0.5, (ptA[1] + ptB[1]) * 0.5)\n\n#carregamos a imagem, convertemos para n\u00edveis de cinza e a borramos levemente\nimage = cv2.imread('objects2.png')\nimage = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\ngray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n\n# aplico um filtro gaussiano para suaviazar a imagem...\ngray = cv2.GaussianBlur(gray, (9,9), 0)\n\n#calculamos as arestas e realizamos uma dilata\u00e7\u00e3o + eros\u00e3o para fechar\n#eventuais gaps entre as arestas dos objetos\nedged = cv2.Canny(gray, 50, 250)\ndilate = cv2.dilate(edged, None, iterations=2)\nerode = cv2.erode(dilate, None, iterations=2)\n\n\ncnts, _ = cv2.findContours(erode.copy(),cv2.RETR_EXTERNAL,cv2.CHAIN_APPROX_SIMPLE)\n\n(cnts, boundingBoxes) = zip(*sorted(zip(cnts, [cv2.boundingRect(c) for c in cnts]), key=lambda b: b[1][0], reverse=False))\n\norig = image.copy()\n#Percorre todos os contornos\nfor c in cnts:\n  # se o contorno n\u00e3o \u00e9 suficientemente grande, ignor\u00e1-lo\n  if cv2.contourArea(c) &lt; 100:\n    continue\n  # calcula a bounding box rotacionada do contorno\n  box = cv2.minAreaRect(c)\n  box = cv2.boxPoints(box) \n  box = np.array(box, dtype=\"int\")\n  #ordena os pontos do contorno de tal modo que eles\n  #apare\u00e7am na seguinte ordem: top-left, top-right,\n  #bottom-right e bottom-left\n  box = order_points(box)\n  cv2.drawContours(orig, [box.astype(\"int\")], -1, (0, 255, 0), 2)\n  for (x, y) in box:\n    cv2.circle(orig, (int(x), int(y)), 5, (25, 0, 0), -1)\n\n  #obt\u00e9m os pontos m\u00e9dios de top-left/top-right e bottom-left e bottom-right\n  (tl, tr, br, bl) = box\n  (tltrX, tltrY) = midpoint(tl, tr)\n  (blbrX, blbrY) = midpoint(bl, br)\n  \n  #obt\u00e9m os pontos m\u00e9dios de top-left/bottom-left e top-right e bottom-right\n  (tlblX, tlblY) = midpoint(tl, bl)\n  (trbrX, trbrY) = midpoint(tr, br)\n\n  #desenha c\u00edculos nos pontos-m\u00e9dios\n  cv2.circle(orig, (int(tltrX), int(tltrY)), 5, (255, 0, 0), -1)\n  cv2.circle(orig, (int(blbrX), int(blbrY)), 5, (255, 0, 0), -1)\n  cv2.circle(orig, (int(tlblX), int(tlblY)), 5, (255, 0, 0), -1)\n  cv2.circle(orig, (int(trbrX), int(trbrY)), 5, (255, 0, 0), -1)\n  \n  #une os pontos-m\u00e9dios com segmentos de reta\n  cv2.line(orig, (int(tltrX), int(tltrY)), (int(blbrX), int(blbrY)),(255, 0, 255), 2)\n  cv2.line(orig, (int(tlblX), int(tlblY)), (int(trbrX), int(trbrY)),(255, 0, 255), 2)\n ###-------------n\u00e3o te mnovidade  \n    \n  # C\u00e1lculo da dist\u00e2ncia entre dois pontos, dist\u00e2ncia euclidiana\n  dA = dist.euclidean((tltrX, tltrY), (blbrX, blbrY))\n  dB = dist.euclidean((tlblX, tlblY), (trbrX, trbrY))\n\n##########---------------isso \u00e9 novidade--------------------------------------------------------------------\n\n  # define a escala para relacionar pixel por centrimetro\n  if pixelsPerMetric is None:\n    pixelsPerMetric = dB / width\n  \n  dimA = dA / pixelsPerMetric\n  dimB = dB / pixelsPerMetric\n  \n  cv2.putText(orig, \"{:.2f}cm\".format(dimB),(int(tltrX - 15), int(tltrY - 10)), cv2.FONT_HERSHEY_SIMPLEX,0.50, (255, 255, 255), 1)\n  cv2.putText(orig, \"{:.2f}cm\".format(dimA),(int(trbrX + 10), int(trbrY)), cv2.FONT_HERSHEY_SIMPLEX,0.50, (255, 255, 255), 1) \n  \nplt.figure(figsize = (10,10))\nplt.imshow(orig); plt.show();\n</pre> ### Seu c\u00f3digo aqui....  ## uma solu\u00e7ao simples \u00e9 basicamente copiar e colar o c\u00f3digo acima e adaptar para a nova imagem. # funciona? sim, mas n\u00e3o \u00e9 a melhor forma de fazer.   # Sugiro utilizar essa exercicio para praticar python e programa\u00e7\u00e3o, tente criar novas fun\u00e7\u00f5es para refatorar o c\u00f3digo.  %matplotlib inline import cv2 from matplotlib import pyplot as plt import numpy as np from scipy.spatial import distance as dist  width=8.89 pixelsPerMetric=None  def order_points(pts):      xSorted = pts[np.argsort(pts[:, 0]), :]      # grab the left-most and right-most points from the sorted     # x-roodinate points      leftMost = xSorted[:2, :]      rightMost = xSorted[2:, :]      # now, sort the left-most coordinates according to their     # y-coordinates so we can grab the top-left and bottom-left     # points, respectively      leftMost = leftMost[np.argsort(leftMost[:, 1]), :]      (tl, bl) = leftMost      # now that we have the top-left coordinate, use it as an     # anchor to calculate the Euclidean distance between the     # top-left and right-most points; by the Pythagorean     # theorem, the point with the largest distance will be     # our bottom-right point      D = dist.cdist(tl[np.newaxis], rightMost, \"euclidean\")[0]      (br, tr) = rightMost[np.argsort(D)[::-1], :]      # return the coordinates in top-left, top-right,     # bottom-right, and bottom-left order      return np.array([tl, tr, br, bl], dtype=\"float32\")      def midpoint(ptA, ptB):   return ((ptA[0] + ptB[0]) * 0.5, (ptA[1] + ptB[1]) * 0.5)  #carregamos a imagem, convertemos para n\u00edveis de cinza e a borramos levemente image = cv2.imread('objects2.png') image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB) gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)  # aplico um filtro gaussiano para suaviazar a imagem... gray = cv2.GaussianBlur(gray, (9,9), 0)  #calculamos as arestas e realizamos uma dilata\u00e7\u00e3o + eros\u00e3o para fechar #eventuais gaps entre as arestas dos objetos edged = cv2.Canny(gray, 50, 250) dilate = cv2.dilate(edged, None, iterations=2) erode = cv2.erode(dilate, None, iterations=2)   cnts, _ = cv2.findContours(erode.copy(),cv2.RETR_EXTERNAL,cv2.CHAIN_APPROX_SIMPLE)  (cnts, boundingBoxes) = zip(*sorted(zip(cnts, [cv2.boundingRect(c) for c in cnts]), key=lambda b: b[1][0], reverse=False))  orig = image.copy() #Percorre todos os contornos for c in cnts:   # se o contorno n\u00e3o \u00e9 suficientemente grande, ignor\u00e1-lo   if cv2.contourArea(c) &lt; 100:     continue   # calcula a bounding box rotacionada do contorno   box = cv2.minAreaRect(c)   box = cv2.boxPoints(box)    box = np.array(box, dtype=\"int\")   #ordena os pontos do contorno de tal modo que eles   #apare\u00e7am na seguinte ordem: top-left, top-right,   #bottom-right e bottom-left   box = order_points(box)   cv2.drawContours(orig, [box.astype(\"int\")], -1, (0, 255, 0), 2)   for (x, y) in box:     cv2.circle(orig, (int(x), int(y)), 5, (25, 0, 0), -1)    #obt\u00e9m os pontos m\u00e9dios de top-left/top-right e bottom-left e bottom-right   (tl, tr, br, bl) = box   (tltrX, tltrY) = midpoint(tl, tr)   (blbrX, blbrY) = midpoint(bl, br)      #obt\u00e9m os pontos m\u00e9dios de top-left/bottom-left e top-right e bottom-right   (tlblX, tlblY) = midpoint(tl, bl)   (trbrX, trbrY) = midpoint(tr, br)    #desenha c\u00edculos nos pontos-m\u00e9dios   cv2.circle(orig, (int(tltrX), int(tltrY)), 5, (255, 0, 0), -1)   cv2.circle(orig, (int(blbrX), int(blbrY)), 5, (255, 0, 0), -1)   cv2.circle(orig, (int(tlblX), int(tlblY)), 5, (255, 0, 0), -1)   cv2.circle(orig, (int(trbrX), int(trbrY)), 5, (255, 0, 0), -1)      #une os pontos-m\u00e9dios com segmentos de reta   cv2.line(orig, (int(tltrX), int(tltrY)), (int(blbrX), int(blbrY)),(255, 0, 255), 2)   cv2.line(orig, (int(tlblX), int(tlblY)), (int(trbrX), int(trbrY)),(255, 0, 255), 2)  ###-------------n\u00e3o te mnovidade          # C\u00e1lculo da dist\u00e2ncia entre dois pontos, dist\u00e2ncia euclidiana   dA = dist.euclidean((tltrX, tltrY), (blbrX, blbrY))   dB = dist.euclidean((tlblX, tlblY), (trbrX, trbrY))  ##########---------------isso \u00e9 novidade--------------------------------------------------------------------    # define a escala para relacionar pixel por centrimetro   if pixelsPerMetric is None:     pixelsPerMetric = dB / width      dimA = dA / pixelsPerMetric   dimB = dB / pixelsPerMetric      cv2.putText(orig, \"{:.2f}cm\".format(dimB),(int(tltrX - 15), int(tltrY - 10)), cv2.FONT_HERSHEY_SIMPLEX,0.50, (255, 255, 255), 1)   cv2.putText(orig, \"{:.2f}cm\".format(dimA),(int(trbrX + 10), int(trbrY)), cv2.FONT_HERSHEY_SIMPLEX,0.50, (255, 255, 255), 1)     plt.figure(figsize = (10,10)) plt.imshow(orig); plt.show();  In\u00a0[18]: Copied! <pre>### vou criar algumas fun\u00e7\u00f5es para refatorar o c\u00f3digo acima...\n\n\n%matplotlib inline\nimport cv2\nfrom matplotlib import pyplot as plt\nimport numpy as np\nfrom scipy.spatial import distance as dist\n\ndef order_points(pts):\n    x_sorted = pts[np.argsort(pts[:, 0]), :]\n    left_most = x_sorted[:2, :]\n    right_most = x_sorted[2:, :]\n    left_most = left_most[np.argsort(left_most[:, 1]), :]\n    tl, bl = left_most\n    d = dist.cdist(tl[np.newaxis], right_most, \"euclidean\")[0]\n    br, tr = right_most[np.argsort(d)[::-1], :]\n    return np.array([tl, tr, br, bl], dtype=\"float32\")\n\ndef midpoint(pt_a, pt_b):\n    return ((pt_a[0] + pt_b[0]) * 0.5, (pt_a[1] + pt_b[1]) * 0.5)\n\ndef process_image(image_path):\n    image = cv2.imread(image_path)\n    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n    gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n    gray = cv2.GaussianBlur(gray, (9, 9), 0)\n    edged = cv2.Canny(gray, 50, 250)\n    dilate = cv2.dilate(edged, None, iterations=2)\n    erode = cv2.erode(dilate, None, iterations=2)\n    return erode\n\n\ndef find_and_sort_contours(eroded_image):\n    cnts, _ = cv2.findContours(eroded_image.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n    (cnts, bounding_boxes) = zip(*sorted(zip(cnts, [cv2.boundingRect(c) for c in cnts]), key=lambda b: b[1][0]))\n    return cnts, bounding_boxes\n\ndef draw_contours(image, cnts):\n    orig = image.copy()\n    for c in cnts:\n        if cv2.contourArea(c) &lt; 100:\n            continue\n        box = cv2.minAreaRect(c)\n        box = cv2.boxPoints(box)\n        box = np.array(box, dtype=\"int\")\n        box = order_points(box)\n        cv2.drawContours(orig, [box.astype(\"int\")], -1, (0, 255, 0), 2)\n        for (x, y) in box:\n            cv2.circle(orig, (int(x), int(y)), 5, (25, 0, 0), -1)\n    return orig\n\ndef draw_midpoints(image, cnts):\n    orig = image.copy()\n    for c in cnts:\n        if cv2.contourArea(c) &lt; 100:\n            continue\n        box = cv2.minAreaRect(c)\n        box = cv2.boxPoints(box)\n        box = np.array(box, dtype=\"int\")\n        box = order_points(box)\n\n        tl, tr, br, bl = box\n        tltr_x, tltr_y = midpoint(tl, tr)\n        blbr_x, blbr_y = midpoint(bl, br)\n        tlbl_x, tlbl_y = midpoint(tl, bl)\n        trbr_x, trbr_y = midpoint(tr, br)\n\n        cv2.circle(orig, (int(tltr_x), int(tltr_y)), 5, (255, 0, 0), -1)\n        cv2.circle(orig, (int(blbr_x), int(blbr_y)), 5, (255, 0, 0), -1)\n        cv2.circle(orig, (int(tlbl_x), int(tlbl_y)), 5, (255, 0, 0), -1)\n        cv2.circle(orig, (int(trbr_x), int(trbr_y)), 5, (255, 0, 0), -1)\n\n        cv2.line(orig, (int(tltr_x), int(tltr_y)), (int(blbr_x), int(blbr_y)), (255, 0, 255), 2)\n        cv2.line(orig, (int(tlbl_x), int(tlbl_y)), (int(trbr_x), int(trbr_y)), (255, 0, 255), 2)\n    return orig\n\ndef draw_dimensions(image, cnts, pixels_per_metric):\n    orig = image.copy()\n    for c in cnts:\n        if cv2.contourArea(c) &lt; 100:\n            continue\n        box = cv2.minAreaRect(c)\n        box = cv2.boxPoints(box)\n        box = np.array(box, dtype=\"int\")\n        box = order_points(box)\n\n        tl, tr, br, bl = box\n        tltr_x, tltr_y = midpoint(tl, tr)\n        blbr_x, blbr_y = midpoint(bl, br)\n        tlbl_x, tlbl_y = midpoint(tl, bl)\n        trbr_x, trbr_y = midpoint(tr, br)\n\n        da = dist.euclidean((tltr_x, tltr_y), (blbr_x, blbr_y))\n        db = dist.euclidean((tlbl_x, tlbl_y), (trbr_x, trbr_y))\n\n        if pixels_per_metric is None:\n            pixels_per_metric = db / width\n\n        dim_a = da / pixels_per_metric\n        dim_b = db / pixels_per_metric\n\n        cv2.putText(orig, \"{:.2f}cm\".format(dim_b), (int(tltr_x - 15), int(tltr_y - 10)), cv2.FONT_HERSHEY_SIMPLEX, 0.50, (255, 255, 255), 1)\n        cv2.putText(orig, \"{:.2f}cm\".format(dim_a), (int(trbr_x + 10), int(trbr_y)), cv2.FONT_HERSHEY_SIMPLEX, 0.50, (255, 255, 255), 1)\n    \n    return orig\n\ndef display_image(image, title=\"Image\", figsize=(10, 10)):\n    plt.figure(figsize=figsize)\n    plt.imshow(image)\n    plt.title(title)\n    plt.axis('off')  # Oculta os eixos\n    plt.show()\n\n### o c\u00f3digo principal fica mais limpo e f\u00e1cil de entender...\n\nwidth = 8.89\npixels_per_metric = None\n\nerode = process_image('objects2.png')\ncnts, bounding_boxes = find_and_sort_contours(erode)\ncontours_image = draw_contours(image, cnts)\nmidpoints_image = draw_midpoints(contours_image, cnts)\ndimensions_image = draw_dimensions(midpoints_image, cnts, pixels_per_metric)\ndisplay_image(dimensions_image, title=\"Imagem final\")\n\n## da pra melhorar ainda mais o c\u00f3digo, mas acredito que j\u00e1 deu pra ter uma ideia de como refatorar o c\u00f3digo.\n</pre> ### vou criar algumas fun\u00e7\u00f5es para refatorar o c\u00f3digo acima...   %matplotlib inline import cv2 from matplotlib import pyplot as plt import numpy as np from scipy.spatial import distance as dist  def order_points(pts):     x_sorted = pts[np.argsort(pts[:, 0]), :]     left_most = x_sorted[:2, :]     right_most = x_sorted[2:, :]     left_most = left_most[np.argsort(left_most[:, 1]), :]     tl, bl = left_most     d = dist.cdist(tl[np.newaxis], right_most, \"euclidean\")[0]     br, tr = right_most[np.argsort(d)[::-1], :]     return np.array([tl, tr, br, bl], dtype=\"float32\")  def midpoint(pt_a, pt_b):     return ((pt_a[0] + pt_b[0]) * 0.5, (pt_a[1] + pt_b[1]) * 0.5)  def process_image(image_path):     image = cv2.imread(image_path)     image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)     gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)     gray = cv2.GaussianBlur(gray, (9, 9), 0)     edged = cv2.Canny(gray, 50, 250)     dilate = cv2.dilate(edged, None, iterations=2)     erode = cv2.erode(dilate, None, iterations=2)     return erode   def find_and_sort_contours(eroded_image):     cnts, _ = cv2.findContours(eroded_image.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)     (cnts, bounding_boxes) = zip(*sorted(zip(cnts, [cv2.boundingRect(c) for c in cnts]), key=lambda b: b[1][0]))     return cnts, bounding_boxes  def draw_contours(image, cnts):     orig = image.copy()     for c in cnts:         if cv2.contourArea(c) &lt; 100:             continue         box = cv2.minAreaRect(c)         box = cv2.boxPoints(box)         box = np.array(box, dtype=\"int\")         box = order_points(box)         cv2.drawContours(orig, [box.astype(\"int\")], -1, (0, 255, 0), 2)         for (x, y) in box:             cv2.circle(orig, (int(x), int(y)), 5, (25, 0, 0), -1)     return orig  def draw_midpoints(image, cnts):     orig = image.copy()     for c in cnts:         if cv2.contourArea(c) &lt; 100:             continue         box = cv2.minAreaRect(c)         box = cv2.boxPoints(box)         box = np.array(box, dtype=\"int\")         box = order_points(box)          tl, tr, br, bl = box         tltr_x, tltr_y = midpoint(tl, tr)         blbr_x, blbr_y = midpoint(bl, br)         tlbl_x, tlbl_y = midpoint(tl, bl)         trbr_x, trbr_y = midpoint(tr, br)          cv2.circle(orig, (int(tltr_x), int(tltr_y)), 5, (255, 0, 0), -1)         cv2.circle(orig, (int(blbr_x), int(blbr_y)), 5, (255, 0, 0), -1)         cv2.circle(orig, (int(tlbl_x), int(tlbl_y)), 5, (255, 0, 0), -1)         cv2.circle(orig, (int(trbr_x), int(trbr_y)), 5, (255, 0, 0), -1)          cv2.line(orig, (int(tltr_x), int(tltr_y)), (int(blbr_x), int(blbr_y)), (255, 0, 255), 2)         cv2.line(orig, (int(tlbl_x), int(tlbl_y)), (int(trbr_x), int(trbr_y)), (255, 0, 255), 2)     return orig  def draw_dimensions(image, cnts, pixels_per_metric):     orig = image.copy()     for c in cnts:         if cv2.contourArea(c) &lt; 100:             continue         box = cv2.minAreaRect(c)         box = cv2.boxPoints(box)         box = np.array(box, dtype=\"int\")         box = order_points(box)          tl, tr, br, bl = box         tltr_x, tltr_y = midpoint(tl, tr)         blbr_x, blbr_y = midpoint(bl, br)         tlbl_x, tlbl_y = midpoint(tl, bl)         trbr_x, trbr_y = midpoint(tr, br)          da = dist.euclidean((tltr_x, tltr_y), (blbr_x, blbr_y))         db = dist.euclidean((tlbl_x, tlbl_y), (trbr_x, trbr_y))          if pixels_per_metric is None:             pixels_per_metric = db / width          dim_a = da / pixels_per_metric         dim_b = db / pixels_per_metric          cv2.putText(orig, \"{:.2f}cm\".format(dim_b), (int(tltr_x - 15), int(tltr_y - 10)), cv2.FONT_HERSHEY_SIMPLEX, 0.50, (255, 255, 255), 1)         cv2.putText(orig, \"{:.2f}cm\".format(dim_a), (int(trbr_x + 10), int(trbr_y)), cv2.FONT_HERSHEY_SIMPLEX, 0.50, (255, 255, 255), 1)          return orig  def display_image(image, title=\"Image\", figsize=(10, 10)):     plt.figure(figsize=figsize)     plt.imshow(image)     plt.title(title)     plt.axis('off')  # Oculta os eixos     plt.show()  ### o c\u00f3digo principal fica mais limpo e f\u00e1cil de entender...  width = 8.89 pixels_per_metric = None  erode = process_image('objects2.png') cnts, bounding_boxes = find_and_sort_contours(erode) contours_image = draw_contours(image, cnts) midpoints_image = draw_midpoints(contours_image, cnts) dimensions_image = draw_dimensions(midpoints_image, cnts, pixels_per_metric) display_image(dimensions_image, title=\"Imagem final\")  ## da pra melhorar ainda mais o c\u00f3digo, mas acredito que j\u00e1 deu pra ter uma ideia de como refatorar o c\u00f3digo.  In\u00a0[\u00a0]: Copied! <pre>### Bora fazer uma IC??\n</pre> ### Bora fazer uma IC??"},{"location":"aulas/PDI/lab10/sol_medidas.html#processamento-de-imagens","title":"PROCESSAMENTO DE IMAGENS\u00b6","text":"<p>Objetivos da aula:</p> <ul> <li>reconhecer e fazer medidas b\u00e1sicas e aproximadas de objetos</li> </ul>"},{"location":"aulas/PDI/lab10/sol_medidas.html#desafio1","title":"desafio1\u00b6","text":"<p>Dica r\u00e1pida de python. Vamos utilizar a fun\u00e7\u00e3o <code>zip</code> do python que retorna uma sequ\u00eancia de tuplas. Pratique um pouco essa fun\u00e7\u00e3o.</p> <ul> <li>http://devfuria.com.br/python/built-in-zip/</li> <li>https://pythonhelp.wordpress.com/2013/04/16/funcao-zip-em-python/</li> <li>https://www.programiz.com/python-programming/methods/built-in/zip</li> </ul> <p>obs. O operador <code>*</code> pode ser utilizado com o zip() para descompactar (unzip) uma lista.</p>"},{"location":"aulas/PDI/lab10/sol_medidas.html#desafio2","title":"desafio2\u00b6","text":"<p>Dica r\u00e1pida de python. Vamos utilizar <code>list comprehensions</code> que basicamente realiza de forma compacta uma manipula\u00e7\u00e3o de listas. Pratique um pouco essa fun\u00e7\u00e3o.</p> <ul> <li>https://pythonhelp.wordpress.com/2011/03/01/list-comprehension/</li> <li>https://www.w3schools.com/python/python_lists_comprehension.asp</li> <li>https://pythonacademy.com.br/blog/list-comprehensions-no-python</li> </ul>"},{"location":"aulas/PDI/lab10/sol_medidas.html#desafio3","title":"desafio3\u00b6","text":"<p>Dica r\u00e1pida de python. Vamos utilizar a fun\u00e7\u00e3o <code>lambda</code> que basicamente realiza de forma pratica uma fun\u00e7\u00e3o an\u00f4nima. Pratique um pouco essa fun\u00e7\u00e3o.</p> <ul> <li>https://www.hashtagtreinamentos.com/funcoes-lambda-python?gclid=CjwKCAjwiuuRBhBvEiwAFXKaNF77HmSrHlWg1Tx5Okpt6x9QFZemjbINiX9sX43R-fCNnXkuy8fiTxoCkiEQAvD_BwE</li> <li>https://www.w3schools.com/python/python_lambda.asp</li> <li>https://www.codingame.com/playgrounds/52499/programacao-python-intermediario---prof--marco-vaz/funcao-lambda</li> </ul>"},{"location":"aulas/PDI/lab10/sol_medidas.html#obtencao-dos-contornos","title":"OBTEN\u00c7\u00c3O DOS CONTORNOS\u00b6","text":"<p>A partir das arestas, podemos obter os contornos dos objetos.</p>"},{"location":"aulas/PDI/lab10/sol_medidas.html#desafio","title":"Desafio\u00b6","text":"<p>Realize o processamento da imagem abaixo a fim de obter os dimensionais de todos os cart\u00f5es. Fa\u00e7a a escolha de um dos cart\u00f5es para ser a refer\u00eancia e servir de calibra\u00e7\u00e3o.</p> <p>O cart\u00e3o da esquerda possui 8.89 x 5.08 cm.</p>"},{"location":"aulas/PDI/lab10/sol_medidas.html#desafio-extra-top","title":"Desafio extra top!\u00b6","text":"<p>Um grande problemada industria de manufatura est\u00e1 na determin\u00e7\u00e3o do dimensional de alguns objetos para controle de qualidade. Nesse sentido, voc\u00ea foi contratado para desenvolver um sistema que ir\u00e1 capturar um frame de um v\u00eddeo, processar e definir o seu dimenssional.</p> <p>Se topar o desafio, vamos fazer um projeto IC?</p>"},{"location":"aulas/PDI/lab11/watershed.html","title":"Lab11 - Transformada de watershed","text":"<p>O NOSSO PROBLEMA</p> <p>Como segmentar objetos semelhantes que est\u00e3o se tocando?</p> <p>At\u00e9 o momento, os objetos est\u00e3o bem separados uns dos outros, neste caso o metodo de segmenta\u00e7\u00e3o de contorno funciona muito bem. E para o caso abaixo?</p> In\u00a0[1]: Copied! <pre>%matplotlib inline\nimport cv2\nfrom matplotlib import pyplot as plt\nimport numpy as np\n\nimg = cv2.imread('water_coins.jpg')\nimg_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n\nplt.figure(figsize = (10,10))\nplt.imshow(img_rgb); plt.show();\n\ngray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\nret, thresh = cv2.threshold(gray,0,255,cv2.THRESH_BINARY_INV+cv2.THRESH_OTSU)\n\nplt.figure(figsize = (10,10))\nplt.imshow(thresh,cmap=\"gray\"); plt.show();\n</pre> %matplotlib inline import cv2 from matplotlib import pyplot as plt import numpy as np  img = cv2.imread('water_coins.jpg') img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)  plt.figure(figsize = (10,10)) plt.imshow(img_rgb); plt.show();  gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY) ret, thresh = cv2.threshold(gray,0,255,cv2.THRESH_BINARY_INV+cv2.THRESH_OTSU)  plt.figure(figsize = (10,10)) plt.imshow(thresh,cmap=\"gray\"); plt.show(); <p>Algoritmo de Watershed</p> <p>Em casos como esse, podemos usar o algoritmo de watershed, uma intui\u00e7\u00e3o de como funciona este algotimo \u00e9 a seguinte.</p> <p>Queremos isolar regi\u00f5es da imagem, para isso vamos imaginar uma imagem como um relevo (imagem topografica), que tem altos e baixos, a intensidade do pixel determina sua altura, o top ou vale. A teoria e a matem\u00e1tica por tr\u00e1s s\u00e3o complexas, mas por temos uma receita de bolo que costuma dar certo.</p> <p></p> <p>Pr\u00f3s e contras</p> <p>Vantagem, conseguimos seguimentar uma imagem em escala de cinza em mais do que duas regi\u00f5es. Mesmo sendo objetos sobrepostos, conseguimos determinar sua fronteira.</p> <p>Como desvantagem temos um problema de inicializa\u00e7\u00e3o, se for aleat\u00f3rio ou mal inicializada, pode gerar resultado ruim.</p> <p>Na OpenCV, temos uma fun\u00e7\u00e3o built-in que implementa o algoritimo de watershed:</p> <pre><code>cv2.watershed(image, markers)\n\nimage: imagem de entrada\n\nmarkers: s\u00e3o sementes \"seeds\", ou seja, onde nasce um objeto. \u00c9 uma imagem do mesmo tamanho da imagem original, mas com regio\u1ebds de interesse delineadas, cada regi\u00e3o \u00e9 equivalente a um centro objeto da imagem, nas bordas das regio\u1ebds o valor da semente \u00e9 -1.</code></pre> <p>Como determinar os markers</p> <pre><code>1 - Determine a \u00e1rea da imagem que \u00e9 o fundo certo (sure background area)\n2 - Encontre uma area em primeiro plano (find sure foreground area)\n3 - A diferen\u00e7a entre as duas areas (sure_bg -sure_fg) \u00e9 uma regi\u00e3o desconhecida pois \u00e9 onde est\u00e1 a borda.\n4 - Rotule as regi\u00f5es, o fundo da imagem com 0 e outros objetos s\u00e3o rotulados com n\u00fameros inteiros a partir de 1.</code></pre> <p>Simples assim...:)</p> In\u00a0[2]: Copied! <pre>%matplotlib inline\nimport cv2\nfrom matplotlib import pyplot as plt\nimport numpy as np\n\nimg = cv2.imread('Osteosarcoma_01.tif')\nimg_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\ncells=img_rgb[:,:,2]  #usando a cor azul, pega melhor o contorno (para esse exemplo de imagem)\n_, thresh = cv2.threshold(cells, 0, 255, cv2.THRESH_OTSU) ## limiariza\u00e7\u00e3o\n\n\nplt.figure(figsize=(20,20))\nplt.subplot(1, 2, 1); plt.imshow(img,cmap=\"gray\")\nplt.subplot(1, 2, 2);plt.imshow(thresh,cmap=\"gray\"); plt.show();\n</pre> %matplotlib inline import cv2 from matplotlib import pyplot as plt import numpy as np  img = cv2.imread('Osteosarcoma_01.tif') img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB) cells=img_rgb[:,:,2]  #usando a cor azul, pega melhor o contorno (para esse exemplo de imagem) _, thresh = cv2.threshold(cells, 0, 255, cv2.THRESH_OTSU) ## limiariza\u00e7\u00e3o   plt.figure(figsize=(20,20)) plt.subplot(1, 2, 1); plt.imshow(img,cmap=\"gray\") plt.subplot(1, 2, 2);plt.imshow(thresh,cmap=\"gray\"); plt.show(); In\u00a0[3]: Copied! <pre># vamos realizar o pre-processamento da imagem, limpando os ruidos e tapando buracos da imagem\n# podemos usar morfologia ou qualquer outro processo.\n\nkernel = np.ones((3,3),np.uint8) # matriz de convolu\u00e7\u00e3o 3x3\n\nopening = cv2.morphologyEx(thresh,cv2.MORPH_OPEN,kernel, iterations = 2) ##morfologia para remover ruidos\n\nplt.figure(figsize=(20,20))\nplt.subplot(1, 2, 1); plt.imshow(thresh,cmap=\"gray\")\nplt.subplot(1, 2, 2);plt.imshow(opening,cmap=\"gray\"); plt.show();\n</pre> # vamos realizar o pre-processamento da imagem, limpando os ruidos e tapando buracos da imagem # podemos usar morfologia ou qualquer outro processo.  kernel = np.ones((3,3),np.uint8) # matriz de convolu\u00e7\u00e3o 3x3  opening = cv2.morphologyEx(thresh,cv2.MORPH_OPEN,kernel, iterations = 2) ##morfologia para remover ruidos  plt.figure(figsize=(20,20)) plt.subplot(1, 2, 1); plt.imshow(thresh,cmap=\"gray\") plt.subplot(1, 2, 2);plt.imshow(opening,cmap=\"gray\"); plt.show(); <p>Vamos fazer um teste usando o que j\u00e1 conhecemos para contar usando o findcontours(), note que a contagem n\u00e3o est\u00e1 correta, pois existe sobreposi\u00e7\u00e3o na imagem.</p> In\u00a0[4]: Copied! <pre>contornos, _ = cv2.findContours(opening, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE) \n\nopening_rgb = cv2.cvtColor(opening, cv2.COLOR_GRAY2RGB) \ncontornos_img = opening_rgb.copy() # C\u00f3pia da m\u00e1scara para ser desenhada \"por cima\"\n\n\n\nfor (i, c) in enumerate(contornos):\n    # draw the contour\n    ((x, y), _) = cv2.minEnclosingCircle(c)  ## truque para pegar as coordenadas de centro x,y de cada contorno\n    cv2.putText(contornos_img, \"#{}\".format(i + 1), (int(x) - 10, int(y)), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)\n    cv2.drawContours(contornos_img, [c], -1, [255, 0, 0], 5);\n\nprint(\"Foram identificados\",len(contornos),\"contornos\")\n\n\nplt.figure(figsize=(20,20))\nplt.subplot(1, 2, 1); plt.imshow(opening,cmap=\"gray\")\nplt.subplot(1, 2, 2);plt.imshow(contornos_img); plt.show();\n</pre>  contornos, _ = cv2.findContours(opening, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)   opening_rgb = cv2.cvtColor(opening, cv2.COLOR_GRAY2RGB)  contornos_img = opening_rgb.copy() # C\u00f3pia da m\u00e1scara para ser desenhada \"por cima\"    for (i, c) in enumerate(contornos):     # draw the contour     ((x, y), _) = cv2.minEnclosingCircle(c)  ## truque para pegar as coordenadas de centro x,y de cada contorno     cv2.putText(contornos_img, \"#{}\".format(i + 1), (int(x) - 10, int(y)), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)     cv2.drawContours(contornos_img, [c], -1, [255, 0, 0], 5);  print(\"Foram identificados\",len(contornos),\"contornos\")   plt.figure(figsize=(20,20)) plt.subplot(1, 2, 1); plt.imshow(opening,cmap=\"gray\") plt.subplot(1, 2, 2);plt.imshow(contornos_img); plt.show(); <pre>Foram identificados 109 contornos\n</pre> <p>Vamos aplicar a transformada de Watershed. Para isso vamos seguir o proprio exemplo de aplica\u00e7\u00e3o da t\u00e9cnica e adaptar para a nosso exemplo.</p> <p>REF: https://opencv24-python-tutorials.readthedocs.io/en/latest/py_tutorials/py_imgproc/py_watershed/py_watershed.html</p> In\u00a0[5]: Copied! <pre># agora que j\u00e1 sabemos onde est\u00e3o os centros das celulas, determinamos uma \u00e1rea de fundo certo (sure background area)\n\nsure_bg = cv2.dilate(opening,kernel,iterations=10)\n\n# Determinamos uma \u00e1rea segura em primeiro plano (Finding sure foreground area)\ndist_transform = cv2.distanceTransform(opening,cv2.DIST_L2,5)\nret, sure_fg = cv2.threshold(dist_transform,0.5*dist_transform.max(),255,0)\n\n\n# Buscamos regi\u00f5es desconhecidas (Finding unknown region)\nsure_fg = np.uint8(sure_fg)\nunknown = cv2.subtract(sure_bg,sure_fg) \n\n\n# Rotulando o marcador\nret, markers = cv2.connectedComponents(sure_fg)\n\n\n# Adicione 1 a todos os marcadores para garantir que o plano de fundo n\u00e3o seja 0, mas 1\nmarkers = markers+10\n\n# Agora, marque a regi\u00e3o desconhecida com zero\nmarkers[unknown==255] = 0 \n\n\nplt.figure(figsize=(15,15))\nplt.subplot(2, 2, 1);plt.imshow(sure_bg,cmap=\"gray\")\nplt.subplot(2, 2, 2);plt.imshow(sure_fg,cmap=\"gray\")\nplt.subplot(2, 2, 3);plt.imshow(unknown,cmap=\"gray\")\nplt.subplot(2, 2, 4); plt.imshow(markers,cmap=\"gray\"); plt.show();\n</pre> # agora que j\u00e1 sabemos onde est\u00e3o os centros das celulas, determinamos uma \u00e1rea de fundo certo (sure background area)  sure_bg = cv2.dilate(opening,kernel,iterations=10)  # Determinamos uma \u00e1rea segura em primeiro plano (Finding sure foreground area) dist_transform = cv2.distanceTransform(opening,cv2.DIST_L2,5) ret, sure_fg = cv2.threshold(dist_transform,0.5*dist_transform.max(),255,0)   # Buscamos regi\u00f5es desconhecidas (Finding unknown region) sure_fg = np.uint8(sure_fg) unknown = cv2.subtract(sure_bg,sure_fg)    # Rotulando o marcador ret, markers = cv2.connectedComponents(sure_fg)   # Adicione 1 a todos os marcadores para garantir que o plano de fundo n\u00e3o seja 0, mas 1 markers = markers+10  # Agora, marque a regi\u00e3o desconhecida com zero markers[unknown==255] = 0    plt.figure(figsize=(15,15)) plt.subplot(2, 2, 1);plt.imshow(sure_bg,cmap=\"gray\") plt.subplot(2, 2, 2);plt.imshow(sure_fg,cmap=\"gray\") plt.subplot(2, 2, 3);plt.imshow(unknown,cmap=\"gray\") plt.subplot(2, 2, 4); plt.imshow(markers,cmap=\"gray\"); plt.show(); In\u00a0[6]: Copied! <pre>#Agora podemos aplicar watershed. \nmarkers = cv2.watershed(img,markers)\n\n# cada contorno fica vermelho\nimg[markers == -1] = [255,0,0]  \n\nprint(markers.shape)\n\nplt.figure(figsize=(20,20))\nplt.subplot(1, 2, 2); plt.imshow(markers,cmap=\"gray\")\nplt.subplot(1, 2, 1);plt.imshow(img); plt.show();\n</pre> #Agora podemos aplicar watershed.  markers = cv2.watershed(img,markers)  # cada contorno fica vermelho img[markers == -1] = [255,0,0]    print(markers.shape)  plt.figure(figsize=(20,20)) plt.subplot(1, 2, 2); plt.imshow(markers,cmap=\"gray\") plt.subplot(1, 2, 1);plt.imshow(img); plt.show();   <pre>(1104, 1376)\n</pre> In\u00a0[7]: Copied! <pre>contornos, _ = cv2.findContours(sure_fg, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE) \n\nopening_rgb = cv2.cvtColor(opening, cv2.COLOR_GRAY2RGB) \ncontornos_img = opening_rgb.copy() # C\u00f3pia da m\u00e1scara para ser desenhada \"por cima\"\n\nfor (i, c) in enumerate(contornos):\n    # desenha o contorno\n    ((x, y), _) = cv2.minEnclosingCircle(c)  ## truque para pegar as coordenadas de centro x,y de cada contorno\n    cv2.putText(contornos_img, \"#{}\".format(i + 1), (int(x) - 10, int(y)), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)\n    cv2.drawContours(contornos_img, [c], -1, [255, 0, 0], 5);\n\nprint(\"Foram identificados\",len(contornos),\"contornos\")\n\n\nplt.figure(figsize=(20,20))\nplt.subplot(1, 2, 1); plt.imshow(opening,cmap=\"gray\")\nplt.subplot(1, 2, 2);plt.imshow(contornos_img); plt.show();\n</pre> contornos, _ = cv2.findContours(sure_fg, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)   opening_rgb = cv2.cvtColor(opening, cv2.COLOR_GRAY2RGB)  contornos_img = opening_rgb.copy() # C\u00f3pia da m\u00e1scara para ser desenhada \"por cima\"  for (i, c) in enumerate(contornos):     # desenha o contorno     ((x, y), _) = cv2.minEnclosingCircle(c)  ## truque para pegar as coordenadas de centro x,y de cada contorno     cv2.putText(contornos_img, \"#{}\".format(i + 1), (int(x) - 10, int(y)), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)     cv2.drawContours(contornos_img, [c], -1, [255, 0, 0], 5);  print(\"Foram identificados\",len(contornos),\"contornos\")   plt.figure(figsize=(20,20)) plt.subplot(1, 2, 1); plt.imshow(opening,cmap=\"gray\") plt.subplot(1, 2, 2);plt.imshow(contornos_img); plt.show(); <pre>Foram identificados 99 contornos\n</pre> In\u00a0[8]: Copied! <pre>%matplotlib inline\nimport cv2\nfrom matplotlib import pyplot as plt\nimport numpy as np\n\nimg = cv2.imread('water_coins.jpg')\nimg_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n\n\nplt.figure(figsize = (10,10))\nplt.imshow(img_rgb); plt.show();\n</pre> %matplotlib inline import cv2 from matplotlib import pyplot as plt import numpy as np  img = cv2.imread('water_coins.jpg') img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)   plt.figure(figsize = (10,10)) plt.imshow(img_rgb); plt.show(); In\u00a0[10]: Copied! <pre>#implemente sua solu\u00e7\u00e3o aqui..\n</pre> #implemente sua solu\u00e7\u00e3o aqui.."},{"location":"aulas/PDI/lab11/watershed.html#processamento-de-imagens","title":"PROCESSAMENTO DE IMAGENS\u00b6","text":"<p>Objetivos da aula:</p> <ul> <li>apresentar e aplicar ao algoritimo de Watershed</li> </ul> <p>ref: https://github.com/bnsreenu/python_for_microscopists/blob/master/033-grain_size_analysis_using_wateshed_segmentation.py</p>"},{"location":"aulas/PDI/lab11/watershed.html#desafio","title":"Desafio\u00b6","text":"<p>Fa\u00e7a a segmenta\u00e7\u00e3o das moedas utilizando o algoritmo de watershed</p>"},{"location":"aulas/PDI/lab12/Template_matching-old.html","title":"Template matching old","text":"<p>Objetivos da aula:</p> <ul> <li>apresentar e aplicar template matching</li> </ul> <p>Template matching</p> <p>At\u00e9 o momenos estudamos t\u00e9cnicas para realizar a segmenta\u00e7\u00e3o e detec\u00e7\u00e3o de objetos e formas simples como circulos e retas e cores.</p> <p>Agora vamos estudar uma t\u00e9cnica chamada template matching, essa t\u00e9cnica realiza o casamento (matching) entre uma imagem de refer\u00eancia (template) com uma imagem de an\u00e1lise.</p> <p>Uma intui\u00e7\u00e3o de como essa t\u00e9cnica funciona \u00e9 lembrar dos filtros lineares, com a fun\u00e7\u00e3o cv2.filter2d(), onde um kernel convolui uma imagem. Em outras palavras a nossa template realiza um processo iterativo varrendo pixel a pixel a imagem de an\u00e1lise buscando a maior correla\u00e7\u00e3o possivel. Na OpenCV podemos utilizar a fun\u00e7\u00e3o built-in cv2.matchTemplate().</p> <p>Queremos encontrar o GOOMBA na imagem. </p> In\u00a0[10]: Copied! <pre>## Vou fazer o download das imagens do laborat\u00f3rio diretamente do reposit\u00f3rio para usar no colab mais facil....\nimport requests\n\n# Definie o modulo e o laborat\u00f3rio\nmodulo ='PDI/'\nlaboratorio = 'lab12'\n\n# URL da API do GitHub para a pasta do reposit\u00f3rio\napi_url = \"https://api.github.com/repos/arnaldojr/cognitivecomputing/contents/material/aulas/\"\n\n# Monta a URL completa\nurl_completa = api_url + modulo + laboratorio\n\nprint(f\"Fazendo o download de: {url_completa}\")\n\n# Requisi\u00e7\u00e3o para obter a lista de arquivos na pasta\nresponse = requests.get(url_completa)\nfiles = response.json()\n\n# Fazer o download de cada arquivo de imagem\nfor file in files:\n    file_name = file['name']\n    if file_name.endswith(('.png', '.jpg', '.jpeg', '.mp4')):  # Adicione mais extens\u00f5es se necess\u00e1rio\n        file_url = file['download_url']\n        print(f\"Baixando {file_name}...\")\n        !wget -q {file_url} -P /content\n\nprint(\"Download conclu\u00eddo.\")\n</pre> ## Vou fazer o download das imagens do laborat\u00f3rio diretamente do reposit\u00f3rio para usar no colab mais facil.... import requests  # Definie o modulo e o laborat\u00f3rio modulo ='PDI/' laboratorio = 'lab12'  # URL da API do GitHub para a pasta do reposit\u00f3rio api_url = \"https://api.github.com/repos/arnaldojr/cognitivecomputing/contents/material/aulas/\"  # Monta a URL completa url_completa = api_url + modulo + laboratorio  print(f\"Fazendo o download de: {url_completa}\")  # Requisi\u00e7\u00e3o para obter a lista de arquivos na pasta response = requests.get(url_completa) files = response.json()  # Fazer o download de cada arquivo de imagem for file in files:     file_name = file['name']     if file_name.endswith(('.png', '.jpg', '.jpeg', '.mp4')):  # Adicione mais extens\u00f5es se necess\u00e1rio         file_url = file['download_url']         print(f\"Baixando {file_name}...\")         !wget -q {file_url} -P /content  print(\"Download conclu\u00eddo.\")  <pre>Fazendo o download de: https://api.github.com/repos/arnaldojr/cognitivecomputing/contents/material/aulas/PDI/lab12\nBaixando mario-template.png...\nBaixando mario-template2.png...\nBaixando mario.png...\nBaixando res.png...\nBaixando res2.png...\nDownload conclu\u00eddo.\n</pre> In\u00a0[11]: Copied! <pre>%matplotlib inline\nimport cv2\nfrom matplotlib import pyplot as plt\nimport numpy as np\n\n# carrega a imagem analisada.\nimg = cv2.imread('mario.png')\nimg_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n\nplt.imshow(img_rgb); plt.show();\n</pre> %matplotlib inline import cv2 from matplotlib import pyplot as plt import numpy as np  # carrega a imagem analisada. img = cv2.imread('mario.png') img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)  plt.imshow(img_rgb); plt.show(); In\u00a0[12]: Copied! <pre>%matplotlib inline\nimport cv2\nfrom matplotlib import pyplot as plt\nimport numpy as np\n\n# carrega as imagens.\ntemplate = cv2.imread('mario-template.png', 0)  ##template\n\nimg = cv2.imread('mario.png')  ### cena\nimg_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n\n# Aplica template Matching\nres = cv2.matchTemplate(img_gray,template,cv2.TM_SQDIFF)\n\n# res \u00e9 uma imagem e podemos plotar seu shape e imagem\n\nprint(res.shape, res.dtype)\n\n\nplt.figure(figsize = (10,10))\nplt.imshow(res,cmap=\"gray\");\n</pre> %matplotlib inline import cv2 from matplotlib import pyplot as plt import numpy as np  # carrega as imagens. template = cv2.imread('mario-template.png', 0)  ##template  img = cv2.imread('mario.png')  ### cena img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)  # Aplica template Matching res = cv2.matchTemplate(img_gray,template,cv2.TM_SQDIFF)  # res \u00e9 uma imagem e podemos plotar seu shape e imagem  print(res.shape, res.dtype)   plt.figure(figsize = (10,10)) plt.imshow(res,cmap=\"gray\"); <pre>(624, 965) float32\n</pre> <p>Visualmente podemos notar que o nosso GOOMBA est\u00e1 destacado na imagem como pixel mais escuro da imagem.</p> <p>Para capturar a posi\u00e7\u00e3o deste pixel vamos usar a fun\u00e7\u00e3o da OpenCV <code>cv2.minMaxLoc()</code> que devolde o valor minimo e maximo al\u00e9m de suas posi\u00e7\u00f5es</p> In\u00a0[13]: Copied! <pre>#Vamos aproveitar para entender melhor o que a fun\u00e7\u00e3o devolve.\n\nprint(cv2.minMaxLoc(res))\n#resultado\n# (1824.0, 58356096.0, (709, 511), (927, 11))\n\n# res \u00e9 umTemos 4 valores;\n# os 2 primeiros s\u00e3o float32, indicamos valores dos pixels com menor e maior valor\n# os 2 ultimos s\u00e3o tuplas que indicam a posi\u00e7\u00e3o (x,y) dos pixels com menor e maior valor\n# vamos separar cada um em uma variavel\n\nmin_val, max_val, min_loc, max_loc = cv2.minMaxLoc(res)\n</pre> #Vamos aproveitar para entender melhor o que a fun\u00e7\u00e3o devolve.  print(cv2.minMaxLoc(res)) #resultado # (1824.0, 58356096.0, (709, 511), (927, 11))  # res \u00e9 umTemos 4 valores; # os 2 primeiros s\u00e3o float32, indicamos valores dos pixels com menor e maior valor # os 2 ultimos s\u00e3o tuplas que indicam a posi\u00e7\u00e3o (x,y) dos pixels com menor e maior valor # vamos separar cada um em uma variavel  min_val, max_val, min_loc, max_loc = cv2.minMaxLoc(res)  <pre>(1824.0, 58356096.0, (709, 511), (927, 11))\n</pre> In\u00a0[\u00a0]: Copied! <pre>## Implemente sua solu\u00e7\u00e3o aqui....\n</pre> ## Implemente sua solu\u00e7\u00e3o aqui....       In\u00a0[15]: Copied! <pre># Resolu\u00e7\u00e3o do desafio1, j\u00e1 fiz pq preciso dela pra resolver o resto do notebook\n\n#Extrai o shape (dimens\u00e3o da imagem)\nlargura, altura = template.shape[::-1]\n\n# ajusta o bounbox da imagem lembra que \u00e9 uma tupla ()\nbottom_right = (min_loc[0] + largura, min_loc[1] + altura)\n\n# desenha o retangulo na imagem original\ncv2.rectangle(img,min_loc, bottom_right, (127,255,255), 4)\n\n#v2.imwrite(\"res.png\",img)\n\nplt.figure(figsize = (10,10))\nplt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB)); plt.show();\n</pre> # Resolu\u00e7\u00e3o do desafio1, j\u00e1 fiz pq preciso dela pra resolver o resto do notebook  #Extrai o shape (dimens\u00e3o da imagem) largura, altura = template.shape[::-1]  # ajusta o bounbox da imagem lembra que \u00e9 uma tupla () bottom_right = (min_loc[0] + largura, min_loc[1] + altura)  # desenha o retangulo na imagem original cv2.rectangle(img,min_loc, bottom_right, (127,255,255), 4)  #v2.imwrite(\"res.png\",img)  plt.figure(figsize = (10,10)) plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB)); plt.show(); In\u00a0[\u00a0]: Copied! <pre>## Implemente sua solu\u00e7\u00e3o aqui....\n</pre> ## Implemente sua solu\u00e7\u00e3o aqui....       <p>Vamos la....</p> In\u00a0[16]: Copied! <pre>%matplotlib inline\nimport cv2\nfrom matplotlib import pyplot as plt\nimport numpy as np\n\n# carrega as imagens.\ntemplate = cv2.imread('mario-template2.png', 0)\n\nimg = cv2.imread('mario.png')\nimg_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n\n# Aplica template Matching\nres = cv2.matchTemplate(img_gray,template,cv2.TM_SQDIFF_NORMED)\n\nplt.figure(figsize = (10,10))\nplt.imshow(res, cmap=\"gray\"); plt.show();\n</pre> %matplotlib inline import cv2 from matplotlib import pyplot as plt import numpy as np  # carrega as imagens. template = cv2.imread('mario-template2.png', 0)  img = cv2.imread('mario.png') img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)  # Aplica template Matching res = cv2.matchTemplate(img_gray,template,cv2.TM_SQDIFF_NORMED)  plt.figure(figsize = (10,10)) plt.imshow(res, cmap=\"gray\"); plt.show(); <p>Visualmente podemos notar que as <code>Caixas ?</code> est\u00e3o destacadas na imagem como os pixels mais escuros da imagem.</p> <p>Neste caso, onde queremos detectar mais que uma ocorrencia, a fun\u00e7\u00e3o cv2.minMaxLoc() n\u00e3o resolve nosso problema, pois devolve apenas uma ocorencia, n\u00e3o uma lista de valores.</p> <p>Vamos utilizar outro metodo para capiturar esses pontos.</p> In\u00a0[19]: Copied! <pre># Vamos entender como funciona a fun\u00e7\u00e3o np.where\n# essa fun\u00e7\u00e3o faz uma busca na matriz e devolve a posi\u00e7\u00e3o que satisfaz a condi\u00e7\u00e3o (x,y)\n\n# S\u00f3 para entender como funciona, vamos criar uma matriz (3,3)\na = np.array([[0, 1, 5],\n              [2, 2, 3],\n              [0, 3, 1]])\nprint(a.shape)\n\n# agora vamos busca nesta matriz os valores que s\u00e3o maiores ou igual a 4\nb = np.where(a &gt;= 1)\n\n# a variavel b \u00e9 uma tupla (x,y) com as posi\u00e7\u00f5es onde a matriz a \u00e9 maior ou igual a 4\nprint(b,type(b))\n\nprint(b[0])  ##vetor linha\nprint(b[1])  ###vetor coluna\nprint(b[::-1])\n</pre> # Vamos entender como funciona a fun\u00e7\u00e3o np.where # essa fun\u00e7\u00e3o faz uma busca na matriz e devolve a posi\u00e7\u00e3o que satisfaz a condi\u00e7\u00e3o (x,y)  # S\u00f3 para entender como funciona, vamos criar uma matriz (3,3) a = np.array([[0, 1, 5],               [2, 2, 3],               [0, 3, 1]]) print(a.shape)  # agora vamos busca nesta matriz os valores que s\u00e3o maiores ou igual a 4 b = np.where(a &gt;= 1)  # a variavel b \u00e9 uma tupla (x,y) com as posi\u00e7\u00f5es onde a matriz a \u00e9 maior ou igual a 4 print(b,type(b))  print(b[0])  ##vetor linha print(b[1])  ###vetor coluna print(b[::-1]) <pre>(3, 3)\n(array([0, 0, 1, 1, 1, 2, 2]), array([1, 2, 0, 1, 2, 1, 2])) &lt;class 'tuple'&gt;\n[0 0 1 1 1 2 2]\n[1 2 0 1 2 1 2]\n(array([1, 2, 0, 1, 2, 1, 2]), array([0, 0, 1, 1, 1, 2, 2]))\n</pre> In\u00a0[20]: Copied! <pre># Vamos aproveitar e entender como funciona o objeto zip\n# O zip recebe 2 ou mais sequencias e cria uma tupla juntando um elemento de cada\n\nc = 'FIAP'\nd = [0,1,2,4]\nzip(c,d)  # objeto zip\n\nfor pares in zip(c, d):\n    print(pares)\n\nprint(\"...\")#pular linha\n\n#no exemplo acima b \u00e9 uma tupla (x,y), para iterar precisamos descompactar a tupla, para isso usamos *.\n\nfor pt in zip(*b[::-1]):\n    print(pt,pt[0],pt[1])\n\n\n# Agora que entendemos, vamos voltar para o nosso problema original.\n</pre> # Vamos aproveitar e entender como funciona o objeto zip # O zip recebe 2 ou mais sequencias e cria uma tupla juntando um elemento de cada  c = 'FIAP' d = [0,1,2,4] zip(c,d)  # objeto zip  for pares in zip(c, d):     print(pares)  print(\"...\")#pular linha  #no exemplo acima b \u00e9 uma tupla (x,y), para iterar precisamos descompactar a tupla, para isso usamos *.  for pt in zip(*b[::-1]):     print(pt,pt[0],pt[1])   # Agora que entendemos, vamos voltar para o nosso problema original. <pre>('F', 0)\n('I', 1)\n('A', 2)\n('P', 4)\n...\n(1, 0) 1 0\n(2, 0) 2 0\n(0, 1) 0 1\n(1, 1) 1 1\n(2, 1) 2 1\n(1, 2) 1 2\n(2, 2) 2 2\n</pre> In\u00a0[17]: Copied! <pre>#Extrai o shape (dimens\u00e3o da imagem)\nw, h = template.shape[::-1]\n\n\n#print(res) #### ajuda a definir o valor de threshold\nthreshold = 0.1\nloc = np.where( res &lt;= threshold)\n\nfor pt in zip(*loc[::-1]):\n    cv2.rectangle(img, pt, (pt[0] + w, pt[1] + h), (0,255,0), 5)\n\n\n\n\n#cv2.imwrite(\"res2.png\",img)\nplt.figure(figsize = (10,10))\n#plt.imshow(img_rgb)\nplt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB)); plt.show();\n</pre> #Extrai o shape (dimens\u00e3o da imagem) w, h = template.shape[::-1]   #print(res) #### ajuda a definir o valor de threshold threshold = 0.1 loc = np.where( res &lt;= threshold)  for pt in zip(*loc[::-1]):     cv2.rectangle(img, pt, (pt[0] + w, pt[1] + h), (0,255,0), 5)     #cv2.imwrite(\"res2.png\",img) plt.figure(figsize = (10,10)) #plt.imshow(img_rgb) plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB)); plt.show();   In\u00a0[\u00a0]: Copied! <pre>#implemente sua solu\u00e7\u00e3o aqui....\n</pre> #implemente sua solu\u00e7\u00e3o aqui...."},{"location":"aulas/PDI/lab12/Template_matching-old.html#desafio-1","title":"DESAFIO 1\u00b6","text":"<p>Desenhe um retangulo como contorno sobre o GOOMBA</p> <p>Dica: A fun\u00e7\u00e3o cv2.rectangle(img, pos_inicial, posi\u00e7\u00e3o_final, color, espessura)</p> <p>Temos de definir pos_inicial e pos_final </p>"},{"location":"aulas/PDI/lab12/Template_matching-old.html#desafio-2","title":"DESAFIO 2\u00b6","text":"<p>Na fun\u00e7\u00e3o cv2.matchTemplate(Image, template, Metodo) temos 3 parametros:</p> <p>Utilizamos o m\u00e9todo cv2.TM_SQDIFF no exerc\u00edcio acima, explore a refer\u00eancia da OpenCV alterando os m\u00e9todos de correla\u00e7\u00e3o.</p> <p>Ref: https://docs.opencv.org/3.4/de/da9/tutorial_template_matching.html</p>"},{"location":"aulas/PDI/lab12/Template_matching-old.html#queremos-encontrar-o-na-imagem","title":"Queremos encontrar o <code>?</code> na imagem.\u00b6","text":"<p>Note que neste caso temos mais de uma ocorrencia na image.A imagem final deve detectar 4 caixas.</p>"},{"location":"aulas/PDI/lab12/Template_matching-old.html#pausa-na-aula-para-dica-rapida-de-python","title":"Pausa na aula para dica r\u00e1pida de python :)\u00b6","text":""},{"location":"aulas/PDI/lab12/Template_matching-old.html#npwhere","title":"np.where()\u00b6","text":"<p>Leia a documenta\u00e7\u00e3o oficial para conhecer a fun\u00e7\u00e3o np.where()</p> <p>link: https://numpy.org/doc/stable/reference/generated/numpy.where.html</p>"},{"location":"aulas/PDI/lab12/Template_matching-old.html#zip","title":"zip()\u00b6","text":"<p>j\u00e1 vimos na aula passada, apenas relembrando....</p>"},{"location":"aulas/PDI/lab12/Template_matching-old.html#voltando","title":"Voltando.....\u00b6","text":""},{"location":"aulas/PDI/lab12/Template_matching-old.html#desafio-3","title":"Desafio 3\u00b6","text":"<p>Refa\u00e7a o exercico acima substituindo o m\u00e9todo TM_SQDIFF_NORMED por outro qualquer. Verifique se \u00e9 necess\u00e1rio alterar a condi\u00e7\u00e3o do threshold ou outro ponto qualquer do c\u00f3digo.</p>"},{"location":"aulas/PDI/lab12/Template_matching-old.html#desafio-4","title":"Desafio 4\u00b6","text":"<p>Para pensar um pouco...</p> <pre><code>O que acontece se a template n\u00e3o estiver na escala do objeto que queremos detectar?\n\nO que acontece que a imagem estiver com um nivel de brilho ou contraste diferente da template?\n\nO que acontece se a imagem estiver rotacionada em rela\u00e7\u00e3o a template?</code></pre>"},{"location":"aulas/PDI/lab12/Template_matching.html","title":"Template Matching com OpenCV","text":"In\u00a0[\u00a0]: Copied! <pre>## Vou fazer o download das imagens do laborat\u00f3rio diretamente do reposit\u00f3rio para ficar mais facil....\n\nimport requests\nimport os\n\n# Define o laborat\u00f3rio\nlaboratorio = 'lab12'  ### altere para o laborat\u00f3rio desejado\ndiretorio = 'lab_images'  ### altere para o diret\u00f3rio que deseja salvar as imagens\n\n# Download de um arquivo\ndef download_file(url, destination):\n    response = requests.get(url, stream=True)\n    if response.status_code == 200:\n        with open(destination, 'wb') as file:\n            for chunk in response.iter_content(chunk_size=8192):\n                file.write(chunk)\n        print(f\"Baixado: {destination}\")\n    else:\n        print(f\"Erro ao baixar {url}\")\n\n# Monta a URL completa\napi_url = \"https://api.github.com/repos/arnaldojr/cognitivecomputing/contents/material/aulas/PDI/\"\nurl_completa = api_url + laboratorio\nprint(f\"Fazendo o download de: {url_completa}\")\n\n# checa se a URL est\u00e1 acess\u00edvel\nresponse = requests.get(url_completa)\nif response.status_code != 200:\n    raise Exception(f\"Erro ao acessar o reposit\u00f3rio: {response.status_code}\")\nfiles = response.json()\n\n\n# Faz o download de cada arquivo\nos.makedirs(diretorio, exist_ok=True) # Cria a pasta downloads\nfor file in files:\n    file_name = file['name']\n    if file_name.endswith(('.png', '.jpg', '.jpeg', '.mp4')):  # Adicione mais extens\u00f5es se necess\u00e1rio\n        file_url = file['download_url']\n        destination = os.path.join(diretorio, file_name)\n        download_file(file_url, destination)\n\nprint(f\"Download conclu\u00eddo. Arquivos salvos na pasta {diretorio}.\")\n</pre> ## Vou fazer o download das imagens do laborat\u00f3rio diretamente do reposit\u00f3rio para ficar mais facil....  import requests import os  # Define o laborat\u00f3rio laboratorio = 'lab12'  ### altere para o laborat\u00f3rio desejado diretorio = 'lab_images'  ### altere para o diret\u00f3rio que deseja salvar as imagens  # Download de um arquivo def download_file(url, destination):     response = requests.get(url, stream=True)     if response.status_code == 200:         with open(destination, 'wb') as file:             for chunk in response.iter_content(chunk_size=8192):                 file.write(chunk)         print(f\"Baixado: {destination}\")     else:         print(f\"Erro ao baixar {url}\")  # Monta a URL completa api_url = \"https://api.github.com/repos/arnaldojr/cognitivecomputing/contents/material/aulas/PDI/\" url_completa = api_url + laboratorio print(f\"Fazendo o download de: {url_completa}\")  # checa se a URL est\u00e1 acess\u00edvel response = requests.get(url_completa) if response.status_code != 200:     raise Exception(f\"Erro ao acessar o reposit\u00f3rio: {response.status_code}\") files = response.json()   # Faz o download de cada arquivo os.makedirs(diretorio, exist_ok=True) # Cria a pasta downloads for file in files:     file_name = file['name']     if file_name.endswith(('.png', '.jpg', '.jpeg', '.mp4')):  # Adicione mais extens\u00f5es se necess\u00e1rio         file_url = file['download_url']         destination = os.path.join(diretorio, file_name)         download_file(file_url, destination)  print(f\"Download conclu\u00eddo. Arquivos salvos na pasta {diretorio}.\") In\u00a0[1]: Copied! <pre>%matplotlib inline\nimport cv2\nimport numpy as np\nfrom matplotlib import pyplot as plt\n\n# Configura\u00e7\u00e3o para exibir imagens maiores\nplt.figure(figsize=(12, 8))\n\n# Carrega a imagem principal (cena do jogo)\nimg = cv2.imread('mario.png')\nimg_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)  # Converte BGR para RGB para visualiza\u00e7\u00e3o\n\n# Exibe a imagem\nplt.title(\"Cena do jogo Mario Bros\")\nplt.imshow(img_rgb)\nplt.axis('off')  # Remove os eixos para melhorar a visualiza\u00e7\u00e3o\nplt.show()\n</pre> %matplotlib inline import cv2 import numpy as np from matplotlib import pyplot as plt  # Configura\u00e7\u00e3o para exibir imagens maiores plt.figure(figsize=(12, 8))  # Carrega a imagem principal (cena do jogo) img = cv2.imread('mario.png') img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)  # Converte BGR para RGB para visualiza\u00e7\u00e3o  # Exibe a imagem plt.title(\"Cena do jogo Mario Bros\") plt.imshow(img_rgb) plt.axis('off')  # Remove os eixos para melhorar a visualiza\u00e7\u00e3o plt.show() In\u00a0[2]: Copied! <pre>%matplotlib inline\nimport cv2\nimport numpy as np\nfrom matplotlib import pyplot as plt\n\n# Carrega as imagens\ntemplate = cv2.imread('mario-template.png', 0)  # Template (GOOMBA) em escala de cinza\nimg = cv2.imread('mario.png')                   # Cena completa\nimg_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY) # Converte para escala de cinza\n\n# Exibe o template\nplt.figure(figsize=(4, 4))\nplt.title(\"Template (GOOMBA)\")\nplt.imshow(template, cmap=\"gray\")\nplt.axis('off')\nplt.show()\n\n# Aplica template matching usando o m\u00e9todo TM_SQDIFF\n# TM_SQDIFF calcula a diferen\u00e7a quadr\u00e1tica - valor menor indica melhor correspond\u00eancia\nres = cv2.matchTemplate(img_gray, template, cv2.TM_SQDIFF)\n\n# Exibe informa\u00e7\u00f5es sobre o resultado\nprint(f\"Dimens\u00f5es do mapa de correspond\u00eancia: {res.shape}\")\nprint(f\"Tipo de dados: {res.dtype}\")\nprint(f\"Valor m\u00ednimo (melhor correspond\u00eancia): {np.min(res):.2f}\")\nprint(f\"Valor m\u00e1ximo (pior correspond\u00eancia): {np.max(res):.2f}\")\n\n# Visualiza o mapa de correspond\u00eancia\nplt.figure(figsize=(10, 8))\nplt.title(\"Mapa de correspond\u00eancia (valores mais escuros = melhor correspond\u00eancia)\")\nplt.imshow(res, cmap=\"hot\")\nplt.colorbar(label=\"Valor de correspond\u00eancia\")\nplt.show()\n</pre> %matplotlib inline import cv2 import numpy as np from matplotlib import pyplot as plt  # Carrega as imagens template = cv2.imread('mario-template.png', 0)  # Template (GOOMBA) em escala de cinza img = cv2.imread('mario.png')                   # Cena completa img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY) # Converte para escala de cinza  # Exibe o template plt.figure(figsize=(4, 4)) plt.title(\"Template (GOOMBA)\") plt.imshow(template, cmap=\"gray\") plt.axis('off') plt.show()  # Aplica template matching usando o m\u00e9todo TM_SQDIFF # TM_SQDIFF calcula a diferen\u00e7a quadr\u00e1tica - valor menor indica melhor correspond\u00eancia res = cv2.matchTemplate(img_gray, template, cv2.TM_SQDIFF)  # Exibe informa\u00e7\u00f5es sobre o resultado print(f\"Dimens\u00f5es do mapa de correspond\u00eancia: {res.shape}\") print(f\"Tipo de dados: {res.dtype}\") print(f\"Valor m\u00ednimo (melhor correspond\u00eancia): {np.min(res):.2f}\") print(f\"Valor m\u00e1ximo (pior correspond\u00eancia): {np.max(res):.2f}\")  # Visualiza o mapa de correspond\u00eancia plt.figure(figsize=(10, 8)) plt.title(\"Mapa de correspond\u00eancia (valores mais escuros = melhor correspond\u00eancia)\") plt.imshow(res, cmap=\"hot\") plt.colorbar(label=\"Valor de correspond\u00eancia\") plt.show() <pre>Dimens\u00f5es do mapa de correspond\u00eancia: (624, 965)\nTipo de dados: float32\nValor m\u00ednimo (melhor correspond\u00eancia): 1859.00\nValor m\u00e1ximo (pior correspond\u00eancia): 58356124.00\n</pre> In\u00a0[3]: Copied! <pre># Encontra os valores m\u00ednimos e m\u00e1ximos e suas localiza\u00e7\u00f5es no mapa de correspond\u00eancia\nmin_val, max_val, min_loc, max_loc = cv2.minMaxLoc(res)\n\nprint(f\"Valores encontrados:\")\nprint(f\"- Valor m\u00ednimo: {min_val:.2f} na posi\u00e7\u00e3o {min_loc} (melhor correspond\u00eancia para TM_SQDIFF)\")\nprint(f\"- Valor m\u00e1ximo: {max_val:.2f} na posi\u00e7\u00e3o {max_loc}\")\n\n# Explica\u00e7\u00e3o dos resultados:\nprint(\"\\nNo m\u00e9todo TM_SQDIFF:\")\nprint(\"- O valor m\u00ednimo representa a melhor correspond\u00eancia\")\nprint(\"- min_loc \u00e9 o ponto superior esquerdo onde o template melhor se encaixa\")\n</pre> # Encontra os valores m\u00ednimos e m\u00e1ximos e suas localiza\u00e7\u00f5es no mapa de correspond\u00eancia min_val, max_val, min_loc, max_loc = cv2.minMaxLoc(res)  print(f\"Valores encontrados:\") print(f\"- Valor m\u00ednimo: {min_val:.2f} na posi\u00e7\u00e3o {min_loc} (melhor correspond\u00eancia para TM_SQDIFF)\") print(f\"- Valor m\u00e1ximo: {max_val:.2f} na posi\u00e7\u00e3o {max_loc}\")  # Explica\u00e7\u00e3o dos resultados: print(\"\\nNo m\u00e9todo TM_SQDIFF:\") print(\"- O valor m\u00ednimo representa a melhor correspond\u00eancia\") print(\"- min_loc \u00e9 o ponto superior esquerdo onde o template melhor se encaixa\") <pre>Valores encontrados:\n- Valor m\u00ednimo: 1859.00 na posi\u00e7\u00e3o (709, 511) (melhor correspond\u00eancia para TM_SQDIFF)\n- Valor m\u00e1ximo: 58356124.00 na posi\u00e7\u00e3o (927, 11)\n\nNo m\u00e9todo TM_SQDIFF:\n- O valor m\u00ednimo representa a melhor correspond\u00eancia\n- min_loc \u00e9 o ponto superior esquerdo onde o template melhor se encaixa\n</pre> In\u00a0[4]: Copied! <pre># Implemente sua solu\u00e7\u00e3o aqui\n# Dicas:\n# 1. Extraia a largura e altura do template\n# 2. Calcule o ponto final do ret\u00e2ngulo (bottom_right)\n# 3. Use cv2.rectangle para desenhar na imagem\n# 4. Converta para RGB para visualiza\u00e7\u00e3o e mostre o resultado\n</pre> # Implemente sua solu\u00e7\u00e3o aqui # Dicas: # 1. Extraia a largura e altura do template # 2. Calcule o ponto final do ret\u00e2ngulo (bottom_right) # 3. Use cv2.rectangle para desenhar na imagem # 4. Converta para RGB para visualiza\u00e7\u00e3o e mostre o resultado     In\u00a0[\u00a0]: Copied! <pre># Solu\u00e7\u00e3o do desafio 1\n\n# Cria uma c\u00f3pia da imagem para n\u00e3o modificar a original\nimg_result = img.copy()\n\n# Extrai as dimens\u00f5es do template (altura e largura)\naltura, largura = template.shape\n\n# Calcula a posi\u00e7\u00e3o do ponto inferior direito do ret\u00e2ngulo (bottom_right)\nbottom_right = (min_loc[0] + largura, min_loc[1] + altura)\n\n# Desenha o ret\u00e2ngulo na imagem\n# Par\u00e2metros: imagem, ponto_inicial, ponto_final, cor (B,G,R), espessura\ncv2.rectangle(img_result, min_loc, bottom_right, (0, 255, 255), 4)\n\n# Exibe o resultado\nplt.figure(figsize=(12, 8))\nplt.title(\"GOOMBA detectado!\")\nplt.imshow(cv2.cvtColor(img_result, cv2.COLOR_BGR2RGB))\nplt.axis('off')\nplt.show()\n</pre> # Solu\u00e7\u00e3o do desafio 1  # Cria uma c\u00f3pia da imagem para n\u00e3o modificar a original img_result = img.copy()  # Extrai as dimens\u00f5es do template (altura e largura) altura, largura = template.shape  # Calcula a posi\u00e7\u00e3o do ponto inferior direito do ret\u00e2ngulo (bottom_right) bottom_right = (min_loc[0] + largura, min_loc[1] + altura)  # Desenha o ret\u00e2ngulo na imagem # Par\u00e2metros: imagem, ponto_inicial, ponto_final, cor (B,G,R), espessura cv2.rectangle(img_result, min_loc, bottom_right, (0, 255, 255), 4)  # Exibe o resultado plt.figure(figsize=(12, 8)) plt.title(\"GOOMBA detectado!\") plt.imshow(cv2.cvtColor(img_result, cv2.COLOR_BGR2RGB)) plt.axis('off') plt.show() In\u00a0[6]: Copied! <pre># Implemente sua solu\u00e7\u00e3o do Desafio 2 aqui\n# Dicas:\n# 1. Crie uma fun\u00e7\u00e3o que aplica diferentes m\u00e9todos e mostra os resultados\n# 2. Lembre-se que para TM_SQDIFF e TM_SQDIFF_NORMED, menores valores s\u00e3o melhores\n# 3. Para os outros m\u00e9todos, maiores valores s\u00e3o melhores\n</pre> # Implemente sua solu\u00e7\u00e3o do Desafio 2 aqui # Dicas: # 1. Crie uma fun\u00e7\u00e3o que aplica diferentes m\u00e9todos e mostra os resultados # 2. Lembre-se que para TM_SQDIFF e TM_SQDIFF_NORMED, menores valores s\u00e3o melhores # 3. Para os outros m\u00e9todos, maiores valores s\u00e3o melhores    In\u00a0[7]: Copied! <pre>%matplotlib inline\nimport cv2\nimport numpy as np\nfrom matplotlib import pyplot as plt\n\n# Carrega o template da caixa de interroga\u00e7\u00e3o\ntemplate = cv2.imread('mario-template2.png', 0)\n\n# Carrega a imagem principal\nimg = cv2.imread('mario.png')\nimg_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n\n# Exibe o template\nplt.figure(figsize=(4, 4))\nplt.title(\"Template (Caixa de interroga\u00e7\u00e3o)\")\nplt.imshow(template, cmap=\"gray\")\nplt.axis('off')\nplt.show()\n\n# Aplica template matching com normaliza\u00e7\u00e3o\n# Usamos TM_SQDIFF_NORMED para obter valores entre 0 e 1\nres = cv2.matchTemplate(img_gray, template, cv2.TM_SQDIFF_NORMED)\n\n# Visualiza o mapa de correspond\u00eancia\nplt.figure(figsize=(12, 8))\nplt.title(\"Mapa de correspond\u00eancia - Observe os m\u00faltiplos pontos escuros\")\nplt.imshow(res, cmap=\"hot\")\nplt.colorbar(label=\"Valor de correspond\u00eancia (menor = melhor)\")\nplt.show()\n</pre> %matplotlib inline import cv2 import numpy as np from matplotlib import pyplot as plt  # Carrega o template da caixa de interroga\u00e7\u00e3o template = cv2.imread('mario-template2.png', 0)  # Carrega a imagem principal img = cv2.imread('mario.png') img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)  # Exibe o template plt.figure(figsize=(4, 4)) plt.title(\"Template (Caixa de interroga\u00e7\u00e3o)\") plt.imshow(template, cmap=\"gray\") plt.axis('off') plt.show()  # Aplica template matching com normaliza\u00e7\u00e3o # Usamos TM_SQDIFF_NORMED para obter valores entre 0 e 1 res = cv2.matchTemplate(img_gray, template, cv2.TM_SQDIFF_NORMED)  # Visualiza o mapa de correspond\u00eancia plt.figure(figsize=(12, 8)) plt.title(\"Mapa de correspond\u00eancia - Observe os m\u00faltiplos pontos escuros\") plt.imshow(res, cmap=\"hot\") plt.colorbar(label=\"Valor de correspond\u00eancia (menor = melhor)\") plt.show() In\u00a0[8]: Copied! <pre># Exemplo did\u00e1tico de np.where()\n\n# Criando uma matriz de exemplo 3x3\nmatriz = np.array([\n    [0, 1, 5],\n    [2, 2, 3],\n    [0, 3, 1]\n])\nprint(f\"Matriz original:\\n{matriz}\\n\")\n\n# Encontrando onde os valores s\u00e3o maiores ou iguais a 2\nposicoes = np.where(matriz &gt;= 2)\nprint(f\"Resultado de np.where(matriz &gt;= 2):\\n{posicoes}\")\nprint(f\"Tipo: {type(posicoes)}\")\n\n# O resultado \u00e9 uma tupla com dois arrays:\nprint(f\"\\nPrimeira parte (\u00edndices das linhas): {posicoes[0]}\")\nprint(f\"Segunda parte (\u00edndices das colunas): {posicoes[1]}\")\n\n# Mostrando os valores encontrados\nprint(\"\\nValores encontrados nas posi\u00e7\u00f5es:\")\nfor i, j in zip(posicoes[0], posicoes[1]):\n    print(f\"matriz[{i}, {j}] = {matriz[i, j]}\")\n</pre> # Exemplo did\u00e1tico de np.where()  # Criando uma matriz de exemplo 3x3 matriz = np.array([     [0, 1, 5],     [2, 2, 3],     [0, 3, 1] ]) print(f\"Matriz original:\\n{matriz}\\n\")  # Encontrando onde os valores s\u00e3o maiores ou iguais a 2 posicoes = np.where(matriz &gt;= 2) print(f\"Resultado de np.where(matriz &gt;= 2):\\n{posicoes}\") print(f\"Tipo: {type(posicoes)}\")  # O resultado \u00e9 uma tupla com dois arrays: print(f\"\\nPrimeira parte (\u00edndices das linhas): {posicoes[0]}\") print(f\"Segunda parte (\u00edndices das colunas): {posicoes[1]}\")  # Mostrando os valores encontrados print(\"\\nValores encontrados nas posi\u00e7\u00f5es:\") for i, j in zip(posicoes[0], posicoes[1]):     print(f\"matriz[{i}, {j}] = {matriz[i, j]}\") <pre>Matriz original:\n[[0 1 5]\n [2 2 3]\n [0 3 1]]\n\nResultado de np.where(matriz &gt;= 2):\n(array([0, 1, 1, 1, 2]), array([2, 0, 1, 2, 1]))\nTipo: &lt;class 'tuple'&gt;\n\nPrimeira parte (\u00edndices das linhas): [0 1 1 1 2]\nSegunda parte (\u00edndices das colunas): [2 0 1 2 1]\n\nValores encontrados nas posi\u00e7\u00f5es:\nmatriz[0, 2] = 5\nmatriz[1, 0] = 2\nmatriz[1, 1] = 2\nmatriz[1, 2] = 3\nmatriz[2, 1] = 3\n</pre> In\u00a0[9]: Copied! <pre># Exemplo did\u00e1tico de zip()\n\nletras = ['F', 'I', 'A', 'P']\nnumeros = [1, 2, 3, 4]\n\nprint(\"Combinando duas listas com zip():\")\nfor letra, numero in zip(letras, numeros):\n    print(f\"Letra: {letra}, N\u00famero: {numero}\")\n\n# Usando zip com a sintaxe * para \"desempacotar\" uma tupla\ncoordenadas = ([1, 2, 3], [10, 20, 30])  # Similar ao resultado de np.where()\nprint(\"\\nDesempacotando uma tupla de coordenadas:\")\nfor x, y in zip(*coordenadas):\n    print(f\"Ponto: ({x}, {y})\")\n</pre> # Exemplo did\u00e1tico de zip()  letras = ['F', 'I', 'A', 'P'] numeros = [1, 2, 3, 4]  print(\"Combinando duas listas com zip():\") for letra, numero in zip(letras, numeros):     print(f\"Letra: {letra}, N\u00famero: {numero}\")  # Usando zip com a sintaxe * para \"desempacotar\" uma tupla coordenadas = ([1, 2, 3], [10, 20, 30])  # Similar ao resultado de np.where() print(\"\\nDesempacotando uma tupla de coordenadas:\") for x, y in zip(*coordenadas):     print(f\"Ponto: ({x}, {y})\") <pre>Combinando duas listas com zip():\nLetra: F, N\u00famero: 1\nLetra: I, N\u00famero: 2\nLetra: A, N\u00famero: 3\nLetra: P, N\u00famero: 4\n\nDesempacotando uma tupla de coordenadas:\nPonto: (1, 10)\nPonto: (2, 20)\nPonto: (3, 30)\n</pre> In\u00a0[10]: Copied! <pre># Cria uma c\u00f3pia da imagem original para n\u00e3o modific\u00e1-la\nimg_result = img.copy()\n\n# Obt\u00e9m as dimens\u00f5es do template\naltura, largura = template.shape\n\n# Define um valor limiar para considerar uma correspond\u00eancia v\u00e1lida\n# Este valor pode precisar de ajustes dependendo da imagem e do m\u00e9todo usado\nthreshold = 0.1\n\n# Encontra todas as posi\u00e7\u00f5es onde o valor de correspond\u00eancia \u00e9 menor que o limiar\n# Como usamos TM_SQDIFF_NORMED, valores menores indicam melhor correspond\u00eancia\nloc = np.where(res &lt;= threshold)\n\nprint(f\"Encontradas {len(loc[0])} poss\u00edveis correspond\u00eancias\")\n\n# Para cada ponto de correspond\u00eancia, desenha um ret\u00e2ngulo\ncount = 0\nfor pt in zip(*loc[::-1]):  # [::-1] inverte as coordenadas para formato (x,y)\n    # Desenha o ret\u00e2ngulo\n    cv2.rectangle(\n        img_result,          # Imagem onde desenhar\n        pt,                  # Ponto superior esquerdo\n        (pt[0] + largura, pt[1] + altura),  # Ponto inferior direito\n        (0, 255, 0),         # Cor verde (BGR)\n        3                    # Espessura da linha\n    )\n    count += 1\n\nprint(f\"Desenhados {count} ret\u00e2ngulos ap\u00f3s filtrar correspond\u00eancias sobrepostas\")\n\n# Exibe o resultado\nplt.figure(figsize=(12, 8))\nplt.title(f\"Caixas de interroga\u00e7\u00e3o detectadas\")\nplt.imshow(cv2.cvtColor(img_result, cv2.COLOR_BGR2RGB))\nplt.axis('off')\nplt.show()\n</pre> # Cria uma c\u00f3pia da imagem original para n\u00e3o modific\u00e1-la img_result = img.copy()  # Obt\u00e9m as dimens\u00f5es do template altura, largura = template.shape  # Define um valor limiar para considerar uma correspond\u00eancia v\u00e1lida # Este valor pode precisar de ajustes dependendo da imagem e do m\u00e9todo usado threshold = 0.1  # Encontra todas as posi\u00e7\u00f5es onde o valor de correspond\u00eancia \u00e9 menor que o limiar # Como usamos TM_SQDIFF_NORMED, valores menores indicam melhor correspond\u00eancia loc = np.where(res &lt;= threshold)  print(f\"Encontradas {len(loc[0])} poss\u00edveis correspond\u00eancias\")  # Para cada ponto de correspond\u00eancia, desenha um ret\u00e2ngulo count = 0 for pt in zip(*loc[::-1]):  # [::-1] inverte as coordenadas para formato (x,y)     # Desenha o ret\u00e2ngulo     cv2.rectangle(         img_result,          # Imagem onde desenhar         pt,                  # Ponto superior esquerdo         (pt[0] + largura, pt[1] + altura),  # Ponto inferior direito         (0, 255, 0),         # Cor verde (BGR)         3                    # Espessura da linha     )     count += 1  print(f\"Desenhados {count} ret\u00e2ngulos ap\u00f3s filtrar correspond\u00eancias sobrepostas\")  # Exibe o resultado plt.figure(figsize=(12, 8)) plt.title(f\"Caixas de interroga\u00e7\u00e3o detectadas\") plt.imshow(cv2.cvtColor(img_result, cv2.COLOR_BGR2RGB)) plt.axis('off') plt.show() <pre>Encontradas 32 poss\u00edveis correspond\u00eancias\nDesenhados 32 ret\u00e2ngulos ap\u00f3s filtrar correspond\u00eancias sobrepostas\n</pre> In\u00a0[12]: Copied! <pre># Implemente sua solu\u00e7\u00e3o do Desafio 3 aqui\n# Dicas:\n# 1. Troque o m\u00e9todo TM_SQDIFF_NORMED por outro (ex: TM_CCOEFF_NORMED)\n# 2. Se usar m\u00e9todos como TM_CCOEFF_NORMED, lembre-se de inverter a condi\u00e7\u00e3o (res &gt;= threshold)\n# 3. Ajuste o valor do threshold conforme necess\u00e1rio\n</pre> # Implemente sua solu\u00e7\u00e3o do Desafio 3 aqui # Dicas: # 1. Troque o m\u00e9todo TM_SQDIFF_NORMED por outro (ex: TM_CCOEFF_NORMED) # 2. Se usar m\u00e9todos como TM_CCOEFF_NORMED, lembre-se de inverter a condi\u00e7\u00e3o (res &gt;= threshold) # 3. Ajuste o valor do threshold conforme necess\u00e1rio"},{"location":"aulas/PDI/lab12/Template_matching.html#template-matching-com-opencv","title":"Template Matching com OpenCV\u00b6","text":""},{"location":"aulas/PDI/lab12/Template_matching.html#objetivos-da-aula","title":"Objetivos da aula:\u00b6","text":"<ul> <li>Entender o conceito de template matching</li> <li>Implementar detec\u00e7\u00e3o de objetos utilizando template matching</li> <li>Explorar diferentes m\u00e9todos de correla\u00e7\u00e3o dispon\u00edveis no OpenCV</li> </ul>"},{"location":"aulas/PDI/lab12/Template_matching.html#introducao-ao-template-matching","title":"Introdu\u00e7\u00e3o ao Template Matching\u00b6","text":"<p>At\u00e9 agora, estudamos t\u00e9cnicas para realizar a segmenta\u00e7\u00e3o e detec\u00e7\u00e3o de objetos e formas simples como c\u00edrculos, retas e cores. Nesta aula, vamos explorar uma t\u00e9cnica mais avan\u00e7ada chamada template matching.</p> <p>O template matching \u00e9 um m\u00e9todo usado para localizar um padr\u00e3o (template) dentro de uma imagem maior. Conceitualmente, \u00e9 como procurar uma pe\u00e7a espec\u00edfica em um quebra-cabe\u00e7a, onde:</p> <ul> <li>Template: \u00c9 a imagem de refer\u00eancia que queremos encontrar</li> <li>Imagem de an\u00e1lise: \u00c9 a imagem maior onde queremos encontrar o template</li> </ul>"},{"location":"aulas/PDI/lab12/Template_matching.html#como-funciona","title":"Como funciona?\u00b6","text":"<p>O algoritmo de template matching funciona de forma similar aos filtros de convolu\u00e7\u00e3o que estudamos anteriormente. O processo consiste em:</p> <ol> <li>Deslizar o template sobre cada posi\u00e7\u00e3o da imagem maior</li> <li>Calcular uma m\u00e9trica de similaridade entre o template e a regi\u00e3o atual</li> <li>Gerar um mapa de similaridade onde os valores indicam o grau de correspond\u00eancia</li> </ol> <p>Na OpenCV, esse processo \u00e9 implementado atrav\u00e9s da fun\u00e7\u00e3o <code>cv2.matchTemplate()</code>.</p>"},{"location":"aulas/PDI/lab12/Template_matching.html#detectando-um-personagem-em-um-cenario-de-jogo","title":"Detectando um personagem em um cen\u00e1rio de jogo\u00b6","text":"<p>Vamos come\u00e7ar com um exemplo: encontrar o GOOMBA em uma cena do jogo Mario Bros.</p> <p></p> <p>Primeiro, vamos carregar a imagem principal:</p>"},{"location":"aulas/PDI/lab12/Template_matching.html#aplicando-template-matching","title":"Aplicando Template Matching\u00b6","text":"<p>Agora vamos carregar a imagem do template (o GOOMBA que queremos encontrar) e aplicar a t\u00e9cnica de template matching:</p>"},{"location":"aulas/PDI/lab12/Template_matching.html#interpretando-o-resultado","title":"Interpretando o Resultado\u00b6","text":"<p>O resultado do template matching \u00e9 uma matriz onde cada pixel representa o grau de correspond\u00eancia entre o template e a regi\u00e3o correspondente na imagem original. No m\u00e9todo <code>cv2.TM_SQDIFF</code> que usamos:</p> <ul> <li>Valores mais baixos indicam melhor correspond\u00eancia (menor diferen\u00e7a)</li> <li>Valores mais altos indicam pior correspond\u00eancia (maior diferen\u00e7a)</li> </ul> <p>Visualmente, podemos notar que o nosso GOOMBA est\u00e1 destacado na imagem como o pixel mais escuro.</p> <p>Para capturar a posi\u00e7\u00e3o exata deste pixel (a melhor correspond\u00eancia), vamos usar a fun\u00e7\u00e3o <code>cv2.minMaxLoc()</code>, que retorna os valores m\u00ednimo e m\u00e1ximo, al\u00e9m de suas posi\u00e7\u00f5es na imagem.</p>"},{"location":"aulas/PDI/lab12/Template_matching.html#desafio-1-destacando-o-objeto-encontrado","title":"DESAFIO 1: Destacando o objeto encontrado\u00b6","text":"<p>Agora que encontramos a posi\u00e7\u00e3o do GOOMBA na imagem, vamos destac\u00e1-lo desenhando um ret\u00e2ngulo ao seu redor.</p>"},{"location":"aulas/PDI/lab12/Template_matching.html#dicas","title":"Dicas:\u00b6","text":"<ul> <li>Use a fun\u00e7\u00e3o <code>cv2.rectangle(img, ponto_inicial, ponto_final, cor, espessura)</code></li> <li>O <code>ponto_inicial</code> j\u00e1 temos: \u00e9 o <code>min_loc</code></li> <li>Para o <code>ponto_final</code>, precisamos somar as dimens\u00f5es do template ao ponto inicial</li> <li>Para cores, use uma tupla (B, G, R) - lembre-se que o OpenCV usa BGR!</li> </ul>"},{"location":"aulas/PDI/lab12/Template_matching.html#desafio-2-explorando-diferentes-metodos-de-correspondencia","title":"DESAFIO 2: Explorando diferentes m\u00e9todos de correspond\u00eancia\u00b6","text":"<p>A fun\u00e7\u00e3o <code>cv2.matchTemplate(imagem, template, m\u00e9todo)</code> suporta diferentes m\u00e9todos de c\u00e1lculo de correla\u00e7\u00e3o, cada um com suas vantagens e caracter\u00edsticas.</p>"},{"location":"aulas/PDI/lab12/Template_matching.html#metodos-disponiveis-no-opencv","title":"M\u00e9todos dispon\u00edveis no OpenCV:\u00b6","text":"<ol> <li>cv2.TM_SQDIFF: Diferen\u00e7a quadr\u00e1tica - valor menor indica melhor correspond\u00eancia</li> <li>cv2.TM_SQDIFF_NORMED: Diferen\u00e7a quadr\u00e1tica normalizada (entre 0 e 1)</li> <li>cv2.TM_CCORR: Correla\u00e7\u00e3o cruzada - valor maior indica melhor correspond\u00eancia</li> <li>cv2.TM_CCORR_NORMED: Correla\u00e7\u00e3o cruzada normalizada</li> <li>cv2.TM_CCOEFF: Coeficiente de correla\u00e7\u00e3o - valor maior indica melhor correspond\u00eancia</li> <li>cv2.TM_CCOEFF_NORMED: Coeficiente de correla\u00e7\u00e3o normalizado</li> </ol>"},{"location":"aulas/PDI/lab12/Template_matching.html#seu-desafio","title":"Seu desafio:\u00b6","text":"<p>Teste pelo menos 3 m\u00e9todos diferentes e compare os resultados visuais e num\u00e9ricos.</p> <p>Refer\u00eancia: OpenCV Template Matching Tutorial</p>"},{"location":"aulas/PDI/lab12/Template_matching.html#detectando-multiplas-ocorrencias-caixas-de-interrogacao","title":"Detectando m\u00faltiplas ocorr\u00eancias: Caixas de interroga\u00e7\u00e3o\u00b6","text":"<p>No exemplo anterior, encontramos uma \u00fanica ocorr\u00eancia do GOOMBA. Mas e se quisermos encontrar m\u00faltiplas ocorr\u00eancias de um objeto na imagem?</p> <p>Vamos agora tentar localizar todas as caixas de interroga\u00e7\u00e3o (<code>?</code>) na imagem do Mario:</p> <p></p> <p>O resultado final deve detectar 4 caixas, como mostrado abaixo:</p> <p></p>"},{"location":"aulas/PDI/lab12/Template_matching.html#detectando-multiplas-correspondencias","title":"Detectando m\u00faltiplas correspond\u00eancias\u00b6","text":"<p>Podemos notar que as caixas de interroga\u00e7\u00e3o aparecem como m\u00faltiplos pontos escuros no mapa de correspond\u00eancia.</p> <p>Para capturar todas essas ocorr\u00eancias, a fun\u00e7\u00e3o <code>cv2.minMaxLoc()</code> n\u00e3o \u00e9 suficiente, pois ela retorna apenas a melhor correspond\u00eancia. Precisamos de uma abordagem diferente:</p> <ol> <li>Definir um valor limiar (threshold) para considerar uma correspond\u00eancia v\u00e1lida</li> <li>Encontrar todas as posi\u00e7\u00f5es onde o valor de correspond\u00eancia \u00e9 menor (ou maior, dependendo do m\u00e9todo) que esse limiar</li> <li>Para cada uma dessas posi\u00e7\u00f5es, desenhar um ret\u00e2ngulo ao redor do objeto encontrado</li> </ol> <p>Vamos usar a fun\u00e7\u00e3o <code>numpy.where()</code> para isso.</p>"},{"location":"aulas/PDI/lab12/Template_matching.html#conceitos-uteis-do-numpy-e-python","title":"Conceitos \u00fateis do NumPy e Python\u00b6","text":"<p>Antes de prosseguir, vamos revisar duas fun\u00e7\u00f5es importantes que utilizaremos:</p>"},{"location":"aulas/PDI/lab12/Template_matching.html#1-numpywhere","title":"1. <code>numpy.where()</code>\u00b6","text":"<p>A fun\u00e7\u00e3o <code>np.where()</code> retorna os \u00edndices onde uma condi\u00e7\u00e3o \u00e9 satisfeita em um array NumPy.</p> <p>Documenta\u00e7\u00e3o: numpy.where</p>"},{"location":"aulas/PDI/lab12/Template_matching.html#2-zip","title":"2. <code>zip()</code>\u00b6","text":"<p>A fun\u00e7\u00e3o <code>zip()</code> em Python permite iterar sobre m\u00faltiplas sequ\u00eancias em paralelo, combinando seus elementos.</p>"},{"location":"aulas/PDI/lab12/Template_matching.html#detectando-todas-as-caixas-de-interrogacao","title":"Detectando todas as caixas de interroga\u00e7\u00e3o\u00b6","text":"<p>Agora vamos aplicar esses conceitos para encontrar todas as caixas de interroga\u00e7\u00e3o na imagem:</p>"},{"location":"aulas/PDI/lab12/Template_matching.html#desafio-3-testando-outros-metodos","title":"DESAFIO 3: Testando outros m\u00e9todos\u00b6","text":"<p>Agora que entendemos como detectar m\u00faltiplas ocorr\u00eancias, vamos testar outros m\u00e9todos de template matching para as caixas de interroga\u00e7\u00e3o.</p> <p>Substitua o m\u00e9todo <code>TM_SQDIFF_NORMED</code> por outro e ajuste o threshold conforme necess\u00e1rio:</p> <ul> <li>Para <code>TM_SQDIFF</code> e <code>TM_SQDIFF_NORMED</code>: use <code>res &lt;= threshold</code> (valores menores s\u00e3o melhores)</li> <li>Para <code>TM_CCORR</code>, <code>TM_CCORR_NORMED</code>, <code>TM_CCOEFF</code> e <code>TM_CCOEFF_NORMED</code>: use <code>res &gt;= threshold</code> (valores maiores s\u00e3o melhores)</li> </ul>"},{"location":"aulas/PDI/lab12/Template_matching.html#desafio-4-limitacoes-do-template-matching","title":"DESAFIO 4: Limita\u00e7\u00f5es do Template Matching\u00b6","text":"<p>O template matching \u00e9 uma t\u00e9cnica \u00fatil, mas tem limita\u00e7\u00f5es importantes. Reflita sobre as seguintes quest\u00f5es:</p> <ol> <li><p>Escala: O que acontece se o template n\u00e3o estiver na mesma escala do objeto que queremos detectar na imagem?</p> </li> <li><p>Ilumina\u00e7\u00e3o: Como o algoritmo se comporta quando h\u00e1 diferen\u00e7as de brilho ou contraste entre o template e a imagem?</p> </li> <li><p>Rota\u00e7\u00e3o: O que acontece se o objeto na imagem estiver rotacionado em rela\u00e7\u00e3o ao template?</p> </li> <li><p>Oclus\u00e3o parcial: Como o m\u00e9todo responde quando o objeto est\u00e1 parcialmente encoberto?</p> </li> </ol> <p>Para cada uma dessas limita\u00e7\u00f5es, existe alguma estrat\u00e9gia que poderia ser aplicada para mitigar o problema? Quais outras t\u00e9cnicas de vis\u00e3o computacional poderiam ser mais adequadas nesses casos?</p>"},{"location":"aulas/PDI/lab13/Features-old.html","title":"Features old","text":"<p>Objetivos da aula:</p> <ul> <li>apresentar e aplicar o conceito de FEATURE</li> <li>apresentar e aplicar o conceito de DESCRITORES</li> </ul> <p>QUAL O PROBLEMA?</p> <p>Estamos tentando ao longo do curso computar imagens de forma eficiente. Na \u00faltima aula aprendemos e usamos a t\u00e9cnica template matching, vimos que \u00e9 uma t\u00e9cnica simples e poderosa que basicamente convolui uma template em um espa\u00e7o de busca (Imagem). Contudo, possui algumas fragilidades tais como, escala, rota\u00e7\u00e3o e intensidade luminosa.</p> <p>Queremos encontrar essa caixa. </p> <p></p> <p>Neste espa\u00e7o de busca, imagem. </p> <p>Vamos pensar um pouco...</p> <p>Com as t\u00e9cnicas que conhecemos, como podemos fazer essa detec\u00e7\u00e3o da caixa??</p> <p>...</p> <p>FEATURES</p> <p>Features em vis\u00e3o computacional s\u00e3o detalhes de uma imagem, que fornecem informa\u00e7\u00f5es sobre o que ela significa. J\u00e1 conhecemos e aplicamos t\u00e9cnicas para detec\u00e7\u00e3o por cor e contorno, por exemplo.</p> <p>Hoje, vamos conhecer uma t\u00e9cnica que extrai da imagem uma descri\u00e7\u00e3o local com pontos de interesse (key points), desta forma criamos uma assinatura para cada ponto da imagem, a ideia \u00e9 maximizar pontos que apresentam que apresentam invari\u00e2ncia a rota\u00e7\u00e3o, escala e transla\u00e7\u00e3o. Assim conseguimos buscar e encontrar esses pontos em outras imagens.</p> <p>Os principais algoritmos s\u00e3o:</p> <p>SIFT,ORB, SURF, FAST, BRISK</p> <p>Onde usamos esses algoritmos?</p> <pre><code>Reconhecimento de objetos\nalinhamento de imagens (imagens panor\u00e2micas)\nreconstru\u00e7\u00e3o 3d\ntracking de imagem\nindexa\u00e7\u00e3o de imagem (banco de imagem)</code></pre> In\u00a0[\u00a0]: Copied! <pre>## vou fazer o download das imagens do reposit\u00f3rio para usar no colab mais facil....\n\n!wget https://raw.githubusercontent.com/arnaldojr/cognitivecomputing/master/material/aulas/PDI/lab13/box_4features.png /content\n!wget https://raw.githubusercontent.com/arnaldojr/cognitivecomputing/master/material/aulas/PDI/lab13/box_in_scene.png /content\n!wget https://raw.githubusercontent.com/arnaldojr/cognitivecomputing/master/material/aulas/PDI/lab13/box.png /content\n!wget https://raw.githubusercontent.com/arnaldojr/cognitivecomputing/master/material/aulas/PDI/lab13/admiravelmundonovo.jpg /content\n!wget https://raw.githubusercontent.com/arnaldojr/cognitivecomputing/master/material/aulas/PDI/lab13/admiravelmundonovo.mp4 /content\n!wget https://raw.githubusercontent.com/arnaldojr/cognitivecomputing/master/material/aulas/PDI/lab13/q22.jpg /content\n!wget https://raw.githubusercontent.com/arnaldojr/cognitivecomputing/master/material/aulas/PDI/lab13/q11.jpg /content\n</pre> ## vou fazer o download das imagens do reposit\u00f3rio para usar no colab mais facil....  !wget https://raw.githubusercontent.com/arnaldojr/cognitivecomputing/master/material/aulas/PDI/lab13/box_4features.png /content !wget https://raw.githubusercontent.com/arnaldojr/cognitivecomputing/master/material/aulas/PDI/lab13/box_in_scene.png /content !wget https://raw.githubusercontent.com/arnaldojr/cognitivecomputing/master/material/aulas/PDI/lab13/box.png /content !wget https://raw.githubusercontent.com/arnaldojr/cognitivecomputing/master/material/aulas/PDI/lab13/admiravelmundonovo.jpg /content !wget https://raw.githubusercontent.com/arnaldojr/cognitivecomputing/master/material/aulas/PDI/lab13/admiravelmundonovo.mp4 /content !wget https://raw.githubusercontent.com/arnaldojr/cognitivecomputing/master/material/aulas/PDI/lab13/q22.jpg /content !wget https://raw.githubusercontent.com/arnaldojr/cognitivecomputing/master/material/aulas/PDI/lab13/q11.jpg /content  In\u00a0[1]: Copied! <pre>%matplotlib inline\nimport cv2\nfrom matplotlib import pyplot as plt\nimport numpy as np\n\n# carrega as imagens\nimg1 = cv2.imread('box.png',0)\nimg2 = cv2.imread('box_in_scene.png',0)\n\n#template\nplt.figure(figsize = (10,10))\nplt.imshow(img1, cmap=\"gray\"); plt.show();\n\n# Imagem espa\u00e7o de busca\nplt.figure(figsize = (10,10))\nplt.imshow(img2, cmap=\"gray\"); plt.show();\n</pre> %matplotlib inline import cv2 from matplotlib import pyplot as plt import numpy as np  # carrega as imagens img1 = cv2.imread('box.png',0) img2 = cv2.imread('box_in_scene.png',0)  #template plt.figure(figsize = (10,10)) plt.imshow(img1, cmap=\"gray\"); plt.show();  # Imagem espa\u00e7o de busca plt.figure(figsize = (10,10)) plt.imshow(img2, cmap=\"gray\"); plt.show();  In\u00a0[2]: Copied! <pre># inicializa com o construtor ORB\norb = cv2.ORB_create()\n</pre> # inicializa com o construtor ORB orb = cv2.ORB_create()  In\u00a0[3]: Copied! <pre># Detecta os keypoints\n#kp = orb.detect(img1,None)\n# Computa os Descritores\n#orb_tuple = orb.compute(img1, kp)\n\n#Podemos usar uma fun\u00e7\u00e3o que calcula os keypoints e Descritores\nkp1, des1 = orb.detectAndCompute(img1,None)\n</pre> # Detecta os keypoints #kp = orb.detect(img1,None) # Computa os Descritores #orb_tuple = orb.compute(img1, kp)  #Podemos usar uma fun\u00e7\u00e3o que calcula os keypoints e Descritores kp1, des1 = orb.detectAndCompute(img1,None)  In\u00a0[4]: Copied! <pre># Desenha os keypoints na imagem \ngray2 = cv2.drawKeypoints(img1, kp1, outImage=np.array([]), flags=0)\n\nplt.figure(figsize=(10, 10))\nplt.imshow(cv2.cvtColor(gray2, cv2.COLOR_BGR2RGB));\n</pre> # Desenha os keypoints na imagem  gray2 = cv2.drawKeypoints(img1, kp1, outImage=np.array([]), flags=0)  plt.figure(figsize=(10, 10)) plt.imshow(cv2.cvtColor(gray2, cv2.COLOR_BGR2RGB));  In\u00a0[5]: Copied! <pre># Os keypoints s\u00e3o formados dos gradientes da imagem naquele ponto, por essa raz\u00e3o possuem amplitude e dire\u00e7\u00e3o\ngray3 = cv2.drawKeypoints(img1, kp1, outImage=np.array([]), flags=cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)\n\n\nplt.figure(figsize=(10, 10))\nplt.imshow(cv2.cvtColor(gray3, cv2.COLOR_BGR2RGB))\n</pre> # Os keypoints s\u00e3o formados dos gradientes da imagem naquele ponto, por essa raz\u00e3o possuem amplitude e dire\u00e7\u00e3o gray3 = cv2.drawKeypoints(img1, kp1, outImage=np.array([]), flags=cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)   plt.figure(figsize=(10, 10)) plt.imshow(cv2.cvtColor(gray3, cv2.COLOR_BGR2RGB)) Out[5]: <pre>&lt;matplotlib.image.AxesImage at 0x14429c730&gt;</pre> In\u00a0[\u00a0]: Copied! <pre>### Implemente sua solu\u00e7\u00e3o aqui.....\n</pre> ### Implemente sua solu\u00e7\u00e3o aqui.....          <p>O resultado para 4 features, nessa imagem conseguimos visualizar os keypoints e sua dire\u00e7\u00e3o e amplitude do vetor gradiente resultante. </p> In\u00a0[\u00a0]: Copied! <pre>## Implemente sua solu\u00e7\u00e3o aqui......\n</pre> ## Implemente sua solu\u00e7\u00e3o aqui......       In\u00a0[6]: Copied! <pre>%matplotlib inline\nimport cv2\nfrom matplotlib import pyplot as plt\nimport numpy as np\n\n# carrega as imagens\nimg1 = cv2.imread('box.png',0)\nimg2 = cv2.imread('box_in_scene.png',0)\n\n# inicializa com o construtor ORB\norb = cv2.ORB_create()\n\n#Podemos usar uma fun\u00e7\u00e3o que calcula os keypoints e Descritores\nkp1, des1 = orb.detectAndCompute(img1,None)\nkp2, des2 = orb.detectAndCompute(img2,None)\n\n\ngray1 = cv2.drawKeypoints(img1, kp1, outImage=np.array([]), flags=0)\ngray2 = cv2.drawKeypoints(img2, kp2, outImage=np.array([]), flags=0)\n\n\n#template\nplt.figure(figsize = (10,10))\nplt.imshow(gray1); plt.show();\n\n# Imagem espa\u00e7o de busca\nplt.figure(figsize = (10,10))\nplt.imshow(gray2); plt.show();\n</pre> %matplotlib inline import cv2 from matplotlib import pyplot as plt import numpy as np  # carrega as imagens img1 = cv2.imread('box.png',0) img2 = cv2.imread('box_in_scene.png',0)  # inicializa com o construtor ORB orb = cv2.ORB_create()  #Podemos usar uma fun\u00e7\u00e3o que calcula os keypoints e Descritores kp1, des1 = orb.detectAndCompute(img1,None) kp2, des2 = orb.detectAndCompute(img2,None)   gray1 = cv2.drawKeypoints(img1, kp1, outImage=np.array([]), flags=0) gray2 = cv2.drawKeypoints(img2, kp2, outImage=np.array([]), flags=0)   #template plt.figure(figsize = (10,10)) plt.imshow(gray1); plt.show();  # Imagem espa\u00e7o de busca plt.figure(figsize = (10,10)) plt.imshow(gray2); plt.show();  In\u00a0[7]: Copied! <pre># cria o objeto bf (Brute-force descriptor matcher)\nbf = cv2.BFMatcher(cv2.NORM_HAMMING, crossCheck=True)\n\n# a fun\u00e7\u00e3o match devolve os matches encontrados\nmatches = bf.match(des1,des2)\n\nprint(\"Foram encontrados: {} matches\".format(len(matches)))\n\nimg3 = cv2.drawMatches(img1,kp1,img2,kp2,matches,None, flags=2)\n\nplt.figure(figsize = (20,10))\nplt.imshow(img3); plt.show();\n</pre> # cria o objeto bf (Brute-force descriptor matcher) bf = cv2.BFMatcher(cv2.NORM_HAMMING, crossCheck=True)  # a fun\u00e7\u00e3o match devolve os matches encontrados matches = bf.match(des1,des2)  print(\"Foram encontrados: {} matches\".format(len(matches)))  img3 = cv2.drawMatches(img1,kp1,img2,kp2,matches,None, flags=2)  plt.figure(figsize = (20,10)) plt.imshow(img3); plt.show();  <pre>Foram encontrados: 148 matches\n</pre> <p>Parece que o resultado n\u00e3o foi o que est\u00e1vamos esperando... mas nem tudo est\u00e1 perdido ainda. vamos fazer alguns ajustes nas fun\u00e7\u00f5es matches e na quantidade keypoints printados. Muitos keypoints s\u00e3o falsos positivos.</p> <p>Primeiro, vamos ordenar o vetor matches para ficar de acordo com a dist\u00e2ncia entre os descritores. Quanto mais baixo, melhor.</p> In\u00a0[8]: Copied! <pre>## Vamos dar uma olhada em duas fun\u00e7\u00f5es novas do python. sorted() e lambda\n\n# essa a lista de compra da feira, item e pre\u00e7o.\n\nlista = [\n    ('Banana', 18),\n    ('Ma\u00e7a', 1),\n    ('Goiaba', 20),\n    ('Uva', 22),\n    ('Pera', 12)\n]\n\nprint(\"lista n\u00e3o ordenada: \",lista) # lista n\u00e3o ordenada\n\nlista_ord = sorted(lista)\n\nprint(\"lista ordenada ordem alfabetica: \",lista_ord) # lista ordenada por indice a..z\n\nlista_ord_pre = sorted(lista, key= lambda x:x[1])\n\nprint(\"lista ordenada por pre\u00e7o: \",lista_ord_pre) # lista ordenada pelo pre\u00e7o\n</pre> ## Vamos dar uma olhada em duas fun\u00e7\u00f5es novas do python. sorted() e lambda  # essa a lista de compra da feira, item e pre\u00e7o.  lista = [     ('Banana', 18),     ('Ma\u00e7a', 1),     ('Goiaba', 20),     ('Uva', 22),     ('Pera', 12) ]  print(\"lista n\u00e3o ordenada: \",lista) # lista n\u00e3o ordenada  lista_ord = sorted(lista)  print(\"lista ordenada ordem alfabetica: \",lista_ord) # lista ordenada por indice a..z  lista_ord_pre = sorted(lista, key= lambda x:x[1])  print(\"lista ordenada por pre\u00e7o: \",lista_ord_pre) # lista ordenada pelo pre\u00e7o <pre>lista n\u00e3o ordenada:  [('Banana', 18), ('Ma\u00e7a', 1), ('Goiaba', 20), ('Uva', 22), ('Pera', 12)]\nlista ordenada ordem alfabetica:  [('Banana', 18), ('Goiaba', 20), ('Ma\u00e7a', 1), ('Pera', 12), ('Uva', 22)]\nlista ordenada por pre\u00e7o:  [('Ma\u00e7a', 1), ('Pera', 12), ('Banana', 18), ('Goiaba', 20), ('Uva', 22)]\n</pre> In\u00a0[9]: Copied! <pre># ordenamos o vetor matches para ficar os melhores (menor distancia) no inicio da lista\n\nmatches = sorted(matches, key = lambda x:x.distance)\n</pre> # ordenamos o vetor matches para ficar os melhores (menor distancia) no inicio da lista  matches = sorted(matches, key = lambda x:x.distance)  In\u00a0[10]: Copied! <pre>img3 = cv2.drawMatches(img1,kp1,img2,kp2,matches[:15],None, flags=2)\n\n\nplt.figure(figsize = (20,10))\nplt.imshow(img3); plt.show();\n</pre> img3 = cv2.drawMatches(img1,kp1,img2,kp2,matches[:15],None, flags=2)   plt.figure(figsize = (20,10)) plt.imshow(img3); plt.show(); In\u00a0[\u00a0]: Copied! <pre>## implemente sua solu\u00e7\u00e3o aqui......\n</pre> ## implemente sua solu\u00e7\u00e3o aqui......       In\u00a0[\u00a0]: Copied! <pre>######## N\u00e3o fa\u00e7a esse desafio no google colab, fa\u00e7a em sua m\u00e1quina. \n######## N\u00e3o fa\u00e7a esse desafio no google colab, fa\u00e7a em sua m\u00e1quina. \n######## N\u00e3o fa\u00e7a esse desafio no google colab, fa\u00e7a em sua m\u00e1quina. \n######## N\u00e3o fa\u00e7a esse desafio no google colab, fa\u00e7a em sua m\u00e1quina. \n######## N\u00e3o fa\u00e7a esse desafio no google colab, fa\u00e7a em sua m\u00e1quina. \n######## N\u00e3o fa\u00e7a esse desafio no google colab, fa\u00e7a em sua m\u00e1quina. \n######## N\u00e3o fa\u00e7a esse desafio no google colab, fa\u00e7a em sua m\u00e1quina. \n######## N\u00e3o fa\u00e7a esse desafio no google colab, fa\u00e7a em sua m\u00e1quina. \n######## N\u00e3o fa\u00e7a esse desafio no google colab, fa\u00e7a em sua m\u00e1quina. \n######## N\u00e3o fa\u00e7a esse desafio no google colab, fa\u00e7a em sua m\u00e1quina. \n######## N\u00e3o fa\u00e7a esse desafio no google colab, fa\u00e7a em sua m\u00e1quina. \n######## N\u00e3o fa\u00e7a esse desafio no google colab, fa\u00e7a em sua m\u00e1quina. \n######## N\u00e3o fa\u00e7a esse desafio no google colab, fa\u00e7a em sua m\u00e1quina. \n######## N\u00e3o fa\u00e7a esse desafio no google colab, fa\u00e7a em sua m\u00e1quina.\n</pre> ######## N\u00e3o fa\u00e7a esse desafio no google colab, fa\u00e7a em sua m\u00e1quina.  ######## N\u00e3o fa\u00e7a esse desafio no google colab, fa\u00e7a em sua m\u00e1quina.  ######## N\u00e3o fa\u00e7a esse desafio no google colab, fa\u00e7a em sua m\u00e1quina.  ######## N\u00e3o fa\u00e7a esse desafio no google colab, fa\u00e7a em sua m\u00e1quina.  ######## N\u00e3o fa\u00e7a esse desafio no google colab, fa\u00e7a em sua m\u00e1quina.  ######## N\u00e3o fa\u00e7a esse desafio no google colab, fa\u00e7a em sua m\u00e1quina.  ######## N\u00e3o fa\u00e7a esse desafio no google colab, fa\u00e7a em sua m\u00e1quina.  ######## N\u00e3o fa\u00e7a esse desafio no google colab, fa\u00e7a em sua m\u00e1quina.  ######## N\u00e3o fa\u00e7a esse desafio no google colab, fa\u00e7a em sua m\u00e1quina.  ######## N\u00e3o fa\u00e7a esse desafio no google colab, fa\u00e7a em sua m\u00e1quina.  ######## N\u00e3o fa\u00e7a esse desafio no google colab, fa\u00e7a em sua m\u00e1quina.  ######## N\u00e3o fa\u00e7a esse desafio no google colab, fa\u00e7a em sua m\u00e1quina.  ######## N\u00e3o fa\u00e7a esse desafio no google colab, fa\u00e7a em sua m\u00e1quina.  ######## N\u00e3o fa\u00e7a esse desafio no google colab, fa\u00e7a em sua m\u00e1quina. In\u00a0[11]: Copied! <pre>%matplotlib inline\nimport cv2\nfrom matplotlib import pyplot as plt\nimport numpy as np\n\n# carrega as imagens\nimg = cv2.imread(\"q11.jpg\")\nimg2 = cv2.imread(\"q22.jpg\")\n\n\n# Exibe as imagens que ser\u00e3o usadas\nplt.figure(figsize = (10,10))\nplt.subplot(1, 2, 1), plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\nplt.subplot(1, 2, 2), plt.imshow(cv2.cvtColor(img2, cv2.COLOR_BGR2RGB))\nplt.show();\n</pre> %matplotlib inline import cv2 from matplotlib import pyplot as plt import numpy as np  # carrega as imagens img = cv2.imread(\"q11.jpg\") img2 = cv2.imread(\"q22.jpg\")   # Exibe as imagens que ser\u00e3o usadas plt.figure(figsize = (10,10)) plt.subplot(1, 2, 1), plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB)) plt.subplot(1, 2, 2), plt.imshow(cv2.cvtColor(img2, cv2.COLOR_BGR2RGB)) plt.show(); In\u00a0[14]: Copied! <pre># Cria o objeto Stitcher\nstitcher = cv2.Stitcher.create()\n\n# Essa \u00e9 a parte mais complicada do c\u00f3digo, \u00e9 aqui que o hard work \u00e9 feito. \n# o m\u00e9todo devolve em status se foi possivel realizar overlap (sopreposi\u00e7\u00e3o) das imagens na variavel status,\n# se sim, a imagem esta panoramica est\u00e1 em result.\n(status, result) = stitcher.stitch((img,img2))\n\nif (status == cv2.STITCHER_OK):\n    print(\"Sucesso, imagem gerada, exiba o result\")\nelse:\n    print(\"falha, n\u00e3o consegui gerar a imagem\")\n</pre> # Cria o objeto Stitcher stitcher = cv2.Stitcher.create()  # Essa \u00e9 a parte mais complicada do c\u00f3digo, \u00e9 aqui que o hard work \u00e9 feito.  # o m\u00e9todo devolve em status se foi possivel realizar overlap (sopreposi\u00e7\u00e3o) das imagens na variavel status, # se sim, a imagem esta panoramica est\u00e1 em result. (status, result) = stitcher.stitch((img,img2))  if (status == cv2.STITCHER_OK):     print(\"Sucesso, imagem gerada, exiba o result\") else:     print(\"falha, n\u00e3o consegui gerar a imagem\") <pre>Sucesso, imagem gerada, exiba o result\n</pre> In\u00a0[15]: Copied! <pre>plt.figure(figsize = (10,10))\nplt.imshow(cv2.cvtColor(result, cv2.COLOR_BGR2RGB)); plt.show();\n</pre> plt.figure(figsize = (10,10)) plt.imshow(cv2.cvtColor(result, cv2.COLOR_BGR2RGB)); plt.show(); <p>Temos um bom resultado, mas as bordas n\u00e3o ficaram boas. Podemos aplicar um crop na imagem. Podemos fazer um crop chutando alguns valores ou podemos tentar fazer esse processo de forma automatica.</p> In\u00a0[16]: Copied! <pre># n\u00e3o \u00e9 a melhor tecnica, mas resolve...\nprint(result.shape)\nh = result.shape[0]\nw = result.shape[1]\nprint(h,w)\ncrop = result[150:2700, 50:3350]\nplt.figure(figsize = (10,10))\nplt.imshow(cv2.cvtColor(crop, cv2.COLOR_BGR2RGB)); plt.show();  \n</pre> # n\u00e3o \u00e9 a melhor tecnica, mas resolve... print(result.shape) h = result.shape[0] w = result.shape[1] print(h,w) crop = result[150:2700, 50:3350] plt.figure(figsize = (10,10)) plt.imshow(cv2.cvtColor(crop, cv2.COLOR_BGR2RGB)); plt.show();   <pre>(2889, 3402, 3)\n2889 3402\n</pre>"},{"location":"aulas/PDI/lab13/Features-old.html#reconhecimento-de-imagem-no-espaco-de-busca","title":"Reconhecimento de imagem no espa\u00e7o de busca\u00b6","text":"<p>Vamos usar a imagem acima para aplicar esse m\u00e9todo.</p> <p>Vamos usar o m\u00e9todo ORB, \u00e9 semelhante ao SIFT, mas n\u00e3o \u00e9 patenteado.</p> <p>https://docs.opencv.org/3.4/db/d95/classcv_1_1ORB.html</p>"},{"location":"aulas/PDI/lab13/Features-old.html#desafio-1","title":"Desafio 1\u00b6","text":"<p>Por default os m\u00e9todos descritores quando s\u00e3o criados est\u00e3o configurados para encontrar 500 features na imagem.</p> <p>Busque na documenta\u00e7\u00e3o da OpenCV como alterar esse par\u00e2metro e descubra quais outros par\u00e2metros podem ser configurados no m\u00e9todo cv2.orb_create()</p> <p>https://docs.opencv.org/3.4/db/d95/classcv_1_1ORB.html</p>"},{"location":"aulas/PDI/lab13/Features-old.html#continuando","title":"Continuando...\u00b6","text":"<p>Agora j\u00e1 possu\u00edmos a \"assinatura\" da nossa caixa de cereais.</p> <p>Vamos realizar a detec\u00e7\u00e3o e descri\u00e7\u00f5es dos keypoints da imagem do espa\u00e7o de busca.</p>"},{"location":"aulas/PDI/lab13/Features-old.html#desafio-2","title":"Desafio 2\u00b6","text":"<p>Fa\u00e7a um c\u00f3digo que calcula os keypoints para a imagem no espa\u00e7o de busca. Compare a caixa de cereal das duas imagens (box e box_in_scene), existe correla\u00e7\u00e3o entre todos os keypoints?</p>"},{"location":"aulas/PDI/lab13/Features-old.html#fazendo-o-match","title":"Fazendo o match...\u00b6","text":"<p>Visualmente podemos ter uma intui\u00e7\u00e3o se existe matching entre os keypoints, mas na vamos usar a fun\u00e7\u00e3o cv2.BFMatcher()</p>"},{"location":"aulas/PDI/lab13/Features-old.html#pausa-para-uma-dica-python","title":"Pausa para uma dica Python\u00b6","text":"<p>ordena\u00e7\u00e3o de vetor e fun\u00e7\u00e3o lambda, veja como \u00e9 simples :)</p>"},{"location":"aulas/PDI/lab13/Features-old.html#voltando-ao-nosso-problema","title":"Voltando ao nosso problema\u00b6","text":""},{"location":"aulas/PDI/lab13/Features-old.html#resultado-de-match","title":"Resultado de match\u00b6","text":"<p>O resultado de matches = bf.match(des1,des2) devolve uma lista de objetos do tipo DMatch. Os atributos s\u00e3o:</p> <ul> <li>DMatch.distance - Distancia entre os descritores da menor para maior dist\u00e2ncia. (Quanto menor melhor)</li> <li>DMatch.trainIdx - Index of the descriptor in train descriptors</li> <li>DMatch.queryIdx - Index of the descriptor in query descriptors</li> <li>DMatch.imgIdx - Index of the train image.</li> </ul>"},{"location":"aulas/PDI/lab13/Features-old.html#desafio-3","title":"Desafio 3\u00b6","text":"<p>Refa\u00e7a este notebook utilizando o m\u00e9todo SIFT.</p> <p>Dicas: No in\u00edcio do c\u00f3digo, basta trocar o orb por sift.</p> <p>Para a fun\u00e7\u00e3o cv2.BFMatcher() use o m\u00e9todo baseado em KNN knnMatch()</p> <p>Encontre por material de ref\u00eancia em projetos de outras pessoas no github.</p>"},{"location":"aulas/PDI/lab13/Features-old.html#desafio-4-para-entregar","title":"Desafio 4 - Para entregar\u00b6","text":"<p>Implemente um c\u00f3digo em python .py que realiza a detec\u00e7\u00e3o em tempo real da webcam. Sugest\u00e3o: como template, escolha um livro, ou algo semelhante.</p> <p>no reposit\u00f3rio deixei como sugest\u00e3o uma imagem e um video que pode ser utilizado como refer\u00eancia se chama <code>admiravelmundonovo</code> jpg e mp4 respectivamente.</p> <p>Para desenhar o contorno quando \u00e9 encontrado match use a fun\u00e7\u00e3o abaixo:</p> <pre>def desenhaContorno(qp,tp,refImg,frame):\n        \"\"\"\n        essa fun\u00e7\u00e3o do tipo void que desenha o contorno quando existe matches das duas imagens\n        \n        recebe:\n         - qp,tp que representa a convers\u00e3o de keypoints em argumentos para o findhomography ref:https://answers.opencv.org/question/122802/how-to-convert-keypoints-to-an-argument-for-findhomography/\n         - refImg = imagem de refer\u00eancia\n         - frame = imagem de destino onde ser\u00e1 desenhado o contorno\n\n    \"\"\"\n        # o findHomography mapeia os pontos de um plano em outro.\n        # ou seja, mapeia os keypoints da imagem ref em frame\n        H,status=cv2.findHomography(qp,tp,cv2.RANSAC,3.0)\n        \n        # extrai o shape da imagem de referencia\n        h,w=refImg.shape\n        # Mapeia os pontos das bordas com base no shape refImg (imagem de referncia), s\u00e3o 4 pontos\n        #  [0,0]        [w-1,0]\n        #\n        # \n        #  [0,h-1]      [w-1,h-1]\n        #\n        refBorda=np.float32([[[0,0],[0,h-1],[w-1,h-1],[w-1,0]]])\n        # Usa refBorda e a matrix de homografia H para calcular a matrix transforma\u00e7\u00e3o de pespectiva\n        frameBorda=cv2.perspectiveTransform(refBorda,H)\n        # polylines desenha poligonos ou qualquer imagem, na cor verde e largura do tra\u00e7o igual a 5.\n        cv2.polylines(frame,[np.int32(frameBorda)],True,(0,255,0),5)\n</pre> <p>Busque por refer\u00eancias externas para resolver o desafio. Bom trabalho.</p>"},{"location":"aulas/PDI/lab13/Features-old.html#imagem-panoramica","title":"Imagem panor\u00e2mica\u00b6","text":"<p>Imagem panor\u00e2mica, para criar a nossa imagem panor\u00e2mica vamos utilizar todos os conceitos que vimos de extra\u00e7\u00e3o e descri\u00e7\u00e3o de features.</p> <p>Vou demonstrar duas t\u00e9cnicas para realizar esse processo.</p> <p>O primeiro utilizando os passos do m\u00e9todo que aprendemos, realizando a extra\u00e7\u00e3o de features com SIFT, destacando as melhores correla\u00e7\u00f5es e realizando a sobreposi\u00e7\u00e3o das imagens. Uma sugest\u00e3o de como realizar este processo est\u00e1 implementado no link do github, os c\u00f3digos est\u00e3o abertos e pode ser explorado.</p> <p>ref. https://github.com/linrl3/Image-Stitching-OpenCV.git</p> <p>O segundo \u00e9 utilizando uma fun\u00e7\u00e3o built-in da openCV para isso, cv2.Stitcher() por debaixo dos panos essa fun\u00e7\u00e3o realiza as mesmas t\u00e9cnicas que estudamos, com a diferen\u00e7a de estar otimizada para uso.</p> <p>ref. https://docs.opencv.org/master/d2/d8d/classcv_1_1Stitcher.html</p>"},{"location":"aulas/PDI/lab13/Features.html","title":"Lab13 - Features","text":"In\u00a0[\u00a0]: Copied! <pre>## Vou fazer o download das imagens do laborat\u00f3rio diretamente do reposit\u00f3rio para ficar mais facil....\n\nimport requests\nimport os\n\n# Define o laborat\u00f3rio\nlaboratorio = 'lab13'  ### altere para o laborat\u00f3rio desejado\ndiretorio = 'lab_images'  ### altere para o diret\u00f3rio que deseja salvar as imagens\n\n# Download de um arquivo\ndef download_file(url, destination):\n    response = requests.get(url, stream=True)\n    if response.status_code == 200:\n        with open(destination, 'wb') as file:\n            for chunk in response.iter_content(chunk_size=8192):\n                file.write(chunk)\n        print(f\"Baixado: {destination}\")\n    else:\n        print(f\"Erro ao baixar {url}\")\n\n# Monta a URL completa\napi_url = \"https://api.github.com/repos/arnaldojr/cognitivecomputing/contents/material/aulas/PDI/\"\nurl_completa = api_url + laboratorio\nprint(f\"Fazendo o download de: {url_completa}\")\n\n# checa se a URL est\u00e1 acess\u00edvel\nresponse = requests.get(url_completa)\nif response.status_code != 200:\n    raise Exception(f\"Erro ao acessar o reposit\u00f3rio: {response.status_code}\")\nfiles = response.json()\n\n\n# Faz o download de cada arquivo\nos.makedirs(diretorio, exist_ok=True) # Cria a pasta downloads\nfor file in files:\n    file_name = file['name']\n    if file_name.endswith(('.png', '.jpg', '.jpeg', '.mp4')):  # Adicione mais extens\u00f5es se necess\u00e1rio\n        file_url = file['download_url']\n        destination = os.path.join(diretorio, file_name)\n        download_file(file_url, destination)\n\nprint(f\"Download conclu\u00eddo. Arquivos salvos na pasta {diretorio}.\")\n</pre> ## Vou fazer o download das imagens do laborat\u00f3rio diretamente do reposit\u00f3rio para ficar mais facil....  import requests import os  # Define o laborat\u00f3rio laboratorio = 'lab13'  ### altere para o laborat\u00f3rio desejado diretorio = 'lab_images'  ### altere para o diret\u00f3rio que deseja salvar as imagens  # Download de um arquivo def download_file(url, destination):     response = requests.get(url, stream=True)     if response.status_code == 200:         with open(destination, 'wb') as file:             for chunk in response.iter_content(chunk_size=8192):                 file.write(chunk)         print(f\"Baixado: {destination}\")     else:         print(f\"Erro ao baixar {url}\")  # Monta a URL completa api_url = \"https://api.github.com/repos/arnaldojr/cognitivecomputing/contents/material/aulas/PDI/\" url_completa = api_url + laboratorio print(f\"Fazendo o download de: {url_completa}\")  # checa se a URL est\u00e1 acess\u00edvel response = requests.get(url_completa) if response.status_code != 200:     raise Exception(f\"Erro ao acessar o reposit\u00f3rio: {response.status_code}\") files = response.json()   # Faz o download de cada arquivo os.makedirs(diretorio, exist_ok=True) # Cria a pasta downloads for file in files:     file_name = file['name']     if file_name.endswith(('.png', '.jpg', '.jpeg', '.mp4')):  # Adicione mais extens\u00f5es se necess\u00e1rio         file_url = file['download_url']         destination = os.path.join(diretorio, file_name)         download_file(file_url, destination)  print(f\"Download conclu\u00eddo. Arquivos salvos na pasta {diretorio}.\") In\u00a0[\u00a0]: Copied! <pre>%matplotlib inline\nimport cv2\nfrom matplotlib import pyplot as plt\nimport numpy as np\n\n# Configura\u00e7\u00f5es para melhor visualiza\u00e7\u00e3o\nplt.rcParams['figure.figsize'] = [12, 8]\nplt.rcParams['font.size'] = 12\n\nimg1 = cv2.imread('box.png', 0)  # Template (objeto de refer\u00eancia)\nimg2 = cv2.imread('box_in_scene.png', 0)  # Imagem de busca\n    \n    \n# Exibir o template\nplt.figure(figsize=(8, 8))\nplt.title(\"Template - Objeto de Refer\u00eancia\")\nplt.imshow(img1, cmap=\"gray\")\nplt.axis('on')\nplt.show()\n\n# Exibir a imagem de busca\nplt.figure(figsize=(12, 10))\nplt.title(\"Imagem de Busca - Cena Completa\")\nplt.imshow(img2, cmap=\"gray\")\nplt.axis('on')\nplt.show()\n</pre> %matplotlib inline import cv2 from matplotlib import pyplot as plt import numpy as np  # Configura\u00e7\u00f5es para melhor visualiza\u00e7\u00e3o plt.rcParams['figure.figsize'] = [12, 8] plt.rcParams['font.size'] = 12  img1 = cv2.imread('box.png', 0)  # Template (objeto de refer\u00eancia) img2 = cv2.imread('box_in_scene.png', 0)  # Imagem de busca           # Exibir o template plt.figure(figsize=(8, 8)) plt.title(\"Template - Objeto de Refer\u00eancia\") plt.imshow(img1, cmap=\"gray\") plt.axis('on') plt.show()  # Exibir a imagem de busca plt.figure(figsize=(12, 10)) plt.title(\"Imagem de Busca - Cena Completa\") plt.imshow(img2, cmap=\"gray\") plt.axis('on') plt.show() <pre></pre> <pre></pre> In\u00a0[7]: Copied! <pre># Inicializar o detector e descritor ORB\n# Por padr\u00e3o, detectar\u00e1 at\u00e9 500 keypoints\norb = cv2.ORB_create()\n\nprint(\"Detector ORB inicializado com sucesso!\")\n</pre> # Inicializar o detector e descritor ORB # Por padr\u00e3o, detectar\u00e1 at\u00e9 500 keypoints orb = cv2.ORB_create()  print(\"Detector ORB inicializado com sucesso!\") <pre></pre> In\u00a0[8]: Copied! <pre># Detectar keypoints e calcular os descritores na imagem template\n\n# Abordagem separada (passo-a-passo):\n# 1. Detectar keypoints\n# kp = orb.detect(img1, None)\n# 2. Calcular descritores\n# kp, des = orb.compute(img1, kp)\n\n# Abordagem combinada (mais eficiente):\nkp1, des1 = orb.detectAndCompute(img1, None)\n\nprint(f\"Foram detectados {len(kp1)} keypoints na imagem template\")\nprint(f\"Formato dos descritores: {des1.shape if des1 is not None else 'Nenhum descritor calculado'}\")\n</pre> # Detectar keypoints e calcular os descritores na imagem template  # Abordagem separada (passo-a-passo): # 1. Detectar keypoints # kp = orb.detect(img1, None) # 2. Calcular descritores # kp, des = orb.compute(img1, kp)  # Abordagem combinada (mais eficiente): kp1, des1 = orb.detectAndCompute(img1, None)  print(f\"Foram detectados {len(kp1)} keypoints na imagem template\") print(f\"Formato dos descritores: {des1.shape if des1 is not None else 'Nenhum descritor calculado'}\") <pre></pre> In\u00a0[9]: Copied! <pre># Visualizar os keypoints detectados (vers\u00e3o simples)\nimg_keypoints = cv2.drawKeypoints(img1, kp1, outImage=None, color=(0,255,0), \n                                 flags=cv2.DrawMatchesFlags_DEFAULT)\n\nplt.figure(figsize=(10, 10))\nplt.title(\"Keypoints detectados na imagem template\")\nplt.imshow(cv2.cvtColor(img_keypoints, cv2.COLOR_BGR2RGB))\nplt.show()\n</pre> # Visualizar os keypoints detectados (vers\u00e3o simples) img_keypoints = cv2.drawKeypoints(img1, kp1, outImage=None, color=(0,255,0),                                   flags=cv2.DrawMatchesFlags_DEFAULT)  plt.figure(figsize=(10, 10)) plt.title(\"Keypoints detectados na imagem template\") plt.imshow(cv2.cvtColor(img_keypoints, cv2.COLOR_BGR2RGB)) plt.show() <pre></pre> In\u00a0[\u00a0]: Copied! <pre># Visualizar os keypoints com informa\u00e7\u00e3o de escala e orienta\u00e7\u00e3o\nimg_keypoints_rich = cv2.drawKeypoints(img1, kp1, outImage=None, \n                                      flags=cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)\n\nplt.figure(figsize=(10, 10))\nplt.title(\"Keypoints com escala e orienta\u00e7\u00e3o\")\nplt.imshow(cv2.cvtColor(img_keypoints_rich, cv2.COLOR_BGR2RGB))\nplt.xlabel(\"As setas indicam a orienta\u00e7\u00e3o do gradiente dominante em cada ponto\")\nplt.show()\n\n# Explica\u00e7\u00e3o dos c\u00edrculos e linhas:\nprint(\"Os c\u00edrculos representam a escala onde o keypoint foi detectado\")\nprint(\"As linhas mostram a orienta\u00e7\u00e3o dominante do gradiente naquele ponto\")\nprint(\"Essas propriedades garantem invari\u00e2ncia \u00e0 escala e rota\u00e7\u00e3o\")\n</pre> # Visualizar os keypoints com informa\u00e7\u00e3o de escala e orienta\u00e7\u00e3o img_keypoints_rich = cv2.drawKeypoints(img1, kp1, outImage=None,                                        flags=cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)  plt.figure(figsize=(10, 10)) plt.title(\"Keypoints com escala e orienta\u00e7\u00e3o\") plt.imshow(cv2.cvtColor(img_keypoints_rich, cv2.COLOR_BGR2RGB)) plt.xlabel(\"As setas indicam a orienta\u00e7\u00e3o do gradiente dominante em cada ponto\") plt.show()  # Explica\u00e7\u00e3o dos c\u00edrculos e linhas: print(\"Os c\u00edrculos representam a escala onde o keypoint foi detectado\") print(\"As linhas mostram a orienta\u00e7\u00e3o dominante do gradiente naquele ponto\") print(\"Essas propriedades garantem invari\u00e2ncia \u00e0 escala e rota\u00e7\u00e3o\") <pre></pre> <pre></pre> In\u00a0[\u00a0]: Copied! <pre># Implemente sua solu\u00e7\u00e3o para o Desafio 1 aqui\n\n# Exemplo de implementa\u00e7\u00e3o com par\u00e2metros customizados\norb_custom = cv2.ORB_create(\n    nfeatures=100,      # N\u00famero m\u00e1ximo de features a serem retidas (padr\u00e3o: 500)\n    scaleFactor=1.2,    # Fator de escala entre n\u00edveis na pir\u00e2mide (padr\u00e3o: 1.2)\n    nlevels=8,          # N\u00famero de n\u00edveis na pir\u00e2mide (padr\u00e3o: 8)\n    edgeThreshold=31,   # Tamanho da borda (padr\u00e3o: 31)\n    firstLevel=0,       # N\u00edvel da pir\u00e2mide onde \u00e9 colocada a imagem de entrada (padr\u00e3o: 0)\n    WTA_K=2,            # N\u00famero de pontos para produzir cada elemento do descritor BRIEF (2 ou 3, padr\u00e3o: 2)\n    scoreType=cv2.ORB_HARRIS_SCORE,  # Tipo de pontua\u00e7\u00e3o (HARRIS_SCORE ou FAST_SCORE)\n    patchSize=31,       # Tamanho do patch usado para orienta\u00e7\u00e3o (padr\u00e3o: 31)\n    fastThreshold=20    # Limiar para o detector de cantos FAST (padr\u00e3o: 20)\n)\n\n# Compare os resultados com diferentes configura\u00e7\u00f5es\n# ...\n</pre> # Implemente sua solu\u00e7\u00e3o para o Desafio 1 aqui  # Exemplo de implementa\u00e7\u00e3o com par\u00e2metros customizados orb_custom = cv2.ORB_create(     nfeatures=100,      # N\u00famero m\u00e1ximo de features a serem retidas (padr\u00e3o: 500)     scaleFactor=1.2,    # Fator de escala entre n\u00edveis na pir\u00e2mide (padr\u00e3o: 1.2)     nlevels=8,          # N\u00famero de n\u00edveis na pir\u00e2mide (padr\u00e3o: 8)     edgeThreshold=31,   # Tamanho da borda (padr\u00e3o: 31)     firstLevel=0,       # N\u00edvel da pir\u00e2mide onde \u00e9 colocada a imagem de entrada (padr\u00e3o: 0)     WTA_K=2,            # N\u00famero de pontos para produzir cada elemento do descritor BRIEF (2 ou 3, padr\u00e3o: 2)     scoreType=cv2.ORB_HARRIS_SCORE,  # Tipo de pontua\u00e7\u00e3o (HARRIS_SCORE ou FAST_SCORE)     patchSize=31,       # Tamanho do patch usado para orienta\u00e7\u00e3o (padr\u00e3o: 31)     fastThreshold=20    # Limiar para o detector de cantos FAST (padr\u00e3o: 20) )  # Compare os resultados com diferentes configura\u00e7\u00f5es # ... In\u00a0[12]: Copied! <pre># Implemente sua solu\u00e7\u00e3o para o Desafio 2 aqui\n\n# Detectar keypoints e calcular descritores na imagem da cena\nkp2, des2 = orb.detectAndCompute(img2, None)\n\nprint(f\"Keypoints na imagem template: {len(kp1)}\")\nprint(f\"Keypoints na imagem da cena: {len(kp2)}\")\n\n# Visualizar os keypoints nas duas imagens\n# ...\n</pre> # Implemente sua solu\u00e7\u00e3o para o Desafio 2 aqui  # Detectar keypoints e calcular descritores na imagem da cena kp2, des2 = orb.detectAndCompute(img2, None)  print(f\"Keypoints na imagem template: {len(kp1)}\") print(f\"Keypoints na imagem da cena: {len(kp2)}\")  # Visualizar os keypoints nas duas imagens # ... <pre></pre> In\u00a0[13]: Copied! <pre>%matplotlib inline\nimport cv2\nfrom matplotlib import pyplot as plt\nimport numpy as np\n\n# Carregar as imagens\nimg1 = cv2.imread('box.png', 0)  # Template (objeto de refer\u00eancia)\nimg2 = cv2.imread('box_in_scene.png', 0)  # Imagem de busca\n\n# Criar detector ORB\norb = cv2.ORB_create(nfeatures=1000)  # Aumentando o n\u00famero de features para melhor visualiza\u00e7\u00e3o\n\n# Calcular keypoints e descritores\nkp1, des1 = orb.detectAndCompute(img1, None)\nkp2, des2 = orb.detectAndCompute(img2, None)\n\nprint(f\"Keypoints na imagem template: {len(kp1)}\")\nprint(f\"Keypoints na imagem da cena: {len(kp2)}\")\n\n# Desenhar keypoints nas imagens\nimg1_keypoints = cv2.drawKeypoints(img1, kp1, outImage=None, color=(0, 255, 0),\n                                  flags=cv2.DrawMatchesFlags_DEFAULT)\nimg2_keypoints = cv2.drawKeypoints(img2, kp2, outImage=None, color=(0, 255, 0),\n                                  flags=cv2.DrawMatchesFlags_DEFAULT)\n\n# Visualizar os resultados\nplt.figure(figsize=(15, 7))\n\nplt.subplot(1, 2, 1)\nplt.title(\"Keypoints no Template\")\nplt.imshow(img1_keypoints)\n\nplt.subplot(1, 2, 2)\nplt.title(\"Keypoints na Cena\")\nplt.imshow(img2_keypoints)\n\nplt.tight_layout()\nplt.show()\n</pre> %matplotlib inline import cv2 from matplotlib import pyplot as plt import numpy as np  # Carregar as imagens img1 = cv2.imread('box.png', 0)  # Template (objeto de refer\u00eancia) img2 = cv2.imread('box_in_scene.png', 0)  # Imagem de busca  # Criar detector ORB orb = cv2.ORB_create(nfeatures=1000)  # Aumentando o n\u00famero de features para melhor visualiza\u00e7\u00e3o  # Calcular keypoints e descritores kp1, des1 = orb.detectAndCompute(img1, None) kp2, des2 = orb.detectAndCompute(img2, None)  print(f\"Keypoints na imagem template: {len(kp1)}\") print(f\"Keypoints na imagem da cena: {len(kp2)}\")  # Desenhar keypoints nas imagens img1_keypoints = cv2.drawKeypoints(img1, kp1, outImage=None, color=(0, 255, 0),                                   flags=cv2.DrawMatchesFlags_DEFAULT) img2_keypoints = cv2.drawKeypoints(img2, kp2, outImage=None, color=(0, 255, 0),                                   flags=cv2.DrawMatchesFlags_DEFAULT)  # Visualizar os resultados plt.figure(figsize=(15, 7))  plt.subplot(1, 2, 1) plt.title(\"Keypoints no Template\") plt.imshow(img1_keypoints)  plt.subplot(1, 2, 2) plt.title(\"Keypoints na Cena\") plt.imshow(img2_keypoints)  plt.tight_layout() plt.show() <pre></pre> <pre></pre> In\u00a0[14]: Copied! <pre># Criar o objeto BFMatcher (Brute-Force Matcher)\n# NORM_HAMMING \u00e9 usado para descritores bin\u00e1rios como ORB\n# crossCheck=True garante que as correspond\u00eancias sejam mutuamente melhores\nbf = cv2.BFMatcher(cv2.NORM_HAMMING, crossCheck=True)\n\n# Encontrar correspond\u00eancias entre os descritores\nmatches = bf.match(des1, des2)\n\nprint(f\"Foram encontradas {len(matches)} correspond\u00eancias entre as imagens\")\n\n# Desenhar todas as correspond\u00eancias\nimg_matches = cv2.drawMatches(img1, kp1, img2, kp2, matches, None, \n                             flags=cv2.DrawMatchesFlags_NOT_DRAW_SINGLE_POINTS)\n\nplt.figure(figsize=(20, 10))\nplt.title('Todas as correspond\u00eancias encontradas')\nplt.imshow(img_matches)\nplt.show()\n</pre> # Criar o objeto BFMatcher (Brute-Force Matcher) # NORM_HAMMING \u00e9 usado para descritores bin\u00e1rios como ORB # crossCheck=True garante que as correspond\u00eancias sejam mutuamente melhores bf = cv2.BFMatcher(cv2.NORM_HAMMING, crossCheck=True)  # Encontrar correspond\u00eancias entre os descritores matches = bf.match(des1, des2)  print(f\"Foram encontradas {len(matches)} correspond\u00eancias entre as imagens\")  # Desenhar todas as correspond\u00eancias img_matches = cv2.drawMatches(img1, kp1, img2, kp2, matches, None,                               flags=cv2.DrawMatchesFlags_NOT_DRAW_SINGLE_POINTS)  plt.figure(figsize=(20, 10)) plt.title('Todas as correspond\u00eancias encontradas') plt.imshow(img_matches) plt.show() <pre></pre> <pre></pre> In\u00a0[\u00a0]: Copied! <pre># Exemplo: ordena\u00e7\u00e3o em Python com sorted() e fun\u00e7\u00f5es lambda\n\n# Lista de compras: (item, pre\u00e7o)\nlista = [\n    ('Banana', 18),\n    ('Ma\u00e7\u00e3', 1),\n    ('Goiaba', 20),\n    ('Uva', 22),\n    ('Pera', 12)\n]\n\nprint(\"Lista n\u00e3o ordenada:\", lista)\n\n# Ordenar por ordem alfab\u00e9tica (primeiro elemento da tupla)\nlista_ord = sorted(lista)\nprint(\"\\nLista ordenada por nome (ordem alfab\u00e9tica):\", lista_ord)\n\n# Ordenar por pre\u00e7o (segundo elemento da tupla)\nlista_ord_preco = sorted(lista, key=lambda x: x[1])\nprint(\"\\nLista ordenada por pre\u00e7o (crescente):\", lista_ord_preco)\n\n# Ordenar por pre\u00e7o decrescente\nlista_ord_preco_desc = sorted(lista, key=lambda x: x[1], reverse=True)\nprint(\"\\nLista ordenada por pre\u00e7o (decrescente):\", lista_ord_preco_desc)\n</pre> # Exemplo: ordena\u00e7\u00e3o em Python com sorted() e fun\u00e7\u00f5es lambda  # Lista de compras: (item, pre\u00e7o) lista = [     ('Banana', 18),     ('Ma\u00e7\u00e3', 1),     ('Goiaba', 20),     ('Uva', 22),     ('Pera', 12) ]  print(\"Lista n\u00e3o ordenada:\", lista)  # Ordenar por ordem alfab\u00e9tica (primeiro elemento da tupla) lista_ord = sorted(lista) print(\"\\nLista ordenada por nome (ordem alfab\u00e9tica):\", lista_ord)  # Ordenar por pre\u00e7o (segundo elemento da tupla) lista_ord_preco = sorted(lista, key=lambda x: x[1]) print(\"\\nLista ordenada por pre\u00e7o (crescente):\", lista_ord_preco)  # Ordenar por pre\u00e7o decrescente lista_ord_preco_desc = sorted(lista, key=lambda x: x[1], reverse=True) print(\"\\nLista ordenada por pre\u00e7o (decrescente):\", lista_ord_preco_desc) <pre></pre> In\u00a0[\u00a0]: Copied! <pre>help(cv2.DMatch)\n</pre> help(cv2.DMatch) <pre></pre> In\u00a0[\u00a0]: Copied! <pre># Ordenar as correspond\u00eancias por dist\u00e2ncia (menor para maior)\nmatches = sorted(matches, key=lambda x: x.distance)\n\n# Ver as dist\u00e2ncias das 10 melhores correspond\u00eancias\nprint(\"Dist\u00e2ncias das 10 melhores correspond\u00eancias:\")\nfor i, match in enumerate(matches[:10]):\n    print(f\"Match {i+1}: {match.distance:.2f}\")\n</pre> # Ordenar as correspond\u00eancias por dist\u00e2ncia (menor para maior) matches = sorted(matches, key=lambda x: x.distance)  # Ver as dist\u00e2ncias das 10 melhores correspond\u00eancias print(\"Dist\u00e2ncias das 10 melhores correspond\u00eancias:\") for i, match in enumerate(matches[:10]):     print(f\"Match {i+1}: {match.distance:.2f}\") <pre></pre> In\u00a0[\u00a0]: Copied! <pre># Desenhar apenas as 15 melhores correspond\u00eancias\nnum_best_matches = 15\nimg_best_matches = cv2.drawMatches(img1, kp1, img2, kp2, matches[:num_best_matches], None, \n                                  flags=cv2.DrawMatchesFlags_NOT_DRAW_SINGLE_POINTS)\n\nplt.figure(figsize=(20, 10))\nplt.title(f'As {num_best_matches} melhores correspond\u00eancias')\nplt.imshow(img_best_matches)\nplt.show()\n</pre> # Desenhar apenas as 15 melhores correspond\u00eancias num_best_matches = 15 img_best_matches = cv2.drawMatches(img1, kp1, img2, kp2, matches[:num_best_matches], None,                                    flags=cv2.DrawMatchesFlags_NOT_DRAW_SINGLE_POINTS)  plt.figure(figsize=(20, 10)) plt.title(f'As {num_best_matches} melhores correspond\u00eancias') plt.imshow(img_best_matches) plt.show() <pre></pre> In\u00a0[\u00a0]: Copied! <pre># Implemente sua solu\u00e7\u00e3o para o Desafio 3 aqui\n\n# Exemplo de implementa\u00e7\u00e3o com SIFT\nimport cv2\nimport numpy as np\nfrom matplotlib import pyplot as plt\n\n# Carregar as imagens\nimg1 = cv2.imread('box.png', 0)  # Template\nimg2 = cv2.imread('box_in_scene.png', 0)  # Cena\n\n# Inicializar SIFT\nsift = cv2.SIFT_create()\n\n# Detectar keypoints e descritores\nkp1, des1 = sift.detectAndCompute(img1, None)\nkp2, des2 = sift.detectAndCompute(img2, None)\n\n# Criar o BFMatcher - NORM_L2 para descritores baseados em gradiente como SIFT\nbf = cv2.BFMatcher(cv2.NORM_L2, crossCheck=False)\n\n# Encontrar os 2 melhores matches para cada descritor\nmatches = bf.knnMatch(des1, des2, k=2)\n\n# Aplicar o teste de ratio de Lowe\ngood_matches = []\nfor m, n in matches:\n    if m.distance &lt; 0.75 * n.distance:\n        good_matches.append(m)\n\nprint(f\"Foram encontrados {len(good_matches)} bons matches ap\u00f3s filtro de ratio\")\n\n# Desenhar os matches\nimg_matches = cv2.drawMatches(img1, kp1, img2, kp2, good_matches, None, \n                             flags=cv2.DrawMatchesFlags_NOT_DRAW_SINGLE_POINTS)\n\nplt.figure(figsize=(20, 10))\nplt.title('SIFT: Matches ap\u00f3s filtro de ratio de Lowe')\nplt.imshow(img_matches)\nplt.show()\n</pre> # Implemente sua solu\u00e7\u00e3o para o Desafio 3 aqui  # Exemplo de implementa\u00e7\u00e3o com SIFT import cv2 import numpy as np from matplotlib import pyplot as plt  # Carregar as imagens img1 = cv2.imread('box.png', 0)  # Template img2 = cv2.imread('box_in_scene.png', 0)  # Cena  # Inicializar SIFT sift = cv2.SIFT_create()  # Detectar keypoints e descritores kp1, des1 = sift.detectAndCompute(img1, None) kp2, des2 = sift.detectAndCompute(img2, None)  # Criar o BFMatcher - NORM_L2 para descritores baseados em gradiente como SIFT bf = cv2.BFMatcher(cv2.NORM_L2, crossCheck=False)  # Encontrar os 2 melhores matches para cada descritor matches = bf.knnMatch(des1, des2, k=2)  # Aplicar o teste de ratio de Lowe good_matches = [] for m, n in matches:     if m.distance &lt; 0.75 * n.distance:         good_matches.append(m)  print(f\"Foram encontrados {len(good_matches)} bons matches ap\u00f3s filtro de ratio\")  # Desenhar os matches img_matches = cv2.drawMatches(img1, kp1, img2, kp2, good_matches, None,                               flags=cv2.DrawMatchesFlags_NOT_DRAW_SINGLE_POINTS)  plt.figure(figsize=(20, 10)) plt.title('SIFT: Matches ap\u00f3s filtro de ratio de Lowe') plt.imshow(img_matches) plt.show() <pre></pre> <pre></pre> In\u00a0[\u00a0]: Copied! <pre># ATEN\u00c7\u00c3O: Este desafio deve ser executado em sua m\u00e1quina local\n# N\u00e3o execute este c\u00f3digo no navegador ou no Google Colab\n</pre> # ATEN\u00c7\u00c3O: Este desafio deve ser executado em sua m\u00e1quina local # N\u00e3o execute este c\u00f3digo no navegador ou no Google Colab    <pre></pre> In\u00a0[\u00a0]: Copied! <pre>%matplotlib inline\nimport cv2\nfrom matplotlib import pyplot as plt\nimport numpy as np\n\n\nimg1 = cv2.imread(\"q11.jpg\")\nimg2 = cv2.imread(\"q22.jpg\")\n    \n# Exibir as imagens que ser\u00e3o combinadas\nplt.figure(figsize=(15, 8))\nplt.subplot(1, 2, 1)\nplt.title(\"Imagem 1\")\nplt.imshow(cv2.cvtColor(img1, cv2.COLOR_BGR2RGB))\n\n\nplt.subplot(1, 2, 2)\nplt.title(\"Imagem 2\")\nplt.imshow(cv2.cvtColor(img2, cv2.COLOR_BGR2RGB))\n\nplt.tight_layout()\nplt.show()\n</pre> %matplotlib inline import cv2 from matplotlib import pyplot as plt import numpy as np   img1 = cv2.imread(\"q11.jpg\") img2 = cv2.imread(\"q22.jpg\")      # Exibir as imagens que ser\u00e3o combinadas plt.figure(figsize=(15, 8)) plt.subplot(1, 2, 1) plt.title(\"Imagem 1\") plt.imshow(cv2.cvtColor(img1, cv2.COLOR_BGR2RGB))   plt.subplot(1, 2, 2) plt.title(\"Imagem 2\") plt.imshow(cv2.cvtColor(img2, cv2.COLOR_BGR2RGB))  plt.tight_layout() plt.show() <pre></pre> In\u00a0[\u00a0]: Copied! <pre># Criar o objeto Stitcher\n# Modos dispon\u00edveis: PANORAMA (padr\u00e3o) ou SCANS\nstitcher = cv2.Stitcher.create(mode=cv2.Stitcher_PANORAMA)\n\n# Realizar o stitching\n# status: c\u00f3digo de erro/sucesso\n# result: imagem panor\u00e2mica resultante\n(status, result) = stitcher.stitch((img1, img2))\n\n# Verificar o resultado\nif status == cv2.Stitcher_OK:\n    print(\"\u2705 Sucesso! Panorama criado com sucesso.\")\n    print(f\"Dimens\u00f5es da imagem resultante: {result.shape}\")\nelse:\n    print(\"\u274c Falha ao criar panorama.\")\n    print(f\"Status: {status}\")\n    # C\u00f3digos de erro poss\u00edveis:\n    # cv2.Stitcher_ERR_NEED_MORE_IMGS (1): Precisa de mais imagens\n    # cv2.Stitcher_ERR_HOMOGRAPHY_EST_FAIL (2): Falha na estimativa de homografia\n    # cv2.Stitcher_ERR_CAMERA_PARAMS_ADJUST_FAIL (3): Falha no ajuste de par\u00e2metros da c\u00e2mera\n</pre> # Criar o objeto Stitcher # Modos dispon\u00edveis: PANORAMA (padr\u00e3o) ou SCANS stitcher = cv2.Stitcher.create(mode=cv2.Stitcher_PANORAMA)  # Realizar o stitching # status: c\u00f3digo de erro/sucesso # result: imagem panor\u00e2mica resultante (status, result) = stitcher.stitch((img1, img2))  # Verificar o resultado if status == cv2.Stitcher_OK:     print(\"\u2705 Sucesso! Panorama criado com sucesso.\")     print(f\"Dimens\u00f5es da imagem resultante: {result.shape}\") else:     print(\"\u274c Falha ao criar panorama.\")     print(f\"Status: {status}\")     # C\u00f3digos de erro poss\u00edveis:     # cv2.Stitcher_ERR_NEED_MORE_IMGS (1): Precisa de mais imagens     # cv2.Stitcher_ERR_HOMOGRAPHY_EST_FAIL (2): Falha na estimativa de homografia     # cv2.Stitcher_ERR_CAMERA_PARAMS_ADJUST_FAIL (3): Falha no ajuste de par\u00e2metros da c\u00e2mera <pre></pre> In\u00a0[\u00a0]: Copied! <pre># Exibir o resultado\nif status == cv2.Stitcher_OK:\n    plt.figure(figsize=(15, 10))\n    plt.title(\"Panorama resultante\")\n    plt.imshow(cv2.cvtColor(result, cv2.COLOR_BGR2RGB))\n    plt.axis('off')\n    plt.show()\n</pre> # Exibir o resultado if status == cv2.Stitcher_OK:     plt.figure(figsize=(15, 10))     plt.title(\"Panorama resultante\")     plt.imshow(cv2.cvtColor(result, cv2.COLOR_BGR2RGB))     plt.axis('off')     plt.show() <pre></pre> In\u00a0[\u00a0]: Copied! <pre># Recortando as bordas da imagem panor\u00e2mica\nif status == cv2.Stitcher_OK:\n    # Obter dimens\u00f5es da imagem\n    h, w = result.shape[:2]\n    print(f\"Dimens\u00f5es originais: {h} x {w}\")\n    \n    # M\u00e9todo simples: recorte manual\n    # Ajuste estes valores conforme necess\u00e1rio para sua imagem espec\u00edfica\n    margin_top = int(h * 0.05)      # 5% de margem superior\n    margin_bottom = int(h * 0.15)   # 15% de margem inferior\n    margin_left = int(w * 0.01)     # 1% de margem esquerda\n    margin_right = int(w * 0.01)    # 1% de margem direita\n    \n    crop = result[margin_top:h-margin_bottom, \n                  margin_left:w-margin_right]\n    \n    print(f\"Dimens\u00f5es ap\u00f3s recorte: {crop.shape[0]} x {crop.shape[1]}\")\n    \n    plt.figure(figsize=(15, 10))\n    plt.title(\"Panorama recortado\")\n    plt.imshow(cv2.cvtColor(crop, cv2.COLOR_BGR2RGB))\n    plt.axis('off')\n    plt.show()\n    \n    # Alternativa: Para um recorte mais preciso, voc\u00ea poderia:\n    # 1. Converter para escala de cinza\n    # 2. Binarizar a imagem para encontrar a regi\u00e3o n\u00e3o-preta\n    # 3. Encontrar o ret\u00e2ngulo de recorte otimizado\n    # Este \u00e9 um exerc\u00edcio adicional que voc\u00ea pode implementar!\n</pre> # Recortando as bordas da imagem panor\u00e2mica if status == cv2.Stitcher_OK:     # Obter dimens\u00f5es da imagem     h, w = result.shape[:2]     print(f\"Dimens\u00f5es originais: {h} x {w}\")          # M\u00e9todo simples: recorte manual     # Ajuste estes valores conforme necess\u00e1rio para sua imagem espec\u00edfica     margin_top = int(h * 0.05)      # 5% de margem superior     margin_bottom = int(h * 0.15)   # 15% de margem inferior     margin_left = int(w * 0.01)     # 1% de margem esquerda     margin_right = int(w * 0.01)    # 1% de margem direita          crop = result[margin_top:h-margin_bottom,                    margin_left:w-margin_right]          print(f\"Dimens\u00f5es ap\u00f3s recorte: {crop.shape[0]} x {crop.shape[1]}\")          plt.figure(figsize=(15, 10))     plt.title(\"Panorama recortado\")     plt.imshow(cv2.cvtColor(crop, cv2.COLOR_BGR2RGB))     plt.axis('off')     plt.show()          # Alternativa: Para um recorte mais preciso, voc\u00ea poderia:     # 1. Converter para escala de cinza     # 2. Binarizar a imagem para encontrar a regi\u00e3o n\u00e3o-preta     # 3. Encontrar o ret\u00e2ngulo de recorte otimizado     # Este \u00e9 um exerc\u00edcio adicional que voc\u00ea pode implementar! <pre></pre> <pre></pre>"},{"location":"aulas/PDI/lab13/Features.html#features-e-descritores-em-visao-computacional","title":"Features e Descritores em Vis\u00e3o Computacional\u00b6","text":""},{"location":"aulas/PDI/lab13/Features.html#objetivos-da-aula","title":"Objetivos da aula:\u00b6","text":"<ul> <li>Compreender o conceito de FEATURES (caracter\u00edsticas) em imagens</li> <li>Aplicar algoritmos de detec\u00e7\u00e3o de pontos-chave (keypoints)</li> <li>Utilizar DESCRITORES para reconhecimento de objetos</li> <li>Implementar matching de imagens com invari\u00e2ncia a escala e rota\u00e7\u00e3o</li> </ul>"},{"location":"aulas/PDI/lab13/Features.html#contextualizacao-do-problema","title":"Contextualiza\u00e7\u00e3o do Problema\u00b6","text":"<p>Em aulas anteriores, exploramos v\u00e1rias t\u00e9cnicas de processamento de imagens, incluindo o template matching. Embora essa t\u00e9cnica seja eficaz para encontrar padr\u00f5es exatos em imagens, ela apresenta limita\u00e7\u00f5es significativas:</p> <ul> <li>Sensibilidade a mudan\u00e7as de escala</li> <li>Problemas com rota\u00e7\u00e3o do objeto</li> <li>Vulnerabilidade a varia\u00e7\u00f5es de ilumina\u00e7\u00e3o</li> <li>Dificuldade com oclus\u00f5es parciais</li> </ul> <p>Para superar essas limita\u00e7\u00f5es, vamos explorar t\u00e9cnicas baseadas em features locais, que s\u00e3o mais robustas a estas transforma\u00e7\u00f5es.</p>"},{"location":"aulas/PDI/lab13/Features.html#o-desafio-detectar-um-objeto-em-uma-cena","title":"O Desafio: Detectar um Objeto em uma Cena\u00b6","text":"<p>Queremos localizar esta caixa espec\u00edfica:</p> <p></p> <p>Dentro desta cena mais complexa:  Observe que a caixa aparece em uma posi\u00e7\u00e3o diferente, com rota\u00e7\u00e3o e escala alteradas, al\u00e9m de estar parcialmente obstru\u00edda.</p>"},{"location":"aulas/PDI/lab13/Features.html#reflexao-inicial","title":"Reflex\u00e3o Inicial\u00b6","text":"<p>\ud83e\udd14 Pense: Com as t\u00e9cnicas que j\u00e1 conhecemos (como template matching, detec\u00e7\u00e3o de contornos ou segmenta\u00e7\u00e3o por cor), seria poss\u00edvel resolver este problema de forma robusta?</p> <ul> <li>Quais seriam as limita\u00e7\u00f5es?</li> <li>Como poder\u00edamos detectar o objeto mesmo quando ele est\u00e1 rotacionado?</li> <li>Como lidar com diferentes escalas?</li> </ul>"},{"location":"aulas/PDI/lab13/Features.html#introducao-as-features-em-visao-computacional","title":"Introdu\u00e7\u00e3o \u00e0s Features em Vis\u00e3o Computacional\u00b6","text":""},{"location":"aulas/PDI/lab13/Features.html#o-que-sao-features","title":"O que s\u00e3o Features?\u00b6","text":"<p>Features (caracter\u00edsticas) s\u00e3o pontos ou regi\u00f5es de interesse em uma imagem que possuem propriedades distintivas, podendo ser identificadas de forma consistente mesmo sob diferentes transforma\u00e7\u00f5es.Podem ser:</p> <ul> <li>Pontos (como cantos ou jun\u00e7\u00f5es)</li> <li>Bordas (mudan\u00e7as abruptas de intensidade)</li> <li>Blobs (regi\u00f5es com propriedades aproximadamente constantes)</li> <li>Regi\u00f5es (\u00e1reas com textura espec\u00edfica)</li> </ul>"},{"location":"aulas/PDI/lab13/Features.html#features-ideais-devem-ser","title":"Features Ideais devem ser:\u00b6","text":"<ul> <li>Repet\u00edveis: Detect\u00e1veis mesmo com mudan\u00e7as de ilumina\u00e7\u00e3o, ru\u00eddo, etc.</li> <li>Distintivas: Facilmente diferenci\u00e1veis de outras features</li> <li>Locais: Ocupando uma pequena \u00e1rea da imagem</li> <li>Numerosas: Em quantidade suficiente para representar o objeto</li> <li>Precisas: Localiz\u00e1veis com exatid\u00e3o</li> <li>Eficientes: R\u00e1pidas de computar</li> </ul>"},{"location":"aulas/PDI/lab13/Features.html#principais-algoritmos-de-deteccao-e-descricao-de-features","title":"Principais Algoritmos de Detec\u00e7\u00e3o e Descri\u00e7\u00e3o de Features:\u00b6","text":"<ol> <li>SIFT (Scale-Invariant Feature Transform) - Robusto mas computacionalmente intensivo</li> <li>SURF (Speeded-Up Robust Features) - Mais r\u00e1pido que SIFT, tamb\u00e9m patenteado</li> <li>ORB (Oriented FAST and Rotated BRIEF) - C\u00f3digo aberto, mais r\u00e1pido</li> <li>FAST (Features from Accelerated Segment Test) - Detector r\u00e1pido, sem descritor</li> <li>BRISK (Binary Robust Invariant Scalable Keypoints) - Alternativa bin\u00e1ria</li> </ol>"},{"location":"aulas/PDI/lab13/Features.html#aplicacoes","title":"Aplica\u00e7\u00f5es:\u00b6","text":"<ul> <li>Reconhecimento de objetos</li> <li>Stitching de imagens (panoramas)</li> <li>Reconstru\u00e7\u00e3o 3D</li> <li>Rastreamento de objetos (tracking)</li> <li>Realidade aumentada</li> <li>Indexa\u00e7\u00e3o e recupera\u00e7\u00e3o de imagens</li> </ul>"},{"location":"aulas/PDI/lab13/Features.html#deteccao-de-features-com-orb","title":"Detec\u00e7\u00e3o de Features com ORB\u00b6","text":"<p>Vamos usar o algoritmo ORB (Oriented FAST and Rotated BRIEF), que \u00e9 uma excelente alternativa aos algoritmos patenteados como SIFT e SURF. O ORB foi desenvolvido pela OpenCV Labs e combina:</p> <ul> <li>O detector FAST modificado para detec\u00e7\u00e3o de keypoints</li> <li>O descritor BRIEF modificado para descri\u00e7\u00e3o de features</li> <li>Adi\u00e7\u00e3o de orienta\u00e7\u00e3o para garantir invari\u00e2ncia \u00e0 rota\u00e7\u00e3o</li> </ul> <p>Documenta\u00e7\u00e3o: OpenCV ORB</p>"},{"location":"aulas/PDI/lab13/Features.html#o-que-sao-descritores","title":"O que s\u00e3o Descritores?\u00b6","text":"<p>Um descritor \u00e9 uma \"assinatura\" matem\u00e1tica que codifica a informa\u00e7\u00e3o ao redor de uma feature detectada. \u00c9 tipicamente um vetor num\u00e9rico que caracteriza:</p> <ul> <li>O padr\u00e3o de intensidade ao redor do ponto</li> <li>A distribui\u00e7\u00e3o de gradientes na vizinhan\u00e7a</li> <li>Outros atributos que permitem a correspond\u00eancia entre features em diferentes imagens</li> </ul>"},{"location":"aulas/PDI/lab13/Features.html#desafio-1-explorando-parametros-do-orb","title":"\ud83d\udd0d Desafio 1: Explorando Par\u00e2metros do ORB\u00b6","text":"<p>Por padr\u00e3o, o detector ORB \u00e9 configurado para encontrar 500 features na imagem.</p>"},{"location":"aulas/PDI/lab13/Features.html#sua-missao","title":"Sua miss\u00e3o:\u00b6","text":"<ol> <li>Consulte a documenta\u00e7\u00e3o do ORB</li> <li>Descubra como alterar o n\u00famero m\u00e1ximo de features detectadas</li> <li>Identifique outros par\u00e2metros importantes do ORB</li> <li>Implemente um exemplo que use par\u00e2metros personalizados</li> <li>Compare o resultado com a implementa\u00e7\u00e3o padr\u00e3o</li> </ol> <p>Dica: Alguns par\u00e2metros importantes incluem <code>nfeatures</code>, <code>scaleFactor</code>, <code>nlevels</code> e <code>edgeThreshold</code>.</p>"},{"location":"aulas/PDI/lab13/Features.html#exemplo-de-resultado-com-poucas-features","title":"Exemplo de resultado com poucas features\u00b6","text":"<p>Com apenas 4 features detectadas, \u00e9 poss\u00edvel visualizar melhor cada keypoint, sua escala e orienta\u00e7\u00e3o:</p> <p></p> <p>Cada c\u00edrculo representa um keypoint, com:</p> <ul> <li>O raio do c\u00edrculo indicando a escala</li> <li>A linha dentro do c\u00edrculo representando a orienta\u00e7\u00e3o</li> </ul>"},{"location":"aulas/PDI/lab13/Features.html#detectando-o-objeto-na-cena","title":"Detectando o Objeto na Cena\u00b6","text":"<p>Agora que j\u00e1 extra\u00edmos os keypoints e descritores da imagem de refer\u00eancia (template), precisamos:</p> <ol> <li>Detectar keypoints e calcular descritores na imagem da cena</li> <li>Encontrar correspond\u00eancias (matches) entre os descritores das duas imagens</li> <li>Filtrar as melhores correspond\u00eancias</li> <li>Determinar a localiza\u00e7\u00e3o do objeto</li> </ol>"},{"location":"aulas/PDI/lab13/Features.html#desafio-2-comparando-keypoints","title":"\ud83d\udd0d Desafio 2: Comparando Keypoints\u00b6","text":""},{"location":"aulas/PDI/lab13/Features.html#sua-missao","title":"Sua miss\u00e3o:\u00b6","text":"<ol> <li>Calcule os keypoints e descritores para a imagem da cena (box_in_scene.png)</li> <li>Visualize os keypoints detectados nas duas imagens</li> <li>Compare os resultados e analise:<ul> <li>Quantos keypoints foram detectados em cada imagem?</li> <li>Existe alguma regi\u00e3o com maior concentra\u00e7\u00e3o de keypoints?</li> <li>Voc\u00ea consegue identificar visualmente pontos correspondentes entre as duas imagens?</li> </ul> </li> </ol> <p>Dica: Use a mesma configura\u00e7\u00e3o do ORB para ambas as imagens para uma compara\u00e7\u00e3o justa.</p>"},{"location":"aulas/PDI/lab13/Features.html#matching-de-features-encontrando-correspondencias","title":"Matching de Features: Encontrando Correspond\u00eancias\u00b6","text":"<p>Agora que detectamos keypoints em ambas as imagens, precisamos encontrar quais pontos da imagem de refer\u00eancia correspondem aos pontos da imagem de busca.</p>"},{"location":"aulas/PDI/lab13/Features.html#algoritmos-de-matching","title":"Algoritmos de Matching:\u00b6","text":"<ol> <li><p>Brute-Force Matcher: Compara cada descritor da primeira imagem com todos os descritores da segunda imagem.</p> </li> <li><p>FLANN (Fast Library for Approximate Nearest Neighbors): Mais r\u00e1pido para grandes conjuntos de dados.</p> </li> </ol> <p>Vamos usar o Brute-Force Matcher que \u00e9 mais simples e adequado para nosso exemplo:</p>"},{"location":"aulas/PDI/lab13/Features.html#filtragem-de-correspondencias","title":"Filtragem de Correspond\u00eancias\u00b6","text":"<p>Como podemos observar, nem todas as correspond\u00eancias encontradas s\u00e3o corretas. Muitas s\u00e3o falsos positivos. Podemos melhorar o resultado ordenando as correspond\u00eancias por qualidade e selecionando apenas as melhores.</p>"},{"location":"aulas/PDI/lab13/Features.html#como-filtrar","title":"Como filtrar?\u00b6","text":"<p>A qualidade de uma correspond\u00eancia \u00e9 determinada pelo atributo <code>distance</code> do objeto <code>DMatch</code>. Quanto menor a dist\u00e2ncia, melhor \u00e9 a correspond\u00eancia.</p> <p>Vamos ordenar as correspond\u00eancias por dist\u00e2ncia e ficar apenas com as melhores:</p>"},{"location":"aulas/PDI/lab13/Features.html#sobre-ordenacao-em-python-com-sorted-e-funcoes-lambda","title":"Sobre ordena\u00e7\u00e3o em Python com <code>sorted()</code> e fun\u00e7\u00f5es lambda\u00b6","text":"<p>Em Python, podemos usar a fun\u00e7\u00e3o <code>sorted()</code> para ordenar uma lista. Quando queremos ordenar por um crit\u00e9rio espec\u00edfico, usamos a fun\u00e7\u00e3o <code>lambda</code> como uma fun\u00e7\u00e3o de chave:</p>"},{"location":"aulas/PDI/lab13/Features.html#aplicando-filtragem-as-correspondencias","title":"Aplicando Filtragem \u00e0s Correspond\u00eancias\u00b6","text":"<p>Agora vamos ordenar as correspond\u00eancias (matches) encontradas pelo atributo <code>distance</code> e selecionar apenas as melhores para visualiza\u00e7\u00e3o:</p>"},{"location":"aulas/PDI/lab13/Features.html#propriedades-do-objeto-dmatch","title":"Propriedades do objeto DMatch:\u00b6","text":"<ul> <li>DMatch.distance: Dist\u00e2ncia entre os descritores (menor = melhor)</li> <li>DMatch.queryIdx: \u00cdndice do keypoint na imagem de consulta (template)</li> <li>DMatch.trainIdx: \u00cdndice do keypoint na imagem de teste (cena)</li> <li>DMatch.imgIdx: \u00cdndice da imagem de teste (\u00fatil em casos com m\u00faltiplas imagens)</li> </ul> <p>https://docs.opencv.org/4.9.0/d4/de0/classcv_1_1DMatch.html</p>"},{"location":"aulas/PDI/lab13/Features.html#desafio-3-implementando-sift","title":"\ud83d\udd0d Desafio 3: Implementando SIFT\u00b6","text":"<p>SIFT (Scale-Invariant Feature Transform) \u00e9 um dos algoritmos mais robustos para detec\u00e7\u00e3o e descri\u00e7\u00e3o de features. Vamos implementar o mesmo exemplo usando SIFT em vez de ORB.</p>"},{"location":"aulas/PDI/lab13/Features.html#sua-missao","title":"Sua miss\u00e3o:\u00b6","text":"<ol> <li>Modifique o c\u00f3digo para usar o algoritmo SIFT</li> <li>Para matching, use o m\u00e9todo <code>knnMatch()</code> do BFMatcher que permite encontrar os k vizinhos mais pr\u00f3ximos</li> <li>Implemente a filtragem de correspond\u00eancias usando o teste de ratio de Lowe<ul> <li>Este teste compara a dist\u00e2ncia do melhor match com o segundo melhor</li> <li>Se ratio = d1/d2 &lt; 0.75, ent\u00e3o \u00e9 um bom match</li> </ul> </li> </ol> <p>Dica: Use <code>cv2.SIFT_create()</code> para criar o detector e descritor SIFT. Para o BFMatcher, use <code>cv2.NORM_L2</code> em vez de <code>cv2.NORM_HAMMING</code>.</p>"},{"location":"aulas/PDI/lab13/Features.html#desafio-4-deteccao-em-tempo-real","title":"\ud83d\udd0d Desafio 4: Detec\u00e7\u00e3o em Tempo Real\u00b6","text":"<p>IMPORTANTE: Este desafio deve ser executado localmente em sua m\u00e1quina, n\u00e3o no Google Colab.</p>"},{"location":"aulas/PDI/lab13/Features.html#sua-missao","title":"Sua miss\u00e3o:\u00b6","text":"<ol> <li>Crie um script Python (.py) que capture v\u00eddeo da webcam</li> <li>Implemente a detec\u00e7\u00e3o de um objeto em tempo real usando t\u00e9cnicas de feature matching</li> <li>Desenhe um contorno ao redor do objeto quando for encontrado</li> </ol>"},{"location":"aulas/PDI/lab13/Features.html#procedimentos","title":"Procedimentos:\u00b6","text":"<ol> <li>Escolha uma imagem de refer\u00eancia (template) - sugest\u00e3o: um livro ou outro objeto plano com textura</li> <li>Extraia features do template usando ORB ou SIFT</li> <li>Para cada frame do v\u00eddeo:<ul> <li>Extraia features</li> <li>Encontre matches</li> <li>Filtre os bons matches</li> <li>Use <code>findHomography</code> para mapear as coordenadas</li> <li>Desenhe um pol\u00edgono ao redor do objeto detectado</li> </ul> </li> </ol>"},{"location":"aulas/PDI/lab13/Features.html#funcao-auxiliar-para-desenhar-o-contorno","title":"Fun\u00e7\u00e3o auxiliar para desenhar o contorno:\u00b6","text":"<pre>def desenhaContorno(qp, tp, refImg, frame):\n    \"\"\"\n        essa fun\u00e7\u00e3o do tipo void que desenha o contorno quando existe matches das duas imagens\n        \n        recebe:\n         - qp,tp que representa a convers\u00e3o de keypoints em argumentos para o findhomography ref:https://answers.opencv.org/question/122802/how-to-convert-keypoints-to-an-argument-for-findhomography/\n         - refImg = imagem de refer\u00eancia\n         - frame = imagem de destino onde ser\u00e1 desenhado o contorno\n\n    \"\"\"\n        # o findHomography mapeia os pontos de um plano em outro.\n        # ou seja, mapeia os keypoints da imagem ref em frame\n        H,status=cv2.findHomography(qp,tp,cv2.RANSAC,3.0)\n        \n        # extrai o shape da imagem de referencia\n        h,w=refImg.shape\n        # Mapeia os pontos das bordas com base no shape refImg (imagem de referncia), s\u00e3o 4 pontos\n        #  [0,0]        [w-1,0]\n        #\n        # \n        #  [0,h-1]      [w-1,h-1]\n        #\n        refBorda=np.float32([[[0,0],[0,h-1],[w-1,h-1],[w-1,0]]])\n        # Usa refBorda e a matrix de homografia H para calcular a matrix transforma\u00e7\u00e3o de pespectiva\n        frameBorda=cv2.perspectiveTransform(refBorda,H)\n        # polylines desenha poligonos ou qualquer imagem, na cor verde e largura do tra\u00e7o igual a 5.\n        cv2.polylines(frame,[np.int32(frameBorda)],True,(0,255,0),5)\n</pre>"},{"location":"aulas/PDI/lab13/Features.html#aplicacao-pratica-criando-imagens-panoramicas","title":"Aplica\u00e7\u00e3o Pr\u00e1tica: Criando Imagens Panor\u00e2micas\u00b6","text":"<p>Uma aplica\u00e7\u00e3o muito comum de feature matching \u00e9 a cria\u00e7\u00e3o de imagens panor\u00e2micas (stitching). Este processo envolve:</p> <ol> <li>Detectar keypoints e calcular descritores em ambas as imagens</li> <li>Encontrar correspond\u00eancias entre os descritores</li> <li>Calcular a transforma\u00e7\u00e3o homogr\u00e1fica entre as imagens</li> <li>Aplicar warping para alinhar as imagens</li> <li>Combinar (blend) as imagens alinhadas</li> </ol> <p>A OpenCV fornece a classe <code>cv2.Stitcher</code> que implementa todo esse processo de forma otimizada.</p>"},{"location":"aulas/PDI/lab13/Features.html#pos-processamento-recortando-as-bordas","title":"P\u00f3s-processamento: Recortando as Bordas\u00b6","text":"<p>Como podemos observar, o panorama resultante possui bordas irregulares devido ao processo de warping. Podemos realizar um recorte (crop) para obter uma imagem retangular limpa.</p>"},{"location":"aulas/PDI/lab13/webcam_sift.html","title":"Webcam sift","text":"In\u00a0[\u00a0]: Copied! In\u00a0[\u00a0]: Copied! <pre># este c\u00f3digo implementa o descritor SIFT e realiza um processo homografia para desenhar o contorno da imagem detectada\nimport cv2\nimport numpy as np\n</pre> # este c\u00f3digo implementa o descritor SIFT e realiza um processo homografia para desenhar o contorno da imagem detectada import cv2 import numpy as np In\u00a0[\u00a0]: Copied! <pre># Numero m\u00ednimo de matches para considerar que encontrou o objeto\nminKPMatch=30\n</pre> # Numero m\u00ednimo de matches para considerar que encontrou o objeto minKPMatch=30 In\u00a0[\u00a0]: Copied! <pre># Inicializa o SIFT\nsift=cv2.SIFT_create(nfeatures=500)\n</pre> # Inicializa o SIFT sift=cv2.SIFT_create(nfeatures=500) In\u00a0[\u00a0]: Copied! <pre># Carrega a imagem de referencia na escala de cinza.\n# Em outras palavras, quero encontrar essa imagem no video. \nrefImg=cv2.imread(\"admiravelmundonovo.jpg\",0)\n</pre> # Carrega a imagem de referencia na escala de cinza. # Em outras palavras, quero encontrar essa imagem no video.  refImg=cv2.imread(\"admiravelmundonovo.jpg\",0) In\u00a0[\u00a0]: Copied! <pre># Calcula os keypoints e Descritores da imagem de referencia\nrefKP,refDesc = sift.detectAndCompute(refImg,None)\n</pre> # Calcula os keypoints e Descritores da imagem de referencia refKP,refDesc = sift.detectAndCompute(refImg,None) In\u00a0[\u00a0]: Copied! <pre># configura a captura de imagem da webcam\nvc=cv2.VideoCapture('admiravelmundonovo.mp4')\n# vc=cv2.VideoCapture(0)\n</pre> # configura a captura de imagem da webcam vc=cv2.VideoCapture('admiravelmundonovo.mp4') # vc=cv2.VideoCapture(0) In\u00a0[\u00a0]: Copied! <pre># Cria um objeto BFMatcher\nbf = cv2.BFMatcher()\n</pre> # Cria um objeto BFMatcher bf = cv2.BFMatcher() In\u00a0[\u00a0]: Copied! <pre># \u00e1rea m\u00ednima para desenhar o pol\u00edgono\nmin_area = 1000\n</pre> # \u00e1rea m\u00ednima para desenhar o pol\u00edgono min_area = 1000 In\u00a0[\u00a0]: Copied! <pre># configs para exibir o texto na tela\nfonte = cv2.FONT_HERSHEY_SIMPLEX\nposicao = (10, 30)  # Posi\u00e7\u00e3o do texto no canto superior esquerdo\nfonte_escala = 1  # Tamanho da fonte\ncor = (255, 0, 0)  # Cor do texto (branco)\nespessura = 2  # Espessura do texto\n</pre> # configs para exibir o texto na tela fonte = cv2.FONT_HERSHEY_SIMPLEX posicao = (10, 30)  # Posi\u00e7\u00e3o do texto no canto superior esquerdo fonte_escala = 1  # Tamanho da fonte cor = (255, 0, 0)  # Cor do texto (branco) espessura = 2  # Espessura do texto In\u00a0[\u00a0]: Copied! <pre>while True:\n    rval, frame = vc.read()\n\n    if not rval:\n        break   \n\n\n    # Converte o frame da web para escala de cinza\n    frameImg=cv2.cvtColor(frame,cv2.COLOR_BGR2GRAY)\n\n    # Calcula os keypoints e Descritores do frame recebido pela webcam\n    frameKP, frameDesc = sift.detectAndCompute(frameImg,None)\n\n    # a fun\u00e7\u00e3o matches devolve os pontos encontrados\n    # para k=2, dois objetos s\u00e3o retornados\n    matches = bf.knnMatch(refDesc,frameDesc, k=2) \n\n    # Filtra os matches encontrados em matches (m,n), para obter um resultado mais limpo\n    # Implementado conforme o paper publicado por D.Lowe\n    goodMatch=[]\n    for m,n in matches:\n        if(m.distance &lt; 0.75*n.distance):\n            goodMatch.append(m)\n       \n    # Testa se foram encontrados matches acima do minimo definido\n    if(len(goodMatch)&gt; minKPMatch):\n        # Se sim, extrai os matches das duas imagens.\n        # isso \u00e9 importante pq sabendo onde os pontos se encontram nas duas imagens\n        # posso correlacionar as coordenadas de uma imagem na outra\n        # ref:https://answers.opencv.org/question/122802/how-to-convert-keypoints-to-an-argument-for-findhomography/\n\n        tp=[]\n        qp=[]\n        for m in goodMatch:\n            qp.append(refKP[m.queryIdx].pt) # fornece os indices de um ID e .pt as coordenadas\n            tp.append(frameKP[m.trainIdx].pt)\n        tp,qp=np.float32((tp,qp))\n        \n        # o findHomography mapeia os pontos de um plano em outro.\n        # ou seja, mapeia os keypoints da imagem ref em frame\n        H,status=cv2.findHomography(qp,tp,cv2.RANSAC,3.0)\n        \n        # extrai o shape da imagem de referencia\n        h,w=refImg.shape\n        # Mapeia os pontos das bordas com base no shape refImg, s\u00e3o 4 pontos\n        #  [0,0]        [w-1,0]\n        #\n        # \n        #  [0,h-1]      [w-1,h-1]\n        #\n        refBorda = np.float32([[[0,0],[0,h-1],[w-1,h-1],[w-1,0]]])\n        # Usa refBorda e a matrix de homografia H para calcular a matrix transforma\u00e7\u00e3o de pespectiva\n        frameBorda = cv2.perspectiveTransform(refBorda,H)\n\n        # Para nao desenhar contornos falsos positivos, vou calcula a area do poligono encontrado e comparar com a area minima\n        area = cv2.contourArea(frameBorda)\n\n        # Desenha o pol\u00edgono se a \u00e1rea for maior que a \u00e1rea m\u00ednima\n        if area &gt; min_area:\n            cv2.polylines(frame, [np.int32(frameBorda)], True, (0, 255, 0), 5)\n            texto = f\"Encontrado match - {len(goodMatch)}/{minKPMatch} - area: {int(area)} - BOM\"\n        else:\n            texto = f\"Encontrado match - {len(goodMatch)}/{minKPMatch} - area: {int(area)} - INSUFICIENTE\"\n    else:\n        texto = f\"Encontrado match - {len(goodMatch)}/{minKPMatch} - RUIM\"\n\n    # Escreva o texto e exibe a imagem\n    cv2.putText(frame, texto, posicao, fonte, fonte_escala, cor, espessura)\n    cv2.imshow(\"resultado\", frame)\n\n    rval, frame = vc.read()\n    if cv2.waitKey(10) &amp; 0xFF == ord('q'):# tecla 'q' para sair do programa\n        break\n</pre> while True:     rval, frame = vc.read()      if not rval:         break          # Converte o frame da web para escala de cinza     frameImg=cv2.cvtColor(frame,cv2.COLOR_BGR2GRAY)      # Calcula os keypoints e Descritores do frame recebido pela webcam     frameKP, frameDesc = sift.detectAndCompute(frameImg,None)      # a fun\u00e7\u00e3o matches devolve os pontos encontrados     # para k=2, dois objetos s\u00e3o retornados     matches = bf.knnMatch(refDesc,frameDesc, k=2)       # Filtra os matches encontrados em matches (m,n), para obter um resultado mais limpo     # Implementado conforme o paper publicado por D.Lowe     goodMatch=[]     for m,n in matches:         if(m.distance &lt; 0.75*n.distance):             goodMatch.append(m)             # Testa se foram encontrados matches acima do minimo definido     if(len(goodMatch)&gt; minKPMatch):         # Se sim, extrai os matches das duas imagens.         # isso \u00e9 importante pq sabendo onde os pontos se encontram nas duas imagens         # posso correlacionar as coordenadas de uma imagem na outra         # ref:https://answers.opencv.org/question/122802/how-to-convert-keypoints-to-an-argument-for-findhomography/          tp=[]         qp=[]         for m in goodMatch:             qp.append(refKP[m.queryIdx].pt) # fornece os indices de um ID e .pt as coordenadas             tp.append(frameKP[m.trainIdx].pt)         tp,qp=np.float32((tp,qp))                  # o findHomography mapeia os pontos de um plano em outro.         # ou seja, mapeia os keypoints da imagem ref em frame         H,status=cv2.findHomography(qp,tp,cv2.RANSAC,3.0)                  # extrai o shape da imagem de referencia         h,w=refImg.shape         # Mapeia os pontos das bordas com base no shape refImg, s\u00e3o 4 pontos         #  [0,0]        [w-1,0]         #         #          #  [0,h-1]      [w-1,h-1]         #         refBorda = np.float32([[[0,0],[0,h-1],[w-1,h-1],[w-1,0]]])         # Usa refBorda e a matrix de homografia H para calcular a matrix transforma\u00e7\u00e3o de pespectiva         frameBorda = cv2.perspectiveTransform(refBorda,H)          # Para nao desenhar contornos falsos positivos, vou calcula a area do poligono encontrado e comparar com a area minima         area = cv2.contourArea(frameBorda)          # Desenha o pol\u00edgono se a \u00e1rea for maior que a \u00e1rea m\u00ednima         if area &gt; min_area:             cv2.polylines(frame, [np.int32(frameBorda)], True, (0, 255, 0), 5)             texto = f\"Encontrado match - {len(goodMatch)}/{minKPMatch} - area: {int(area)} - BOM\"         else:             texto = f\"Encontrado match - {len(goodMatch)}/{minKPMatch} - area: {int(area)} - INSUFICIENTE\"     else:         texto = f\"Encontrado match - {len(goodMatch)}/{minKPMatch} - RUIM\"      # Escreva o texto e exibe a imagem     cv2.putText(frame, texto, posicao, fonte, fonte_escala, cor, espessura)     cv2.imshow(\"resultado\", frame)      rval, frame = vc.read()     if cv2.waitKey(10) &amp; 0xFF == ord('q'):# tecla 'q' para sair do programa         break In\u00a0[\u00a0]: Copied! <pre>vc.release()\ncv2.destroyAllWindows()\n</pre> vc.release() cv2.destroyAllWindows()"},{"location":"aulas/PDI/lab14/haarCascade.html","title":"Lab14 - Detector haar Cascade","text":"<p>Objetivos da aula:</p> <ul> <li>apresentar uma introdu\u00e7\u00e3o sobre aprendizado de m\u00e1quina</li> <li>apresentar e aplicar o haar cascade para detec\u00e7\u00e3o de face</li> <li>apresentar uma intui\u00e7\u00e3o do algoritimo de Viola Jones</li> </ul> <p>Como fazer a dete\u00e7\u00e3o de faces?</p> <p>O nosso objetivo hoje \u00e9 compreender a essencia de algoritimos para detec\u00e7\u00e3o facial, apenas refor\u00e7ando que j\u00e1 sabemos, esses algoritmos s\u00e3o utilizados para diversas aplica\u00e7\u00f5es, desde a lendaria camera tekpix, passando por smartphones e o google fotos para classificador na organiza\u00e7\u00e3o de pastas por pessoas, por exemplo.</p> <p>Aprendizado de m\u00e1quina</p> <p>Antes de entrar em tecnicas mais avan\u00e7adas de Deep Learning em vis\u00e3o computacional, vamos introduzir este tema estudando e aplicando o m\u00e9todo muito cl\u00e1ssico de classifica\u00e7\u00e3o em cascata de faces desenvolvido por Viola e Jones, na OpenCV temos exemplares pr\u00e9-treinados para detec\u00e7\u00e3o de faces e de olhos.</p> <p>**Classificador Haar-Cascade **</p> <p>Voc\u00ea vai ver em todo e qualquer curso ou livro de vis\u00e3o computacional o detector de face de Viola-Jones sendo mencionado. Inventado em 2001, foi disruptivo no campo da vis\u00e3o computacional, por que finalmente permitiu a detec\u00e7\u00e3o e o reconhecimento de rostos em tempo real.</p> <p>Muito obrigado Viola e Jones :)</p> <p>ref: https://www.cs.cmu.edu/~efros/courses/LBMV07/Papers/viola-cvpr-01.pdf https://docs.opencv.org/master/db/d28/tutorial_cascade_classifier.html</p> <p>Para apresentar uma intui\u00e7\u00e3o de como funciona, vamos imaginar o seguinte:</p> <p>Algumas caracteristicas do rosto s\u00e3o bem definidas e conseguimos correlacionar tais como bochecha com olhos, testa com nariz.... Para encontrar essas correla\u00e7\u00f5es usamos a ideia de feature e convolu\u00e7\u00e3o que ja estudamos. Podemos visualizar essa t\u00e9cnica no gif da Lena.</p> <p>ref. https://vimeo.com/12774628</p> In\u00a0[1]: Copied! <pre>## Vou fazer o download das imagens do laborat\u00f3rio diretamente do reposit\u00f3rio para usar no colab mais facil....\nimport requests\n\n# Definie o modulo e o laborat\u00f3rio\nmodulo ='PDI/'\nlaboratorio = 'lab14'\n\n# URL da API do GitHub para a pasta do reposit\u00f3rio\napi_url = \"https://api.github.com/repos/arnaldojr/cognitivecomputing/contents/material/aulas/\"\n\n# Monta a URL completa\nurl_completa = api_url + modulo + laboratorio\n\nprint(f\"Fazendo o download de: {url_completa}\")\n\n# Requisi\u00e7\u00e3o para obter a lista de arquivos na pasta\nresponse = requests.get(url_completa)\nfiles = response.json()\n\n# Fazer o download de cada arquivo de imagem\nfor file in files:\n    file_name = file['name']\n    if file_name.endswith(('.png', '.jpg', '.jpeg', '.mp4')):  # Adicione mais extens\u00f5es se necess\u00e1rio\n        file_url = file['download_url']\n        print(f\"Baixando {file_name}...\")\n        !wget -q {file_url} -P /content\n\nprint(\"Download conclu\u00eddo.\")\n</pre> ## Vou fazer o download das imagens do laborat\u00f3rio diretamente do reposit\u00f3rio para usar no colab mais facil.... import requests  # Definie o modulo e o laborat\u00f3rio modulo ='PDI/' laboratorio = 'lab14'  # URL da API do GitHub para a pasta do reposit\u00f3rio api_url = \"https://api.github.com/repos/arnaldojr/cognitivecomputing/contents/material/aulas/\"  # Monta a URL completa url_completa = api_url + modulo + laboratorio  print(f\"Fazendo o download de: {url_completa}\")  # Requisi\u00e7\u00e3o para obter a lista de arquivos na pasta response = requests.get(url_completa) files = response.json()  # Fazer o download de cada arquivo de imagem for file in files:     file_name = file['name']     if file_name.endswith(('.png', '.jpg', '.jpeg', '.mp4')):  # Adicione mais extens\u00f5es se necess\u00e1rio         file_url = file['download_url']         print(f\"Baixando {file_name}...\")         !wget -q {file_url} -P /content  print(\"Download conclu\u00eddo.\")   <pre>Fazendo o download de: https://api.github.com/repos/arnaldojr/cognitivecomputing/contents/material/aulas/PDI/lab14\nBaixando acumulador.jpg...\nBaixando lena-eye-face.png...\nBaixando lena.png...\nDownload conclu\u00eddo.\n</pre> In\u00a0[2]: Copied! <pre>%matplotlib inline\nimport cv2\nfrom matplotlib import pyplot as plt\nimport numpy as np\n\n#caminho onde est\u00e3o os pesos\npath = cv2.data.haarcascades + \"haarcascade_frontalface_default.xml\"\n\n# Inicializa o classificador cascade\nface = cv2.CascadeClassifier(path)\n\nprint(\"Os pesos est\u00e3o no diretorio: \", path)\n</pre> %matplotlib inline import cv2 from matplotlib import pyplot as plt import numpy as np  #caminho onde est\u00e3o os pesos path = cv2.data.haarcascades + \"haarcascade_frontalface_default.xml\"  # Inicializa o classificador cascade face = cv2.CascadeClassifier(path)  print(\"Os pesos est\u00e3o no diretorio: \", path)  <pre>Os pesos est\u00e3o no diretorio:  /usr/local/lib/python3.10/dist-packages/cv2/data/haarcascade_frontalface_default.xml\n</pre> In\u00a0[\u00a0]: Copied! <pre># Fa\u00e7a aqui os ajustes que forem necess\u00e1rios.....\n</pre> # Fa\u00e7a aqui os ajustes que forem necess\u00e1rios.....           <p>O m\u00e9todo detectMultiScale() realiza o processo de varredura que vimos no gif acima e retorna uma lista com as faces encontrardas.</p> <p>Este possui 3 parametros principais;</p> <pre><code>gray image \u2013 Imagem de entrada na escala de cinza.\nscaleFactor \u2013 Parametro para ajustar a escala, em uma imagem pode conter rostos maiores e menores. Esse parametro tenta corrigir isso.\nminNeighbors \u2013 Este par\u00e2metro especifica o n\u00famero de vizinhos que uma janela deve ter para ser chamado de face.</code></pre> <p>Voc\u00ea pode ler mais sobre isso aqui. https://docs.opencv.org/2.4.13.2/modules/objdetect/doc/cascade_classification.html#cv2.CascadeClassifier.detectMultiScale</p> In\u00a0[3]: Copied! <pre>img = cv2.imread('lena.png')\nimg_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n\n# O m\u00e9todo detectMultiScale() realiza o processo de varredura que vimos no gif acima e retorna uma lista com as faces encontrardas.\n\nfaces_return = face.detectMultiScale(img_gray, scaleFactor = 1.2, minNeighbors = 5)\n\n\nprint('Faces encontradas: ', len(faces_return),type(faces_return), faces_return)\nprint(\"\")\nprint(\"x:\", faces_return[0][0])\nprint(\"y:\", faces_return[0][0])\nprint(\"x e y, representam a coodenada top esquerda da face detectada\")\nprint(\"\")\nprint(\"Largura :\", faces_return[0][0])\nprint(\"Altura:\", faces_return[0][0])\n</pre> img = cv2.imread('lena.png') img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)  # O m\u00e9todo detectMultiScale() realiza o processo de varredura que vimos no gif acima e retorna uma lista com as faces encontrardas.  faces_return = face.detectMultiScale(img_gray, scaleFactor = 1.2, minNeighbors = 5)   print('Faces encontradas: ', len(faces_return),type(faces_return), faces_return) print(\"\") print(\"x:\", faces_return[0][0]) print(\"y:\", faces_return[0][0]) print(\"x e y, representam a coodenada top esquerda da face detectada\") print(\"\") print(\"Largura :\", faces_return[0][0]) print(\"Altura:\", faces_return[0][0]) <pre>Faces encontradas:  1 &lt;class 'numpy.ndarray'&gt; [[224 210 156 156]]\n\nx: 224\ny: 224\nx e y, representam a coodenada top esquerda da face detectada\n\nLargura : 224\nAltura: 224\n</pre> In\u00a0[4]: Copied! <pre>## Dica r\u00e1pida de python\n\n#Podemos iterar varias listas ao mesmo tempo dentro de um unico *for* de forma simultanea usando o python\n\n# Exemplo, vamos criar uma lista qualquer\n\na = np.array([[\"x\", \"y\", \"largura\", \"altura\"]])\n\nprint (a)\nfor (x,y,w,h) in a:\n    print(\"posi\u00e7\u00e3o (x,y): \", x,y, \"largura: \", w, \"altura\",h)\n</pre> ## Dica r\u00e1pida de python  #Podemos iterar varias listas ao mesmo tempo dentro de um unico *for* de forma simultanea usando o python  # Exemplo, vamos criar uma lista qualquer  a = np.array([[\"x\", \"y\", \"largura\", \"altura\"]])  print (a) for (x,y,w,h) in a:     print(\"posi\u00e7\u00e3o (x,y): \", x,y, \"largura: \", w, \"altura\",h)  <pre>[['x' 'y' 'largura' 'altura']]\nposi\u00e7\u00e3o (x,y):  x y largura:  largura altura altura\n</pre> In\u00a0[5]: Copied! <pre>    # Implemente sua solu\u00e7\u00e3o aqui.....\n</pre>     # Implemente sua solu\u00e7\u00e3o aqui.....           In\u00a0[\u00a0]: Copied! <pre>    # Implemente sua solu\u00e7\u00e3o aqui.....\n</pre>     # Implemente sua solu\u00e7\u00e3o aqui.....     In\u00a0[\u00a0]: Copied! <pre># implemente aqui sua sulu\u00e7\u00e3o.............\n</pre> # implemente aqui sua sulu\u00e7\u00e3o............."},{"location":"aulas/PDI/lab14/haarCascade.html#implementacao-na-opencv","title":"Implementa\u00e7\u00e3o na OpenCV\u00b6","text":"<p>Vamos implementar um detector de face baseado em haar cascade, como essa t\u00e9cnica \u00e9 baseada em machine learning, vamos utilizar uma rede com os pesos do classificador treinado e dispoiniblizado pela OpenCV.</p> <p>J\u00e1 temos esses arquivos com os pesos das redes quando instalamos a OpenCV, o que temos que fazer \u00e9 carregar esses pesos.</p>"},{"location":"aulas/PDI/lab14/haarCascade.html#desafio-1","title":"Desafio 1\u00b6","text":""},{"location":"aulas/PDI/lab14/haarCascade.html#se-nao-estiver-usando-o-google-coclab","title":"<code>Se n\u00e3o estiver usando o google coclab</code>\u00b6","text":"<p>Pode acontecer de n\u00e3o encontrar o caminho do diretorio com os pesos. Como suget\u00e3o, verifique se ja possui os arquivos de pesos. Caso n\u00e3o encontre, ser\u00e1 necess\u00e1rio fazer o download desses pesos. Para facilitar a vida, na pasta cascade j\u00e1 est\u00e3o os pesos note que s\u00e3o varios arquivos. Fa\u00e7a os ajustes necess\u00e1rios para carregar os pesos da rede.</p> <p>vamos usar o \"haarcascade_frontalface_default.xml\".</p>"},{"location":"aulas/PDI/lab14/haarCascade.html#desafio-2","title":"Desafio 2\u00b6","text":"<p>Usando as posi\u00e7\u00f5es da lista <code>face_return</code>. Implemente uma fun\u00e7\u00e3o que desenha um um retangulo sobre a face detectada.</p>"},{"location":"aulas/PDI/lab14/haarCascade.html#desafio-3","title":"Desafio 3\u00b6","text":"<p>Vamos aproveitar que temos as coodenadas da face e vamos lembrar como faz um crop (recorte ) desta imagem.</p>"},{"location":"aulas/PDI/lab14/haarCascade.html#desafio-4","title":"Desafio 4\u00b6","text":"<p><code>Fa\u00e7a a dete\u00e7\u00e3o dos olhos</code> da Lena, carrege os pesos que correspodem a detec\u00e7\u00e3o de olhos e implemente sua solu\u00e7\u00e3o.</p> <p>Escolha um modelo haarcascade coerente para realizar essa tarefa.</p> <p>Dica: Os olhos fazem parte da face, nesse sentido, n\u00e3o \u00e9 necess\u00e1rio fazer a varredura em toda a imagem, basta fazer a varredura dentro dos limites onde est\u00e1 contida a face, concorda???</p>"},{"location":"aulas/PDI/lab14/haarCascade.html#desafio-5","title":"Desafio 5\u00b6","text":"<p>No inicio da aula falamos que o m\u00e9todo de Viola-Jones foi desruptivo por que tornou capaz a detec\u00e7\u00e3o de faces em tempo real. Implemente um c\u00f3digo .py que realiza a dete\u00e7\u00e3o em tempo real, capturando a imagem da sua webcam.</p>"},{"location":"aulas/PDI/lab15/EventMouse.html","title":"Lab15 - Event Mouse","text":"<p>Objetivos da aula:</p> <ul> <li>apresentar e aplicar o Event click do mouse</li> </ul> <p>QUAL O PROBLEMA?</p> <p>N\u00e3o \u00e9 bem um problema mas pode ser util em alguns casos saber interagir na imagem com o mouse para fazer um recorte da imaem, saber o RGB de um pixel ou encontrar um angulo entre retas. Sabemos fazer isso sem mouser, mas gastamos um tempinho para fazer todos os ajustes...</p> <p>Visualmente \u00e9 simples essa tarefa, basta clicar com o mouse na regi\u00e3o escolhida e pronto!.</p> In\u00a0[\u00a0]: Copied! <pre>## vou fazer o download das imagens do reposit\u00f3rio para usar no colab mais facil....\n\n!wget https://raw.githubusercontent.com/arnaldojr/cognitivecomputing/master/material/aulas/PDI/lab15/admiravelmundonovo.jpg /content\n!wget https://raw.githubusercontent.com/arnaldojr/cognitivecomputing/master/material/aulas/PDI/lab15/transferidor.jpg /content\n</pre> ## vou fazer o download das imagens do reposit\u00f3rio para usar no colab mais facil....  !wget https://raw.githubusercontent.com/arnaldojr/cognitivecomputing/master/material/aulas/PDI/lab15/admiravelmundonovo.jpg /content !wget https://raw.githubusercontent.com/arnaldojr/cognitivecomputing/master/material/aulas/PDI/lab15/transferidor.jpg /content In\u00a0[1]: Copied! <pre>import cv2\nimport numpy as np\n \n# \n# cria uma matriz (imagem) de 480x640 com 3 canais (r,g,b), img toda preta com maximos de 0-255\nimg = np.zeros((480, 640, 3), dtype=\"uint8\")\n  \n# exibe a img\ncv2.imshow('image', img)\n\n# \u00e9 uma fun\u00e7\u00e3o de callback para tratativa de eventos do mouse\ndef mouse_click(event, x, y, flags, param):\n    \n    # se foi click do botao direito \n    if event == cv2.EVENT_RBUTTONDOWN:\n        # fa\u00e7a a fun\u00e7\u00e3o.... \n        pass\n    if event == cv2.EVENT_LBUTTONDOWN:\n        # fa\u00e7a a fun\u00e7\u00e3o.... \n        pass\n\n\n\n\n\n#  configura o evento do mouse e chama a fun\u00e7\u00e3o mouse_click\ncv2.setMouseCallback('image', mouse_click)\n   \ncv2.waitKey(0)\n  \n# \ncv2.destroyAllWindows()\n</pre> import cv2 import numpy as np   #  # cria uma matriz (imagem) de 480x640 com 3 canais (r,g,b), img toda preta com maximos de 0-255 img = np.zeros((480, 640, 3), dtype=\"uint8\")    # exibe a img cv2.imshow('image', img)  # \u00e9 uma fun\u00e7\u00e3o de callback para tratativa de eventos do mouse def mouse_click(event, x, y, flags, param):          # se foi click do botao direito      if event == cv2.EVENT_RBUTTONDOWN:         # fa\u00e7a a fun\u00e7\u00e3o....          pass     if event == cv2.EVENT_LBUTTONDOWN:         # fa\u00e7a a fun\u00e7\u00e3o....          pass      #  configura o evento do mouse e chama a fun\u00e7\u00e3o mouse_click cv2.setMouseCallback('image', mouse_click)     cv2.waitKey(0)    #  cv2.destroyAllWindows() <pre>2024-04-01 11:53:22.997 Python[30860:5062868] WARNING: Secure coding is automatically enabled for restorable state! However, not on all supported macOS versions of this application. Opt-in to secure coding explicitly by implementing NSApplicationDelegate.applicationSupportsSecureRestorableState:.\n</pre> <p>O c\u00f3digo acima cria uma imagem preta e fica aguardando um evento do mouse. O mouse pode gerar alguns tipos de eventos, mas quais s\u00e3o eles???</p> In\u00a0[2]: Copied! <pre># Dica python como usar um list comprehensions no python e a fun\u00e7\u00e3o built-in dir()\n\nimport cv2\nimport numpy as np\n\n# A fun\u00e7\u00e3o dir() devolte todas propriedades e m\u00e9todos de um objeto especifico\n#print(len(dir(cv2)))\n#print (dir(cv2))\n\n\n# Vamos varrer o objeto cv2 e filtrar apenas os m\u00e9todos que tem rela\u00e7\u00e3o com EVENT\neventos = []\nfor i in dir(cv2):\n    if 'EVENT' in i:\n        eventos.append(i)\nprint(eventos)\nprint(len(eventos))\n\n# Usando List comprehension\n# Devolve uma lista na variavel events filtando os dados de outra lista\n\n#events = [i for i in dir(cv2) if 'EVENT' in i]\n#print( events )\n</pre> # Dica python como usar um list comprehensions no python e a fun\u00e7\u00e3o built-in dir()  import cv2 import numpy as np  # A fun\u00e7\u00e3o dir() devolte todas propriedades e m\u00e9todos de um objeto especifico #print(len(dir(cv2))) #print (dir(cv2))   # Vamos varrer o objeto cv2 e filtrar apenas os m\u00e9todos que tem rela\u00e7\u00e3o com EVENT eventos = [] for i in dir(cv2):     if 'EVENT' in i:         eventos.append(i) print(eventos) print(len(eventos))  # Usando List comprehension # Devolve uma lista na variavel events filtando os dados de outra lista  #events = [i for i in dir(cv2) if 'EVENT' in i] #print( events )    <pre>['EVENT_FLAG_ALTKEY', 'EVENT_FLAG_CTRLKEY', 'EVENT_FLAG_LBUTTON', 'EVENT_FLAG_MBUTTON', 'EVENT_FLAG_RBUTTON', 'EVENT_FLAG_SHIFTKEY', 'EVENT_LBUTTONDBLCLK', 'EVENT_LBUTTONDOWN', 'EVENT_LBUTTONUP', 'EVENT_MBUTTONDBLCLK', 'EVENT_MBUTTONDOWN', 'EVENT_MBUTTONUP', 'EVENT_MOUSEHWHEEL', 'EVENT_MOUSEMOVE', 'EVENT_MOUSEWHEEL', 'EVENT_RBUTTONDBLCLK', 'EVENT_RBUTTONDOWN', 'EVENT_RBUTTONUP']\n18\n</pre> <p>Basicamente s\u00e3o esses:</p> <p>Eventos:</p> <pre><code>    CV_EVENT_MOUSEMOVE: movimento do mouse\n\n    CV_EVENT_LBUTTONDOWN: Pressione o bot\u00e3o esquerdo do mouse\n    CV_EVENT_RBUTTONDOWN: Pressione o bot\u00e3o direito do mouse\n    CV_EVENT_MBUTTONDOWN: Pressione o bot\u00e3o do meio do mouse\n\n    CV_EVENT_LBUTTONUP: solte o bot\u00e3o esquerdo\n    CV_EVENT_RBUTTONUP: solte o bot\u00e3o direito \n    CV_EVENT_MBUTTONUP: Solte o bot\u00e3o do meio\n\n    CV_EVENT_LBUTTONDBLCLK: clique duplo esquerdo\n    CV_EVENT_RBUTTONDBLCLK: Clique duplo direito \n    CV_EVENT_MBUTTONDBLCLK: clique duplo do bot\u00e3o do meio\n    \n    CV_EVENT_MOUSEWHEEL: Mova o mouse para frente (+) ou para tr\u00e1s (-)\n    CV_EVENT_MOUSEHWHEEL: Mova o mouse para a direita (+) ou esquerda (-)\n    </code></pre> <p>Flags:</p> <pre><code>    CV_EVENT_FLAG_LBUTTON: Clique com o bot\u00e3o esquerdo e arraste\n    CV_EVENT_FLAG_RBUTTON: Clique com o bot\u00e3o direito e arraste\n    CV_EVENT_FLAG_MBUTTON: bot\u00e3o do meio arrastar\n    \n    CV_EVENT_FLAG_CTRLKEY: Pressione e segure Ctrl\n    CV_EVENT_FLAG_SHIFTKEY: shift pressione e segure\n    CV_EVENT_FLAG_ALTKEY: pressione e segure alt</code></pre> In\u00a0[4]: Copied! <pre>import cv2\nimport numpy as np\n \n# Carrega uma imagem\n# Neste caso estamos criando uma imagem RGB preta de tamanho 480x640\nimg = np.zeros((480, 640, 3), dtype=\"uint8\")\n  \n# Exibe a imagem\ncv2.imshow('image', img)\n\n# Fun\u00e7\u00e3o de callback, quando ocorre um evento do mouse, essa fun\u00e7\u00e3o \u00e9 chamada\ndef mouse_click(event, x, y, flags, param):\n    global img\n    # Se foi o bot\u00e3o esquerdo do mouse  \n\n\n    # Se foi o bot\u00e3o direito do mouse  \n    if event == cv2.EVENT_RBUTTONDOWN:\n        \n        # ---------- implemente a solu\u00e7\u00e3o... \n        img[:,:] = [255,0,0]\n\n        cv2.imshow('image', img)\n    # Se foi o bot\u00e3o direito do mouse  \n\n    if event == cv2.EVENT_LBUTTONDBLCLK:\n        \n        # ---------- implemente a solu\u00e7\u00e3o... \n        img[:,:] = [0,0,255]\n\n        cv2.imshow('image', img)\n\n\n\n# Seta a fun\u00e7\u00e3o de callback que ser\u00e1 chamada \n# Evento 'image', fun\u00e7\u00e3o callback mouse_click  \ncv2.setMouseCallback('image', mouse_click)\n   \ncv2.waitKey(0)\n  \n# fecha a janela.\ncv2.destroyAllWindows()\n</pre> import cv2 import numpy as np   # Carrega uma imagem # Neste caso estamos criando uma imagem RGB preta de tamanho 480x640 img = np.zeros((480, 640, 3), dtype=\"uint8\")    # Exibe a imagem cv2.imshow('image', img)  # Fun\u00e7\u00e3o de callback, quando ocorre um evento do mouse, essa fun\u00e7\u00e3o \u00e9 chamada def mouse_click(event, x, y, flags, param):     global img     # Se foi o bot\u00e3o esquerdo do mouse         # Se foi o bot\u00e3o direito do mouse       if event == cv2.EVENT_RBUTTONDOWN:                  # ---------- implemente a solu\u00e7\u00e3o...          img[:,:] = [255,0,0]          cv2.imshow('image', img)     # Se foi o bot\u00e3o direito do mouse        if event == cv2.EVENT_LBUTTONDBLCLK:                  # ---------- implemente a solu\u00e7\u00e3o...          img[:,:] = [0,0,255]          cv2.imshow('image', img)    # Seta a fun\u00e7\u00e3o de callback que ser\u00e1 chamada  # Evento 'image', fun\u00e7\u00e3o callback mouse_click   cv2.setMouseCallback('image', mouse_click)     cv2.waitKey(0)    # fecha a janela. cv2.destroyAllWindows() In\u00a0[5]: Copied! <pre>import cv2\nimport numpy as np\n \n# Carrega uma imagem\nimg = cv2.imread('admiravelmundonovo.jpg')\n  \n# Exibe a imagem\ncv2.imshow('image', img)\n\n# Fun\u00e7\u00e3o de callback, quando ocorre um evento do mouse, essa fun\u00e7\u00e3o \u00e9 chamada\ndef mouse_click(event, x, y, flags, param):\n    \n    # Se foi o bot\u00e3o esquerdo do mouse  \n    if event == cv2.EVENT_LBUTTONDOWN:\n        \n        # Realiza fun\u00e7\u00e3o... \n        #blue = img[y,x,0]\n        #green = img[y,x,1]\n        #red = img[y,x,2]\n        blue, green, red = img[y,x]\n        #print (red, green, blue)\n        msg = \"R:\" + str(red) + \", G:\" + str(green) + \", B:\" +str(blue)\n        cv2.putText(img,msg,(x,y),cv2.FONT_HERSHEY_COMPLEX,1.5,(255,255,255),2)\n\n        cv2.imshow('image', img)\n\n# Seta a fun\u00e7\u00e3o de callback que ser\u00e1 chamada \n# Evento 'image', fun\u00e7\u00e3o callback mouse_click  \ncv2.setMouseCallback('image', mouse_click)\n   \ncv2.waitKey(0)\n  \n# fecha a janela.\ncv2.destroyAllWindows()\n</pre> import cv2 import numpy as np   # Carrega uma imagem img = cv2.imread('admiravelmundonovo.jpg')    # Exibe a imagem cv2.imshow('image', img)  # Fun\u00e7\u00e3o de callback, quando ocorre um evento do mouse, essa fun\u00e7\u00e3o \u00e9 chamada def mouse_click(event, x, y, flags, param):          # Se foi o bot\u00e3o esquerdo do mouse       if event == cv2.EVENT_LBUTTONDOWN:                  # Realiza fun\u00e7\u00e3o...          #blue = img[y,x,0]         #green = img[y,x,1]         #red = img[y,x,2]         blue, green, red = img[y,x]         #print (red, green, blue)         msg = \"R:\" + str(red) + \", G:\" + str(green) + \", B:\" +str(blue)         cv2.putText(img,msg,(x,y),cv2.FONT_HERSHEY_COMPLEX,1.5,(255,255,255),2)          cv2.imshow('image', img)  # Seta a fun\u00e7\u00e3o de callback que ser\u00e1 chamada  # Evento 'image', fun\u00e7\u00e3o callback mouse_click   cv2.setMouseCallback('image', mouse_click)     cv2.waitKey(0)    # fecha a janela. cv2.destroyAllWindows() In\u00a0[1]: Copied! <pre># Implemente a solu\u00e7\u00e3o aqui.....\n</pre> # Implemente a solu\u00e7\u00e3o aqui.....     In\u00a0[6]: Copied! <pre>import cv2\nimport numpy as np\n \n# Carrega uma imagem\n# Neste caso estamos criando uma imagem RGB preta de tamanho 480x640\nimg = np.zeros((480, 640, 3), dtype=\"uint8\")\n  \n# Exibe a imagem\ncv2.imshow('image', img)\n\n# Fun\u00e7\u00e3o de callback, quando ocorre um evento do mouse, essa fun\u00e7\u00e3o \u00e9 chamada\ndef mouse_click(event, x, y, flags, param):\n    \n    # Se foi movimento do mouse   \n    if event == cv2.EVENT_MOUSEMOVE:\n        \n        # Realiza fun\u00e7\u00e3o... \n        \n        cv2.circle(img, (x,y), 20,(0,255,0), -1)\n        cv2.imshow('image', img)\n\n\n# Seta a fun\u00e7\u00e3o de callback que ser\u00e1 chamada \n# Evento 'image', fun\u00e7\u00e3o callback mouse_click  \ncv2.setMouseCallback('image', mouse_click)\n   \ncv2.waitKey(0)\n  \n# fecha a janela.\ncv2.destroyAllWindows()\n</pre> import cv2 import numpy as np   # Carrega uma imagem # Neste caso estamos criando uma imagem RGB preta de tamanho 480x640 img = np.zeros((480, 640, 3), dtype=\"uint8\")    # Exibe a imagem cv2.imshow('image', img)  # Fun\u00e7\u00e3o de callback, quando ocorre um evento do mouse, essa fun\u00e7\u00e3o \u00e9 chamada def mouse_click(event, x, y, flags, param):          # Se foi movimento do mouse        if event == cv2.EVENT_MOUSEMOVE:                  # Realiza fun\u00e7\u00e3o...                   cv2.circle(img, (x,y), 20,(0,255,0), -1)         cv2.imshow('image', img)   # Seta a fun\u00e7\u00e3o de callback que ser\u00e1 chamada  # Evento 'image', fun\u00e7\u00e3o callback mouse_click   cv2.setMouseCallback('image', mouse_click)     cv2.waitKey(0)    # fecha a janela. cv2.destroyAllWindows() In\u00a0[\u00a0]: Copied! <pre># Implemente a solu\u00e7\u00e3o aqui.....\n</pre> # Implemente a solu\u00e7\u00e3o aqui.....        <p>Muito legal mas... pouco util at\u00e9 o momento. Vamos desenvolver aplica\u00e7\u00f5es mais interessantes.</p> In\u00a0[7]: Copied! <pre>import cv2\nimport numpy as np\n \n# Carrega uma imagem\n# Neste caso estamos criando uma imagem RGB preta de tamanho 480x640\nimg = np.zeros((480, 640, 3), dtype=\"uint8\")\n  \n# Exibe a imagem\ncv2.imshow('image', img)\n\n# Cria duas variaveis globais\nclicks = 0      # conta a quantidade de clicks dada\ncoordinates = [] # salva as coordenadas de cada click\n\n\n# Fun\u00e7\u00e3o de callback, quando ocorre um evento do mouse, essa fun\u00e7\u00e3o \u00e9 chamada\ndef mouse_click(event, x, y, flags, param):\n    global clicks, coordinates, image\n    # Se foi movimento do mouse  \n\n    if clicks &lt; 2:\n        if event == cv2.EVENT_LBUTTONDBLCLK:\n            clicks += 1        \n            coordinates.append([x, y])\n            cv2.circle(img, (x,y), 2,(0,255,0), -1)\n            cv2.imshow('image', img)\n            print(clicks, coordinates)\n\n    # Se foi o bot\u00e3o esquerdo do mouse  \n    else:\n        if event == cv2.EVENT_RBUTTONDOWN:\n            img[:,:,] = 0\n            img[:,:,1] = 0\n            img[:,:,2] = 0\n            clicks = 0\n            coordinates = []\n            cv2.imshow('image', img)\n        else:\n            start_point = tuple(coordinates[0]) \n            end_point = tuple(coordinates[1])\n            print(start_point,end_point)\n            cv2.line(img, start_point, end_point, (0,255,0), 2)\n            cv2.imshow('image', img)\n\n\n# Seta a fun\u00e7\u00e3o de callback que ser\u00e1 chamada \n# Evento 'image', fun\u00e7\u00e3o callback mouse_click  \ncv2.setMouseCallback('image', mouse_click)\n   \ncv2.waitKey(0)\n  \n# fecha a janela.\ncv2.destroyAllWindows()\n</pre> import cv2 import numpy as np   # Carrega uma imagem # Neste caso estamos criando uma imagem RGB preta de tamanho 480x640 img = np.zeros((480, 640, 3), dtype=\"uint8\")    # Exibe a imagem cv2.imshow('image', img)  # Cria duas variaveis globais clicks = 0      # conta a quantidade de clicks dada coordinates = [] # salva as coordenadas de cada click   # Fun\u00e7\u00e3o de callback, quando ocorre um evento do mouse, essa fun\u00e7\u00e3o \u00e9 chamada def mouse_click(event, x, y, flags, param):     global clicks, coordinates, image     # Se foi movimento do mouse        if clicks &lt; 2:         if event == cv2.EVENT_LBUTTONDBLCLK:             clicks += 1                     coordinates.append([x, y])             cv2.circle(img, (x,y), 2,(0,255,0), -1)             cv2.imshow('image', img)             print(clicks, coordinates)      # Se foi o bot\u00e3o esquerdo do mouse       else:         if event == cv2.EVENT_RBUTTONDOWN:             img[:,:,] = 0             img[:,:,1] = 0             img[:,:,2] = 0             clicks = 0             coordinates = []             cv2.imshow('image', img)         else:             start_point = tuple(coordinates[0])              end_point = tuple(coordinates[1])             print(start_point,end_point)             cv2.line(img, start_point, end_point, (0,255,0), 2)             cv2.imshow('image', img)   # Seta a fun\u00e7\u00e3o de callback que ser\u00e1 chamada  # Evento 'image', fun\u00e7\u00e3o callback mouse_click   cv2.setMouseCallback('image', mouse_click)     cv2.waitKey(0)    # fecha a janela. cv2.destroyAllWindows() In\u00a0[\u00a0]: Copied! <pre># implemente sua solu\u00e7\u00e3o aqui...........\n</pre> # implemente sua solu\u00e7\u00e3o aqui...........                In\u00a0[8]: Copied! <pre>import cv2\nimport numpy as np\n \n# Carrega uma imagem\n# Neste caso estamos criando uma imagem RGB preta de tamanho 480x640\nimg = np.zeros((480, 640, 3), dtype=\"uint8\")\n  \n# Exibe a imagem\ncv2.imshow('image', img)\n\npoints = []\n\n# Fun\u00e7\u00e3o de callback, quando ocorre um evento do mouse, essa fun\u00e7\u00e3o \u00e9 chamada\ndef mouse_click(event, x, y, flags, param): \n    global points\n\n    if event == cv2.EVENT_LBUTTONDOWN:\n        points = [(x, y)]\n\n    elif event == cv2.EVENT_LBUTTONUP:\n        points.append((x, y))\n        p1 = tuple(points[0]) \n        p2 = tuple(points[1])\n\n        cv2.rectangle(img, p1 , p2, (0, 255, 0), 3)\n        cv2.imshow('image', img)\n\n# Seta a fun\u00e7\u00e3o de callback que ser\u00e1 chamada \n# Evento 'image', fun\u00e7\u00e3o callback mouse_click  \ncv2.setMouseCallback('image', mouse_click)\n   \ncv2.waitKey(0)\n  \n# fecha a janela.\ncv2.destroyAllWindows()\n</pre> import cv2 import numpy as np   # Carrega uma imagem # Neste caso estamos criando uma imagem RGB preta de tamanho 480x640 img = np.zeros((480, 640, 3), dtype=\"uint8\")    # Exibe a imagem cv2.imshow('image', img)  points = []  # Fun\u00e7\u00e3o de callback, quando ocorre um evento do mouse, essa fun\u00e7\u00e3o \u00e9 chamada def mouse_click(event, x, y, flags, param):      global points      if event == cv2.EVENT_LBUTTONDOWN:         points = [(x, y)]      elif event == cv2.EVENT_LBUTTONUP:         points.append((x, y))         p1 = tuple(points[0])          p2 = tuple(points[1])          cv2.rectangle(img, p1 , p2, (0, 255, 0), 3)         cv2.imshow('image', img)  # Seta a fun\u00e7\u00e3o de callback que ser\u00e1 chamada  # Evento 'image', fun\u00e7\u00e3o callback mouse_click   cv2.setMouseCallback('image', mouse_click)     cv2.waitKey(0)    # fecha a janela. cv2.destroyAllWindows() <pre>2024-04-01 11:56:24.318 Python[30860:5062868] Warning: Window move completed without beginning\n</pre> In\u00a0[6]: Copied! <pre># Implemente sua resposta.......\n</pre> # Implemente sua resposta......."},{"location":"aulas/PDI/lab15/EventMouse.html#event-mouse","title":"Event Mouse\u00b6","text":"<p>Podemos criar uma interface gr\u00e1fica e interatividade com o mouse, nesse caso, baseado em eventos.</p> <p>Toda a vez que ocorre um evento do mouse, uma fun\u00e7\u00e3o de callback \u00e9 executada no c\u00f3digo.</p> <p>Vamos ver isso funcionado no c\u00f3digo.</p> <p>Lembrete: No notebook pode travar, \u00e9 melhor rodar em um arquivo .py</p>"},{"location":"aulas/PDI/lab15/EventMouse.html#desafio-1","title":"Desafio 1\u00b6","text":"<p>O nosso c\u00f3digo est\u00e1 funcionando mas, note que n\u00e3o mandamos realizar nenhum a\u00e7\u00e3o na chamada do callback.</p> <p>Implemente um c\u00f3digo que troca a cor da imagem a cada click.</p>"},{"location":"aulas/PDI/lab15/EventMouse.html#projeto-1","title":"Projeto 1\u00b6","text":"<p>Vamos criar o nosso proprio color picker.</p> <p>Ao clicar sobre a imagem, aparece a intensidade do pixel em RGB.</p>"},{"location":"aulas/PDI/lab15/EventMouse.html#desafio-2","title":"Desafio 2\u00b6","text":"<p>Vamos melhorar um pouco esse color picker...</p> <p>Fa\u00e7a um script que ao clicar sobre a imagem, aparece a intensidade do pixel em RGB e abre uma nova janela (100x100) com essa cor.</p>"},{"location":"aulas/PDI/lab15/EventMouse.html#projeto-2","title":"Projeto 2\u00b6","text":"<p>Vamos implementar um c\u00f3digo que desenha um circulo na imagem conforme o mouse anda pela tela. (tipo Paint-Brush)</p>"},{"location":"aulas/PDI/lab15/EventMouse.html#desafio-3","title":"Desafio 3\u00b6","text":"<p>Ficou legal, mas ainda esta bem \"zoado\"...</p> <p>Melhore este c\u00f3digo, altere o c\u00f3digo para desenhar um circulo na imagem se o bot\u00e3o esquerdo estiver pressionado, quando solta o bot\u00e3o para de desenhar.</p> <p>Implemente tambem a fun\u00e7\u00e3o que limpa a tela quando o bot\u00e3o direto \u00e9 pressionado.</p>"},{"location":"aulas/PDI/lab15/EventMouse.html#projeto-3","title":"Projeto 3\u00b6","text":"<p>Vamos fazer um c\u00f3digo que marca dois pontos na tela com o bot\u00e3o esquerdo e tra\u00e7a uma reta. Quando clica com o direito zera.</p>"},{"location":"aulas/PDI/lab15/EventMouse.html#desafio-4","title":"Desafio 4\u00b6","text":"<p>A logica implementada acima n\u00e3o foi a mais otimizada... mas com base nele (ou n\u00e3o), fa\u00e7a um programa que calcula o angulo entre quais 3 pontos. O resultado deve ser exibido no tela.</p> <p>Dicas:</p> <pre><code>cv2.putText() para escrever na tela. \n\ncalculo do angulo: Se n\u00e3o lembra de trigonometria, n\u00e3o tem problema! Da um google de como calcular o angulo entre 2 linhas ou entre 3 pontos. por exemplo: https://manivannan-ai.medium.com/find-the-angle-between-three-points-from-2d-using-python-348c513e2cd</code></pre>"},{"location":"aulas/PDI/lab15/EventMouse.html#projeto-4","title":"Projeto 4\u00b6","text":"<p>A sele\u00e7\u00e3o de um regi\u00e3o de interesse nada mais \u00e9 que a determina\u00e7\u00e3o de das coordenadas iniciais e finais do boundbox.</p>"},{"location":"aulas/PDI/lab15/EventMouse.html#desafio-5","title":"Desafio 5\u00b6","text":"<p>Fa\u00e7a um script que o usuario define uma area de sele\u00e7\u00e3o. essa imagem \u00e9 aberta em uma nova janela e se for pressionado a tecla \"s\" salva a imagem no diretorio.</p> <p>Dicas:</p> <pre><code>cv2.imwrite() para salvar.\n\nif key == ord('s') : dar uma lida na fun\u00e7\u00e3o cv2.waiKey() e ord().  </code></pre>"},{"location":"aulas/PDI/lab16/dlib2.html","title":"Lab16 - Detector dlib","text":"<p>Objetivos da aula:</p> <ul> <li>apresentar e aplicar o dlib para detec\u00e7\u00e3o de face</li> </ul> <p>N\u00e3o se vive vive apenas de HAAR CASCADE</p> <p>Muito obrigado Viola e Jones! Se n\u00e3o fosse por voc\u00eas n\u00e3o teriamos hoje outras bibliotecas t\u00e3o incriveis para detec\u00e7\u00e3o de face quanto Haar Cascade.</p> <p>Atualmente temos dispon\u00edveis para uso outras diversas redes j\u00e1 treinadas para detec\u00e7\u00e3o n\u00e3o apenas de face mas tambem de m\u00e3os, corpo, objetos.....</p> <p>Vou destacar algumas redes:</p> <p>Dlib C++</p> <p>MTCNN</p> <p>Media Pipe</p> <p>Cada uma das redes acima aplica usam t\u00e9cnicas de machine learning na etapa de treinamento para realizar a detec\u00e7\u00e3o essas redes dentre outras coisas conseguem realizar a dete\u00e7\u00e3o de face. Hoje vamos da destaque especial para a rede Dlid. Como sugest\u00e3o leia a documeta\u00e7\u00e3o e aprenda a usar as rede MTCNN e Media Pipe para descobrir qual \u00e9 mais r\u00e1pida, mais leve ou mais acurada.</p> In\u00a0[2]: Copied! <pre>## Vou fazer o download das imagens do laborat\u00f3rio diretamente do reposit\u00f3rio para usar no colab mais facil....\nimport requests\n\n# Definie o modulo e o laborat\u00f3rio\nmodulo ='PDI/'\nlaboratorio = 'lab16'\n\n# URL da API do GitHub para a pasta do reposit\u00f3rio\napi_url = \"https://api.github.com/repos/arnaldojr/cognitivecomputing/contents/material/aulas/\"\n\n# Monta a URL completa\nurl_completa = api_url + modulo + laboratorio\n\nprint(f\"Fazendo o download de: {url_completa}\")\n\n# Requisi\u00e7\u00e3o para obter a lista de arquivos na pasta\nresponse = requests.get(url_completa)\nfiles = response.json()\n\n# Fazer o download de cada arquivo de imagem\nfor file in files:\n    file_name = file['name']\n    if file_name.endswith(('.png', '.jpg', '.jpeg', '.mp4')):  # Adicione mais extens\u00f5es se necess\u00e1rio\n        file_url = file['download_url']\n        print(f\"Baixando {file_name}...\")\n        !wget -q {file_url} -P /content\n\nprint(\"Download conclu\u00eddo.\")\n\n!wget -q https://raw.githubusercontent.com/arnaldojr/cognitivecomputing/master/material/aulas/PDI/lab13/admiravelmundonovo.mp4 /content\n</pre> ## Vou fazer o download das imagens do laborat\u00f3rio diretamente do reposit\u00f3rio para usar no colab mais facil.... import requests  # Definie o modulo e o laborat\u00f3rio modulo ='PDI/' laboratorio = 'lab16'  # URL da API do GitHub para a pasta do reposit\u00f3rio api_url = \"https://api.github.com/repos/arnaldojr/cognitivecomputing/contents/material/aulas/\"  # Monta a URL completa url_completa = api_url + modulo + laboratorio  print(f\"Fazendo o download de: {url_completa}\")  # Requisi\u00e7\u00e3o para obter a lista de arquivos na pasta response = requests.get(url_completa) files = response.json()  # Fazer o download de cada arquivo de imagem for file in files:     file_name = file['name']     if file_name.endswith(('.png', '.jpg', '.jpeg', '.mp4')):  # Adicione mais extens\u00f5es se necess\u00e1rio         file_url = file['download_url']         print(f\"Baixando {file_name}...\")         !wget -q {file_url} -P /content  print(\"Download conclu\u00eddo.\")  !wget -q https://raw.githubusercontent.com/arnaldojr/cognitivecomputing/master/material/aulas/PDI/lab13/admiravelmundonovo.mp4 /content  <pre>Fazendo o download de: https://api.github.com/repos/arnaldojr/cognitivecomputing/contents/material/aulas/PDI/lab16\nBaixando boca.png...\nBaixando installdlib.png...\nBaixando landmark.png...\nBaixando lena.png...\nDownload conclu\u00eddo.\n</pre> In\u00a0[3]: Copied! <pre>%matplotlib inline\nimport cv2\nfrom matplotlib import pyplot as plt\n\nimport dlib\n\n# carrega uma imagem para detectar o rosto\nimg1 = cv2.imread('lena.png')\nimg1_gray = cv2.cvtColor(img1, cv2.COLOR_BGR2GRAY)\n\n# Inicializa o detector dlib\ndetector = dlib.get_frontal_face_detector()\n\n# Faz dete\u00e7\u00e3o das faces\nfaces = detector(img1_gray)\n\nprint(faces)\n\n\nfor face in faces:\n        x,y = face.left(), face.top()  # topo esquerda\n        x1,y1 = face.right(), face.bottom() #baixo direita\n\n        cv2.rectangle(img1, (x, y), (x1, y1), (0, 255, 0), 1)\n\n\n# Exibe imagem\nplt.figure(figsize = (10,10))\nplt.imshow(cv2.cvtColor(img1,cv2.COLOR_BGR2RGB)); plt.show();\n</pre> %matplotlib inline import cv2 from matplotlib import pyplot as plt  import dlib  # carrega uma imagem para detectar o rosto img1 = cv2.imread('lena.png') img1_gray = cv2.cvtColor(img1, cv2.COLOR_BGR2GRAY)  # Inicializa o detector dlib detector = dlib.get_frontal_face_detector()  # Faz dete\u00e7\u00e3o das faces faces = detector(img1_gray)  print(faces)   for face in faces:         x,y = face.left(), face.top()  # topo esquerda         x1,y1 = face.right(), face.bottom() #baixo direita          cv2.rectangle(img1, (x, y), (x1, y1), (0, 255, 0), 1)   # Exibe imagem plt.figure(figsize = (10,10)) plt.imshow(cv2.cvtColor(img1,cv2.COLOR_BGR2RGB)); plt.show();  <pre>rectangles[[(228, 228) (377, 377)]]\n</pre> In\u00a0[7]: Copied! <pre># usando o linux fica facil fazer o download...\nprint(f\"Baixando pesos da rede...\")\n\n!wget -q http://dlib.net/files/shape_predictor_68_face_landmarks.dat.bz2 /content\n!bzip2 -d shape_predictor_68_face_landmarks.dat.bz2\n\nprint(f\"Download completo.\")\n</pre> # usando o linux fica facil fazer o download... print(f\"Baixando pesos da rede...\")  !wget -q http://dlib.net/files/shape_predictor_68_face_landmarks.dat.bz2 /content !bzip2 -d shape_predictor_68_face_landmarks.dat.bz2  print(f\"Download completo.\") <pre>Baixando pesos da rede...\nbzip2: Output file shape_predictor_68_face_landmarks.dat already exists.\nDownload completo.\n</pre> In\u00a0[8]: Copied! <pre>%matplotlib inline\nimport cv2\nfrom matplotlib import pyplot as plt\n\nimport dlib\n\n# carrega uma imagem para detectar o rosto\nimg1 = cv2.imread('lena.png')\n\nimg1_gray = cv2.cvtColor(img1, cv2.COLOR_BGR2GRAY)\n\n# Inicializa o detector dlib\ndetector = dlib.get_frontal_face_detector()\n\n# Inicializa o identificador de Landmark identifier. Voc\u00ea ter esse arquiva na pasta do projeto\npredictor = dlib.shape_predictor(\"shape_predictor_68_face_landmarks.dat\")\n\n# Faz dete\u00e7\u00e3o das faces\nfaces = detector(img1_gray)\n\nprint(\"Numeros de faces detectadas: {}\".format(len(faces)))\n\n# para todas faces detectadas\nfor face in faces:\n  print(\"Left: {} Top: {} Right: {} Bottom: {}\".format(\n            face.left(), face.top(), face.right(), face.bottom()))\n  # Faz a predi\u00e7\u00e3o dos landmarks\n  shape = predictor(img1_gray, face)\n\n  # shape \u00e9 uma lista de tupla com as posi\u00e7\u00f5es (x, y) dos landmarks\n  print(\"\\nAo todo s\u00e3o: {} landmarks \\n\\nEsses s\u00e3o landmarks: {} \".format(len(shape.parts()) , shape.parts()))\n</pre> %matplotlib inline import cv2 from matplotlib import pyplot as plt  import dlib  # carrega uma imagem para detectar o rosto img1 = cv2.imread('lena.png')  img1_gray = cv2.cvtColor(img1, cv2.COLOR_BGR2GRAY)  # Inicializa o detector dlib detector = dlib.get_frontal_face_detector()  # Inicializa o identificador de Landmark identifier. Voc\u00ea ter esse arquiva na pasta do projeto predictor = dlib.shape_predictor(\"shape_predictor_68_face_landmarks.dat\")  # Faz dete\u00e7\u00e3o das faces faces = detector(img1_gray)  print(\"Numeros de faces detectadas: {}\".format(len(faces)))  # para todas faces detectadas for face in faces:   print(\"Left: {} Top: {} Right: {} Bottom: {}\".format(             face.left(), face.top(), face.right(), face.bottom()))   # Faz a predi\u00e7\u00e3o dos landmarks   shape = predictor(img1_gray, face)    # shape \u00e9 uma lista de tupla com as posi\u00e7\u00f5es (x, y) dos landmarks   print(\"\\nAo todo s\u00e3o: {} landmarks \\n\\nEsses s\u00e3o landmarks: {} \".format(len(shape.parts()) , shape.parts()))  <pre>Numeros de faces detectadas: 1\nLeft: 228 Top: 228 Right: 377 Bottom: 377\n\nAo todo s\u00e3o: 68 landmarks \n\nEsses s\u00e3o landmarks: points[(209, 268), (207, 291), (207, 315), (211, 337), (221, 357), (238, 373), (255, 385), (275, 394), (293, 395), (306, 388), (315, 373), (322, 358), (330, 343), (338, 326), (345, 311), (349, 294), (349, 279), (242, 250), (256, 244), (271, 243), (285, 247), (298, 254), (327, 257), (334, 251), (342, 248), (349, 246), (355, 250), (312, 271), (313, 287), (315, 303), (317, 319), (295, 326), (302, 328), (309, 330), (315, 329), (320, 326), (255, 267), (265, 261), (278, 262), (285, 272), (275, 275), (263, 274), (318, 273), (327, 263), (337, 262), (342, 268), (338, 275), (328, 276), (267, 350), (285, 348), (299, 345), (305, 347), (310, 345), (315, 347), (319, 349), (313, 357), (308, 362), (302, 364), (295, 364), (282, 360), (273, 352), (297, 352), (304, 353), (309, 352), (315, 351), (309, 351), (304, 352), (297, 352)] \n</pre> In\u00a0[9]: Copied! <pre>%matplotlib inline\nimport cv2\nfrom matplotlib import pyplot as plt\n\nimport dlib\n\n# carrega uma imagem para detectar o rosto\nimg1 = cv2.imread('lena.png')\n\nimg1_gray = cv2.cvtColor(img1, cv2.COLOR_BGR2GRAY)\n\n# Inicializa o detector dlib\ndetector = dlib.get_frontal_face_detector()\n\n# Inicializa o identificador de Landmark identifier. Voc\u00ea ter esse arquiva na pasta do projeto\npredictor = dlib.shape_predictor(\"shape_predictor_68_face_landmarks.dat\")\n\n# Faz dete\u00e7\u00e3o das faces\nfaces = detector(img1_gray)\n\n#print(\"Numeros de faces detectadas: {}\".format(len(faces)))\n\n# para todas faces detectadas\nfor face in faces:\n  # print(\"Left: {} Top: {} Right: {} Bottom: {}\".format(\n  #           face.left(), face.top(), face.right(), face.bottom()))\n  # Faz a predi\u00e7\u00e3o dos landmarks\n  shape = predictor(img1_gray, face)\n\n  # shape \u00e9 uma lista de tupla com as posi\u00e7\u00f5es (x, y) dos landmarks\n  # da uma olhada na quantidade total e nos 3 primeiros\n  # print(len(shape.parts()) , shape.parts()[0:3])\n\n###---- varendo os landmarks e fazendo a marca\u00e7\u00e3o na imagem----###\n\n  for i in range(len(shape.parts())): #S\u00e3o 68 landmark detectados por face\n      # Desenha um circulo e exibe o indice do landmark\n      # shape.part(i).x devolve o valor x da coordenada\n#      print(\"mark: {} coordenada x: {}, coordenada y: {}\".format(i+1, shape.part(i).x, shape.part(i).y))\n\n      # desenha um circulo na coordenada do laandmark\n      cv2.circle(img1, (shape.part(i).x, shape.part(i).y), 1, (0,255,0), thickness=-1)\n\n      # Escreve o indice de cada landmark na imagem\n      cv2.putText(img1, str(i+1), (shape.part(i).x,shape.part(i).y), fontFace=cv2.FONT_HERSHEY_SCRIPT_SIMPLEX, fontScale=0.3, color=(0, 0, 255))\n\n\n# Exibe imagem\nplt.figure(figsize = (10,10))\nplt.imshow(cv2.cvtColor(img1,cv2.COLOR_BGR2RGB)); plt.show();\n</pre> %matplotlib inline import cv2 from matplotlib import pyplot as plt  import dlib  # carrega uma imagem para detectar o rosto img1 = cv2.imread('lena.png')  img1_gray = cv2.cvtColor(img1, cv2.COLOR_BGR2GRAY)  # Inicializa o detector dlib detector = dlib.get_frontal_face_detector()  # Inicializa o identificador de Landmark identifier. Voc\u00ea ter esse arquiva na pasta do projeto predictor = dlib.shape_predictor(\"shape_predictor_68_face_landmarks.dat\")  # Faz dete\u00e7\u00e3o das faces faces = detector(img1_gray)  #print(\"Numeros de faces detectadas: {}\".format(len(faces)))  # para todas faces detectadas for face in faces:   # print(\"Left: {} Top: {} Right: {} Bottom: {}\".format(   #           face.left(), face.top(), face.right(), face.bottom()))   # Faz a predi\u00e7\u00e3o dos landmarks   shape = predictor(img1_gray, face)    # shape \u00e9 uma lista de tupla com as posi\u00e7\u00f5es (x, y) dos landmarks   # da uma olhada na quantidade total e nos 3 primeiros   # print(len(shape.parts()) , shape.parts()[0:3])  ###---- varendo os landmarks e fazendo a marca\u00e7\u00e3o na imagem----###    for i in range(len(shape.parts())): #S\u00e3o 68 landmark detectados por face       # Desenha um circulo e exibe o indice do landmark       # shape.part(i).x devolve o valor x da coordenada #      print(\"mark: {} coordenada x: {}, coordenada y: {}\".format(i+1, shape.part(i).x, shape.part(i).y))        # desenha um circulo na coordenada do laandmark       cv2.circle(img1, (shape.part(i).x, shape.part(i).y), 1, (0,255,0), thickness=-1)        # Escreve o indice de cada landmark na imagem       cv2.putText(img1, str(i+1), (shape.part(i).x,shape.part(i).y), fontFace=cv2.FONT_HERSHEY_SCRIPT_SIMPLEX, fontScale=0.3, color=(0, 0, 255))   # Exibe imagem plt.figure(figsize = (10,10)) plt.imshow(cv2.cvtColor(img1,cv2.COLOR_BGR2RGB)); plt.show();  In\u00a0[\u00a0]: Copied! <pre>### Implemente sua solu\u00e7\u00e3o aqui...\n</pre> ### Implemente sua solu\u00e7\u00e3o aqui...      In\u00a0[\u00a0]: Copied! <pre>### Implemente sua solu\u00e7\u00e3o em um arquivo .py\n\n## n\u00e3o fa\u00e7a no colab\n## n\u00e3o fa\u00e7a no colab\n## n\u00e3o fa\u00e7a no colab\n## n\u00e3o fa\u00e7a no colab\n## n\u00e3o fa\u00e7a no colab\n</pre> ### Implemente sua solu\u00e7\u00e3o em um arquivo .py  ## n\u00e3o fa\u00e7a no colab ## n\u00e3o fa\u00e7a no colab ## n\u00e3o fa\u00e7a no colab ## n\u00e3o fa\u00e7a no colab ## n\u00e3o fa\u00e7a no colab  In\u00a0[\u00a0]: Copied! <pre>### Implemente sua solu\u00e7\u00e3o em um arquivo .py\n</pre> ### Implemente sua solu\u00e7\u00e3o em um arquivo .py   In\u00a0[\u00a0]: Copied! <pre>import cv2\nimport dlib\n\n\ndef draw_text_info():\n    \"\"\"Fun\u00e7\u00e3o para escrever na tela as instru\u00e7\u00f5es de uso\"\"\"\n\n    menu_pos = (10, 20)\n    menu_pos_2 = (10, 40)\n    menu_pos_3 = (10, 60)\n    info_1 = \"Selecione com o mouse o objeto para rastreamento\"\n    info_2 = \"Use '1' para start, '2' para reset\"\n\n    cv2.putText(frame, info_1, menu_pos, cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255))\n    cv2.putText(frame, info_2, menu_pos_2, cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255))\n    if tracking_state:\n        cv2.putText(frame, \"Rastreando...\", menu_pos_3, cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0))\n    else:\n        cv2.putText(frame, \"N\u00e3o rastreando\", menu_pos_3, cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255))\n\n\n\npoints = []\n\n\n# Fun\u00e7\u00e3o de callback do mouse\ndef mouse_click(event, x, y, flags, param):\n    global points\n\n    if event == cv2.EVENT_LBUTTONDOWN:\n        points = [(x, y)]\n\n    elif event == cv2.EVENT_LBUTTONUP:\n        points.append((x, y))\n\n\n\ncapture = cv2.VideoCapture(0)\n\n\nwindow_name = \"tracking\"\ncv2.namedWindow(window_name)\ncv2.setMouseCallback(window_name, mouse_click)\n\n# Inicializa metodo de correla\u00e7\u00e3o de rastreamento\ntracker = dlib.correlation_tracker()\n\n# Variavel de estado\ntracking_state = False\n\nwhile True:\n    ret, frame = capture.read()\n\n    draw_text_info()\n\n    # Se objeto esta selecionado\n    if len(points) == 2:\n        cv2.rectangle(frame, points[0], points[1], (0, 0, 255), 3)\n        dlib_rectangle = dlib.rectangle(points[0][0], points[0][1], points[1][0], points[1][1])\n\n    # Se \u00e9 pra rastrear\n    if tracking_state == True:\n        tracker.update(frame)\n        pos = tracker.get_position()\n        cv2.rectangle(frame, (int(pos.left()), int(pos.top())), (int(pos.right()), int(pos.bottom())), (0, 255, 0), 3)\n\n    # l\u00ea teclado\n    key = 0xFF &amp; cv2.waitKey(1)\n\n    # '1' start\n    if key == ord(\"1\"):\n        if len(points) == 2:\n            # Start tracking:\n            tracker.start_track(frame, dlib_rectangle)\n            tracking_state = True\n            points = []\n\n    # '2' reset\n    if key == ord(\"2\"):\n        points = []\n        tracking_state = False\n\n    if key == ord('q'):\n        break\n\n    cv2.imshow(window_name, frame)\n\n# Release everything:\ncapture.release()\ncv2.destroyAllWindows()\n</pre> import cv2 import dlib   def draw_text_info():     \"\"\"Fun\u00e7\u00e3o para escrever na tela as instru\u00e7\u00f5es de uso\"\"\"      menu_pos = (10, 20)     menu_pos_2 = (10, 40)     menu_pos_3 = (10, 60)     info_1 = \"Selecione com o mouse o objeto para rastreamento\"     info_2 = \"Use '1' para start, '2' para reset\"      cv2.putText(frame, info_1, menu_pos, cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255))     cv2.putText(frame, info_2, menu_pos_2, cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255))     if tracking_state:         cv2.putText(frame, \"Rastreando...\", menu_pos_3, cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0))     else:         cv2.putText(frame, \"N\u00e3o rastreando\", menu_pos_3, cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255))    points = []   # Fun\u00e7\u00e3o de callback do mouse def mouse_click(event, x, y, flags, param):     global points      if event == cv2.EVENT_LBUTTONDOWN:         points = [(x, y)]      elif event == cv2.EVENT_LBUTTONUP:         points.append((x, y))    capture = cv2.VideoCapture(0)   window_name = \"tracking\" cv2.namedWindow(window_name) cv2.setMouseCallback(window_name, mouse_click)  # Inicializa metodo de correla\u00e7\u00e3o de rastreamento tracker = dlib.correlation_tracker()  # Variavel de estado tracking_state = False  while True:     ret, frame = capture.read()      draw_text_info()      # Se objeto esta selecionado     if len(points) == 2:         cv2.rectangle(frame, points[0], points[1], (0, 0, 255), 3)         dlib_rectangle = dlib.rectangle(points[0][0], points[0][1], points[1][0], points[1][1])      # Se \u00e9 pra rastrear     if tracking_state == True:         tracker.update(frame)         pos = tracker.get_position()         cv2.rectangle(frame, (int(pos.left()), int(pos.top())), (int(pos.right()), int(pos.bottom())), (0, 255, 0), 3)      # l\u00ea teclado     key = 0xFF &amp; cv2.waitKey(1)      # '1' start     if key == ord(\"1\"):         if len(points) == 2:             # Start tracking:             tracker.start_track(frame, dlib_rectangle)             tracking_state = True             points = []      # '2' reset     if key == ord(\"2\"):         points = []         tracking_state = False      if key == ord('q'):         break      cv2.imshow(window_name, frame)  # Release everything: capture.release() cv2.destroyAllWindows() In\u00a0[\u00a0]: Copied! <pre># Implemente sua solu\u00e7\u00e3o aqui......\n</pre> # Implemente sua solu\u00e7\u00e3o aqui......    In\u00a0[\u00a0]: Copied! <pre>from math import dist\nimport time\nimport numpy as np\nimport dlib\nimport cv2\n\n# definir constantes\nEYE_AR_THRESH = 0.3\nEYE_AR_CONSEC_FRAMES = 40\nCOUNTER = 0\n\ndef eye_aspect_ratio(eye):\n    # calcula a distancia euclidiana vertical os olhos\n    # vertical eye landmarks (x, y)-coordinates\n    A = dist(eye[1], eye[5])\n    B = dist(eye[2], eye[4])\n\n    # # calcula a distancia euclidiana horizontal os olhos\n    # eye landmark (x, y)-coordinates\n    C = dist(eye[0], eye[3])\n\n    # calcula uma taxa de abertura dos olhos\n    ear = (A + B) / (2.0 * C)\n\n    # return the eye aspect ratio\n    return ear\n\n\n# inicializa o detector e preditor do dlib\ndetector = dlib.get_frontal_face_detector()\npredictor = dlib.shape_predictor(\"shape_predictor_68_face_landmarks.dat\")\n\n# pega os \u00edndices do previsor, para olhos esquerdo e direito\n(lStart, lEnd) = (42, 48)\n(rStart, rEnd) = (36, 42)\n\n# inicializar v\u00eddeo\nvs = cv2.VideoCapture(0)\n#vs = cv2.VideoCapture(\"admiravelmundonovo.mp4\")\n\n\n# loop sobre os frames do v\u00eddeo\nwhile True:\n    ret, frame = vs.read()\n    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n\n    # detectar faces (grayscale)\n    rects = detector(gray, 0)\n\n    # loop nas detec\u00e7\u00f5es de faces\n    for rect in rects:\n\n        shape = predictor(gray, rect)\n        #devolve shape em uma lista coords\n        coords = np.zeros((shape.num_parts, 2), dtype=int)\n        for i in range(0,68): #S\u00e3o 68 landmark em cada face\n            coords[i] = (shape.part(i).x, shape.part(i).y)\n\n        # extrair coordenadas dos olhos e calcular a propor\u00e7\u00e3o de abertura\n        leftEye = coords[lStart:lEnd]\n        rightEye = coords[rStart:rEnd]\n\n        leftEAR = eye_aspect_ratio(leftEye)\n        rightEAR = eye_aspect_ratio(rightEye)\n\n        # ratio m\u00e9dia para os dois olhos\n        ear = (leftEAR + rightEAR) / 2.0\n\n        # convex hull cria um contorno com base nos pontos\n        leftEyeHull = cv2.convexHull(leftEye)\n        rightEyeHull = cv2.convexHull(rightEye)\n        cv2.drawContours(frame, [leftEyeHull], -1, (0, 255, 0), 1)\n        cv2.drawContours(frame, [rightEyeHull], -1, (0, 255, 0), 1)\n\n        # checar ratio x threshold\n        if ear &lt; EYE_AR_THRESH:\n            COUNTER += 1\n\n            # dentro dos crit\u00e9rios\n            if COUNTER &gt;= EYE_AR_CONSEC_FRAMES:\n                cv2.putText(frame, \"[ALERTA] FADIGA!\", (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)\n\n        # caso acima do threshold, resetar o contador e desligar o alarme\n        else:\n            COUNTER = 0\n            # desenhar a propor\u00e7\u00e3o de abertura dos olhos\n        cv2.putText(frame, \"EAR: {:.2f}\".format(ear), (300, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)\n\n    # Exibe resultado\n    cv2.imshow(\"Frame\", frame) # se estiver rodando local\n    key = cv2.waitKey(1) &amp; 0xFF\n    # tecla para sair do script \"q\"\n    if key == ord(\"q\"):\n        break\n\n# clean\ncv2.destroyAllWindows()\nvs.release()\n</pre> from math import dist import time import numpy as np import dlib import cv2  # definir constantes EYE_AR_THRESH = 0.3 EYE_AR_CONSEC_FRAMES = 40 COUNTER = 0  def eye_aspect_ratio(eye):     # calcula a distancia euclidiana vertical os olhos     # vertical eye landmarks (x, y)-coordinates     A = dist(eye[1], eye[5])     B = dist(eye[2], eye[4])      # # calcula a distancia euclidiana horizontal os olhos     # eye landmark (x, y)-coordinates     C = dist(eye[0], eye[3])      # calcula uma taxa de abertura dos olhos     ear = (A + B) / (2.0 * C)      # return the eye aspect ratio     return ear   # inicializa o detector e preditor do dlib detector = dlib.get_frontal_face_detector() predictor = dlib.shape_predictor(\"shape_predictor_68_face_landmarks.dat\")  # pega os \u00edndices do previsor, para olhos esquerdo e direito (lStart, lEnd) = (42, 48) (rStart, rEnd) = (36, 42)  # inicializar v\u00eddeo vs = cv2.VideoCapture(0) #vs = cv2.VideoCapture(\"admiravelmundonovo.mp4\")   # loop sobre os frames do v\u00eddeo while True:     ret, frame = vs.read()     gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)      # detectar faces (grayscale)     rects = detector(gray, 0)      # loop nas detec\u00e7\u00f5es de faces     for rect in rects:          shape = predictor(gray, rect)         #devolve shape em uma lista coords         coords = np.zeros((shape.num_parts, 2), dtype=int)         for i in range(0,68): #S\u00e3o 68 landmark em cada face             coords[i] = (shape.part(i).x, shape.part(i).y)          # extrair coordenadas dos olhos e calcular a propor\u00e7\u00e3o de abertura         leftEye = coords[lStart:lEnd]         rightEye = coords[rStart:rEnd]          leftEAR = eye_aspect_ratio(leftEye)         rightEAR = eye_aspect_ratio(rightEye)          # ratio m\u00e9dia para os dois olhos         ear = (leftEAR + rightEAR) / 2.0          # convex hull cria um contorno com base nos pontos         leftEyeHull = cv2.convexHull(leftEye)         rightEyeHull = cv2.convexHull(rightEye)         cv2.drawContours(frame, [leftEyeHull], -1, (0, 255, 0), 1)         cv2.drawContours(frame, [rightEyeHull], -1, (0, 255, 0), 1)          # checar ratio x threshold         if ear &lt; EYE_AR_THRESH:             COUNTER += 1              # dentro dos crit\u00e9rios             if COUNTER &gt;= EYE_AR_CONSEC_FRAMES:                 cv2.putText(frame, \"[ALERTA] FADIGA!\", (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)          # caso acima do threshold, resetar o contador e desligar o alarme         else:             COUNTER = 0             # desenhar a propor\u00e7\u00e3o de abertura dos olhos         cv2.putText(frame, \"EAR: {:.2f}\".format(ear), (300, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)      # Exibe resultado     cv2.imshow(\"Frame\", frame) # se estiver rodando local     key = cv2.waitKey(1) &amp; 0xFF     # tecla para sair do script \"q\"     if key == ord(\"q\"):         break  # clean cv2.destroyAllWindows() vs.release() In\u00a0[\u00a0]: Copied! <pre># Implemente sua solu\u00e7\u00e3o aqui......\n</pre> # Implemente sua solu\u00e7\u00e3o aqui......"},{"location":"aulas/PDI/lab16/dlib2.html#dlib","title":"Dlib\u00b6","text":"<p>A Dlib, al\u00e9m de realizar a predi\u00e7\u00e3o para detectar uma face, ela consegue ressaltar alguns pontos da face. Esses pontos de destaque s\u00e3o chamados de landmarks, a Dlib consegue encontrar 68 pontos da face como cantos dos olhos, sobrancelhas, boca e ponta do nariz.</p> <p>Cada landmark devolve uma coordenada da posi\u00e7\u00e3o (x,y) da imagem.</p>"},{"location":"aulas/PDI/lab16/dlib2.html#instalacao-dlib","title":"Instala\u00e7\u00e3o Dlib\u00b6","text":"<p>no linux, a instala\u00e7\u00e3o \u00e9 feita com o comando:</p> <pre>pip install dlib\n    \n</pre>"},{"location":"aulas/PDI/lab16/dlib2.html#verificacao-da-instalacao","title":"Verifica\u00e7\u00e3o da instala\u00e7\u00e3o\u00b6","text":"<p>pode ser necess\u00e1rio instalar alguns pacotes extras:</p> <pre>!sudo apt-get update\n!sudo apt-get install -y build-essential cmake\n!sudo apt-get install -y libopenblas-dev liblapack-dev\n!sudo apt-get install -y libx11-dev libgtk-3-dev\n!pip install dlib\n</pre>"},{"location":"aulas/PDI/lab16/dlib2.html#para-instalar-a-biblioteca-dlib-no-windows-localmente-voce-pode-seguir-estes-passos","title":"Para instalar a biblioteca dlib no <code>Windows localmente</code>, voc\u00ea pode seguir estes passos:\u00b6","text":"<ol> <li><p>Instale o CMake: dlib requer CMake para ser compilado. Voc\u00ea pode baixar e instalar o CMake a partir do site oficial: https://cmake.org/download/. Certifique-se de adicionar o CMake ao seu <code>PATH</code> durante a instala\u00e7\u00e3o.</p> </li> <li><p>Instale o Visual Studio: dlib precisa de um compilador C++ para ser compilado no Windows. Voc\u00ea pode usar o Visual Studio Community Edition, que \u00e9 gratuito para uso pessoal. Certifique-se de incluir o desenvolvimento em C++ durante a instala\u00e7\u00e3o. Voc\u00ea pode baix\u00e1-lo aqui: https://visualstudio.microsoft.com/vs/community/.</p> </li> <li><p>Instale a dlib: Abra um prompt de comando (CMD) ou PowerShell e execute o seguinte comando para instalar a dlib:</p> </li> </ol> <pre>pip install dlib\n</pre> <p>Esse comando deve compilar e instalar a dlib. Dependendo do seu sistema, esse processo pode levar algum tempo.</p> <ol> <li>Verifique a instala\u00e7\u00e3o: Ap\u00f3s a instala\u00e7\u00e3o, voc\u00ea pode verificar se a dlib foi instalada corretamente abrindo um terminal ou prompt de comando e executando o seguinte comando Python:</li> </ol> <pre>python -c \"import dlib; print(dlib.__version__)\"\n</pre> <p>Se tudo estiver correto, esse comando deve imprimir a vers\u00e3o da dlib instalada sem gerar erros.</p>"},{"location":"aulas/PDI/lab16/dlib2.html#detecao-de-faces-com-o-dlib","title":"Dete\u00e7\u00e3o de faces com o dlib\u00b6","text":"<p>Vamos fazer o nosso \"Hello World\" usando a Dlib, neste caso, vamos implementar um detector de face simples.</p> <p>Note que o m\u00e9todo \u00e9 bem similar ao que j\u00e1 conhecemos, a lista de faces detectadas \u00e9 um pouco diferente.</p>"},{"location":"aulas/PDI/lab16/dlib2.html#deteccao-dos-landmarks-da-face","title":"Detec\u00e7\u00e3o dos landmarks da face\u00b6","text":"<p>Para predi\u00e7\u00e3o dos landmarks uma rede neural j\u00e1 treinada \u00e9 utilizada, ser\u00e3o preditos 68 pontos da face.</p> <p>Para carregar os pesos da rede \u00e9 necess\u00e1rio fazer o download em:</p> <p>hape_predictor_68_face_landmarks.dat</p>"},{"location":"aulas/PDI/lab16/dlib2.html#dlib-positions","title":"Dlib positions\u00b6","text":"<ul> <li>(\"mouth\", (48, 68)),</li> <li>(\"right_eyebrow\", (17, 22)),</li> <li>(\"left_eyebrow\", (22, 27)),</li> <li>(\"right_eye\", (36, 42)),</li> <li>(\"left_eye\", (42, 48)),</li> <li>(\"nose\", (27, 35)),</li> <li>(\"jaw\", (0, 17))</li> </ul>"},{"location":"aulas/PDI/lab16/dlib2.html#desafio-1","title":"Desafio 1\u00b6","text":"<p>Implemente um c\u00f3digo que faz o crop de uma das regi\u00f5es preditas.</p> <p>Exemplo: crop da boca, sobrancelha, olho, nariz ou boca.</p>"},{"location":"aulas/PDI/lab16/dlib2.html#desafio-2","title":"Desafio 2\u00b6","text":"<p>Fa\u00e7a um c\u00f3digo capaz de detectar em tempo real as landmarks face pela webcam.</p>"},{"location":"aulas/PDI/lab16/dlib2.html#nao-faca-no-colab","title":"N\u00e3o fa\u00e7a no colab\u00b6","text":""},{"location":"aulas/PDI/lab16/dlib2.html#desafio-extra","title":"Desafio extra\u00b6","text":"<p>Altere o aquivo de pesos da rede para rede shape_predictor_5_face_landmarks e an\u00e1lise o tempo de resposta da rede. Ficou mais r\u00e1pida a detec\u00e7\u00e3o, a mesma coisa ou mais lenta?</p>"},{"location":"aulas/PDI/lab16/dlib2.html#tracking","title":"Tracking\u00b6","text":"<p>O tracking de objetos ou de faces possui diversas aplica\u00e7\u00f5es.O rastreamento de objetos tenta estimar a trajet\u00f3ria do alvo ao longo da sequ\u00eancia de v\u00eddeo onde apenas a localiza\u00e7\u00e3o inicial de um alvo \u00e9 conhecida. Basicamente o custo computacional para realiza\u00e7\u00e3o de rastreamento de um objeto \u00e9 muito menor, o que \u00e9 cr\u00edtico em aplicativos em tempo real, comparado ao custo computacional para a detec\u00e7\u00e3o de um objeto, onde a cada frame \u00e9 realizado a detec\u00e7\u00e3o do zero.</p> <p>Uma t\u00e9cnica muito poderosa para a realiza\u00e7\u00e3o de rastreamento \u00e9 DCF (discriminative correlation filter).A biblioteca dlib implementa um rastreador baseado em DCF, que \u00e9 f\u00e1cil de usar para rastreamento de faces ou objetos.</p> <p>Artigo bacana para se aprofundar na teoria: https://arxiv.org/pdf/1611.08461.pdf</p>"},{"location":"aulas/PDI/lab16/dlib2.html#rastreamento-de-objetos","title":"Rastreamento de objetos\u00b6","text":""},{"location":"aulas/PDI/lab16/dlib2.html#desafio-4","title":"Desafio 4\u00b6","text":"<p>Com base no c\u00f3digo acima, implemente um c\u00f3digo que faz o tracking de face</p>"},{"location":"aulas/PDI/lab16/dlib2.html#detector-de-fadiga","title":"Detector de fadiga\u00b6","text":"<p>O detector de fadiga pode ser elaborado a partir a abertura dos olhos, o c\u00f3digo a baixo foi inspirado no link: Artigo de ref\u00eancia</p> <p>Al\u00e9m deste artigo, vamos utilizar algumas outras fun\u00e7\u00f5es da OpenCV que ainda n\u00e3o conhecemos.</p> <p>cv2.convexHull = Cria um contorno com base nos pontos. https://learnopencv.com/convex-hull-using-opencv-in-python-and-c/</p>"},{"location":"aulas/PDI/lab16/dlib2.html#dlib-positions","title":"Dlib positions\u00b6","text":"<ul> <li>(\"mouth\", (48, 68)),</li> <li>(\"right_eyebrow\", (17, 22)),</li> <li>(\"left_eyebrow\", (22, 27)),</li> <li>(\"right_eye\", (36, 42)),</li> <li>(\"left_eye\", (42, 48)),</li> <li>(\"nose\", (27, 35)),</li> <li>(\"jaw\", (0, 17))</li> </ul>"},{"location":"aulas/PDI/lab16/dlib2.html#desafio-5","title":"Desafio 5\u00b6","text":"<p>Inspirado na solu\u00e7\u00e3o do detector de fadiga, implemente um c\u00f3digo que faz a dete\u00e7\u00e3o de emo\u00e7\u00e3o. Ou seja, detecta se a pessoa esta sorrindo ou n\u00e3o.</p>"},{"location":"aulas/PDI/lab17/mediapipe.html","title":"Lab17 - Mediapipe","text":"In\u00a0[\u00a0]: Copied! <pre>## instala\u00e7\u00e3o via pip\n\n#!pip install mediapipe==0.10.9\n</pre> ## instala\u00e7\u00e3o via pip  #!pip install mediapipe==0.10.9 In\u00a0[11]: Copied! <pre>import mediapipe as mp\nimport cv2\nimport numpy as np\nimport matplotlib.pyplot as plt\n</pre> import mediapipe as mp import cv2 import numpy as np import matplotlib.pyplot as plt In\u00a0[17]: Copied! <pre># Configura\u00e7\u00f5es de desenho\nmp_drawing = mp.solutions.drawing_utils\nmp_drawing_styles = mp.solutions.drawing_styles\nmp_face_mesh = mp.solutions.face_mesh\n\n# Crie uma inst\u00e2ncia do objeto FaceMesh\nface_mesh = mp_face_mesh.FaceMesh(\n    static_image_mode=True,\n    max_num_faces=1,\n    refine_landmarks=True,\n    min_detection_confidence=0.5)\n\nfile = 'lena.png'\n\n# Leia o arquivo de imagem com cv2 e converta de BGR para RGB\nimage = cv2.imread(file)\nresults = face_mesh.process(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n\nface_found = results.multi_face_landmarks\nprint(f'foram encontradas: {len(face_found)} faces na imagem')\n\nif face_found:\n    # Crie uma c\u00f3pia da imagem\n    annotated_image = image.copy()\n\n    # Desenha as landmarks e conex\u00f5es\n    mp_drawing.draw_landmarks(\n        image=annotated_image,\n        landmark_list=results.multi_face_landmarks[0],\n        connections=mp_face_mesh.FACEMESH_TESSELATION,\n        landmark_drawing_spec=None,\n        connection_drawing_spec=mp_drawing_styles.get_default_face_mesh_tesselation_style())\n\n    # Plota a imagem\n    plt.figure(figsize=(10, 10))\n    plt.imshow(cv2.cvtColor(annotated_image, cv2.COLOR_BGR2RGB))\n    plt.axis('off')\n    plt.show()\n\n# N\u00e3o se esque\u00e7a de liberar os recursos do objeto face_mesh quando terminar\n# face_mesh.close()\n</pre>  # Configura\u00e7\u00f5es de desenho mp_drawing = mp.solutions.drawing_utils mp_drawing_styles = mp.solutions.drawing_styles mp_face_mesh = mp.solutions.face_mesh  # Crie uma inst\u00e2ncia do objeto FaceMesh face_mesh = mp_face_mesh.FaceMesh(     static_image_mode=True,     max_num_faces=1,     refine_landmarks=True,     min_detection_confidence=0.5)  file = 'lena.png'  # Leia o arquivo de imagem com cv2 e converta de BGR para RGB image = cv2.imread(file) results = face_mesh.process(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))  face_found = results.multi_face_landmarks print(f'foram encontradas: {len(face_found)} faces na imagem')  if face_found:     # Crie uma c\u00f3pia da imagem     annotated_image = image.copy()      # Desenha as landmarks e conex\u00f5es     mp_drawing.draw_landmarks(         image=annotated_image,         landmark_list=results.multi_face_landmarks[0],         connections=mp_face_mesh.FACEMESH_TESSELATION,         landmark_drawing_spec=None,         connection_drawing_spec=mp_drawing_styles.get_default_face_mesh_tesselation_style())      # Plota a imagem     plt.figure(figsize=(10, 10))     plt.imshow(cv2.cvtColor(annotated_image, cv2.COLOR_BGR2RGB))     plt.axis('off')     plt.show()  # N\u00e3o se esque\u00e7a de liberar os recursos do objeto face_mesh quando terminar # face_mesh.close()  <pre>I0000 00:00:1712871282.566201       1 gl_context.cc:344] GL version: 2.1 (2.1 Metal - 88), renderer: Apple M2\n</pre> <pre>foram encontradas: 1 faces na imagem\n</pre> In\u00a0[\u00a0]: Copied! <pre># seu c\u00f3digo aqui...\n</pre> # seu c\u00f3digo aqui... In\u00a0[\u00a0]: Copied! <pre># seu c\u00f3digo aqui...\n</pre> # seu c\u00f3digo aqui... In\u00a0[20]: Copied! <pre>mp_drawing = mp.solutions.drawing_utils\nmp_hands = mp.solutions.hands\n</pre> mp_drawing = mp.solutions.drawing_utils mp_hands = mp.solutions.hands In\u00a0[21]: outputPrepend Copied! <pre>cap = cv2.VideoCapture(0)\n\nwith mp_hands.Hands(min_detection_confidence=0.8, min_tracking_confidence=0.5) as hands: \n    while cap.isOpened():\n        ret, frame = cap.read()\n        \n        # BGR 2 RGB\n        image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n        \n        # Flip on horizontal\n        image = cv2.flip(image, 1)\n        \n        # Set flag\n        image.flags.writeable = False\n        \n        # Detections\n        results = hands.process(image)\n        \n        # Set flag to true\n        image.flags.writeable = True\n        \n        # RGB 2 BGR\n        image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n        \n        # Rendering results\n        if results.multi_hand_landmarks:\n            for num, hand in enumerate(results.multi_hand_landmarks):\n                mp_drawing.draw_landmarks(image, hand, mp_hands.HAND_CONNECTIONS, \n                                        mp_drawing.DrawingSpec(color=(121, 22, 76), thickness=2, circle_radius=4),\n                                        mp_drawing.DrawingSpec(color=(250, 44, 250), thickness=2, circle_radius=2),\n                                         )\n            \n        \n        cv2.imshow('Hand Tracking', image)\n\n        if cv2.waitKey(10) &amp; 0xFF == ord('q'):\n            break\n\ncap.release()\ncv2.destroyAllWindows()\n</pre> cap = cv2.VideoCapture(0)  with mp_hands.Hands(min_detection_confidence=0.8, min_tracking_confidence=0.5) as hands:      while cap.isOpened():         ret, frame = cap.read()                  # BGR 2 RGB         image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)                  # Flip on horizontal         image = cv2.flip(image, 1)                  # Set flag         image.flags.writeable = False                  # Detections         results = hands.process(image)                  # Set flag to true         image.flags.writeable = True                  # RGB 2 BGR         image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)                  # Rendering results         if results.multi_hand_landmarks:             for num, hand in enumerate(results.multi_hand_landmarks):                 mp_drawing.draw_landmarks(image, hand, mp_hands.HAND_CONNECTIONS,                                          mp_drawing.DrawingSpec(color=(121, 22, 76), thickness=2, circle_radius=4),                                         mp_drawing.DrawingSpec(color=(250, 44, 250), thickness=2, circle_radius=2),                                          )                               cv2.imshow('Hand Tracking', image)          if cv2.waitKey(10) &amp; 0xFF == ord('q'):             break  cap.release() cv2.destroyAllWindows() <pre>I0000 00:00:1712871632.333893       1 gl_context.cc:344] GL version: 2.1 (2.1 Metal - 88), renderer: Apple M2\n2024-04-11 18:40:32.487 Python[40047:7578102] WARNING: Secure coding is automatically enabled for restorable state! However, not on all supported macOS versions of this application. Opt-in to secure coding explicitly by implementing NSApplicationDelegate.applicationSupportsSecureRestorableState:.\n</pre> In\u00a0[22]: Copied! <pre>import cv2\nimport mediapipe\nimport time\n\nctime=0\nptime=0\n\ncap=cv2.VideoCapture(0)\n\nmedhands=mediapipe.solutions.hands\nhands=medhands.Hands(max_num_hands=1,min_detection_confidence=0.7)\ndraw=mediapipe.solutions.drawing_utils\n\nwhile True:\n    success, img=cap.read() #pega um frame da imagem\n    \n    img = cv2.flip(img,1) # inverte a imagem\n    \n    imgrgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)  \n    \n    \n    #realiza a detec\u00e7\u00e3o da m\u00e3o na imagem\n    res = hands.process(imgrgb)\n    \n    lmlist=[]\n    tipids=[4,8,12,16,20] # lista com as pontas dos dedos\n    \n    #desenha no canto da tela um retangulo, os numeros v\u00e3o aparecer aqui\n    cv2.rectangle(img,(20,350),(90,440),(0,255,204),cv2.FILLED)\n    cv2.rectangle(img,(20,350),(90,440),(0,0,0),5)\n    \n    ## se detectar alguma m\u00e3o entra no if \n    if res.multi_hand_landmarks:\n        for handlms in res.multi_hand_landmarks:\n            for id,lm in enumerate(handlms.landmark):\n                \n                h,w,c= img.shape\n                cx,cy=int(lm.x * w) , int(lm.y * h)\n                lmlist.append([id,cx,cy])\n                if len(lmlist) != 0 and len(lmlist)==21:\n                    fingerlist=[]\n                    \n                    #thumb and dealing with flipping of hands\n                    if lmlist[12][1] &gt; lmlist[20][1]:\n                        if lmlist[tipids[0]][1] &gt; lmlist[tipids[0]-1][1]:\n                            fingerlist.append(1)\n                        else:\n                            fingerlist.append(0)\n                    else:\n                        if lmlist[tipids[0]][1] &lt; lmlist[tipids[0]-1][1]:\n                            fingerlist.append(1)\n                        else:\n                            fingerlist.append(0)\n                    \n                    #others\n                    for id in range (1,5):\n                        if lmlist[tipids[id]][2] &lt; lmlist[tipids[id]-2][2]:\n                            fingerlist.append(1)\n                        else:\n                            fingerlist.append(0)\n                    \n                    \n                    if len(fingerlist)!=0:  # se a lista for diferente de zero ent\u00e3o \n                        fingercount=fingerlist.count(1) # conta quantidade de dedos\n                    \n                    # escreve na tela a quantidade detectada\n                    cv2.putText(img,str(fingercount),(25,430),cv2.FONT_HERSHEY_PLAIN,6,(0,0,0),5)\n                    \n                #change color of points and lines\n                draw.draw_landmarks(img,handlms,medhands.HAND_CONNECTIONS,draw.DrawingSpec(color=(0,255,204),thickness=2,circle_radius=2),draw.DrawingSpec(color=(0,0,0),thickness=2,circle_radius=3))\n          \n    cv2.imshow(\"hand gestures\",img)\n    \n    #press q to quit\n    if cv2.waitKey(1) == ord('q'):\n        break\ncap.release()   \ncv2.destroyAllWindows()\n</pre> import cv2 import mediapipe import time  ctime=0 ptime=0  cap=cv2.VideoCapture(0)  medhands=mediapipe.solutions.hands hands=medhands.Hands(max_num_hands=1,min_detection_confidence=0.7) draw=mediapipe.solutions.drawing_utils  while True:     success, img=cap.read() #pega um frame da imagem          img = cv2.flip(img,1) # inverte a imagem          imgrgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)                 #realiza a detec\u00e7\u00e3o da m\u00e3o na imagem     res = hands.process(imgrgb)          lmlist=[]     tipids=[4,8,12,16,20] # lista com as pontas dos dedos          #desenha no canto da tela um retangulo, os numeros v\u00e3o aparecer aqui     cv2.rectangle(img,(20,350),(90,440),(0,255,204),cv2.FILLED)     cv2.rectangle(img,(20,350),(90,440),(0,0,0),5)          ## se detectar alguma m\u00e3o entra no if      if res.multi_hand_landmarks:         for handlms in res.multi_hand_landmarks:             for id,lm in enumerate(handlms.landmark):                                  h,w,c= img.shape                 cx,cy=int(lm.x * w) , int(lm.y * h)                 lmlist.append([id,cx,cy])                 if len(lmlist) != 0 and len(lmlist)==21:                     fingerlist=[]                                          #thumb and dealing with flipping of hands                     if lmlist[12][1] &gt; lmlist[20][1]:                         if lmlist[tipids[0]][1] &gt; lmlist[tipids[0]-1][1]:                             fingerlist.append(1)                         else:                             fingerlist.append(0)                     else:                         if lmlist[tipids[0]][1] &lt; lmlist[tipids[0]-1][1]:                             fingerlist.append(1)                         else:                             fingerlist.append(0)                                          #others                     for id in range (1,5):                         if lmlist[tipids[id]][2] &lt; lmlist[tipids[id]-2][2]:                             fingerlist.append(1)                         else:                             fingerlist.append(0)                                                               if len(fingerlist)!=0:  # se a lista for diferente de zero ent\u00e3o                          fingercount=fingerlist.count(1) # conta quantidade de dedos                                          # escreve na tela a quantidade detectada                     cv2.putText(img,str(fingercount),(25,430),cv2.FONT_HERSHEY_PLAIN,6,(0,0,0),5)                                      #change color of points and lines                 draw.draw_landmarks(img,handlms,medhands.HAND_CONNECTIONS,draw.DrawingSpec(color=(0,255,204),thickness=2,circle_radius=2),draw.DrawingSpec(color=(0,0,0),thickness=2,circle_radius=3))                cv2.imshow(\"hand gestures\",img)          #press q to quit     if cv2.waitKey(1) == ord('q'):         break cap.release()    cv2.destroyAllWindows() <pre>I0000 00:00:1712871645.820581       1 gl_context.cc:344] GL version: 2.1 (2.1 Metal - 88), renderer: Apple M2\n</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre>"},{"location":"aulas/PDI/lab17/mediapipe.html#mediapipe","title":"Mediapipe\u00b6","text":"<p>Objetivos da aula:</p> <ul> <li>Apresentar e aplicar a biblioteca <code>mediapipe</code></li> </ul> <p>Mediapipe \u00e9 uma biblioteca de processamento de m\u00eddia de c\u00f3digo aberto desenvolvida pelo Google, que fornece uma ampla variedade de algoritmos e ferramentas de vis\u00e3o computacional para an\u00e1lise de dados em tempo real.</p> <p>A biblioteca \u00e9 implementada em C++ e Python, com suporte para processamento em CPU e GPU.</p> <p>Entre as funcionalidades oferecidas pela biblioteca Mediapipe, destacam-se a detec\u00e7\u00e3o de <code>keypoints</code>, <code>tracking</code>, <code>classifica\u00e7\u00e3o de gestos</code>, <code>reconhecimento facial</code>, <code>pose estimation</code>, <code>detec\u00e7\u00e3o de objetos</code> e <code>segmenta\u00e7\u00e3o de imagem</code>.</p> <p>A implementa\u00e7\u00e3o desses algoritmos \u00e9 feita utilizando t\u00e9cnicas de aprendizado de m\u00e1quina e redes neurais profundas, incluindo redes neurais convolucionais e redes de grafos.</p>"},{"location":"aulas/PDI/lab17/mediapipe.html#instalacao","title":"Instala\u00e7\u00e3o\u00b6","text":"<p>A instala\u00e7\u00e3o \u00e9 simples. Mas pode acontecer incompatibilidade de vers\u00f5es entre o python e algumas dependencias. Caso n\u00e3o consiga instalar via <code>pip</code> ser\u00e1 necess\u00e1rio investigar o erro para entender o que precisa ser ajustado na instala\u00e7\u00e3o.</p> <p>No meu caso, usando Mac M2, estou usando:</p> <ul> <li>python 3.9.6</li> <li>mediapipe==0.10.9</li> </ul>"},{"location":"aulas/PDI/lab17/mediapipe.html#primeiros-passos","title":"Primeiros passos\u00b6","text":"<p>O site oficial da documenta\u00e7\u00e3o do Mediapipe \u00e9 o https://mediapipe.dev/.</p> <p>J\u00e1 existe bastante conte\u00fado contendo informa\u00e7\u00f5es detalhadas sobre como utilizar cada uma das funcionalidades da biblioteca, incluindo tutoriais em v\u00eddeo e em texto, exemplos de c\u00f3digo, e muito mais.</p> <p>Al\u00e9m disso, a p\u00e1gina oferece uma ampla variedade de recursos adicionais, como f\u00f3runs de discuss\u00e3o, bibliotecas de modelos pr\u00e9-treinados, e outros materiais \u00fateis para desenvolvedores de vis\u00e3o computacional.</p>"},{"location":"aulas/PDI/lab17/mediapipe.html#face","title":"Face\u00b6","text":"<p>O <code>Mediapipe face mesh</code> \u00e9 um recurso da biblioteca Mediapipe que permite a detec\u00e7\u00e3o e rastreamento de faces.</p>"},{"location":"aulas/PDI/lab17/mediapipe.html#desafio1","title":"desafio1\u00b6","text":"<p>Fa\u00e7a os ajustes para o c\u00f3digo rodar com webcam.</p>"},{"location":"aulas/PDI/lab17/mediapipe.html#desafio-2","title":"Desafio 2\u00b6","text":"<p>Implemente uma solu\u00e7\u00e3o que detecta se a pessoa est\u00e1 de olhos abertos ou fechados.</p>"},{"location":"aulas/PDI/lab17/mediapipe.html#tracking-de-mao","title":"Tracking de m\u00e3o\u00b6","text":"<p>O <code>Mediapipe Hand Tracking</code> \u00e9 um recurso da biblioteca Mediapipe que permite a detec\u00e7\u00e3o e rastreamento das m\u00e3os em tempo real, a partir de uma entrada de v\u00eddeo ou imagem.</p> <p>Esse recurso utiliza uma <code>rede neural</code> que \u00e9 <code>treinada</code> para reconhecer pontos de refer\u00eancia nas m\u00e3os, como a base dos dedos, pontas dos dedos e pulso.</p>"},{"location":"aulas/PDI/lab17/mediapipe.html#contagem-dos-dedos","title":"contagem dos dedos\u00b6","text":"<p>adaptado de: https://github.com/ANANTH-SWAMY/NUMBER-DETECTION-WITH-MEDIAPIPE</p>"},{"location":"aulas/PDI/lab17/mediapipe.html#desafio-3","title":"Desafio 3\u00b6","text":"<p>O mediapipe possui um modo para detec\u00e7\u00e3o de pose, o dense pose. Implemente uma solu\u00e7\u00e3o que realiza</p>"},{"location":"aulas/PDI/lab17/mediapipe_face.html","title":"Mediapipe face","text":"In\u00a0[\u00a0]: Copied! <pre>import cv2\nimport mediapipe as mp\n</pre> import cv2 import mediapipe as mp In\u00a0[\u00a0]: Copied! <pre>\n</pre> In\u00a0[\u00a0]: Copied! <pre>mp_face_mesh = mp.solutions.face_mesh\nface_mesh = mp_face_mesh.FaceMesh()\n</pre> mp_face_mesh = mp.solutions.face_mesh face_mesh = mp_face_mesh.FaceMesh() In\u00a0[\u00a0]: Copied! <pre>cap = cv2.VideoCapture(0)\n</pre> cap = cv2.VideoCapture(0) In\u00a0[\u00a0]: Copied! <pre>\n</pre> In\u00a0[\u00a0]: Copied! <pre>while True:\n\n    ret,frame = cap.read()\n\n    if ret is not True:\n        break\n\n    h,w,_ = frame.shape\n    rgb_image = cv2.cvtColor(frame,cv2.COLOR_BGR2RGB)\n\n\n    ressult = face_mesh.process(rgb_image)\n\n    for facial_landmarks in ressult.multi_face_landmarks:\n        for i in range(0,468):\n            pt1 = facial_landmarks.landmark[i]\n            x = int(pt1.x*w)\n            y = int(pt1.y*h)\n            cv2.circle(frame, (x,y), 1,(0,255,0),-1)\n    \n    cv2.imshow(\"Img\", frame)\n\n    key = cv2.waitKey(1)\n    if key == 27:           \n        break               \n</pre> while True:      ret,frame = cap.read()      if ret is not True:         break      h,w,_ = frame.shape     rgb_image = cv2.cvtColor(frame,cv2.COLOR_BGR2RGB)       ressult = face_mesh.process(rgb_image)      for facial_landmarks in ressult.multi_face_landmarks:         for i in range(0,468):             pt1 = facial_landmarks.landmark[i]             x = int(pt1.x*w)             y = int(pt1.y*h)             cv2.circle(frame, (x,y), 1,(0,255,0),-1)          cv2.imshow(\"Img\", frame)      key = cv2.waitKey(1)     if key == 27:                    break                In\u00a0[\u00a0]: Copied! <pre>cv2.destroyAllWindows()\ncap.release()\n</pre> cv2.destroyAllWindows() cap.release()"},{"location":"aulas/PDI/lab18/index.html","title":"Lab18 - Yolo","text":""},{"location":"aulas/PDI/lab18/index.html#modulo-dnn-opencv","title":"Modulo DNN OpenCV","text":"<p>Acesso os c\u00f3digos python para testar:</p> <ul> <li>Yolo - imagem</li> <li>Yolo - video</li> </ul>"},{"location":"aulas/PDI/lab18/index.html#deteccao-de-objetos-com-yolov5-e-opencv-em-python","title":"Detec\u00e7\u00e3o de Objetos com YOLOv5 e OpenCV em Python","text":"<p>Vamos compreender o uso do modelo YOLOv5 para detec\u00e7\u00e3o de objetos em imagens usando a OpenCV. </p> <p>O <code>m\u00f3dulo DNN (Deep Neural Network) do OpenCV</code> \u00e9 uma biblioteca que oferece uma interface para <code>executar infer\u00eancias a partir de redes neurais</code>. Ele suporta uma variedade de frameworks de aprendizado profundo, incluindo <code>TensorFlow, Caffe, Torch/PyTorch, e Darknet (YOLO)</code>. A principal vantagem do m\u00f3dulo DNN \u00e9 permitir o uso de modelos pr\u00e9-treinados de deep learning em aplica\u00e7\u00f5es de vis\u00e3o computacional diretamente com o OpenCV, sem depender dos frameworks originais.</p>"},{"location":"aulas/PDI/lab18/index.html#importacao-das-bibliotecas-necessarias","title":"Importa\u00e7\u00e3o das Bibliotecas Necess\u00e1rias","text":"<pre><code>import cv2\nimport numpy as np\n</code></pre> <ul> <li><code>cv2</code>: Biblioteca OpenCV para opera\u00e7\u00f5es de vis\u00e3o computacional.</li> <li><code>numpy</code>: Biblioteca para manipula\u00e7\u00e3o de arrays e matrizes de alta performance.</li> </ul>"},{"location":"aulas/PDI/lab18/index.html#carregamento-do-modelo-yolov5","title":"Carregamento do Modelo YOLOv5","text":"<pre><code>net = cv2.dnn.readNet('yolov5m.onnx')\n</code></pre> <p>Carrega o modelo pr\u00e9-treinado YOLOv5 (formato ONNX). O modelo \u00e9 respons\u00e1vel por realizar as predi\u00e7\u00f5es das localiza\u00e7\u00f5es dos objetos.</p> <p>A yolov5 disponibiliza algumas vers\u00f5es:</p> <ul> <li><code>yolov5m</code>: Modelo m\u00e9dio, oferece um equil\u00edbrio entre velocidade e precis\u00e3o. \u00c9 adequado para aplica\u00e7\u00f5es que necessitam de uma boa precis\u00e3o, mas ainda assim mant\u00eam a necessidade de ser relativamente r\u00e1pido. \u00c9 maior que o yolov5s, resultando em uma precis\u00e3o melhorada, por\u00e9m com uma velocidade um pouco reduzida.</li> <li><code>yolov5n</code>: Modelo nano, \u00e9 a vers\u00e3o mais leve e r\u00e1pida, projetada para ser extremamente r\u00e1pida e para funcionar em dispositivos com recursos limitados, como smartphones e dispositivos IoT. Ele sacrifica precis\u00e3o em prol de velocidade e baixo consumo de recursos.</li> <li><code>yolov5s</code>: Modelo pequeno, \u00e9 a vers\u00e3o que busca um equil\u00edbrio entre velocidade e uso de recursos, mantendo uma precis\u00e3o razo\u00e1vel. \u00c9 ideal para aplica\u00e7\u00f5es que necessitam de uma detec\u00e7\u00e3o de objetos razoavelmente r\u00e1pida e eficiente em termos de recursos.</li> </ul> <p>Warning</p> <p>Voc\u00ea deve ter esse arquivo baixado em usa m\u00e1quina, o arquivo \u00e9 encontrado no link: https://github.com/spmallick/learnopencv/tree/master/Object-Detection-using-YOLOv5-and-OpenCV-DNN-in-CPP-and-Python/models</p>"},{"location":"aulas/PDI/lab18/index.html#leitura-das-classes-possiveis","title":"Leitura das Classes Poss\u00edveis","text":"<pre><code>classesFile = \"coco.names\"\nwith open(classesFile, 'rt') as f:\n    classes = f.read().rstrip('\\n').split('\\n')\n</code></pre> <p>Carrega os nomes das classes que o modelo \u00e9 capaz de detectar (baseado no dataset COCO que foi usado no treinamento).</p> <p>Warning</p> <p>Voc\u00ea deve ter esse arquivo baixado em usa m\u00e1quina, o arquivo \u00e9 encontrado no link: https://github.com/spmallick/learnopencv/blob/master/Object-Detection-using-YOLOv5-and-OpenCV-DNN-in-CPP-and-Python/coco.names</p>"},{"location":"aulas/PDI/lab18/index.html#interpretacao-dos-resultados","title":"Interpreta\u00e7\u00e3o dos Resultados","text":"<p>As vari\u00e1veis <code>class_ids</code>, <code>confidences</code>, e <code>boxes</code> s\u00e3o criadas para armazenarem os IDs das classes, as confian\u00e7as das detec\u00e7\u00f5es e as coordenadas das caixas delimitadoras, respectivamente. Seguindo uma estrutura de listas.</p> <pre><code>class_ids = []\nconfidences = []\nboxes = []\n</code></pre>"},{"location":"aulas/PDI/lab18/index.html#leitura-da-imagem","title":"Leitura da Imagem","text":"<pre><code>image = cv2.imread('img.jpg')\n</code></pre> <p>Carrega uma imagem <code>image</code> para teste. Esta imagem ser\u00e1 usada para a detec\u00e7\u00e3o de objetos.</p>"},{"location":"aulas/PDI/lab18/index.html#preparacao-da-imagem-para-o-modelo","title":"Prepara\u00e7\u00e3o da Imagem para o Modelo","text":"<pre><code>blob = cv2.dnn.blobFromImage(image, 1/255.0, (640, 640), swapRB=True, crop=False)\nnet.setInput(blob)\n</code></pre> <ul> <li><code>blobFromImage</code>: Converte a imagem para o formato necess\u00e1rio pelo modelo (blob), realiza normaliza\u00e7\u00f5es (como escalonamento) e muda o layout de cores de BGR para RGB.</li> <li><code>setInput</code>: Define o blob como entrada para a rede.</li> </ul>"},{"location":"aulas/PDI/lab18/index.html#processamento-da-deteccao","title":"Processamento da Detec\u00e7\u00e3o","text":"<pre><code>output_layers = net.getUnconnectedOutLayersNames()\noutputs = net.forward(output_layers)\n</code></pre> <ul> <li><code>getUnconnectedOutLayersNames()</code>: Em modelos como YOLO, estas camadas de sa\u00edda s\u00e3o as que fornecem as previs\u00f5es finais ap\u00f3s a passagem da imagem pela rede. Essas camadas s\u00e3o importantes porque s\u00e3o elas que cont\u00eam as informa\u00e7\u00f5es sobre as detec\u00e7\u00f5es feitas pela rede, como coordenadas de caixas delimitadoras, classes detectadas e confian\u00e7as associadas a essas detec\u00e7\u00f5es.</li> <li><code>forward(output_layers)</code>: Executa a rede neural para processar a entrada fornecida (a imagem transformada em um blob). O m\u00e9todo forward \u00e9 usado para propagar o blob atrav\u00e9s da rede, calculando a sa\u00edda nas camadas especificadas pelo argumento output_layers.</li> </ul> <p>Warning</p> <p>O resultado, <code>outputs</code>, \u00e9 um conjunto de arrays. Cada array corresponde a uma das camadas de sa\u00edda especificadas e cont\u00e9m as informa\u00e7\u00f5es detectadas para diferentes partes da imagem. Para o YOLO, esses arrays incluem as coordenadas das caixas delimitadoras (x, y, largura, altura), a confian\u00e7a de que h\u00e1 um objeto dentro da caixa e as probabilidades de cada classe para o objeto detectado.</p>"},{"location":"aulas/PDI/lab18/index.html#entendendo-a-saida-outputs","title":"Entendendo a saida outputs","text":"<p><code>Outputs</code> \u00e9 uma lista onde cada elemento \u00e9 um array NumPy. Cada array corresponde \u00e0s detec\u00e7\u00f5es feitas em uma certa camada de sa\u00edda da rede neural. Para o YOLOv5, normalmente existem tr\u00eas arrays, um para cada escala de detec\u00e7\u00e3o.</p> <p>Cada array tem uma estrutura tridimensional, comummente descrita como <code>(1, N, M)</code>, onde:</p> <ul> <li>1 representa o batch size, ou seja, o n\u00famero de imagens processadas. Geralmente \u00e9 1, pois processa-se uma imagem de cada vez.</li> <li>N \u00e9 o n\u00famero de caixas de detec\u00e7\u00e3o produzidas pela camada. Por exemplo, 25200 caixas (bounding boxes) ou detec\u00e7\u00f5es potenciais que o modelo gera para a imagem. \u00c9 o resultado da multiplica\u00e7\u00e3o do n\u00famero de \u00e2ncoras (anchor boxes) por diferentes tamanhos de grade (grid sizes) em que a imagem \u00e9 dividida durante a detec\u00e7\u00e3o.</li> <li>M \u00e9 o n\u00famero de caracter\u00edsticas por caixa de detec\u00e7\u00e3o. No YOLO com o dataset COCO, M \u00e9 geralmente 85, que inclui:<ul> <li>4 valores para a localiza\u00e7\u00e3o da caixa delimitadora (cx, cy, largura, altura), indicando o centro, largura e altura da caixa.</li> <li>1 valor para a confian\u00e7a de que a caixa cont\u00e9m um objeto.</li> <li>80 valores representando a probabilidade de cada uma das 80 classes poss\u00edveis no dataset COCO.</li> </ul> </li> </ul>"},{"location":"aulas/PDI/lab18/index.html#interpretando-os-resultados","title":"Interpretando os resultados","text":"<p>Para extrair e utilizar as informa\u00e7\u00f5es de detec\u00e7\u00e3o a partir do outputs, voc\u00ea deve realizar os seguintes passos:</p> <ul> <li><code>Extra\u00e7\u00e3o de Dados</code>: Itere sobre cada elemento (caixa de detec\u00e7\u00e3o) do array. Cada elemento cont\u00e9m informa\u00e7\u00f5es detalhadas sobre uma detec\u00e7\u00e3o potencial.</li> <li><code>Processamento de Caixas</code>: Para cada caixa de detec\u00e7\u00e3o, extraia as coordenadas (cx, cy, largura, altura) e a confian\u00e7a. Aplique o fator de escala \u00e0s coordenadas para converter essas coordenadas do espa\u00e7o da imagem redimensionada para o espa\u00e7o da imagem original.</li> <li><code>Filtragem por Confian\u00e7a</code>: Verifique se a confian\u00e7a de que a caixa cont\u00e9m um objeto \u00e9 superior a um limiar (por exemplo, 0.5). Isso reduz o n\u00famero de falsos positivos.</li> <li><code>Identifica\u00e7\u00e3o da Classe</code>: Dentro dos 80 valores de probabilidade de classe, identifique o \u00edndice (classe) com a maior probabilidade. Esse \u00edndice corresponde \u00e0 classe do objeto detectado na caixa.</li> <li><code>Non-Max Suppression (NMS)</code>: Uma vez que v\u00e1rias caixas podem ser detectadas para o mesmo objeto, o NMS \u00e9 usado para filtrar e manter apenas a caixa com a maior confian\u00e7a, enquanto remove caixas que t\u00eam uma grande sobreposi\u00e7\u00e3o com ela.</li> </ul>"},{"location":"aulas/PDI/lab18/index.html#processamento-das-deteccoes","title":"Processamento das Detec\u00e7\u00f5es","text":"<pre><code>rows = outputs[0].shape[1]\nimage_height, image_width = image.shape[:2]\nx_factor = image_width / 640\ny_factor = image_height / 640\n\nfor r in range(rows):\n    row = outputs[0][0][r] # pega a linha r, que cont\u00e9m as coordenadas da caixa delimitadora, confian\u00e7a e probabilidades de classe\n    confidence = row[4] # pega a confian\u00e7a da detec\u00e7\u00e3o\n\n    # Discard bad detections and continue.\n    if confidence &gt;= 0.45:\n        classes_scores = row[5:] # pega as probabilidades de classe\n\n        # pega o indice com a classe de maior score.\n        class_id = np.argmax(classes_scores)\n\n        if (classes_scores[class_id] &gt; 0.5): # se o score for maior que 0.5\n            confidences.append(confidence)  # adiciona a confian\u00e7a\n            class_ids.append(class_id)    # adiciona o id da classe\n\n            cx, cy, w, h = row[0], row[1], row[2], row[3] # pega as coordenadas do centro x, centro y, largura e altura\n\n            left = int((cx - w/2) * x_factor) # calcula a coordenada x do canto superior esquerdo\n            top = int((cy - h/2) * y_factor) # calcula a coordenada y do canto superior esquerdo\n            width = int(w * x_factor) # calcula a largura\n            height = int(h * y_factor) # calcula a altura\n\n            box = np.array([left, top, width, height]) # cria um array com as coordenadas\n            boxes.append(box) # adiciona o array na lista de boxes\n</code></pre> <ul> <li> <p>rows = outputs[0].shape[1]: Esta linha obt\u00e9m o n\u00famero de detec\u00e7\u00f5es retornadas pela primeira camada de sa\u00edda da rede neural. Em modelos como o YOLO, outputs[0] \u00e9 um tensor que cont\u00e9m as detec\u00e7\u00f5es para a imagem, onde cada \"row (linha)\" representa uma detec\u00e7\u00e3o potencial. shape[1] se refere \u00e0 dimens\u00e3o que cont\u00e9m o n\u00famero de detec\u00e7\u00f5es.</p> </li> <li> <p><code>x_factor e y_factor</code>: fator de redimensionamento no eixo x (largura) e y (altura).</p> </li> <li> <p><code>for r in range(rows)</code>: Itera sobre cada uma das detec\u00e7\u00f5es. A vari\u00e1vel rows representa o n\u00famero total de detec\u00e7\u00f5es poss\u00edveis para uma escala de sa\u00edda do modelo.</p> </li> <li> <p><code>Extra\u00e7\u00e3o de dados para cada detec\u00e7\u00e3o</code>:</p> <ul> <li><code>row = outputs[0][0][r]</code>: Extrai a linha r do primeiro tensor de sa\u00edda, que cont\u00e9m todas as informa\u00e7\u00f5es necess\u00e1rias para essa detec\u00e7\u00e3o espec\u00edfica.</li> <li><code>confidence = row[4]</code>: Extrai a confian\u00e7a de que a caixa delimitadora cont\u00e9m algum objeto.</li> </ul> </li> <li> <p><code>Filtragem de detec\u00e7\u00f5es por confian\u00e7a</code>:</p> <ul> <li><code>if confidence &gt;= 0.45</code>: Processa apenas as detec\u00e7\u00f5es que t\u00eam uma confian\u00e7a de pelo menos 0.45. Isso ajuda a eliminar falsos positivos ou detec\u00e7\u00f5es de baixa qualidade.</li> </ul> </li> <li> <p>Extra\u00e7\u00e3o e verifica\u00e7\u00e3o das probabilidades das classes:</p> <ul> <li><code>classes_scores = row[5:]</code>: Obt\u00e9m as probabilidades de cada classe para a detec\u00e7\u00e3o atual.</li> <li><code>class_id = np.argmax(classes_scores)</code>: Identifica o \u00edndice da classe que tem a maior probabilidade (score mais alto).</li> <li><code>if (classes_scores[class_id] &gt; 0.5)</code>: Verifica se a maior probabilidade de classe excede 0.5, indicando uma alta confian\u00e7a na classifica\u00e7\u00e3o do objeto.</li> </ul> </li> <li> <p>Extra\u00e7\u00e3o das coordenadas da caixa delimitadora e ajuste para o tamanho original da imagem:</p> <ul> <li><code>cx, cy, w, h = row[0], row[1], row[2], row[3]</code>: Extrai as coordenadas do centro da caixa, sua largura e altura da detec\u00e7\u00e3o.</li> <li><code>left = int((cx - w/2) * x_factor)</code>: Calcula a coordenada x do canto superior esquerdo da caixa, ajustando para o tamanho original da imagem.</li> <li><code>top = int((cy - h/2) * y_factor)</code>: Calcula a coordenada y do canto superior esquerdo, tamb\u00e9m ajustando para o tamanho original.</li> <li><code>width = int(w * x_factor), height = int(h * y_factor)</code>: Calcula a largura e altura reais da caixa delimitadora no tamanho original da imagem.</li> </ul> </li> <li> <p>Armazenamento das caixas delimitadoras:</p> <ul> <li><code>box = np.array([left, top, width, height])</code>: Cria um array com as coordenadas ajustadas da caixa delimitadora.</li> <li><code>boxes.append(box)</code>: Adiciona o array das coordenadas da caixa \u00e0 lista de boxes, que ser\u00e1 usada mais tarde para desenhar as caixas na imagem e aplicar a supress\u00e3o de m\u00e1ximos n\u00e3o-m\u00e1ximos (NMS).</li> </ul> </li> </ul>"},{"location":"aulas/PDI/lab18/index.html#aplicacao-do-non-maximum-suppression-nms","title":"Aplica\u00e7\u00e3o do Non-Maximum Suppression (NMS)","text":"<pre><code>indices = cv2.dnn.NMSBoxes(boxes, confidences, 0.45, 0.45)\n</code></pre> <p>NMS \u00e9 usado para eliminar caixas delimitadoras redundantes, mantendo apenas as mais prov\u00e1veis para cada objeto.</p>"},{"location":"aulas/PDI/lab18/index.html#desenho-das-caixas-delimitadoras-e-rotulos-na-imagem","title":"Desenho das Caixas Delimitadoras e R\u00f3tulos na Imagem","text":"<pre><code>for i in indices:\n    ...\n    cv2.rectangle(image, (left, top), (left + width, top + height), (255,178,50), 3*1)\n    ...\n    cv2.putText(image, label, (left, top + dim[1]), FONT_FACE, FONT_SCALE, YELLOW, 1, cv2.LINE_AA)\n</code></pre> <p>Desenha ret\u00e2ngulos e texto para as detec\u00e7\u00f5es finais na imagem.</p>"},{"location":"aulas/PDI/lab18/index.html#exibicao-da-imagem","title":"Exibi\u00e7\u00e3o da Imagem","text":"<pre><code>cv2.imshow('Output', image)\ncv2.waitKey(0)\n</code></pre>"},{"location":"aulas/PDI/lab18/yolo.html","title":"Yolo","text":"In\u00a0[\u00a0]: Copied! <pre>import cv2\nimport numpy as np\n</pre> import cv2 import numpy as np In\u00a0[\u00a0]: Copied! <pre># Carregar o modelo YOLOv5 ONNX\nnet = cv2.dnn.readNet('yolov5m.onnx')\n</pre> # Carregar o modelo YOLOv5 ONNX net = cv2.dnn.readNet('yolov5m.onnx') In\u00a0[\u00a0]: Copied! <pre># Ler uma imagem\nimage = cv2.imread('img.jpg')\n</pre> # Ler uma imagem image = cv2.imread('img.jpg') In\u00a0[\u00a0]: Copied! <pre># Preparar a entrada para o modelo\nblob = cv2.dnn.blobFromImage(image, 1/255.0, (640, 640), swapRB=True, crop=False)\nnet.setInput(blob)\n</pre> # Preparar a entrada para o modelo blob = cv2.dnn.blobFromImage(image, 1/255.0, (640, 640), swapRB=True, crop=False) net.setInput(blob) In\u00a0[\u00a0]: Copied! <pre># Processar os resultados da detec\u00e7\u00e3o...\n# o forward retorna uma lista de tensores, cada tensor cont\u00e9m as detec\u00e7\u00f5es de um n\u00edvel de escala\noutput_layers = net.getUnconnectedOutLayersNames()\noutputs = net.forward(output_layers)\n</pre> # Processar os resultados da detec\u00e7\u00e3o... # o forward retorna uma lista de tensores, cada tensor cont\u00e9m as detec\u00e7\u00f5es de um n\u00edvel de escala output_layers = net.getUnconnectedOutLayersNames() outputs = net.forward(output_layers) In\u00a0[\u00a0]: Copied! <pre># Lists to hold respective values while unwrapping.\nclass_ids = []\nconfidences = []\nboxes = []\nclassesFile = \"coco.names\"\nclasses = None\nwith open(classesFile, 'rt') as f:\n    classes = f.read().rstrip('\\n').split('\\n')\nFONT_FACE = cv2.FONT_HERSHEY_SIMPLEX\nFONT_SCALE = 0.7\nBLACK  = (0,0,0)\nBLUE   = (255,178,50)\nYELLOW = (0,255,255)\nRED = (0,0,255)\n</pre> # Lists to hold respective values while unwrapping. class_ids = [] confidences = [] boxes = [] classesFile = \"coco.names\" classes = None with open(classesFile, 'rt') as f:     classes = f.read().rstrip('\\n').split('\\n') FONT_FACE = cv2.FONT_HERSHEY_SIMPLEX FONT_SCALE = 0.7 BLACK  = (0,0,0) BLUE   = (255,178,50) YELLOW = (0,255,255) RED = (0,0,255) In\u00a0[\u00a0]: Copied! <pre># vamos entender a sa\u00edda do modelo YOLOv5\n# cada detec\u00e7\u00e3o \u00e9 representada por 85 valores\n# 4 valores para as coordenadas da caixa delimitadora\n# 1 valor para a confian\u00e7a\n# 80 valores para as probabilidades de classe\n# outputs[0] \u00e9 o tensor de sa\u00edda do modelo, que cont\u00e9m as detec\u00e7\u00f5es do n\u00edvel de escala 0, que \u00e9 a escala original da imagem (640x640)\nprint(f'outputs[0].shape: {outputs[0].shape]}')\n</pre> # vamos entender a sa\u00edda do modelo YOLOv5 # cada detec\u00e7\u00e3o \u00e9 representada por 85 valores # 4 valores para as coordenadas da caixa delimitadora # 1 valor para a confian\u00e7a # 80 valores para as probabilidades de classe # outputs[0] \u00e9 o tensor de sa\u00edda do modelo, que cont\u00e9m as detec\u00e7\u00f5es do n\u00edvel de escala 0, que \u00e9 a escala original da imagem (640x640) print(f'outputs[0].shape: {outputs[0].shape]}') In\u00a0[\u00a0]: Copied! <pre># pega o n\u00famero de detec\u00e7\u00f5es\nrows = outputs[0].shape[1]\nimage_height, image_width = image.shape[:2]\n</pre> # pega o n\u00famero de detec\u00e7\u00f5es rows = outputs[0].shape[1] image_height, image_width = image.shape[:2] In\u00a0[\u00a0]: Copied! <pre># Resizing factor.\nx_factor = image_width / 640\ny_factor =  image_height / 640\n</pre> # Resizing factor. x_factor = image_width / 640 y_factor =  image_height / 640 In\u00a0[\u00a0]: Copied! <pre># Iterate through 25200 detections.\nfor r in range(rows):\n    row = outputs[0][0][r] # pega a linha r, que cont\u00e9m as coordenadas da caixa delimitadora, confian\u00e7a e probabilidades de classe\n    confidence = row[4] # pega a confian\u00e7a da detec\u00e7\u00e3o\n\n    # Discard bad detections and continue.\n    if confidence &gt;= 0.45:\n        classes_scores = row[5:] # pega as probabilidades de classe\n\n        # pega o indice com a classe de maior score.\n        class_id = np.argmax(classes_scores)\n\n        if (classes_scores[class_id] &gt; 0.5): # se o score for maior que 0.5\n            confidences.append(confidence)  # adiciona a confian\u00e7a\n            class_ids.append(class_id)    # adiciona o id da classe\n\n            cx, cy, w, h = row[0], row[1], row[2], row[3] # pega as coordenadas do centro x, centro y, largura e altura\n\n            left = int((cx - w/2) * x_factor) # calcula a coordenada x do canto superior esquerdo\n            top = int((cy - h/2) * y_factor) # calcula a coordenada y do canto superior esquerdo\n            width = int(w * x_factor) # calcula a largura\n            height = int(h * y_factor) # calcula a altura\n            \n            box = np.array([left, top, width, height]) # cria um array com as coordenadas\n            boxes.append(box) # adiciona o array na lista de boxes\n</pre> # Iterate through 25200 detections. for r in range(rows):     row = outputs[0][0][r] # pega a linha r, que cont\u00e9m as coordenadas da caixa delimitadora, confian\u00e7a e probabilidades de classe     confidence = row[4] # pega a confian\u00e7a da detec\u00e7\u00e3o      # Discard bad detections and continue.     if confidence &gt;= 0.45:         classes_scores = row[5:] # pega as probabilidades de classe          # pega o indice com a classe de maior score.         class_id = np.argmax(classes_scores)          if (classes_scores[class_id] &gt; 0.5): # se o score for maior que 0.5             confidences.append(confidence)  # adiciona a confian\u00e7a             class_ids.append(class_id)    # adiciona o id da classe              cx, cy, w, h = row[0], row[1], row[2], row[3] # pega as coordenadas do centro x, centro y, largura e altura              left = int((cx - w/2) * x_factor) # calcula a coordenada x do canto superior esquerdo             top = int((cy - h/2) * y_factor) # calcula a coordenada y do canto superior esquerdo             width = int(w * x_factor) # calcula a largura             height = int(h * y_factor) # calcula a altura                          box = np.array([left, top, width, height]) # cria um array com as coordenadas             boxes.append(box) # adiciona o array na lista de boxes In\u00a0[\u00a0]: Copied! <pre># Aplica o NMS, que \u00e9 um algoritmo que remove as caixas que se sobrep\u00f5em\n# Retorna os \u00edndices das caixas que devem ser mantidas\nindices = cv2.dnn.NMSBoxes(boxes, confidences, 0.45, 0.45) \nfor i in indices:\n    box = boxes[i]\n    left = box[0]\n    top = box[1]\n    width = box[2]\n    height = box[3]\n    cv2.rectangle(image, (left, top), (left + width, top + height), (255,178,50), 3*1)\n    label = \"{}:{:.2f}\".format(classes[class_ids[i]], confidences[i])\n   \n    text_size = cv2.getTextSize(label, FONT_FACE, FONT_SCALE, 1)\n    dim, baseline = text_size[0], text_size[1] \n    # desenha um ret\u00e2ngulo preto para o texto\n    cv2.rectangle(image, (left, top), (left + dim[0], top + dim[1] + baseline), BLACK, cv2.FILLED);\n    # escreve a classe e a confian\u00e7a\n    cv2.putText(image, label, (left, top + dim[1]), FONT_FACE, FONT_SCALE, YELLOW, 1, cv2.LINE_AA)\n</pre> # Aplica o NMS, que \u00e9 um algoritmo que remove as caixas que se sobrep\u00f5em # Retorna os \u00edndices das caixas que devem ser mantidas indices = cv2.dnn.NMSBoxes(boxes, confidences, 0.45, 0.45)  for i in indices:     box = boxes[i]     left = box[0]     top = box[1]     width = box[2]     height = box[3]     cv2.rectangle(image, (left, top), (left + width, top + height), (255,178,50), 3*1)     label = \"{}:{:.2f}\".format(classes[class_ids[i]], confidences[i])         text_size = cv2.getTextSize(label, FONT_FACE, FONT_SCALE, 1)     dim, baseline = text_size[0], text_size[1]      # desenha um ret\u00e2ngulo preto para o texto     cv2.rectangle(image, (left, top), (left + dim[0], top + dim[1] + baseline), BLACK, cv2.FILLED);     # escreve a classe e a confian\u00e7a     cv2.putText(image, label, (left, top + dim[1]), FONT_FACE, FONT_SCALE, YELLOW, 1, cv2.LINE_AA) In\u00a0[\u00a0]: Copied! <pre>cv2.imshow('Output', image)\ncv2.waitKey(0)\n</pre> cv2.imshow('Output', image) cv2.waitKey(0)"},{"location":"aulas/PDI/lab18/yolo_video.html","title":"Yolo video","text":"In\u00a0[\u00a0]: Copied! <pre>import cv2\nimport numpy as np\n</pre> import cv2 import numpy as np In\u00a0[\u00a0]: Copied! <pre># Carregar o modelo YOLOv5 ONNX\nnet = cv2.dnn.readNet('yolov5m.onnx')\n</pre> # Carregar o modelo YOLOv5 ONNX net = cv2.dnn.readNet('yolov5m.onnx') In\u00a0[\u00a0]: Copied! <pre># Abrir um v\u00eddeo\ncap = cv2.VideoCapture(0)\n</pre> # Abrir um v\u00eddeo cap = cv2.VideoCapture(0) In\u00a0[\u00a0]: Copied! <pre>classesFile = \"coco.names\"\nclasses = None\nwith open(classesFile, 'rt') as f:\n    classes = f.read().rstrip('\\n').split('\\n')\n</pre> classesFile = \"coco.names\" classes = None with open(classesFile, 'rt') as f:     classes = f.read().rstrip('\\n').split('\\n') In\u00a0[\u00a0]: Copied! <pre>FONT_FACE = cv2.FONT_HERSHEY_SIMPLEX\nFONT_SCALE = 0.7\nBLACK = (0, 0, 0)\nYELLOW = (0, 255, 255)\n</pre> FONT_FACE = cv2.FONT_HERSHEY_SIMPLEX FONT_SCALE = 0.7 BLACK = (0, 0, 0) YELLOW = (0, 255, 255) In\u00a0[\u00a0]: Copied! <pre>while True:\n    # Ler um frame do v\u00eddeo\n    ret, frame = cap.read()\n    if not ret:\n        break\n\n    # Preparar a entrada para o modelo\n    blob = cv2.dnn.blobFromImage(frame, 1/255.0, (640, 640), swapRB=True, crop=False)\n    net.setInput(blob)\n\n    # Executar a detec\u00e7\u00e3o de objetos\n    outputs = net.forward(net.getUnconnectedOutLayersNames())\n\n    # Processar os resultados da detec\u00e7\u00e3o\n    boxes = []\n    confidences = []\n    class_ids = []\n\n    rows = outputs[0].shape[1]\n    image_height, image_width = frame.shape[:2]\n    x_factor = image_width / 640\n    y_factor = image_height / 640\n\n    for r in range(rows):\n        row = outputs[0][0][r]\n        confidence = row[4]\n        if confidence &gt;= 0.45:\n            classes_scores = row[5:]\n            class_id = np.argmax(classes_scores)\n            if classes_scores[class_id] &gt; 0.2:\n                confidences.append(confidence)\n                class_ids.append(class_id)\n\n                cx, cy, w, h = row[0], row[1], row[2], row[3]\n                left = int((cx - w/2) * x_factor)\n                top = int((cy - h/2) * y_factor)\n                width = int(w * x_factor)\n                height = int(h * y_factor)\n                box = np.array([left, top, width, height])\n                boxes.append(box)\n\n    indices = cv2.dnn.NMSBoxes(boxes, confidences, 0.45, 0.45)\n    for i in indices:\n        box = boxes[i]\n        left = box[0]\n        top = box[1]\n        width = box[2]\n        height = box[3]\n        cv2.rectangle(frame, (left, top), (left + width, top + height), (255, 178, 50), 3)\n        label = \"{}:{:.2f}\".format(classes[class_ids[i]], confidences[i])\n        text_size = cv2.getTextSize(label, FONT_FACE, FONT_SCALE, 1)\n        dim, baseline = text_size[0], text_size[1]\n        cv2.rectangle(frame, (left, top), (left + dim[0], top + dim[1] + baseline), BLACK, cv2.FILLED)\n        cv2.putText(frame, label, (left, top + dim[1]), FONT_FACE, FONT_SCALE, YELLOW, 1, cv2.LINE_AA)\n\n    # Exibir o frame com os objetos detectados\n    cv2.imshow('Output', frame)\n    if cv2.waitKey(1) &amp; 0xFF == ord('q'):\n        break\n</pre> while True:     # Ler um frame do v\u00eddeo     ret, frame = cap.read()     if not ret:         break      # Preparar a entrada para o modelo     blob = cv2.dnn.blobFromImage(frame, 1/255.0, (640, 640), swapRB=True, crop=False)     net.setInput(blob)      # Executar a detec\u00e7\u00e3o de objetos     outputs = net.forward(net.getUnconnectedOutLayersNames())      # Processar os resultados da detec\u00e7\u00e3o     boxes = []     confidences = []     class_ids = []      rows = outputs[0].shape[1]     image_height, image_width = frame.shape[:2]     x_factor = image_width / 640     y_factor = image_height / 640      for r in range(rows):         row = outputs[0][0][r]         confidence = row[4]         if confidence &gt;= 0.45:             classes_scores = row[5:]             class_id = np.argmax(classes_scores)             if classes_scores[class_id] &gt; 0.2:                 confidences.append(confidence)                 class_ids.append(class_id)                  cx, cy, w, h = row[0], row[1], row[2], row[3]                 left = int((cx - w/2) * x_factor)                 top = int((cy - h/2) * y_factor)                 width = int(w * x_factor)                 height = int(h * y_factor)                 box = np.array([left, top, width, height])                 boxes.append(box)      indices = cv2.dnn.NMSBoxes(boxes, confidences, 0.45, 0.45)     for i in indices:         box = boxes[i]         left = box[0]         top = box[1]         width = box[2]         height = box[3]         cv2.rectangle(frame, (left, top), (left + width, top + height), (255, 178, 50), 3)         label = \"{}:{:.2f}\".format(classes[class_ids[i]], confidences[i])         text_size = cv2.getTextSize(label, FONT_FACE, FONT_SCALE, 1)         dim, baseline = text_size[0], text_size[1]         cv2.rectangle(frame, (left, top), (left + dim[0], top + dim[1] + baseline), BLACK, cv2.FILLED)         cv2.putText(frame, label, (left, top + dim[1]), FONT_FACE, FONT_SCALE, YELLOW, 1, cv2.LINE_AA)      # Exibir o frame com os objetos detectados     cv2.imshow('Output', frame)     if cv2.waitKey(1) &amp; 0xFF == ord('q'):         break In\u00a0[\u00a0]: Copied! <pre># Liberar recursos\ncap.release()\ncv2.destroyAllWindows()\n</pre> # Liberar recursos cap.release() cv2.destroyAllWindows()"},{"location":"aulas/PDI/solucoes/index.html","title":"Solu\u00e7\u00f5es PDI","text":""},{"location":"aulas/PDI/solucoes/index.html#solucao-dos-labs","title":"Solu\u00e7\u00e3o dos labs","text":"<p>Um guia para voc\u00eas consultarem as solu\u00e7\u00f5es poss\u00edveis dos desafios propostos nos laborat\u00f3rios desenvolvidos em aula. Lembre-se de que a pr\u00e1tica \u00e9 essencial para o aprendizado, ent\u00e3o tente resolver os exerc\u00edcios por conta pr\u00f3pria antes de consultar as solu\u00e7\u00f5es.</p>"},{"location":"aulas/PDI/solucoes/index.html#indice","title":"\u00cdndice","text":"<ul> <li>Lab01 - Intro PID</li> <li>Lab02 - Seguimenta\u00e7\u00e3o por pixel</li> <li>Lab03 - Histograma e equaliza\u00e7\u00e3o</li> <li>Lab04 - Filtros de Convolu\u00e7\u00e3o</li> <li>Lab05 - Espa\u00e7o de cor e contorno </li> <li>Lab06 - Transformada de Hough e morfologia</li> <li>Lab07 - Traking de objetos e movimento</li> <li>Lab08 - Relacionamento e opera\u00e7\u00f5es entre imagens</li> <li>Lab09 - FFT</li> <li>Lab10 - Medidas aproximadas</li> <li> <p>Lab11 - Transformada de watershed</p> </li> <li> <p>Lab12 - Template matching</p> </li> <li>Lab13 - Features</li> <li>Lab14 - Detector haar Cascade</li> <li>Lab15 - Event Mouse</li> <li>Lab16 - Detector dlib</li> <li>Lab17 - Mediapipe</li> <li>Lab18 - Yolo</li> </ul>"},{"location":"aulas/PDI/solucoes/index.html#gs-24","title":"GS-24","text":"<ul> <li>Solu\u00e7\u00e3o GS-24</li> </ul>"},{"location":"aulas/iot/ex0/index.html","title":"Index","text":""},{"location":"aulas/iot/ex0/index.html#from-zero-to-hero","title":"From Zero to Hero!!","text":"<p>Espero que estejam animados para mergulhar no mundo dos Sistemas Embarcados e IoT com programa\u00e7\u00e3o em C/C++ usando o Arduino. </p> <p>Para come\u00e7ar do jeito certo e com o p\u00e9 direito!</p> <p>Pratique com essa lista de exerc\u00edcios que vai ajud\u00e1-lo a dominar os conceitos b\u00e1sicos de C/C++, focando apenas na programa\u00e7\u00e3o e utilizando o Monitor Serial para entrada e sa\u00edda de dados, sem se preocupar com hardware Arduino, por enquanto.</p> <p>S\u00e3o exerc\u00edcios abrangendo temas para praticar e aprimorar suas habilidades de programa\u00e7\u00e3o, independentemente do n\u00edvel de experi\u00eancia.</p>"},{"location":"aulas/iot/ex0/index.html#exercicios-conceitos-fundamentais-sem-hardware","title":"Exercicios: Conceitos Fundamentais sem Hardware","text":"<p>Exercise</p> <p>\"Hello, World!\" no Monitor Serial Familiarize-se com o Arduino IDE e o Monitor Serial, escrevendo um programa simples que imprime \"Hello, World!\" no Monitor Serial.</p> <p>Progress</p> <p>Solu\u00e7\u00e3o...</p> <p>Dica: https://docs.arduino.cc/software/ide-v2/tutorials/ide-v2-serial-monitor.</p> <p>Exercise</p> <p>Vari\u00e1veis e Opera\u00e7\u00f5es Matem\u00e1ticas Crie um programa que recebe dois n\u00fameros inteiros do Monitor Serial, realiza opera\u00e7\u00f5es matem\u00e1ticas b\u00e1sicas (adi\u00e7\u00e3o, subtra\u00e7\u00e3o, multiplica\u00e7\u00e3o e divis\u00e3o) e exibe os resultados no Monitor Serial.</p> <p>Exercise</p> <p>Estruturas de Controle: if, else e switch-case Escreva um programa que receba um n\u00famero inteiro do Monitor Serial e, usando estruturas de controle, verifique se o n\u00famero \u00e9 par ou \u00edmpar, positivo ou negativo e imprima o resultado no Monitor Serial.</p> <p>Exercise</p> <p>Estruturas de Repeti\u00e7\u00e3o: for e while Desenvolva um programa que imprima no Monitor Serial os primeiros N n\u00fameros da sequ\u00eancia de Fibonacci, onde N \u00e9 um n\u00famero inteiro fornecido pelo usu\u00e1rio atrav\u00e9s do Monitor Serial.</p> <p>Exercise</p> <p>Fun\u00e7\u00f5es Crie um programa que utiliza fun\u00e7\u00f5es para converter temperaturas entre graus Celsius e Fahrenheit. O usu\u00e1rio deve inserir a temperatura e a escala desejada (C ou F) no Monitor Serial, e o programa deve retornar a temperatura convertida.</p> <p>Exercise</p> <p>Vetores e manipula\u00e7\u00e3o de dados Desenvolva um programa que recebe uma sequ\u00eancia de N n\u00fameros inteiros pelo Monitor Serial, armazena em um vetor, e calcula a m\u00e9dia, o maior e o menor n\u00famero. Imprima os resultados no Monitor Serial.</p> <p>Exercise</p> <p>Manipula\u00e7\u00e3o de Strings Escreva um programa que receba uma string do Monitor Serial e determine o n\u00famero de palavras, o n\u00famero de vogais e o n\u00famero de consoantes na string. Imprima os resultados no Monitor Serial.</p> <p>Exercise</p> <p>Ponteiros Crie um programa que recebe dois n\u00fameros inteiros do Monitor Serial e troque seus valores usando ponteiros. Imprima os valores antes e depois da troca no Monitor Serial.</p> <p>Exercise</p> <p>Estruturas (structs) e Tipos Definidos pelo Usu\u00e1rio Crie um programa que gerencia informa\u00e7\u00f5es de alunos, como nome, idade e notas. Utilize structs para armazenar as informa\u00e7\u00f5es e fun\u00e7\u00f5es para realizar opera\u00e7\u00f5es, como adicionar um aluno, remover um aluno, calcular a m\u00e9dia das notas e exibir as informa\u00e7\u00f5es dos alunos no Monitor Serial.</p>"},{"location":"aulas/iot/ex0/solucao.html","title":"Solu\u00e7\u00e3o From Zero to Hero!","text":""},{"location":"aulas/iot/ex0/solucao.html#solucao-from-zero-to-hero","title":"Solu\u00e7\u00e3o From Zero to Hero!!","text":""},{"location":"aulas/iot/ex0/solucao.html#exercicio-1","title":"Exercicio 1","text":"<p>Exercise</p> <p>\"Hello, World!\" no Monitor Serial</p> <p>Familiarize-se com o Arduino IDE e o Monitor Serial, escrevendo um programa simples que imprime \"Hello, World!\" no Monitor Serial.</p> <pre><code>void setup() {\n  // Inicia a comunica\u00e7\u00e3o serial com o monitor em 9600 bps\n  Serial.begin(9600);\n}\n\nvoid loop() {\n\n  Serial.println(\"Hello, World!\");\n  delay(1000); // Aguarda 1 segundo\n}\n</code></pre> <p>Progress</p> <p>Continuar...</p>"},{"location":"aulas/iot/ex0/solucao.html#exercicio-2","title":"Exercicio 2","text":"<p>Exercise</p> <p>Vari\u00e1veis e Opera\u00e7\u00f5es Matem\u00e1ticas</p> <p>Crie um programa que recebe dois n\u00fameros inteiros do Monitor Serial, realiza opera\u00e7\u00f5es matem\u00e1ticas b\u00e1sicas (adi\u00e7\u00e3o, subtra\u00e7\u00e3o, multiplica\u00e7\u00e3o e divis\u00e3o) e exibe os resultados no Monitor Serial.</p> <pre><code>int num1, num2;\n\nvoid setup() {\n  Serial.begin(9600);\n}\n\nvoid loop() {\n    Serial.println(\"Digite o primeiro n\u00famero:\");\n    while (Serial.available() == 0) {} // Aguarda o primeiro n\u00famero\n    num1 = Serial.parseInt();\n\n    Serial.println(\"Digite o segundo n\u00famero:\");\n    while (Serial.available() == 0) {} // Aguarda o segundo n\u00famero\n    num2 = Serial.parseInt();\n\n    Serial.print(\"Soma: \");\n    Serial.println(num1 + num2);\n\n    Serial.print(\"Subtra\u00e7\u00e3o: \");\n    Serial.println(num1 - num2);\n\n    Serial.print(\"Multiplica\u00e7\u00e3o: \");\n    Serial.println(num1 * num2);\n\n    if (num2 != 0) {\n      Serial.print(\"Divis\u00e3o: \");\n      Serial.println(num1 / num2);\n    } else {\n      Serial.println(\"Divis\u00e3o por zero n\u00e3o permitida.\");\n    }\n    delay(1000); // Aguarda 1 segundo\n}\n</code></pre> <p>Progress</p> <p>Continuar...</p>"},{"location":"aulas/iot/ex0/solucao.html#exercicio-3","title":"Exercicio 3","text":"<p>Exercise</p> <p>Estruturas de Controle: if, else e switch-case</p> <p>Escreva um programa que receba um n\u00famero inteiro do Monitor Serial e, usando estruturas de controle, verifique se o n\u00famero \u00e9 par ou \u00edmpar, positivo ou negativo e imprima o resultado no Monitor Serial.</p> <pre><code>void setup() {\n    Serial.begin(9600);\n    Serial.println(\"Digite um n\u00famero inteiro:\");\n}\n\nvoid loop() {\n\n    if (Serial.available() &gt; 0) {\n        int num = Serial.parseInt();\n\n        if (num % 2 == 0) {\n            Serial.println(\"O n\u00famero \u00e9 par.\");\n        } else {\n            Serial.println(\"O n\u00famero \u00e9 \u00edmpar.\");\n        }\n\n        if (num &gt; 0) {\n            Serial.println(\"O n\u00famero \u00e9 positivo.\");\n        } else if (num &lt; 0) {\n            Serial.println(\"O n\u00famero \u00e9 negativo.\");\n        } else {\n            Serial.println(\"O n\u00famero \u00e9 zero.\");\n        }\n        Serial.println(\"Digite um n\u00famero inteiro:\");  \n    }\n}\n</code></pre> <p>Progress</p> <p>Continuar...</p>"},{"location":"aulas/iot/ex0/solucao.html#exercicio-4","title":"Exercicio 4","text":"<p>Exercise</p> <p>Estruturas de Repeti\u00e7\u00e3o: for e while</p> <p>Desenvolva um programa que imprima no Monitor Serial os primeiros N n\u00fameros da sequ\u00eancia de Fibonacci, onde N \u00e9 um n\u00famero inteiro fornecido pelo usu\u00e1rio atrav\u00e9s do Monitor Serial.</p> <pre><code>int n;\n\nvoid setup() {\n  Serial.begin(9600);\n  Serial.println(\"Digite o valor de N:\");\n}\n\nvoid loop() {\n  if (Serial.available() &gt; 0) {\n    n = Serial.parseInt();\n    int a = 0, b = 1, c;\n\n    Serial.print(\"Sequ\u00eancia de Fibonacci: \");\n    Serial.print(a);\n    Serial.print(\", \");\n    Serial.print(b);\n\n    for (int i = 2; i &lt; n; i++) {\n      c = a + b;\n      Serial.print(\", \");\n      Serial.print(c);\n      a = b;\n      b = c;\n    }\n    Serial.println();\n    Serial.println(\"Digite o valor de N:\");\n  }\n}\n</code></pre> <p>Progress</p> <p>Continuar...</p>"},{"location":"aulas/iot/ex0/solucao.html#exercicio-5","title":"Exercicio 5","text":"<p>Exercise</p> <p>Fun\u00e7\u00f5es</p> <p>Crie um programa que utiliza fun\u00e7\u00f5es para converter temperaturas entre graus Celsius e Fahrenheit. O usu\u00e1rio deve inserir a temperatura e a escala desejada (C ou F) no Monitor Serial, e o programa deve retornar a temperatura convertida.</p> <pre><code>float converteFahrenheit(float celsius) {\n  return celsius * 9.0 / 5.0 + 32;\n}\n\nfloat converteCelsius(float fahrenheit) {\n    float valor = (fahrenheit - 32) * 5.0 / 9.0;\n  return valor;\n}\n\nvoid setup() {\n  Serial.begin(9600);\n  Serial.println(\"Digite a temperatura e a escala (C ou F):\");\n}\n\nvoid loop() {\n  if (Serial.available() &gt; 0) {\n    float temp = Serial.parseFloat();\n    char scale = Serial.read();\n\n    if (scale == 'C' || scale == 'c') {\n      Serial.print(\"Temperatura em Fahrenheit: \");\n      Serial.println(converteFahrenheit(temp));\n    } else if (scale == 'F' || scale == 'f') {\n      Serial.print(\"Temperatura em Celsius: \");\n      Serial.println(converteCelsius(temp));\n    } else {\n      Serial.println(\"Escala inv\u00e1lida.\");\n    }\n  }\n}\n</code></pre> <p>Progress</p> <p>Continuar...</p>"},{"location":"aulas/iot/ex0/solucao.html#exercicio-6","title":"Exercicio 6","text":"<p>Exercise</p> <p>Vetores e manipula\u00e7\u00e3o de dados</p> <p>Desenvolva um programa que recebe uma sequ\u00eancia de N n\u00fameros inteiros pelo Monitor Serial, armazena em um vetor, e calcula a m\u00e9dia, o maior e o menor n\u00famero. Imprima os resultados no Monitor Serial.</p> <pre><code>#define TAMANHO_MAXIMO 100  // Defina um tamanho m\u00e1ximo para o vetor\n\nint vetor[TAMANHO_MAXIMO];  // Vetor de tamanho fixo\n\nvoid setup() {\n  Serial.begin(9600);\n  Serial.println(\"Digite o numero de elementos no vetor:\");\n}\n\nvoid lerElementos(int vetor[], int tamanho) {\n  for (int i = 0; i &lt; tamanho; i++) {\n    Serial.print(\"Digite o numero \");\n    Serial.print(i + 1);\n    Serial.print(\": \");\n\n    while (Serial.available() == 0) {} // Aguarda input\n    vetor[i] = Serial.parseInt();\n    Serial.println(vetor[i]);\n  }\n}\n\nfloat calcularMedia(int vetor[], int tamanho) {\n  int soma = 0;\n  for (int i = 0; i &lt; tamanho; i++) {\n    soma += vetor[i];\n  }\n  float media = (float)soma / tamanho;\n  return media;\n}\n\nint encontrarMaior(int vetor[], int tamanho) {\n  int maior = vetor[0];\n  for (int i = 1; i &lt; tamanho; i++) {\n    if (vetor[i] &gt; maior) {\n      maior = vetor[i];\n    }\n  }\n  return maior;\n}\n\nint encontrarMenor(int vetor[], int tamanho) {\n  int menor = vetor[0];\n  for (int i = 1; i &lt; tamanho; i++) {\n    if (vetor[i] &lt; menor) {\n      menor = vetor[i];\n    }\n  }\n  return menor;\n}\n\nvoid loop() {\n  if (Serial.available() &gt; 0) {\n    int n = Serial.parseInt();\n\n    if (n &gt; TAMANHO_MAXIMO) {\n      Serial.print(\"Numero de elementos escolhido excede o tamanho m\u00e1ximo permitido de \");\n      Serial.println(TAMANHO_MAXIMO);\n      n = TAMANHO_MAXIMO;\n    }\n\n    Serial.print(\"Numero de elementos: \");\n    Serial.println(n);\n\n    lerElementos(vetor, n);\n\n\n    float media = calcularMedia(vetor, n);\n    int maior = encontrarMaior(vetor, n);\n    int menor = encontrarMenor(vetor, n);\n\n    Serial.print(\"Media: \");\n    Serial.println(media);\n\n    Serial.print(\"Maior numero: \");\n    Serial.println(maior);\n\n    Serial.print(\"Menor numero: \");\n    Serial.println(menor);\n\n    Serial.println(\"Digite o numero de elementos no vetor:\");\n\n  }\n}\n</code></pre> <p>Progress</p> <p>Continuar...</p>"},{"location":"aulas/iot/ex0/solucao.html#exercicio-7","title":"Exercicio 7","text":"<p>Exercise</p> <p>Manipula\u00e7\u00e3o de Strings</p> <p>Escreva um programa que receba uma string do Monitor Serial e determine o n\u00famero de palavras, o n\u00famero de vogais e o n\u00famero de consoantes na string. Imprima os resultados no Monitor Serial.</p> <p>Tip</p> <p>Esse ex\u00e9rcicio n\u00e3o funcionou no tinkercad, mas no wokwi deu certo.</p> <pre><code>#define TAMANHO_MAXIMO 100;  // Defina um tamanho m\u00e1ximo para o vetor\n\nvoid setup() {\n  Serial.begin(9600);\n  Serial.println(\"Digite uma string:\");\n}\n// O `\\0` \u00e9 o caractere nulo que indica o fim da string\n// || \u00e9 o operador l\u00f3gico OU e &amp;&amp; \u00e9 o operador l\u00f3gico E\n\n#define TAMANHO_MAXIMO 100\n\nvoid setup() {\n  Serial.begin(9600);\n  Serial.println(\"Digite uma string:\");\n}\n\nvoid loop() {\n\n  if (Serial.available() &gt; 0) {\n    char palavras[TAMANHO_MAXIMO]; // Array para armazenar a string com um tamanho m\u00e1ximo de 100 caracteres\n\n    lerString(palavras, TAMANHO_MAXIMO);\n\n    int numPalavras = contarPalavras(palavras);\n    int numVogais = contarVogais(palavras);\n    int numConsoantes = contarConsoantes(palavras);\n\n    // Imprime os resultados no Monitor Serial\n    Serial.print(\"N\u00famero de palavras: \");\n    Serial.println(numPalavras);\n    Serial.print(\"N\u00famero de vogais: \");\n    Serial.println(numVogais);\n    Serial.print(\"N\u00famero de consoantes: \");\n    Serial.println(numConsoantes);\n\n    // Aguarda nova entrada do usu\u00e1rio\n    Serial.println(\"Digite outra string:\");\n  }\n}\n\n// Fun\u00e7\u00e3o que l\u00ea uma string da Serial e armazena em um array de caracteres\nvoid lerString(char buffer[], int maxLength) {\n  int index = 0;\n\n  while (true) {\n    if (Serial.available() &gt; 0) {   // Verifica se h\u00e1 dados dispon\u00edveis na porta serial\n      char receivedChar = Serial.read(); // L\u00ea o caractere recebido\n\n      if (receivedChar == '\\n') {  // Verifica se o caractere \u00e9 uma nova linha (Enter)\n        buffer[index] = '\\0';    // Termina a string com um caractere nulo\n        Serial.print(\"Voc\u00ea digitou: \");\n        Serial.println(buffer);  // Imprime a string recebida\n        break;  // Sai do loop\n      } else {\n        buffer[index] = receivedChar; // Armazena o caractere no array\n        index++;  // Incrementa o \u00edndice\n\n        if (index &gt;= maxLength - 1) {  // Limita o tamanho da string para evitar estouro de mem\u00f3ria\n          Serial.println(\"String muito longa!\");\n          buffer[index] = '\\0';  // Termina a string com um caractere nulo\n          break;  // Sai do loop\n        }\n      }\n    }\n  }\n}\n\n// Fun\u00e7\u00e3o que conta o n\u00famero de palavras em uma string, considerando que uma palavra \u00e9 uma sequ\u00eancia de letras min\u00fasculas\nint contarPalavras(char input[]) {\n  int numPalavras = 0;\n  bool novaPalavra = true;\n  for (int i = 0; input[i] != '\\0'; i++) {\n    char c = input[i];\n    if (c &gt;= 'a' &amp;&amp; c &lt;= 'z') {\n      if (novaPalavra) {\n        numPalavras++;\n        novaPalavra = false;\n      }\n    } else {\n      novaPalavra = true;\n    }\n  }\n  return numPalavras;\n}\n\n// Fun\u00e7\u00e3o que conta o n\u00famero de vogais em uma string \nint contarVogais(char input[]) {\n  int numVogais = 0;\n  for (int i = 0; input[i] != '\\0'; i++) {\n    char c = input[i];\n    if (c == 'a' || c == 'e' || c == 'i' || c == 'o' || c == 'u') {\n      numVogais++;\n    }\n  }\n  return numVogais;\n}\n\n// Fun\u00e7\u00e3o que conta o n\u00famero de consoantes em uma string\nint contarConsoantes(char input[]) {\n  int numConsoantes = 0;\n  for (int i = 0; input[i] != '\\0'; i++) {\n    char c = input[i];\n    if (c &gt;= 'a' &amp;&amp; c &lt;= 'z' &amp;&amp; !(c == 'a' || c == 'e' || c == 'i' || c == 'o' || c == 'u')) {\n      numConsoantes++;\n    }\n  }\n  return numConsoantes;\n}\n</code></pre> <p>Progress</p> <p>Continuar...</p>"},{"location":"aulas/iot/ex0/solucao.html#exercicio-8","title":"Exercicio 8","text":"<p>Exercise</p> <p>Ponteiros</p> <p>Crie um programa que recebe dois n\u00fameros inteiros do Monitor Serial e troque seus valores usando ponteiros. Imprima os valores antes e depois da troca no Monitor Serial.</p> <pre><code>void troca(int *a, int *b) {\n    int temp = *a;\n    *a = *b;\n    *b = temp;\n  }\n\n  int num1, num2;\n\n  void setup() {\n    Serial.begin(9600);\n    Serial.println(\"Digite o primeiro n\u00famero:\");\n  }\n\n  void loop() {\n    if (Serial.available() &gt; 0) {\n      num1 = Serial.parseInt();\n      Serial.println(\"Digite o segundo n\u00famero:\");\n\n      while (Serial.available() == 0) {} // Aguarda o segundo n\u00famero\n      num2 = Serial.parseInt();\n\n      Serial.print(\"Antes da troca: num1 = \");\n      Serial.print(num1);\n      Serial.print(\", num2 = \");\n      Serial.println(num2);\n\n      troca(&amp;num1, &amp;num2);\n\n      Serial.print(\"Depois da troca: num1 = \");\n      Serial.print(num1);\n      Serial.print(\", num2 = \");\n      Serial.println(num2);\n\n      while (true); // Pausa o programa ap\u00f3s a execu\u00e7\u00e3o\n    }\n  }\n</code></pre> <p>Progress</p> <p>Continuar...</p>"},{"location":"aulas/iot/ex0/solucao.html#exercicio-9","title":"Exercicio 9","text":"<p>Exercise</p> <p>Estruturas (structs) e Tipos Definidos pelo Usu\u00e1rio</p> <p>Crie um programa que gerencia informa\u00e7\u00f5es de alunos, como nome, idade e notas. Utilize structs para armazenar as informa\u00e7\u00f5es e fun\u00e7\u00f5es para realizar opera\u00e7\u00f5es, como adicionar um aluno, remover um aluno, calcular a m\u00e9dia das notas e exibir as informa\u00e7\u00f5es dos alunos no Monitor Serial.</p> <p>Tip</p> <p>Esse eu fiz com ajuda do gpt, n\u00e3o consegui testar pra saber se est\u00e1 funcionando....</p> <pre><code>struct Aluno {\n    String nome;\n    int idade;\n    float notas[3];\n  };\n\n  Aluno alunos[10];\n  int alunoCount = 0;\n\n  void adicionarAluno() {\n    if (alunoCount &lt; 10) {\n      Serial.println(\"Digite o nome do aluno:\");\n      while (Serial.available() == 0) {}\n      alunos[alunoCount].nome = Serial.readString();\n\n      Serial.println(\"Digite a idade do aluno:\");\n      while (Serial.available() == 0) {}\n      alunos[alunoCount].idade = Serial.parseInt();\n\n      for (int i = 0; i &lt; 3; i++) {\n        Serial.print(\"Digite a nota \");\n        Serial.print(i + 1);\n        Serial.println(\":\");\n        while (Serial.available() == 0) {}\n        alunos[alunoCount].notas[i] = Serial.parseFloat();\n      }\n\n      alunoCount++;\n    } else {\n      Serial.println(\"N\u00famero m\u00e1ximo de alunos alcan\u00e7ado.\");\n    }\n  }\n\n  void exibirAlunos() {\n    for (int i = 0; i &lt; alunoCount; i++) {\n      Serial.print(\"Nome: \");\n      Serial.println(alunos[i].nome);\n      Serial.print(\"Idade: \");\n      Serial.println(alunos[i].idade);\n      float media = 0;\n      for (int j = 0; j &lt; 3; j++) {\n        Serial.print(\"Nota \");\n        Serial.print(j + 1);\n        Serial.print(\": \");\n        Serial.println(alunos[i].notas[j]);\n        media += alunos[i].notas[j];\n      }\n      Serial.print(\"M\u00e9dia: \");\n      Serial.println(media / 3);\n    }\n  }\n\n  void setup() {\n    Serial.begin(9600);\n    Serial.println(\"Gerenciamento de alunos:\");\n    adicionarAluno();\n    adicionarAluno();\n    exibirAlunos();\n  }\n\n  void loop() {}\n</code></pre>"},{"location":"aulas/iot/ex1/index.html","title":"Index","text":""},{"location":"aulas/iot/ex1/index.html#o-que-esse-codigo-faz","title":"O que esse c\u00f3digo faz?","text":"<p>Este c\u00f3digo de exemplo demonstra como piscar um LED com arduino (blink led).</p>"},{"location":"aulas/iot/ex1/index.html#circuito-protoboard","title":"Circuito protoboard","text":""},{"location":"aulas/iot/ex1/index.html#codigo","title":"C\u00f3digo","text":"<pre><code>int led = 13; //defindo o valor 13 para a vari\u00e1vel led\n\nvoid setup(){\n    pinMode(led,OUTPUT); //declara led (pino 13 do arduino) como saida (OUTPUT)\n}\n\nvoid loop(){\n    digitalWrite(led, HIGH); //acende (HIGH) o led\n    delay(1000); //delay em milisegundos (1 seg)\n    digitalWrite(led, LOW); //apaga o led (LOW)\n    delay(1000); //delay em milisegundos\n}\n</code></pre> Circuito simulador"},{"location":"aulas/iot/ex1/index.html#links-para-download","title":"Links para Download","text":"<ul> <li> <p>C\u00f3digo arduino </p> </li> <li> <p>Thinkercad online</p> </li> <li> <p>SimulIDE</p> </li> </ul>"},{"location":"aulas/iot/ex2/index.html","title":"Index","text":""},{"location":"aulas/iot/ex2/index.html#o-que-esse-codigo-faz","title":"O que esse c\u00f3digo faz?","text":"<p>Este c\u00f3digo de exemplo demonstra como acender e apagar um LED em um intervalo de 100 milissegundos ao pressionar um bot\u00e3o com Arduino.</p>"},{"location":"aulas/iot/ex2/index.html#circuito-protoboard","title":"Circuito protoboard","text":""},{"location":"aulas/iot/ex2/index.html#codigo","title":"C\u00f3digo","text":"<pre><code>const int led = 13; //define o apelido led para o valor 13\nconst int botao = 5; //define o apelido botao para o valor 5\n\nvoid setup(){\n  pinMode(led, OUTPUT); //declara o pino13 (led) como sa\u00edda\n  pinMode(botao, INPUT_PULLUP); //declara o pino5 (botao) como entrada\n}\n\nvoid loop(){\n  // Faz a leitura do botao\n  if (digitalRead(botao) == LOW) {\n    digitalWrite(led, HIGH); //acende o led\n    delay(100); //delay em milissegundos\n    digitalWrite(led, LOW); //apaga o led\n    delay(100); //delay em milissegundos\n  }\n}\n</code></pre> Circuito simulador"},{"location":"aulas/iot/ex2/index.html#links-para-download","title":"Links para Download","text":"<ul> <li> <p>C\u00f3digo arduino</p> </li> <li> <p>Thinkercad online</p> </li> </ul>"},{"location":"aulas/iot/ex3/index.html","title":"Index","text":""},{"location":"aulas/iot/ex3/index.html#o-que-esse-codigo-faz","title":"O que esse c\u00f3digo faz?","text":"<p>Este c\u00f3digo de exemplo demonstra como controlar dois LEDs com Arduino usando um bot\u00e3o e um potenci\u00f4metro. Um LED acende e apaga em um intervalo de 100 milissegundos ao pressionar um bot\u00e3o, enquanto o outro LED acende e apaga no mesmo intervalo quando o valor do potenci\u00f4metro \u00e9 maior ou igual a 500.</p>"},{"location":"aulas/iot/ex3/index.html#circuito-protoboard","title":"Circuito protoboard","text":""},{"location":"aulas/iot/ex3/index.html#codigo","title":"C\u00f3digo","text":"<pre><code>const int led = 13; //define o apelido led para o valor 13\nconst int botao = 5; //define o apelido botao para o valor 5\nconst int ledPwm = 11; //define o apelido ledPwm para o valor 11\nconst int potAD = A0; //define o apelido potenciometro para o valor A0\n\nvoid setup(){\n  // Entradas e sa\u00eddas digitais\n  pinMode(led, OUTPUT); //declara o pino13 (led) como sa\u00edda\n  pinMode(botao, INPUT_PULLUP); //declara o pino5 (botao) como entrada\n\n  // Entradas e sa\u00eddas anal\u00f3gicas\n  pinMode(ledPwm, OUTPUT); //declara o pino11 (ledPwm) como sa\u00edda\n  pinMode(potAD, INPUT); //declara o pinoA0 (potenciometro) como entrada\n}\n\nvoid loop(){\n  // Faz a leitura do botao\n  if (digitalRead(botao) == LOW) {\n    digitalWrite(led, HIGH); //acende o led\n    delay(100); //delay em milissegundos\n    digitalWrite(led, LOW); //apaga o led\n    delay(100); //delay em milissegundos\n  }\n  // Faz a leitura anal\u00f3gica do potenciometro\n  int pot = analogRead(potAD);\n  if (pot &gt;= 500) {\n    digitalWrite(ledPwm, HIGH); //acende o led\n    delay(100); //delay em milissegundos\n    digitalWrite(ledPwm, LOW); //apaga o led\n    delay(100); //delay em milissegundos\n  }\n}\n</code></pre> Circuito simulador"},{"location":"aulas/iot/ex3/index.html#links-para-download","title":"Links para Download","text":"<ul> <li> <p>C\u00f3digo arduino</p> </li> <li> <p>Thinkercad online</p> </li> </ul>"},{"location":"aulas/iot/ex4/index.html","title":"Index","text":""},{"location":"aulas/iot/ex4/index.html#o-que-esse-codigo-faz","title":"O que esse c\u00f3digo faz?","text":"<p>Este c\u00f3digo de exemplo demonstra como controlar dois LEDs com Arduino usando um bot\u00e3o e um potenci\u00f4metro, substituindo o uso de <code>delay()</code> por <code>millis()</code>. Um LED alterna seu estado a cada 100 milissegundos ao pressionar um bot\u00e3o, enquanto o outro LED alterna seu estado no mesmo intervalo quando o valor do potenci\u00f4metro \u00e9 maior ou igual a 500.</p>"},{"location":"aulas/iot/ex4/index.html#circuito-protoboard","title":"Circuito protoboard","text":""},{"location":"aulas/iot/ex4/index.html#codigo","title":"C\u00f3digo","text":"<pre><code>const int led = 13; //define o apelido led para o valor 13\nconst int botao = 5; //define o apelido botao para o valor 5\nconst int ledPwm = 11; //define o apelido ledPwm para o valor 11\nconst int potAD = A0; //define o apelido potenciometro para o valor A0\n\nunsigned long tempo1 = 0, tempo2 = 0;\n\nvoid setup() {\n  // Entradas e sa\u00eddas digitais\n  pinMode(led, OUTPUT); //declara o pino13 (led) como sa\u00edda\n  pinMode(botao, INPUT_PULLUP); //declara o pino5 (botao) como entrada\n\n  // Entradas e sa\u00eddas anal\u00f3gicas\n  pinMode(ledPwm, OUTPUT); //declara o pino11 (ledPwm) como sa\u00edda\n  pinMode(potAD, INPUT); //declara o pinoA0 (potenciometro) como entrada\n}\n\nvoid loop() {\n  //usando millis no lugar do delay\n  if (millis() - tempo1 &gt;= 100){\n    tempo1 = millis(); \n    if (digitalRead(botao) == LOW){\n      digitalWrite(led, !digitalRead(led));    \n    }\n  }\n  // usando millis \n  int pot = analogRead(potAD);\n  if (millis() - tempo2 &gt;= 100 &amp;&amp; pot &gt;= 500){\n    tempo2 = millis(); \n    digitalWrite(ledPwm, !digitalRead(ledPwm));     \n  }\n}\n</code></pre> Circuito simulador"},{"location":"aulas/iot/ex4/index.html#links-para-download","title":"Links para Download","text":"<ul> <li> <p>C\u00f3digo arduino</p> </li> <li> <p>Thinkercad online</p> </li> </ul>"},{"location":"aulas/iot/ex5/index.html","title":"Index","text":""},{"location":"aulas/iot/ex5/index.html#o-que-esse-codigo-faz","title":"O que esse c\u00f3digo faz?","text":"<p>Este c\u00f3digo de exemplo demonstra como controlar dois LEDs com Arduino usando um bot\u00e3o e um potenci\u00f4metro. Um LED \u00e9 acionado por uma interrup\u00e7\u00e3o externa quando o bot\u00e3o \u00e9 pressionado, e o outro LED alterna seu estado quando o valor do potenci\u00f4metro \u00e9 maior ou igual a 500.</p>"},{"location":"aulas/iot/ex5/index.html#circuito-protoboard","title":"Circuito protoboard","text":""},{"location":"aulas/iot/ex5/index.html#codigo","title":"C\u00f3digo","text":"<pre><code>const int led = 13; //define o apelido led para o valor 13\nconst int botao = 2; //define o apelido botao para o valor 2\nconst int ledPwm = 11; //define o apelido ledPwm para o valor 11\nconst int potAD = A0; //define o apelido potenciometro para o valor A0\n\nvoid setup(){\n  // Entradas e sa\u00eddas digitais\n  pinMode(led, OUTPUT); //declara o pino13 (led) como sa\u00edda\n  pinMode(botao, INPUT_PULLUP); //declara o pino2 (botao) como entrada\n  // Entradas e sa\u00eddas anal\u00f3gicas\n  pinMode(ledPwm, OUTPUT); //declara o pino11 (ledPwm) como sa\u00edda\n  pinMode(potAD, INPUT); //declara o pinoA0 (potenciometro) como entrada\n\n  // Configura\u00e7\u00e3o da Interrup\u00e7\u00e3o\n  attachInterrupt(digitalPinToInterrupt(botao), interrupcaoPino2, RISING);  // Configura o pino2 como interrup\u00e7\u00e3o externa do tipo Rising (borda de LOW para HIGH)\n}\n\nvoid loop(){  \n  // Programa principal\n  int pot = analogRead(potAD);\n  if (pot &gt;= 500){\n    digitalWrite(ledPwm, !digitalRead(ledPwm)); \n    delay(100);    \n  } \n}\n\nvoid interrupcaoPino2() // Fun\u00e7\u00e3o de interrup\u00e7\u00e3o do pino2, \u00e9 executado quando o bot\u00e3o do pino2 \u00e9 pressionado\n{                    \n  digitalWrite(led, !digitalRead(led));\n}\n</code></pre> Circuito simulador"},{"location":"aulas/iot/ex5/index.html#links-para-download","title":"Links para Download","text":"<ul> <li> <p>C\u00f3digo arduino</p> </li> <li> <p>Thinkercad online</p> </li> </ul>"},{"location":"aulas/iot/ex6/index.html","title":"Index","text":""},{"location":"aulas/iot/ex6/index.html#o-que-esse-codigo-faz","title":"O que esse c\u00f3digo faz?","text":"<p>Este c\u00f3digo de exemplo demonstra como realizar a comunica\u00e7\u00e3o serial entre um arduino e um computador, neste exeplo vamos usar um script python.</p> <p></p>"},{"location":"aulas/iot/ex6/index.html#um-pouquinho-de-teoria","title":"Um pouquinho de teoria","text":"<ul> <li> <p><code>Defini\u00e7\u00e3o de comunica\u00e7\u00e3o serial</code>: A comunica\u00e7\u00e3o serial \u00e9 um m\u00e9todo de comunica\u00e7\u00e3o de dados em que os bits de informa\u00e7\u00f5es s\u00e3o transmitidos sequencialmente, um ap\u00f3s o outro, atrav\u00e9s de um \u00fanico canal de comunica\u00e7\u00e3o. \u00c9 uma abordagem simples e comum para transferir dados entre dispositivos, como microcontroladores e computadores.</p> </li> <li> <p><code>Taxa de transmiss\u00e3o (baud rate)</code>: A taxa de transmiss\u00e3o, ou baud rate, \u00e9 a velocidade na qual os bits s\u00e3o transmitidos atrav\u00e9s do canal de comunica\u00e7\u00e3o serial. \u00c9 medida em bits por segundo (bps). Taxas de transmiss\u00e3o comuns comumente utilizadas incluem 9600, 19200 e 115200 bps. A taxa de transmiss\u00e3o deve ser configurada corretamente em ambos os dispositivos de comunica\u00e7\u00e3o (transmissor e receptor) para garantir que os dados sejam transmitidos e recebidos com precis\u00e3o.</p> </li> <li> <p><code>Protocolos de comunica\u00e7\u00e3o serial</code>: Existem v\u00e1rios protocolos de comunica\u00e7\u00e3o serial dispon\u00edveis, cada um com suas pr\u00f3prias especifica\u00e7\u00f5es e caracter\u00edsticas. Alguns dos protocolos mais comuns incluem UART (Universal Asynchronous Receiver/Transmitter), SPI (Serial Peripheral Interface) e I2C (Inter-Integrated Circuit). Neste tutorial, estamos usando a comunica\u00e7\u00e3o UART atrav\u00e9s da porta serial dispon\u00edvel no Arduino.</p> </li> <li> <p><code>Aplica\u00e7\u00f5es da comunica\u00e7\u00e3o serial</code>: A comunica\u00e7\u00e3o serial \u00e9 amplamente utilizada em v\u00e1rias aplica\u00e7\u00f5es, como comunica\u00e7\u00e3o entre microcontroladores e perif\u00e9ricos (por exemplo, sensores, displays, etc.), comunica\u00e7\u00e3o entre computadores e dispositivos eletr\u00f4nicos (por exemplo, impressoras, modems, etc.), e at\u00e9 mesmo em redes de comunica\u00e7\u00e3o industrial (por exemplo, Modbus, Profibus, etc.).</p> </li> <li> <p><code>Vantagens da comunica\u00e7\u00e3o serial</code>: Algumas das principais vantagens da comunica\u00e7\u00e3o serial incluem sua simplicidade, baixo custo, capacidade de transmitir dados a longas dist\u00e2ncias e baixa contagem de pinos nos dispositivos envolvidos.</p> </li> </ul>"},{"location":"aulas/iot/ex6/index.html#codigos","title":"C\u00f3digos","text":"<p>O c\u00f3digo funciona como um \"Eco\", o script Python enviar\u00e1 a mensagem para o Arduino, que a ler\u00e1 e a enviar\u00e1 de volta. A mensagem ser\u00e1 exibida no terminal ou prompt de comando.</p> <pre><code>void setup() {\n  Serial.begin(9600); // Inicia a comunica\u00e7\u00e3o serial com uma taxa de transmiss\u00e3o de 9600 bps\n}\n\nvoid loop() {\n  if (Serial.available() &gt; 0) { // Verifica se h\u00e1 dados dispon\u00edveis para leitura\n    String message = Serial.readString(); // L\u00ea a mensagem enviada pelo Python\n    Serial.println(message); // Envia a mensagem de volta para o Python\n  }\n}\n</code></pre> <p>A segunda parte \u00e9 o c\u00f3digo python (lembre-se de criar um arduino_serial.py)</p> <pre><code>import serial\nimport time\n\ndef main():\n    ser = serial.Serial('COM3', 9600) # Altere 'COM3' para a porta serial do seu Arduino\n    time.sleep(2) # D\u00e1 tempo para a conex\u00e3o ser estabelecida\n\n    while True:\n        msg = input(\"Digite uma mensagem para enviar ao Arduino: \")\n        ser.write(msg.encode()) # Envia a mensagem para o Arduino\n        time.sleep(1) # Aguarda a resposta do Arduino\n\n        while ser.inWaiting() &gt; 0:\n            response = ser.readline().decode().strip() # L\u00ea a resposta do Arduino\n            print(\"Resposta do Arduino:\", response)\n\nif __name__ == \"__main__\":\n    main()\n</code></pre>"},{"location":"aulas/iot/ex6/index.html#executando-o-script","title":"Executando o script","text":"<ul> <li>Abra o terminal ou prompt de comando e navegue at\u00e9 a pasta onde o arquivo \"arduino_serial.py\" est\u00e1 localizado.</li> <li>Execute o seguinte comando: python arduino_serial.py</li> <li>Digite a mensagem que deseja enviar para o Arduino e pressione Enter.</li> <li>O script Python enviar\u00e1 a mensagem para o Arduino, que a ler\u00e1 e a enviar\u00e1 de volta. A mensagem ser\u00e1 exibida no terminal ou prompt de comando.</li> </ul>"},{"location":"aulas/iot/ex6/index.html#desafios","title":"Desafios","text":""},{"location":"aulas/iot/ex6/index.html#desafio-1","title":"Desafio 1","text":"<p>Fa\u00e7a os ajustes necess\u00e1rios para solucionar o checkpoint.</p>"},{"location":"aulas/iot/ex7/index.html","title":"Index","text":""},{"location":"aulas/iot/ex7/index.html#o-que-esse-codigo-faz","title":"O que esse c\u00f3digo faz?","text":"<p>Este c\u00f3digo de exemplo demonstra o uso de PWM</p>"},{"location":"aulas/iot/ex7/index.html#circuito-protoboard","title":"Circuito protoboard","text":""},{"location":"aulas/iot/ex7/index.html#codigo","title":"C\u00f3digo","text":"<pre><code>    const int ledPin = 11; // Pino do LED (suporta PWM)\n    const int potPin = A0; // Pino do potenci\u00f4metro\n\n    void setup() {\n      pinMode(ledPin, OUTPUT);\n    }\n\n    void loop() {\n      int sensorValue = analogRead(potPin); // L\u00ea o valor do potenci\u00f4metro\n      int pwmValue = map(sensorValue, 0, 1023, 0, 255); // Mapeia o valor lido para o intervalo do PWM (0-255)\n      analogWrite(ledPin, pwmValue); // Define o duty cycle do PWM\n      delay(10);\n    }\n</code></pre> Circuito simulador"},{"location":"aulas/iot/ex7/index.html#links-para-download","title":"Links para Download","text":"<ul> <li> <p>C\u00f3digo arduino</p> </li> <li> <p>Thinkercad online</p> </li> </ul>"},{"location":"aulas/iot/intro/index.html","title":"Introdu\u00e7\u00e3o","text":"<p>Fa\u00e7a o download do pdf de Introdu\u00e7\u00e3o.</p> <ul> <li>arquivo pdf: Introdu\u00e7\u00e3o</li> </ul>"},{"location":"aulas/iot/intro/dicas.html","title":"Eletr\u00f4nica b\u00e1sica","text":""},{"location":"aulas/iot/intro/dicas.html#introducao-a-eletricidade-basica","title":"Introdu\u00e7\u00e3o \u00e0 Eletricidade B\u00e1sica","text":"<p>A eletr\u00f4nica \u00e9 o ramo da f\u00edsica que estuda o fluxo de el\u00e9trons em materiais semicondutores, condutores e isolantes. Compreender os conceitos fundamentais de eletricidade \u00e9 essencial para o desenvolvimento de circuitos e sistemas eletr\u00f4nicos.</p>"},{"location":"aulas/iot/intro/dicas.html#conceitos-fundamentais","title":"Conceitos Fundamentais","text":"<ul> <li>Carga El\u00e9trica ( Q ): Propriedade das part\u00edculas que determina as intera\u00e7\u00f5es eletromagn\u00e9ticas. Medida em coulombs (C).</li> <li>Corrente El\u00e9trica ( I ): Fluxo de cargas el\u00e9tricas atrav\u00e9s de um condutor. Medida em amperes (A).</li> </ul> <p>$$   I = \\frac{dQ}{dt}   $$</p> <ul> <li>Tens\u00e3o El\u00e9trica (Diferen\u00e7a de Potencial,  V ): Energia potencial el\u00e9trica por unidade de carga. Medida em volts (V).</li> <li>Resist\u00eancia El\u00e9trica ( R ): Oposi\u00e7\u00e3o ao fluxo de corrente em um material. Medida em ohms (\u03a9).</li> </ul>"},{"location":"aulas/iot/intro/dicas.html#lei-de-ohm","title":"Lei de Ohm","text":"<p>A rela\u00e7\u00e3o entre tens\u00e3o, corrente e resist\u00eancia \u00e9 dada pela Lei de Ohm:</p> <p>$$   V = R \\times I   $$</p> <p>Onde:</p> <ul> <li> V : Tens\u00e3o em volts (V)</li> <li> I : Corrente em amperes (A)</li> <li> R : Resist\u00eancia em ohms (\u03a9)</li> </ul>"},{"location":"aulas/iot/intro/dicas.html#simuladores-eletronicos","title":"Simuladores Eletr\u00f4nicos","text":"<p>Os simuladores eletr\u00f4nicos s\u00e3o ferramentas essenciais para projetar, testar e validar circuitos antes da montagem f\u00edsica. Eles permitem economizar tempo e recursos, identificando poss\u00edveis problemas antecipadamente.</p>"},{"location":"aulas/iot/intro/dicas.html#principais-simuladores","title":"Principais Simuladores","text":"<ul> <li>Wokwi: Simulador online gratuito que permite simular microcontroladores como Arduino, ESP32 e Raspberry Pi Pico, al\u00e9m de diversos componentes eletr\u00f4nicos.</li> </ul> <p>Wokwi - Simulador Online</p> <ul> <li>SimulIDE: Simulador offline em tempo real para eletr\u00f4nica, microcontroladores e Arduino. \u00c9 uma ferramenta leve que oferece simula\u00e7\u00e3o de circuitos anal\u00f3gicos e digitais.</li> </ul> <p>Site Oficial do SimulIDE</p> <ul> <li> <p>SPICE (Simulation Program with Integrated Circuit Emphasis): Um padr\u00e3o da ind\u00fastria para simula\u00e7\u00e3o de circuitos anal\u00f3gicos e digitais.</p> </li> <li> <p>LTspice: Gratuito, oferecido pela Analog Devices.     Download LTspice</p> </li> <li> <p>Proteus: Software que combina simula\u00e7\u00e3o de circuitos com simula\u00e7\u00e3o de microcontroladores.</p> </li> </ul> <p>Site Oficial do Proteus</p> <ul> <li>Tinkercad Circuits: Simulador online gratuito, ideal para iniciantes.</li> </ul> <p>Tinkercad Circuits</p>"},{"location":"aulas/iot/intro/dicas.html#vantagens-do-uso-de-simuladores","title":"Vantagens do Uso de Simuladores","text":"<ul> <li>Economia de Recursos: Evita desperd\u00edcio de componentes e materiais.</li> <li>Seguran\u00e7a: Permite testar circuitos sem risco de danos f\u00edsicos.</li> <li>An\u00e1lise Detalhada: Possibilidade de visualizar formas de onda, correntes e tens\u00f5es em diferentes pontos do circuito.</li> <li>Itera\u00e7\u00e3o R\u00e1pida: Facilita modifica\u00e7\u00f5es e otimiza\u00e7\u00f5es no projeto.</li> </ul>"},{"location":"aulas/iot/intro/dicas.html#protoboard","title":"Protoboard","text":"<p>A protoboard \u00e9 uma plataforma de prototipagem sem solda utilizada em eletr\u00f4nica para montar circuitos tempor\u00e1rios e testar configura\u00e7\u00f5es antes da implementa\u00e7\u00e3o final. Sua estrutura interna \u00e9 composta por trilhas condutoras de metal organizadas em linhas e colunas, permitindo conex\u00f5es r\u00e1pidas e reconfigur\u00e1veis entre componentes.</p>"},{"location":"aulas/iot/intro/dicas.html#estrutura-interna","title":"Estrutura Interna","text":"<ul> <li>Barramentos de Alimenta\u00e7\u00e3o: Localizados nas extremidades da protoboard, esses barramentos s\u00e3o utilizados para distribuir as tens\u00f5es de alimenta\u00e7\u00e3o e terra (GND) ao longo da placa. \u00c9 comum que sejam separados no meio, exigindo pontes de conex\u00e3o para continuidade el\u00e9trica.</li> <li>\u00c1reas de Conex\u00e3o: No centro, a protoboard possui grupos de cinco furos conectados eletricamente em colunas, permitindo a inser\u00e7\u00e3o de terminais de componentes e jumpers para interliga\u00e7\u00e3o.</li> </ul>"},{"location":"aulas/iot/intro/dicas.html#boas-praticas-de-utilizacao","title":"Boas Pr\u00e1ticas de Utiliza\u00e7\u00e3o","text":"<ul> <li>Organiza\u00e7\u00e3o dos Componentes: Posicione os componentes de maneira l\u00f3gica para minimizar o comprimento dos jumpers e reduzir interfer\u00eancias eletromagn\u00e9ticas. Componentes similares devem ser agrupados para facilitar a an\u00e1lise do circuito.</li> <li>Integridade das Conex\u00f5es: Utilize jumpers de qualidade e evite a inser\u00e7\u00e3o excessiva de componentes nos mesmos pontos para prevenir desgaste dos contatos internos, que pode levar a mau funcionamento devido a conex\u00f5es intermitentes.</li> <li>Desacoplamento de Alimenta\u00e7\u00e3o: Em circuitos com componentes sens\u00edveis ou de alta velocidade, adicione capacitores de desacoplamento pr\u00f3ximos aos pinos de alimenta\u00e7\u00e3o dos CI's para reduzir ru\u00eddos e instabilidades causadas por flutua\u00e7\u00f5es na tens\u00e3o de alimenta\u00e7\u00e3o.</li> <li>Limita\u00e7\u00f5es: Evite utilizar a protoboard para circuitos de alta frequ\u00eancia ou correntes elevadas, pois a indut\u00e2ncia e capacit\u00e2ncia parasitas podem afetar o desempenho do circuito.</li> </ul> <p>Tip</p> <p>Para um guia detalhado sobre a utiliza\u00e7\u00e3o eficiente da protoboard, consulte: https://portal.vidadesilicio.com.br/protoboard/</p>"},{"location":"aulas/iot/intro/dicas.html#chaves-e-botoes","title":"Chaves e Bot\u00f5es","text":"<p>Chaves e bot\u00f5es s\u00e3o componentes eletromec\u00e2nicos utilizados para controlar o fluxo de corrente em um circuito, funcionando como dispositivos de entrada em sistemas digitais.</p>"},{"location":"aulas/iot/intro/dicas.html#consideracoes-tecnicas","title":"Considera\u00e7\u00f5es T\u00e9cnicas","text":"<ul> <li>Tipos de Chaves: Existem diversos tipos, como SPST (Single Pole Single Throw), SPDT (Single Pole Double Throw), DPDT (Double Pole Double Throw), cada um adequado para aplica\u00e7\u00f5es espec\u00edficas conforme a necessidade de contatos e configura\u00e7\u00f5es de circuito.</li> <li>Debouncing: Devido \u00e0s caracter\u00edsticas mec\u00e2nicas, ao acionar uma chave ou bot\u00e3o, podem ocorrer m\u00faltiplos contatos r\u00e1pidos (bounce), gerando ru\u00eddos no sinal. \u00c9 importante implementar t\u00e9cnicas de debouncing, seja por hardware (capacitores, resistores) ou software (algoritmos de filtragem), para garantir a estabilidade do sinal de entrada.</li> <li>Pull-up e Pull-down Resistores: Utilizados para definir um n\u00edvel l\u00f3gico definido quando a chave est\u00e1 aberta, prevenindo estados flutuantes que podem causar comportamento indeterminado no circuito digital.</li> </ul> <p>Tip</p> <p>Para aprofundar-se no tema de chaves e bot\u00f5es, acesse: https://www.robocore.net/tutoriais/introducao-a-chaves-e-botoes</p>"},{"location":"aulas/iot/intro/dicas.html#leds","title":"LEDs","text":"<p>Os LEDs (Light Emitting Diodes) s\u00e3o dispositivos semicondutores que emitem luz quando polarizados diretamente. S\u00e3o utilizados nas mais diversas aplica\u00e7\u00f5es do nosso dia-a-dia como indicadores luminosos em circuitos eletr\u00f4nicos.</p>"},{"location":"aulas/iot/intro/dicas.html#caracteristicas-e-utilizacao","title":"Caracter\u00edsticas e Utiliza\u00e7\u00e3o","text":"<ul> <li>Polaridade: LEDs possuem anodo (+) e catodo (-). A corrente deve fluir do anodo para o catodo; a invers\u00e3o de polaridade impede a condu\u00e7\u00e3o e pode danificar o componente.</li> <li>Tens\u00e3o e Corrente: Cada LED possui uma tens\u00e3o direta ($ V_{\\text{LED}} ) espec\u00edfica, geralmente entre 1,8V e 3,3V, e uma corrente nominal ( I_{\\text{LED}} $), tipicamente 10mA a 20mA.</li> </ul>"},{"location":"aulas/iot/intro/dicas.html#calculo-do-resistor-limitador","title":"C\u00e1lculo do Resistor Limitador","text":"<p>Para limitar a corrente e proteger o LED, calcula-se o resistor em s\u00e9rie:</p> <p>$$   R = \\frac{V_{fonte} - V_{LED}}{I_{LED}}   $$</p> <p>Onde:</p> <ul> <li>$ V_{\\text{fonte}} $: Tens\u00e3o da fonte de alimenta\u00e7\u00e3o.</li> <li>$ V_{\\text{LED}} $: Queda de tens\u00e3o no LED.</li> <li>$ I_{\\text{LED}} $: Corrente desejada atrav\u00e9s do LED.</li> </ul> <p>Exemplo: Para um LED com $ V_{\\text{LED}} = 2V $ alimentado por uma fonte de 5V e corrente de 15mA:</p> <p>$$   R = \\frac{5V - 2V}{15mA} = 200 \\Omega   $$</p> <p>Nesse caso o valor comercial \u00e9 $R = 220 \\Omega $.</p>"},{"location":"aulas/iot/intro/dicas.html#aplicacoes-avancadas","title":"Aplica\u00e7\u00f5es Avan\u00e7adas","text":"<ul> <li>Controle por PWM: A modula\u00e7\u00e3o por largura de pulso permite controlar a intensidade luminosa do LED, variando o ciclo de trabalho do sinal de controle.</li> <li>Multiplexa\u00e7\u00e3o: Em sistemas com m\u00faltiplos LEDs, a multiplexa\u00e7\u00e3o permite controlar v\u00e1rios LEDs com menos pinos do microcontrolador, acionando-os em sequ\u00eancias r\u00e1pidas para criar a ilus\u00e3o de ilumina\u00e7\u00e3o cont\u00ednua.</li> <li>Matrizes de LEDs: Utilizadas em displays e pain\u00e9is, exigem t\u00e9cnicas espec\u00edficas de controle, como varredura de linhas e colunas, e cuidados com corrente total e dissipa\u00e7\u00e3o de calor.</li> </ul> <p>Tip</p> <p>Para mais detalhes sobre LEDs e circuitos associados, visite: https://www.makerhero.com/blog/aprenda-a-piscar-um-led-com-arduino/</p>"},{"location":"aulas/iot/intro/dicas.html#sensores-e-atuadores","title":"Sensores e Atuadores","text":"<p>Os sensores s\u00e3o dispositivos que detectam eventos ou mudan\u00e7as no ambiente f\u00edsico e fornecem uma sa\u00edda correspondente, geralmente sob a forma de um sinal el\u00e9trico. Atuadores convertem sinais el\u00e9tricos em a\u00e7\u00e3o f\u00edsica, permitindo ao sistema interagir com o ambiente.</p>"},{"location":"aulas/iot/intro/dicas.html#sensores","title":"Sensores","text":"<ul> <li>Tipos Comuns:</li> <li>Temperatura: Termistores, termopares, sensores digitais (DS18B20).</li> <li>Luminosidade: Fotoresistores (LDR), fotodiodos, fototransistores.</li> <li>Umidade: Sensores capacitivos e resistivos.</li> <li>Press\u00e3o: Sensores piezorresistivos, piezoel\u00e9tricos.</li> </ul>"},{"location":"aulas/iot/intro/dicas.html#atuadores","title":"Atuadores","text":"<ul> <li>Tipos Comuns:</li> <li>Motores DC: Convers\u00e3o de energia el\u00e9trica em movimento rotacional; requerem circuitos de controle como pontes H para revers\u00e3o de sentido.</li> <li>Servomotores: Oferecem controle preciso de posi\u00e7\u00e3o angular; controlados via sinal PWM espec\u00edfico.</li> <li>Rel\u00e9s: Permitem o acionamento de cargas de alta pot\u00eancia isolando o circuito de controle.</li> <li>Buzzer: Dispositivos piezoel\u00e9tricos utilizados para gerar som; podem ser controlados por sinais digitais ou anal\u00f3gicos.</li> </ul>"},{"location":"aulas/iot/intro/introarduino.html","title":"Sistemas Embarcados","text":""},{"location":"aulas/iot/intro/introarduino.html#conceitos-basicos-e-introdutorios","title":"Conceitos b\u00e1sicos e introdut\u00f3rios","text":"<p>A programa\u00e7\u00e3o arduino n\u00e3o \u00e9 complicada, vou apresentar alguns conceitos importante relacionados a software, ferramentas e hardware para te ajudar a embarcar nesse universo.</p>"},{"location":"aulas/iot/intro/introarduino.html#placa-arduino","title":"Placa Arduino","text":"<p>Existem diversas placas e vers\u00f5es de Arduinos, vamos conhecer o mais simples e famoso, o Arduino UNO. Essa placa possui pinos que podem ser configurados como entradas e saidas para sensores atuadores ou para comunica\u00e7\u00e3o com outros sistemas de hardwares, como mostra a figura:</p> <p></p> <ol> <li>Microcontrolador - este \u00e9 o c\u00e9rebro de um Arduino, \u00e9 nele que carregamos os programas. Pense nisso como um min\u00fasculo computador, projetado para executar apenas um n\u00famero espec\u00edfico de coisas.</li> <li>Porta USB - usada para conectar sua placa Arduino a um computador.</li> <li>Chip USB para Serial - o USB para Serial, respons\u00e1vel por fazer a convers\u00e3o de protocolos, \u00e9 um componente importante, pois \u00e9 o que torna poss\u00edvel programar e comunicar a placa Arduino a partir do seu computador. </li> <li>Pinos digitais - pinos que usam l\u00f3gica digital (0,1 ou LOW/HIGH). Comumente usado para chaves e para ligar/desligar um LED.</li> <li>Pinos anal\u00f3gicos - pinos que podem ler valores anal\u00f3gicos em uma resolu\u00e7\u00e3o de 10 bits (0-1023).</li> <li>Pinos de 5V / 3,3V - esses pinos s\u00e3o usados para alimentar (energia) componentes externos.</li> <li>GND - tamb\u00e9m conhecido como terra, negativo, Ground, \u00e9 utilizado para completar um circuito, onde o n\u00edvel el\u00e9trico est\u00e1 em 0 volt.</li> <li>VIN - significa Voltage In, onde voc\u00ea pode conectar fontes de alimenta\u00e7\u00e3o externas.</li> </ol>"},{"location":"aulas/iot/intro/introarduino.html#pinagem","title":"Pinagem","text":"<p>A placa do Arduino UNO possui 14 pinos que podem ser configurados como Entrada/Saida (INPUT/OUTPUT) Digitai, 6 pinos de entrada Analogica com resolu\u00e7\u00e3o de 10 bits, Alguns pinos podem ser configurados para fun\u00e7\u00f5es especificas como Serial, PWM, SPI, TWI(I2C), ISR entre outros...   </p> <p></p>"},{"location":"aulas/iot/intro/introarduino.html#software-embarcado","title":"Software Embarcado","text":"<p>O software embarcado \u00e9 o programa que define o funcionamento de um sistema embarcado, ou sej\u00e1, \u00e9 o c\u00f3digo que fica gravado no chip da placa Arduino. Ele \u00e9 projetado para executar tarefas espec\u00edficas, com um alto grau de efici\u00eancia e confiabilidade. De forma geral, a estrutura de um c\u00f3digo segue um padr\u00e3o, que pode ser dividido em tr\u00eas partes principais:</p> <ol> <li>Inicializa\u00e7\u00e3o: Nesta etapa, o c\u00f3digo realiza a configura\u00e7\u00e3o inicial dos perif\u00e9ricos, como sensores e atuadores, e estabelece a comunica\u00e7\u00e3o com outros dispositivos ou sistemas. Isso inclui a configura\u00e7\u00e3o de pinos de entrada e sa\u00edda, taxas de comunica\u00e7\u00e3o, entre outros, no Arduino inclue a \"void setup()\".</li> <li>La\u00e7o de Repeti\u00e7\u00e3o Infinito: O la\u00e7o infinito, tamb\u00e9m conhecido no Arduino como \"void loop()\", \u00e9 o cora\u00e7\u00e3o do software embarcado. Ele \u00e9 respons\u00e1vel por manter o programa em execu\u00e7\u00e3o cont\u00ednua, permitindo que o sistema embarcado execute suas tarefas de forma repetitiva e ininterrupta.</li> <li>Interrup\u00e7\u00f5es: As interrup\u00e7\u00f5es s\u00e3o eventos que ocorrem de forma ass\u00edncrona ao la\u00e7o infinito, permitindo que o software embarcado responda a eventos externos ou internos, como sinais de sensores ou temporizadores. Esses eventos s\u00e3o geralmente tratados por fun\u00e7\u00f5es espec\u00edficas chamadas rotinas de servi\u00e7o de interrup\u00e7\u00e3o (ISR). </li> </ol> <p>Neste exemplo, a fun\u00e7\u00e3o \"setup()\" \u00e9 respons\u00e1vel pela inicializa\u00e7\u00e3o, enquanto a fun\u00e7\u00e3o \"loop()\" cont\u00e9m as tarefas a serem executadas repetidamente no la\u00e7o infinito.</p> <p><pre><code>int led = 13;\n\nvoid setup(){\n    pinMode(led,OUTPUT);\n}\n\nvoid loop(){\n    digitalWrite(led, HIGH); \n    delay(1000); \n    digitalWrite(led, LOW); \n    delay(1000); \n}\n</code></pre> A representa\u00e7\u00e3o deste programa pode ser visualizada na figura abaixo: </p> <p></p> <p>Para saber mais desse exemplo acesse: <code>Laborat\u00f3rio -&gt; IoT e Sistemas Embarcados --&gt; Blink led</code></p>"},{"location":"aulas/iot/intro/introarduino.html#a-linguagem-arduino","title":"A linguagem arduino","text":"<p>A linguagem Arduino \u00e9 propria, MAS \u00e9 baseada em C/C++ e simplifica a programa\u00e7\u00e3o de microcontroladores atrav\u00e9s de um ambiente de desenvolvimento integrado (IDE) amig\u00e1vel e simples.</p> <p>Agumas semelhan\u00e7as com as linguagens C/C++ (e outras tambem...) s\u00e3o:</p> <ul> <li> <p>Sintaxes e Estrutura b\u00e1sica: A estrutura b\u00e1sica do c\u00f3digo Arduino, incluindo a defini\u00e7\u00e3o de fun\u00e7\u00f5es, vari\u00e1veis, constantes e operadores, \u00e9 semelhante \u00e0 encontrada em C e C++.</p> </li> <li> <p>Fun\u00e7\u00f5es e bibliotecas: A linguagem Arduino permite a utiliza\u00e7\u00e3o de fun\u00e7\u00f5es e bibliotecas padr\u00e3o de C/C++, al\u00e9m de bibliotecas espec\u00edficas para Arduino.</p> </li> <li> <p>Ponteiros e aloca\u00e7\u00e3o de mem\u00f3ria: Assim como em C e C++, a linguagem Arduino permite o uso de ponteiros e a manipula\u00e7\u00e3o de mem\u00f3ria.</p> </li> </ul>"},{"location":"aulas/iot/intro/introarduino.html#entendo-elementos-basicos-de-codigo","title":"Entendo elementos b\u00e1sicos de c\u00f3digo","text":"<p>De forma geral a programa\u00e7\u00e3o de sistemas embarcados envolve o desenvolvimento de aplica\u00e7\u00f5es que interagem com o mundo f\u00edsico atrav\u00e9s de sensores e atuadores. Para compreender e dominar essas intera\u00e7\u00f5es, \u00e9 crucial aprender sobre os conceitos fundamentais, como Entrada e Sa\u00edda Digital, Debounce de bot\u00e3o Digital, Entrada e Sa\u00edda Anal\u00f3gica, Interrup\u00e7\u00e3o Externa e Interfaces de comunica\u00e7\u00e3o como UART/I2C/SPI (Comunica\u00e7\u00e3o Serial).</p>"},{"location":"aulas/iot/intro/introarduino.html#saida-digital","title":"Sa\u00edda Digital","text":"<p>A sa\u00edda digital \u00e9 uma forma b\u00e1sica de comunica\u00e7\u00e3o com componentes externos, como LEDs e rel\u00e9s. Os pinos de sa\u00edda digital podem ser configurados para atuar como fonte ou dreno de corrente, dependendo da necessidade do circuito. Os sinais s\u00e3o transmitidos como valores discretos, geralmente <code>0 (LOW) e 1 (HIGH)</code>. No Arduino, \u00e9 poss\u00edvel configurar os pinos de entrada/sa\u00edda como sa\u00edda digital usando a fun\u00e7\u00e3o pinMode() e controlar o estado do pino usando a fun\u00e7\u00e3o <code>digitalWrite()</code>.</p> Dica <p>Veja o lab Blink led</p>"},{"location":"aulas/iot/intro/introarduino.html#entrada-digital","title":"Entrada Digital","text":"<p>A entrada digital permite que um microcontrolador leia sinais digitais externos, geralmente <code>0 (LOW) e 1 (HIGH)</code>. No Arduino, os pinos de entrada/sa\u00edda podem ser configurados como entrada digital usando a fun\u00e7\u00e3o pinMode() e ler o estado do pino com a fun\u00e7\u00e3o <code>digitalRead()</code>.</p> Dica <p>Veja o lab Led bot\u00e3o</p>"},{"location":"aulas/iot/intro/introarduino.html#entrada-analogica","title":"Entrada Anal\u00f3gica","text":"<p>A convers\u00e3o de sinais anal\u00f3gicos em valores digitais \u00e9 realizada por um conversor anal\u00f3gico-digital (ADC) presente no microcontrolador. O ADC possui uma resolu\u00e7\u00e3o espec\u00edfica, geralmente 10 bits no Arduino UNO, que determina a quantidade de valores poss\u00edveis para representar o sinal anal\u00f3gico.</p> Dica <p>Veja o lab Bot\u00e3o pod led</p>"},{"location":"aulas/iot/intro/introarduino.html#pwm-saida-analogica","title":"PWM (Sa\u00edda \"Anal\u00f3gica\")","text":"<p>A t\u00e9cnica PWM permite controlar a energia entregue a dispositivos externos atrav\u00e9s da varia\u00e7\u00e3o do tempo de ativa\u00e7\u00e3o do sinal digital. A frequ\u00eancia do sinal PWM \u00e9 geralmente fixa, enquanto o duty cycle (raz\u00e3o entre o tempo de ativa\u00e7\u00e3o e o per\u00edodo do sinal) varia entre 0 e 100%. No Arduino UNO esse valor \u00e9 definido em 8bits, ou seja, de 0 at\u00e9 255.</p> Dica <p>Veja o lab PWM</p>"},{"location":"aulas/iot/intro/introarduino.html#interrupcao-externa","title":"Interrup\u00e7\u00e3o Externa","text":"<p>As interrup\u00e7\u00f5es externas podem ser configuradas para serem disparadas em diferentes condi\u00e7\u00f5es, como mudan\u00e7a de estado, n\u00edvel alto ou baixo e bordas de subida ou descida. Ao ser disparada, a interrup\u00e7\u00e3o executa a rotina de tratamento de interrup\u00e7\u00e3o, interrompendo temporariamente o fluxo principal do programa.</p> Dica <p>Veja o lab Interrup\u00e7\u00e3o de pino</p>"},{"location":"aulas/iot/intro/introarduino.html#o-uso-de-delay-em-sistemas-embarcados","title":"O uso de delay em sistemas embarcados","text":"<p>Evitar delays \u00e9 fundamental para garantir o bom funcionamento e a efici\u00eancia do sistema embarcado. O uso excessivo de delays pode resultar em um desempenho inadequado e na incapacidade de responder a eventos em tempo real. Ao inv\u00e9s de utilizar a fun\u00e7\u00e3o delay(), opte por utilizar millis() e t\u00e9cnicas de programa\u00e7\u00e3o n\u00e3o bloqueantes para criar temporiza\u00e7\u00f5es.</p> Dica <p>Veja o lab Fun\u00e7\u00e3o millis    </p>"},{"location":"aulas/iot/intro/introarduino.html#uart-comunicacao-serial","title":"UART (Comunica\u00e7\u00e3o Serial)","text":"<p>UART (Universal Asynchronous Receiver-Transmitter) \u00e9 um protocolo de comunica\u00e7\u00e3o serial que permite a transmiss\u00e3o de dados entre dispositivos de forma ass\u00edncrona, sem a necessidade de um clock de refer\u00eancia compartilhado. No Arduino, a comunica\u00e7\u00e3o serial \u00e9 geralmente implementada usando as fun\u00e7\u00f5es <code>Serial.begin(), Serial.print(), Serial.println() e Serial.read()</code>.</p> Dica <p>Veja o lab Comunica\u00e7\u00e3o Serial </p>"},{"location":"aulas/iot/intro/introarduino.html#referencias","title":"Refer\u00eancias","text":"<p>A comunidade Arduino \u00e9 muito grande e gera muito material de qualidade, \u00e9 facil encontrar foruns, tutoriais e videos que te auxiliam no aprendizado. De toda a forma, abaixo tem alguns link da documenta\u00e7\u00e3o oficial que podem te ajudar.</p> <ul> <li>https://www.arduino.cc/reference/en/?_gl=1*19zvap6*_ga*MTA5MDMxODM2My4xNjgyNTEwNDg3*_ga_NEXN8H46L5*MTY4MjUyNzkzMS4yLjEuMTY4MjUyODg0Ni4wLjAuMA..</li> <li>https://docs.arduino.cc/learn/starting-guide/getting-started-arduino#general</li> <li></li> </ul>"},{"location":"aulas/iot/lab01-esp/index.html","title":"Lab 01: Introdu\u00e7\u00e3o ao ESP32 e Conectividade IoT","text":"<p>Neste laborat\u00f3rio, vamos explorar o ESP32, um microcontrolador poderoso com recursos integrados de Wi-Fi e Bluetooth, tornando-o ideal para projetos IoT. Aprenderemos como configurar o ambiente de desenvolvimento, conectar \u00e0 internet, utilizar Bluetooth e enviar dados para plataformas IoT.</p>"},{"location":"aulas/iot/lab01-esp/index.html#objetivos-de-aprendizado","title":"Objetivos de Aprendizado","text":"<ul> <li>Configurar o ambiente de desenvolvimento para ESP32 no Arduino IDE</li> <li>Conectar o ESP32 a uma rede Wi-Fi</li> <li>Implementar comunica\u00e7\u00e3o por Bluetooth</li> <li>Enviar dados para uma plataforma IoT (ThingSpeak)</li> <li>Criar um servidor web simples com ESP32</li> </ul>"},{"location":"aulas/iot/lab01-esp/index.html#pre-requisitos","title":"Pr\u00e9-requisitos","text":"<ul> <li>Arduino IDE instalado</li> <li>Placa ESP32</li> <li>Cabo micro-USB</li> <li>Acesso a uma rede Wi-Fi</li> <li>Conhecimentos b\u00e1sicos de Arduino e eletr\u00f4nica</li> </ul>"},{"location":"aulas/iot/lab01-esp/index.html#1-configurando-o-esp32-no-arduino-ide","title":"1. Configurando o ESP32 no Arduino IDE","text":""},{"location":"aulas/iot/lab01-esp/index.html#11-instalando-o-suporte-a-placa-esp32","title":"1.1 Instalando o Suporte \u00e0 Placa ESP32","text":"<p>Para programar o ESP32 usando o <code>Arduino IDE **1.X**</code>, precisamos adicionar o pacote de suporte:</p> <ol> <li>Abra o Arduino IDE</li> <li>V\u00e1 para Arquivo &gt; Prefer\u00eancias</li> <li>No campo \"URLs Adicionais para Gerenciadores de Placas\", adicione:    <pre><code>https://dl.espressif.com/dl/package_esp32_index.json\n</code></pre></li> <li>Clique em \"OK\"</li> <li>V\u00e1 para Ferramentas &gt; Placa &gt; Gerenciador de Placas</li> <li>Pesquise por \"ESP32\" e instale \"ESP32 by Espressif Systems\"</li> <li>Ap\u00f3s a instala\u00e7\u00e3o, selecione sua placa ESP32 em Ferramentas &gt; Placa &gt; ESP32</li> </ol> <p>Warning</p> <p>Fa\u00e7a isso apenas para a vers\u00e3o 1.x do arduino IDE, para a vers\u00e3o 2.X voc\u00ea pode pesquisar e instalar diretamente a placa esp32.</p>"},{"location":"aulas/iot/lab01-esp/index.html#12-testando-a-instalacao-blink-com-esp32","title":"1.2 Testando a Instala\u00e7\u00e3o: Blink com ESP32","text":"<p>Vamos come\u00e7ar com um exemplo simples para garantir que tudo esteja configurado corretamente:</p> <pre><code>// Programa b\u00e1sico de piscar LED para ESP32\n\n// LED interno do ESP32 (pode variar dependendo da placa)\nconst int LED_BUILTIN = 2;\n\nvoid setup() {\n  // Inicializa o pino digital como sa\u00edda\n  pinMode(LED_BUILTIN, OUTPUT);\n\n  // Inicia a comunica\u00e7\u00e3o serial\n  Serial.begin(115200);\n  Serial.println(\"ESP32 Blink Test\");\n}\n\nvoid loop() {\n  digitalWrite(LED_BUILTIN, HIGH);   // Liga o LED\n  Serial.println(\"LED ON\");\n  delay(1000);                      // Espera 1 segundo\n\n  digitalWrite(LED_BUILTIN, LOW);    // Desliga o LED\n  Serial.println(\"LED OFF\");\n  delay(1000);                      // Espera 1 segundo\n}\n</code></pre> <p>Carregue este c\u00f3digo e verifique se o LED interno do ESP32 pisca. Se funcionar, sua configura\u00e7\u00e3o est\u00e1 correta.</p>"},{"location":"aulas/iot/lab01-esp/index.html#2-conectando-esp32-a-internet-via-wi-fi","title":"2. Conectando ESP32 \u00e0 Internet via Wi-Fi","text":""},{"location":"aulas/iot/lab01-esp/index.html#21-conexao-wi-fi-basica","title":"2.1 Conex\u00e3o Wi-Fi B\u00e1sica","text":"<p>O ESP32 tem capacidade Wi-Fi integrada. Vamos criar um exemplo simples para conectar \u00e0 sua rede Wi-Fi:</p> <pre><code>#include &lt;WiFi.h&gt;\n\n// Credenciais da rede Wi-Fi\nconst char* ssid = \"SUA_REDE_WIFI\";\nconst char* password = \"SUA_SENHA_WIFI\";\n\nvoid setup() {\n  Serial.begin(115200);\n  delay(1000);\n\n  Serial.println(\"\\nConectando \u00e0 rede Wi-Fi\");\n\n  // Inicia conex\u00e3o com Wi-Fi\n  WiFi.begin(ssid, password);\n\n  // Aguarda conex\u00e3o\n  while (WiFi.status() != WL_CONNECTED) {\n    delay(500);\n    Serial.print(\".\");\n  }\n\n  Serial.println(\"\");\n  Serial.println(\"Conectado \u00e0 rede Wi-Fi!\");\n  Serial.print(\"Endere\u00e7o IP: \");\n  Serial.println(WiFi.localIP());\n}\n\nvoid loop() {\n  // Seu c\u00f3digo aqui\n  delay(1000);\n}\n</code></pre> <p>Warning</p> <p>Antes de carregar o c\u00f3digo, substitua \"SUA_REDE_WIFI\" e \"SUA_SENHA_WIFI\" pelas informa\u00e7\u00f5es da sua rede Wi-Fi.</p>"},{"location":"aulas/iot/lab01-esp/index.html#22-criando-um-servidor-web-simples","title":"2.2 Criando um Servidor Web Simples","text":"<p>Vamos aproveitar a conex\u00e3o Wi-Fi para criar um servidor web simples que exibe dados e controla um LED:</p> <pre><code>#include &lt;WiFi.h&gt;\n#include &lt;WebServer.h&gt;\n\n// Credenciais da rede Wi-Fi\nconst char* ssid = \"SUA_REDE_WIFI\";\nconst char* password = \"SUA_SENHA_WIFI\";\n\n// Definindo a porta do servidor web (padr\u00e3o: 80)\nWebServer server(80);\n\n// LED pin\nconst int ledPin = 2;\nbool ledStatus = LOW;\n\nvoid setup() {\n  Serial.begin(115200);\n  pinMode(ledPin, OUTPUT);\n\n  // Conectar \u00e0 rede Wi-Fi\n  WiFi.begin(ssid, password);\n  while (WiFi.status() != WL_CONNECTED) {\n    delay(500);\n    Serial.print(\".\");\n  }\n\n  Serial.println(\"\");\n  Serial.println(\"Conectado \u00e0 rede Wi-Fi!\");\n  Serial.print(\"Endere\u00e7o IP: \");\n  Serial.println(WiFi.localIP());\n\n  // Rotas para o servidor web\n  server.on(\"/\", handleRoot);\n  server.on(\"/led/on\", handleLedOn);\n  server.on(\"/led/off\", handleLedOff);\n\n  // Inicia o servidor\n  server.begin();\n  Serial.println(\"Servidor HTTP iniciado\");\n}\n\nvoid loop() {\n  server.handleClient();\n}\n\n// Fun\u00e7\u00e3o para p\u00e1gina inicial\nvoid handleRoot() {\n  String html = \"&lt;!DOCTYPE html&gt;&lt;html&gt;&lt;head&gt;\";\n  html += \"&lt;meta name='viewport' content='width=device-width, initial-scale=1.0'&gt;\";\n  html += \"&lt;style&gt;body{font-family:Arial;text-align:center;margin-top:50px;}\";\n  html += \"button{background-color:#4CAF50;border:none;color:white;padding:15px 32px;\";\n  html += \"text-align:center;font-size:16px;margin:4px 2px;cursor:pointer;border-radius:10px;}&lt;/style&gt;\";\n  html += \"&lt;/head&gt;&lt;body&gt;\";\n  html += \"&lt;h1&gt;ESP32 Web Server&lt;/h1&gt;\";\n  html += \"&lt;p&gt;Status do LED: \";\n  html += (ledStatus == HIGH) ? \"LIGADO\" : \"DESLIGADO\";\n  html += \"&lt;/p&gt;\";\n  html += \"&lt;button onclick=\\\"location.href='/led/on'\\\"&gt;LIGAR LED&lt;/button&gt;\";\n  html += \"&lt;button onclick=\\\"location.href='/led/off'\\\"&gt;DESLIGAR LED&lt;/button&gt;\";\n  html += \"&lt;/body&gt;&lt;/html&gt;\";\n  server.send(200, \"text/html\", html);\n}\n\n// Fun\u00e7\u00e3o para ligar o LED\nvoid handleLedOn() {\n  ledStatus = HIGH;\n  digitalWrite(ledPin, ledStatus);\n  server.sendHeader(\"Location\", \"/\");\n  server.send(303);\n}\n\n// Fun\u00e7\u00e3o para desligar o LED\nvoid handleLedOff() {\n  ledStatus = LOW;\n  digitalWrite(ledPin, ledStatus);\n  server.sendHeader(\"Location\", \"/\");\n  server.send(303);\n}\n</code></pre> <p>Ap\u00f3s carregar o c\u00f3digo, abra um navegador e digite o endere\u00e7o IP exibido no monitor serial. Voc\u00ea ver\u00e1 uma p\u00e1gina web simples que permite controlar o LED do ESP32.</p>"},{"location":"aulas/iot/lab01-esp/index.html#3-comunicacao-bluetooth-com-esp32","title":"3. Comunica\u00e7\u00e3o Bluetooth com ESP32","text":"<p>O ESP32 possui Bluetooth integrado, tanto o cl\u00e1ssico quanto o BLE (Bluetooth Low Energy). Vamos criar um exemplo usando BLE:</p>"},{"location":"aulas/iot/lab01-esp/index.html#31-servidor-ble-simples","title":"3.1 Servidor BLE Simples","text":"<pre><code>#include &lt;BLEDevice.h&gt;\n#include &lt;BLEUtils.h&gt;\n#include &lt;BLEServer.h&gt;\n\n// Defini\u00e7\u00e3o dos UUIDs para servi\u00e7o e caracter\u00edstica BLE\n// See the following for generating UUIDs:\n// https://www.uuidgenerator.net/\n#define SERVICE_UUID        \"4fafc201-1fb5-459e-8fcc-c5c9c331914b\"\n#define CHARACTERISTIC_UUID \"beb5483e-36e1-4688-b7f5-ea07361b26a8\"\n\nvoid setup() {\n  Serial.begin(115200);\n  Serial.println(\"Iniciando servidor BLE...\");\n\n  // Cria o dispositivo BLE\n  BLEDevice::init(\"ESP32-BLE-Demo\");\n\n  // Cria o servidor BLE\n  BLEServer *pServer = BLEDevice::createServer();\n\n  // Cria um servi\u00e7o BLE\n  BLEService *pService = pServer-&gt;createService(SERVICE_UUID);\n\n  // Cria uma caracter\u00edstica BLE\n  BLECharacteristic *pCharacteristic = pService-&gt;createCharacteristic(\n                                         CHARACTERISTIC_UUID,\n                                         BLECharacteristic::PROPERTY_READ |\n                                         BLECharacteristic::PROPERTY_WRITE\n                                       );\n\n  // Define o valor inicial da caracter\u00edstica\n  pCharacteristic-&gt;setValue(\"Hello from ESP32!\");\n\n  // Inicia o servi\u00e7o\n  pService-&gt;start();\n\n  // Inicia a publicidade do servi\u00e7o\n  BLEAdvertising *pAdvertising = BLEDevice::getAdvertising();\n  pAdvertising-&gt;addServiceUUID(SERVICE_UUID);\n  pAdvertising-&gt;setScanResponse(true);\n  pAdvertising-&gt;setMinPreferred(0x06);  \n  pAdvertising-&gt;setMinPreferred(0x12);\n  BLEDevice::startAdvertising();\n\n  Serial.println(\"Servidor BLE iniciado! Aguardando conex\u00f5es...\");\n}\n\nvoid loop() {\n  // O BLE funciona em segundo plano, ent\u00e3o n\u00e3o precisamos fazer nada espec\u00edfico no loop\n  delay(2000);\n}\n</code></pre> <p>Para testar, voc\u00ea pode usar aplicativos como \"nRF Connect\" (dispon\u00edvel para Android e iOS) para escanear, conectar e interagir com o servidor BLE do ESP32.</p>"},{"location":"aulas/iot/lab01-esp/index.html#4-enviando-dados-para-plataformas-iot-thingspeak","title":"4. Enviando Dados para Plataformas IoT: ThingSpeak","text":"<p>ThingSpeak \u00e9 uma plataforma IoT popular que permite coletar e armazenar dados de sensores na nuvem, al\u00e9m de analis\u00e1-los e visualiz\u00e1-los.</p>"},{"location":"aulas/iot/lab01-esp/index.html#41-configurando-thingspeak","title":"4.1 Configurando ThingSpeak","text":"<p>Antes de come\u00e7ar:</p> <ol> <li>Crie uma conta no ThingSpeak</li> <li>Crie um novo canal (Channel)</li> <li>Configure os campos (Fields) que deseja usar para seus dados</li> <li>Anote a API Key do canal (Write API Key)</li> </ol>"},{"location":"aulas/iot/lab01-esp/index.html#42-enviando-dados-de-temperatura-e-umidade","title":"4.2 Enviando Dados de Temperatura e Umidade","text":"<p>Para este exemplo, vamos simular dados de temperatura e umidade e envi\u00e1-los para o ThingSpeak:</p> <pre><code>#include &lt;WiFi.h&gt;\n#include &lt;HTTPClient.h&gt;\n\n// Credenciais da rede Wi-Fi\nconst char* ssid = \"SUA_REDE_WIFI\";\nconst char* password = \"SUA_SENHA_WIFI\";\n\n// Credenciais ThingSpeak\nString apiKey = \"SUA_API_KEY_THINGSPEAK\";\nconst char* server = \"api.thingspeak.com\";\n\n// Intervalo entre envios de dados (em milissegundos)\nconst unsigned long intervaloEnvio = 20000;  // 20 segundos\nunsigned long tempoUltimoEnvio = 0;\n\nvoid setup() {\n  Serial.begin(115200);\n\n  // Conectar \u00e0 rede Wi-Fi\n  WiFi.begin(ssid, password);\n  Serial.print(\"Conectando \u00e0 rede Wi-Fi\");\n\n  while (WiFi.status() != WL_CONNECTED) {\n    delay(500);\n    Serial.print(\".\");\n  }\n\n  Serial.println(\"\");\n  Serial.println(\"Wi-Fi conectado\");\n  Serial.print(\"Endere\u00e7o IP: \");\n  Serial.println(WiFi.localIP());\n}\n\nvoid loop() {\n  // Verifica se \u00e9 hora de enviar dados\n  if ((millis() - tempoUltimoEnvio) &gt; intervaloEnvio) {\n    // Simula leituras de sensores\n    float temperatura = random(20, 30) + (float)random(0, 100) / 100.0; // 20-30\u00b0C\n    float umidade = random(40, 90) + (float)random(0, 100) / 100.0;     // 40-90%\n\n    // Mostra leituras no monitor serial\n    Serial.print(\"Temperatura: \");\n    Serial.print(temperatura);\n    Serial.println(\" \u00b0C\");\n    Serial.print(\"Umidade: \");\n    Serial.print(umidade);\n    Serial.println(\" %\");\n\n    // Verifica se a conex\u00e3o Wi-Fi ainda est\u00e1 ativa\n    if (WiFi.status() == WL_CONNECTED) {\n      HTTPClient http;\n\n      // Monta a URL com os dados\n      String url = \"http://api.thingspeak.com/update?api_key=\" + apiKey;\n      url += \"&amp;field1=\" + String(temperatura);\n      url += \"&amp;field2=\" + String(umidade);\n\n      // Inicia conex\u00e3o HTTP\n      http.begin(url);\n\n      // Envia requisi\u00e7\u00e3o GET\n      int httpCode = http.GET();\n\n      // Verifica o c\u00f3digo de retorno\n      if (httpCode &gt; 0) {\n        String resposta = http.getString();\n        Serial.println(\"Resposta do ThingSpeak: \" + resposta);\n      } else {\n        Serial.println(\"Falha na requisi\u00e7\u00e3o HTTP\");\n      }\n\n      http.end();\n    } else {\n      Serial.println(\"Conex\u00e3o Wi-Fi perdida. Tentando reconectar...\");\n      WiFi.reconnect();\n    }\n\n    // Atualiza o tempo do \u00faltimo envio\n    tempoUltimoEnvio = millis();\n  }\n}\n</code></pre> <p>Warning</p> <p>Substitua \"SUA_API_KEY_THINGSPEAK\" pela chave de API que voc\u00ea obteve ao criar seu canal no ThingSpeak.</p>"},{"location":"aulas/iot/lab01-esp/index.html#5-mqtt-com-esp32-comunicacao-com-broker","title":"5. MQTT com ESP32: Comunica\u00e7\u00e3o com Broker","text":"<p>O protocolo MQTT \u00e9 amplamente utilizado em aplica\u00e7\u00f5es IoT devido \u00e0 sua leveza e efici\u00eancia. Vamos criar um exemplo de publica\u00e7\u00e3o/assinatura usando MQTT:</p>"},{"location":"aulas/iot/lab01-esp/index.html#51-instalando-a-biblioteca-pubsubclient","title":"5.1 Instalando a biblioteca PubSubClient","text":"<ol> <li>No Arduino IDE, v\u00e1 para Ferramentas &gt; Gerenciar Bibliotecas</li> <li>Pesquise por \"PubSubClient\"</li> <li>Instale a biblioteca criada por Nick O'Leary</li> </ol>"},{"location":"aulas/iot/lab01-esp/index.html#52-cliente-mqtt-basico","title":"5.2 Cliente MQTT B\u00e1sico","text":"<pre><code>#include &lt;WiFi.h&gt;\n#include &lt;PubSubClient.h&gt;\n\n// Credenciais da rede Wi-Fi\nconst char* ssid = \"SUA_REDE_WIFI\";\nconst char* password = \"SUA_SENHA_WIFI\";\n\n// Configura\u00e7\u00e3o do servidor MQTT (Broker)\nconst char* mqtt_server = \"broker.mqtt.cool\";  // Broker p\u00fablico\nconst int mqtt_port = 1883;\nconst char* mqtt_clientID = \"ESP32Client\";\nconst char* mqtt_username = \"\";  // Se n\u00e3o precisar de autentica\u00e7\u00e3o\nconst char* mqtt_password = \"\";  // Se n\u00e3o precisar de autentica\u00e7\u00e3o\n\n// T\u00f3picos MQTT\nconst char* topico_pub = \"esp32/dados\";    // T\u00f3pico para publicar\nconst char* topico_sub = \"esp32/comandos\";  // T\u00f3pico para assinar\n\n// Instanciando objetos\nWiFiClient espClient;\nPubSubClient client(espClient);\n\n// Vari\u00e1veis para controle de tempo\nunsigned long ultimoEnvio = 0;\nconst long intervalo = 5000;  // Intervalo de envio (5 segundos)\n\n// LED para indica\u00e7\u00e3o visual\nconst int ledPin = 2;\n\nvoid setup_wifi() {\n  delay(10);\n  Serial.println();\n  Serial.print(\"Conectando \u00e0 rede \");\n  Serial.println(ssid);\n\n  WiFi.begin(ssid, password);\n\n  while (WiFi.status() != WL_CONNECTED) {\n    delay(500);\n    Serial.print(\".\");\n  }\n\n  Serial.println(\"\");\n  Serial.println(\"WiFi conectado\");\n  Serial.print(\"Endere\u00e7o IP: \");\n  Serial.println(WiFi.localIP());\n}\n\n// Fun\u00e7\u00e3o de callback chamada quando uma mensagem \u00e9 recebida em um t\u00f3pico assinado\nvoid callback(char* topic, byte* payload, unsigned int length) {\n  Serial.print(\"Mensagem recebida no t\u00f3pico: \");\n  Serial.println(topic);\n\n  Serial.print(\"Conte\u00fado: \");\n  String message;\n  for (int i = 0; i &lt; length; i++) {\n    message += (char)payload[i];\n  }\n  Serial.println(message);\n\n  // Verifica se a mensagem \u00e9 para ligar ou desligar o LED\n  if (String(topic) == topico_sub) {\n    if (message == \"ON\") {\n      digitalWrite(ledPin, HIGH);\n      Serial.println(\"LED ligado\");\n    } else if (message == \"OFF\") {\n      digitalWrite(ledPin, LOW);\n      Serial.println(\"LED desligado\");\n    }\n  }\n}\n\nvoid reconnect() {\n  // Loop at\u00e9 reconectar\n  while (!client.connected()) {\n    Serial.print(\"Tentando conex\u00e3o MQTT...\");\n\n    // Tenta conectar\n    if (client.connect(mqtt_clientID, mqtt_username, mqtt_password)) {\n      Serial.println(\"conectado\");\n\n      // Assina o t\u00f3pico\n      client.subscribe(topico_sub);\n    } else {\n      Serial.print(\"falhou, rc=\");\n      Serial.print(client.state());\n      Serial.println(\" tentando novamente em 5 segundos\");\n\n      // Aguarda antes de tentar novamente\n      delay(5000);\n    }\n  }\n}\n\nvoid setup() {\n  pinMode(ledPin, OUTPUT);\n  Serial.begin(115200);\n\n  setup_wifi();\n  client.setServer(mqtt_server, mqtt_port);\n  client.setCallback(callback);\n}\n\nvoid loop() {\n  // Verifica conex\u00e3o com o broker MQTT\n  if (!client.connected()) {\n    reconnect();\n  }\n  client.loop();\n\n  // Publica dados periodicamente\n  unsigned long agora = millis();\n  if (agora - ultimoEnvio &gt; intervalo) {\n    ultimoEnvio = agora;\n\n    // Simula dados de sensor\n    float temperatura = random(20, 30) + (float)random(0, 100) / 100.0;\n\n    // Converte float para String\n    String temp_str = String(temperatura);\n\n    // Publica a temperatura\n    Serial.print(\"Publicando temperatura: \");\n    Serial.println(temp_str);\n    client.publish(topico_pub, temp_str.c_str());\n  }\n}\n</code></pre> <p>Para testar este exemplo, voc\u00ea pode usar clientes MQTT como o MQTT Explorer ou o aplicativo MQTT Dash para Android.</p>"},{"location":"aulas/iot/lab01-esp/index.html#6-criando-um-projeto-integrado-estacao-meteorologica-iot","title":"6. Criando um Projeto Integrado: Esta\u00e7\u00e3o Meteorol\u00f3gica IoT","text":"<p>Agora, vamos combinar v\u00e1rias t\u00e9cnicas em um projeto mais completo: uma esta\u00e7\u00e3o meteorol\u00f3gica que publica dados via MQTT e tamb\u00e9m pode ser acessada por uma p\u00e1gina web.</p> <p>Para este projeto, voc\u00ea precisar\u00e1:</p> <ul> <li>ESP32</li> <li>Sensor DHT11 (temperatura e umidade)</li> <li>Resistor de 10K (para o DHT11)</li> <li>Jumpers</li> </ul>"},{"location":"aulas/iot/lab01-esp/index.html#61-instalacao-da-biblioteca-dht","title":"6.1 Instala\u00e7\u00e3o da Biblioteca DHT","text":"<ol> <li>No Arduino IDE, v\u00e1 para Ferramentas &gt; Gerenciar Bibliotecas</li> <li>Pesquise por \"DHT sensor library\"</li> <li>Instale a biblioteca criada por Adafruit</li> </ol>"},{"location":"aulas/iot/lab01-esp/index.html#62-codigo-completo-da-estacao-meteorologica","title":"6.2 C\u00f3digo Completo da Esta\u00e7\u00e3o Meteorol\u00f3gica","text":"<pre><code>#include &lt;WiFi.h&gt;\n#include &lt;WebServer.h&gt;\n#include &lt;PubSubClient.h&gt;\n#include &lt;DHT.h&gt;\n#include &lt;ArduinoJson.h&gt;\n\n// Configura\u00e7\u00e3o do DHT\n#define DHTPIN 4      // Pino do DHT\n#define DHTTYPE DHT11 // Tipo do sensor DHT\nDHT dht(DHTPIN, DHTTYPE);\n\n// Configura\u00e7\u00e3o da rede Wi-Fi\nconst char* ssid = \"SUA_REDE_WIFI\";\nconst char* password = \"SUA_SENHA_WIFI\";\n\n// Configura\u00e7\u00e3o do servidor MQTT\nconst char* mqtt_server = \"broker.mqtt.cool\";\nconst int mqtt_port = 1883;\nconst char* mqtt_clientID = \"ESP32WeatherStation\";\nconst char* mqtt_topic = \"estacao/dados\";\n\n// Servidor Web\nWebServer server(80);\n\n// Vari\u00e1veis para armazenar leituras\nfloat temperatura = 0;\nfloat umidade = 0;\nunsigned long ultimaLeitura = 0;\nconst long intervaloLeitura = 2000;  // Intervalo entre leituras (2 segundos)\nunsigned long ultimoEnvioMQTT = 0;\nconst long intervaloEnvioMQTT = 10000;  // Intervalo entre envios MQTT (10 segundos)\n\n// Objetos de comunica\u00e7\u00e3o\nWiFiClient espClient;\nPubSubClient mqttClient(espClient);\n\n// Configura\u00e7\u00e3o do WiFi\nvoid setupWiFi() {\n  delay(10);\n  Serial.println();\n  Serial.print(\"Conectando \u00e0 rede \");\n  Serial.println(ssid);\n\n  WiFi.begin(ssid, password);\n\n  while (WiFi.status() != WL_CONNECTED) {\n    delay(500);\n    Serial.print(\".\");\n  }\n\n  Serial.println(\"\");\n  Serial.println(\"WiFi conectado\");\n  Serial.print(\"Endere\u00e7o IP: \");\n  Serial.println(WiFi.localIP());\n}\n\n// Reconex\u00e3o ao broker MQTT\nvoid reconnectMQTT() {\n  while (!mqttClient.connected()) {\n    Serial.print(\"Tentando conectar ao MQTT...\");\n    if (mqttClient.connect(mqtt_clientID)) {\n      Serial.println(\"conectado\");\n    } else {\n      Serial.print(\"falhou, rc=\");\n      Serial.print(mqttClient.state());\n      Serial.println(\" tentando novamente em 5 segundos\");\n      delay(5000);\n    }\n  }\n}\n\n// L\u00ea os dados do sensor DHT\nvoid lerSensorDHT() {\n  // Verifica se j\u00e1 passou o intervalo para nova leitura\n  unsigned long agora = millis();\n  if (agora - ultimaLeitura &gt; intervaloLeitura) {\n    ultimaLeitura = agora;\n\n    // L\u00ea temperatura e umidade\n    float novaUmidade = dht.readHumidity();\n    float novaTemperatura = dht.readTemperature();\n\n    // Verifica se a leitura foi bem-sucedida\n    if (!isnan(novaUmidade) &amp;&amp; !isnan(novaTemperatura)) {\n      umidade = novaUmidade;\n      temperatura = novaTemperatura;\n      Serial.print(\"Temperatura: \");\n      Serial.print(temperatura);\n      Serial.print(\"\u00b0C, Umidade: \");\n      Serial.print(umidade);\n      Serial.println(\"%\");\n    } else {\n      Serial.println(\"Falha na leitura do sensor DHT!\");\n    }\n  }\n}\n\n// Envia dados via MQTT\nvoid enviarDadosMQTT() {\n  unsigned long agora = millis();\n  if (agora - ultimoEnvioMQTT &gt; intervaloEnvioMQTT) {\n    ultimoEnvioMQTT = agora;\n\n    if (mqttClient.connected()) {\n      // Cria JSON com os dados\n      StaticJsonDocument&lt;128&gt; doc;\n      doc[\"dispositivo\"] = mqtt_clientID;\n      doc[\"temperatura\"] = temperatura;\n      doc[\"umidade\"] = umidade;\n\n      char buffer[128];\n      serializeJson(doc, buffer);\n\n      // Publica no t\u00f3pico\n      mqttClient.publish(mqtt_topic, buffer);\n      Serial.println(\"Dados enviados via MQTT\");\n    }\n  }\n}\n\n// Configura\u00e7\u00e3o do servidor web\nvoid configureWebServer() {\n  // Rota principal - p\u00e1gina HTML\n  server.on(\"/\", HTTP_GET, []() {\n    String html = \"&lt;!DOCTYPE html&gt;&lt;html&gt;&lt;head&gt;\";\n    html += \"&lt;meta name='viewport' content='width=device-width, initial-scale=1.0'&gt;\";\n    html += \"&lt;meta http-equiv='refresh' content='5'&gt;\"; // Atualiza a p\u00e1gina a cada 5 segundos\n    html += \"&lt;style&gt;body{font-family:Arial;text-align:center;margin-top:50px;background-color:#f0f0f0;}\";\n    html += \".container{max-width:400px;margin:0 auto;background-color:white;padding:20px;border-radius:10px;box-shadow:0 0 10px rgba(0,0,0,0.1);}\";\n    html += \".data{font-size:24px;margin:20px 0;}\";\n    html += \".temp{color:#e74c3c;}.humid{color:#3498db;}\";\n    html += \"h1{color:#2c3e50;}&lt;/style&gt;\";\n    html += \"&lt;/head&gt;&lt;body&gt;\";\n    html += \"&lt;div class='container'&gt;\";\n    html += \"&lt;h1&gt;ESP32 Esta\u00e7\u00e3o Meteorol\u00f3gica&lt;/h1&gt;\";\n    html += \"&lt;div class='data temp'&gt;Temperatura: &lt;strong&gt;\" + String(temperatura) + \" \u00b0C&lt;/strong&gt;&lt;/div&gt;\";\n    html += \"&lt;div class='data humid'&gt;Umidade: &lt;strong&gt;\" + String(umidade) + \" %&lt;/strong&gt;&lt;/div&gt;\";\n    html += \"&lt;p&gt;\u00daltima atualiza\u00e7\u00e3o: \" + String(millis() / 1000) + \" segundos atr\u00e1s&lt;/p&gt;\";\n    html += \"&lt;p&gt;&lt;small&gt;Endere\u00e7o IP: \" + WiFi.localIP().toString() + \"&lt;/small&gt;&lt;/p&gt;\";\n    html += \"&lt;/div&gt;&lt;/body&gt;&lt;/html&gt;\";\n    server.send(200, \"text/html\", html);\n  });\n\n  // API REST para obter dados em formato JSON\n  server.on(\"/api/dados\", HTTP_GET, []() {\n    StaticJsonDocument&lt;128&gt; doc;\n    doc[\"temperatura\"] = temperatura;\n    doc[\"umidade\"] = umidade;\n    doc[\"timestamp\"] = millis() / 1000;\n\n    String json;\n    serializeJson(doc, json);\n    server.send(200, \"application/json\", json);\n  });\n\n  // Inicia o servidor\n  server.begin();\n  Serial.println(\"Servidor web iniciado\");\n}\n\nvoid setup() {\n  Serial.begin(115200);\n\n  // Inicia o sensor DHT\n  dht.begin();\n\n  // Configura o Wi-Fi\n  setupWiFi();\n\n  // Configura o cliente MQTT\n  mqttClient.setServer(mqtt_server, mqtt_port);\n\n  // Configura o servidor web\n  configureWebServer();\n\n  Serial.println(\"Sistema inicializado\");\n}\n\nvoid loop() {\n  // Verifica conex\u00e3o MQTT\n  if (!mqttClient.connected()) {\n    reconnectMQTT();\n  }\n  mqttClient.loop();\n\n  // L\u00ea o sensor\n  lerSensorDHT();\n\n  // Envia dados por MQTT\n  enviarDadosMQTT();\n\n  // Processa requisi\u00e7\u00f5es web\n  server.handleClient();\n}\n</code></pre> <p>Warning</p> <p>Lembre-se de alterar as credenciais de Wi-Fi e outras configura\u00e7\u00f5es conforme necess\u00e1rio.</p>"},{"location":"aulas/iot/lab01-esp/index.html#7-desafios-e-exercicios","title":"7. Desafios e Exerc\u00edcios","text":""},{"location":"aulas/iot/lab01-esp/index.html#desafio-1-controle-remoto-via-mqtt","title":"Desafio 1: Controle Remoto via MQTT","text":"<p>Modifique o c\u00f3digo da esta\u00e7\u00e3o meteorol\u00f3gica para receber comandos via MQTT que possam controlar um componente adicional, como um LED RGB ou um buzzer.</p>"},{"location":"aulas/iot/lab01-esp/index.html#desafio-2-armazenamento-de-dados-no-spiffs","title":"Desafio 2: Armazenamento de Dados no SPIFFS","text":"<p>Utilize o sistema de arquivos SPIFFS do ESP32 para armazenar dados hist\u00f3ricos quando a conex\u00e3o com a internet estiver indispon\u00edvel.</p>"},{"location":"aulas/iot/lab01-esp/index.html#desafio-3-integracao-com-alexa","title":"Desafio 3: Integra\u00e7\u00e3o com Alexa","text":"<p>Pesquise e implemente uma integra\u00e7\u00e3o do ESP32 com a Alexa da Amazon para controle de voz de dispositivos conectados.</p>"},{"location":"aulas/iot/lab01-esp/index.html#recursos-adicionais","title":"Recursos Adicionais","text":"<ul> <li>Documenta\u00e7\u00e3o oficial do ESP32</li> <li>Biblioteca ESP32 para Arduino</li> <li>Biblioteca WiFi para ESP32</li> <li>PubSubClient para MQTT</li> <li>ThingSpeak Documentation</li> </ul>"},{"location":"aulas/iot/lab02-esp/index.html","title":"Sistemas Embarcados: Integrando ESP32 com Sensor MPU6050","text":"<p>Sistemas embarcados que monitoram movimento e orienta\u00e7\u00e3o est\u00e3o presentes em in\u00fameras aplica\u00e7\u00f5es modernas, desde dispositivos vest\u00edveis at\u00e9 drones e sistemas de navega\u00e7\u00e3o. Nesta aula, vamos explorar a integra\u00e7\u00e3o do <code>ESP32</code> com o sensor de movimento <code>MPU6050</code>, que combina aceler\u00f4metro e girosc\u00f3pio em um \u00fanico chip.</p> <p>Esta combina\u00e7\u00e3o permite criar sistemas capazes de detectar movimentos, medir inclina\u00e7\u00e3o, identificar vibra\u00e7\u00f5es e muito mais. O ESP32, com sua capacidade de processamento superior e conectividade sem fio, complementa perfeitamente o MPU6050, permitindo aplica\u00e7\u00f5es IoT avan\u00e7adas.</p> <p>O MPU6050 \u00e9 um dispositivo de 6 eixos que combina:</p> <p></p> <ul> <li>Aceler\u00f4metro de 3 eixos (X, Y, Z)</li> <li>Girosc\u00f3pio de 3 eixos (X, Y, Z)</li> <li>Processador Digital de Movimento (DMP - Digital Motion Processor)</li> <li>Conversor anal\u00f3gico-digital de 16 bits para cada canal</li> <li>Buffer FIFO de 1024 bytes</li> <li>Sensor de temperatura integrado</li> </ul> <p>Princ\u00edpios de funcionamento:</p> <p></p> <p>Aceler\u00f4metro:  Mede acelera\u00e7\u00e3o linear nos tr\u00eas eixos. Em repouso, detecta apenas a acelera\u00e7\u00e3o gravitacional (9,8 m/s\u00b2). A acelera\u00e7\u00e3o \u00e9 medida em g (1g = 9,8 m/s\u00b2).</p> <p>O aceler\u00f4metro utiliza estruturas microsc\u00f3picas capacitivas que se movem em resposta \u00e0 acelera\u00e7\u00e3o, alterando a capacit\u00e2ncia, que \u00e9 convertida em um sinal el\u00e9trico proporcional \u00e0 acelera\u00e7\u00e3o.</p> <p>Girosc\u00f3pio: Mede velocidade angular (taxa de rota\u00e7\u00e3o) em torno dos tr\u00eas eixos, comumente expressa em graus por segundo (\u00b0/s). Baseia-se no princ\u00edpio do efeito Coriolis, onde uma massa vibrante sofre uma for\u00e7a perpendicular quando submetida a rota\u00e7\u00e3o.</p> <p>Escalas configur\u00e1veis: - Aceler\u00f4metro: \u00b12g, \u00b14g, \u00b18g ou \u00b116g - Girosc\u00f3pio: \u00b1250\u00b0/s, \u00b1500\u00b0/s, \u00b11000\u00b0/s ou \u00b12000\u00b0/s</p>"},{"location":"aulas/iot/lab02-esp/index.html#comunicacao-i2c","title":"Comunica\u00e7\u00e3o I2C","text":"<p>O MPU6050 utiliza o protocolo I2C para comunica\u00e7\u00e3o, um barramento serial que requer apenas dois fios: - SCL (Serial Clock): Sinal de clock - SDA (Serial Data): Linha de dados</p> <p>Caracter\u00edsticas do I2C: - Comunica\u00e7\u00e3o half-duplex, multi-master, multi-slave - Cada dispositivo possui um endere\u00e7o \u00fanico (MPU6050 usa 0x68 por padr\u00e3o) - Velocidades t\u00edpicas: 100kHz (modo padr\u00e3o), 400kHz (modo r\u00e1pido) - Protocolo baseado em transa\u00e7\u00f5es de endere\u00e7amento, escrita e leitura</p> <p>O ESP32 possui m\u00faltiplos controladores I2C e pode utilizar praticamente qualquer par de pinos GPIO para implementar o barramento.</p>"},{"location":"aulas/iot/lab02-esp/index.html#ambiente-de-desenvolvimento","title":"Ambiente de Desenvolvimento","text":"<p>Para esta aula, utilizaremos:</p> <ol> <li>Hardware:</li> <li>Placa de desenvolvimento ESP32 (DevKit ou NodeMCU ESP32)</li> <li>M\u00f3dulo MPU6050</li> <li>Cabos jumper</li> <li>Protoboard</li> <li> <p>Cabo USB para programa\u00e7\u00e3o</p> </li> <li> <p>Software:</p> </li> <li>Arduino IDE</li> <li>Biblioteca ESP32 para Arduino</li> <li>Biblioteca para MPU6050 (Adafruit MPU6050 ou outra biblioteca compat\u00edvel)</li> </ol>"},{"location":"aulas/iot/lab02-esp/index.html#instalacao-das-bibliotecas-necessarias","title":"Instala\u00e7\u00e3o das Bibliotecas Necess\u00e1rias:","text":"<p>Atrav\u00e9s do Gerenciador de Bibliotecas (Sketch \u2192 Incluir Biblioteca \u2192 Gerenciar Bibliotecas):</p> <ol> <li>Instale \"Adafruit MPU6050\" (que tamb\u00e9m instalar\u00e1 depend\u00eancias como \"Adafruit Unified Sensor\")</li> <li>Alternativamente, voc\u00ea pode usar a biblioteca \"MPU6050\" de Jeff Rowberg</li> </ol>"},{"location":"aulas/iot/lab02-esp/index.html#montagem-do-circuito","title":"Montagem do Circuito","text":"<p>A conex\u00e3o do MPU6050 ao ESP32 \u00e9 relativamente simples:</p> MPU6050 ESP32 Fun\u00e7\u00e3o VCC 3.3V Alimenta\u00e7\u00e3o GND GND Terra SCL GPIO22 Clock I2C SDA GPIO21 Dados I2C XDA N\u00e3o conectado Mestre I2C auxiliar (opcional) XCL N\u00e3o conectado Clock I2C auxiliar (opcional) AD0 GND Sele\u00e7\u00e3o de endere\u00e7o I2C (Low = 0x68) INT GPIO17 (opcional) Interrup\u00e7\u00e3o de dados prontos <p></p> <p>Considera\u00e7\u00f5es importantes:</p> <ul> <li><code>O MPU6050 opera com 3,3V. Conect\u00e1-lo a 5V pode danificar o sensor</code>.</li> <li>Recomenda-se usar resistores pull-up de 4,7k\u03a9 nas linhas SCL e SDA para maior estabilidade, embora o ESP32 e o MPU6050 j\u00e1 possuam pull-ups internos que podem ser suficientes para dist\u00e2ncias curtas.</li> <li>Mantenha os cabos de conex\u00e3o I2C o mais curtos poss\u00edvel para minimizar ru\u00eddo.</li> </ul>"},{"location":"aulas/iot/lab02-esp/index.html#implementacao-de-software","title":"Implementa\u00e7\u00e3o de Software","text":""},{"location":"aulas/iot/lab02-esp/index.html#bibliotecas-necessarias","title":"Bibliotecas Necess\u00e1rias","text":"<p>Para facilitar o desenvolvimento, utilizaremos bibliotecas que abstraem a complexidade da comunica\u00e7\u00e3o com o MPU6050:</p> <pre><code>#include &lt;Wire.h&gt;              // Biblioteca I2C padr\u00e3o\n#include &lt;Adafruit_MPU6050.h&gt;  // Abstrai comandos para o MPU6050\n#include &lt;Adafruit_Sensor.h&gt;   // Interface unificada para sensores\n</code></pre>"},{"location":"aulas/iot/lab02-esp/index.html#codigo-base","title":"C\u00f3digo Base","text":"<p>Vamos come\u00e7ar com um c\u00f3digo b\u00e1sico para inicializar e ler dados do MPU6050:</p> <pre><code>#include &lt;Wire.h&gt;\n#include &lt;Adafruit_MPU6050.h&gt;\n#include &lt;Adafruit_Sensor.h&gt;\n\nAdafruit_MPU6050 mpu;\n\nvoid setup() {\n  Serial.begin(115200);\n  while (!Serial) delay(10);  // Aguarda conex\u00e3o serial (para Arduino Leonardo/Micro)\n\n  Serial.println(\"Teste do Sensor MPU6050\");\n\n  // Inicializa o MPU6050\n  if (!mpu.begin()) {\n    Serial.println(\"Falha ao encontrar o chip MPU6050\");\n    while (1) {\n      delay(10);\n    }\n  }\n\n  Serial.println(\"MPU6050 encontrado!\");\n\n  // Configura o alcance do aceler\u00f4metro\n  mpu.setAccelerometerRange(MPU6050_RANGE_8_G);\n\n  // Configura o alcance do girosc\u00f3pio\n  mpu.setGyroRange(MPU6050_RANGE_500_DEG);\n\n  // Configura filtro passa-baixa\n  mpu.setFilterBandwidth(MPU6050_BAND_21_HZ);\n\n  Serial.println(\"Configura\u00e7\u00e3o conclu\u00edda!\");\n  delay(100);\n}\n\nvoid loop() {\n  // Obt\u00e9m novos eventos do sensor com as leituras\n  sensors_event_t a, g, temp;\n  mpu.getEvent(&amp;a, &amp;g, &amp;temp);\n\n  // Imprime os dados do aceler\u00f4metro\n  Serial.print(\"Acelera\u00e7\u00e3o (m/s^2): X=\");\n  Serial.print(a.acceleration.x);\n  Serial.print(\", Y=\");\n  Serial.print(a.acceleration.y);\n  Serial.print(\", Z=\");\n  Serial.println(a.acceleration.z);\n\n  // Imprime os dados do girosc\u00f3pio\n  Serial.print(\"Rota\u00e7\u00e3o (rad/s): X=\");\n  Serial.print(g.gyro.x);\n  Serial.print(\", Y=\");\n  Serial.print(g.gyro.y);\n  Serial.print(\", Z=\");\n  Serial.println(g.gyro.z);\n\n  // Imprime a temperatura\n  Serial.print(\"Temperatura: \");\n  Serial.print(temp.temperature);\n  Serial.println(\" \u00b0C\");\n\n  Serial.println(\"------------------------\");\n  delay(500);\n}\n</code></pre>"},{"location":"aulas/iot/lab02-esp/index.html#desafio","title":"Desafio","text":"<p>Monte o circuito e grave o c\u00f3digo acima para testes testar e validar o funcionamento do sensor.</p>"},{"location":"aulas/iot/lab02-esp/index.html#calibracao-do-sensor","title":"Calibra\u00e7\u00e3o do Sensor","text":"<p>O MPU6050, como a maioria dos sensores inerciais de baixo custo, possui deriva (bias) e ru\u00eddo. A calibra\u00e7\u00e3o \u00e9 essencial para medi\u00e7\u00f5es precisas.</p> <p>Procedimento de calibra\u00e7\u00e3o simplificado:</p> <pre><code>#include &lt;Wire.h&gt;\n#include &lt;Adafruit_MPU6050.h&gt;\n#include &lt;Adafruit_Sensor.h&gt;\n\nAdafruit_MPU6050 mpu;\n\n// Vari\u00e1veis para armazenar os valores de calibra\u00e7\u00e3o\nfloat accel_x_offset = 0;\nfloat accel_y_offset = 0;\nfloat accel_z_offset = 0;\nfloat gyro_x_offset = 0;\nfloat gyro_y_offset = 0;\nfloat gyro_z_offset = 0;\n\nconst int numReadings = 1000;  // N\u00famero de leituras para calibra\u00e7\u00e3o\n\nvoid setup() {\n  Serial.begin(115200);\n  while (!Serial) delay(10);\n\n  Serial.println(\"Calibra\u00e7\u00e3o do MPU6050\");\n\n  if (!mpu.begin()) {\n    Serial.println(\"Falha ao encontrar chip MPU6050\");\n    while (1) {\n      delay(10);\n    }\n  }\n\n  mpu.setAccelerometerRange(MPU6050_RANGE_8_G);\n  mpu.setGyroRange(MPU6050_RANGE_500_DEG);\n  mpu.setFilterBandwidth(MPU6050_BAND_21_HZ);\n\n  // Calibra\u00e7\u00e3o:\n  Serial.println(\"Mantenha o sensor parado e nivelado para calibra\u00e7\u00e3o...\");\n  delay(2000);  // Tempo para posicionar o sensor\n\n  Serial.println(\"Iniciando calibra\u00e7\u00e3o...\");\n\n  // Coleta m\u00faltiplas leituras para m\u00e9dia\n  for (int i = 0; i &lt; numReadings; i++) {\n    sensors_event_t a, g, temp;\n    mpu.getEvent(&amp;a, &amp;g, &amp;temp);\n\n    // Somando leituras\n    accel_x_offset += a.acceleration.x;\n    accel_y_offset += a.acceleration.y;\n    accel_z_offset += a.acceleration.z - 9.8; // Subtrair a gravidade no eixo Z\n    gyro_x_offset += g.gyro.x;\n    gyro_y_offset += g.gyro.y;\n    gyro_z_offset += g.gyro.z;\n\n    delay(5);\n  }\n\n  // Calculando m\u00e9dias\n  accel_x_offset /= numReadings;\n  accel_y_offset /= numReadings;\n  accel_z_offset /= numReadings;\n  gyro_x_offset /= numReadings;\n  gyro_y_offset /= numReadings;\n  gyro_z_offset /= numReadings;\n\n  Serial.println(\"Calibra\u00e7\u00e3o conclu\u00edda!\");\n  Serial.print(\"Offsets do aceler\u00f4metro: X=\");\n  Serial.print(accel_x_offset);\n  Serial.print(\", Y=\");\n  Serial.print(accel_y_offset);\n  Serial.print(\", Z=\");\n  Serial.println(accel_z_offset);\n\n  Serial.print(\"Offsets do girosc\u00f3pio: X=\");\n  Serial.print(gyro_x_offset);\n  Serial.print(\", Y=\");\n  Serial.print(gyro_y_offset);\n  Serial.print(\", Z=\");\n  Serial.println(gyro_z_offset);\n}\n\nvoid loop() {\n  // L\u00ea os dados do sensor\n  sensors_event_t a, g, temp;\n  mpu.getEvent(&amp;a, &amp;g, &amp;temp);\n\n  // Aplica os offsets\n  float accel_x = a.acceleration.x - accel_x_offset;\n  float accel_y = a.acceleration.y - accel_y_offset;\n  float accel_z = a.acceleration.z - accel_z_offset;\n  float gyro_x = g.gyro.x - gyro_x_offset;\n  float gyro_y = g.gyro.y - gyro_y_offset;\n  float gyro_z = g.gyro.z - gyro_z_offset;\n\n  // Exibe os dados calibrados\n  Serial.print(\"Acelera\u00e7\u00e3o calibrada (m/s^2): X=\");\n  Serial.print(accel_x);\n  Serial.print(\", Y=\");\n  Serial.print(accel_y);\n  Serial.print(\", Z=\");\n  Serial.println(accel_z);\n\n  Serial.print(\"Rota\u00e7\u00e3o calibrada (rad/s): X=\");\n  Serial.print(gyro_x);\n  Serial.print(\", Y=\");\n  Serial.print(gyro_y);\n  Serial.print(\", Z=\");\n  Serial.println(gyro_z);\n\n  delay(500);\n}\n</code></pre>"},{"location":"aulas/iot/lab02-esp/index.html#desafio_1","title":"Desafio","text":"<p>Caso o seu sensor apresente muito ruido e varia\u00e7\u00e3o, fa\u00e7a o procedimento de calibra\u00e7\u00e3o para tentar melhorar as medi\u00e7\u00f5es.</p>"},{"location":"aulas/iot/lab02-esp/index.html#processamento-de-dados","title":"Processamento de Dados","text":""},{"location":"aulas/iot/lab02-esp/index.html#acelerometro","title":"Aceler\u00f4metro","text":"<p>O aceler\u00f4metro \u00e9 um sensor capaz de medir a acelera\u00e7\u00e3o linear nos tr\u00eas eixos: X, Y e Z. Essas medi\u00e7\u00f5es incluem tanto movimentos din\u00e2micos quanto a acelera\u00e7\u00e3o causada pela gravidade.</p> <p>A partir das leituras, podemos realizar diferentes tipos de processamento:</p> <ol> <li>C\u00e1lculo de \u00e2ngulos de inclina\u00e7\u00e3o:</li> </ol> <p>Quando o sensor est\u00e1 est\u00e1tico (sem movimento), a \u00fanica acelera\u00e7\u00e3o presente \u00e9 a gravidade (g = 9{,}8\\ \\mathrm{m/s^2}).</p> <p>Sabemos que:</p> <ul> <li>Para o eixo X: o \u00e2ngulo de inclina\u00e7\u00e3o $ heta_x$ \u00e9 dado pela proje\u00e7\u00e3o da gravidade nos eixos Y e Z.</li> <li>Para o eixo Y: o \u00e2ngulo de inclina\u00e7\u00e3o $ heta_y$ \u00e9 dado pela proje\u00e7\u00e3o da gravidade nos eixos X e Z.</li> </ul> <p>As equa\u00e7\u00f5es s\u00e3o:</p>  \\theta_x = \\arctan\\left(\\frac{a_y}{\\sqrt{a_x^2 + a_z^2}}\\right)   \\theta_y = \\arctan\\left(\\frac{-a_x}{\\sqrt{a_y^2 + a_z^2}}\\right)  <p>Onde: g = 9.8\\ \\mathrm{m/s^2} - a_x, a_y, a_z s\u00e3o as leituras brutas do aceler\u00f4metro em cada eixo. - A fun\u00e7\u00e3o arctan \u00e9 a fun\u00e7\u00e3o arcotangente (em radianos).</p> <p>Se quisermos os \u00e2ngulos em graus, multiplicamos por:</p>  \\text{graus} = \\text{radianos} \\times \\left( \\frac{180}{\\pi} \\right)  <pre><code>// C\u00e1lculo de \u00e2ngulos usando aceler\u00f4metro\nfloat accel_angle_x = atan2(accel_y, sqrt(accel_x * accel_x + accel_z * accel_z)) * 180 / PI;\nfloat accel_angle_y = atan2(-accel_x, sqrt(accel_y * accel_y + accel_z * accel_z)) * 180 / PI;\n</code></pre> <ol> <li>Detec\u00e7\u00e3o de movimento:</li> </ol> <p>Quando o dispositivo se move, a acelera\u00e7\u00e3o total se altera. Para identificar esse movimento, calculamos a magnitude da acelera\u00e7\u00e3o:</p> <p>A equa\u00e7\u00e3o da magnitude vetorial \u00e9:</p>  |a| = \\sqrt{a_x^2 + a_y^2 + a_z^2}  <p>Se a magnitude diferir significativamente da acelera\u00e7\u00e3o gravitacional padr\u00e3o g = 9.8\\ \\mathrm{m/s^2}, interpretamos isso como movimento.</p> <pre><code>// Magnitude da acelera\u00e7\u00e3o total (removendo a gravidade)\nfloat accel_magnitude = sqrt(accel_x * accel_x + accel_y * accel_y + accel_z * accel_z);\n\n// Detecta movimento baseado na diferen\u00e7a em rela\u00e7\u00e3o \u00e0 gravidade\nif (abs(accel_magnitude - 9.8) &gt; 2.0) {\n  Serial.println(\"Movimento detectado!\");\n}\n</code></pre> <p>Crit\u00e9rio utilizado:</p> <ul> <li> <p>Um desvio maior que 2\\ \\mathrm{m/s^2} da gravidade indica presen\u00e7a de movimento.</p> </li> <li> <p>Detec\u00e7\u00e3o de queda livre:</p> </li> </ul> <p>Durante a queda livre, o aceler\u00f4metro tende a medir uma acelera\u00e7\u00e3o pr\u00f3xima de zero em todos os eixos, pois o sensor e seu corpo de refer\u00eancia est\u00e3o acelerando juntos sob a gravidade.</p> <p>O mesmo c\u00e1lculo da magnitude da acelera\u00e7\u00e3o \u00e9 usado:</p>  |a| = \\sqrt{a_x^2 + a_y^2 + a_z^2}  <p>Condi\u00e7\u00e3o de detec\u00e7\u00e3o: - Se |a| for muito pr\u00f3ximo de 0\\ \\mathrm{m/s^2} (por exemplo, menor que 2.0\\ \\mathrm{m/s^2}), assumimos que o sensor est\u00e1 em queda livre.</p> <pre><code>// Magnitude da acelera\u00e7\u00e3o total\nfloat accel_magnitude = sqrt(accel_x * accel_x + accel_y * accel_y + accel_z * accel_z);\n\n// Detecta queda livre\nif (accel_magnitude &lt; 2.0) {  // Pr\u00f3ximo a zero, mas com alguma margem\n  Serial.println(\"Queda livre detectada!\");\n}\n</code></pre>"},{"location":"aulas/iot/lab02-esp/index.html#giroscopio","title":"Girosc\u00f3pio","text":"<p>O girosc\u00f3pio mede velocidade angular nos tr\u00eas eixos: X, Y e Z.</p> <p>Com essas medi\u00e7\u00f5es, podemos realizar diversos processamentos:</p>"},{"location":"aulas/iot/lab02-esp/index.html#1-calculo-de-angulo-por-integracao","title":"1. C\u00e1lculo de \u00c2ngulo por Integra\u00e7\u00e3o","text":"<p>A velocidade angular \u00e9 integrada no tempo para estimar o \u00e2ngulo de rota\u00e7\u00e3o.</p> <p>A equa\u00e7\u00e3o b\u00e1sica \u00e9:</p>  \\theta(t) = \\theta_0 + \\int_0^t \\omega(t) \\ dt  <p>Onde: - \\theta(t) \u00e9 o \u00e2ngulo acumulado. - \\omega(t) \u00e9 a velocidade angular. - dt \u00e9 o intervalo de tempo entre as leituras.</p> <p><pre><code>// Vari\u00e1veis globais\nfloat angle_x = 0;\nfloat angle_y = 0;\nfloat angle_z = 0;\nunsigned long last_time = 0;\n\nvoid loop() {\n  // ...c\u00f3digo para ler o MPU6050...\n\n  // Convers\u00e3o de rad/s para graus/s\n  float gyro_x_deg = gyro_x * 180 / PI;\n  float gyro_y_deg = gyro_y * 180 / PI;\n  float gyro_z_deg = gyro_z * 180 / PI;\n\n  // C\u00e1lculo do intervalo de tempo\n  unsigned long current_time = millis();\n  float dt = (current_time - last_time) / 1000.0; // Converter para segundos\n  last_time = current_time;\n\n  // Integra\u00e7\u00e3o (\u00e2ngulo = \u00e2ngulo anterior + velocidade angular * tempo)\n  angle_x += gyro_x_deg * dt;\n  angle_y += gyro_y_deg * dt;\n  angle_z += gyro_z_deg * dt;\n\n  Serial.print(\"\u00c2ngulos por girosc\u00f3pio (graus): X=\");\n  Serial.print(angle_x);\n  Serial.print(\", Y=\");\n  Serial.print(angle_y);\n  Serial.print(\", Z=\");\n  Serial.println(angle_z);\n\n  // ... resto do c\u00f3digo ...\n}\n</code></pre> Limita\u00e7\u00e3o: A integra\u00e7\u00e3o acumula erro ao longo do tempo (deriva), tornando os \u00e2ngulos cada vez menos precisos.</p>"},{"location":"aulas/iot/lab02-esp/index.html#filtro-complementar","title":"Filtro Complementar","text":"<p>Para obter melhores estimativas de orienta\u00e7\u00e3o, combinamos os dados do aceler\u00f4metro e girosc\u00f3pio usando um filtro complementar. </p> <p>O filtro complementar combina: - Aceler\u00f4metro: Fornece refer\u00eancia absoluta mas \u00e9 sens\u00edvel a acelera\u00e7\u00f5es externas - Girosc\u00f3pio: Possui boa resposta a curto prazo, mas deriva ao longo do tempo</p> <p>A equa\u00e7\u00e3o do filtro \u00e9:</p>  \\text{angle}_{\\text{final}} = \\alpha (\\text{angle}_{\\text{gyro}}) + (1 - \\alpha)(\\text{angle}_{\\text{accel}})  <p>Onde: - \\alpha \u00e9 o coeficiente de pondera\u00e7\u00e3o (ex.: 0.96).</p> <pre><code>// Defini\u00e7\u00f5es globais\nfloat angle_x = 0;\nfloat angle_y = 0;\nunsigned long last_time = 0;\nfloat alpha = 0.96; // Fator de filtragem (ajust\u00e1vel)\n\nvoid loop() {\n  // ...c\u00f3digo para ler o MPU6050...\n\n  // C\u00e1lculo dos \u00e2ngulos do aceler\u00f4metro\n  float accel_angle_x = atan2(accel_y, sqrt(accel_x * accel_x + accel_z * accel_z)) * 180 / PI;\n  float accel_angle_y = atan2(-accel_x, sqrt(accel_y * accel_y + accel_z * accel_z)) * 180 / PI;\n\n  // Convers\u00e3o de rad/s para deg/s\n  float gyro_x_deg = gyro_x * 180 / PI;\n  float gyro_y_deg = gyro_y * 180 / PI;\n\n  // C\u00e1lculo do intervalo de tempo\n  unsigned long current_time = millis();\n  float dt = (current_time - last_time) / 1000.0;\n  last_time = current_time;\n\n  // Aplica\u00e7\u00e3o do filtro complementar\n  angle_x = alpha * (angle_x + gyro_x_deg * dt) + (1 - alpha) * accel_angle_x;\n  angle_y = alpha * (angle_y + gyro_y_deg * dt) + (1 - alpha) * accel_angle_y;\n\n  Serial.print(\"\u00c2ngulos filtrados (graus): X=\");\n  Serial.print(angle_x);\n  Serial.print(\", Y=\");\n  Serial.println(angle_y);\n\n  delay(10);\n}\n</code></pre>"},{"location":"aulas/iot/lab02-esp/index.html#aplicacoes-praticas","title":"Aplica\u00e7\u00f5es Pr\u00e1ticas","text":""},{"location":"aulas/iot/lab02-esp/index.html#deteccao-de-movimento-acionamento-de-led","title":"Detec\u00e7\u00e3o de Movimento (Acionamento de LED)","text":"<p>Sistema de detec\u00e7\u00e3o de movimento baseado em aceler\u00f4metro para acionar um LED:</p> <pre><code>#include &lt;Wire.h&gt;\n#include &lt;Adafruit_MPU6050.h&gt;\n#include &lt;Adafruit_Sensor.h&gt;\n\nAdafruit_MPU6050 mpu;\n\nconst int ledPin = 2;  // LED conectado ao GPIO2\nfloat accel_threshold = 2.0;  // Threshold para detec\u00e7\u00e3o de movimento (m/s\u00b2)\n\n// Vari\u00e1veis de calibra\u00e7\u00e3o\nfloat accel_x_offset = 0;\nfloat accel_y_offset = 0;\nfloat accel_z_offset = 0;\n\nvoid setup() {\n  Serial.begin(115200);\n  pinMode(ledPin, OUTPUT);\n\n  // Inicializa\u00e7\u00e3o do MPU6050\n  if (!mpu.begin()) {\n    Serial.println(\"Falha ao encontrar chip MPU6050\");\n    while (1) {\n      delay(10);\n    }\n  }\n\n  mpu.setAccelerometerRange(MPU6050_RANGE_8_G);\n  mpu.setGyroRange(MPU6050_RANGE_500_DEG);\n  mpu.setFilterBandwidth(MPU6050_BAND_21_HZ);\n\n  // Calibra\u00e7\u00e3o r\u00e1pida (pode ser expandida conforme exemplo anterior)\n  calibrarSensor();\n\n  Serial.println(\"Sistema de detec\u00e7\u00e3o de movimento iniciado\");\n}\n\nvoid calibrarSensor() {\n  Serial.println(\"Calibrando sensor...\");\n\n  // M\u00e9dia de 100 leituras\n  for (int i = 0; i &lt; 100; i++) {\n    sensors_event_t a, g, temp;\n    mpu.getEvent(&amp;a, &amp;g, &amp;temp);\n    accel_x_offset += a.acceleration.x;\n    accel_y_offset += a.acceleration.y;\n    accel_z_offset += a.acceleration.z - 9.8; // Remove a gravidade\n    delay(10);\n  }\n\n  accel_x_offset /= 100;\n  accel_y_offset /= 100;\n  accel_z_offset /= 100;\n\n  Serial.println(\"Calibra\u00e7\u00e3o conclu\u00edda\");\n}\n\nbool detectarMovimento() {\n  sensors_event_t a, g, temp;\n  mpu.getEvent(&amp;a, &amp;g, &amp;temp);\n\n  // Aplicar calibra\u00e7\u00e3o\n  float accel_x = a.acceleration.x - accel_x_offset;\n  float accel_y = a.acceleration.y - accel_y_offset;\n  float accel_z = a.acceleration.z - accel_z_offset;\n\n  // Calcular magnitude da acelera\u00e7\u00e3o\n  float magnitude = sqrt(accel_x * accel_x + accel_y * accel_y + accel_z * accel_z);\n\n  // Verificar se excede o threshold (removendo a componente da gravidade)\n  if (abs(magnitude - 9.8) &gt; accel_threshold) {\n    return true;\n  }\n  return false;\n}\n\nvoid loop() {\n  if (detectarMovimento()) {\n    Serial.println(\"Movimento detectado!\");\n    digitalWrite(ledPin, HIGH);  // Acende o LED\n    delay(1000);                 // Mant\u00e9m aceso por 1 segundo\n  } else {\n    digitalWrite(ledPin, LOW);   // Desliga o LED\n  }\n\n  delay(50);  // Pequeno atraso para estabilidade\n}\n</code></pre>"},{"location":"aulas/iot/lab02-esp/index.html#32-controle-de-orientacao-servo-motor","title":"3.2 Controle de Orienta\u00e7\u00e3o (Servo Motor)","text":"<p>Controle de servo motor baseado na inclina\u00e7\u00e3o detectada:</p> <pre><code>#include &lt;Wire.h&gt;\n#include &lt;Adafruit_MPU6050.h&gt;\n#include &lt;Adafruit_Sensor.h&gt;\n#include &lt;ESP32Servo.h&gt;\n\nAdafruit_MPU6050 mpu;\nServo myServo;\n\nconst int servoPin = 13;  // Servo conectado ao GPIO13\nfloat angle_x = 0;\nfloat angle_y = 0;\nunsigned long last_time = 0;\nfloat alpha = 0.96; // Fator de filtragem\n\nvoid setup() {\n  Serial.begin(115200);\n\n  // Inicializa\u00e7\u00e3o do MPU6050\n  if (!mpu.begin()) {\n    Serial.println(\"Falha ao encontrar chip MPU6050\");\n    while (1) {\n      delay(10);\n    }\n  }\n\n  mpu.setAccelerometerRange(MPU6050_RANGE_2_G);\n  mpu.setGyroRange(MPU6050_RANGE_250_DEG);\n  mpu.setFilterBandwidth(MPU6050_BAND_21_HZ);\n\n  // Inicializa\u00e7\u00e3o do servo\n  ESP32PWM::allocateTimer(0);\n  myServo.setPeriodHertz(50);    // PWM frequency\n  myServo.attach(servoPin, 500, 2400); // pino, pulso m\u00ednimo, pulso m\u00e1ximo\n\n  last_time = millis();\n  Serial.println(\"Sistema de controle por inclina\u00e7\u00e3o iniciado\");\n}\n\nvoid loop() {\n  // Obter dados do sensor\n  sensors_event_t a, g, temp;\n  mpu.getEvent(&amp;a, &amp;g, &amp;temp);\n\n  // C\u00e1lculo dos \u00e2ngulos do aceler\u00f4metro\n  float accel_angle_x = atan2(a.acceleration.y, \n                              sqrt(a.acceleration.x * a.acceleration.x + \n                                   a.acceleration.z * a.acceleration.z)) * 180 / PI;\n\n  // Convers\u00e3o de rad/s para graus/s\n  float gyro_x_deg = g.gyro.x * 180 / PI;\n\n  // C\u00e1lculo do intervalo de tempo\n  unsigned long current_time = millis();\n  float dt = (current_time - last_time) / 1000.0;\n  last_time = current_time;\n\n  // Filtro complementar\n  angle_x = alpha * (angle_x + gyro_x_deg * dt) + (1 - alpha) * accel_angle_x;\n\n  // Mapeamento do \u00e2ngulo para posi\u00e7\u00e3o do servo (ajuste conforme necess\u00e1rio)\n  // Limitando entre -45 e +45 graus, para servo entre 0 e 180\n  float servo_angle = map(constrain(angle_x, -45, 45), -45, 45, 0, 180);\n\n  // Posi\u00e7\u00e3o do servo\n  myServo.write(servo_angle);\n\n  // Exibi\u00e7\u00e3o de dados\n  Serial.print(\"\u00c2ngulo X: \");\n  Serial.print(angle_x);\n  Serial.print(\" | Posi\u00e7\u00e3o do servo: \");\n  Serial.println(servo_angle);\n\n  delay(20);\n}\n\n// Fun\u00e7\u00e3o auxiliar para mapear valores float\nfloat map(float x, float in_min, float in_max, float out_min, float out_max) {\n  return (x - in_min) * (out_max - out_min) / (in_max - in_min) + out_min;\n}\n</code></pre>"},{"location":"aulas/iot/lab02-esp/index.html#projeto-completo-monitoramento-de-orientacao-com-esp32","title":"Projeto Completo: Monitoramento de Orienta\u00e7\u00e3o com ESP32","text":"<p>Vamos construir um sistema embarcado interativo para monitoramento de orienta\u00e7\u00e3o em tempo real, usando:</p> <ul> <li>ESP32 como microcontrolador e servidor Wi-Fi</li> <li>Sensor MPU6050 para medir acelera\u00e7\u00e3o e rota\u00e7\u00e3o</li> <li>P\u00e1gina Web que visualiza a orienta\u00e7\u00e3o em 3D via navegador</li> </ul>    Seu navegador n\u00e3o suporta v\u00eddeo HTML5.  <p>Vamos dividir o projeto em etapas para facilitar o entendimento:</p>"},{"location":"aulas/iot/lab02-esp/index.html#1-estrutura-geral-do-projeto","title":"1. Estrutura Geral do Projeto","text":"<ul> <li>Sensor MPU6050: Captura dados de acelera\u00e7\u00e3o (for\u00e7as) e girosc\u00f3pio (velocidade angular).</li> <li>ESP32: Processa os dados, aplica filtro complementar e cria um servidor web para transmitir os valores.</li> <li>Frontend Web: P\u00e1gina HTML com um cubo 3D que gira conforme a orienta\u00e7\u00e3o medida.</li> <li>Comunica\u00e7\u00e3o: Navegador se conecta via HTTP local para receber dados a cada 100 ms.</li> </ul>"},{"location":"aulas/iot/lab02-esp/index.html#2-configuracao-e-inicializacao","title":"2. Configura\u00e7\u00e3o e Inicializa\u00e7\u00e3o","text":"<ul> <li>Configuramos a conex\u00e3o Wi-Fi do ESP32.</li> <li>Inicializamos o sensor MPU6050 ajustando:</li> <li>Faixa do aceler\u00f4metro para \u00b12G</li> <li>Faixa do girosc\u00f3pio para \u00b1250\u00b0/s</li> <li>Largura de banda do filtro interno</li> </ul> <p>O objetivo \u00e9 garantir alta sensibilidade e estabilidade para medi\u00e7\u00e3o dos movimentos.</p>"},{"location":"aulas/iot/lab02-esp/index.html#3-aquisicao-de-dados-do-sensor","title":"3. Aquisi\u00e7\u00e3o de Dados do Sensor","text":"<ul> <li>Usamos a fun\u00e7\u00e3o <code>mpu.getEvent(&amp;a, &amp;g, &amp;temp)</code> para ler:</li> <li>Acelera\u00e7\u00e3o (<code>a</code>)</li> <li>Velocidade angular (<code>g</code>)</li> <li> <p>Temperatura (<code>temp</code>, opcional)</p> </li> <li> <p>Calculamos os \u00e2ngulos:</p> </li> <li>Inclina\u00e7\u00e3o X: Baseado no eixo Y do aceler\u00f4metro.</li> <li>Inclina\u00e7\u00e3o Y: Baseado no eixo X do aceler\u00f4metro.</li> <li> <p>Yaw (rota\u00e7\u00e3o Z): Integrando a velocidade do girosc\u00f3pio Z ao longo do tempo.</p> </li> <li> <p>Aplicamos um filtro complementar para combinar as informa\u00e7\u00f5es de aceler\u00f4metro e girosc\u00f3pio, compensando ru\u00eddos e drift.</p> </li> </ul>"},{"location":"aulas/iot/lab02-esp/index.html#4-visualizacao-grafica-no-navegador","title":"4. Visualiza\u00e7\u00e3o Gr\u00e1fica no Navegador","text":"<ul> <li>Como o Frontend Funciona: </li> <li>P\u00e1gina HTML simples, com um canvas onde desenhamos o cubo.</li> <li>Implementamos um mini \"motor gr\u00e1fico\" 3D usando apenas JavaScript puro + Canvas 2D.</li> <li> <p>As faces do cubo recebem cores diferentes e ilumina\u00e7\u00e3o simulada, para melhorar a percep\u00e7\u00e3o visual.</p> </li> <li> <p>Atualiza\u00e7\u00e3o em Tempo Real:</p> </li> <li>A cada 100 ms, o navegador faz um fetch('/data').</li> <li>Os novos \u00e2ngulos s\u00e3o aplicados no cubo para atualizar a orienta\u00e7\u00e3o.</li> </ul>"},{"location":"aulas/iot/lab02-esp/index.html#5-codigo-fonte-completo","title":"5. C\u00f3digo Fonte Completo","text":"<pre><code>#include &lt;Wire.h&gt;\n#include &lt;Adafruit_MPU6050.h&gt;\n#include &lt;Adafruit_Sensor.h&gt;\n#include &lt;WiFi.h&gt;\n#include &lt;WebServer.h&gt;\n#include &lt;ArduinoJson.h&gt;\n\n// ======== Prot\u00f3tipos de fun\u00e7\u00f5es =========\nvoid atualizarDadosSensor(unsigned long dt_ms);\n\n// ======== Vari\u00e1veis Wi-Fi e Servidor ========\n// Credenciais da rede Wi-Fi\nconst char* ssid = \"SeuSSID\";\nconst char* password = \"SuaSenha\";\nWebServer server(80);\n\n// ======== Objeto Sensor ========\nAdafruit_MPU6050 mpu;\n\n// ======== Vari\u00e1veis de processamento ========\nfloat angle_x = 0;\nfloat angle_y = 0;\nfloat yaw_angle = 0;\nunsigned long last_sensor_update = 0;\nconst unsigned long sensor_update_interval = 10; // em ms\nfloat alpha = 0.96; // Filtro complementar\n\n// ======== HTML da p\u00e1gina web (corrigido UTF-8 e com 3D) ========\nconst char index_html[] PROGMEM = R\"rawliteral(\n&lt;!DOCTYPE HTML&gt;\n&lt;html lang=\"pt-BR\"&gt;\n&lt;head&gt;\n  &lt;meta charset=\"UTF-8\"&gt;\n  &lt;meta name=\"viewport\" content=\"width=device-width, initial-scale=1\"&gt;\n  &lt;title&gt;Monitor MPU6050 3D&lt;/title&gt;\n  &lt;style&gt;\n    body { margin: 0; overflow: hidden; font-family: Arial; text-align: center; background-color: #1a1a2e; }\n    #canvas3d { width: 100vw; height: 100vh; display: block; background: #1a1a2e; }\n    #info { \n      position: absolute; \n      top: 10px; \n      left: 10px; \n      color: white; \n      font-size: 18px; \n      background-color: rgba(0,0,0,0.5); \n      padding: 10px; \n      border-radius: 10px; \n    }\n  &lt;/style&gt;\n&lt;/head&gt;\n&lt;body&gt;\n&lt;div id=\"info\"&gt;\n  &lt;h2&gt;Monitor de Orienta\u00e7\u00e3o MPU6050&lt;/h2&gt;\n  \u00c2ngulo X: &lt;span id=\"angleX\"&gt;0&lt;/span&gt;\u00b0&lt;br&gt;\n  \u00c2ngulo Y: &lt;span id=\"angleY\"&gt;0&lt;/span&gt;\u00b0&lt;br&gt;\n  Yaw: &lt;span id=\"yaw\"&gt;0&lt;/span&gt;\u00b0\n&lt;/div&gt;\n&lt;canvas id=\"canvas3d\"&gt;&lt;/canvas&gt;\n&lt;script&gt;\n// ===== Mini 3D Engine =====\nconst canvas = document.getElementById('canvas3d');\nconst ctx = canvas.getContext('2d');\nlet width = canvas.width = window.innerWidth;\nlet height = canvas.height = window.innerHeight;\nwindow.addEventListener('resize', () =&gt; {\n  width = canvas.width = window.innerWidth;\n  height = canvas.height = window.innerHeight;\n});\n\n// Defini\u00e7\u00e3o do cubo em 3D\nconst vertices = [\n  [-1, -1, -1], [1, -1, -1],\n  [1, 1, -1], [-1, 1, -1],\n  [-1, -1, 1], [1, -1, 1],\n  [1, 1, 1], [-1, 1, 1]\n];\n\n// Defini\u00e7\u00e3o das faces do cubo\nconst faces = [\n  [0, 1, 2, 3], // Face frente\n  [1, 5, 6, 2], // Face direita\n  [5, 4, 7, 6], // Face tr\u00e1s\n  [4, 0, 3, 7], // Face esquerda\n  [3, 2, 6, 7], // Face superior\n  [4, 5, 1, 0]  // Face inferior\n];\n\n// Cores para cada face\nconst faceColors = [\n  \"#FF5733\", // Laranja\n  \"#33FF57\", // Verde\n  \"#3357FF\", // Azul\n  \"#FF33A8\", // Rosa\n  \"#FFFF33\", // Amarelo\n  \"#33FFFF\"  // Ciano\n];\n\n// Defini\u00e7\u00e3o das arestas do cubo\nconst edges = [\n  [0,1],[1,2],[2,3],[3,0],\n  [4,5],[5,6],[6,7],[7,4],\n  [0,4],[1,5],[2,6],[3,7]\n];\n\nlet angleX = 0;\nlet angleY = 0;\nlet yaw = 0;\n\n// Fun\u00e7\u00e3o para calcular a normal de uma face\nfunction getFaceNormal(faceVertices) {\n  const [a, b, c] = faceVertices;\n\n  // Vetores de dois lados da face\n  const v1 = [\n    b[0] - a[0],\n    b[1] - a[1],\n    b[2] - a[2]\n  ];\n\n  const v2 = [\n    c[0] - a[0],\n    c[1] - a[1],\n    c[2] - a[2]\n  ];\n\n  // Produto vetorial para obter a normal\n  const normal = [\n    v1[1] * v2[2] - v1[2] * v2[1],\n    v1[2] * v2[0] - v1[0] * v2[2],\n    v1[0] * v2[1] - v1[1] * v2[0]\n  ];\n\n  // Normaliza\u00e7\u00e3o\n  const length = Math.sqrt(normal[0]**2 + normal[1]**2 + normal[2]**2);\n  return [normal[0]/length, normal[1]/length, normal[2]/length];\n}\n\n// Fun\u00e7\u00e3o para desenhar cubo\nfunction drawCube() {\n  ctx.clearRect(0, 0, width, height);\n\n  // Calcular posi\u00e7\u00f5es dos v\u00e9rtices ap\u00f3s rota\u00e7\u00e3o\n  const rotatedVertices = vertices.map(v =&gt; {\n    let [x,y,z] = v;\n\n    // Rota\u00e7\u00e3o em X\n    let rx = x;\n    let ry = y*Math.cos(angleX) - z*Math.sin(angleX);\n    let rz = y*Math.sin(angleX) + z*Math.cos(angleX);\n\n    // Rota\u00e7\u00e3o em Y\n    let rrx = rx*Math.cos(angleY) + rz*Math.sin(angleY);\n    let rry = ry;\n    let rrz = -rx*Math.sin(angleY) + rz*Math.cos(angleY);\n\n    // Rota\u00e7\u00e3o em Z (Yaw)\n    let rrrx = rrx*Math.cos(yaw) - rry*Math.sin(yaw);\n    let rrry = rrx*Math.sin(yaw) + rry*Math.cos(yaw);\n    let rrrz = rrz;\n\n    return [rrrx, rrry, rrrz];\n  });\n\n  // Calcular centro de cada face e sua profundidade para ordena\u00e7\u00e3o\n  const facesWithDepth = faces.map((face, i) =&gt; {\n    const faceVertices = face.map(idx =&gt; rotatedVertices[idx]);\n\n    // Calcular centro da face\n    const centerX = faceVertices.reduce((sum, v) =&gt; sum + v[0], 0) / 4;\n    const centerY = faceVertices.reduce((sum, v) =&gt; sum + v[1], 0) / 4;\n    const centerZ = faceVertices.reduce((sum, v) =&gt; sum + v[2], 0) / 4;\n\n    // Calcular normal da face\n    const normal = getFaceNormal(faceVertices);\n\n    // Dire\u00e7\u00e3o da luz (simplificada)\n    const lightDir = [0, 0, -1];\n\n    // Calcular intensidade da luz na face\n    const lightIntensity = -(normal[0] * lightDir[0] + normal[1] * lightDir[1] + normal[2] * lightDir[2]);\n\n    return {\n      index: i,\n      vertices: faceVertices,\n      depth: centerZ,\n      normal: normal,\n      lightIntensity: Math.max(0.4, lightIntensity)  // Garantir ilumina\u00e7\u00e3o m\u00ednima\n    };\n  });\n\n  // Ordenar faces por profundidade (painter's algorithm)\n  facesWithDepth.sort((a, b) =&gt; b.depth - a.depth);\n\n  // Projetar v\u00e9rtices para 2D\n  const points = rotatedVertices.map(v =&gt; {\n    let [x, y, z] = v;\n    let scale = 400 / (z + 5);\n    return [\n      x * scale + width/2,\n      y * scale + height/2\n    ];\n  });\n\n  // Desenhar as faces em ordem de profundidade\n  facesWithDepth.forEach(face =&gt; {\n    const faceIdx = face.index;\n    const faceVertexIndices = faces[faceIdx];\n\n    // Obter cor da face e ajustar com a intensidade da luz\n    const baseColor = faceColors[faceIdx];\n    const r = parseInt(baseColor.slice(1, 3), 16);\n    const g = parseInt(baseColor.slice(3, 5), 16);\n    const b = parseInt(baseColor.slice(5, 7), 16);\n\n    // Aplicar intensidade da luz\n    const lightIntensity = face.lightIntensity;\n    const shadedColor = `rgb(${Math.floor(r * lightIntensity)}, ${Math.floor(g * lightIntensity)}, ${Math.floor(b * lightIntensity)})`;\n\n    // Desenhar face\n    ctx.beginPath();\n    ctx.moveTo(points[faceVertexIndices[0]][0], points[faceVertexIndices[0]][1]);\n    for (let i = 1; i &lt; faceVertexIndices.length; i++) {\n      ctx.lineTo(points[faceVertexIndices[i]][0], points[faceVertexIndices[i]][1]);\n    }\n    ctx.closePath();\n\n    // Preencher face com a cor ajustada pela ilumina\u00e7\u00e3o\n    ctx.fillStyle = shadedColor;\n    ctx.fill();\n\n    // Desenhar contornos\n    ctx.strokeStyle = \"#000\";\n    ctx.lineWidth = 1;\n    ctx.stroke();\n  });\n}\n\n// Atualiza\u00e7\u00e3o cont\u00ednua\nfunction animate() {\n  drawCube();\n  requestAnimationFrame(animate);\n}\nanimate();\n\n// Atualizar \u00e2ngulos vindo do ESP32\nsetInterval(function() {\n  fetch('/data')\n    .then(response =&gt; response.json())\n    .then(data =&gt; {\n      document.getElementById('angleX').textContent = data.angleX.toFixed(2);\n      document.getElementById('angleY').textContent = data.angleY.toFixed(2);\n      document.getElementById('yaw').textContent = data.yaw.toFixed(2);\n      angleX = data.angleX * Math.PI / 180;\n      angleY = data.angleY * Math.PI / 180;\n      yaw = data.yaw * Math.PI / 180;\n    });\n}, 100);\n&lt;/script&gt;\n&lt;/body&gt;\n&lt;/html&gt;\n)rawliteral\";\n\n\n// ======== Setup ========\nvoid setup() {\n  Serial.begin(115200);\n\n  // Inicializa\u00e7\u00e3o do sensor MPU6050\n  if (!mpu.begin()) {\n    Serial.println(\"Erro ao inicializar o MPU6050\");\n    while (true) delay(10);\n  }\n\n  mpu.setAccelerometerRange(MPU6050_RANGE_2_G);\n  mpu.setGyroRange(MPU6050_RANGE_250_DEG);\n  mpu.setFilterBandwidth(MPU6050_BAND_21_HZ);\n\n  // Conectar no Wi-Fi\n  WiFi.begin(ssid, password);\n  Serial.print(\"Conectando\");\n  while (WiFi.status() != WL_CONNECTED) {\n    Serial.print(\".\");\n    delay(500);\n  }\n  Serial.println(\"\\nWi-Fi conectado\");\n  Serial.print(\"IP: \");\n  Serial.println(WiFi.localIP());\n\n  // Servidor Web\n  server.on(\"/\", HTTP_GET, []() {\n    server.send_P(200, \"text/html\", index_html);\n  });\n\n  server.on(\"/data\", HTTP_GET, []() {\n    StaticJsonDocument&lt;300&gt; doc;\n    doc[\"angleX\"] = angle_x;\n    doc[\"angleY\"] = angle_y;\n    doc[\"yaw\"] = yaw_angle;\n    String jsonResponse;\n    serializeJson(doc, jsonResponse);\n    server.send(200, \"application/json\", jsonResponse);\n  });\n\n  server.begin();\n  Serial.println(\"Servidor HTTP iniciado\");\n\n  last_sensor_update = millis();\n}\n\n// ======== Loop ESP32 ========\nvoid loop() {\n  server.handleClient();\n\n  unsigned long current_time = millis();\n  if (current_time - last_sensor_update &gt;= sensor_update_interval) {\n    unsigned long dt_ms = current_time - last_sensor_update;\n    last_sensor_update = current_time;\n    atualizarDadosSensor(dt_ms);\n  }\n}\n\n// ======== Fun\u00e7\u00e3o de Atualizar Dados do Sensor ========\nvoid atualizarDadosSensor(unsigned long dt_ms) {\n  sensors_event_t a, g, temp;\n  mpu.getEvent(&amp;a, &amp;g, &amp;temp);\n\n  float accel_angle_x = atan2(a.acceleration.y, sqrt(a.acceleration.x * a.acceleration.x + a.acceleration.z * a.acceleration.z)) * 180.0 / PI;\n  float accel_angle_y = atan2(-a.acceleration.x, sqrt(a.acceleration.y * a.acceleration.y + a.acceleration.z * a.acceleration.z)) * 180.0 / PI;\n\n  float gyro_x_deg = g.gyro.x * 180.0 / PI;\n  float gyro_y_deg = g.gyro.y * 180.0 / PI;\n  float gyro_z_deg = g.gyro.z * 180.0 / PI;\n\n  float dt = dt_ms / 1000.0;\n\n  // Filtro complementar\n  angle_x = alpha * (angle_x + gyro_x_deg * dt) + (1.0 - alpha) * accel_angle_x;\n  angle_y = alpha * (angle_y + gyro_y_deg * dt) + (1.0 - alpha) * accel_angle_y;\n\n  // Yaw - integra\u00e7\u00e3o direta do girosc\u00f3pio z\n  yaw_angle += gyro_z_deg * dt;\n\n  if (yaw_angle &lt; 0) yaw_angle += 360;\n  if (yaw_angle &gt;= 360) yaw_angle -= 360;\n}\n</code></pre>"},{"location":"aulas/iot/lab02-esp/index.html#desafios","title":"Desafios","text":"<ul> <li>Crie um sistema de <code>detec\u00e7\u00e3o de movimento</code> para fazer o ESP32 emitir um sinal sonoro (usando um buzzer) quando o movimento ultrapassar determinado limiar.</li> <li>Implemente uma fun\u00e7\u00e3o que detecte \"tap\" no sensor (batida r\u00e1pida) e conte o n\u00famero de taps em sequ\u00eancia.</li> <li>Implemente um ped\u00f4metro que detecte passos usando o padr\u00e3o de acelera\u00e7\u00e3o caracter\u00edstico ao caminhar.</li> <li>Implemente um filtro de Kalman para fus\u00e3o de sensores, em vez do filtro complementar.</li> <li>Crie um sistema que use o ESP32 e o MPU6050 para controlar um modelo 3D em um navegador via WebSocket, mostrando a orienta\u00e7\u00e3o em tempo real.</li> </ul>"},{"location":"aulas/iot/lab03-esp/index.html","title":"Lab03","text":""},{"location":"aulas/iot/lab03-esp/index.html#integracao-com-python-e-emulacao-de-teclado","title":"Integra\u00e7\u00e3o com Python e Emula\u00e7\u00e3o de Teclado","text":"<p>Vamos criar uma interface entre nosso sistema embarcado e o computador, transformando o ESP32+MPU6050 em um dispositivo de entrada alternativo.</p> <p>Especificamente, vamos desenvolver um sistema que:</p> <ol> <li>Captura dados de movimento/orienta\u00e7\u00e3o do MPU6050</li> <li>Transmite esses dados para o computador via comunica\u00e7\u00e3o serial</li> <li>Processa os dados usando um script Python</li> <li>Emula pressionamentos de teclas baseados nos movimentos detectados</li> </ol> <p>Esta interface permite criar controles baseados em gestos para diversas aplica\u00e7\u00f5es, como jogos, apresenta\u00e7\u00f5es, navegadores, entre outros. O sistema funciona como um tradutor que converte movimentos f\u00edsicos em comandos de teclado para qualquer software em execu\u00e7\u00e3o no computador.</p>"},{"location":"aulas/iot/lab03-esp/index.html#comunicacao-esp32-computador","title":"Comunica\u00e7\u00e3o ESP32-Computador","text":""},{"location":"aulas/iot/lab03-esp/index.html#transmissao-de-dados-via-serial","title":"Transmiss\u00e3o de Dados via Serial","text":"<p>A porta USB que usamos para programar o ESP32 tamb\u00e9m pode ser usada para comunica\u00e7\u00e3o durante a execu\u00e7\u00e3o do programa. Esta \u00e9 a forma mais direta de enviar dados do microcontrolador para o computador.</p> <p>Caracter\u00edsticas da comunica\u00e7\u00e3o serial:</p> <ul> <li>Conex\u00e3o bidirecional (podemos enviar e receber dados)</li> <li>N\u00e3o requer hardware adicional </li> <li>Velocidades t\u00edpicas de 9600 a 115200 bps (bits por segundo)</li> <li>Permite transmiss\u00e3o de texto ou dados bin\u00e1rios</li> </ul> <p>No lado do ESP32 (Arduino IDE):</p> <pre><code>void setup() {\n  // Inicializa a comunica\u00e7\u00e3o serial a 115200 bits por segundo\n  Serial.begin(115200);\n}\n\nvoid loop() {\n  // Envia uma mensagem simples\n  Serial.println(\"Ol\u00e1, computador!\");\n  delay(1000);\n}\n</code></pre> <p>Do lado do Python:</p> <pre><code>import serial\n\n# Abre a porta serial (ajustar a porta COM conforme necess\u00e1rio)\n# No Windows ser\u00e1 algo como 'COM3', 'COM4', etc.\n# No Linux/Mac ser\u00e1 algo como '/dev/ttyUSB0' ou '/dev/cu.usbserial'\nser = serial.Serial('COM3', 115200)\n\n# L\u00ea e imprime dados recebidos\nwhile True:\n    if ser.in_waiting &gt; 0:\n        line = ser.readline().decode('utf-8').rstrip()\n        print(f\"Recebido: {line}\")\n</code></pre>"},{"location":"aulas/iot/lab03-esp/index.html#protocolo-de-dados","title":"Protocolo de dados","text":"<p>Para facilitar o processamento dos dados no Python, \u00e9 importante enviar informa\u00e7\u00f5es em um formato estruturado. Algumas op\u00e7\u00f5es comuns:</p> <ol> <li> <p>Valores Separados por V\u00edrgula (CSV): <pre><code>angulo_x,angulo_y,aceleracao_z\n</code></pre></p> </li> <li> <p>Nota\u00e7\u00e3o JSON: <pre><code>{\"ax\": 0.1, \"ay\": -0.5, \"az\": 9.8, \"gx\": 0.01, \"gy\": 0.02, \"gz\": -0.01}\n</code></pre></p> </li> <li> <p>Formato Personalizado com Delimitadores: <pre><code>&lt;BEGIN&gt;0.1,-0.5,9.8,0.01,0.02,-0.01&lt;END&gt;\n</code></pre></p> </li> </ol> <p>Por enquanto, usaremos o formato CSV por sua simplicidade e baixo overhead.</p> <p>Implementa\u00e7\u00e3o no ESP32:</p> <pre><code>#include &lt;Wire.h&gt;\n#include &lt;Adafruit_MPU6050.h&gt;\n#include &lt;Adafruit_Sensor.h&gt;\n\n// ======== Prot\u00f3tipos de fun\u00e7\u00f5es =========\nvoid atualizarDadosSensor(unsigned long dt_ms);\n\n// ======== Objeto Sensor ========\nAdafruit_MPU6050 mpu;\n\n// ======== Vari\u00e1veis de processamento ========\nfloat angle_x = 0;\nfloat angle_y = 0;\nfloat yaw_angle = 0;\nunsigned long last_sensor_update = 0;\nunsigned long last_data_send = 0;\nconst unsigned long sensor_update_interval = 10; // em ms\nconst unsigned long data_update = 50; // em ms\nfloat alpha = 0.96; // Filtro complementar\n\n\n\n// ======== Setup ========\nvoid setup() {\n  Serial.begin(115200);\n\n  // Inicializa\u00e7\u00e3o do sensor MPU6050\n  if (!mpu.begin()) {\n    Serial.println(\"Erro ao inicializar o MPU6050\");\n    while (true) delay(10);\n  }\n\n  mpu.setAccelerometerRange(MPU6050_RANGE_2_G);\n  mpu.setGyroRange(MPU6050_RANGE_250_DEG);\n  mpu.setFilterBandwidth(MPU6050_BAND_21_HZ);\n\n  last_sensor_update = millis();\n}\n\n// ======== Loop ESP32 ========\nvoid loop() {\n\n  unsigned long current_time = millis();\n  if (current_time - last_sensor_update &gt;= sensor_update_interval) {\n    unsigned long dt_ms = current_time - last_sensor_update;\n    last_sensor_update = current_time;\n    atualizarDadosSensor(dt_ms);\n  }\n  if (current_time - last_data_send &gt;= data_update) {\n    last_data_send = current_time;\n    Serial.print(angle_x);\n    Serial.print(\",\");\n    Serial.print(angle_y);\n    Serial.print(\",\");\n    Serial.println(yaw_angle);\n  }\n}\n\n// ======== Fun\u00e7\u00e3o de Atualizar Dados do Sensor ========\nvoid atualizarDadosSensor(unsigned long dt_ms) {\n  sensors_event_t a, g, temp;\n  mpu.getEvent(&amp;a, &amp;g, &amp;temp);\n\n  float accel_angle_x = atan2(a.acceleration.y, sqrt(a.acceleration.x * a.acceleration.x + a.acceleration.z * a.acceleration.z)) * 180.0 / PI;\n  float accel_angle_y = atan2(-a.acceleration.x, sqrt(a.acceleration.y * a.acceleration.y + a.acceleration.z * a.acceleration.z)) * 180.0 / PI;\n\n  float gyro_x_deg = g.gyro.x * 180.0 / PI;\n  float gyro_y_deg = g.gyro.y * 180.0 / PI;\n  float gyro_z_deg = g.gyro.z * 180.0 / PI;\n\n  float dt = dt_ms / 1000.0;\n\n  // Filtro complementar\n  angle_x = alpha * (angle_x + gyro_x_deg * dt) + (1.0 - alpha) * accel_angle_x;\n  angle_y = alpha * (angle_y + gyro_y_deg * dt) + (1.0 - alpha) * accel_angle_y;\n\n  // Yaw - integra\u00e7\u00e3o direta do girosc\u00f3pio z\n  yaw_angle += gyro_z_deg * dt;\n\n  if (yaw_angle &lt; 0) yaw_angle += 360;\n  if (yaw_angle &gt;= 360) yaw_angle -= 360;\n}\n</code></pre>"},{"location":"aulas/iot/lab03-esp/index.html#desenvolvimento-do-script-python","title":"Desenvolvimento do Script Python","text":""},{"location":"aulas/iot/lab03-esp/index.html#leitura-de-dados-seriais","title":"Leitura de Dados Seriais","text":"<p>Para comunica\u00e7\u00e3o serial em Python, usamos a biblioteca <code>pyserial</code>. Vamos instalar as depend\u00eancias necess\u00e1rias:</p> <pre><code>pip install pyserial pyautogui\n</code></pre> <p>Estrutura b\u00e1sica para leitura de dados seriais:</p> <pre><code>import serial\nimport time\n\n# Configura\u00e7\u00e3o da porta serial\n# No Windows ser\u00e1 algo como 'COM3', 'COM4', etc.\n# No Linux/Mac ser\u00e1 algo como '/dev/ttyUSB0' ou '/dev/cu.usbserial'\nSERIAL_PORT = '/dev/cu.usbserial-0001'  # Ajuste conforme seu sistema\nBAUD_RATE = 115200\n\ntry:\n    # Abrir conex\u00e3o serial\n    ser = serial.Serial(SERIAL_PORT, BAUD_RATE)\n    print(f\"Conectado a {SERIAL_PORT} a {BAUD_RATE} bps\")\n\n    # Esperar pela inicializa\u00e7\u00e3o da conex\u00e3o\n    time.sleep(2)\n\n    while True:\n        # Verificar se h\u00e1 dados dispon\u00edveis\n        if ser.in_waiting &gt; 0:\n            # Ler uma linha de dados\n            line = ser.readline().decode('utf-8').rstrip()\n\n            try:\n                # Dividir a linha CSV em valores individuais\n                values = line.split(',')\n                if len(values) == 3:\n                    angle_x = float(values[0])\n                    angle_y = float(values[1])\n                    angle_z = float(values[2])\n\n                    print(f\"X: {angle_x:.2f}\u00b0, Y: {angle_y:.2f}\u00b0, Z-Accel: {angle_z:.2f}\u00b0\")\n            except ValueError:\n                # Ignorar linhas inv\u00e1lidas\n                pass\n\nexcept serial.SerialException as e:\n    print(f\"Erro ao abrir porta serial: {e}\")\nexcept KeyboardInterrupt:\n    print(\"Programa interrompido pelo usu\u00e1rio\")\nfinally:\n    # Garantir que a porta seja fechada\n    if 'ser' in locals() and ser.is_open:\n        ser.close()\n        print(\"Porta serial fechada\")\n</code></pre>"},{"location":"aulas/iot/lab03-esp/index.html#processamento-de-dados","title":"Processamento de Dados","text":"<p>Antes de emular teclas, precisamos processar os dados do sensor para reconhecer gestos ou movimentos espec\u00edficos:</p> <pre><code>def process_movement(angle_x, angle_y, angle_z):\n    \"\"\"\n    Processa os dados de movimento e retorna o comando correspondente\n    \"\"\"\n    # Definir os limiares para detec\u00e7\u00e3o de movimentos\n    TILT_THRESHOLD = 20  # Graus\n\n    # Inicializar comando vazio\n    command = None\n\n    # Inclina\u00e7\u00e3o para esquerda\n    if angle_y &lt; -TILT_THRESHOLD:\n        command = \"LEFT\"\n    # Inclina\u00e7\u00e3o para direita\n    elif angle_y &gt; TILT_THRESHOLD:\n        command = \"RIGHT\"\n    # Inclina\u00e7\u00e3o para frente\n    elif angle_x &lt; -TILT_THRESHOLD:\n        command = \"UP\"\n    # Inclina\u00e7\u00e3o para tr\u00e1s\n    elif angle_x &gt; TILT_THRESHOLD:\n        command = \"DOWN\"\n\n    return command\n</code></pre>"},{"location":"aulas/iot/lab03-esp/index.html#emulacao-de-teclado-com-pyautogui","title":"Emula\u00e7\u00e3o de Teclado com PyAutoGUI","text":"<p>A biblioteca PyAutoGUI permite simular pressionamentos de teclas e movimentos do mouse:</p> <pre><code>import pyautogui\n\n# Configura\u00e7\u00e3o de seguran\u00e7a (pausa entre comandos)\npyautogui.PAUSE = 0.1\n\ndef execute_command(command):\n    \"\"\"\n    Executa um comando atrav\u00e9s da emula\u00e7\u00e3o de teclas\n    \"\"\"\n    if command is None:\n        return\n\n    # Mapear comandos para teclas\n    key_mapping = {\n        \"UP\": \"up\",\n        \"DOWN\": \"down\",\n        \"LEFT\": \"left\",\n        \"RIGHT\": \"right\"\n    }\n\n    # Verificar se o comando existe no mapeamento\n    if command in key_mapping:\n        # Pressionar a tecla correspondente\n        key = key_mapping[command]\n        print(f\"Pressionando tecla: {key}\")\n        pyautogui.press(key)\n</code></pre>"},{"location":"aulas/iot/lab03-esp/index.html#projeto-controle-de-jogosaplicacoes-com-gestos","title":"Projeto: Controle de Jogos/Aplica\u00e7\u00f5es com Gestos","text":"<p>Vamos integrar tudo em um projeto completo que usa o ESP32+MPU6050 como controle de movimento para aplica\u00e7\u00f5es no computador</p>"},{"location":"aulas/iot/lab03-esp/index.html#script-python-completo","title":"Script Python Completo","text":"<pre><code>import serial\nimport time\nimport pyautogui\nimport argparse\nimport sys\n\n# Configura\u00e7\u00f5es padr\u00e3o\n# no macOS, a porta pode ser algo como '/dev/cu.usb**XXXX'\n# no Linux, pode ser '/dev/ttyUSB0' ou '/dev/ttyACM0'\n# no Windows, pode ser 'COM3', 'COM4', etc.\nDEFAULT_PORT = '/dev/cu.usbserial-0001'  # Altere conforme necess\u00e1rio\nDEFAULT_BAUD = 115200\nDEFAULT_THRESHOLD = 20  # Graus para ativa\u00e7\u00e3o\nDEFAULT_COOLDOWN = 0.5  # Segundos entre comandos\n\n# Configura\u00e7\u00e3o do PyAutoGUI\npyautogui.PAUSE = 0.1  # Pausa de 100ms entre comandos\npyautogui.FAILSAFE = True  # Mova o mouse para o canto superior esquerdo para abortar\n\nclass MotionController:\n    def __init__(self, port=DEFAULT_PORT, baud=DEFAULT_BAUD, \n                 threshold=DEFAULT_THRESHOLD, cooldown=DEFAULT_COOLDOWN):\n        \"\"\"Inicializa o controlador de movimento\"\"\"\n        self.port = port\n        self.baud = baud\n        self.threshold = threshold\n        self.cooldown = cooldown\n\n        self.ser = None\n        self.last_command = None\n        self.last_command_time = 0\n\n        # Mapeamento de comandos para teclas\n        self.key_mapping = {\n            \"UP\": \"up\",\n            \"DOWN\": \"down\",\n            \"LEFT\": \"left\",\n            \"RIGHT\": \"right\"\n        }\n\n    def connect(self):\n        \"\"\"Estabelece conex\u00e3o com a porta serial\"\"\"\n        try:\n            self.ser = serial.Serial(self.port, self.baud)\n            print(f\"Conectado a {self.port} a {self.baud} bps\")\n            time.sleep(2)  # Aguarda estabiliza\u00e7\u00e3o\n            return True\n        except serial.SerialException as e:\n            print(f\"Erro ao abrir porta serial: {e}\")\n            return False\n\n    def process_movement(self, angle_x, angle_y, accel_z):\n        \"\"\"Processa os dados de movimento e retorna o comando\"\"\"\n        # Inicializar comando vazio\n        command = None\n\n        # Inclina\u00e7\u00e3o para esquerda\n        if angle_y &lt; -self.threshold:\n            command = \"LEFT\"\n        # Inclina\u00e7\u00e3o para direita\n        elif angle_y &gt; self.threshold:\n            command = \"RIGHT\"\n        # Inclina\u00e7\u00e3o para frente\n        elif angle_x &lt; -self.threshold:\n            command = \"UP\"\n        # Inclina\u00e7\u00e3o para tr\u00e1s\n        elif angle_x &gt; self.threshold:\n            command = \"DOWN\"\n\n        return command\n\n    def execute_command(self, command):\n        \"\"\"Executa um comando via emula\u00e7\u00e3o de tecla\"\"\"\n        # Verifica se o comando existe e se passou o tempo de cooldown\n        current_time = time.time()\n\n        if (command is not None and \n            (command != self.last_command or \n             current_time - self.last_command_time &gt;= self.cooldown)):\n\n            # Verifica se o comando est\u00e1 no mapeamento\n            if command in self.key_mapping:\n                # Pressiona a tecla correspondente\n                key = self.key_mapping[command]\n                print(f\"Pressionando tecla: {key}\")\n                pyautogui.press(key)\n\n                # Atualiza o \u00faltimo comando e o tempo\n                self.last_command = command\n                self.last_command_time = current_time\n\n    def run(self):\n        \"\"\"Loop principal do controlador\"\"\"\n        if not self.connect():\n            return\n\n        print(\"Iniciando monitoramento de movimentos...\")\n        print(\"Pressione Ctrl+C para sair\")\n\n        try:\n            while True:\n                # Verifica se h\u00e1 dados dispon\u00edveis\n                if self.ser.in_waiting &gt; 0:\n                    # L\u00ea uma linha de dados\n                    line = self.ser.readline().decode('utf-8').rstrip()\n\n                    try:\n                        # Divide a linha em valores\n                        values = line.split(',')\n                        if len(values) == 3:\n                            angle_x = float(values[0])\n                            angle_y = float(values[1])\n                            accel_z = float(values[2])\n\n                            # Exibe os valores para debug\n                            print(f\"X: {angle_x:.1f}\u00b0, Y: {angle_y:.1f}\u00b0, Z: {accel_z:.1f}m/s\u00b2\", end=\"\")\n\n                            # Processa o movimento e executa o comando\n                            command = self.process_movement(angle_x, angle_y, accel_z)\n                            if command:\n                                print(f\" | Comando: {command}\")\n                                self.execute_command(command)\n                            else:\n                                print(\" | Sem comando\")\n                    except ValueError:\n                        # Ignora linhas inv\u00e1lidas\n                        pass\n\n                time.sleep(0.01)  # Pequena pausa para n\u00e3o sobrecarregar a CPU\n\n        except KeyboardInterrupt:\n            print(\"\\nPrograma interrompido pelo usu\u00e1rio\")\n        finally:\n            # Garante que a porta seja fechada\n            if self.ser and self.ser.is_open:\n                self.ser.close()\n                print(\"Porta serial fechada\")\n\ndef main():\n    \"\"\"Fun\u00e7\u00e3o principal para execu\u00e7\u00e3o via linha de comando\"\"\"\n    # Configura\u00e7\u00e3o do parser de argumentos\n    parser = argparse.ArgumentParser(description='Controle por gestos com ESP32 e MPU6050')\n    parser.add_argument('-p', '--port', default=DEFAULT_PORT,\n                        help=f'Porta serial (default: {DEFAULT_PORT})')\n    parser.add_argument('-b', '--baud', type=int, default=DEFAULT_BAUD,\n                        help=f'Taxa de transmiss\u00e3o (default: {DEFAULT_BAUD})')\n    parser.add_argument('-t', '--threshold', type=float, default=DEFAULT_THRESHOLD,\n                        help=f'Limiar de inclina\u00e7\u00e3o em graus (default: {DEFAULT_THRESHOLD})')\n    parser.add_argument('-c', '--cooldown', type=float, default=DEFAULT_COOLDOWN,\n                        help=f'Tempo m\u00ednimo entre comandos em segundos (default: {DEFAULT_COOLDOWN})')\n\n    # Analisa os argumentos da linha de comando\n    args = parser.parse_args()\n\n    # Cria e executa o controlador\n    controller = MotionController(\n        port=args.port,\n        baud=args.baud,\n        threshold=args.threshold,\n        cooldown=args.cooldown\n    )\n    controller.run()\n\nif __name__ == \"__main__\":\n    main()\n</code></pre> <p>Como usar o script:</p> <ol> <li>Carregue o firmware no ESP32 usando a Arduino IDE</li> <li>Conecte o ESP32 ao computador via USB</li> <li>Execute o script Python</li> <li>Incline o ESP32+MPU6050 para emular as teclas de seta</li> </ol> <p>Op\u00e7\u00f5es da linha de comando: <pre><code>python motion_controller.py --port COM3 --threshold 15 --cooldown 0.3\n</code></pre></p>"},{"location":"aulas/iot/lab03-esp/index.html#casos-de-uso-avancados","title":"Casos de Uso Avan\u00e7ados","text":""},{"location":"aulas/iot/lab03-esp/index.html#controle-de-apresentacoes","title":"Controle de Apresenta\u00e7\u00f5es","text":"<p>Podemos adaptar o c\u00f3digo para controlar apresenta\u00e7\u00f5es de slides:</p> <pre><code># Modifica\u00e7\u00e3o no mapeamento de teclas para controle de apresenta\u00e7\u00f5es\nself.key_mapping = {\n    \"LEFT\": \"left\",     # Slide anterior\n    \"RIGHT\": \"right\",   # Pr\u00f3ximo slide\n    \"UP\": \"home\",       # Primeira slide\n    \"DOWN\": \"end\"       # \u00daltimo slide\n}\n</code></pre> <p>Tamb\u00e9m podemos adicionar gestos mais complexos:</p> <pre><code># No m\u00e9todo process_movement:\n# Detectar gesto de \"picar\" para iniciar/parar apresenta\u00e7\u00e3o\nif abs(accel_z) &gt; 15:  # Detecta movimento brusco vertical\n    return \"TOGGLE\"\n\n# No mapeamento:\nself.key_mapping[\"TOGGLE\"] = \"f5\"  # Inicia/termina apresenta\u00e7\u00e3o no PowerPoint\n</code></pre>"},{"location":"aulas/iot/lab03-esp/index.html#controle-de-jogos","title":"Controle de Jogos","text":"<p>Para jogos simples, podemos mapear movimentos para teclas usadas no jogo:</p> <pre><code># Mapeamento para jogos de corrida\nself.key_mapping = {\n    \"LEFT\": \"a\",       # Esquerda\n    \"RIGHT\": \"d\",      # Direita\n    \"UP\": \"w\",         # Acelerar\n    \"DOWN\": \"s\"        # Frear\n}\n</code></pre> <p>Para jogos mais complexos, podemos adicionar detec\u00e7\u00e3o de rota\u00e7\u00e3o:</p> <pre><code>def process_movement(self, angle_x, angle_y, gyro_z):\n    # Comandos b\u00e1sicos de inclina\u00e7\u00e3o\n    if angle_y &lt; -self.threshold:\n        return \"LEFT\"\n    elif angle_y &gt; self.threshold:\n        return \"RIGHT\"\n    # ...\n\n    # Detectar rota\u00e7\u00e3o para a\u00e7\u00f5es adicionais\n    if gyro_z &gt; 100:  # Rota\u00e7\u00e3o r\u00e1pida no sentido hor\u00e1rio\n        return \"ACTION1\"\n    elif gyro_z &lt; -100:  # Rota\u00e7\u00e3o r\u00e1pida no sentido anti-hor\u00e1rio\n        return \"ACTION2\"\n</code></pre>"},{"location":"aulas/iot/lab03-esp/index.html#controle-de-midia","title":"Controle de M\u00eddia","text":"<p>Podemos adaptar para controle de reprodu\u00e7\u00e3o de m\u00eddia:</p> <pre><code># Mapeamento para controle de m\u00eddia\nself.key_mapping = {\n    \"LEFT\": \"prevtrack\",    # Faixa anterior\n    \"RIGHT\": \"nexttrack\",   # Pr\u00f3xima faixa\n    \"UP\": \"volumeup\",       # Aumentar volume\n    \"DOWN\": \"volumedown\",   # Diminuir volume\n}\n\n# Adicionar detec\u00e7\u00e3o de \"shake\" para play/pause\nif abs(accel_z) &gt; 20:\n    return \"PLAYPAUSE\"\n\nself.key_mapping[\"PLAYPAUSE\"] = \"playpause\"\n</code></pre>"},{"location":"aulas/iot/lab03-esp/index.html#otimizacoes-e-boas-praticas","title":"Otimiza\u00e7\u00f5es e Boas Pr\u00e1ticas","text":""},{"location":"aulas/iot/lab03-esp/index.html#otimizacao-do-firmware-esp32","title":"Otimiza\u00e7\u00e3o do Firmware ESP32","text":"<ol> <li> <p>Redu\u00e7\u00e3o de Jitter: <pre><code>// Usar o temporizador de hardware para timing mais preciso\nhw_timer_t *timer = NULL;\nportMUX_TYPE timerMux = portMUX_INITIALIZER_UNLOCKED;\n\nvoid IRAM_ATTR onTimer() {\n  portENTER_CRITICAL_ISR(&amp;timerMux);\n  // Leitura do sensor\n  portEXIT_CRITICAL_ISR(&amp;timerMux);\n}\n\nvoid setup() {\n  // ...\n  // Configurar timer a 100Hz (10ms)\n  timer = timerBegin(0, 80, true);\n  timerAttachInterrupt(timer, &amp;onTimer, true);\n  timerAlarmWrite(timer, 10000, true);\n  timerAlarmEnable(timer);\n}\n</code></pre></p> </li> <li> <p>Redu\u00e7\u00e3o do Consumo de Energia: <pre><code>// Modo de baixo consumo quando inativo\nif (current_time - last_activity_time &gt; INACTIVE_TIMEOUT) {\n  mpu.setSleepEnabled(true);\n  esp_sleep_enable_timer_wakeup(5 * 1000000); // Acordar em 5 segundos\n  esp_light_sleep_start();\n  mpu.setSleepEnabled(false);\n  last_activity_time = millis();\n}\n</code></pre></p> </li> </ol>"},{"location":"aulas/iot/lab03-esp/index.html#otimizacao-do-script-python","title":"Otimiza\u00e7\u00e3o do Script Python","text":"<ol> <li>Interface Gr\u00e1fica: <pre><code>def create_gui():\n    \"\"\"Cria uma interface gr\u00e1fica simples\"\"\"\n    import tkinter as tk\n    from matplotlib.figure import Figure\n    from matplotlib.backends.backend_tkagg import FigureCanvasTkAgg\n\n    root = tk.Tk()\n    root.title(\"Controle de Movimento ESP32+MPU6050\")\n\n    # Criar figura para visualiza\u00e7\u00e3o dos \u00e2ngulos\n    fig = Figure(figsize=(6, 4))\n    ax = fig.add_subplot(111)\n    ax.set_ylim(-90, 90)\n    ax.set_xlabel(\"Tempo\")\n    ax.set_ylabel(\"\u00c2ngulo (graus)\")\n    ax.grid(True)\n\n    # Linhas para \u00e2ngulos X e Y\n    line_x, = ax.plot([], [], 'r-', label='\u00c2ngulo X')\n    line_y, = ax.plot([], [], 'b-', label='\u00c2ngulo Y')\n    ax.legend()\n\n    # Adicionar canvas \u00e0 janela\n    canvas = FigureCanvasTkAgg(fig, master=root)\n    canvas.draw()\n    canvas.get_tk_widget().pack(side=tk.TOP, fill=tk.BOTH, expand=1)\n\n    # Controles\n    frame = tk.Frame(root)\n    frame.pack(side=tk.BOTTOM, fill=tk.X)\n\n    # Bot\u00e3o para conectar/desconectar\n    btn_connect = tk.Button(frame, text=\"Conectar\")\n    btn_connect.pack(side=tk.LEFT, padx=5, pady=5)\n\n    # Bot\u00e3o para calibrar\n    btn_calibrate = tk.Button(frame, text=\"Calibrar\")\n    btn_calibrate.pack(side=tk.LEFT, padx=5, pady=5)\n\n    # Slider para ajustar threshold\n    lbl_threshold = tk.Label(frame, text=\"Limiar:\")\n    lbl_threshold.pack(side=tk.LEFT, padx=5, pady=5)\n\n    threshold_var = tk.DoubleVar(value=DEFAULT_THRESHOLD)\n    slider_threshold = tk.Scale(frame, from_=5, to=45, \n                                orient=tk.HORIZONTAL, \n                                variable=threshold_var)\n    slider_threshold.pack(side=tk.LEFT, padx=5, pady=5)\n\n    return root, line_x, line_y, threshold_var\n</code></pre></li> </ol>"},{"location":"aulas/iot/lab03-esp/index.html#desafios-e-exercicios","title":"Desafios e Exerc\u00edcios","text":"<ul> <li>Adapte o sistema para controlar o volume do computador com movimentos de inclina\u00e7\u00e3o</li> <li>Implemente um novo gesto (\"shake\" ou batida dupla) para fun\u00e7\u00e3o de mudo (mute/unmute)</li> <li>Crie um sistema para calibra\u00e7\u00e3o interativa via interface gr\u00e1fica</li> <li>Adicione suporte para mapear diferentes gestos para diferentes aplica\u00e7\u00f5es</li> <li>Implemente um sistema de aprendizagem de gestos personalizados</li> <li>Integre com reconhecimento de gestos mais complexos (c\u00edrculos, desenhos no ar)</li> <li>Crie um controle para drone ou rob\u00f4 que use os dados do MPU6050 via Wi-Fi em vez de USB</li> </ul>"},{"location":"aulas/iot/lab1/index.html","title":"Lab01 - Led","text":""},{"location":"aulas/iot/lab1/index.html#introducao-ao-arduino-e-controle-de-leds","title":"Introdu\u00e7\u00e3o ao Arduino e Controle de LEDs","text":""},{"location":"aulas/iot/lab1/index.html#visao-geral","title":"Vis\u00e3o Geral","text":"<p>Neste laborat\u00f3rio, voc\u00ea ir\u00e1 aprender os conceitos b\u00e1sicos do Arduino realizando experimentos com LEDs e um buzzer. Os desafios propostos ajudar\u00e3o voc\u00ea a compreender os fundamentos de programa\u00e7\u00e3o do Arduino, controle de pinos digitais e temporiza\u00e7\u00e3o.</p>"},{"location":"aulas/iot/lab1/index.html#desafio-1-controle-basico-de-leds","title":"Desafio 1: Controle B\u00e1sico de LEDs","text":"<p>Objetivo: Criar um circuito com dois LEDs que piscam sincronizadamente.</p>"},{"location":"aulas/iot/lab1/index.html#instrucoes","title":"Instru\u00e7\u00f5es:","text":"<ol> <li> <p>Monte o circuito conforme mostrado na imagem abaixo:    </p> </li> <li> <p>Conecte:</p> </li> <li>LED 1 ao pino digital 13</li> <li> <p>LED 2 ao pino digital 12</p> </li> <li> <p>Escreva um c\u00f3digo que fa\u00e7a os LEDs piscarem simultaneamente com um intervalo de 0,5 segundos.</p> </li> </ol>"},{"location":"aulas/iot/lab1/index.html#dicas","title":"Dicas:","text":"<ul> <li>Use as fun\u00e7\u00f5es <code>digitalWrite()</code> para controlar os LEDs</li> <li>Use <code>delay()</code> para controlar o tempo entre os estados</li> <li>Lembre-se de configurar os pinos como sa\u00edda usando <code>pinMode()</code></li> </ul>"},{"location":"aulas/iot/lab1/index.html#desafio-2-sequencia-de-leds","title":"Desafio 2: Sequ\u00eancia de LEDs","text":"<p>Objetivo: Controlar dois LEDs seguindo uma sequ\u00eancia temporal espec\u00edfica.</p>"},{"location":"aulas/iot/lab1/index.html#instrucoes_1","title":"Instru\u00e7\u00f5es:","text":"<ol> <li> <p>Use o mesmo circuito do Desafio 1.</p> </li> <li> <p>Programe os LEDs para acenderem conforme a carta de tempo abaixo:    </p> </li> </ol> <p>Onde:    - 1 = n\u00edvel l\u00f3gico alto (HIGH) - LED aceso    - 0 = n\u00edvel l\u00f3gico baixo (LOW) - LED apagado    - Cada intervalo = 500ms (meio segundo)</p>"},{"location":"aulas/iot/lab1/index.html#dicas_1","title":"Dicas:","text":"<ul> <li>Observe cuidadosamente o padr\u00e3o e organize seu c\u00f3digo de forma l\u00f3gica</li> <li>A sequ\u00eancia deve ser repetida continuamente</li> </ul>"},{"location":"aulas/iot/lab1/index.html#desafio-3-codigo-morse-com-buzzer","title":"Desafio 3: C\u00f3digo Morse com Buzzer","text":"<p>Objetivo: Criar um sistema que reproduza seu nome em c\u00f3digo Morse usando um buzzer.</p>"},{"location":"aulas/iot/lab1/index.html#instrucoes_2","title":"Instru\u00e7\u00f5es:","text":"<ol> <li>Monte um circuito adicionando um buzzer piezoel\u00e9trico ao seu Arduino.</li> <li>Conecte o terminal positivo do buzzer a um pino digital (sugest\u00e3o: pino 8)</li> <li> <p>Conecte o terminal negativo ao GND</p> </li> <li> <p>Usando a tabela de c\u00f3digo Morse abaixo, programe o Arduino para reproduzir seu nome:    </p> </li> </ol>"},{"location":"aulas/iot/lab1/index.html#convencoes-do-codigo-morse","title":"Conven\u00e7\u00f5es do C\u00f3digo Morse:","text":"<ul> <li>Ponto (\u2022): tom curto (200ms)</li> <li>Tra\u00e7o (\u2212): tom longo (600ms)</li> <li>Espa\u00e7o entre s\u00edmbolos de uma mesma letra: pausa curta (200ms)</li> <li>Espa\u00e7o entre letras: pausa m\u00e9dia (600ms)</li> <li>Espa\u00e7o entre palavras: pausa longa (1400ms)</li> </ul>"},{"location":"aulas/iot/lab1/index.html#dicas_2","title":"Dicas:","text":"<ul> <li>Use a fun\u00e7\u00e3o <code>tone()</code> para gerar sons no buzzer</li> <li>Use a fun\u00e7\u00e3o <code>noTone()</code> para silenciar o buzzer</li> <li>Considere criar fun\u00e7\u00f5es auxiliares para representar pontos e tra\u00e7os</li> </ul>"},{"location":"aulas/iot/lab1/index.html#programacao-com-millis-temporizacao-avancada-sem-bloqueio","title":"Programa\u00e7\u00e3o com millis() - Temporiza\u00e7\u00e3o Avan\u00e7ada sem Bloqueio","text":""},{"location":"aulas/iot/lab1/index.html#conceitos-teoricos","title":"Conceitos Te\u00f3ricos","text":"<p>A fun\u00e7\u00e3o <code>delay()</code> \u00e9 simples de usar, mas apresenta uma limita\u00e7\u00e3o fundamental: ela bloqueia a execu\u00e7\u00e3o do programa, impedindo que o Arduino fa\u00e7a qualquer outra coisa durante a espera. Isso torna imposs\u00edvel realizar m\u00faltiplas tarefas simultaneamente, como:</p> <ul> <li>Monitorar bot\u00f5es enquanto LEDs piscam</li> <li>Ler sensores em intervalos regulares enquanto atualiza um display</li> <li>Controlar m\u00faltiplos dispositivos com diferentes tempos de atualiza\u00e7\u00e3o</li> </ul> <p>A fun\u00e7\u00e3o <code>millis()</code> oferece uma solu\u00e7\u00e3o para esse problema:</p> <ul> <li>Retorna o n\u00famero de milissegundos desde que o programa iniciou (contador sempre crescente)</li> <li>Permite criar temporizadores n\u00e3o-bloqueantes</li> <li>Possibilita executar v\u00e1rias tarefas \"simultaneamente\" (multitarefa cooperativa)</li> </ul>"},{"location":"aulas/iot/lab1/index.html#implementacao-pratica","title":"Implementa\u00e7\u00e3o Pr\u00e1tica","text":"<p>Para implementar um temporizador com <code>millis()</code>:</p> <ol> <li>Armazene o valor atual de <code>millis()</code> como um ponto de refer\u00eancia</li> <li>Em cada loop, compare o valor atual de <code>millis()</code> com sua refer\u00eancia</li> <li>Execute uma a\u00e7\u00e3o quando a diferen\u00e7a atingir ou ultrapassar o intervalo desejado</li> <li>Atualize sua refer\u00eancia para o pr\u00f3ximo intervalo</li> </ol> <p>Exemplo b\u00e1sico para piscar um LED a cada segundo sem bloquear o programa:</p> <pre><code>const int ledPin = 13;\nunsigned long previousMillis = 0;  // \u00daltimo momento em que o LED foi atualizado\nconst long interval = 1000;        // Intervalo em milissegundos (1 segundo)\nint ledState = LOW;                // Estado atual do LED\n\nvoid setup() {\n  pinMode(ledPin, OUTPUT);\n}\n\nvoid loop() {\n  // Captura o tempo atual em milissegundos\n  unsigned long currentMillis = millis();\n\n  // Verifica se \u00e9 hora de atualizar o LED\n  if (currentMillis - previousMillis &gt;= interval) {\n    // Salva o \u00faltimo momento em que atualizamos o LED\n    previousMillis = currentMillis;\n\n    // Se o LED est\u00e1 desligado, ligue-o e vice-versa\n    if (ledState == LOW) {\n      ledState = HIGH;\n    } else {\n      ledState = LOW;\n    }\n\n    // Atualiza o LED com seu novo estado\n    digitalWrite(ledPin, ledState);\n  }\n\n  // Aqui voc\u00ea pode realizar outras tarefas sem ser bloqueado!\n  // Por exemplo, ler sensores, verificar bot\u00f5es, etc.\n}\n</code></pre>"},{"location":"aulas/iot/lab1/index.html#vantagens-do-millis","title":"Vantagens do millis()","text":"<ol> <li>Multitarefa: Permite controlar v\u00e1rios dispositivos com diferentes intervalos de tempo</li> <li>Responsividade: O programa continua respondendo a entradas mesmo durante temporiza\u00e7\u00f5es</li> <li>Flexibilidade: Possibilita implementar temporizadores complexos e padr\u00f5es de temporiza\u00e7\u00e3o</li> <li>Efici\u00eancia: Melhor utiliza\u00e7\u00e3o do processador, executando tarefas enquanto \"espera\"</li> </ol>"},{"location":"aulas/iot/lab1/index.html#limitacoes-do-millis","title":"Limita\u00e7\u00f5es do millis()","text":"<ol> <li>O contador volta a zero ap\u00f3s aproximadamente 50 dias de execu\u00e7\u00e3o cont\u00ednua (estouro)</li> <li>C\u00f3digo um pouco mais complexo que usando <code>delay()</code></li> <li>Requer vari\u00e1veis adicionais para rastrear os tempos</li> </ol>"},{"location":"aulas/iot/lab1/index.html#desafio-4-led-piscante-com-millis","title":"Desafio 4: LED Piscante com millis()","text":"<p>Objetivo: Recriar o Desafio 1 usando <code>millis()</code> em vez de <code>delay()</code>.</p>"},{"location":"aulas/iot/lab1/index.html#instrucoes_3","title":"Instru\u00e7\u00f5es:","text":"<ol> <li>Use o mesmo circuito do Desafio 1.</li> <li>Modifique seu c\u00f3digo para utilizar <code>millis()</code> para temporiza\u00e7\u00e3o n\u00e3o-bloqueante.</li> <li>Adicione as seguintes funcionalidades:</li> <li>LED 1 deve piscar a cada 500ms</li> <li>LED 2 deve piscar a cada 1000ms</li> <li>Os LEDs devem funcionar independentemente (em frequ\u00eancias diferentes)</li> </ol>"},{"location":"aulas/iot/lab1/index.html#dicas_3","title":"Dicas:","text":"<ul> <li>Crie vari\u00e1veis separadas para rastrear o tempo de cada LED</li> <li>N\u00e3o use <code>delay()</code> em nenhuma parte do c\u00f3digo</li> <li>Estruture seu c\u00f3digo de forma a permitir adicionar mais funcionalidades no futuro</li> </ul>"},{"location":"aulas/iot/lab1/index.html#desafio-5-sistema-multi-tarefa","title":"Desafio 5: Sistema Multi-tarefa","text":"<p>Objetivo: Criar um sistema que realize tr\u00eas tarefas simultaneamente, usando <code>millis()</code> para temporiza\u00e7\u00e3o.</p>"},{"location":"aulas/iot/lab1/index.html#instrucoes_4","title":"Instru\u00e7\u00f5es:","text":"<ol> <li>Monte um circuito com dois LEDs e um buzzer.</li> <li>Programe o sistema para realizar as seguintes tarefas:</li> <li>LED 1: Pisca a cada 1 segundo</li> <li>LED 2: Sequ\u00eancia espec\u00edfica (2 segundos aceso, 1 segundo apagado)</li> <li>Buzzer: Reproduz um bipe curto a cada 5 segundos</li> </ol>"},{"location":"aulas/iot/lab1/index.html#dicas_4","title":"Dicas:","text":"<ul> <li>Use <code>millis()</code> para toda a temporiza\u00e7\u00e3o</li> <li>Organize seu c\u00f3digo com fun\u00e7\u00f5es separadas para cada tarefa</li> <li>Pense em como estruturar seu programa para facilitar a adi\u00e7\u00e3o de novas tarefas no futuro</li> </ul>"},{"location":"aulas/iot/lab10/index.html","title":"Lab03","text":""},{"location":"aulas/iot/lab10/index.html#o-que-vamos-ver-neste-lab","title":"O que vamos ver neste lab?","text":"<ul> <li>Configurar um servidor web Flask na Raspberry Pi.</li> <li>Controlar um LED atrav\u00e9s de uma interface web.</li> <li>Compreender os conceitos b\u00e1sicos de programa\u00e7\u00e3o GPIO com a Raspberry Pi.</li> </ul>"},{"location":"aulas/iot/lab10/index.html#montando-um-webserver-em-flask","title":"Montando um Webserver em Flask","text":"<p>Vamos montar um webserver na raspberry pi com flask. A ideia deste exemplo \u00e9 controlar por um navegador web o status de um led entre ligado e desligado:</p> <p></p>"},{"location":"aulas/iot/lab10/index.html#instalando-o-flask-e-configurando-o-ambiente","title":"Instalando o Flask e configurando o ambiente","text":"<p>Warning</p> <p>Ligue a Raspberry PI, fa\u00e7a o acesso SSH e certifique que est\u00e1 com acesso a internet. </p> <p>No terminal da raspberry pi, atualize os reposit\u00f3rios:</p> <pre><code>sudo apt update\n</code></pre> <p>Instale os pacotes do flask</p> <pre><code>sudo apt-get install python3-flask\n</code></pre> <p>Agora vamos criar nossa arvore de projeto:</p> <p><pre><code>- webserver\n    - static\n        - index.css\n    - templates\n        - index.html\n    - app.py\n</code></pre> onde: </p> <ul> <li>webserver: diret\u00f3rio principal do projeto.<ul> <li>static: diret\u00f3rio para arquivos est\u00e1ticos.<ul> <li>index.css: arquivo de estilos CSS para a interface web.</li> </ul> </li> <li>templates: diret\u00f3rio para arquivos HTML.<ul> <li>index.html: arquivo HTML principal da aplica\u00e7\u00e3o.</li> </ul> </li> <li>app.py: script Python que cont\u00e9m a l\u00f3gica do servidor Flask e a programa\u00e7\u00e3o GPIO.</li> </ul> </li> </ul> <p>No terminal da Raspberry PI, crie a estrutura de diret\u00f3rios:</p> <pre><code>cd ~\nmkdir webserver\ncd webserver\nmkdir static templates\nls\n</code></pre> <p>Exercise</p> <p>O comando <code>ls</code> lista os arquivos e diret\u00f3rios no diret\u00f3rio atual. Leia a saida do terminal e verifique se os diretorios foram criados corretamente.</p>"},{"location":"aulas/iot/lab10/index.html#vamos-criar-o-apppy","title":"Vamos criar o <code>app.py</code>.","text":"<p>No terminal da Raspberry PI, digite:</p> <pre><code>nano app.py\n</code></pre> <p>Com o editor nano aberto, insira o seguinte c\u00f3digo:</p> <pre><code>'''\n    Servidor web com flask para controle de um LED.\n'''\nimport RPi.GPIO as GPIO\nfrom flask import Flask, render_template, request\n\napp = Flask(__name__)\n\nGPIO.setmode(GPIO.BCM)\nGPIO.setwarnings(False)\n\n# Define o pino GPIO para o LED\nledRed = 2\n\n# Inicializa o status do LED como desligado\nledRedSts = 0\n\n# Define o pino do LED como sa\u00edda\nGPIO.setup(ledRed, GPIO.OUT)   \n\n# Desliga o LED inicialmente\nGPIO.output(ledRed, GPIO.LOW)\n\n@app.route(\"/\")\ndef index():\n    # L\u00ea o status do GPIO\n    ledRedSts = GPIO.input(ledRed)\n\n    templateData = {\n            'ledRed'  : ledRedSts,\n        }\n    return render_template('index.html', **templateData)\n\n@app.route(\"/&lt;deviceName&gt;/&lt;action&gt;\")\ndef action(deviceName, action):\n    if deviceName == 'ledRed':\n        actuator = ledRed\n\n    if action == \"on\":\n        GPIO.output(actuator, GPIO.HIGH)\n    if action == \"off\":\n        GPIO.output(actuator, GPIO.LOW)\n\n    ledRedSts = GPIO.input(ledRed)\n\n    templateData = {\n            'ledRed'  : ledRedSts,\n    }\n    return render_template('index.html', **templateData)\n\nif __name__ == \"__main__\":\n   app.run(host='0.0.0.0', port=80, debug=True)\n</code></pre> <p>Shooooooowwwwww! N\u00e3o esque\u00e7a de Salvar e fechar o editor nano. Ctrl+X &gt;&gt; Y</p>"},{"location":"aulas/iot/lab10/index.html#vamos-criar-a-pagina-html-indexhtml","title":"Vamos criar a pagina html <code>index.html</code>.","text":"<p>No terminal da Raspberry Pi, navegue at\u00e9 o diret\u00f3rio <code>templates</code> e crie o arquivo <code>index.html</code>:</p> <pre><code>cd templates\nnano index.html\n</code></pre> <p>Insira o seguinte c\u00f3digo:</p> <pre><code>&lt;!DOCTYPE html&gt;\n   &lt;head&gt;\n      &lt;title&gt;Webserver&lt;/title&gt;\n      &lt;link rel=\"stylesheet\" href='../static/index.css'/&gt;\n   &lt;/head&gt;\n\n   &lt;body&gt;\n\n        &lt;h2&gt; Controle LED &lt;/h2&gt;\n\n        &lt;h3&gt; RED LED ==&gt;  {{ ledRed  }}  ==&gt;  \n            {% if  ledRed   == 1 %}\n                &lt;a href=\"/ledRed/off\"class=\"button\"&gt;TURN OFF&lt;/a&gt;\n            {% else %}\n                &lt;a href=\"/ledRed/on\" class=\"button\"&gt;TURN ON&lt;/a&gt; \n            {% endif %} \n        &lt;/h3&gt;\n\n   &lt;/body&gt;\n&lt;/html&gt;\n</code></pre> <p>Shooooooowwwwww! N\u00e3o esque\u00e7a de Salvar e fechar o editor nano. Ctrl+X &gt;&gt; Y</p>"},{"location":"aulas/iot/lab10/index.html#vamos-criar-o-arquivo-de-estilo-css-indexcss","title":"Vamos criar o arquivo de estilo css <code>index.css</code>.","text":"<p>No terminal da Raspberry Pi, navegue at\u00e9 o diret\u00f3rio <code>static</code> e crie o arquivo <code>index.css</code>:</p> <pre><code>cd ..\ncd static\nnano index.html\n</code></pre> <p>Com o editor nano aberto digite:</p> <pre><code>body {\n   background: blue;\n   color: yellow;\n}\n\n.button {\n  font: bold 15px Arial;\n  text-decoration: none;\n  background-color: #EEEEEE;\n  color: #333333;\n  padding: 2px 6px 2px 6px;\n  border-collapse: separete;\n  border-spacing: 0;\n  border-top: 1px solid #CCCCCC;\n  border-right: 1px solid #333333;\n  border-bottom: 1px solid #333333;\n  border-left: 1px solid #CCCCCC;\n}\n</code></pre> <p>Shooooooowwwwww! N\u00e3o esque\u00e7a de Salvar e fechar o editor nano. Ctrl+X &gt;&gt; Y</p>"},{"location":"aulas/iot/lab10/index.html#hora-de-testar","title":"Hora de testar","text":"<p>Vamos testar nosso webserver simples.</p> <p>No terminal da Raspberry Pi, retorne ao diret\u00f3rio principal e execute o script:</p> <pre><code>cd ..\nsudo python app.py\n</code></pre> <p>Deixe o Flask rodando na Raspberry Pi. Em um computador ou smartphone (que deve estar na mesma rede da Raspberry Pi), abra um navegador web e digite o IP da Raspberry Pi. Para encontrar o IP da Raspberry Pi, voc\u00ea pode usar o comando:</p> <pre><code>hostname -I\n</code></pre> <p>Warning</p> <p>O resultado esperado \u00e9 abrir uma p\u00e1gina web onde voc\u00ea pode controlar o LED.</p>"},{"location":"aulas/iot/lab10/index.html#desafios","title":"Desafios","text":"<p>Agora que j\u00e1 entendemos a estrutura b\u00e1sica do webserver em Python, fa\u00e7a os <code>Desafios</code> abaixo.</p> <p>Exercise</p> <p>Compreenda o c\u00f3digo app.py e monte o circuito adequado para conseguir visualizar o led acender e apagar.</p> <p>Exercise</p> <p>Altere o c\u00f3digo app.py e adicione mais 2 led e 2 bot\u00f5es (totalizando 3 leds, 2 bot\u00f5es), lembre-se de adaptar os arquivos HTML para exibir os status no frontend. </p> <p>Exercise</p> <p>Utilize seus conhecimentos web e proponha melhorias de UI/UX para o exerc\u00edcio anterior. Explore bibliotecas CSS como Bootstrap ou Materialize para aprimorar a interface.</p>"},{"location":"aulas/iot/lab11/index.html","title":"Index","text":""},{"location":"aulas/iot/lab2/index.html","title":"Lab02 - Serial","text":""},{"location":"aulas/iot/lab2/index.html#comunicacao-serial-no-wokwi","title":"Comunica\u00e7\u00e3o Serial no Wokwi","text":"<p>Ao final deste laborat\u00f3rio, voc\u00ea ser\u00e1 capaz de:</p> <ul> <li>Compreender os princ\u00edpios da comunica\u00e7\u00e3o serial</li> <li>Implementar comunica\u00e7\u00e3o entre Arduino e computador</li> <li>Enviar e receber dados via porta serial</li> <li>Processar comandos recebidos pela porta serial</li> </ul>"},{"location":"aulas/iot/lab2/index.html#fundamentos-da-comunicacao-serial","title":"Fundamentos da Comunica\u00e7\u00e3o Serial","text":""},{"location":"aulas/iot/lab2/index.html#o-que-e-comunicacao-serial","title":"O que \u00e9 Comunica\u00e7\u00e3o Serial?","text":"<p>A comunica\u00e7\u00e3o serial \u00e9 um protocolo de comunica\u00e7\u00e3o onde os dados s\u00e3o transmitidos um bit de cada vez, sequencialmente, atrav\u00e9s de um canal de comunica\u00e7\u00e3o. \u00c9 amplamente utilizada para comunica\u00e7\u00e3o entre microcontroladores e outros dispositivos devido \u00e0 sua simplicidade e confiabilidade.</p>"},{"location":"aulas/iot/lab2/index.html#parametros-da-comunicacao-serial","title":"Par\u00e2metros da Comunica\u00e7\u00e3o Serial","text":"<ul> <li>Baud Rate: Velocidade de transmiss\u00e3o em bits por segundo (bps)</li> <li>Bits de Dados: N\u00famero de bits em cada pacote (geralmente 8)</li> <li>Bits de Parada: Bits que indicam o fim de um pacote (geralmente 1)</li> <li>Paridade: M\u00e9todo de verifica\u00e7\u00e3o de erros (geralmente nenhum)</li> </ul>"},{"location":"aulas/iot/lab2/index.html#uart-no-arduino","title":"UART no Arduino","text":"<p>O Arduino possui um conversor USB-Serial integrado que permite a comunica\u00e7\u00e3o com o computador atrav\u00e9s da porta USB. </p> <p>Internamente, o microcontrolador utiliza o perif\u00e9rico UART (Universal Asynchronous Receiver/Transmitter) para implementar a comunica\u00e7\u00e3o serial.</p> <p></p>"},{"location":"aulas/iot/lab2/index.html#comunicacao-arduino-computador","title":"Comunica\u00e7\u00e3o Arduino-Computador","text":""},{"location":"aulas/iot/lab2/index.html#configuracao-basica","title":"Configura\u00e7\u00e3o B\u00e1sica","text":"<p>Para iniciar a comunica\u00e7\u00e3o serial no Arduino, utilizamos a fun\u00e7\u00e3o <code>Serial.begin()</code> no <code>setup()</code>, especificando o baud rate:</p> <pre><code>void setup() {\n  Serial.begin(9600); // Inicia comunica\u00e7\u00e3o serial a 9600 bps\n}\n</code></pre>"},{"location":"aulas/iot/lab2/index.html#enviando-dados-para-o-computador","title":"Enviando Dados para o Computador","text":"<p>Para enviar dados do Arduino para o computador, utilizamos as fun\u00e7\u00f5es:</p> <ul> <li><code>Serial.print()</code>: Envia dados sem quebra de linha</li> <li><code>Serial.println()</code>: Envia dados com quebra de linha no final</li> </ul> <pre><code>void loop() {\n  Serial.println(\"Ol\u00e1, Mundo!\"); // Envia a mensagem com quebra de linha\n  delay(1000); // Espera 1 segundo\n}\n</code></pre>"},{"location":"aulas/iot/lab2/index.html#recebendo-dados-do-computador","title":"Recebendo Dados do Computador","text":"<p>Para receber dados do computador no Arduino, utilizamos as fun\u00e7\u00f5es:</p> <ul> <li><code>Serial.available()</code>: Verifica se h\u00e1 dados dispon\u00edveis para leitura</li> <li><code>Serial.read()</code>: L\u00ea um byte da porta serial</li> <li><code>Serial.readString()</code>: L\u00ea uma string completa da porta serial</li> </ul> <pre><code>void loop() {\n  if (Serial.available() &gt; 0) { // Verifica se h\u00e1 dados dispon\u00edveis\n    String comando = Serial.readString(); // L\u00ea a string enviada\n    // Processa o comando recebido\n  }\n}\n</code></pre> <p>Vamos pra pr\u00e1tica!!!</p>"},{"location":"aulas/iot/lab2/index.html#configuracao-do-ambiente-no-wokwi","title":"Configura\u00e7\u00e3o do Ambiente no Wokwi","text":"<ul> <li> <p>Acesse o site Wokwi.</p> </li> <li> <p>Clique em Start New Project e selecione Arduino Uno.</p> </li> </ul>"},{"location":"aulas/iot/lab2/index.html#desafio-1-comunicacao-entre-arduino-e-computador","title":"Desafio 1: Comunica\u00e7\u00e3o entre Arduino e Computador","text":"<p>Vamos estabelecer uma comunica\u00e7\u00e3o b\u00e1sica entre o Arduino e o computador utilizando o Monitor Serial do Wokwi.</p> <ul> <li>Carregue o seguinte c\u00f3digo no simulador:</li> </ul> <pre><code>void setup() {\n  Serial.begin(9600); // Inicia a comunica\u00e7\u00e3o serial a 9600 bps\n}\n\nvoid loop() {\n  Serial.println(\"Ol\u00e1, Mundo!\"); // Envia a mensagem \"Ol\u00e1, Mundo!\" para o computador\n  delay(1000); // Espera 1 segundo\n}\n</code></pre> <ul> <li> <p>Observe o painel \"Serial Monitor\" que aparecer\u00e1 automaticamente</p> </li> <li> <p>Voc\u00ea deve ver a mensagem \"Ol\u00e1, Mundo!\" sendo exibida a cada segundo como a imagem a seguir.</p> </li> </ul> <p></p> <ul> <li>Modifique o c\u00f3digo para enviar seu nome e n\u00famero de matr\u00edcula</li> </ul>"},{"location":"aulas/iot/lab2/index.html#desafio-2-cronometro-virtual","title":"Desafio 2: Cron\u00f4metro virtual","text":"<p>Com base no que foi aboradado no lab passado, voc\u00ea dever\u00e1 criar um cron\u00f4metro virtual que exibe o tempo decorrido desde o in\u00edcio da simula\u00e7\u00e3o usando a fun\u00e7\u00e3o <code>millis()</code>.</p> <p>Instru\u00e7\u00f5es:</p> <ul> <li>Utilize a fun\u00e7\u00e3o <code>millis()</code> para exibir no Serial Monitor quanto tempo se passou desde que o Arduino come\u00e7ou a funcionar, em segundos.</li> <li> <p>Fa\u00e7a com que a mensagem seja atualizada inicialmente a cada 1 segundo.</p> </li> <li> <p>Agora com a base do c\u00f3digo funcionando ok, modifique seu c\u00f3digo para que o intervalo entre as mensagens seja alterado <code>dinamicamente</code>, da seguinte forma:</p> </li> <li> <p>1 segundo durante os primeiros 10 segundos.</p> </li> <li>2 segundos entre 10 e 20 segundos.</li> <li>5 segundos ap\u00f3s 20 segundos.</li> </ul> <p>\u00c9 esperado como resultado que seja exibido no serial monitor:</p> <pre><code>Tempo decorrido: 1 segundos\nTempo decorrido: 2 segundos\n//assim at\u00e9 10...\nTempo decorrido: 10 segundos\nTempo decorrido: 12 segundos\n//assim at\u00e9 20...\nTempo decorrido: 20 segundos\nTempo decorrido: 25 segundos\nTempo decorrido: 30 segundos\n//assim acima de 20...\n</code></pre>"},{"location":"aulas/iot/lab2/index.html#desafio-3-recebendo-dados-do-computador","title":"Desafio 3: Recebendo Dados do Computador","text":"<p>Vamos criar uma interface para controlar um LED atrav\u00e9s de comandos enviados pelo Serial Monitor.</p> <p>Carregue o seguinte c\u00f3digo no seu Arduino:</p> <pre><code>String comando = \"\"; // Vari\u00e1vel para armazenar o comando recebido\nconst int ledPin = 10;\n\nvoid setup() {\n  Serial.begin(9600);\n  pinMode(ledPin, OUTPUT); // Define o pino como sa\u00edda\n  Serial.println(\"Digite LIGAR ou DESLIGAR para controlar o LED\");\n}\n\nvoid loop() {\n  if (Serial.available()) { // Verifica se h\u00e1 dados dispon\u00edveis para leitura\n    comando = Serial.readStringUntil('\\n'); // L\u00ea a string at\u00e9 encontrar uma quebra de linha\n    comando.trim(); // Remove espa\u00e7os e quebras de linha extras\n\n    if (comando.equalsIgnoreCase(\"LIGAR\")) {\n      digitalWrite(ledPin, HIGH); // Acende o LED no pino\n      Serial.println(\"LED Ligado!\");\n    } else if (comando.equalsIgnoreCase(\"DESLIGAR\")) {\n      digitalWrite(ledPin, LOW); // Apaga o LED no pino\n      Serial.println(\"LED Desligado!\");\n    } else {\n      Serial.println(\"Comando n\u00e3o reconhecido. Use LIGAR ou DESLIGAR\");\n    }\n  }\n}\n</code></pre>"},{"location":"aulas/iot/lab2/index.html#montagem-no-wokwi","title":"Montagem no Wokwi:","text":"<ul> <li> <p>Adicione um LED ao pino que est\u00e1 configurado no c\u00f3digo (da mesma forma que fizemos no labs anteriores).</p> </li> <li> <p>Inicie a simula\u00e7\u00e3o, digite <code>LIGAR</code> e pressione Enter.</p> </li> <li> <p>O LED do Arduino deve acender.</p> </li> <li> <p>Digite <code>DESLIGAR</code> e pressione Enter para apagar o LED.</p> </li> </ul> <p></p> <p>Warning</p> <p>A comunica\u00e7\u00e3o serial \u00e9 sens\u00edvel a mai\u00fasculas e min\u00fasculas. Certifique-se de digitar os comandos exatamente como est\u00e3o no c\u00f3digo.</p> <p>voc\u00ea pode usar o m\u00e9todo <code>equalsIgnoreCase()</code> para torna o c\u00f3digo mais robusto, aceitando varia\u00e7\u00f5es como \"ligar\", \"Ligar\" ou \"LIgaR\".</p>"},{"location":"aulas/iot/lab2/index.html#desafio-4-cronometro-dinamico","title":"Desafio 4: Cron\u00f4metro Din\u00e2mico","text":"<p>Com base nos desafio 2 e desafio 3, crie um <code>cron\u00f4metro inteligente</code>. </p> <p>O intervalo das mensagens n\u00e3o ser\u00e1 fixo: ele dever\u00e1 mudar conforme comandos enviados pelo usu\u00e1rio atrav\u00e9s do Monitor Serial.</p>"},{"location":"aulas/iot/lab2/index.html#requisitos-do-desafio","title":"Requisitos do Desafio:","text":"<ul> <li> <p>Crie um cron\u00f4metro que exiba, a cada intervalo, o tempo decorrido desde o in\u00edcio da execu\u00e7\u00e3o (em segundos).</p> </li> <li> <p>Inicialmente, o intervalo entre mensagens deve ser de 1 segundo.</p> </li> <li> <p>Atrav\u00e9s do Monitor Serial, permita que o usu\u00e1rio altere dinamicamente o intervalo entre as mensagens digitando comandos como:</p> </li> <li> <p>intervalo 500 (define o intervalo para 500 ms)</p> </li> <li> <p>intervalo 2000 (define o intervalo para 2000 ms)</p> </li> <li> <p>Implemente tamb\u00e9m comandos especiais:</p> </li> <li> <p><code>pausar</code> para interromper temporariamente a exibi\u00e7\u00e3o das mensagens.</p> </li> <li><code>continuar</code> para retomar a contagem.</li> </ul> <p>\u00c9 esperado como resultado que seja exibido no serial monitor:</p> <pre><code>Tempo decorrido: 1 segundos\nTempo decorrido: 2 segundos\nTempo decorrido: 3 segundos\n// Usu\u00e1rio digita: intervalo 3000\nIntervalo alterado para 3000 ms.\nTempo decorrido: 6 segundos\nTempo decorrido: 9 segundos\n// Usu\u00e1rio digita: pausar\nCron\u00f4metro pausado.\n// Usu\u00e1rio digita: continuar\nCron\u00f4metro retomado.\nTempo decorrido: 12 segundos\nTempo decorrido: 15 segundos\n// Usu\u00e1rio digita: intervalo 2000\nIntervalo alterado para 2000 ms.\nTempo decorrido: 17 segundos\nTempo decorrido: 19 segundos\n</code></pre>"},{"location":"aulas/iot/lab3/index.html","title":"Lab03 - Bot\u00e3o","text":""},{"location":"aulas/iot/lab3/index.html#entradas-digitais","title":"Entradas Digitais","text":""},{"location":"aulas/iot/lab3/index.html#conceitos-importantes","title":"Conceitos Importantes","text":""},{"location":"aulas/iot/lab3/index.html#entradas-digitais_1","title":"Entradas Digitais","text":"<p>Uma entrada digital no Arduino pode ler apenas dois estados: HIGH (n\u00edvel alto, 5V) ou LOW (n\u00edvel baixo, 0V). \u00c9 ideal para componentes que possuem apenas dois estados, como bot\u00f5es, chaves e sensores digitais.</p>"},{"location":"aulas/iot/lab3/index.html#pull-up-e-pull-down","title":"Pull-up e Pull-down","text":"<p>Resistores de pull-up e pull-down s\u00e3o utilizados para garantir um estado l\u00f3gico definido quando um bot\u00e3o n\u00e3o est\u00e1 pressionado, evitando estados flutuantes:</p> <ul> <li>Pull-up: Mant\u00e9m o pino em n\u00edvel alto (HIGH) quando o bot\u00e3o n\u00e3o est\u00e1 pressionado</li> <li>Pull-down: Mant\u00e9m o pino em n\u00edvel baixo (LOW) quando o bot\u00e3o n\u00e3o est\u00e1 pressionado</li> </ul> <p>O Arduino possui resistores pull-up internos que podem ser ativados com <code>pinMode(pino, INPUT_PULLUP)</code>.</p>"},{"location":"aulas/iot/lab3/index.html#debounce","title":"Debounce","text":"<p>Bot\u00f5es mec\u00e2nicos frequentemente geram m\u00faltiplas transi\u00e7\u00f5es (ru\u00eddos) quando pressionados ou soltos. O debounce \u00e9 uma t\u00e9cnica para filtrar essas transi\u00e7\u00f5es e garantir leituras est\u00e1veis.</p>"},{"location":"aulas/iot/lab3/index.html#desafio-1-controle-de-led-com-botao","title":"Desafio 1: Controle de LED com Bot\u00e3o","text":"<p>Objetivo: Utilizar um bot\u00e3o para controlar um LED, implementando a t\u00e9cnica de debounce.</p>"},{"location":"aulas/iot/lab3/index.html#instrucoes","title":"Instru\u00e7\u00f5es:","text":"<ol> <li> <p>Monte o circuito conforme mostrado na imagem abaixo:    </p> </li> <li> <p>Conecte:</p> </li> <li>Bot\u00e3o ao pino digital 2</li> <li> <p>LED ao pino digital 13</p> </li> <li> <p>Implemente um c\u00f3digo que:</p> </li> <li>Quando o bot\u00e3o for pressionado e solto, o LED mude de estado (ligado para desligado ou vice-versa)</li> <li>Quando o bot\u00e3o for pressionado e mantido, o LED mude de estado apenas uma vez</li> </ol>"},{"location":"aulas/iot/lab3/index.html#codigo-base","title":"C\u00f3digo Base:","text":"<pre><code>// const \u00e9 uma constante. logo o valor n\u00e3o muda\nconst int buttonPin = 2;\nconst int ledPin = 13;\n// cria uma vari\u00e1vel\nint buttonState = 0;\n\nvoid setup() {\n    // configura o LED como sa\u00edda:\n    pinMode(ledPin, OUTPUT);\n    // configura o bot\u00e3o como entrada com pull-up interno:\n    pinMode(buttonPin, INPUT_PULLUP);\n}\n\nvoid loop() {\n    // L\u00ea o estado do bot\u00e3o:\n    buttonState = digitalRead(buttonPin);\n    // se o bot\u00e3o estiver pressionado (n\u00edvel LOW devido ao pull-up)\n    if (buttonState == LOW) {\n        // liga o led\n        digitalWrite(ledPin, HIGH);\n    } else {\n        // apaga o led\n        digitalWrite(ledPin, LOW);\n        delay(1000);\n    }\n}\n</code></pre>"},{"location":"aulas/iot/lab3/index.html#etapa-1-analise-do-codigo-base","title":"Etapa 1: An\u00e1lise do C\u00f3digo Base","text":"<p>Execute o c\u00f3digo fornecido e observe seu comportamento, respondendo: - O que acontece quando voc\u00ea pressiona e solta o bot\u00e3o? - O que acontece quando pressiona e mant\u00e9m o bot\u00e3o pressionado?</p> <p>Aten\u00e7\u00e3o: Voc\u00ea vai notar que o funcionamento nem sempre \u00e9 preciso. \u00c0s vezes o LED parece n\u00e3o responder corretamente ao bot\u00e3o. Isso ocorre devido ao problema de \"bounce\" (trepida\u00e7\u00e3o) dos bot\u00f5es mec\u00e2nicos.</p>"},{"location":"aulas/iot/lab3/index.html#etapa-2-implementacao-de-debounce","title":"Etapa 2: Implementa\u00e7\u00e3o de Debounce","text":"<p>Para resolver o problema de trepida\u00e7\u00e3o, vamos implementar a t\u00e9cnica de debounce utilizando a fun\u00e7\u00e3o <code>millis()</code>:</p> <pre><code>const int buttonPin = 2;   // Pino do bot\u00e3o\nconst int ledPin = 13;     // Pino do LED\n\nint ledState = LOW;        // Estado atual do LED\nint lastButtonState = HIGH; // \u00daltimo estado do bot\u00e3o\nint buttonState;           // Estado atual do bot\u00e3o\n\nunsigned long lastDebounceTime = 0;  // \u00daltimo tempo de debounce\nunsigned long debounceDelay = 50;    // Tempo de debounce de 50ms\n\nvoid setup() {\n  pinMode(ledPin, OUTPUT);\n  pinMode(buttonPin, INPUT_PULLUP);\n  digitalWrite(ledPin, ledState);\n}\n\nvoid loop() {\n  // Leitura do bot\u00e3o\n  int reading = digitalRead(buttonPin);\n\n  // Se o estado mudou, reinicia o timer de debounce\n  if (reading != lastButtonState) {\n    lastDebounceTime = millis();\n  }\n\n  // Verifica se passou tempo suficiente desde a \u00faltima mudan\u00e7a\n  if ((millis() - lastDebounceTime) &gt; debounceDelay) {\n    // Se o estado lido for diferente do estado atual do bot\u00e3o\n    if (reading != buttonState) {\n      buttonState = reading;\n\n      // Se o bot\u00e3o foi pressionado (LOW devido ao pull-up)\n      if (buttonState == LOW) {\n        // Inverte o estado do LED\n        ledState = !ledState;\n      }\n    }\n  }\n\n  // Atualiza o LED de acordo com o estado\n  digitalWrite(ledPin, ledState);\n\n  // Salva o estado lido para compara\u00e7\u00e3o na pr\u00f3xima itera\u00e7\u00e3o\n  lastButtonState = reading;\n}\n</code></pre>"},{"location":"aulas/iot/lab3/index.html#dicas","title":"Dicas:","text":"<ul> <li>Entenda o fluxo do c\u00f3digo e o papel de cada vari\u00e1vel</li> <li>Observe como a fun\u00e7\u00e3o <code>millis()</code> \u00e9 usada para verificar o tempo decorrido</li> <li>Note que o LED s\u00f3 muda de estado quando um bot\u00e3o \u00e9 considerado est\u00e1vel por pelo menos 50ms</li> </ul>"},{"location":"aulas/iot/lab3/index.html#desafio-2-comunicacao-serial-para-monitoramento","title":"Desafio 2: Comunica\u00e7\u00e3o Serial para Monitoramento","text":"<p>Objetivo: Implementar comunica\u00e7\u00e3o serial para monitorar o estado do bot\u00e3o e do LED.</p>"},{"location":"aulas/iot/lab3/index.html#instrucoes_1","title":"Instru\u00e7\u00f5es:","text":"<ol> <li>Use o mesmo circuito do Desafio 1.</li> <li>Modifique o c\u00f3digo para exibir no Monitor Serial:</li> <li>Estado atual do bot\u00e3o (Pressionado/Solto)</li> <li>Estado atual do LED (Ligado/Desligado)</li> <li>Timestamp em milissegundos</li> <li>Uma mensagem quando o estado do LED mudar</li> </ol>"},{"location":"aulas/iot/lab3/index.html#exemplo-de-saida-esperada","title":"Exemplo de Sa\u00edda Esperada:","text":"<pre><code>[1500] Bot\u00e3o: Solto | LED: Desligado\n[2100] Bot\u00e3o: Pressionado | LED: Desligado\n[2160] Bot\u00e3o: Pressionado | LED: Ligado - LED mudou de estado!\n[2700] Bot\u00e3o: Solto | LED: Ligado\n</code></pre>"},{"location":"aulas/iot/lab3/index.html#dicas_1","title":"Dicas:","text":"<ol> <li> <p>Inicialize a comunica\u00e7\u00e3o serial no <code>setup()</code>:    <pre><code>void setup() {\n  Serial.begin(9600);  // Inicia comunica\u00e7\u00e3o serial a 9600 bps\n  // ... resto do c\u00f3digo\n}\n</code></pre></p> </li> <li> <p>Use <code>Serial.print()</code> para enviar dados sem quebra de linha e <code>Serial.println()</code> para enviar com quebra de linha.</p> </li> <li> <p>Construa mensagens informativas:    <pre><code>Serial.print(\"[\");\nSerial.print(millis());\nSerial.print(\"] Bot\u00e3o: \");\nSerial.print(buttonState == LOW ? \"Pressionado\" : \"Solto\");\nSerial.print(\" | LED: \");\nSerial.println(ledState == HIGH ? \"Ligado\" : \"Desligado\");\n</code></pre></p> </li> <li> <p>Acesse o Monitor Serial atrav\u00e9s do menu \"Ferramentas &gt; Monitor Serial\" ou pressionando Ctrl+Shift+M.</p> </li> </ol>"},{"location":"aulas/iot/lab4/index.html","title":"Lab04 - PWM e Analog","text":""},{"location":"aulas/iot/lab4/index.html#entradas-analogicas-e-controle-pwm","title":"Entradas Anal\u00f3gicas e Controle PWM","text":""},{"location":"aulas/iot/lab4/index.html#conceitos-fundamentais","title":"Conceitos Fundamentais","text":""},{"location":"aulas/iot/lab4/index.html#entradas-analogicas","title":"Entradas Anal\u00f3gicas","text":"<p>Enquanto entradas digitais leem apenas dois estados (HIGH ou LOW), as entradas anal\u00f3gicas podem detectar uma faixa cont\u00ednua de valores de tens\u00e3o, convertendo-os em valores digitais entre 0 e 1023 (resolu\u00e7\u00e3o de 10 bits).</p> <ul> <li>Arduino Uno e similares: 6 pinos de entrada anal\u00f3gica (A0 a A5)</li> <li>Tens\u00e3o de refer\u00eancia padr\u00e3o: 5V (pode ser alterada)</li> <li>Aplica\u00e7\u00f5es t\u00edpicas: Leitura de sensores de temperatura, luz, press\u00e3o, dist\u00e2ncia, etc.</li> </ul>"},{"location":"aulas/iot/lab4/index.html#funcao-analogread","title":"Fun\u00e7\u00e3o analogRead()","text":"<pre><code>int valorSensor = analogRead(A0); // L\u00ea valor entre 0 e 1023\n</code></pre>"},{"location":"aulas/iot/lab4/index.html#saidas-pwm-pulse-width-modulation","title":"Sa\u00eddas PWM (Pulse Width Modulation)","text":"<p>O PWM \u00e9 uma t\u00e9cnica que simula uma sa\u00edda anal\u00f3gica atrav\u00e9s de pulsos digitais com largura vari\u00e1vel. Quanto maior o ciclo de trabalho (duty cycle), maior a m\u00e9dia da tens\u00e3o de sa\u00edda.</p> <ul> <li>Arduino Uno: 6 pinos com capacidade PWM (geralmente marcados com ~)</li> <li>Resolu\u00e7\u00e3o: 8 bits (valores entre 0 e 255)</li> <li>Aplica\u00e7\u00f5es t\u00edpicas: Controle de intensidade de LEDs, velocidade de motores, tons em buzzers</li> </ul>"},{"location":"aulas/iot/lab4/index.html#funcao-analogwrite","title":"Fun\u00e7\u00e3o analogWrite()","text":"<pre><code>analogWrite(pinoPWM, valor); // valor entre 0 (0%) e 255 (100%)\n</code></pre>"},{"location":"aulas/iot/lab4/index.html#funcao-map","title":"Fun\u00e7\u00e3o map()","text":"<p>Esta fun\u00e7\u00e3o \u00e9 extremamente \u00fatil para converter valores entre diferentes intervalos:</p> <pre><code>// Converte um valor de um intervalo para outro\nint valorConvertido = map(valor, deMenor, deMaior, paraMenor, paraMaior);\n\n// Exemplo: converter valor do potenci\u00f4metro (0-1023) para PWM (0-255)\nint brilho = map(analogRead(A0), 0, 1023, 0, 255);\n</code></pre>"},{"location":"aulas/iot/lab4/index.html#desafio-1-controle-de-brilho-com-potenciometro","title":"Desafio 1: Controle de Brilho com Potenci\u00f4metro","text":"<p>Objetivo: Usar um potenci\u00f4metro para controlar o brilho de um LED atrav\u00e9s de PWM.</p>"},{"location":"aulas/iot/lab4/index.html#instrucoes","title":"Instru\u00e7\u00f5es:","text":"<ol> <li> <p>Monte o circuito conforme mostrado na imagem abaixo:    </p> </li> <li> <p>Conecte:</p> </li> <li>Potenci\u00f4metro ao pino anal\u00f3gico A0</li> <li> <p>LED ao pino digital 3 (com capacidade PWM)</p> </li> <li> <p>Implemente um c\u00f3digo que:</p> </li> <li>Leia o valor do potenci\u00f4metro (0-1023)</li> <li>Converta esse valor para a escala PWM (0-255)</li> <li>Aplique o valor convertido para controlar o brilho do LED</li> </ol>"},{"location":"aulas/iot/lab4/index.html#codigo-base","title":"C\u00f3digo Base:","text":"<pre><code>const int potPin = A0;    // Pino do potenci\u00f4metro\nconst int ledPin = 3;     // Pino PWM do LED\n\nint potValue = 0;         // Valor lido do potenci\u00f4metro\nint ledBrightness = 0;    // Valor de brilho do LED\n\nvoid setup() {\n  pinMode(ledPin, OUTPUT);  // Configura o pino do LED como sa\u00edda\n  Serial.begin(9600);       // Inicia comunica\u00e7\u00e3o serial\n}\n\nvoid loop() {\n  // L\u00ea o valor do potenci\u00f4metro\n  potValue = analogRead(potPin);\n\n  // Converte o valor do potenci\u00f4metro (0-1023) para a escala PWM (0-255)\n  ledBrightness = map(potValue, 0, 1023, 0, 255);\n\n  // Define o brilho do LED\n  analogWrite(ledPin, ledBrightness);\n\n  // Exibe os valores no monitor serial\n  Serial.print(\"Potenci\u00f4metro: \");\n  Serial.print(potValue);\n  Serial.print(\" | Brilho LED: \");\n  Serial.println(ledBrightness);\n\n  // Pequeno atraso para estabilizar as leituras\n  delay(100);\n}\n</code></pre>"},{"location":"aulas/iot/lab4/index.html#perguntas-para-reflexao","title":"Perguntas para reflex\u00e3o:","text":"<ol> <li>O que acontece quando voc\u00ea gira o potenci\u00f4metro lentamente? E rapidamente?</li> <li>Como o valor do potenci\u00f4metro \u00e9 convertido para controlar o LED?</li> <li>Qual a diferen\u00e7a entre usar <code>digitalWrite()</code> e <code>analogWrite()</code> para controlar um LED?</li> </ol>"},{"location":"aulas/iot/lab4/index.html#desafio-2-sensor-de-luz-ldr-com-indicador-visual","title":"Desafio 2: Sensor de Luz (LDR) com Indicador Visual","text":"<p>Objetivo: Criar um sistema que l\u00ea a intensidade de luz ambiente e a representa visualmente com um LED.</p>"},{"location":"aulas/iot/lab4/index.html#instrucoes_1","title":"Instru\u00e7\u00f5es:","text":"<ol> <li> <p>Monte o circuito conforme mostrado na imagem abaixo:    </p> </li> <li> <p>Conecte:</p> </li> <li>LDR e resistor de 10k\u03a9 em divisor de tens\u00e3o ao pino A5</li> <li> <p>LED ao pino digital 10 (com capacidade PWM)</p> </li> <li> <p>Implemente um c\u00f3digo que:</p> </li> <li>Leia o valor do sensor de luz (LDR)</li> <li>Quanto mais escuro o ambiente, mais brilhante o LED deve ficar</li> <li>Quanto mais claro o ambiente, menos brilhante o LED deve ficar</li> </ol>"},{"location":"aulas/iot/lab4/index.html#dicas","title":"Dicas:","text":"<ul> <li>O LDR (Light Dependent Resistor) diminui sua resist\u00eancia quando exposto \u00e0 luz</li> <li>Use a fun\u00e7\u00e3o <code>map()</code> de forma inversa para o LED brilhar mais no escuro</li> <li>Adicione calibra\u00e7\u00e3o para adaptar o sistema a diferentes condi\u00e7\u00f5es de ilumina\u00e7\u00e3o</li> </ul>"},{"location":"aulas/iot/lab4/index.html#codigo-exemplo","title":"C\u00f3digo Exemplo:","text":"<pre><code>const int ldrPin = A5;      // Pino do LDR\nconst int ledPin = 10;      // Pino PWM do LED\n\nint ldrValue = 0;           // Valor lido do LDR\nint ledBrightness = 0;      // Valor de brilho do LED\nint minLight = 1023;        // Valor m\u00ednimo de luz (ajustado na calibra\u00e7\u00e3o)\nint maxLight = 0;           // Valor m\u00e1ximo de luz (ajustado na calibra\u00e7\u00e3o)\nbool calibrated = false;    // Indica se a calibra\u00e7\u00e3o foi realizada\n\nvoid setup() {\n  pinMode(ledPin, OUTPUT);  // Configura o pino do LED como sa\u00edda\n  Serial.begin(9600);       // Inicia comunica\u00e7\u00e3o serial\n\n  Serial.println(\"Sensor de luz com indicador visual\");\n  Serial.println(\"Calibrando o sensor por 5 segundos...\");\n\n  // Calibra\u00e7\u00e3o do sensor de luz durante 5 segundos\n  unsigned long startTime = millis();\n  while (millis() - startTime &lt; 5000) {\n    ldrValue = analogRead(ldrPin);\n\n    // Atualiza os valores m\u00ednimo e m\u00e1ximo\n    if (ldrValue &lt; minLight) minLight = ldrValue;\n    if (ldrValue &gt; maxLight) maxLight = ldrValue;\n\n    delay(100);\n  }\n\n  calibrated = true;\n  Serial.print(\"Calibra\u00e7\u00e3o conclu\u00edda! Faixa: \");\n  Serial.print(minLight);\n  Serial.print(\" a \");\n  Serial.println(maxLight);\n}\n\nvoid loop() {\n  // L\u00ea o valor do sensor de luz\n  ldrValue = analogRead(ldrPin);\n\n  // Se calibrado, mapeia o valor do LDR para o brilho do LED\n  if (calibrated) {\n    // Inverte o mapeamento para o LED brilhar mais no escuro\n    ledBrightness = map(ldrValue, minLight, maxLight, 255, 0);\n\n    // Restringe o valor entre 0 e 255\n    ledBrightness = constrain(ledBrightness, 0, 255);\n  }\n  else {\n    ledBrightness = 0;  // Se n\u00e3o calibrado, mant\u00e9m o LED desligado\n  }\n\n  // Define o brilho do LED\n  analogWrite(ledPin, ledBrightness);\n\n  // Exibe os valores no monitor serial\n  Serial.print(\"Luz ambiente: \");\n  Serial.print(ldrValue);\n  Serial.print(\" | Brilho LED: \");\n  Serial.println(ledBrightness);\n\n  delay(100);\n}\n</code></pre>"},{"location":"aulas/iot/lab4/index.html#desafio-3-controle-proporcional-de-temporizacao","title":"Desafio 3: Controle Proporcional de Temporiza\u00e7\u00e3o","text":"<p>Objetivo: Implementar um sistema onde o potenci\u00f4metro controla a velocidade de intermit\u00eancia de um LED, usando <code>millis()</code> para temporiza\u00e7\u00e3o n\u00e3o-bloqueante.</p>"},{"location":"aulas/iot/lab4/index.html#instrucoes_2","title":"Instru\u00e7\u00f5es:","text":"<ol> <li>Use o mesmo circuito do Desafio 1.</li> <li>Implemente um c\u00f3digo que:</li> <li>Leia o valor do potenci\u00f4metro</li> <li>Converta esse valor para um intervalo de tempo (100ms a 2000ms)</li> <li>Fa\u00e7a o LED piscar nesse intervalo, sem usar <code>delay()</code></li> <li>Mostre no monitor serial o valor do potenci\u00f4metro e o intervalo calculado</li> </ol>"},{"location":"aulas/iot/lab4/index.html#desafio-4-theremin-optico","title":"Desafio 4: Theremin \u00d3ptico","text":"<p>Objetivo: Criar um instrumento musical simples controlado pela luz, onde a intensidade de luz controla a frequ\u00eancia de um som em um buzzer.</p>"},{"location":"aulas/iot/lab4/index.html#instrucoes_3","title":"Instru\u00e7\u00f5es:","text":"<ol> <li>Monte um circuito com:</li> <li>LDR conectado ao pino A0</li> <li> <p>Buzzer conectado ao pino 8</p> </li> <li> <p>Implemente um c\u00f3digo que:</p> </li> <li>Leia o valor do LDR</li> <li>Converta para uma frequ\u00eancia aud\u00edvel (100Hz a 2000Hz)</li> <li>Gere um tom no buzzer correspondente \u00e0 leitura do LDR</li> <li>Permita \"tocar\" o instrumento movendo a m\u00e3o sobre o sensor</li> </ol>"},{"location":"aulas/iot/lab4/index.html#dicas_1","title":"Dicas:","text":"<ul> <li>Use a fun\u00e7\u00e3o <code>tone(pin, frequency)</code> para gerar sons no buzzer</li> <li>Adicione bot\u00f5es para ligar/desligar o som ou mudar \"escalas\"</li> <li>Experimente adicionar um segundo sensor para controlar volume ou outra caracter\u00edstica do som</li> </ul>"},{"location":"aulas/iot/lab4/index.html#material-de-referencia","title":"Material de Refer\u00eancia","text":"<ul> <li>Documenta\u00e7\u00e3o oficial do Arduino sobre analogRead()</li> <li>Documenta\u00e7\u00e3o oficial do Arduino sobre analogWrite()</li> <li>Tutorial sobre PWM no Arduino</li> </ul>"},{"location":"aulas/iot/lab4-old/index.html","title":"Index","text":""},{"location":"aulas/iot/lab4-old/index.html#memoria-eeprom","title":"Memoria EEPROM","text":"<p>A mem\u00f3ria EEPROM (Electrically Erasable Programmable Read-Only Memory) \u00e9 uma mem\u00f3ria n\u00e3o vol\u00e1til, o que significa que os dados armazenados nela persistem mesmo depois de desligar o Arduino. \u00c9 \u00fatil para armazenar pequenas quantidades de dados que precisam ser preservados entre reinicializa\u00e7\u00f5es, como configura\u00e7\u00f5es ou contadores.</p> <p>Warning</p> <p>Essa memoria n\u00e3o \u00e9 infinita, pelo contrario! a memoria EEPROM \u00e9 bem pequena, no caso do Arduino UNO \u00e9 de apenas 1KB (1000 Bytes) tenha isso em mente para n\u00e3o ultrapassar esse valor.</p>"},{"location":"aulas/iot/lab4-old/index.html#desafio-1-escrevendo-e-lendo-dados-na-eeprom","title":"Desafio 1: Escrevendo e Lendo Dados na EEPROM","text":"<p>Neste desafio, vamos aprender a escrever e ler dados na mem\u00f3ria EEPROM. Vamos escrever apenas 1 unico valor inteiro.</p> <p>Monte um circuito com um bot\u00e3o no pino 2 e carregue o seguinte c\u00f3digo no seu Arduino:</p> <pre><code>#include &lt;EEPROM.h&gt;\n\nconst int buttonPin = 2; // Pino do bot\u00e3o\nint lastButtonState = HIGH;\nint buttonState; \n\nunsigned long lastDebounceTime = 0;\nunsigned long debounceDelay = 50;    \n\nvoid setup() {\n  Serial.begin(9600);\n  pinMode(buttonPin, INPUT_PULLUP); \n\n  EEPROM.write(0, 123); // Escreve o valor 123 na posi\u00e7\u00e3o 0 da EEPROM\n  delay(10); // Pequeno delay para garantir a escrita na memoria\n}\n\nvoid loop() {\n  int reading = digitalRead(buttonPin); // L\u00ea o estado do bot\u00e3o\n  if (reading != lastButtonState) {\n    lastDebounceTime = millis();\n  }\n  if ((millis() - lastDebounceTime) &gt; debounceDelay) {\n    if (reading != buttonState) {\n      buttonState = reading;\n\n      // Se o bot\u00e3o estiver pressionado (estado LOW devido ao pull-up)\n      if (buttonState == LOW) {\n\n        int valor = EEPROM.read(0); // L\u00ea o valor na posi\u00e7\u00e3o 0 da EEPROM\n        Serial.println(valor); // Imprime o valor\n      }\n    }\n  }\n\n  lastButtonState = reading; // Atualiza o estado anterior do bot\u00e3o\n}\n</code></pre>"},{"location":"aulas/iot/lab4-old/index.html#desafio-2-armazenando-e-recuperando-strings","title":"Desafio 2: Armazenando e Recuperando Strings","text":"<p>Agora altere o c\u00f3digo para escrever e ler <code>Strings</code>. </p> <p>Altre o c\u00f3digo do desafio 1 para:</p> <pre><code>- Salve na memoria EEPROM a frase: `Let's Rock the Future` \n- Recuperar o valor salvo na memoria quando apertar o bot\u00e3o.\n</code></pre> <p>Tip</p> <ul> <li>Defina a frase como do tipo String. <code>String frase = \"sua frase aqui\"</code></li> <li>Conhe\u00e7a um pouco mais do objeto String lendo a documenta\u00e7\u00e3o aqui</li> <li>Para salvar na memoria EEPROM temos que rodar um <code>la\u00e7o for</code> para salvar caractere por caractere. <code>for (int i = 0; i &lt; frase.length(); i++){}</code></li> <li>Dentro do la\u00e7o for, defina a posi\u00e7\u00e3o inicial da memoria e salve cada indice do frase <code>EEPROM.write(startPos + i, frase[i]);</code></li> <li>Fa\u00e7a a mesma coisa para recuperar os dados.     </li> </ul>"},{"location":"aulas/iot/lab4-old/index.html#desafio-3-exiba-os-resultados-em-um-display-lcd","title":"Desafio 3: Exiba os resultados em um display LCD","text":"<p>Agora vamos exibir o valor da memoria EEPROM em um display LCD. Para isso, busque por refer\u00eancias na internet de como realizar a liga\u00e7\u00e3o e elaborar o circuito.  </p> <p>Tip</p> <p>execute os codigo exemplo que encontrar na internet para verificar o funcionamento do circuito antes de escrever seu proprio c\u00f3digo</p>"},{"location":"aulas/iot/lab5/index.html","title":"Lab01","text":"<p>Neste Laborat\u00f3rio vamos trabalhar com Node-red e conhecer o protocolo MQTT.</p> <ul> <li>arquivo pdf do laborat\u00f3rio: laborat\u00f3rio5</li> </ul>"},{"location":"aulas/iot/lab5/index.html#introducao-a-iot","title":"Introdu\u00e7\u00e3o \u00e0 IoT","text":""},{"location":"aulas/iot/lab5/index.html#agenda","title":"Agenda","text":"<ul> <li>Instala\u00e7\u00e3o do Node-RED e primeiros testes</li> <li>Montagem de um dashboard no Node-RED</li> <li>Cria\u00e7\u00e3o de um end-point</li> <li>Apresenta\u00e7\u00e3o do MQTT</li> </ul>"},{"location":"aulas/iot/lab5/index.html#conectando-dispositivos-a-aplicacoes","title":"Conectando dispositivos a aplica\u00e7\u00f5es","text":"<p>Agora que j\u00e1 exploramos as funcionalidades do Arduino e sua capacidade de conectar sensores e atuadores, vamos prosseguir conectando o Arduino a aplica\u00e7\u00f5es que fazem uso desse dispositivo.</p> <p>Em primeiro lugar, vamos relembrar a arquitetura que usaremos para os dispositivos de IoT se conectarem \u00e0s suas aplica\u00e7\u00f5es.</p>"},{"location":"aulas/iot/lab5/index.html#arquitetura-basica-de-iot","title":"Arquitetura b\u00e1sica de IoT","text":"<p>A arquitetura de implanta\u00e7\u00e3o apresentada aqui \u00e9 um modelo padr\u00e3o para inspirar projetos reais. Ela inclui os elementos fundamentais para a conectividade, sem detalhar solu\u00e7\u00f5es para problemas acess\u00f3rios.</p> <p></p> <ul> <li>Interoperabilidade: facilita a compatibilidade entre diferentes projetos de IoT.</li> <li>Modularidade: define m\u00f3dulos que podem ser criados separadamente ou usados como \"off-the-shelf\".</li> </ul>"},{"location":"aulas/iot/lab5/index.html#dispositivos-de-iot","title":"Dispositivos de IoT","text":"<p>Os dispositivos de IoT interagem com o ambiente ao seu redor, capturando dados de sensores ou executando comandos por meio de atuadores.</p> <ul> <li>Cada funcionalidade no dispositivo pode ser considerada uma aplica\u00e7\u00e3o (Endpoint Application).</li> <li>Cada aplica\u00e7\u00e3o deve ser univocamente endere\u00e7\u00e1vel.</li> </ul>"},{"location":"aulas/iot/lab5/index.html#conector-de-iot","title":"Conector de IoT","text":"<p>Os conectores de IoT gerenciam mensagens que chegam dos dispositivos ou s\u00e3o destinadas a eles, adaptando-as ao protocolo de cada dispositivo.</p> <ul> <li>Pode haver conectores diferentes para protocolos variados.</li> <li>Protocolos comuns em IoT: MQTT, WebSocket, CoAP, LoRaWAN.</li> </ul>"},{"location":"aulas/iot/lab5/index.html#gerenciamento-de-dispositivos-e-dados","title":"Gerenciamento de dispositivos e dados","text":"<p>Este componente faz o gerenciamento remoto dos dispositivos e de seus dados, autorizando o acesso de outras aplica\u00e7\u00f5es.</p> <ul> <li>Cadastra novos dispositivos e aplica\u00e7\u00f5es.</li> <li>Monitora a disponibilidade dos dispositivos.</li> <li>Envia comandos de gerenciamento, como inicializa\u00e7\u00e3o, reinicializa\u00e7\u00e3o, desligamento e atualiza\u00e7\u00e3o de firmware.</li> </ul>"},{"location":"aulas/iot/lab5/index.html#bancos-de-dados-e-analise-de-dados","title":"Bancos de dados e an\u00e1lise de dados","text":"<p>Armazena dados provenientes das aplica\u00e7\u00f5es e comandos destinados aos dispositivos.</p> <ul> <li>Bancos de dados NoSQL s\u00e3o mais indicados para a IoT devido \u00e0 natureza diversificada e em constante mudan\u00e7a dos dados.</li> <li>Analisadores de dados monitoram os dados para melhor aproveitamento.</li> </ul>"},{"location":"aulas/iot/lab5/index.html#gateway","title":"Gateway","text":"<p>O gateway conecta dispositivos sem acesso direto \u00e0 internet e realiza a convers\u00e3o de protocolos entre os dispositivos de IoT e o conector de IoT.</p> <p></p> <ul> <li>Gerencia m\u00faltiplos protocolos, especialmente em LAN\u2019s, PAN\u2019s e HAN\u2019s (ex: Zigbee, Bluetooth, LoRa, Thread/6LoWPAN).</li> </ul>"},{"location":"aulas/iot/lab5/index.html#node-red","title":"Node-RED","text":"<p>O Node-RED \u00e9 uma plataforma de programa\u00e7\u00e3o visual para sistemas baseados em eventos. Ele executa como um servidor web e \u00e9 amplamente utilizado para conectar dispositivos de IoT.</p> <ul> <li>Programado em Node.js, \u00e9 uma ferramenta visual para editar fluxos de mensagens.</li> <li>Dispon\u00edvel em servi\u00e7os de Cloud como o IBM Bluemix.</li> </ul>"},{"location":"aulas/iot/lab5/index.html#instalacao-do-node-red","title":"Instala\u00e7\u00e3o do Node-RED","text":"<ol> <li>Instale o Node.js (vers\u00e3o LTS) no site Node.js.</li> <li>No terminal, digite:      <pre><code>npm install -g --unsafe-perm node-red\n</code></pre></li> <li>Para rodar o Node-RED:      <pre><code>node-red\n</code></pre></li> <li>Acesse no navegador: http://localhost:1880</li> </ol>"},{"location":"aulas/iot/lab5/index.html#primeiro-fluxo-no-node-red","title":"Primeiro fluxo no Node-RED","text":"<ul> <li>Conecte um n\u00f3 de entrada do tipo \"inject\" a um n\u00f3 \"debug\", fa\u00e7a o deploy e observe o resultado no painel de debug.</li> <li>Modifique o n\u00f3 \"inject\" e veja as altera\u00e7\u00f5es no resultado.</li> </ul>"},{"location":"aulas/iot/lab5/index.html#desafios-no-node-red","title":"Desafios no Node-RED","text":""},{"location":"aulas/iot/lab5/index.html#desafio-1-monitor-de-clima","title":"Desafio 1: Monitor de clima","text":"<ol> <li>Cadastre-se no site OpenWeather, crie um token e leia a documenta\u00e7\u00e3o da API Current.</li> <li>Crie uma URL para obter o tempo de uma cidade de sua prefer\u00eancia e compare o resultado com a sa\u00edda no Node-RED.</li> </ol>"},{"location":"aulas/iot/lab5/index.html#desafio-2-dashboard","title":"Desafio 2: Dashboard","text":"<p>Crie um dashboard que exiba informa\u00e7\u00f5es de duas ou mais cidades, incluindo: - Temperatura atual - Temperatura m\u00ednima - Temperatura m\u00e1xima - Velocidade do vento - Umidade relativa - Sensa\u00e7\u00e3o t\u00e9rmica</p> <p>Atualize os dados a cada 3 ou 5 segundos.</p>"},{"location":"aulas/iot/lab5/index.html#mqtt-message-queuing-telemetry-transport","title":"MQTT (Message Queuing Telemetry Transport)","text":"<p>O MQTT \u00e9 um protocolo de comunica\u00e7\u00e3o leve projetado especificamente para dispositivos com recursos limitados, como sensores e atuadores, e cen\u00e1rios de redes com alta lat\u00eancia e baixa largura de banda. Sua simplicidade e baixo overhead o tornam ideal para a Internet das Coisas (IoT).</p> <p></p>"},{"location":"aulas/iot/lab5/index.html#caracteristicas-principais-do-mqtt","title":"Caracter\u00edsticas principais do MQTT:","text":"<ul> <li>Modelo Publish/Subscribe: O MQTT usa um modelo de comunica\u00e7\u00e3o ass\u00edncrono, onde os clientes se inscrevem (subscribe) em t\u00f3picos espec\u00edficos para receber mensagens e publicam (publish) mensagens nesses t\u00f3picos para serem recebidas por outros clientes.</li> <li>Broker: O broker \u00e9 o servidor central que gerencia as mensagens publicadas e as distribui para os clientes inscritos em t\u00f3picos espec\u00edficos.</li> <li>Qualidade de Servi\u00e7o (QoS): O MQTT oferece tr\u00eas n\u00edveis de QoS que controlam a entrega das mensagens, garantindo diferentes n\u00edveis de confiabilidade:</li> <li>QoS 0 - At most once: A mensagem \u00e9 entregue no m\u00e1ximo uma vez, sem confirma\u00e7\u00e3o de recebimento. Risco de perda de mensagem.</li> <li>QoS 1 - At least once: A mensagem \u00e9 entregue ao menos uma vez. H\u00e1 confirma\u00e7\u00e3o de recebimento, mas pode ocorrer duplica\u00e7\u00e3o de mensagens.</li> <li> <p>QoS 2 - Exactly once: A mensagem \u00e9 entregue exatamente uma vez, garantindo a entrega sem duplica\u00e7\u00e3o ou perda, por\u00e9m com maior overhead.</p> </li> <li> <p>Retained Messages: Uma mensagem publicada pode ser marcada como \"retida\", o que significa que o broker armazenar\u00e1 essa \u00faltima mensagem publicada no t\u00f3pico e enviar\u00e1 imediatamente aos novos clientes que se inscreverem no t\u00f3pico, mesmo ap\u00f3s a publica\u00e7\u00e3o original.</p> </li> <li>Last Will and Testament (LWT): O LWT \u00e9 uma mensagem que o broker envia automaticamente caso um cliente MQTT se desconecte inesperadamente, notificando os outros clientes da rede sobre a falha.</li> </ul> <p></p>"},{"location":"aulas/iot/lab5/index.html#funcionamento-do-mqtt","title":"Funcionamento do MQTT:","text":"<ol> <li>Publica\u00e7\u00e3o de Mensagens: Um cliente publica uma mensagem em um t\u00f3pico espec\u00edfico no broker.</li> <li>Inscri\u00e7\u00e3o em T\u00f3picos: Outros clientes se inscrevem em t\u00f3picos de interesse e, quando uma mensagem \u00e9 publicada nesses t\u00f3picos, o broker a entrega aos inscritos.</li> <li>Filtragem por T\u00f3picos: O MQTT utiliza hierarquias de t\u00f3picos, permitindo o uso de caracteres coringa para subscri\u00e7\u00e3o:</li> <li>+: Corresponde a um \u00fanico n\u00edvel de um t\u00f3pico. Exemplo: <code>sala/+/temperatura</code> se inscreve em todos os sensores de temperatura de diferentes salas.</li> <li>#: Corresponde a todos os n\u00edveis subsequentes do t\u00f3pico. Exemplo: <code>sala/#</code> se inscreve em todos os t\u00f3picos que come\u00e7am com \"sala\".</li> </ol>"},{"location":"aulas/iot/lab5/index.html#exemplos-de-brokers-mqtt","title":"Exemplos de Brokers MQTT:","text":"<ul> <li>Brokers P\u00fablicos:</li> <li>iot.eclipse.org</li> <li>test.mosquitto.org</li> <li>dev.rabbitmq.com</li> <li>broker.mqttdashboard.com</li> </ul>"},{"location":"aulas/iot/lab5/index.html#desafio-3-cliente-mqtt-no-node-red","title":"Desafio 3: Cliente MQTT no Node-RED","text":"<p>No Node-RED, um fluxo pode ser criado para simular um chat entre dois ou mais clientes MQTT. Para isso, deve-se configurar t\u00f3picos que sigam boas pr\u00e1ticas de nomea\u00e7\u00e3o, como camelCase, e criar dois n\u00f3s principais:</p> <ul> <li>Node MQTT In: Subscreva-se a um t\u00f3pico espec\u00edfico e receba mensagens publicadas nesse t\u00f3pico.</li> <li>Node MQTT Out: Publique mensagens em um t\u00f3pico que os outros clientes est\u00e3o escutando.</li> </ul> <p></p> <p>Exemplo de configura\u00e7\u00e3o:</p> <ul> <li>T\u00f3pico de envio: <code>arnaldoAVianaJr/chat/mensagem</code></li> <li>Para receber mensagens, crie um n\u00f3 que se inscreva em: arnaldoAVianaJr/#.</li> </ul> <p></p> <p>Tip</p> <p>Esse fluxo de comunica\u00e7\u00e3o pode ser testado em um ambiente local ou em um dos brokers p\u00fablicos mencionados anteriormente.</p>"},{"location":"aulas/iot/lab6/index.html","title":"Lab02","text":""},{"location":"aulas/iot/lab6/index.html#integracao-arduino-e-node-red","title":"Integra\u00e7\u00e3o Arduino e Node-RED","text":"<p>Vamo integrar sensores com Arduino, monitorar dados em tempo real no Node-RED, desenvolver sistemas supervis\u00f3rios usando JSON, dashboards e protocolo MQTT.</p>"},{"location":"aulas/iot/lab6/index.html#instalacao-e-uso-de-bibliotecas-externas-para-arduino","title":"Instala\u00e7\u00e3o e uso de bibliotecas externas para arduino","text":"<p>Normalmente os criadores das bibliotecas descrevem o passo-a-passo para utilizar as bibliotecas criadas, mas de forma geral podemos instalar uma biblioteca externa de duas formas: </p> <ul> <li> <p>Por Download: </p> <ul> <li>Fazer o download do arquivo .zip da biblioteca </li> <li>Descompactar o arquivo dentro da pasta <code>documentos/Arduino/libraries/</code></li> <li>Pronto! Podemos usar em nosso projeto.</li> <li>De forma geral \u00e9 isso, eventualmente o criador da biblioteca ir\u00e1 orientar eventuais etapas adicionais. </li> </ul> </li> <li> <p>Pelo gerenciador de bibliotecas:</p> <ul> <li>abra o Arduino IDE</li> <li>acesse: Sketch ==&gt; Include Library ==&gt; Manage Libraries\u2026 </li> <li>Digite na busca o nome da biblioteca</li> <li>Encontre a op\u00e7\u00e3o desejada e clique em instalar</li> <li>Pronto! Podemos usar em nosso projeto.</li> <li>Algumas libs dependem de outras de outras libs, nesse caso \u00e9 necess\u00e1rio instalar todas as libs.</li> </ul> </li> </ul> Imagem passo-a-passo <p></p> <p>DICA: Explore a documenta\u00e7\u00e3o e os exemplos da biblioteca instalada.   </p>"},{"location":"aulas/iot/lab6/index.html#biblioteca-arduinojson","title":"Biblioteca ArduinoJson","text":"<p>A biblioteca ArduinoJson \u00e9 uma ferramenta escrita em C++ que facilita a comunica\u00e7\u00e3o de dados no formato JSON (JavaScript Object Notation) em projetos de IoT com Arduino. O formato JSON \u00e9 amplamente utilizado por ser leve, leg\u00edvel e compat\u00edvel com diversas plataformas. Para quem j\u00e1 utiliza Python, a estrutura do JSON \u00e9 semelhante \u00e0 de dicion\u00e1rios, por exemplo:</p> <p>{\"Key1\":\"Value1\", \"Key2\":\"Value2\", \"Key3\":\"Value3\",\"....\":.\"....\"}  </p> <p>A documenta\u00e7\u00e3o oficial da biblioteca pode ser consultada em: arduinoJSON - https://arduinojson.org/</p> <p>Exercise</p> <p>Fa\u00e7a a instala\u00e7\u00e3o da biblioteca arduinoJSON direto pelo ArduinoIDE, no campo de busca digite <code>ArduinoJson</code> e instale a biblioteca. Para mais detalhes de como realizar a instala\u00e7\u00e3o acesse aqui a documenta\u00e7\u00e3o oficial - https://arduinojson.org/v6/doc/installation/</p>"},{"location":"aulas/iot/lab6/index.html#sensor-dht11","title":"Sensor DHT11","text":"<p>O DHT11 \u00e9 um sensor digital de temperatura e umidade muito utilizado em diversas aplica\u00e7\u00f5es. Para facilitar o trabalho utilizamos uma biblioteca para realizar as leituras de temperatura e umidade. </p> <p></p> Pino Descri\u00e7\u00e3o 1 Alimenta\u00e7\u00e3o, VCC, 3,5V ~ 5,5V 2 DATA, transmiss\u00e3o de dados 3 NC, N\u00e3o Conectado 4 Alimenta\u00e7\u00e3o, GND, 0v <p>Aten\u00e7\u00e3o: Certifique-se de conectar corretamente os pinos de alimenta\u00e7\u00e3o para evitar danos ao sensor.</p> <p>Exercise</p> <p>Fa\u00e7a a instala\u00e7\u00e3o das bibliotecas para usar o DHT11: Adafruit Unified Sensor Libs: </p> <ol> <li> <p>Adafruit Sensor</p> </li> <li> <p>DHT Sensor. </p> </li> </ol> <p>Ap\u00f3s o download descompacte o arquivo .zip e mova-o para a pasta <code>~/Arduino/Libraries/</code></p>"},{"location":"aulas/iot/lab6/index.html#testando-o-sensor-dht11","title":"Testando o sensor DHT11","text":"<p>Para testar o funcionamento do sensor vamos executar <code>2 etapas</code>: Montagem do <code>hardware</code> e Desenvolvimento do <code>Software</code>.</p>"},{"location":"aulas/iot/lab6/index.html#o-hardware-de-teste","title":"O hardware de teste","text":"<p>Monte o circuito da imagem abaixo e n\u00e3o esque\u00e7a de conectar o resistor </p> <p></p> <p>Exercise</p> <p>De acordo com o circuito qual o pino do arduino \u00e9 utilizado para realizar comunica\u00e7\u00e3o digital com o sensor DHT11?</p>"},{"location":"aulas/iot/lab6/index.html#o-codigo-de-teste","title":"O c\u00f3digo de teste","text":"<p>Crie um novo projeto no ArduinoIDE e utilize o c\u00f3digo de teste abaixo: Este c\u00f3digo foi adaptado do site filipeflop</p> <pre><code>/*\nC\u00f3digo para teste do sensor DHT11 \n\n*/\n#include \"DHT.h\"\n#define DHTPIN  7  //define o pino usado no arduino\n#define DHTTYPE DHT11\nDHT dht(DHTPIN, DHTTYPE); //declara a objeto da classe\n\nvoid setup() \n{\n  Serial.begin(9600);\n  Serial.println(\"DHTxx test!\");\n  dht.begin();\n}\n\nvoid loop() \n{\n  float h = dht.readHumidity();  // faz leitura da umidade\n  float t = dht.readTemperature();  // faz leitura da temperatura\n\n  // testa se retorno \u00e9 valido, caso contr\u00e1rio algo est\u00e1 errado.\n  if (isnan(t) || isnan(h)) \n  {\n    Serial.println(\"Falha na leitura do sensor DHT\");\n  } \n  else\n  {\n    Serial.print(\"Umidade: \");\n    Serial.print(h);\n    Serial.print(\" %\\t\");\n    Serial.print(\"Temperatura: \");\n    Serial.print(t);\n    Serial.println(\" *C\");\n  }\n  delay(500); //delay de 0,5s\n}\n</code></pre>"},{"location":"aulas/iot/lab6/index.html#o-teste","title":"O teste","text":"<p>Ap\u00f3s montar o circuito e carregar o c\u00f3digo, abra o <code>Monitor Serial</code> do Arduino IDE para visualizar as leituras de temperatura e umidade em tempo real. O resultado esperado \u00e9 semelhante ao da imagem abaixo.</p> <p></p> <ul> <li><code>Parab\u00e9ns!!</code> Primeira parte concluida, vamos em frente... </li> </ul>"},{"location":"aulas/iot/lab6/index.html#usando-a-biblioteca-arduinojson","title":"Usando a biblioteca ArduinoJson","text":"<p>Agora vamos aprimorar o c\u00f3digo do Arduino para enviar as informa\u00e7\u00f5es do sensor DHT11 em formato JSON. Isso facilita a integra\u00e7\u00e3o com sistemas como o Node-RED e o uso de protocolos como MQTT.</p> <pre><code>/*\nC\u00f3digo exemplo demonstrando o funcionamento do Sensor DHT11 enviando \ninforma\u00e7\u00f5es via serial no formato JSON para o servidor node-Red que recebe e transmite via protocolo MQTT \n\n*/\n\n/////Json\n#include &lt;ArduinoJson.h&gt;\nconst int TAMANHO = 50;  //define o tamanho do buffer para o json\n\n///// Sensor DHT\n#include \"DHT.h\"\n#define DHTPIN  7  //define o pino usado no arduino\n#define DHTTYPE DHT11\nDHT dht(DHTPIN, DHTTYPE); //declara a objeto da classe\n\n////// Outras declara\u00e7\u00f5es\n#define led 13 //define led conectado no pino 13\n\nvoid setup() \n{\n  //inicialia c sensor\n  dht.begin();\n\n  //inicializa comunica\u00e7\u00e3o serial\n  Serial.begin(9600);\n\n  //configura pinos de saida do arduinos\n  pinMode(led, OUTPUT);\n}\n\nvoid loop() \n{\n  StaticJsonDocument&lt;TAMANHO&gt; json; //Aloca buffer para objeto json\n\n  // Faz a leitura da temperatura  \n  float temp = dht.readTemperature();\n  // faz a leitura da humidade\n  float umi = dht.readHumidity();\n\n  //formato de escrita do json\n  json[\"temperatura\"] = temp;\n  json[\"umidade\"] = umi;\n\n  serializeJson(json, Serial);\n  Serial.println();\n\n  //delay\n  delay(500);\n}\n</code></pre> <p><code>Um ponto importante</code>: Definir a variavel <code>TAMANHO</code> que serve como buffer em bytes para alocar o JSON que vamos trabalhar. Para isso podemos utilizar o <code>ArduinoJson Assistant</code> neste link: https://arduinojson.org/v6/assistant/#/step1, siga o passo-a-passo da ferramenta para descobrir o valor minimo que devemos utilizar. </p> <p>Exercise</p> <p>Utilizando o <code>ArduinoJson Assistant</code> qual o valor recomendado para o json do exemplo abaixo?</p> <pre><code>{\n\"valorSensor1\":10.10258,\n\"valorSensor2\":50.28546\n}    \n</code></pre> <ul> <li><code>Parab\u00e9ns!!</code> Mais uma etapa completa! Agora o nosso programa envia dados no formato Json, facilitando a integra\u00e7\u00e3o com outros sistemas incluindo o Node-RED. </li> <li>\u00c9 muito importante que ele n\u00e3o envie pela Serial nada diferente do formato JSON, por isso cuidado com um Serial.println de teste ou esquecido no meio do c\u00f3digo.</li> </ul>"},{"location":"aulas/iot/lab6/index.html#comunicacao-serial-com-node-red","title":"Comunica\u00e7\u00e3o serial com node-RED","text":"<p>No flow do node-red, vamos usar o node <code>serialport</code> para realizar a comunica\u00e7\u00e3o serial entre o node-red e o arduino conectado na porta que conectado na porta USB, por padr\u00e3o esse n\u00e3o vem instalado. Fa\u00e7a a instala\u00e7\u00e3o do node <code>node-red-node-serialport</code>.</p> <p></p> <p>No node-RED monte o flow:</p> <p></p> <p>Agora configure o node da serial da seguinte forma: </p> <pre><code>- Serial Port: com o nome da porta COM que est\u00e1 alocada para o arduino\n- baud rate: para 9600.\n</code></pre> <p></p> <p>Fa\u00e7a o deplay e se tudo estiver correto, no debug vai aparecer as mensagens recebidas pelo arduino.</p> <p></p>"},{"location":"aulas/iot/lab6/index.html#desenvolvimento-de-um-sistema-supervisorio-para-monitoramento-de-temperatura-e-umidade","title":"Desenvolvimento de um sistema supervis\u00f3rio para monitoramento de temperatura e umidade","text":"<p>Agora que o Node-RED j\u00e1 est\u00e1 recebendo os dados do Arduino em formato JSON, vamos transformar esses dados em informa\u00e7\u00f5es visuais e interativas em um dashboard, criando um sistema supervis\u00f3rio simples.</p> <p>Passos para criar o dashboard: - No Node-RED, utilize os nodes do pacote node-red-dashboard para criar a interface. - Separe os valores de temperatura e umidade do JSON recebido utilizando um node function ou change, conforme necess\u00e1rio. - Adicione dois widgets do tipo gauge (medidor) para exibir, separadamente, a temperatura e a umidade em tempo real. - Adicione dois widgets do tipo chart (gr\u00e1fico) para acompanhar a evolu\u00e7\u00e3o dos valores ao longo do tempo. - Conecte os nodes de acordo com o fluxo desejado para garantir que os dados recebidos do Arduino sejam corretamente encaminhados para os widgets do dashboard.</p> <p>Exercise</p> <p>Fa\u00e7a as adapta\u00e7\u00f5es necess\u00e1rias para exibir os valores de temperatura e umidade em 2 gauge e 2 chart como na imagem abaixo:</p> <p></p> <p>Exercise</p> <p>Baseado na solu\u00e7\u00e3o do desafio anterior, altere o fluxo para enviar os dados do node-RED via protocolo MQTT. Agora em um segundo computador crie um fluxo no node-RED que recebe os topicos enviados pelo primeiro flow em MQTT.</p>"},{"location":"aulas/iot/lab6/index.html#controlando-o-arduino-pelo-node-red","title":"Controlando o arduino pelo node-RED","text":"<p>At\u00e9 aqui, enviamos dados do Arduino para o Node-RED. Agora, vamos realizar o caminho inverso: controlar dispositivos conectados ao Arduino a partir de comandos enviados pelo Node-RED via comunica\u00e7\u00e3o serial. </p> <p>Exercise</p> <p>Adicione um <code>dashboard switch</code> e configure para enviar a string \u201cliga\u201d e \u201cdesliga\u201d pela serial, para controlar um LED do arduino. DICA: Veja o exemplo abaixo como refer\u00eancia.</p> <pre><code>#include &lt;ArduinoJson.h&gt;\nconst int LED = 3;\nconst int TAMANHO = 200;\nvoid setup() {\n  Serial.begin(9600);\n  //O valor padr\u00e3o de 1000ms \u00e9 muito tempo\n  Serial.setTimeout(10);\n  pinMode(LED,OUTPUT);\n}\nvoid loop() {\n  if (Serial.available() &gt; 0) {\n    //L\u00ea o JSON dispon\u00edvel na porta serial:\n    StaticJsonDocument&lt;TAMANHO&gt; json;\n    deserializeJson(json, Serial);\n    if(json.containsKey(\"led\")) {\n      int valor = json[\"led\"];\n      analogWrite(LED, valor);\n    }\n  } \n  delay(300);\n}\n</code></pre>"},{"location":"aulas/iot/lab6/index.html#validando-regas-de-decisao","title":"Validando regas de decis\u00e3o","text":"<p>Vamos a criar l\u00f3gicas de decis\u00e3o no Node-RED para analisar dados recebidos via MQTT e gerar respostas personalizadas.</p> <p>Fluxo B\u00e1sico de Trabalho: 1. Receber JSON via MQTT: Configure um node MQTT in para assinar um t\u00f3pico espec\u00edfico (ex: sensor/temperatura). 2. Convers\u00e3o para Objeto JavaScript: Conecte, se necess\u00e1rio, a um node JSON para parsear a mensagem recebida. 3. Valida\u00e7\u00e3o com <code>Node Function</code>: Utilize um node function para implementar suas regras de neg\u00f3cio. 4. Envio da Resposta via MQTT: Conecte a um node MQTT out para publicar o resultado do processamento.</p>"},{"location":"aulas/iot/lab6/index.html#sistema-de-alerta-de-temperatura","title":"Sistema de Alerta de Temperatura","text":"<p>[MQTT in] \u2192 [JSON] \u2192 [Function] \u2192 [MQTT out]</p>"},{"location":"aulas/iot/lab6/index.html#codigo-do-node-function","title":"C\u00f3digo do Node Function","text":"<pre><code>// Recebe mensagem do t\u00f3pico 'sensor/temperatura'\nconst temp = msg.payload.temperatura;\nconst umid = msg.payload.umidade;\n\n// Regras de neg\u00f3cio\nlet status = \"NORMAL\";\nif(temp &gt; 30) {\n    status = \"ALERTA: Temperatura cr\u00edtica!\";\n} else if(umid &gt; 70) {\n    status = \"AVISO: Umidade elevada\";\n}\n\n// Cria novo JSON de controle\nmsg.payload = {\n    \"timestamp\": Date.now(),\n    \"sensor_id\": msg.topic.split(\"/\")[1],\n    \"status\": status,\n    \"acao_recomendada\": temp &gt; 30 ? \"Ligar ventila\u00e7\u00e3o\" : \"Nenhuma a\u00e7\u00e3o\"\n};\n\nreturn msg;\n</code></pre> Tabela de Regras de Neg\u00f3cio: Condi\u00e7\u00e3o A\u00e7\u00e3o T\u00f3pico de Resposta Temperatura &gt; 30\u00b0C Enviar comando ventila\u00e7\u00e3o controle/ventilador/1 Umidade &gt; 70% Ativar desumidificador controle/desumidificador Ambos valores normais Manter sistema em standby sistema/status <p>Exercise</p> <p>Crie um flow que recebe dados do t\u00f3pico <code>sensor/temperatura</code> Adicione valida\u00e7\u00e3o para umidade <code>abaixo de 30%</code></p> <p>Gere um novo JSON com estrutura:</p> <pre><code>{\n  \"alerta\": \"BAIXA_UMIDADE\",\n  \"comando\": \"ligar_umidificador\"\n}\n</code></pre> <p>Publique no t\u00f3pico <code>controle/umidificador</code></p> <p>Dica: Utilize o Debug node para monitorar a transforma\u00e7\u00e3o dos dados em cada etapa do processo.</p>"},{"location":"aulas/iot/lab6/index.html#desafios","title":"Desafios","text":"<p>J\u00e1 construimos toda a infraestrutura com a base necess\u00e1ria para desenvolver os desafios deste lab.</p>"},{"location":"aulas/iot/lab6/index.html#desafio-1-alerta-de-condicoes-climaticas","title":"Desafio 1: Alerta de Condi\u00e7\u00f5es Clim\u00e1ticas","text":"<p>Objetivo: Criar um sistema de alerta que notifica o usu\u00e1rio quando a temperatura e/ou umidade ultrapassam um limite definido.</p>"},{"location":"aulas/iot/lab6/index.html#instrucoes","title":"Instru\u00e7\u00f5es:","text":"<ul> <li>Utilize o Node-RED para definir limites de temperatura e umidade (por exemplo, temperatura acima de 30\u00b0C e umidade abaixo de 40%).</li> <li>Quando os valores lidos pelo sensor DHT11 ultrapassarem esses limites, um alerta deve ser exibido no dashboard.</li> <li>Adicione um LED no Arduino para acender quando os limites forem ultrapassados.</li> </ul>"},{"location":"aulas/iot/lab6/index.html#desafio-2-registro-de-dados","title":"Desafio 2: Registro de Dados","text":"<p>Objetivo: Armazenar os dados de temperatura e umidade em um banco de dados ou arquivo para an\u00e1lise posterior.</p>"},{"location":"aulas/iot/lab6/index.html#instrucoes_1","title":"Instru\u00e7\u00f5es:","text":"<ul> <li>Utilize o Node-RED para encaminhar os dados recebidos do Arduino para um banco de dados de sua escolha (pode ser um banco de dados SQL, NoSQL ou at\u00e9 mesmo um arquivo CSV).</li> </ul>"},{"location":"aulas/iot/lab6/index.html#desafio-3-integracao-com-outros-sensores","title":"Desafio 3: Integra\u00e7\u00e3o com Outros Sensores","text":"<p>Objetivo: Integrar outros sensores ao sistema e exibir seus dados no Node-RED.</p>"},{"location":"aulas/iot/lab6/index.html#instrucoes_2","title":"Instru\u00e7\u00f5es:","text":"<ul> <li>Escolha um ou mais sensores adicionais compat\u00edveis com Arduino (por exemplo, sensor de luminosidade, sensor de movimento, sensor de g\u00e1s, etc.).</li> <li>Integre o(s) sensor(es) escolhido(s) ao seu circuito Arduino.</li> <li>Modifique o c\u00f3digo do Arduino para ler os dados do(s) novo(s) sensor(es) e enviar esses dados para o Node-RED em formato JSON, juntamente com os dados de temperatura e umidade.</li> <li>No Node-RED, configure o dashboard para exibir os dados do(s) novo(s) sensor(es) em tempo real, seja atrav\u00e9s de gr\u00e1ficos, medidores ou outros widgets relevantes.</li> </ul> <p>Como um desafio adicional configurar alertas ou a\u00e7\u00f5es espec\u00edficas com base nos dados do(s) novo(s) sensor(es). Por exemplo, se um sensor de luminosidade detectar que est\u00e1 escuro, um LED pode ser acionado automaticamente.</p>"},{"location":"aulas/iot/lab7/index.html","title":"Lab03","text":""},{"location":"aulas/iot/lab7/index.html#lab7-api-rest-json-node-red","title":"Lab7 - API REST JSON NODE-RED","text":""},{"location":"aulas/iot/lab7/index.html#criando-servidor-no-node-red","title":"Criando servidor no Node-Red","text":""},{"location":"aulas/iot/lab7/index.html#estrutura-da-api","title":"Estrutura da API:","text":"<ol> <li> <p>Acender ou apagar o LED:</p> </li> <li> <p>Endpoint: <code>/led</code></p> </li> <li> <p>M\u00e9todos:</p> <ul> <li>GET: Retorna o estado atual do LED (0 ou 1).</li> <li>POST: Muda o estado do LED. O corpo da solicita\u00e7\u00e3o deve conter um JSON com o novo estado.</li> <li>PUT: Mesma funcionalidade do POST.</li> <li>DELETE: Desliga o LED.</li> </ul> </li> <li> <p>Capturar o status do bot\u00e3o:</p> </li> <li> <p>Endpoint: <code>/button</code></p> </li> <li>M\u00e9todo:<ul> <li>GET: Retorna o estado atual do bot\u00e3o (pressionado ou n\u00e3o pressionado).</li> </ul> </li> </ol> <p>O objetivo \u00e9 criar os endponts <code>/led</code> e <code>/button</code> que v\u00e3o representar o estado do sensor e atuador conectado ao dispositivo inteligente IoT. </p> <p>O resultado das rotas ser\u00e1:</p> <ul> <li>Endpoint <code>/led</code>:</li> </ul> <p></p> <ul> <li>Endpoint <code>/button</code>:</li> </ul> <p></p> <ul> <li>Monte o fluxo e teste:</li> </ul> <p></p> <p>onde:</p> <ul> <li>function10:</li> </ul> <pre><code>// Supondo que o estado do LED \u00e9 armazenado em uma vari\u00e1vel global.\nvar ledState = global.get(\"ledState\") || 0; // Se n\u00e3o estiver definido, assume 0.\nmsg.payload = {\n    \"state\": ledState\n};\nreturn msg;\n</code></pre> <ul> <li>function11:</li> </ul> <pre><code>var newState = msg.payload.state;\nif (newState === 0 || newState === 1) {\n    global.set(\"ledState\", newState);\n    msg.payload = {\n        \"message\": \"LED atualizado com sucesso.\"\n    };\n} else {\n    msg.payload = {\n        \"message\": \"Estado inv\u00e1lido.\"\n    };\n    msg.statusCode = 400; // C\u00f3digo de erro para \"Bad Request\"\n}\nreturn msg;\n</code></pre> <ul> <li>function12:</li> </ul> <pre><code>global.set(\"ledState\", 0);\nmsg.payload = {\n    \"message\": \"LED desligado com sucesso.\"\n};\nreturn msg;\n</code></pre> <ul> <li>function13:</li> </ul> <pre><code>// Supondo que o estado do bot\u00e3o \u00e9 armazenado em uma vari\u00e1vel global.\nvar buttonState = global.get(\"buttonState\") || 0; \nmsg.payload = {\n    \"state\": buttonState\n};\nreturn msg;\n</code></pre> <ul> <li>function14:</li> </ul> <pre><code>global.set(\"buttonState\", 1);\nreturn msg;\n</code></pre> <ul> <li>function15:</li> </ul> <pre><code>global.set(\"buttonState\", 0);\nreturn msg;\n</code></pre>"},{"location":"aulas/iot/lab7/index.html#cors-cross-origin-resource-sharing","title":"CORS - Cross-Origin Resource Sharing","text":"<p>Quando voc\u00ea cria uma API REST, especialmente para aplica\u00e7\u00f5es de IoT, \u00e9 comum que diferentes clientes (como navegadores web, aplicativos m\u00f3veis ou outros dispositivos) tentem acess\u00e1-la de diferentes origens. Portanto, lidar com o Controle de Acesso de Origem Cruzada (CORS - Cross-Origin Resource Sharing) \u00e9 uma considera\u00e7\u00e3o importante.</p> <p>Por padr\u00e3o, por motivos de seguran\u00e7a, os navegadores restringem solicita\u00e7\u00f5es HTTP de serem feitas entre sites. Isso significa que, se voc\u00ea tiver uma interface web rodando em um dom\u00ednio ou porta e tentar fazer uma solicita\u00e7\u00e3o AJAX para sua API Node-RED em um dom\u00ednio ou porta diferente, o navegador bloquear\u00e1 a solicita\u00e7\u00e3o, a menos que a API indique que essas solicita\u00e7\u00f5es cruzadas s\u00e3o aceit\u00e1veis.</p> <p>O cabe\u00e7alho <code>\"Content-Type\":\"application/json\"</code> informa aos clientes que a API retornar\u00e1 dados no formato JSON. O cabe\u00e7alho <code>\"Access-Control-Allow-Origin\":\"*\"</code> permite que qualquer site fa\u00e7a solicita\u00e7\u00f5es \u00e0 sua API. Isso \u00e9 adequado para desenvolvimento ou em ambientes controlados, mas tenha cuidado ao usar essa configura\u00e7\u00e3o em produ\u00e7\u00e3o devido a considera\u00e7\u00f5es de seguran\u00e7a.</p>"},{"location":"aulas/iot/lab7/index.html#dicas-para-realizar-requisicoes","title":"Dicas para realizar requisi\u00e7\u00f5es","text":"<p>Utilizar o <code>curl</code> \u00e9 uma forma simples de testar APIs diretamente do terminal ou linha de comando.</p> <p>No <code>Windows</code> o <code>CMD</code> interpreta alguns caracteres de maneira especial, a gente precisa ajustar a sintaxe ou usar o <code>PowerShell</code> em vez do CMD.</p> <p>Se for no CMD, o ajuste \u00e9 <code>\\\"</code> para usar <code>\"</code> interna da chave do JSON e fica:</p> <pre><code>curl -X POST -H \"Content-Type: application/json\" -d \"{\\\"state\\\": 0}\" http://localhost:1880/led\n</code></pre> <p>Se for no PowerShell, n\u00e3o muda: permanece:</p> <pre><code>curl -X POST -H 'Content-Type: application/json' -d '{\"state\": 0}' http://localhost:1880/led\n ```\n\nOs outros comandos permanecem iguais:\n\n\n```bash\ncurl -X GET http://localhost:1880/led\n\ncurl -X DELETE http://localhost:1880/led\n\ncurl -X GET http://localhost:1880/button\n</code></pre> <p>Se utilizar o Postman n\u00e3o ter\u00e1 esse problema. </p> <p></p>"},{"location":"aulas/iot/lab7/index.html#mais-informacoes","title":"Mais informa\u00e7\u00f5es","text":"<p>Fa\u00e7a o download do pdf da aula.</p> <ul> <li>arquivo pdf: lab7</li> </ul>"},{"location":"aulas/iot/lab8/index.html","title":"Lab01","text":""},{"location":"aulas/iot/lab8/index.html#raspberry-pi","title":"Raspberry PI","text":"<p>At\u00e9 agora em nosso curso, trabalhamos com pequenos projetos envolvendo sensores e atuadores, utilizando o Arduino UNO como nossa principal plataforma de hardware. Tamb\u00e9m exploramos integra\u00e7\u00f5es com Python e Node-Red.</p> <p>Neste m\u00f3dulo, iniciaremos nossa imers\u00e3o em computa\u00e7\u00e3o embarcada voltada para a Internet das Coisas (IoT) utilizando o <code>Raspberry PI</code>. Abordaremos t\u00f3picos como: introdu\u00e7\u00e3o \u00e0 Raspberry Pi, Sistema Operacional Linux, inicializa\u00e7\u00e3o da placa Raspberry PI, configura\u00e7\u00e3o e uso dos GPIOs, integra\u00e7\u00e3o com Arduino, Node-Red e muito mais.</p>"},{"location":"aulas/iot/lab8/index.html#conteudo-deste-laboratorio","title":"Conte\u00fado deste Laborat\u00f3rio","text":"<ul> <li>Introdu\u00e7\u00e3o \u00e0 Raspberry PI e compara\u00e7\u00e3o com o Arduino.</li> <li>Primeiros passos com a Raspberry Pi:<ul> <li>Conhecendo o hardware.</li> <li>Instalando o Sistema Operacional na Raspberry PI.</li> <li>Modos de uso: GUI vs. Headless.<ul> <li>Configura\u00e7\u00e3o para acesso via SSH e Wi-Fi no modo Headless.</li> <li>Uso do VNC Viewer.</li> <li>Modo Desktop (GUI).</li> </ul> </li> <li>Controlando os GPIOs: Exemplo com LED.<ul> <li>Controle via linha de comando.</li> <li>Uso de Shell Script.</li> <li>E mais...</li> </ul> </li> </ul> </li> </ul>"},{"location":"aulas/iot/lab8/index.html#raspberry-pi-vs-arduino","title":"Raspberry PI vs. Arduino","text":"<p>Lembrando do Arduino UNO que utilizamos, ele \u00e9 baseado em um <code>microcontrolador</code> de 8-bit (datasheet). Sua arquitetura RISC \u00e9 adequada para sistemas embarcados simples, mas n\u00e3o suporta um sistema operacional completo, o que pode limitar a implementa\u00e7\u00e3o de sistemas mais avan\u00e7ados.</p> <p>Para executar um sistema operacional completo, precisamos de um <code>processador</code>, como os modelos Intel 386, i5, i7, Celeron, entre outros (datasheet do Intel i7). Em aplica\u00e7\u00f5es de computa\u00e7\u00e3o embarcada, muitas vezes optamos por uma alternativa mais compacta e econ\u00f4mica ao computador tradicional, como os <code>SBCs</code> (Single Board Computers).</p> <p>Os SBCs s\u00e3o computadores completos em uma \u00fanica placa, combinando processador, mem\u00f3ria, suporte de rede, v\u00eddeo, \u00e1udio e outros recursos. S\u00e3o compactos e geralmente mais acess\u00edveis que um computador convencional.</p> <p>A <code>Raspberry PI</code> \u00e9 um dos SBCs mais populares e vers\u00e1teis dispon\u00edveis. Foi lan\u00e7ada em 2012 pela Raspberry Pi Foundation e utiliza processadores ARM da Broadcom, similares aos encontrados em smartphones. Desde seu lan\u00e7amento, diversos modelos foram introduzidos, como a Raspberry PI 3, 4, Zero, entre outros.</p> <p>Documenta\u00e7\u00e3o oficial da Raspberry PI</p> <p>Outros modelos de SBCs</p> <p>Com essa introdu\u00e7\u00e3o, vamos aprender a utilizar a Raspberry PI.</p>"},{"location":"aulas/iot/lab8/index.html#desafio-1","title":"Desafio 1","text":"<p>Responda as perguntas abaixo:</p> <p>Question</p> <p>Pergunta 1: Qual dos dois, Raspberry PI ou Arduino, \u00e9 mais adequado para rodar um sistema operacional completo?</p> <ul> <li> Raspberry PI</li> <li> Arduino</li> <li> Ambos</li> </ul> <p>Answer</p> <p>O Raspberry PI possui capacidade de rodar um SO completo.</p> <p>Question</p> <p>Pergunta 2: O Arduino UNO \u00e9 baseado em qual tipo de componente central?</p> <ul> <li> Microcontrolador</li> <li> Processador</li> <li> Disco r\u00edgido</li> <li> Placa de v\u00eddeo </li> </ul> <p>Answer</p> <p>O arduino UNO \u00e9 baseado em um microcontrolador.</p> <p>Question</p> <p>Pergunta 3: Qual \u00e9 a principal vantagem dos computadores de placa \u00fanica (SBC) como o Raspberry PI em rela\u00e7\u00e3o aos computadores convencionais?</p> <ul> <li> Eles t\u00eam mais poder de processamento.</li> <li> Eles podem executar m\u00faltiplos sistemas operacionais simultaneamente.</li> <li> Eles s\u00e3o mais caros e robustos.</li> <li> Eles s\u00e3o de baixo custo e possuem pequenas dimens\u00f5es.</li> </ul> <p>Answer</p> <p>Eles s\u00e3o de baixo custo e possuem pequenas dimens\u00f5es.</p> <p>Progress</p> <p>Continuar...</p>"},{"location":"aulas/iot/lab8/index.html#raspberry-pi-primeiros-passos","title":"Raspberry PI - Primeiros Passos","text":""},{"location":"aulas/iot/lab8/index.html#visao-geral","title":"Vis\u00e3o Geral","text":"<p>H\u00e1 v\u00e1rios modelos de Raspberry PI dispon\u00edveis. Em nosso curso, focaremos na <code>Raspberry PI 3 Model B+</code>.</p> <p></p> <p></p> <p>Complemento: - Fonte de Alimenta\u00e7\u00e3o: 5V @ &gt;2A - Cart\u00e3o SD: micro SD Card &gt;8GB Classe 10 ou superior</p>"},{"location":"aulas/iot/lab8/index.html#sistema-operacional","title":"Sistema Operacional","text":"<p>Existem v\u00e1rias distribui\u00e7\u00f5es de sistemas operacionais compat\u00edveis com a Raspberry PI, incluindo:</p> <ul> <li>Raspbian - Uso geral.</li> <li>Ubuntu - Uso geral.</li> <li>RetroPie - Emulador de videogame.</li> <li>OSMC - Media Center.</li> <li>Home Assistant - Automa\u00e7\u00e3o residencial.</li> <li>E muitos outros...</li> </ul> <p>Chega de teoria! Vamos \u00e0 pr\u00e1tica. Siga este guia atentamente e execute todos os passos.</p> <p>Progress</p> <p>Continuar...</p>"},{"location":"aulas/iot/lab8/index.html#instalando-o-sistema-operacional","title":"Instalando o Sistema Operacional","text":"<p>O sistema operacional da Raspberry PI \u00e9 armazenado em um <code>micro SD Card</code>. Recomenda-se usar um cart\u00e3o de pelo menos 8GB Classe 10 ou superior. Existem v\u00e1rias maneiras de instalar o sistema operacional, e aqui, vamos gui\u00e1-lo passo a passo.</p> <p>As vers\u00f5es do sistema operacional podem ser encontradas aqui. Em nosso curso, utilizaremos o <code>Raspberry Pi OS (legacy)</code>, baseado no Debian 10 (Buster).</p> <p></p> <p>Info</p> <p>Para facilitar, aqui est\u00e1 o link para download.</p> <p>Para gravar o cart\u00e3o SD, recomendamos o uso do <code>Balena Etcher</code>, dispon\u00edvel para v\u00e1rias plataformas.</p> <p>Link para download do Balena Etcher</p> <p>Siga os passos abaixo para preparar seu cart\u00e3o SD:</p> <ol> <li>Insira o cart\u00e3o SD no adaptador USB e conecte-o ao seu computador.</li> <li>Baixe o Raspberry Pi OS.</li> <li>Baixe e instale o Balena Etcher.</li> <li>Abra o Balena Etcher e siga os passos para gravar o cart\u00e3o SD.</li> <li>Ap\u00f3s a grava\u00e7\u00e3o, reconecte o adaptador USB ao computador.</li> <li>Voc\u00ea deve ver duas parti\u00e7\u00f5es, uma delas chamada \"boot\". Se n\u00e3o, formate o cart\u00e3o SD em FAT32 e repita o processo.</li> </ol> <p>Progress</p> <p>Continuar...</p>"},{"location":"aulas/iot/lab8/index.html#modo-de-uso-interface-grafica","title":"Modo de Uso - Interface Gr\u00e1fica","text":"<p>Nota: Esta se\u00e7\u00e3o \u00e9 apenas para conhecimento adicional, pois n\u00e3o usaremos a Raspberry PI desta maneira em nosso curso.</p> <p>Para usar a Raspberry PI como um computador convencional, conecte um monitor via HDMI, um teclado e um mouse. Insira o cart\u00e3o SD gravado e conecte a fonte de alimenta\u00e7\u00e3o. O sistema operacional ser\u00e1 inicializado e estar\u00e1 pronto para uso.</p> <p></p> <p></p>"},{"location":"aulas/iot/lab8/index.html#modo-de-uso-headless","title":"Modo de Uso - Headless","text":"<p>Nesta se\u00e7\u00e3o, aprenderemos a usar a Raspberry PI no modo <code>Headless</code>, sem a necessidade de monitor, teclado ou mouse. Algumas configura\u00e7\u00f5es s\u00e3o necess\u00e1rias antes de iniciar a Raspberry PI neste modo.</p>"},{"location":"aulas/iot/lab8/index.html#habilitando-ssh","title":"Habilitando SSH","text":"<p>Para ativar o acesso SSH, crie um arquivo vazio chamado \"ssh\" na pasta \"boot\" do cart\u00e3o SD.</p> <p>Siga os passos abaixo:</p> <ol> <li>Conecte o cart\u00e3o SD ao adaptador USB e insira-o no computador.</li> <li>Acesse a parti\u00e7\u00e3o chamada \"boot\".</li> <li>Crie um arquivo chamado \"ssh\" (sem extens\u00e3o) na raiz da parti\u00e7\u00e3o.</li> </ol> <p>O resultado deve ser semelhante ao mostrado na imagem:</p> <p></p> <p>Progress</p> <p>Continuar...</p>"},{"location":"aulas/iot/lab8/index.html#configurando-a-rede-wi-fi","title":"Configurando a Rede Wi-Fi","text":"<p>A configura\u00e7\u00e3o da rede Wi-Fi \u00e9 feita atrav\u00e9s do arquivo \"wpa_supplicant.conf\", que deve ser criado na pasta \"boot\" do cart\u00e3o SD.</p> <p>Siga as instru\u00e7\u00f5es abaixo para configurar sua rede Wi-Fi:</p> <ol> <li>Crie um arquivo chamado \"wpa_supplicant.conf\" na raiz da parti\u00e7\u00e3o \"boot\".</li> <li>Abra o arquivo com um editor de texto e configure-o de acordo com o exemplo fornecido.</li> </ol> <p>Nota: Certifique-se de estar conectado \u00e0 mesma rede Wi-Fi que a Raspberry PI.</p> <p>Agora, com tudo configurado, \u00e9 hora de ligar a Raspberry PI e test\u00e1-la.</p>"},{"location":"aulas/iot/lab8/index.html#desafio-2","title":"Desafio 2","text":"<p>Responda as perguntas abaixo:</p> <p>Question</p> <p>Pergunta 4: Qual \u00e9 a principal fun\u00e7\u00e3o do arquivo <code>wpa_supplicant.conf</code> na pasta <code>boot</code> do Raspberry PI?</p> <ul> <li> Habilitar o SSH.</li> <li> Configurar a rede Wi-Fi.</li> <li> Iniciar o sistema operacional.</li> <li> Configurar a sa\u00edda de v\u00eddeo.</li> </ul> <p>Answer</p> <p>Configurar a rede Wi-Fi.</p> <p>Question</p> <p>Pergunta 5: Ao configurar o Raspberry PI no modo <code>Headless</code>, o que \u00e9 necess\u00e1rio fazer para habilitar o acesso SSH?</p> <ul> <li> Criar um arquivo chamado <code>ssh</code> na pasta <code>home</code>.</li> <li> Criar um arquivo chamado <code>ssh</code> na pasta <code>boot</code>.</li> <li> Instalar um software adicional.</li> <li> Configurar o firewall para permitir o acesso SSH.</li> </ul> <p>Answer</p> <p>Criar um arquivo chamado <code>ssh</code> na pasta <code>boot</code>.</p> <p>Question</p> <p>Pergunta 6: Qual software \u00e9 recomendado para acessar o Raspberry PI via SSH a partir de um computador?</p> <ul> <li> WinRAR</li> <li> Balena Etcher</li> <li> PuTTY</li> <li> Microsoft Word</li> </ul> <p>Answer</p> <p>PuTTY</p> <p>Progress</p> <p>Continuar...</p>"},{"location":"aulas/iot/lab8/index.html#primeiro-teste-com-a-raspberry-pi","title":"Primeiro Teste com a Raspberry PI","text":"<p>Para nosso primeiro teste, montaremos um circuito simples para acender um LED. Siga o esquema abaixo:</p> <p></p> <p>No terminal da Raspberry PI, execute os comandos a seguir para controlar o LED:</p> <pre><code># Configura o pino GPIO 17 como sa\u00edda (output)\necho \"17\" &gt; /sys/class/gpio/export\necho \"out\" &gt; /sys/class/gpio/gpio17/direction\n\n# Acende o LED (n\u00edvel l\u00f3gico alto)\necho \"1\" &gt; /sys/class/gpio/gpio17/value\n\n# Apaga o LED (n\u00edvel l\u00f3gico baixo)\necho \"0\" &gt; /sys/class/gpio/gpio17/value\n\n# Libera o pino GPIO 17\necho \"17\" &gt; /sys/class/gpio/unexport\n</code></pre> <p>Se tudo funcionou corretamente, voc\u00ea deve ter visto o LED acender e apagar.</p>"},{"location":"aulas/iot/lab8/index.html#desafio-3-opcional","title":"Desafio 3 (opcional)","text":"<p>Agora \u00e9 sua vez! A Raspberry PI permite controlar seus pinos GPIO usando v\u00e1rias linguagens de programa\u00e7\u00e3o. Escolha sua linguagem preferida e escreva um c\u00f3digo para fazer o LED piscar a cada segundo. Aqui est\u00e1 um exemplo para ajud\u00e1-lo. Acesse Aqui </p>"},{"location":"aulas/iot/lab9/index.html","title":"Lab02","text":""},{"location":"aulas/iot/lab9/index.html#o-que-vamos-ver-neste-lab","title":"O que vamos ver neste lab?","text":"<ul> <li>Raspberry Pi: <ul> <li>Conhecendo os pinos</li> <li>Usando a biblioteca RPI.GPIO </li> </ul> </li> </ul>"},{"location":"aulas/iot/lab9/index.html#conhecendo-os-pinos-da-raspberry-pi","title":"Conhecendo os pinos da Raspberry Pi","text":"<p>Podemos utilizar a Raspberry Pi para conectar sensores e atuadores, de forma semelhante como foi feito utilizando o Arduino, para isso utilizamos os barramento de pinos da Raspberry Pi chamado de GPIO (General Purpose Input Output). Ao todo s\u00e3o 40 pinos (para RPI 2 ou superior) e de forma geral cada pino possui uma fun\u00e7\u00e3o ou caracteristica especifica.</p> <p>Warning</p> <p>Cuidado: Devemos ter aten\u00e7\u00e3o para n\u00e3o conectar os perifericos na placa de forma incorreta. Existe risco de queimar a Raspberry Pi.  </p> <p>A imagem abaixo \u00e9 um guia simples para cada pino. Parece complicado na primeira vez, mas \u00e9 tranquilo.</p> <p></p> <p>Vamos conhecer o que \u00e9 cada pino:</p> <pre><code>- Pinos de Alimenta\u00e7\u00e3o: \n    - 3.3V (ao todo 2 pinos)\n    - 5V (ao todo 2 pinos)\n    - GND/Ground/0V (ao todo 8 pinos)\n\n- Pinos de interface:\n    - GPIO (General purpose input and output): S\u00e3o os pinos de entrada/saida. A tens\u00e3o de saida \u00e9 de 3.3V.\n    - I2C/SPI/UART: Protocolos de comunica\u00e7\u00e3o especificos utilizados para realizar a interface m\u00f3dulos epecificos com a Raspberry Pi.\n</code></pre> <p>Warning</p> <p>Aten\u00e7\u00e3o: Observe a correla\u00e7\u00e3o dos pinos para n\u00e3o ligar invertido. </p> <p>Exercise</p> <p>Quantos pinos GPIO est\u00e3o disponiveis?</p> <p>Progress</p> <p>Continuar...</p>"},{"location":"aulas/iot/lab9/index.html#configurando-os-gpios","title":"Configurando os GPIOs","text":"<p>No final do lab07 montamos um simples pisca led e programamos configurando os valores dos registradores. Existem formas mais simples de programar os GPIOs da rasbperry pi, vamos programar em Python :) </p> <p>Vamos utilizara biblioteca <code>RPI.GPIO</code>, que permite de forma simples configurar e usar os GPIOs com script em Python, vamos preparar o nosso ambiente de desenvolvimento:</p> <p>Exercise</p> <ul> <li> <p>Inicialize a Raspberry Pi. (modo Desktop ou SSH).</p> <ul> <li>Se tiver d\u00favida de como fazer, volte para o lab07.</li> </ul> </li> <li> <p>Abra o terminal da raspberry pi.</p> </li> <li> <p>Certifique-se de estar com acesso a internet.</p> </li> </ul> <p>No terminal da raspberry pi, atualize os reposit\u00f3rios:</p> <pre><code>sudo apt update\n</code></pre> <p>Em seguida, tente instalar o pacote RPi.GPIO: A documenta\u00e7\u00e3o da biblioteca est\u00e1 disponivel no aqui.</p> <pre><code>sudo apt install rpi.gpio\n</code></pre> <p>Se ainda n\u00e3o estiver instalado, ser\u00e1 instalado. Se j\u00e1 estiver instalado, ser\u00e1 atualizado se uma vers\u00e3o mais recente estiver dispon\u00edvel.</p> <p>Progress</p> <p>Continuar...</p>"},{"location":"aulas/iot/lab9/index.html#conhecendo-a-biblioteca-rpigpio","title":"Conhecendo a biblioteca RPi.GPIO","text":"<p>\u00c9 uma biblioteca simples de usar e vamos ver as principais fun\u00e7\u00f5es da RPi.GPIO atrav\u00e9s do c\u00f3digo de exemplo abaixo:</p> <ul> <li> <p><code>GPIO.setmode()</code> = Define o modo de acesso aos pino da raspberry pi, existem 2 modos de definir a mesma coisa:</p> <ul> <li>GPIO.BOARD  = Posi\u00e7\u00e3o f\u00edsica do pino na raspberry pi</li> <li>GPIO.BCM    = Numero ap\u00f3s GPIOxx</li> </ul> </li> </ul> <p>exemplo: BOARD 11 = GPIO17</p> <ul> <li> <p><code>GPIO.setup()</code> = Define a fun\u00e7\u00e3o do pino, entrada (GPIO.IN) ou saida (GPIO.OUT)</p> </li> <li> <p><code>GPIO.output()</code> = Define o estado do pino definido como saida em nivel logico baixo (GPIO.LOW) ou alto (GPIO.HIGH)</p> </li> <li> <p><code>GPIO.input()</code> = Faz a leitura do estado do pino definido como entrada. Geralmente quando usamos um pino como entrada configuramos no setup o parametro pull_up_down (como exemplo: GPIO.setup(18, GPIO.IN, pull_up_down=GPIO.PUD_UP))</p> </li> </ul> <p>Exercise</p> <p>Monte o circuito abaixo:</p> <p></p> <ul> <li>No terminal da RPI, digite:</li> </ul> <pre><code>cd ~\nmkdir src\ncd src\ntouch blinkled.py  \n</code></pre> <ul> <li>Criamos um diretorio chamado src e um arquivo python chamado blinkled.py</li> <li>Abra o arquivo blinkled.py e escreva o c\u00f3digo abaixo.</li> <li>Para abrir o arquivo digite: nano blinkled.py</li> <li>Ap\u00f3s digitar o c\u00f3digo python, salve e feche o arquivo: Ctlr+X &gt;&gt;&gt; Y </li> <li> <p>Vamos rodar nosso c\u00f3digo python, no terminal digite:</p> <ul> <li>python blinkled.py</li> </ul> </li> <li> <p>Se tudo deu certo, o led est\u00e1 piscando. :)</p> <ul> <li>para interromper o c\u00f3digo aperte Ctrl+C.</li> </ul> </li> </ul> <p>Warning</p> <p>Os 2 c\u00f3digos realizam a mesma fun\u00e7\u00e3o, a diferen\u00e7a est\u00e1 apenas no setmode. Escolha um dos c\u00f3digos para testar. </p> <pre><code>import RPi.GPIO as GPIO  ### import da biblioteca gpio\nimport time\n\n# usando o a posi\u00e7\u00e3o fis\u00edca do pino na raspberry pi\nGPIO.setmode(GPIO.BOARD)\n\n# configura o pino fisico 11 como saida\nGPIO.setup(11, GPIO.OUT)\n\nwhille True:  \n    # escreve no pino 11 nivel logico alto\n    GPIO.output(11, GPIO.HIGH)\n    time.sleep(1) # delay de 1s\n\n    # escreve no pino 11 nivel logico baixo\n    GPIO.output(11, GPIO.LOW)\n    time.sleep(1) # delay de 1s\n\nGPIO.cleanup()  # Limpa configura\u00e7\u00e3o finaliza o programa\n</code></pre> <pre><code>import RPi.GPIO as GPIO  ### import da biblioteca gpio\n\n# usando o numero ap\u00f3s GPIOxx da raspberry pi\nGPIO.setmode(GPIO.BCM)\n\n# configura o GPIO17 como saida\nGPIO.setup(17, GPIO.OUT)\n\nwhille True:  \n    # escreve no GPIO17 nivel logico alto\n    GPIO.output(17, GPIO.HIGH)\n    time.sleep(1) # delay de 1s\n\n    # escreve no GPIO17 nivel logico baixo\n    GPIO.output(17, GPIO.LOW)\n    time.sleep(1) # delay de 1s\n\nGPIO.cleanup()  # Limpa configura\u00e7\u00e3o finaliza o programa\n</code></pre>"},{"location":"aulas/iot/lab9/index.html#desafios","title":"Desafios","text":"<p>Agora que j\u00e1 entendemos a estrutura b\u00e1sica do script python, fa\u00e7a os <code>Desafios</code> abaixo.</p> <p>Exercise</p> <p>Sem\u00e1faro de transito: </p> <pre><code>- Monte um circuito com 3 leds (1 verde, 1 amarelo, 1 vermelho);\n- crie um novo script chamado semaforo.py;\n- Escreva um c\u00f3digo que ir\u00e1 acender os leds na sequ\u00eancia e intervalo:\n    - Verde (5segundos)\n    - Amarelo (3segundos)\n    - Vermelho (6segundos)\n    - loop (volta para o verde)\n</code></pre> <p>Exercise</p> <p>leitura de bot\u00e3o e Led: </p> <ul> <li>Monte o circuito: </li> </ul> <p></p> <ul> <li>Escreva um c\u00f3digo que:<ul> <li>Enquanto nenhum bot\u00e3o for pressionado, os leds ficam apagados;</li> <li>Se o bot\u00e3o1 for pressionado:<ul> <li>os leds acendem na sequ\u00eancia: Verde - Amarelo - Vermelho</li> </ul> </li> <li>Se o bot\u00e3o2 for pressionado:<ul> <li>os leds acendem na sequencia: Vermelho - Amarelo - Verde </li> </ul> </li> </ul> </li> </ul> <p>Dica: Geralmente quando usamos algum pino como entrada configuramos no setup o parametro pull_up_down (como exemplo: GPIO.setup(18, GPIO.IN, pull_up_down=GPIO.PUD_UP) ou GPIO.setup(18, GPIO.IN, pull_up_down=GPIO.PUD_DOWN).</p> <p>Exercise</p> <p>Sensor de temperatura: Para quem tiver curiosidade pode dar uma olhada como utilizar o sensor de temperatura DTH11 neste link.</p> <p>Exercise</p> <p></p> <p>Desenvolva um Sensor de estacionamento veicular. A id\u00e9ia \u00e9 simples. Vamos utilizar 1 sensor de dist\u00e2ncia ultrass\u00f4nico e 3 leds de cores difenciadas. Parte do problema j\u00e1 est\u00e1 resolvido voc\u00ea pode acessar o tutorial adaptar o c\u00f3digo do Sensor HC-SR04 e implementar a logica dos led.</p>"},{"location":"aulas/iot/labnovo/visao.html","title":"Laborat\u00f3rio - Comunica\u00e7\u00e3o Arduino-Python com OpenCV","text":""},{"location":"aulas/iot/labnovo/visao.html#visao-geral","title":"Vis\u00e3o Geral","text":"<p>Neste laborat\u00f3rio, voc\u00ea aprender\u00e1 a estabelecer comunica\u00e7\u00e3o bidirecional entre o Arduino e um computador executando Python com OpenCV. Este tipo de integra\u00e7\u00e3o permite que voc\u00ea crie sistemas interativos onde o processamento de imagem pode controlar atuadores f\u00edsicos, criando uma ponte entre o mundo virtual e o real.</p>"},{"location":"aulas/iot/labnovo/visao.html#objetivos-de-aprendizado","title":"Objetivos de Aprendizado","text":"<p>Ao final deste laborat\u00f3rio, voc\u00ea ser\u00e1 capaz de: - Estabelecer comunica\u00e7\u00e3o serial entre Arduino e Python - Processar imagens em tempo real com OpenCV - Implementar detec\u00e7\u00e3o de cores e movimento em v\u00eddeo - Enviar comandos baseados em eventos visuais para o Arduino - Criar um sistema interativo controlado por vis\u00e3o computacional</p>"},{"location":"aulas/iot/labnovo/visao.html#materiais-necessarios","title":"Materiais Necess\u00e1rios","text":"<ul> <li>Placa Arduino (Uno ou similar)</li> <li>Cabo USB</li> <li>3 LEDs (vermelho, verde e azul)</li> <li>3 Resistores de 220\u03a9</li> <li>Webcam ou c\u00e2mera integrada do notebook</li> <li>Breadboard e jumpers</li> <li>Computador com Python, PySerial e OpenCV instalados</li> </ul>"},{"location":"aulas/iot/labnovo/visao.html#1-fundamentos-da-comunicacao-serial-arduino-python","title":"1. Fundamentos da Comunica\u00e7\u00e3o Serial Arduino-Python","text":"<p>A comunica\u00e7\u00e3o entre Arduino e Python \u00e9 estabelecida atrav\u00e9s da porta serial, permitindo a troca de dados em ambas as dire\u00e7\u00f5es:</p> <ul> <li>O Arduino envia dados de sensores ou estados de dispositivos</li> <li>O Python envia comandos para controlar atuadores ou solicitar informa\u00e7\u00f5es</li> </ul>"},{"location":"aulas/iot/labnovo/visao.html#11-preparacao-do-ambiente","title":"1.1 Prepara\u00e7\u00e3o do Ambiente","text":"<p>Antes de come\u00e7ar, instale as bibliotecas Python necess\u00e1rias:</p> <pre><code>pip install pyserial opencv-python numpy\n</code></pre>"},{"location":"aulas/iot/labnovo/visao.html#12-esquema-de-montagem-do-circuito","title":"1.2 Esquema de Montagem do Circuito","text":"<p>Monte o seguinte circuito no Arduino:</p> <p></p> <p>Conex\u00f5es: - LED Vermelho: Pino 9 (com resistor de 220\u03a9) - LED Verde: Pino 10 (com resistor de 220\u03a9) - LED Azul: Pino 11 (com resistor de 220\u03a9)</p>"},{"location":"aulas/iot/labnovo/visao.html#2-programacao-do-arduino","title":"2. Programa\u00e7\u00e3o do Arduino","text":"<p>O c\u00f3digo Arduino abaixo estabelece a comunica\u00e7\u00e3o serial e permite controlar os LEDs atrav\u00e9s de comandos recebidos:</p> <pre><code>// Defini\u00e7\u00e3o dos pinos\nconst int ledVermelho = 9;\nconst int ledVerde = 10;\nconst int ledAzul = 11;\n\nString comandoRecebido = \"\";\nboolean comandoCompleto = false;\n\nvoid setup() {\n  // Configura\u00e7\u00e3o dos pinos como sa\u00edda\n  pinMode(ledVermelho, OUTPUT);\n  pinMode(ledVerde, OUTPUT);\n  pinMode(ledAzul, OUTPUT);\n\n  // Inicia a comunica\u00e7\u00e3o serial\n  Serial.begin(9600);\n  Serial.println(\"Arduino pronto para receber comandos!\");\n\n  // Teste inicial dos LEDs\n  testarLEDs();\n}\n\nvoid loop() {\n  // Verifica se h\u00e1 dados dispon\u00edveis na porta serial\n  if (Serial.available() &gt; 0) {\n    // L\u00ea o caractere recebido\n    char caracterRecebido = Serial.read();\n\n    // Se o caractere for uma quebra de linha, o comando est\u00e1 completo\n    if (caracterRecebido == '\\n') {\n      comandoCompleto = true;\n    } else {\n      // Adiciona o caractere ao comando atual\n      comandoRecebido += caracterRecebido;\n    }\n  }\n\n  // Se o comando estiver completo, processa-o\n  if (comandoCompleto) {\n    processarComando(comandoRecebido);\n\n    // Limpa o comando e reseta a flag\n    comandoRecebido = \"\";\n    comandoCompleto = false;\n  }\n}\n\n// Fun\u00e7\u00e3o para processar o comando recebido\nvoid processarComando(String comando) {\n  comando.trim(); // Remove espa\u00e7os e quebras de linha extras\n\n  Serial.print(\"Comando recebido: \");\n  Serial.println(comando);\n\n  if (comando == \"VERMELHO_ON\") {\n    digitalWrite(ledVermelho, HIGH);\n    Serial.println(\"LED Vermelho ligado\");\n  } \n  else if (comando == \"VERMELHO_OFF\") {\n    digitalWrite(ledVermelho, LOW);\n    Serial.println(\"LED Vermelho desligado\");\n  }\n  else if (comando == \"VERDE_ON\") {\n    digitalWrite(ledVerde, HIGH);\n    Serial.println(\"LED Verde ligado\");\n  }\n  else if (comando == \"VERDE_OFF\") {\n    digitalWrite(ledVerde, LOW);\n    Serial.println(\"LED Verde desligado\");\n  }\n  else if (comando == \"AZUL_ON\") {\n    digitalWrite(ledAzul, HIGH);\n    Serial.println(\"LED Azul ligado\");\n  }\n  else if (comando == \"AZUL_OFF\") {\n    digitalWrite(ledAzul, LOW);\n    Serial.println(\"LED Azul desligado\");\n  }\n  else if (comando == \"TODOS_ON\") {\n    digitalWrite(ledVermelho, HIGH);\n    digitalWrite(ledVerde, HIGH);\n    digitalWrite(ledAzul, HIGH);\n    Serial.println(\"Todos os LEDs ligados\");\n  }\n  else if (comando == \"TODOS_OFF\") {\n    digitalWrite(ledVermelho, LOW);\n    digitalWrite(ledVerde, LOW);\n    digitalWrite(ledAzul, LOW);\n    Serial.println(\"Todos os LEDs desligados\");\n  }\n  else if (comando == \"STATUS\") {\n    enviarStatus();\n  }\n  else {\n    Serial.println(\"Comando n\u00e3o reconhecido\");\n  }\n}\n\n// Fun\u00e7\u00e3o para testar os LEDs\nvoid testarLEDs() {\n  // Testa cada LED em sequ\u00eancia\n  digitalWrite(ledVermelho, HIGH);\n  delay(500);\n  digitalWrite(ledVermelho, LOW);\n\n  digitalWrite(ledVerde, HIGH);\n  delay(500);\n  digitalWrite(ledVerde, LOW);\n\n  digitalWrite(ledAzul, HIGH);\n  delay(500);\n  digitalWrite(ledAzul, LOW);\n\n  // Pisca todos juntos\n  for (int i = 0; i &lt; 3; i++) {\n    digitalWrite(ledVermelho, HIGH);\n    digitalWrite(ledVerde, HIGH);\n    digitalWrite(ledAzul, HIGH);\n    delay(200);\n    digitalWrite(ledVermelho, LOW);\n    digitalWrite(ledVerde, LOW);\n    digitalWrite(ledAzul, LOW);\n    delay(200);\n  }\n}\n\n// Envia o status dos LEDs via serial\nvoid enviarStatus() {\n  Serial.print(\"STATUS:\");\n  Serial.print(digitalRead(ledVermelho));\n  Serial.print(\",\");\n  Serial.print(digitalRead(ledVerde));\n  Serial.print(\",\");\n  Serial.println(digitalRead(ledAzul));\n}\n</code></pre>"},{"location":"aulas/iot/labnovo/visao.html#3-script-python-para-teste-de-comunicacao","title":"3. Script Python para Teste de Comunica\u00e7\u00e3o","text":"<p>Antes de implementar a detec\u00e7\u00e3o por OpenCV, vamos testar a comunica\u00e7\u00e3o com um script Python simples:</p> <pre><code>import serial\nimport time\n\n# Configura\u00e7\u00e3o da porta serial\n# Em Windows, use 'COMx' (ex: 'COM3')\n# Em Linux/Mac, use '/dev/ttyUSBx' ou '/dev/ttyACMx' (ex: '/dev/ttyACM0')\nporta_serial = '/dev/ttyACM0'  # Ajuste para sua porta\n\ntry:\n    # Abre a conex\u00e3o serial\n    arduino = serial.Serial(porta_serial, 9600, timeout=1)\n    print(f\"Conectado \u00e0 porta {porta_serial}\")\n    time.sleep(2)  # Espera a conex\u00e3o estabilizar\n\n    # L\u00ea a mensagem inicial do Arduino\n    linha = arduino.readline().decode('utf-8').strip()\n    print(f\"Arduino diz: {linha}\")\n\n    # Testa os comandos\n    comandos = [\n        \"VERMELHO_ON\", \"VERDE_ON\", \"AZUL_ON\",\n        \"TODOS_OFF\", \"STATUS\", \"TODOS_ON\",\n        \"VERMELHO_OFF\", \"VERDE_OFF\", \"AZUL_OFF\"\n    ]\n\n    for comando in comandos:\n        print(f\"\\nEnviando comando: {comando}\")\n        arduino.write(f\"{comando}\\n\".encode())\n        time.sleep(1)\n\n        # L\u00ea a resposta do Arduino\n        while arduino.in_waiting &gt; 0:\n            resposta = arduino.readline().decode('utf-8').strip()\n            print(f\"Resposta: {resposta}\")\n\n        time.sleep(1)\n\nexcept serial.SerialException as e:\n    print(f\"Erro de conex\u00e3o serial: {e}\")\nexcept KeyboardInterrupt:\n    print(\"\\nPrograma encerrado pelo usu\u00e1rio\")\nfinally:\n    # Fecha a conex\u00e3o serial se estiver aberta\n    if 'arduino' in locals() and arduino.is_open:\n        arduino.close()\n        print(\"Conex\u00e3o serial fechada\")\n</code></pre>"},{"location":"aulas/iot/labnovo/visao.html#instrucoes-para-execucao","title":"Instru\u00e7\u00f5es para execu\u00e7\u00e3o:","text":"<ol> <li>Carregue o c\u00f3digo no Arduino</li> <li>Identifique a porta COM do Arduino (verificando em Ferramentas &gt; Porta no Arduino IDE)</li> <li>Ajuste a vari\u00e1vel <code>porta_serial</code> no script Python</li> <li>Execute o script e verifique se os LEDs respondem aos comandos</li> </ol>"},{"location":"aulas/iot/labnovo/visao.html#4-detector-de-cores-com-opencv","title":"4. Detector de Cores com OpenCV","text":"<p>Agora vamos criar um sistema que detecta cores na c\u00e2mera e controla os LEDs do Arduino:</p> <pre><code>import cv2\nimport numpy as np\nimport serial\nimport time\nimport argparse\n\n# Fun\u00e7\u00e3o para encontrar a porta serial automaticamente\ndef encontrar_arduino():\n    import serial.tools.list_ports\n\n    portas = list(serial.tools.list_ports.comports())\n    for p in portas:\n        if 'Arduino' in p.description or 'CH340' in p.description or 'ACM' in p.device:\n            return p.device\n    return None\n\n# Parser de argumentos\nparser = argparse.ArgumentParser(description='Controle de LEDs do Arduino com detec\u00e7\u00e3o de cores')\nparser.add_argument('--porta', type=str, default=None, help='Porta serial do Arduino (ex: COM3, /dev/ttyACM0)')\nargs = parser.parse_args()\n\n# Configura\u00e7\u00e3o da porta serial\nporta_serial = args.porta\nif porta_serial is None:\n    porta_serial = encontrar_arduino()\n    if porta_serial is None:\n        print(\"Arduino n\u00e3o encontrado. Especifique a porta manualmente com --porta\")\n        exit(1)\n\nprint(f\"Tentando conectar na porta {porta_serial}...\")\n\n# Conecta ao Arduino\ntry:\n    arduino = serial.Serial(porta_serial, 9600, timeout=1)\n    print(f\"Conectado \u00e0 porta {porta_serial}\")\n    time.sleep(2)  # Espera a inicializa\u00e7\u00e3o\nexcept serial.SerialException as e:\n    print(f\"Erro ao conectar: {e}\")\n    exit(1)\n\n# Inicializa a c\u00e2mera\ncap = cv2.VideoCapture(0)\nif not cap.isOpened():\n    print(\"Erro ao abrir a c\u00e2mera\")\n    arduino.close()\n    exit(1)\n\n# Status dos LEDs\nled_status = {\"vermelho\": False, \"verde\": False, \"azul\": False}\n\n# Faixas de cores HSV\n# Vermelho (devido \u00e0 natureza circular do HSV, dividimos em duas faixas)\nvermelho_baixo1 = np.array([0, 100, 100])\nvermelho_alto1 = np.array([10, 255, 255])\nvermelho_baixo2 = np.array([160, 100, 100])\nvermelho_alto2 = np.array([180, 255, 255])\n\n# Verde\nverde_baixo = np.array([40, 100, 100])\nverde_alto = np.array([80, 255, 255])\n\n# Azul\nazul_baixo = np.array([100, 100, 100])\nazul_alto = np.array([140, 255, 255])\n\nprint(\"Sistema iniciado! Mostre objetos coloridos para a c\u00e2mera.\")\nprint(\"Pressione 'q' para sair.\")\n\n# Para evitar enviar comandos repetidos\nultimo_comando = \"\"\nultimo_envio = time.time()\n\ntry:\n    while True:\n        # Captura o frame\n        ret, frame = cap.read()\n        if not ret:\n            print(\"Erro ao capturar frame\")\n            break\n\n        # Espelha horizontalmente para interface mais natural\n        frame = cv2.flip(frame, 1)\n\n        # Converte para HSV\n        hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n\n        # Cria m\u00e1scaras para cada cor\n        mascara_vermelho1 = cv2.inRange(hsv, vermelho_baixo1, vermelho_alto1)\n        mascara_vermelho2 = cv2.inRange(hsv, vermelho_baixo2, vermelho_alto2)\n        mascara_vermelho = cv2.bitwise_or(mascara_vermelho1, mascara_vermelho2)\n\n        mascara_verde = cv2.inRange(hsv, verde_baixo, verde_alto)\n        mascara_azul = cv2.inRange(hsv, azul_baixo, azul_alto)\n\n        # Aplica opera\u00e7\u00f5es morfol\u00f3gicas para reduzir ru\u00eddo\n        kernel = np.ones((5, 5), np.uint8)\n        mascara_vermelho = cv2.morphologyEx(mascara_vermelho, cv2.MORPH_OPEN, kernel)\n        mascara_verde = cv2.morphologyEx(mascara_verde, cv2.MORPH_OPEN, kernel)\n        mascara_azul = cv2.morphologyEx(mascara_azul, cv2.MORPH_OPEN, kernel)\n\n        # Encontra contornos\n        contornos_vermelho, _ = cv2.findContours(mascara_vermelho, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n        contornos_verde, _ = cv2.findContours(mascara_verde, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n        contornos_azul, _ = cv2.findContours(mascara_azul, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n\n        # Analisa contornos e determina a\u00e7\u00f5es\n        comando = None\n\n        # Verifica vermelho\n        area_vermelha = 0\n        for c in contornos_vermelho:\n            area = cv2.contourArea(c)\n            area_vermelha += area\n            if area &gt; 5000:  # \u00c1rea m\u00ednima para considerar\n                cv2.drawContours(frame, [c], 0, (0, 0, 255), 3)\n                if not led_status[\"vermelho\"]:\n                    comando = \"VERMELHO_ON\"\n                    led_status[\"vermelho\"] = True\n\n        if area_vermelha &lt; 3000 and led_status[\"vermelho\"]:\n            comando = \"VERMELHO_OFF\"\n            led_status[\"vermelho\"] = False\n\n        # Verifica verde\n        area_verde = 0\n        for c in contornos_verde:\n            area = cv2.contourArea(c)\n            area_verde += area\n            if area &gt; 5000:\n                cv2.drawContours(frame, [c], 0, (0, 255, 0), 3)\n                if not led_status[\"verde\"]:\n                    comando = \"VERDE_ON\"\n                    led_status[\"verde\"] = True\n\n        if area_verde &lt; 3000 and led_status[\"verde\"]:\n            comando = \"VERDE_OFF\"\n            led_status[\"verde\"] = False\n\n        # Verifica azul\n        area_azul = 0\n        for c in contornos_azul:\n            area = cv2.contourArea(c)\n            area_azul += area\n            if area &gt; 5000:\n                cv2.drawContours(frame, [c], 0, (255, 0, 0), 3)\n                if not led_status[\"azul\"]:\n                    comando = \"AZUL_ON\"\n                    led_status[\"azul\"] = True\n\n        if area_azul &lt; 3000 and led_status[\"azul\"]:\n            comando = \"AZUL_OFF\"\n            led_status[\"azul\"] = False\n\n        # Envia comando se for diferente do \u00faltimo e tiver passado pelo menos 0.5 segundos\n        tempo_atual = time.time()\n        if comando and (comando != ultimo_comando or tempo_atual - ultimo_envio &gt; 1.0):\n            arduino.write(f\"{comando}\\n\".encode())\n            ultimo_comando = comando\n            ultimo_envio = tempo_atual\n            print(f\"Comando enviado: {comando}\")\n\n            # L\u00ea resposta do Arduino\n            time.sleep(0.1)  # Pequena pausa para garantir que o Arduino tenha tempo de responder\n            while arduino.in_waiting &gt; 0:\n                resposta = arduino.readline().decode('utf-8').strip()\n                print(f\"Arduino: {resposta}\")\n\n        # Exibe informa\u00e7\u00f5es na imagem\n        cv2.putText(frame, f\"LED Vermelho: {led_status['vermelho']}\", (10, 30), \n                    cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)\n        cv2.putText(frame, f\"LED Verde: {led_status['verde']}\", (10, 60), \n                    cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)\n        cv2.putText(frame, f\"LED Azul: {led_status['azul']}\", (10, 90), \n                    cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 0, 0), 2)\n\n        # Exibe um quadro de refer\u00eancia para colocar os objetos\n        cv2.rectangle(frame, (int(frame.shape[1]/2)-100, int(frame.shape[0]/2)-100),\n                     (int(frame.shape[1]/2)+100, int(frame.shape[0]/2)+100), (255, 255, 255), 2)\n        cv2.putText(frame, \"Coloque objetos coloridos aqui\", \n                   (int(frame.shape[1]/2)-140, int(frame.shape[0]/2)-110),\n                   cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 2)\n\n        # Mostra o resultado\n        cv2.imshow(\"Detector de Cores\", frame)\n\n        # Sai com 'q'\n        if cv2.waitKey(1) &amp; 0xFF == ord('q'):\n            break\n\nexcept KeyboardInterrupt:\n    print(\"\\nPrograma encerrado pelo usu\u00e1rio\")\nexcept Exception as e:\n    print(f\"Erro: {e}\")\nfinally:\n    # Desliga todos os LEDs antes de sair\n    arduino.write(\"TODOS_OFF\\n\".encode())\n    time.sleep(0.5)\n\n    # Libera os recursos\n    cap.release()\n    cv2.destroyAllWindows()\n    arduino.close()\n    print(\"Programa finalizado\")\n</code></pre>"},{"location":"aulas/iot/labnovo/visao.html#5-detector-de-movimentos","title":"5. Detector de Movimentos","text":"<p>Como desafio adicional, implemente um sistema que detecta movimento e controla os LEDs:</p> <pre><code>import cv2\nimport numpy as np\nimport serial\nimport time\nimport argparse\nfrom collections import deque\n\n# Fun\u00e7\u00e3o para encontrar a porta serial automaticamente\ndef encontrar_arduino():\n    import serial.tools.list_ports\n\n    portas = list(serial.tools.list_ports.comports())\n    for p in portas:\n        if 'Arduino' in p.description or 'CH340' in p.description or 'ACM' in p.device:\n            return p.device\n    return None\n\n# Parser de argumentos\nparser = argparse.ArgumentParser(description='Detector de movimentos para Arduino')\nparser.add_argument('--porta', type=str, default=None, help='Porta serial do Arduino')\nparser.add_argument('--sensibilidade', type=float, default=20, help='Sensibilidade do detector (5-50)')\nargs = parser.parse_args()\n\n# Configura\u00e7\u00e3o da porta serial\nporta_serial = args.porta\nif porta_serial is None:\n    porta_serial = encontrar_arduino()\n    if porta_serial is None:\n        print(\"Arduino n\u00e3o encontrado. Especifique a porta manualmente com --porta\")\n        exit(1)\n\n# Sensibilidade ajust\u00e1vel (maior = mais sens\u00edvel)\nsensibilidade = max(5, min(50, args.sensibilidade))\nprint(f\"Sensibilidade: {sensibilidade}\")\n\n# Conecta ao Arduino\ntry:\n    arduino = serial.Serial(porta_serial, 9600, timeout=1)\n    print(f\"Conectado \u00e0 porta {porta_serial}\")\n    time.sleep(2)  # Espera a inicializa\u00e7\u00e3o\nexcept serial.SerialException as e:\n    print(f\"Erro ao conectar: {e}\")\n    exit(1)\n\n# Inicializa a c\u00e2mera\ncap = cv2.VideoCapture(0)\nif not cap.isOpened():\n    print(\"Erro ao abrir a c\u00e2mera\")\n    arduino.close()\n    exit(1)\n\n# Hist\u00f3rico dos \u00faltimos n\u00edveis de movimento\nhistorico_movimentos = deque(maxlen=10)\ntodos_leds_ligados = False\n\n# Captura o primeiro frame para compara\u00e7\u00e3o\nret, frame1 = cap.read()\nif not ret:\n    print(\"Erro ao capturar o frame inicial\")\n    cap.release()\n    arduino.close()\n    exit(1)\n\n# Converte para escala de cinza e aplica blur\ncinza1 = cv2.cvtColor(frame1, cv2.COLOR_BGR2GRAY)\ncinza1 = cv2.GaussianBlur(cinza1, (21, 21), 0)\n\nprint(\"Sistema de detec\u00e7\u00e3o de movimento iniciado!\")\nprint(\"Pressione 'q' para sair.\")\n\ntry:\n    while True:\n        # Captura o pr\u00f3ximo frame\n        ret, frame2 = cap.read()\n        if not ret:\n            print(\"Erro ao capturar frame\")\n            break\n\n        # Converte para escala de cinza e aplica blur\n        cinza2 = cv2.cvtColor(frame2, cv2.COLOR_BGR2GRAY)\n        cinza2 = cv2.GaussianBlur(cinza2, (21, 21), 0)\n\n        # Calcula a diferen\u00e7a entre os frames\n        frameDelta = cv2.absdiff(cinza1, cinza2)\n        thresh = cv2.threshold(frameDelta, 25, 255, cv2.THRESH_BINARY)[1]\n\n        # Dilata a imagem para preencher buracos\n        thresh = cv2.dilate(thresh, None, iterations=2)\n\n        # Encontra contornos\n        contornos, _ = cv2.findContours(thresh.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n\n        # Vari\u00e1vel para medir quantidade de movimento\n        movimento_total = 0\n\n        # Processa cada contorno\n        for contorno in contornos:\n            area = cv2.contourArea(contorno)\n            movimento_total += area\n\n            # Se o contorno \u00e9 maior que um certo tamanho, consideramos movimento significativo\n            if area &gt; 500:\n                (x, y, w, h) = cv2.boundingRect(contorno)\n                cv2.rectangle(frame2, (x, y), (x + w, y + h), (0, 255, 0), 2)\n\n        # Atualiza o hist\u00f3rico\n        historico_movimentos.append(movimento_total)\n\n        # Calcula a m\u00e9dia de movimento recente\n        movimento_medio = sum(historico_movimentos) / len(historico_movimentos) if historico_movimentos else 0\n\n        # Determina a\u00e7\u00e3o com base no n\u00edvel de movimento\n        if movimento_medio &gt; sensibilidade * 1000:  # Movimento significativo\n            if not todos_leds_ligados:\n                arduino.write(\"TODOS_ON\\n\".encode())\n                todos_leds_ligados = True\n                print(\"Movimento detectado - LEDs LIGADOS\")\n        elif todos_leds_ligados and movimento_medio &lt; sensibilidade * 500:  # Pouco movimento\n            arduino.write(\"TODOS_OFF\\n\".encode())\n            todos_leds_ligados = False\n            print(\"Movimento cessou - LEDs DESLIGADOS\")\n\n        # Se houver movimento moderado, pisca o LED azul\n        if sensibilidade * 500 &lt;= movimento_medio &lt; sensibilidade * 1000:\n            if time.time() % 1 &lt; 0.5:  # Pisca a cada meio segundo\n                arduino.write(\"AZUL_ON\\n\".encode())\n            else:\n                arduino.write(\"AZUL_OFF\\n\".encode())\n\n        # Exibe informa\u00e7\u00f5es na tela\n        cv2.putText(frame2, f\"Movimento: {int(movimento_medio)}\", (10, 20),\n                    cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 2)\n\n        # Adiciona uma barra de movimento\n        barra_comprimento = int(min(movimento_medio / 100, frame2.shape[1]-20))\n        cv2.rectangle(frame2, (10, 40), (10 + barra_comprimento, 60), (0, 0, 255), -1)\n\n        # Status dos LEDs\n        cv2.putText(frame2, f\"LEDs: {'LIGADOS' if todos_leds_ligados else 'DESLIGADOS'}\", \n                   (10, 80), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n\n        # Exibe o frame\n        cv2.imshow(\"Detector de Movimento\", frame2)\n        cv2.imshow(\"Threshold\", thresh)\n\n        # Atualiza o frame anterior\n        cinza1 = cinza2\n\n        # Verifica se o usu\u00e1rio quer sair\n        key = cv2.waitKey(1) &amp; 0xFF\n        if key == ord('q'):\n            break\n        # Aumenta sensibilidade\n        elif key == ord('+') or key == ord('='):\n            sensibilidade = min(50, sensibilidade + 2)\n            print(f\"Sensibilidade aumentada para: {sensibilidade}\")\n        # Diminui sensibilidade\n        elif key == ord('-'):\n            sensibilidade = max(5, sensibilidade - 2)\n            print(f\"Sensibilidade reduzida para: {sensibilidade}\")\n\nexcept KeyboardInterrupt:\n    print(\"\\nPrograma encerrado pelo usu\u00e1rio\")\nexcept Exception as e:\n    print(f\"Erro: {e}\")\nfinally:\n    # Desliga todos os LEDs\n    arduino.write(\"TODOS_OFF\\n\".encode())\n    time.sleep(0.5)\n\n    # Libera recursos\n    cap.release()\n    cv2.destroyAllWindows()\n    arduino.close()\n    print(\"Programa finalizado\")\n</code></pre>"},{"location":"aulas/iot/labnovo/visao.html#6-desafio-final-controle-por-gestos","title":"6. Desafio Final: Controle por Gestos","text":"<p>Como desafio final, implemente um sistema que reconhece gestos simples da m\u00e3o para controlar os LEDs do Arduino. Para isso, voc\u00ea pode utilizar bibliotecas como MediaPipe ou implementar seu pr\u00f3prio detector baseado em contornos.</p>"},{"location":"aulas/iot/labnovo/visao.html#exemplos-de-gestos","title":"Exemplos de gestos:","text":"<ul> <li>1 dedo: Liga LED Vermelho</li> <li>2 dedos: Liga LED Verde</li> <li>3 dedos: Liga LED Azul</li> <li>5 dedos (m\u00e3o aberta): Liga todos os LEDs</li> <li>Punho fechado: Desliga todos os LEDs</li> </ul>"},{"location":"aulas/iot/labnovo/visao.html#criterios-de-avaliacao","title":"Crit\u00e9rios de Avalia\u00e7\u00e3o","text":"<ol> <li>Comunica\u00e7\u00e3o Arduino-Python: Implementa\u00e7\u00e3o correta da comunica\u00e7\u00e3o bidirecional</li> <li>Detec\u00e7\u00e3o de cores: Calibra\u00e7\u00e3o adequada das faixas de cores e implementa\u00e7\u00e3o da detec\u00e7\u00e3o</li> <li>Detec\u00e7\u00e3o de movimento: Algoritmo de detec\u00e7\u00e3o robusto e parametriz\u00e1vel</li> <li>Interface de usu\u00e1rio: Visualiza\u00e7\u00e3o clara do estado do sistema e feedback visual</li> <li>C\u00f3digo limpo: Organiza\u00e7\u00e3o, coment\u00e1rios e tratamento de erros</li> <li>Relat\u00f3rio: Documenta\u00e7\u00e3o clara do funcionamento do sistema e an\u00e1lise dos resultados</li> </ol>"},{"location":"aulas/iot/labnovo/visao.html#referencias-e-recursos-adicionais","title":"Refer\u00eancias e Recursos Adicionais","text":"<ul> <li>Documenta\u00e7\u00e3o PySerial</li> <li>Tutoriais OpenCV</li> <li>Biblioteca MediaPipe para Detec\u00e7\u00e3o de M\u00e3os</li> <li>Tutorial de Comunica\u00e7\u00e3o Serial Arduino-Python</li> <li>Guia de Detec\u00e7\u00e3o de Cores com OpenCV</li> </ul>"},{"location":"aulas/iot/labnovo/visao.html#entrega","title":"Entrega","text":"<p>Submeta: 1. C\u00f3digo Arduino (.ino) 2. Scripts Python (.py) 3. Relat\u00f3rio com:    - Descri\u00e7\u00e3o da implementa\u00e7\u00e3o    - Capturas de tela ou v\u00eddeos demonstrando o funcionamento    - Desafios encontrados e solu\u00e7\u00f5es adotadas    - Poss\u00edveis melhorias e aplica\u00e7\u00f5es pr\u00e1ticas</p>"},{"location":"aulas/iot/modulos/modulo1.html","title":"M\u00f3dulo 1: Introdu\u00e7\u00e3o ao Arduino IDE e Fundamentos de Programa\u00e7\u00e3o","text":"<p>Bem-vindo ao M\u00f3dulo 1 do curso \"Programa\u00e7\u00e3o em Arduino: Conceitos Fundamentais sem Hardware\". Neste m\u00f3dulo, voc\u00ea ser\u00e1 introduzido ao ambiente de desenvolvimento Arduino IDE e aos fundamentos da programa\u00e7\u00e3o em C/C++ no contexto do Arduino. O foco ser\u00e1 na compreens\u00e3o da estrutura b\u00e1sica de um sketch (programa Arduino) e nos conceitos iniciais de vari\u00e1veis e tipos de dados.</p>"},{"location":"aulas/iot/modulos/modulo1.html#objetivos-do-modulo","title":"Objetivos do M\u00f3dulo","text":"<ul> <li>Instalar e configurar o Arduino IDE.</li> <li>Compreender a estrutura b\u00e1sica de um sketch Arduino.</li> <li>Familiarizar-se com as fun\u00e7\u00f5es <code>setup()</code> e <code>loop()</code>.</li> <li>Escrever e executar o primeiro programa \"Hello, World!\" usando o Monitor Serial.</li> <li>Entender a declara\u00e7\u00e3o e inicializa\u00e7\u00e3o de vari\u00e1veis.</li> <li>Conhecer os tipos de dados primitivos em Arduino: <code>int</code>, <code>float</code>, <code>char</code>, <code>boolean</code>.</li> </ul>"},{"location":"aulas/iot/modulos/modulo1.html#1-introducao-ao-arduino-ide","title":"1. Introdu\u00e7\u00e3o ao Arduino IDE","text":""},{"location":"aulas/iot/modulos/modulo1.html#11-o-que-e-o-arduino-ide","title":"1.1 O que \u00e9 o Arduino IDE?","text":"<p>O Arduino IDE (Integrated Development Environment) \u00e9 um ambiente de desenvolvimento integrado que permite escrever, compilar e enviar c\u00f3digo para placas Arduino. Ele fornece uma interface simples e intuitiva para programar microcontroladores usando uma linguagem baseada em C/C++.</p>"},{"location":"aulas/iot/modulos/modulo1.html#12-instalacao-do-arduino-ide","title":"1.2 Instala\u00e7\u00e3o do Arduino IDE","text":"<p>Passos para instalar o Arduino IDE:</p>"},{"location":"aulas/iot/modulos/modulo1.html#download","title":"Download:","text":"<ol> <li>Acesse o site oficial: https://www.arduino.cc/en/software</li> <li>Escolha a vers\u00e3o compat\u00edvel com o seu sistema operacional (Windows, macOS, Linux).</li> </ol>"},{"location":"aulas/iot/modulos/modulo1.html#instalacao","title":"Instala\u00e7\u00e3o:","text":"<ol> <li>Execute o arquivo baixado e siga as instru\u00e7\u00f5es de instala\u00e7\u00e3o padr\u00e3o.</li> <li>Aceite os termos de licen\u00e7a e selecione os componentes que deseja instalar.</li> </ol>"},{"location":"aulas/iot/modulos/modulo1.html#primeira-execucao","title":"Primeira Execu\u00e7\u00e3o:","text":"<ol> <li>Abra o Arduino IDE ap\u00f3s a instala\u00e7\u00e3o para verificar se est\u00e1 funcionando corretamente.</li> </ol> <p>Nota: Para este curso, n\u00e3o \u00e9 necess\u00e1rio ter uma placa Arduino conectada ao computador, pois utilizaremos o Monitor Serial e simuladores quando necess\u00e1rio.</p>"},{"location":"aulas/iot/modulos/modulo1.html#2-estrutura-basica-de-um-sketch-arduino","title":"2. Estrutura B\u00e1sica de um Sketch Arduino","text":"<p>Um sketch \u00e9 o nome dado a um programa escrito para o Arduino. Todo sketch possui uma estrutura b\u00e1sica composta pelas fun\u00e7\u00f5es <code>setup()</code> e <code>loop()</code>.</p>"},{"location":"aulas/iot/modulos/modulo1.html#21-funcao-setup","title":"2.1 Fun\u00e7\u00e3o <code>setup()</code>","text":"<pre><code>void setup() {\n  // C\u00f3digo a ser executado uma vez no in\u00edcio\n}\n</code></pre> <p>Prop\u00f3sito: A fun\u00e7\u00e3o <code>setup()</code> \u00e9 chamada uma vez quando o programa inicia. \u00c9 usada para inicializar vari\u00e1veis, configurar pinos e iniciar bibliotecas.</p>"},{"location":"aulas/iot/modulos/modulo1.html#22-funcao-loop","title":"2.2 Fun\u00e7\u00e3o <code>loop()</code>","text":"<pre><code>void loop() {\n  // C\u00f3digo a ser executado continuamente\n}\n</code></pre> <p>Prop\u00f3sito: Ap\u00f3s a execu\u00e7\u00e3o da <code>setup()</code>, a fun\u00e7\u00e3o <code>loop()</code> \u00e9 chamada repetidamente em um ciclo infinito. \u00c9 onde o c\u00f3digo principal do programa \u00e9 executado, permitindo que ele responda a eventos e execute tarefas cont\u00ednuas.</p>"},{"location":"aulas/iot/modulos/modulo1.html#23-exemplo-de-estrutura-basica","title":"2.3 Exemplo de Estrutura B\u00e1sica","text":"<pre><code>void setup() {\n  // Inicializa\u00e7\u00f5es\n}\n\nvoid loop() {\n  // C\u00f3digo principal\n}\n</code></pre>"},{"location":"aulas/iot/modulos/modulo1.html#3-primeiro-programa-hello-world-no-monitor-serial","title":"3. Primeiro Programa: \"Hello, World!\" no Monitor Serial","text":"<p>Vamos escrever um programa simples que imprime \"Hello, World!\" no Monitor Serial do Arduino IDE.</p>"},{"location":"aulas/iot/modulos/modulo1.html#31-o-que-e-o-monitor-serial","title":"3.1 O que \u00e9 o Monitor Serial?","text":"<p>O Monitor Serial \u00e9 uma ferramenta integrada no Arduino IDE que permite enviar e receber dados pela porta serial. Ele \u00e9 \u00fatil para depura\u00e7\u00e3o e intera\u00e7\u00e3o com o programa em execu\u00e7\u00e3o.</p>"},{"location":"aulas/iot/modulos/modulo1.html#32-escrevendo-o-programa","title":"3.2 Escrevendo o Programa","text":"<p>Passo 1: Abra o Arduino IDE e crie um novo sketch.</p> <p>Passo 2: Digite o seguinte c\u00f3digo:</p> <pre><code>void setup() {\n  Serial.begin(9600); // Inicia a comunica\u00e7\u00e3o serial a 9600 bps\n}\n\nvoid loop() {\n  Serial.println(\"Hello, World!\"); // Imprime \"Hello, World!\" no Monitor Serial\n  delay(1000); // Aguarda 1 segundo\n}\n</code></pre> <p>Explica\u00e7\u00e3o do C\u00f3digo:</p> <ul> <li><code>Serial.begin(9600);</code> inicia a comunica\u00e7\u00e3o serial na taxa de 9600 bits por segundo (bps).</li> <li><code>Serial.println(\"Hello, World!\");</code> envia a string \"Hello, World!\" seguida de uma nova linha para o Monitor Serial.</li> <li><code>delay(1000);</code> pausa a execu\u00e7\u00e3o por 1000 milissegundos (1 segundo).</li> </ul> <p>Passo 3: Compilar e Executar</p> <ul> <li>Compilar: Clique no bot\u00e3o de verifica\u00e7\u00e3o (\u2714) para compilar o c\u00f3digo e verificar se h\u00e1 erros.</li> <li>Executar: Como n\u00e3o estamos usando hardware f\u00edsico, podemos simular a execu\u00e7\u00e3o ou simplesmente entender que o c\u00f3digo enviaria \"Hello, World!\" ao Monitor Serial a cada segundo.</li> </ul> <p>Passo 4: Abrir o Monitor Serial</p> <ol> <li>No Arduino IDE, clique em Ferramentas &gt; Monitor Serial ou pressione <code>Ctrl + Shift + M</code>.</li> <li>Configure a taxa de transmiss\u00e3o para 9600 baud (deve corresponder ao valor definido em <code>Serial.begin()</code>).</li> </ol> <p>Resultado Esperado:</p> <pre><code>Hello, World!\nHello, World!\nHello, World!\n...\n</code></pre> <p>A mensagem ser\u00e1 repetida a cada segundo.</p>"},{"location":"aulas/iot/modulos/modulo1.html#4-variaveis-e-tipos-de-dados","title":"4. Vari\u00e1veis e Tipos de Dados","text":"<p>Vari\u00e1veis s\u00e3o espa\u00e7os na mem\u00f3ria do microcontrolador que armazenam valores que podem ser alterados durante a execu\u00e7\u00e3o do programa. Em Arduino, as vari\u00e1veis devem ser declaradas com um tipo de dado espec\u00edfico.</p>"},{"location":"aulas/iot/modulos/modulo1.html#41-declaracao-e-inicializacao-de-variaveis","title":"4.1 Declara\u00e7\u00e3o e Inicializa\u00e7\u00e3o de Vari\u00e1veis","text":"<p>Declara\u00e7\u00e3o: Informar ao compilador o nome e o tipo da vari\u00e1vel.</p> <pre><code>int numero; // Declara uma vari\u00e1vel inteira chamada 'numero'\n</code></pre> <p>Inicializa\u00e7\u00e3o: Atribuir um valor inicial \u00e0 vari\u00e1vel.</p> <pre><code>numero = 10; // Atribui o valor 10 \u00e0 vari\u00e1vel 'numero'\n</code></pre> <p>Declara\u00e7\u00e3o e Inicializa\u00e7\u00e3o Simult\u00e2nea:</p> <pre><code>int numero = 10; // Declara e inicializa 'numero' com 10\n</code></pre>"},{"location":"aulas/iot/modulos/modulo1.html#42-tipos-de-dados-primitivos","title":"4.2 Tipos de Dados Primitivos","text":""},{"location":"aulas/iot/modulos/modulo1.html#421-int-inteiro","title":"4.2.1 <code>int</code> (Inteiro)","text":"<ul> <li>Descri\u00e7\u00e3o: Armazena n\u00fameros inteiros, positivos ou negativos, sem decimais.</li> <li>Tamanho: Geralmente 16 bits no Arduino Uno (varia conforme a placa).</li> <li>Intervalo: De -32.768 a 32.767 (para 16 bits).</li> <li>Exemplo:</li> </ul> <pre><code>int idade = 25;\n</code></pre>"},{"location":"aulas/iot/modulos/modulo1.html#422-float-ponto-flutuante","title":"4.2.2 <code>float</code> (Ponto Flutuante)","text":"<ul> <li>Descri\u00e7\u00e3o: Armazena n\u00fameros com casas decimais.</li> <li>Tamanho: 32 bits.</li> <li>Precis\u00e3o: Aproximadamente 6 a 7 d\u00edgitos significativos.</li> <li>Exemplo:</li> </ul> <pre><code>float temperatura = 36.5;\n</code></pre>"},{"location":"aulas/iot/modulos/modulo1.html#423-char-caractere","title":"4.2.3 <code>char</code> (Caractere)","text":"<ul> <li>Descri\u00e7\u00e3o: Armazena um \u00fanico caractere ou pequenos n\u00fameros inteiros.</li> <li>Tamanho: 8 bits.</li> <li>Intervalo: De -128 a 127.</li> <li>Exemplo:</li> </ul> <pre><code>char letra = 'A';\n</code></pre>"},{"location":"aulas/iot/modulos/modulo1.html#424-boolean-booleano","title":"4.2.4 <code>boolean</code> (Booleano)","text":"<ul> <li>Descri\u00e7\u00e3o: Armazena valores l\u00f3gicos <code>true</code> (verdadeiro) ou <code>false</code> (falso).</li> <li>Tamanho: 8 bits (apesar de usar apenas 1 bit).</li> <li>Exemplo:</li> </ul> <pre><code>boolean estado = true;\n</code></pre>"},{"location":"aulas/iot/modulos/modulo1.html#43-exemplo-pratico-usando-variaveis","title":"4.3 Exemplo Pr\u00e1tico: Usando Vari\u00e1veis","text":"<p>Vamos criar um programa que declara diferentes tipos de vari\u00e1veis e as imprime no Monitor Serial.</p> <p>C\u00f3digo:</p> <pre><code>void setup() {\n  Serial.begin(9600);\n\n  int numero = 42;\n  float pi = 3.1416;\n  char caractere = 'C';\n  boolean verdade = true;\n\n  Serial.print(\"N\u00famero inteiro: \");\n  Serial.println(numero);\n\n  Serial.print(\"N\u00famero float: \");\n  Serial.println(pi);\n\n  Serial.print(\"Caractere: \");\n  Serial.println(caractere);\n\n  Serial.print(\"Valor booleano: \");\n  Serial.println(verdade);\n}\n\nvoid loop() {\n  // N\u00e3o h\u00e1 c\u00f3digo no loop\n}\n</code></pre> <p>Explica\u00e7\u00e3o do C\u00f3digo:</p> <ul> <li><code>Serial.print()</code> vs. <code>Serial.println()</code>:</li> <li><code>Serial.print()</code> envia o dado sem pular para a pr\u00f3xima linha.</li> <li><code>Serial.println()</code> envia o dado e adiciona uma nova linha.</li> <li>As vari\u00e1veis s\u00e3o declaradas e inicializadas dentro da fun\u00e7\u00e3o <code>setup()</code>.</li> </ul> <p>Resultado Esperado no Monitor Serial:</p> <pre><code>N\u00famero inteiro: 42\nN\u00famero float: 3.14\nCaractere: C\nValor booleano: 1\n</code></pre> <p>Observa\u00e7\u00e3o:</p> <ul> <li>O valor booleano <code>true</code> \u00e9 impresso como <code>1</code>, e <code>false</code> seria <code>0</code>.</li> <li>O n\u00famero <code>float</code> pode ser arredondado dependendo da configura\u00e7\u00e3o.</li> </ul>"},{"location":"aulas/iot/modulos/modulo1.html#5-exercicios-praticos","title":"5. Exerc\u00edcios Pr\u00e1ticos","text":""},{"location":"aulas/iot/modulos/modulo1.html#exercicio-1-modificar-o-hello-world","title":"Exerc\u00edcio 1: Modificar o \"Hello, World!\"","text":"<p>Tarefa: Altere o programa \"Hello, World!\" para que ele pe\u00e7a ao usu\u00e1rio um nome (via Monitor Serial) e ent\u00e3o exiba \"Hello, [Nome]!\".</p> <p>Dicas:</p> <ul> <li>Use <code>Serial.readString()</code> para ler a entrada do usu\u00e1rio.</li> <li>Lembre-se de configurar o Monitor Serial para enviar nova linha ou retorno de carro ap\u00f3s a entrada.</li> </ul> <p>C\u00f3digo Exemplo:</p> <pre><code>String nome; // Declara uma vari\u00e1vel do tipo String\n\nvoid setup() {\n  Serial.begin(9600);\n  Serial.println(\"Digite seu nome:\");\n\n  // Aguarda at\u00e9 que haja dados dispon\u00edveis\n  while (Serial.available() == 0) {\n    // Aguarda o usu\u00e1rio digitar\n  }\n\n  nome = Serial.readString(); // L\u00ea a string digitada\n  Serial.print(\"Hello, \");\n  Serial.print(nome);\n}\n\nvoid loop() {\n  // C\u00f3digo vazio\n}\n</code></pre>"},{"location":"aulas/iot/modulos/modulo1.html#exercicio-2-calculadora-simples","title":"Exerc\u00edcio 2: Calculadora Simples","text":"<p>Tarefa: Escreva um programa que solicite dois n\u00fameros inteiros ao usu\u00e1rio e exiba a soma, subtra\u00e7\u00e3o, multiplica\u00e7\u00e3o e divis\u00e3o desses n\u00fameros.</p> <p>Dicas:</p> <ul> <li>Use <code>Serial.parseInt()</code> para ler n\u00fameros inteiros do Monitor Serial.</li> <li>Cuidado com a divis\u00e3o por zero.</li> </ul>"},{"location":"aulas/iot/modulos/modulo1.html#6-conceitos-importantes","title":"6. Conceitos Importantes","text":""},{"location":"aulas/iot/modulos/modulo1.html#61-comentarios-no-codigo","title":"6.1 Coment\u00e1rios no C\u00f3digo","text":"<p>Coment\u00e1rios de Linha \u00danica: Usando <code>//</code></p> <pre><code>// Este \u00e9 um coment\u00e1rio de linha \u00fanica\n</code></pre> <p>Coment\u00e1rios de M\u00faltiplas Linhas: Usando <code>/* */</code></p> <pre><code>/*\n   Este \u00e9 um coment\u00e1rio\n   de m\u00faltiplas linhas\n*/\n</code></pre> <p>Import\u00e2ncia: Coment\u00e1rios ajudam a documentar o c\u00f3digo, tornando-o mais leg\u00edvel e f\u00e1cil de entender.</p>"},{"location":"aulas/iot/modulos/modulo1.html#62-boas-praticas","title":"6.2 Boas Pr\u00e1ticas","text":"<ul> <li>Nomes de Vari\u00e1veis Descritivos: Use nomes que indiquem o prop\u00f3sito da vari\u00e1vel.</li> </ul> <pre><code>int contador; // Melhor que 'c' ou 'x'\n</code></pre> <ul> <li>Indenta\u00e7\u00e3o e Formata\u00e7\u00e3o: Organize o c\u00f3digo com indenta\u00e7\u00e3o consistente para melhorar a legibilidade.</li> <li>Evitar Vari\u00e1veis Globais Desnecess\u00e1rias: Declare vari\u00e1veis dentro do menor escopo poss\u00edvel.</li> </ul>"},{"location":"aulas/iot/modulos/modulo10.html","title":"M\u00f3dulo 10: Comunica\u00e7\u00e3o Serial Avan\u00e7ada","text":"<p>Bem-vindo ao M\u00f3dulo 10 do curso \"Programa\u00e7\u00e3o em Arduino: Conceitos Fundamentais sem Hardware\". Neste m\u00f3dulo, voc\u00ea ir\u00e1 aprofundar seu conhecimento sobre comunica\u00e7\u00e3o serial na linguagem de programa\u00e7\u00e3o Arduino (C/C++). A comunica\u00e7\u00e3o serial \u00e9 essencial para a troca de dados entre o Arduino e outros dispositivos, como computadores, m\u00f3dulos de comunica\u00e7\u00e3o e outros microcontroladores.</p>"},{"location":"aulas/iot/modulos/modulo10.html#objetivos-do-modulo","title":"Objetivos do M\u00f3dulo","text":"<ul> <li>Compreender os conceitos avan\u00e7ados de comunica\u00e7\u00e3o serial.</li> <li>Aprender a configurar e utilizar diferentes protocolos de comunica\u00e7\u00e3o serial, incluindo UART, I2C e SPI.</li> <li>Implementar comunica\u00e7\u00e3o serial entre m\u00faltiplos dispositivos Arduino.</li> <li>Utilizar a biblioteca <code>SoftwareSerial</code> para criar portas seriais adicionais.</li> <li>Gerenciar a transfer\u00eancia e o parsing de dados de forma eficiente.</li> <li>Resolver exerc\u00edcios pr\u00e1ticos para consolidar o conhecimento sobre comunica\u00e7\u00e3o serial avan\u00e7ada.</li> </ul>"},{"location":"aulas/iot/modulos/modulo10.html#1-introducao-a-comunicacao-serial-avancada","title":"1. Introdu\u00e7\u00e3o \u00e0 Comunica\u00e7\u00e3o Serial Avan\u00e7ada","text":""},{"location":"aulas/iot/modulos/modulo10.html#11-revisao-da-comunicacao-serial-basica","title":"1.1 Revis\u00e3o da Comunica\u00e7\u00e3o Serial B\u00e1sica","text":"<p>Anteriormente, aprendemos a utilizar o Monitor Serial para enviar e receber dados entre o Arduino e o computador. Neste m\u00f3dulo, expandiremos esse conhecimento para incluir comunica\u00e7\u00e3o entre dispositivos e utiliza\u00e7\u00e3o de protocolos mais complexos.</p>"},{"location":"aulas/iot/modulos/modulo10.html#12-importancia-da-comunicacao-serial-avancada","title":"1.2 Import\u00e2ncia da Comunica\u00e7\u00e3o Serial Avan\u00e7ada","text":"<ul> <li>Interconectividade: Permite que o Arduino se comunique com uma variedade de dispositivos, como sensores avan\u00e7ados, m\u00f3dulos de comunica\u00e7\u00e3o (Wi-Fi, Bluetooth) e outros microcontroladores.</li> <li>Controle Remoto: Facilita o controle e monitoramento do Arduino a partir de dispositivos externos.</li> <li>Transfer\u00eancia de Dados: Habilita a troca eficiente de grandes volumes de dados entre dispositivos.</li> </ul>"},{"location":"aulas/iot/modulos/modulo10.html#2-protocolos-de-comunicacao-serial","title":"2. Protocolos de Comunica\u00e7\u00e3o Serial","text":""},{"location":"aulas/iot/modulos/modulo10.html#21-uart-universal-asynchronous-receivertransmitter","title":"2.1 UART (Universal Asynchronous Receiver/Transmitter)","text":"<p>UART \u00e9 um protocolo de comunica\u00e7\u00e3o serial ass\u00edncrona que utiliza dois fios principais: TX (transmiss\u00e3o) e RX (recep\u00e7\u00e3o).</p> <p>Caracter\u00edsticas:</p> <ul> <li>Comunica\u00e7\u00e3o ponto a ponto.</li> <li>N\u00e3o requer um rel\u00f3gio compartilhado.</li> <li>Configura\u00e7\u00f5es comuns: baud rate, paridade, bits de dados e bits de parada.</li> </ul> <p>Exemplo de Configura\u00e7\u00e3o UART:</p> <pre><code>void setup() {\n    Serial.begin(9600); // Inicializa a comunica\u00e7\u00e3o serial a 9600 baud\n}\n\nvoid loop() {\n    if (Serial.available() &gt; 0) {\n        char recebido = Serial.read();\n        Serial.print(\"Voc\u00ea digitou: \");\n        Serial.println(recebido);\n    }\n}\n</code></pre>"},{"location":"aulas/iot/modulos/modulo10.html#22-i2c-inter-integrated-circuit","title":"2.2 I2C (Inter-Integrated Circuit)","text":"<p>I2C \u00e9 um protocolo de comunica\u00e7\u00e3o serial s\u00edncrona que utiliza dois fios: SDA (Serial Data) e SCL (Serial Clock).</p> <p>Caracter\u00edsticas:</p> <ul> <li>Comunica\u00e7\u00e3o multi-mestre e multi-escravo.</li> <li>Utiliza endere\u00e7amento para identificar dispositivos.</li> <li>Ideal para comunica\u00e7\u00e3o com sensores e dispositivos que possuem suporte a I2C.</li> </ul> <p>Exemplo de Comunica\u00e7\u00e3o I2C:</p> <pre><code>#include &lt;Wire.h&gt;\n\nvoid setup() {\n    Wire.begin(); // Inicia o I2C como mestre\n    Serial.begin(9600);\n}\n\nvoid loop() {\n    Wire.beginTransmission(8); // Endere\u00e7o do dispositivo escravo\n    Wire.write(\"Hello\");\n    Wire.endTransmission();\n    delay(1000);\n}\n</code></pre>"},{"location":"aulas/iot/modulos/modulo10.html#23-spi-serial-peripheral-interface","title":"2.3 SPI (Serial Peripheral Interface)","text":"<p>SPI \u00e9 um protocolo de comunica\u00e7\u00e3o serial s\u00edncrona que utiliza quatro fios: MOSI (Master Out Slave In), MISO (Master In Slave Out), SCK (Serial Clock) e SS (Slave Select).</p> <p>Caracter\u00edsticas:</p> <ul> <li>Comunica\u00e7\u00e3o full-duplex.</li> <li>Alta velocidade de transfer\u00eancia de dados.</li> <li>Utilizado para comunica\u00e7\u00e3o com dispositivos de alta velocidade, como cart\u00f5es SD e displays LCD.</li> </ul> <p>Exemplo de Comunica\u00e7\u00e3o SPI:</p> <pre><code>#include &lt;SPI.h&gt;\n\nvoid setup() {\n    SPI.begin(); // Inicia o SPI como mestre\n    pinMode(10, OUTPUT); // SS\n    digitalWrite(10, HIGH);\n    Serial.begin(9600);\n}\n\nvoid loop() {\n    digitalWrite(10, LOW);\n    SPI.transfer(0xFF); // Envia byte\n    digitalWrite(10, HIGH);\n    delay(1000);\n}\n</code></pre>"},{"location":"aulas/iot/modulos/modulo10.html#3-comunicacao-serial-entre-multiplos-dispositivos-arduino","title":"3. Comunica\u00e7\u00e3o Serial Entre M\u00faltiplos Dispositivos Arduino","text":""},{"location":"aulas/iot/modulos/modulo10.html#31-comunicacao-uart-entre-dois-arduinos","title":"3.1 Comunica\u00e7\u00e3o UART Entre Dois Arduinos","text":"<p>Configura\u00e7\u00e3o:</p> <ul> <li>Conectar o pino TX do Arduino A ao pino RX do Arduino B.</li> <li>Conectar o pino RX do Arduino A ao pino TX do Arduino B.</li> <li>Conectar GND entre os dois Arduinos.</li> </ul> <p>Exemplo de C\u00f3digo para o Arduino A (Transmissor):</p> <pre><code>void setup() {\n    Serial.begin(9600);\n}\n\nvoid loop() {\n    Serial.println(\"Ol\u00e1 Arduino B!\");\n    delay(1000);\n}\n</code></pre> <p>Exemplo de C\u00f3digo para o Arduino B (Receptor):</p> <pre><code>void setup() {\n    Serial.begin(9600);\n}\n\nvoid loop() {\n    if (Serial.available() &gt; 0) {\n        String mensagem = Serial.readString();\n        Serial.print(\"Recebi: \");\n        Serial.println(mensagem);\n    }\n}\n</code></pre>"},{"location":"aulas/iot/modulos/modulo10.html#32-comunicacao-i2c-entre-multiplos-dispositivos-arduino","title":"3.2 Comunica\u00e7\u00e3o I2C Entre M\u00faltiplos Dispositivos Arduino","text":"<p>Configura\u00e7\u00e3o:</p> <ul> <li>Conectar SDA a SDA e SCL a SCL entre os Arduinos.</li> <li>Definir endere\u00e7os \u00fanicos para cada dispositivo escravo.</li> </ul> <p>Exemplo de C\u00f3digo para o Arduino Mestre:</p> <pre><code>#include &lt;Wire.h&gt;\n\nvoid setup() {\n    Wire.begin(); // Inicia como mestre\n    Serial.begin(9600);\n}\n\nvoid loop() {\n    Wire.beginTransmission(8); // Endere\u00e7o do escravo\n    Wire.write(\"Dados do Mestre\");\n    Wire.endTransmission();\n    delay(1000);\n}\n</code></pre> <p>Exemplo de C\u00f3digo para o Arduino Escravo:</p> <pre><code>#include &lt;Wire.h&gt;\n\nvoid setup() {\n    Wire.begin(8); // Endere\u00e7o do escravo\n    Wire.onReceive(receiveEvent);\n    Serial.begin(9600);\n}\n\nvoid loop() {\n    // N\u00e3o h\u00e1 c\u00f3digo no loop\n}\n\nvoid receiveEvent(int bytes) {\n    while (Wire.available()) {\n        char c = Wire.read();\n        Serial.print(c);\n    }\n    Serial.println();\n}\n</code></pre>"},{"location":"aulas/iot/modulos/modulo10.html#4-utilizando-a-biblioteca-softwareserial","title":"4. Utilizando a Biblioteca <code>SoftwareSerial</code>","text":"<p>A biblioteca <code>SoftwareSerial</code> permite criar portas seriais adicionais em pinos digitais, permitindo comunica\u00e7\u00e3o com m\u00faltiplos dispositivos seriais.</p>"},{"location":"aulas/iot/modulos/modulo10.html#41-configuracao-da-softwareserial","title":"4.1 Configura\u00e7\u00e3o da <code>SoftwareSerial</code>","text":"<p>Exemplo de Uso:</p> <pre><code>#include &lt;SoftwareSerial.h&gt;\n\n// Define os pinos RX e TX para a SoftwareSerial\nSoftwareSerial meuSerial(10, 11); // RX, TX\n\nvoid setup() {\n    Serial.begin(9600);        // Porta serial padr\u00e3o\n    meuSerial.begin(4800);     // Porta serial adicional\n    Serial.println(\"Iniciando comunica\u00e7\u00e3o serial...\");\n}\n\nvoid loop() {\n    if (meuSerial.available()) {\n        char c = meuSerial.read();\n        Serial.print(\"Recebi via SoftwareSerial: \");\n        Serial.println(c);\n    }\n\n    if (Serial.available()) {\n        char c = Serial.read();\n        meuSerial.print(c);\n    }\n}\n</code></pre> <p>Explica\u00e7\u00e3o:</p> <ul> <li>Defini\u00e7\u00e3o: <code>SoftwareSerial meuSerial(10, 11);</code> define pinos 10 e 11 como RX e TX adicionais.</li> <li>Inicializa\u00e7\u00e3o: <code>meuSerial.begin(4800);</code> configura a velocidade da porta serial adicional.</li> <li>Transfer\u00eancia de Dados: Dados recebidos na <code>SoftwareSerial</code> s\u00e3o enviados para a porta serial padr\u00e3o e vice-versa.</li> </ul>"},{"location":"aulas/iot/modulos/modulo10.html#5-gerenciamento-de-transferencia-e-parsing-de-dados","title":"5. Gerenciamento de Transfer\u00eancia e Parsing de Dados","text":""},{"location":"aulas/iot/modulos/modulo10.html#51-formatacao-de-dados","title":"5.1 Formata\u00e7\u00e3o de Dados","text":"<p>Para uma comunica\u00e7\u00e3o eficiente, \u00e9 importante definir um protocolo de formata\u00e7\u00e3o de dados, utilizando delimitadores ou estruturas espec\u00edficas.</p> <p>Exemplo de Dados Delimitados por V\u00edrgulas:</p> <pre><code>String dados = \"23.5,47.8,15.2\"; // Temperatura, Umidade, Press\u00e3o\nSerial.println(dados);\n</code></pre>"},{"location":"aulas/iot/modulos/modulo10.html#52-parsing-de-dados-recebidos","title":"5.2 Parsing de Dados Recebidos","text":"<p>No lado receptor, os dados podem ser divididos e convertidos para os tipos apropriados.</p> <p>Exemplo de Parsing:</p> <pre><code>void setup() {\n    Serial.begin(9600);\n}\n\nvoid loop() {\n    if (Serial.available() &gt; 0) {\n        String recebidos = Serial.readStringUntil('\\n');\n        int primeiraVirgula = recebidos.indexOf(',');\n        int segundaVirgula = recebidos.indexOf(',', primeiraVirgula + 1);\n\n        float temperatura = recebidos.substring(0, primeiraVirgula).toFloat();\n        float umidade = recebidos.substring(primeiraVirgula + 1, segundaVirgula).toFloat();\n        float pressao = recebidos.substring(segundaVirgula + 1).toFloat();\n\n        Serial.print(\"Temperatura: \");\n        Serial.println(temperatura);\n        Serial.print(\"Umidade: \");\n        Serial.println(umidade);\n        Serial.print(\"Press\u00e3o: \");\n        Serial.println(pressao);\n    }\n}\n</code></pre> <p>Explica\u00e7\u00e3o:</p> <ul> <li>Delimita\u00e7\u00e3o: Utiliza v\u00edrgulas para separar os valores.</li> <li>Parsing: Usa <code>indexOf</code> e <code>substring</code> para extrair e converter os valores para <code>float</code>.</li> </ul>"},{"location":"aulas/iot/modulos/modulo10.html#6-comunicacao-serial-com-multiplos-dispositivos","title":"6. Comunica\u00e7\u00e3o Serial com M\u00faltiplos Dispositivos","text":""},{"location":"aulas/iot/modulos/modulo10.html#61-comunicacao-entre-arduino-e-computador-via-serial-usb","title":"6.1 Comunica\u00e7\u00e3o entre Arduino e Computador via Serial USB","text":"<p>O Arduino pode se comunicar com o computador atrav\u00e9s da porta USB utilizando a porta serial padr\u00e3o.</p> <p>Exemplo de Envio de Dados para o Computador:</p> <pre><code>void setup() {\n    Serial.begin(9600);\n}\n\nvoid loop() {\n    Serial.println(\"Dados do Arduino\");\n    delay(1000);\n}\n</code></pre>"},{"location":"aulas/iot/modulos/modulo10.html#62-comunicacao-entre-arduino-e-modulos-bluetooth","title":"6.2 Comunica\u00e7\u00e3o entre Arduino e M\u00f3dulos Bluetooth","text":"<p>Utilizando m\u00f3dulos como o HC-05, o Arduino pode se comunicar sem fio com dispositivos como smartphones.</p> <p>Exemplo de Configura\u00e7\u00e3o com <code>SoftwareSerial</code>:</p> <pre><code>#include &lt;SoftwareSerial.h&gt;\n\nSoftwareSerial bluetooth(10, 11); // RX, TX\n\nvoid setup() {\n    Serial.begin(9600);\n    bluetooth.begin(9600);\n    Serial.println(\"Conectado ao Bluetooth.\");\n}\n\nvoid loop() {\n    if (bluetooth.available()) {\n        char c = bluetooth.read();\n        Serial.print(\"Recebi via Bluetooth: \");\n        Serial.println(c);\n    }\n\n    if (Serial.available()) {\n        char c = Serial.read();\n        bluetooth.print(c);\n    }\n}\n</code></pre> <p>Explica\u00e7\u00e3o:</p> <ul> <li>Defini\u00e7\u00e3o: Pinos 10 e 11 s\u00e3o usados para comunica\u00e7\u00e3o serial com o m\u00f3dulo Bluetooth.</li> <li>Transfer\u00eancia de Dados: Dados recebidos do Bluetooth s\u00e3o enviados para o Monitor Serial e vice-versa.</li> </ul>"},{"location":"aulas/iot/modulos/modulo10.html#7-exemplos-praticos","title":"7. Exemplos Pr\u00e1ticos","text":""},{"location":"aulas/iot/modulos/modulo10.html#71-comunicacao-serial-entre-dois-arduinos-usando-i2c","title":"7.1 Comunica\u00e7\u00e3o Serial Entre Dois Arduinos Usando I2C","text":"<pre><code>// C\u00f3digo para o Arduino Mestre\n#include &lt;Wire.h&gt;\n\nvoid setup() {\n    Wire.begin(); // Inicia como mestre\n    Serial.begin(9600);\n}\n\nvoid loop() {\n    Wire.beginTransmission(8); // Endere\u00e7o do escravo\n    Wire.write(\"Dados do Mestre\");\n    Wire.endTransmission();\n    delay(1000);\n}\n</code></pre> <pre><code>// C\u00f3digo para o Arduino Escravo\n#include &lt;Wire.h&gt;\n\nvoid setup() {\n    Wire.begin(8); // Endere\u00e7o do escravo\n    Wire.onReceive(receiveEvent);\n    Serial.begin(9600);\n}\n\nvoid loop() {\n    // N\u00e3o h\u00e1 c\u00f3digo no loop\n}\n\nvoid receiveEvent(int bytes) {\n    while (Wire.available()) {\n        char c = Wire.read();\n        Serial.print(c);\n    }\n    Serial.println();\n}\n</code></pre> <p>Explica\u00e7\u00e3o:</p> <ul> <li>Mestre: Envia uma string \"Dados do Mestre\" para o escravo a cada segundo.</li> <li>Escravo: Recebe os dados e os imprime no Monitor Serial.</li> </ul>"},{"location":"aulas/iot/modulos/modulo10.html#72-utilizando-softwareserial-para-comunicacao-com-um-modulo-bluetooth","title":"7.2 Utilizando <code>SoftwareSerial</code> para Comunica\u00e7\u00e3o com um M\u00f3dulo Bluetooth","text":"<pre><code>#include &lt;SoftwareSerial.h&gt;\n\nSoftwareSerial bluetooth(10, 11); // RX, TX\n\nvoid setup() {\n    Serial.begin(9600);\n    bluetooth.begin(9600);\n    Serial.println(\"Conectado ao Bluetooth.\");\n}\n\nvoid loop() {\n    if (bluetooth.available()) {\n        char c = bluetooth.read();\n        Serial.print(\"Recebi via Bluetooth: \");\n        Serial.println(c);\n    }\n\n    if (Serial.available()) {\n        char c = Serial.read();\n        bluetooth.print(c);\n    }\n}\n</code></pre> <p>Explica\u00e7\u00e3o:</p> <ul> <li>Envio e Recebimento: Permite enviar e receber dados entre o Arduino e um dispositivo Bluetooth, como um smartphone, utilizando a porta serial adicional criada pela biblioteca <code>SoftwareSerial</code>.</li> </ul>"},{"location":"aulas/iot/modulos/modulo10.html#73-comunicacao-serial-com-parsing-de-dados-delimitados","title":"7.3 Comunica\u00e7\u00e3o Serial com Parsing de Dados Delimitados","text":"<pre><code>void setup() {\n    Serial.begin(9600);\n    Serial.println(\"Envie dados no formato: temperatura,umidade,pressao\");\n}\n\nvoid loop() {\n    if (Serial.available() &gt; 0) {\n        String recebidos = Serial.readStringUntil('\\n');\n        int primeiraVirgula = recebidos.indexOf(',');\n        int segundaVirgula = recebidos.indexOf(',', primeiraVirgula + 1);\n\n        if (primeiraVirgula &gt; 0 &amp;&amp; segundaVirgula &gt; primeiraVirgula) {\n            float temperatura = recebidos.substring(0, primeiraVirgula).toFloat();\n            float umidade = recebidos.substring(primeiraVirgula + 1, segundaVirgula).toFloat();\n            float pressao = recebidos.substring(segundaVirgula + 1).toFloat();\n\n            Serial.print(\"Temperatura: \");\n            Serial.println(temperatura);\n            Serial.print(\"Umidade: \");\n            Serial.println(umidade);\n            Serial.print(\"Press\u00e3o: \");\n            Serial.println(pressao);\n        } else {\n            Serial.println(\"Formato inv\u00e1lido. Tente novamente.\");\n        }\n    }\n}\n</code></pre> <p>Explica\u00e7\u00e3o:</p> <ul> <li>Formato de Dados: Espera uma string no formato \"temperatura,umidade,pressao\".</li> <li>Parsing: Divide a string com base nas v\u00edrgulas e converte os segmentos para <code>float</code>.</li> <li>Valida\u00e7\u00e3o: Verifica se o formato dos dados est\u00e1 correto antes de processar.</li> </ul>"},{"location":"aulas/iot/modulos/modulo10.html#8-exercicios-praticos","title":"8. Exerc\u00edcios Pr\u00e1ticos","text":""},{"location":"aulas/iot/modulos/modulo10.html#exercicio-1-comunicacao-serial-entre-arduino-e-pc-com-comando-de-controle","title":"Exerc\u00edcio 1: Comunica\u00e7\u00e3o Serial Entre Arduino e PC com Comando de Controle","text":"<ul> <li> <p>Tarefa: Crie um programa onde o Arduino recebe comandos do computador via Serial para ligar e desligar um LED. Use comandos como \"LIGAR\" e \"DESLIGAR\".</p> </li> <li> <p>Dicas:</p> </li> <li>Utilize <code>Serial.readStringUntil('\\n')</code> para ler comandos completos.</li> <li> <p>Compare strings para identificar o comando recebido.</p> </li> <li> <p>Exemplo de C\u00f3digo:</p> </li> </ul> <pre><code>const int ledPin = 13;\n\nvoid setup() {\n    pinMode(ledPin, OUTPUT);\n    Serial.begin(9600);\n    Serial.println(\"Digite 'LIGAR' ou 'DESLIGAR' para controlar o LED.\");\n}\n\nvoid loop() {\n    if (Serial.available() &gt; 0) {\n        String comando = Serial.readStringUntil('\\n');\n        comando.trim(); // Remove espa\u00e7os em branco\n\n        if (comando.equalsIgnoreCase(\"LIGAR\")) {\n            digitalWrite(ledPin, HIGH);\n            Serial.println(\"LED Ligado.\");\n        } else if (comando.equalsIgnoreCase(\"DESLIGAR\")) {\n            digitalWrite(ledPin, LOW);\n            Serial.println(\"LED Desligado.\");\n        } else {\n            Serial.println(\"Comando inv\u00e1lido. Use 'LIGAR' ou 'DESLIGAR'.\");\n        }\n    }\n}\n</code></pre>"},{"location":"aulas/iot/modulos/modulo10.html#exercicio-2-comunicacao-serial-com-arduino-e-modulo-bluetooth-para-controle-de-servo","title":"Exerc\u00edcio 2: Comunica\u00e7\u00e3o Serial com Arduino e M\u00f3dulo Bluetooth para Controle de Servo","text":"<ul> <li> <p>Tarefa: Desenvolva um sistema onde um smartphone envia comandos via Bluetooth para o Arduino controlar a posi\u00e7\u00e3o de um servo motor. Utilize comandos como \"ESQUERDA\" e \"DIREITA\" para ajustar o \u00e2ngulo do servo.</p> </li> <li> <p>Dicas:</p> </li> <li>Utilize a biblioteca <code>SoftwareSerial</code> para comunica\u00e7\u00e3o com o m\u00f3dulo Bluetooth.</li> <li> <p>Controle o servo utilizando a biblioteca <code>Servo</code>.</p> </li> <li> <p>Exemplo de C\u00f3digo:</p> </li> </ul> <pre><code>#include &lt;SoftwareSerial.h&gt;\n#include &lt;Servo.h&gt;\n\nSoftwareSerial bluetooth(10, 11); // RX, TX\nServo meuServo;\n\nvoid setup() {\n    Serial.begin(9600);\n    bluetooth.begin(9600);\n    meuServo.attach(9); // Servo conectado ao pino 9\n    meuServo.write(90); // Posi\u00e7\u00e3o inicial\n    Serial.println(\"Controle do Servo via Bluetooth iniciado.\");\n}\n\nvoid loop() {\n    if (bluetooth.available() &gt; 0) {\n        String comando = bluetooth.readStringUntil('\\n');\n        comando.trim();\n\n        if (comando.equalsIgnoreCase(\"ESQUERDA\")) {\n            int pos = meuServo.read();\n            pos -= 10;\n            if (pos &lt; 0) pos = 0;\n            meuServo.write(pos);\n            Serial.print(\"Servo movido para a esquerda: \");\n            Serial.println(pos);\n        } else if (comando.equalsIgnoreCase(\"DIREITA\")) {\n            int pos = meuServo.read();\n            pos += 10;\n            if (pos &gt; 180) pos = 180;\n            meuServo.write(pos);\n            Serial.print(\"Servo movido para a direita: \");\n            Serial.println(pos);\n        } else {\n            Serial.println(\"Comando inv\u00e1lido. Use 'ESQUERDA' ou 'DIREITA'.\");\n        }\n    }\n}\n</code></pre>"},{"location":"aulas/iot/modulos/modulo10.html#exercicio-3-comunicacao-serial-com-parsing-de-dados-para-monitoramento-de-sensores","title":"Exerc\u00edcio 3: Comunica\u00e7\u00e3o Serial com Parsing de Dados para Monitoramento de Sensores","text":"<ul> <li> <p>Tarefa: Crie um programa onde o Arduino envia dados de m\u00faltiplos sensores formatados em JSON para o computador. Utilize parsing para organizar os dados recebidos.</p> </li> <li> <p>Dicas:</p> </li> <li>Utilize delimitadores para estruturar os dados em formato JSON.</li> <li> <p>Implemente fun\u00e7\u00f5es para criar e interpretar strings JSON.</p> </li> <li> <p>Exemplo de C\u00f3digo:</p> </li> </ul> <pre><code>#include &lt;ArduinoJson.h&gt;\n\nvoid setup() {\n    Serial.begin(9600);\n    Serial.println(\"Monitoramento de Sensores Iniciado.\");\n}\n\nvoid loop() {\n    // Simula\u00e7\u00e3o de leituras de sensores\n    float temperatura = 23.5;\n    float umidade = 47.8;\n    float pressao = 1013.25;\n\n    // Cria um documento JSON\n    StaticJsonDocument&lt;200&gt; doc;\n    doc[\"temperatura\"] = temperatura;\n    doc[\"umidade\"] = umidade;\n    doc[\"pressao\"] = pressao;\n\n    // Serializa o JSON\n    String output;\n    serializeJson(doc, output);\n    Serial.println(output);\n\n    delay(1000);\n}\n</code></pre> <p>Explica\u00e7\u00e3o:</p> <ul> <li>Biblioteca <code>ArduinoJson</code>: Facilita a cria\u00e7\u00e3o e parsing de dados em formato JSON.</li> <li>Cria\u00e7\u00e3o do JSON: Armazena os valores dos sensores em um documento JSON e o envia via Serial.</li> <li>Monitoramento: O computador pode receber e interpretar os dados estruturados para visualiza\u00e7\u00e3o ou processamento.</li> </ul>"},{"location":"aulas/iot/modulos/modulo10.html#9-conceitos-importantes","title":"9. Conceitos Importantes","text":""},{"location":"aulas/iot/modulos/modulo10.html#91-baud-rate","title":"9.1 Baud Rate","text":"<ul> <li>Defini\u00e7\u00e3o: Taxa de transmiss\u00e3o de dados na comunica\u00e7\u00e3o serial, medida em bits por segundo (bps).</li> <li>Considera\u00e7\u00f5es:</li> <li>Deve ser consistente entre os dispositivos comunicantes.</li> <li>Baud rates comuns: 9600, 19200, 38400, 57600, 115200.</li> </ul>"},{"location":"aulas/iot/modulos/modulo10.html#92-paridade-e-bits-de-parada","title":"9.2 Paridade e Bits de Parada","text":"<ul> <li>Paridade: M\u00e9todo de verifica\u00e7\u00e3o de erros que adiciona um bit extra para garantir a integridade dos dados.</li> <li>Bits de Parada: Indicam o final de um byte de dados.</li> <li>Configura\u00e7\u00e3o: Geralmente configurada como 8N1 (8 bits de dados, sem paridade, 1 bit de parada).</li> </ul>"},{"location":"aulas/iot/modulos/modulo10.html#93-softwareserial-vs-hardwareserial","title":"9.3 SoftwareSerial vs. HardwareSerial","text":"<ul> <li>HardwareSerial:</li> <li>Utiliza a porta serial padr\u00e3o do Arduino.</li> <li>Mais eficiente e r\u00e1pido.</li> <li> <p>Limitado a uma \u00fanica porta serial (exceto em Arduinos com m\u00faltiplas portas seriais).</p> </li> <li> <p>SoftwareSerial:</p> </li> <li>Permite criar portas seriais adicionais em pinos digitais.</li> <li>Menos eficiente e pode ser mais lenta.</li> <li>\u00datil para comunica\u00e7\u00e3o com m\u00faltiplos dispositivos seriais.</li> </ul>"},{"location":"aulas/iot/modulos/modulo10.html#94-parsing-de-dados","title":"9.4 Parsing de Dados","text":"<ul> <li>Defini\u00e7\u00e3o: Processo de interpretar e extrair informa\u00e7\u00f5es de uma string ou fluxo de dados.</li> <li>Import\u00e2ncia: Essencial para organizar e utilizar dados recebidos de forma estruturada.</li> </ul>"},{"location":"aulas/iot/modulos/modulo10.html#95-boas-praticas-na-comunicacao-serial","title":"9.5 Boas Pr\u00e1ticas na Comunica\u00e7\u00e3o Serial","text":"<ul> <li>Consist\u00eancia: Mantenha as configura\u00e7\u00f5es de baud rate e par\u00e2metros de comunica\u00e7\u00e3o consistentes entre os dispositivos.</li> <li>Delimita\u00e7\u00e3o de Dados: Utilize delimitadores claros para separar diferentes partes dos dados.</li> <li>Valida\u00e7\u00e3o: Sempre verifique e valide os dados recebidos para evitar erros de interpreta\u00e7\u00e3o.</li> <li>Gerenciamento de Buffer: Evite sobrecarregar o buffer serial, controlando a quantidade e a frequ\u00eancia dos dados enviados.</li> </ul>"},{"location":"aulas/iot/modulos/modulo10.html#10-recursos-adicionais","title":"10. Recursos Adicionais","text":"<ul> <li> <p>Documenta\u00e7\u00e3o Oficial do Arduino:</p> </li> <li> <p>Comunica\u00e7\u00e3o Serial</p> </li> <li>Biblioteca <code>SoftwareSerial</code></li> <li> <p>Biblioteca <code>ArduinoJson</code></p> </li> <li> <p>Tutoriais e Guias:</p> </li> <li> <p>Guia Completo de Comunica\u00e7\u00e3o Serial no Arduino</p> </li> <li>Utilizando I2C e SPI no Arduino</li> <li> <p>Introdu\u00e7\u00e3o ao JSON com Arduino</p> </li> <li> <p>V\u00eddeos Educacionais:</p> </li> <li> <p>Comunica\u00e7\u00e3o Serial Avan\u00e7ada no Arduino</p> </li> <li>Entendendo I2C e SPI no Arduino</li> <li>Utilizando a Biblioteca <code>ArduinoJson</code></li> </ul>"},{"location":"aulas/iot/modulos/modulo10.html#11-conclusao-do-modulo","title":"11. Conclus\u00e3o do M\u00f3dulo","text":"<p>Neste m\u00f3dulo, voc\u00ea aprendeu:</p> <ul> <li>Conceitos avan\u00e7ados de comunica\u00e7\u00e3o serial, incluindo UART, I2C e SPI.</li> <li>Como configurar e utilizar diferentes protocolos de comunica\u00e7\u00e3o serial no Arduino.</li> <li>Implementa\u00e7\u00e3o de comunica\u00e7\u00e3o serial entre m\u00faltiplos dispositivos Arduino.</li> <li>Utiliza\u00e7\u00e3o da biblioteca <code>SoftwareSerial</code> para criar portas seriais adicionais.</li> <li>T\u00e9cnicas de transfer\u00eancia e parsing de dados para comunica\u00e7\u00e3o eficiente.</li> <li>Integra\u00e7\u00e3o de comunica\u00e7\u00e3o serial com m\u00f3dulos de comunica\u00e7\u00e3o como Bluetooth.</li> <li>Praticou com exemplos e exerc\u00edcios que refor\u00e7am o entendimento da comunica\u00e7\u00e3o serial avan\u00e7ada.</li> </ul> <p>Voc\u00ea est\u00e1 agora preparado para avan\u00e7ar para o pr\u00f3ximo m\u00f3dulo, onde exploraremos Controle de Motores e Atuadores, aprofundando seu conhecimento em automa\u00e7\u00e3o e controle com Arduino.</p>"},{"location":"aulas/iot/modulos/modulo10.html#12-proximos-passos","title":"12. Pr\u00f3ximos Passos","text":"<ul> <li>Revisar o conte\u00fado deste m\u00f3dulo e certificar-se de que compreendeu os conceitos apresentados.</li> <li>Completar os exerc\u00edcios propostos para consolidar o aprendizado.</li> <li>Preparar-se para o M\u00f3dulo 11: Controle de Motores e Atuadores.</li> </ul> <p>Se tiver d\u00favidas ou precisar de assist\u00eancia, n\u00e3o hesite em procurar recursos adicionais ou participar de comunidades de aprendizagem para obter suporte.</p> <p>Bom trabalho e continue assim!</p>"},{"location":"aulas/iot/modulos/modulo11.html","title":"M\u00f3dulo 11: Controle de Motores e Atuadores","text":"<p>Bem-vindo ao M\u00f3dulo 11 do curso \"Programa\u00e7\u00e3o em Arduino: Conceitos Fundamentais sem Hardware\". Neste m\u00f3dulo, voc\u00ea ir\u00e1 aprender a controlar diferentes tipos de motores e atuadores utilizando o Arduino. O controle eficiente de motores \u00e9 essencial para uma ampla gama de aplica\u00e7\u00f5es, desde rob\u00f3tica at\u00e9 automa\u00e7\u00e3o residencial.</p>"},{"location":"aulas/iot/modulos/modulo11.html#objetivos-do-modulo","title":"Objetivos do M\u00f3dulo","text":"<ul> <li>Compreender os diferentes tipos de motores e atuadores dispon\u00edveis para Arduino.</li> <li>Aprender a controlar motores DC, servos e motores de passo.</li> <li>Entender como utilizar drivers de motor para controlar a dire\u00e7\u00e3o e velocidade dos motores.</li> <li>Implementar controle de motores utilizando sinais digitais e PWM.</li> <li>Utilizar bibliotecas espec\u00edficas para facilitar o controle de motores e atuadores.</li> <li>Resolver exerc\u00edcios pr\u00e1ticos para consolidar o conhecimento sobre controle de motores e atuadores.</li> </ul>"},{"location":"aulas/iot/modulos/modulo11.html#1-introducao-a-motores-e-atuadores","title":"1. Introdu\u00e7\u00e3o a Motores e Atuadores","text":""},{"location":"aulas/iot/modulos/modulo11.html#11-o-que-sao-motores-e-atuadores","title":"1.1 O que s\u00e3o Motores e Atuadores?","text":"<p>Motores s\u00e3o dispositivos que convertem energia el\u00e9trica em movimento mec\u00e2nico. Atuadores s\u00e3o dispositivos que recebem comandos el\u00e9tricos para realizar uma a\u00e7\u00e3o f\u00edsica, como mover uma parte de um rob\u00f4 ou abrir uma v\u00e1lvula.</p>"},{"location":"aulas/iot/modulos/modulo11.html#12-tipos-comuns-de-motores-e-atuadores","title":"1.2 Tipos Comuns de Motores e Atuadores","text":"<ul> <li>Motor DC (Corrente Cont\u00ednua): Simples de controlar, ideal para aplica\u00e7\u00f5es que requerem movimento cont\u00ednuo.</li> <li>Servo Motor: Permite controle preciso de posi\u00e7\u00e3o angular, amplamente utilizado em rob\u00f3tica e sistemas de controle.</li> <li>Motor de Passo: Move-se em passos discretos, permitindo controle preciso de posi\u00e7\u00e3o e velocidade.</li> <li>Rel\u00e9s: Atuadores eletromec\u00e2nicos usados para controlar circuitos de alta pot\u00eancia com sinais de baixa pot\u00eancia.</li> <li>Solenoides: Atuadores lineares que convertem energia el\u00e9trica em movimento linear.</li> </ul>"},{"location":"aulas/iot/modulos/modulo11.html#2-controle-de-motores-dc","title":"2. Controle de Motores DC","text":""},{"location":"aulas/iot/modulos/modulo11.html#21-componentes-necessarios","title":"2.1 Componentes Necess\u00e1rios","text":"<ul> <li>Motor DC</li> <li>Driver de Motor (por exemplo, L298N, L293D)</li> <li>Fonte de Alimenta\u00e7\u00e3o Adequada</li> <li>Cabos de Conex\u00e3o</li> <li>Arduino</li> </ul>"},{"location":"aulas/iot/modulos/modulo11.html#22-conectando-o-motor-dc-ao-arduino","title":"2.2 Conectando o Motor DC ao Arduino","text":"<p>Os motores DC requerem um driver de motor para controlar a dire\u00e7\u00e3o e velocidade. O driver atua como um interruptor que permite ao Arduino controlar o motor de forma segura.</p> <p>Exemplo de Conex\u00e3o com L298N:</p> <ul> <li>Motor DC:</li> <li>Conecte os terminais do motor \u00e0s sa\u00eddas do driver (OUT1 e OUT2).</li> <li>Driver L298N:</li> <li>IN1 e IN2: Conectados a pinos digitais do Arduino para controle de dire\u00e7\u00e3o.</li> <li>ENA: Conectado a um pino PWM do Arduino para controle de velocidade.</li> <li>VCC e GND: Conectados \u00e0 fonte de alimenta\u00e7\u00e3o adequada.</li> <li>Arduino:</li> <li>Conecte os pinos de controle (IN1, IN2, ENA) aos pinos digitais e PWM.</li> </ul>"},{"location":"aulas/iot/modulos/modulo11.html#23-exemplo-de-codigo-para-controle-de-motor-dc","title":"2.3 Exemplo de C\u00f3digo para Controle de Motor DC","text":"<pre><code>// Defini\u00e7\u00e3o dos pinos\nconst int IN1 = 9;\nconst int IN2 = 8;\nconst int ENA = 10;\n\nvoid setup() {\n    // Configura os pinos como sa\u00edda\n    pinMode(IN1, OUTPUT);\n    pinMode(IN2, OUTPUT);\n    pinMode(ENA, OUTPUT);\n}\n\nvoid loop() {\n    // Motor girando para frente\n    digitalWrite(IN1, HIGH);\n    digitalWrite(IN2, LOW);\n    analogWrite(ENA, 200); // Controle de velocidade (0-255)\n    delay(2000);\n\n    // Motor girando para tr\u00e1s\n    digitalWrite(IN1, LOW);\n    digitalWrite(IN2, HIGH);\n    analogWrite(ENA, 200); // Controle de velocidade (0-255)\n    delay(2000);\n\n    // Motor desligado\n    digitalWrite(IN1, LOW);\n    digitalWrite(IN2, LOW);\n    analogWrite(ENA, 0); // Velocidade zero\n    delay(2000);\n}\n</code></pre> <p>Explica\u00e7\u00e3o:</p> <ul> <li>Dire\u00e7\u00e3o do Motor: Controlada pelos pinos IN1 e IN2. Configurar IN1 alto e IN2 baixo faz o motor girar para frente, e vice-versa para girar para tr\u00e1s.</li> <li>Velocidade do Motor: Controlada pelo pino ENA usando PWM (<code>analogWrite</code>). O valor varia de 0 (parado) a 255 (velocidade m\u00e1xima).</li> </ul>"},{"location":"aulas/iot/modulos/modulo11.html#3-controle-de-servo-motors","title":"3. Controle de Servo Motors","text":""},{"location":"aulas/iot/modulos/modulo11.html#31-o-que-e-um-servo-motor","title":"3.1 O que \u00e9 um Servo Motor?","text":"<p>Um servo motor \u00e9 um motor que permite controle preciso de posi\u00e7\u00e3o angular. \u00c9 composto por um motor DC, um conjunto de engrenagens, um potenci\u00f4metro e um circuito de controle.</p>"},{"location":"aulas/iot/modulos/modulo11.html#32-conectando-um-servo-motor-ao-arduino","title":"3.2 Conectando um Servo Motor ao Arduino","text":"<p>Componentes Necess\u00e1rios:</p> <ul> <li>Servo Motor</li> <li>Cabos de Conex\u00e3o</li> <li>Fonte de Alimenta\u00e7\u00e3o Adequada (se necess\u00e1rio)</li> <li>Arduino</li> </ul> <p>Conex\u00e3o:</p> <ul> <li>VCC (Vermelho): Conectado a 5V ou a uma fonte de alimenta\u00e7\u00e3o externa.</li> <li>GND (Preto ou Marrom): Conectado ao GND do Arduino.</li> <li>Sinal (Amarelo ou Branco): Conectado a um pino digital do Arduino (por exemplo, pino 9).</li> </ul>"},{"location":"aulas/iot/modulos/modulo11.html#33-exemplo-de-codigo-para-controle-de-servo-motor","title":"3.3 Exemplo de C\u00f3digo para Controle de Servo Motor","text":"<pre><code>#include &lt;Servo.h&gt;\n\nServo meuServo; // Cria um objeto Servo\n\nconst int pinoServo = 9; // Pino conectado ao servo\n\nvoid setup() {\n    meuServo.attach(pinoServo); // Anexa o servo ao pino especificado\n}\n\nvoid loop() {\n    // Move o servo para 0 graus\n    meuServo.write(0);\n    delay(1000);\n\n    // Move o servo para 90 graus\n    meuServo.write(90);\n    delay(1000);\n\n    // Move o servo para 180 graus\n    meuServo.write(180);\n    delay(1000);\n}\n</code></pre> <p>Explica\u00e7\u00e3o:</p> <ul> <li>Biblioteca Servo: Facilita o controle de servo motors.</li> <li>M\u00e9todo <code>write()</code>: Define a posi\u00e7\u00e3o do servo em graus (0 a 180).</li> </ul>"},{"location":"aulas/iot/modulos/modulo11.html#4-controle-de-motores-de-passo","title":"4. Controle de Motores de Passo","text":""},{"location":"aulas/iot/modulos/modulo11.html#41-o-que-e-um-motor-de-passo","title":"4.1 O que \u00e9 um Motor de Passo?","text":"<p>Um motor de passo \u00e9 um motor que divide uma rota\u00e7\u00e3o completa em um n\u00famero de passos iguais. Permite controle preciso de posi\u00e7\u00e3o e velocidade sem a necessidade de sensores de feedback.</p>"},{"location":"aulas/iot/modulos/modulo11.html#42-conectando-um-motor-de-passo-ao-arduino","title":"4.2 Conectando um Motor de Passo ao Arduino","text":"<p>Componentes Necess\u00e1rios:</p> <ul> <li>Motor de Passo (Bipolar ou Unipolar)</li> <li>Driver de Motor de Passo (por exemplo, A4988, ULN2003)</li> <li>Fonte de Alimenta\u00e7\u00e3o Adequada</li> <li>Cabos de Conex\u00e3o</li> <li>Arduino</li> </ul> <p>Conex\u00e3o com ULN2003 (para motores unipolares):</p> <ul> <li>Motor de Passo:</li> <li>Conecte as bobinas do motor aos terminais do driver ULN2003.</li> <li>Driver ULN2003:</li> <li>IN1, IN2, IN3, IN4: Conectados a pinos digitais do Arduino para controle.</li> <li>VCC e GND: Conectados \u00e0 fonte de alimenta\u00e7\u00e3o e ao GND do Arduino.</li> <li>Arduino:</li> <li>Conecte os pinos de controle (IN1-IN4) aos pinos digitais.</li> </ul>"},{"location":"aulas/iot/modulos/modulo11.html#43-exemplo-de-codigo-para-controle-de-motor-de-passo-com-uln2003","title":"4.3 Exemplo de C\u00f3digo para Controle de Motor de Passo com ULN2003","text":"<pre><code>// Defini\u00e7\u00e3o dos pinos\nconst int IN1 = 8;\nconst int IN2 = 9;\nconst int IN3 = 10;\nconst int IN4 = 11;\n\n// Sequ\u00eancia de passos para motor de passo\nint passos[4][4] = {\n    {1, 0, 0, 1},\n    {1, 1, 0, 0},\n    {0, 1, 1, 0},\n    {0, 0, 1, 1}\n};\n\nvoid setup() {\n    // Configura os pinos como sa\u00edda\n    pinMode(IN1, OUTPUT);\n    pinMode(IN2, OUTPUT);\n    pinMode(IN3, OUTPUT);\n    pinMode(IN4, OUTPUT);\n}\n\nvoid loop() {\n    // Gira o motor para frente\n    for(int i = 0; i &lt; 4; i++) {\n        digitalWrite(IN1, passos[i][0]);\n        digitalWrite(IN2, passos[i][1]);\n        digitalWrite(IN3, passos[i][2]);\n        digitalWrite(IN4, passos[i][3]);\n        delay(100);\n    }\n\n    delay(1000);\n\n    // Gira o motor para tr\u00e1s\n    for(int i = 3; i &gt;= 0; i--) {\n        digitalWrite(IN1, passos[i][0]);\n        digitalWrite(IN2, passos[i][1]);\n        digitalWrite(IN3, passos[i][2]);\n        digitalWrite(IN4, passos[i][3]);\n        delay(100);\n    }\n\n    delay(1000);\n}\n</code></pre> <p>Explica\u00e7\u00e3o:</p> <ul> <li>Sequ\u00eancia de Passos: Define a sequ\u00eancia de ativa\u00e7\u00e3o dos pinos para girar o motor.</li> <li>Controle Direcional: Alterando a ordem da sequ\u00eancia, o motor gira para frente ou para tr\u00e1s.</li> <li>Delay: Controla a velocidade de rota\u00e7\u00e3o do motor.</li> </ul>"},{"location":"aulas/iot/modulos/modulo11.html#5-utilizando-drivers-de-motor-avancados","title":"5. Utilizando Drivers de Motor Avan\u00e7ados","text":""},{"location":"aulas/iot/modulos/modulo11.html#51-driver-l298n","title":"5.1 Driver L298N","text":"<p>O L298N \u00e9 um driver de motor dual que permite controlar dois motores DC ou um motor de passo com facilidade.</p> <p>Caracter\u00edsticas:</p> <ul> <li>Suporta motores de at\u00e9 46V e 2A por canal.</li> <li>Permite controle de dire\u00e7\u00e3o e velocidade.</li> <li>Inclui termina\u00e7\u00e3o de prote\u00e7\u00e3o e dissipa\u00e7\u00e3o de calor.</li> </ul>"},{"location":"aulas/iot/modulos/modulo11.html#52-conectando-o-l298n-ao-arduino","title":"5.2 Conectando o L298N ao Arduino","text":"<p>Componentes Necess\u00e1rios:</p> <ul> <li>Driver L298N</li> <li>Motores DC ou de Passo</li> <li>Fonte de Alimenta\u00e7\u00e3o Adequada</li> <li>Cabos de Conex\u00e3o</li> <li>Arduino</li> </ul> <p>Conex\u00e3o:</p> <ul> <li>Motor 1 e Motor 2: Conectados \u00e0s sa\u00eddas do driver.</li> <li>IN1, IN2, IN3, IN4: Conectados a pinos digitais do Arduino para controle de dire\u00e7\u00e3o.</li> <li>ENA e ENB: Conectados a pinos PWM do Arduino para controle de velocidade.</li> <li>VCC e GND: Conectados \u00e0 fonte de alimenta\u00e7\u00e3o e ao GND do Arduino.</li> <li>12V: Alimenta\u00e7\u00e3o dos motores (se aplic\u00e1vel).</li> </ul>"},{"location":"aulas/iot/modulos/modulo11.html#53-exemplo-de-codigo-para-controle-de-dois-motores-dc-com-l298n","title":"5.3 Exemplo de C\u00f3digo para Controle de Dois Motores DC com L298N","text":"<pre><code>// Defini\u00e7\u00e3o dos pinos para Motor 1\nconst int IN1 = 8;\nconst int IN2 = 9;\nconst int ENA = 10;\n\n// Defini\u00e7\u00e3o dos pinos para Motor 2\nconst int IN3 = 11;\nconst int IN4 = 12;\nconst int ENB = 13;\n\nvoid setup() {\n    // Configura os pinos como sa\u00edda\n    pinMode(IN1, OUTPUT);\n    pinMode(IN2, OUTPUT);\n    pinMode(IN3, OUTPUT);\n    pinMode(IN4, OUTPUT);\n    pinMode(ENA, OUTPUT);\n    pinMode(ENB, OUTPUT);\n}\n\nvoid loop() {\n    // Motor 1 para frente\n    digitalWrite(IN1, HIGH);\n    digitalWrite(IN2, LOW);\n    analogWrite(ENA, 200);\n\n    // Motor 2 para tr\u00e1s\n    digitalWrite(IN3, LOW);\n    digitalWrite(IN4, HIGH);\n    analogWrite(ENB, 200);\n\n    delay(2000);\n\n    // Motor 1 para tr\u00e1s\n    digitalWrite(IN1, LOW);\n    digitalWrite(IN2, HIGH);\n    analogWrite(ENA, 200);\n\n    // Motor 2 para frente\n    digitalWrite(IN3, HIGH);\n    digitalWrite(IN4, LOW);\n    analogWrite(ENB, 200);\n\n    delay(2000);\n}\n</code></pre> <p>Explica\u00e7\u00e3o:</p> <ul> <li>Controle Dual: Permite controlar dois motores independentes, facilitando aplica\u00e7\u00f5es como rob\u00f4s com rodas duplas.</li> <li>Velocidade e Dire\u00e7\u00e3o: Utiliza sinais digitais para dire\u00e7\u00e3o e PWM para velocidade.</li> </ul>"},{"location":"aulas/iot/modulos/modulo11.html#6-bibliotecas-para-controle-de-motores","title":"6. Bibliotecas para Controle de Motores","text":""},{"location":"aulas/iot/modulos/modulo11.html#61-biblioteca-servo","title":"6.1 Biblioteca Servo","text":"<p>A biblioteca <code>Servo</code> facilita o controle de servo motors, permitindo mover o servo para posi\u00e7\u00f5es espec\u00edficas com facilidade.</p> <p>Instala\u00e7\u00e3o:</p> <p>A biblioteca <code>Servo</code> geralmente vem pr\u00e9-instalada no IDE do Arduino. Caso n\u00e3o esteja, pode ser instalada atrav\u00e9s do gerenciador de bibliotecas.</p>"},{"location":"aulas/iot/modulos/modulo11.html#62-biblioteca-stepper","title":"6.2 Biblioteca Stepper","text":"<p>A biblioteca <code>Stepper</code> simplifica o controle de motores de passo, gerenciando a sequ\u00eancia de passos automaticamente.</p> <p>Instala\u00e7\u00e3o:</p> <p>A biblioteca <code>Stepper</code> tamb\u00e9m est\u00e1 inclu\u00edda na IDE do Arduino. Para motores de passo mais avan\u00e7ados, bibliotecas como <code>AccelStepper</code> podem ser utilizadas.</p>"},{"location":"aulas/iot/modulos/modulo11.html#63-biblioteca-adafruit-motor-shield","title":"6.3 Biblioteca Adafruit Motor Shield","text":"<p>O Adafruit Motor Shield oferece uma interface f\u00e1cil para controlar motores DC, motores de passo e servos, utilizando menos pinos do Arduino.</p> <p>Instala\u00e7\u00e3o:</p> <p>Pode ser instalada atrav\u00e9s do gerenciador de bibliotecas do Arduino:</p> <ol> <li>Abra o IDE do Arduino.</li> <li>V\u00e1 para Sketch &gt; Include Library &gt; Manage Libraries...</li> <li>Procure por \"Adafruit Motor Shield\" e instale a biblioteca.</li> </ol> <p>Exemplo de Uso com Adafruit Motor Shield:</p> <pre><code>#include &lt;Wire.h&gt;\n#include &lt;Adafruit_MotorShield.h&gt;\n\n// Cria o objeto do Motor Shield\nAdafruit_MotorShield AFMS = Adafruit_MotorShield();\n\n// Seleciona o motor DC no slot M1\nAdafruit_DCMotor *motor1 = AFMS.getMotor(1);\n\nvoid setup() {\n    Serial.begin(9600);\n    if (!AFMS.begin()) { // Inicializa o Motor Shield\n        Serial.println(\"Motor Shield n\u00e3o encontrado.\");\n        while (1);\n    }\n\n    motor1-&gt;setSpeed(150); // Define a velocidade (0-255)\n    motor1-&gt;run(FORWARD);  // Motor gira para frente\n}\n\nvoid loop() {\n    motor1-&gt;run(FORWARD);\n    delay(2000);\n\n    motor1-&gt;run(BACKWARD);\n    delay(2000);\n\n    motor1-&gt;run(RELEASE);\n    delay(1000);\n}\n</code></pre> <p>Explica\u00e7\u00e3o:</p> <ul> <li>Inicializa\u00e7\u00e3o: Verifica se o Motor Shield est\u00e1 conectado corretamente.</li> <li>Controle: Utiliza m\u00e9todos da biblioteca para definir a velocidade e dire\u00e7\u00e3o do motor.</li> </ul>"},{"location":"aulas/iot/modulos/modulo11.html#7-exemplos-praticos","title":"7. Exemplos Pr\u00e1ticos","text":""},{"location":"aulas/iot/modulos/modulo11.html#71-controlando-um-servo-motor-com-inputs-do-usuario","title":"7.1 Controlando um Servo Motor com Inputs do Usu\u00e1rio","text":"<pre><code>#include &lt;Servo.h&gt;\n\nServo meuServo;\nconst int pinoServo = 9;\n\nvoid setup() {\n    Serial.begin(9600);\n    meuServo.attach(pinoServo);\n    Serial.println(\"Digite um \u00e2ngulo entre 0 e 180:\");\n}\n\nvoid loop() {\n    if (Serial.available() &gt; 0) {\n        int angulo = Serial.parseInt();\n        if (angulo &gt;= 0 &amp;&amp; angulo &lt;= 180) {\n            meuServo.write(angulo);\n            Serial.print(\"Servo movido para: \");\n            Serial.println(angulo);\n        } else {\n            Serial.println(\"\u00c2ngulo inv\u00e1lido. Tente novamente.\");\n        }\n    }\n}\n</code></pre> <p>Explica\u00e7\u00e3o:</p> <ul> <li>Input do Usu\u00e1rio: Recebe um valor de \u00e2ngulo via Monitor Serial e move o servo para a posi\u00e7\u00e3o correspondente.</li> <li>Valida\u00e7\u00e3o: Garante que o \u00e2ngulo esteja dentro do intervalo v\u00e1lido (0 a 180 graus).</li> </ul>"},{"location":"aulas/iot/modulos/modulo11.html#72-controlando-a-velocidade-de-um-motor-dc-com-potenciometro","title":"7.2 Controlando a Velocidade de um Motor DC com Potenci\u00f4metro","text":"<pre><code>const int ENA = 10;\nconst int IN1 = 9;\nconst int IN2 = 8;\nconst int pinoPot = A0;\n\nvoid setup() {\n    pinMode(IN1, OUTPUT);\n    pinMode(IN2, OUTPUT);\n    pinMode(ENA, OUTPUT);\n    Serial.begin(9600);\n}\n\nvoid loop() {\n    int valorPot = analogRead(pinoPot);\n    int velocidade = map(valorPot, 0, 1023, 0, 255);\n    analogWrite(ENA, velocidade);\n    Serial.print(\"Velocidade: \");\n    Serial.println(velocidade);\n    delay(100);\n}\n</code></pre> <p>Explica\u00e7\u00e3o:</p> <ul> <li>Controle Anal\u00f3gico: Utiliza um potenci\u00f4metro para ajustar a velocidade do motor DC em tempo real.</li> <li>Mapeamento: Converte o valor anal\u00f3gico (0-1023) para um valor PWM (0-255).</li> </ul>"},{"location":"aulas/iot/modulos/modulo11.html#73-implementando-movimento-preciso-com-motor-de-passo","title":"7.3 Implementando Movimento Preciso com Motor de Passo","text":"<pre><code>#include &lt;Stepper.h&gt;\n\n// Define o n\u00famero de passos por revolu\u00e7\u00e3o do motor\nconst int passosPorRevolucao = 200;\n\n// Inicializa a biblioteca Stepper\nStepper meuStepper(passosPorRevolucao, 8, 9, 10, 11);\n\nvoid setup() {\n    Serial.begin(9600);\n    meuStepper.setSpeed(60); // Define a velocidade (RPM)\n}\n\nvoid loop() {\n    Serial.println(\"Giro para frente\");\n    meuStepper.step(passosPorRevolucao); // Gira uma revolu\u00e7\u00e3o\n    delay(1000);\n\n    Serial.println(\"Giro para tr\u00e1s\");\n    meuStepper.step(-passosPorRevolucao); // Gira uma revolu\u00e7\u00e3o na dire\u00e7\u00e3o oposta\n    delay(1000);\n}\n</code></pre> <p>Explica\u00e7\u00e3o:</p> <ul> <li>Biblioteca Stepper: Facilita o controle de motores de passo, gerenciando a sequ\u00eancia de passos.</li> <li>Controle Direcional: Passos positivos giram o motor para frente e passos negativos para tr\u00e1s.</li> </ul>"},{"location":"aulas/iot/modulos/modulo11.html#8-exercicios-praticos","title":"8. Exerc\u00edcios Pr\u00e1ticos","text":""},{"location":"aulas/iot/modulos/modulo11.html#exercicio-1-controlar-dois-motores-dc-independentes","title":"Exerc\u00edcio 1: Controlar Dois Motores DC Independentes","text":"<ul> <li> <p>Tarefa: Crie um projeto que controla dois motores DC independentemente, permitindo que cada motor gire para frente ou para tr\u00e1s com diferentes velocidades.</p> </li> <li> <p>Dicas:</p> </li> <li>Utilize um driver de motor dual como o L298N.</li> <li> <p>Controle a dire\u00e7\u00e3o e velocidade de cada motor separadamente.</p> </li> <li> <p>Exemplo de C\u00f3digo:</p> </li> </ul> <pre><code>// Defini\u00e7\u00e3o dos pinos para Motor 1\nconst int IN1 = 8;\nconst int IN2 = 9;\nconst int ENA = 10;\n\n// Defini\u00e7\u00e3o dos pinos para Motor 2\nconst int IN3 = 11;\nconst int IN4 = 12;\nconst int ENB = 13;\n\nvoid setup() {\n    // Configura os pinos como sa\u00edda\n    pinMode(IN1, OUTPUT);\n    pinMode(IN2, OUTPUT);\n    pinMode(IN3, OUTPUT);\n    pinMode(IN4, OUTPUT);\n    pinMode(ENA, OUTPUT);\n    pinMode(ENB, OUTPUT);\n}\n\nvoid loop() {\n    // Motor 1 para frente com velocidade 200\n    digitalWrite(IN1, HIGH);\n    digitalWrite(IN2, LOW);\n    analogWrite(ENA, 200);\n\n    // Motor 2 para tr\u00e1s com velocidade 150\n    digitalWrite(IN3, LOW);\n    digitalWrite(IN4, HIGH);\n    analogWrite(ENB, 150);\n\n    delay(3000);\n\n    // Motor 1 para tr\u00e1s com velocidade 200\n    digitalWrite(IN1, LOW);\n    digitalWrite(IN2, HIGH);\n    analogWrite(ENA, 200);\n\n    // Motor 2 para frente com velocidade 150\n    digitalWrite(IN3, HIGH);\n    digitalWrite(IN4, LOW);\n    analogWrite(ENB, 150);\n\n    delay(3000);\n}\n</code></pre>"},{"location":"aulas/iot/modulos/modulo11.html#exercicio-2-controlar-a-posicao-de-um-servo-com-botoes","title":"Exerc\u00edcio 2: Controlar a Posi\u00e7\u00e3o de um Servo com Bot\u00f5es","text":"<ul> <li> <p>Tarefa: Desenvolva um sistema onde dois bot\u00f5es controlam a posi\u00e7\u00e3o de um servo motor, movendo-o para a esquerda ou para a direita.</p> </li> <li> <p>Dicas:</p> </li> <li>Utilize resistores de pull-down para os bot\u00f5es.</li> <li> <p>Controle a posi\u00e7\u00e3o do servo incrementando ou decrementando o \u00e2ngulo.</p> </li> <li> <p>Exemplo de C\u00f3digo:</p> </li> </ul> <pre><code>#include &lt;Servo.h&gt;\n\nServo meuServo;\nconst int pinoServo = 9;\nconst int botaoEsquerda = 2;\nconst int botaoDireita = 3;\n\nint posicao = 90; // Posi\u00e7\u00e3o inicial\n\nvoid setup() {\n    meuServo.attach(pinoServo);\n    pinMode(botaoEsquerda, INPUT_PULLUP);\n    pinMode(botaoDireita, INPUT_PULLUP);\n    meuServo.write(posicao);\n    Serial.begin(9600);\n}\n\nvoid loop() {\n    if (digitalRead(botaoEsquerda) == LOW) {\n        posicao -= 5;\n        if (posicao &lt; 0) posicao = 0;\n        meuServo.write(posicao);\n        Serial.print(\"Posi\u00e7\u00e3o: \");\n        Serial.println(posicao);\n        delay(200); // Debounce\n    }\n\n    if (digitalRead(botaoDireita) == LOW) {\n        posicao += 5;\n        if (posicao &gt; 180) posicao = 180;\n        meuServo.write(posicao);\n        Serial.print(\"Posi\u00e7\u00e3o: \");\n        Serial.println(posicao);\n        delay(200); // Debounce\n    }\n}\n</code></pre> <p>Explica\u00e7\u00e3o:</p> <ul> <li>Bot\u00f5es: Dois bot\u00f5es conectados aos pinos 2 e 3 controlam a dire\u00e7\u00e3o do movimento do servo.</li> <li>Controle de Posi\u00e7\u00e3o: Incrementa ou decrementa o \u00e2ngulo do servo em 5 graus a cada pressionamento.</li> </ul>"},{"location":"aulas/iot/modulos/modulo11.html#exercicio-3-controlar-um-motor-de-passo-com-potenciometro","title":"Exerc\u00edcio 3: Controlar um Motor de Passo com Potenci\u00f4metro","text":"<ul> <li> <p>Tarefa: Implemente um sistema onde a velocidade de um motor de passo \u00e9 controlada por um potenci\u00f4metro.</p> </li> <li> <p>Dicas:</p> </li> <li>Utilize a biblioteca <code>Stepper</code> para facilitar o controle.</li> <li> <p>Mapeie a leitura do potenci\u00f4metro para a velocidade do motor.</p> </li> <li> <p>Exemplo de C\u00f3digo:</p> </li> </ul> <pre><code>#include &lt;Stepper.h&gt;\n\nconst int passosPorRevolucao = 200;\nStepper meuStepper(passosPorRevolucao, 8, 9, 10, 11);\n\nconst int pinoPot = A0;\n\nvoid setup() {\n    Serial.begin(9600);\n}\n\nvoid loop() {\n    int valorPot = analogRead(pinoPot);\n    int velocidade = map(valorPot, 0, 1023, 0, 60); // Mapeia para 0-60 RPM\n    meuStepper.setSpeed(velocidade);\n    meuStepper.step(100); // Move 100 passos\n    Serial.print(\"Velocidade: \");\n    Serial.println(velocidade);\n    delay(500);\n}\n</code></pre> <p>Explica\u00e7\u00e3o:</p> <ul> <li>Controle de Velocidade: Utiliza um potenci\u00f4metro para ajustar a velocidade do motor de passo em tempo real.</li> <li>Mapeamento: Converte a leitura anal\u00f3gica (0-1023) para uma velocidade em RPM (0-60).</li> </ul>"},{"location":"aulas/iot/modulos/modulo11.html#9-conceitos-importantes","title":"9. Conceitos Importantes","text":""},{"location":"aulas/iot/modulos/modulo11.html#91-drivers-de-motor","title":"9.1 Drivers de Motor","text":"<ul> <li>Defini\u00e7\u00e3o: Circuitos que permitem ao Arduino controlar motores de alta pot\u00eancia de forma segura.</li> <li>Tipos Comuns: L298N, L293D, A4988, ULN2003.</li> <li>Considera\u00e7\u00f5es: Escolha o driver adequado com base na corrente e tens\u00e3o do motor.</li> </ul>"},{"location":"aulas/iot/modulos/modulo11.html#92-pwm-pulse-width-modulation","title":"9.2 PWM (Pulse Width Modulation)","text":"<ul> <li>Defini\u00e7\u00e3o: T\u00e9cnica de controle de velocidade de motores ajustando a largura dos pulsos de tens\u00e3o.</li> <li>Aplica\u00e7\u00e3o: Utilizada para controlar a velocidade de motores DC e a intensidade de LEDs.</li> <li>Frequ\u00eancia: Importante para evitar ru\u00eddos e vibra\u00e7\u00f5es indesejadas.</li> </ul>"},{"location":"aulas/iot/modulos/modulo11.html#93-controlando-direcao-e-velocidade","title":"9.3 Controlando Dire\u00e7\u00e3o e Velocidade","text":"<ul> <li>Dire\u00e7\u00e3o: Controlada atrav\u00e9s da invers\u00e3o dos sinais de controle nos pinos de dire\u00e7\u00e3o.</li> <li>Velocidade: Controlada ajustando o valor de PWM aplicado ao driver do motor.</li> </ul>"},{"location":"aulas/iot/modulos/modulo11.html#94-bibliotecas-para-facilitar-o-controle","title":"9.4 Bibliotecas para Facilitar o Controle","text":"<ul> <li>Servo: Simplifica o controle de servo motors.</li> <li>Stepper: Facilita o controle de motores de passo.</li> <li>Adafruit Motor Shield: Oferece uma interface simplificada para controlar m\u00faltiplos motores e atuadores.</li> </ul>"},{"location":"aulas/iot/modulos/modulo11.html#95-boas-praticas-no-controle-de-motores","title":"9.5 Boas Pr\u00e1ticas no Controle de Motores","text":"<ul> <li>Prote\u00e7\u00e3o contra Sobrecorrente: Utilize fus\u00edveis ou circuitos de prote\u00e7\u00e3o para evitar danos aos componentes.</li> <li>Alimenta\u00e7\u00e3o Adequada: Certifique-se de que a fonte de alimenta\u00e7\u00e3o atende \u00e0s necessidades dos motores.</li> <li>Gerenciamento de Calor: Drivers de motor podem aquecer; utilize dissipadores de calor se necess\u00e1rio.</li> <li>Isolamento de Sinais: Utilize optoacopladores para isolar o Arduino dos circuitos de alta pot\u00eancia, se aplic\u00e1vel.</li> </ul>"},{"location":"aulas/iot/modulos/modulo11.html#10-recursos-adicionais","title":"10. Recursos Adicionais","text":"<ul> <li> <p>Documenta\u00e7\u00e3o Oficial do Arduino:</p> </li> <li> <p>Servo Library</p> </li> <li>Stepper Library</li> <li> <p>Motor Shield Library</p> </li> <li> <p>Tutoriais e Guias:</p> </li> <li> <p>Controle de Motores DC com Arduino</p> </li> <li>Controlando Servo Motors</li> <li> <p>Controlando Motores de Passo</p> </li> <li> <p>V\u00eddeos Educacionais:</p> </li> <li> <p>Controlando Motores DC com Arduino</p> </li> <li>Controle de Servo Motor com Arduino</li> <li>Motor de Passo com Arduino</li> </ul>"},{"location":"aulas/iot/modulos/modulo11.html#11-conclusao-do-modulo","title":"11. Conclus\u00e3o do M\u00f3dulo","text":"<p>Neste m\u00f3dulo, voc\u00ea aprendeu:</p> <ul> <li>Os diferentes tipos de motores e atuadores e suas aplica\u00e7\u00f5es.</li> <li>Como controlar motores DC utilizando drivers de motor e sinais PWM.</li> <li>Como utilizar a biblioteca <code>Servo</code> para controlar servo motors com precis\u00e3o.</li> <li>O funcionamento e controle de motores de passo utilizando a biblioteca <code>Stepper</code>.</li> <li>Como utilizar drivers de motor avan\u00e7ados como o L298N e Adafruit Motor Shield.</li> <li>Conceitos fundamentais como PWM, controle direcional e velocidade.</li> <li>Praticou com exemplos e exerc\u00edcios que refor\u00e7am o entendimento do controle de motores e atuadores.</li> </ul> <p>Voc\u00ea est\u00e1 agora preparado para avan\u00e7ar para o pr\u00f3ximo m\u00f3dulo, onde exploraremos Sensores e Aquisi\u00e7\u00e3o de Dados, aprofundando seu conhecimento em leitura e interpreta\u00e7\u00e3o de dados de sensores com Arduino.</p>"},{"location":"aulas/iot/modulos/modulo11.html#12-proximos-passos","title":"12. Pr\u00f3ximos Passos","text":"<ul> <li>Revisar o conte\u00fado deste m\u00f3dulo e certificar-se de que compreendeu os conceitos apresentados.</li> <li>Completar os exerc\u00edcios propostos para consolidar o aprendizado.</li> <li>Preparar-se para o M\u00f3dulo 12: Sensores e Aquisi\u00e7\u00e3o de Dados.</li> </ul> <p>Se tiver d\u00favidas ou precisar de assist\u00eancia, n\u00e3o hesite em procurar recursos adicionais ou participar de comunidades de aprendizagem para obter suporte.</p> <p>Bom trabalho e continue assim!</p>"},{"location":"aulas/iot/modulos/modulo12.html","title":"M\u00f3dulo 12: Sensores e Aquisi\u00e7\u00e3o de Dados","text":"<p>Bem-vindo ao M\u00f3dulo 12 do curso \"Programa\u00e7\u00e3o em Arduino: Conceitos Fundamentais sem Hardware\". Neste m\u00f3dulo, voc\u00ea ir\u00e1 explorar o uso de sensores e as t\u00e9cnicas de aquisi\u00e7\u00e3o de dados com o Arduino. Sensores s\u00e3o componentes essenciais que permitem ao Arduino interagir com o ambiente f\u00edsico, coletando informa\u00e7\u00f5es que podem ser processadas e utilizadas em diversos projetos.</p>"},{"location":"aulas/iot/modulos/modulo12.html#objetivos-do-modulo","title":"Objetivos do M\u00f3dulo","text":"<ul> <li>Compreender os diferentes tipos de sensores dispon\u00edveis para Arduino.</li> <li>Aprender a conectar e configurar sensores com o Arduino.</li> <li>Implementar a leitura de dados de sensores utilizando entradas anal\u00f3gicas e digitais.</li> <li>Utilizar bibliotecas espec\u00edficas para facilitar a comunica\u00e7\u00e3o com sensores complexos.</li> <li>Processar e interpretar os dados coletados de sensores.</li> <li>Resolver exerc\u00edcios pr\u00e1ticos para consolidar o conhecimento sobre sensores e aquisi\u00e7\u00e3o de dados.</li> </ul>"},{"location":"aulas/iot/modulos/modulo12.html#1-introducao-a-sensores-e-aquisicao-de-dados","title":"1. Introdu\u00e7\u00e3o a Sensores e Aquisi\u00e7\u00e3o de Dados","text":""},{"location":"aulas/iot/modulos/modulo12.html#11-o-que-sao-sensores","title":"1.1 O que s\u00e3o Sensores?","text":"<p>Sensores s\u00e3o dispositivos que detectam eventos ou mudan\u00e7as no ambiente f\u00edsico e convertem essas informa\u00e7\u00f5es em sinais el\u00e9tricos que podem ser processados pelo Arduino. Eles permitem que o Arduino interaja com o mundo real, tornando poss\u00edvel a cria\u00e7\u00e3o de projetos inteligentes e responsivos.</p>"},{"location":"aulas/iot/modulos/modulo12.html#12-importancia-da-aquisicao-de-dados","title":"1.2 Import\u00e2ncia da Aquisi\u00e7\u00e3o de Dados","text":"<p>A aquisi\u00e7\u00e3o de dados envolve a coleta, processamento e an\u00e1lise de informa\u00e7\u00f5es provenientes de sensores. \u00c9 um componente fundamental em sistemas de automa\u00e7\u00e3o, monitoramento ambiental, rob\u00f3tica e muitas outras aplica\u00e7\u00f5es que requerem intera\u00e7\u00e3o com o ambiente.</p>"},{"location":"aulas/iot/modulos/modulo12.html#13-tipos-comuns-de-sensores-para-arduino","title":"1.3 Tipos Comuns de Sensores para Arduino","text":"<ul> <li>Sensores de Temperatura: Como o LM35 e o DHT11/DHT22.</li> <li>Sensores de Umidade: Integrados em sensores como o DHT11/DHT22.</li> <li>Sensores de Movimento: Como o PIR (Passive Infrared) e aceler\u00f4metros.</li> <li>Sensores de Luz: Como o LDR (Light Dependent Resistor).</li> <li>Sensores de Dist\u00e2ncia: Como o Ultrass\u00f4nico HC-SR04.</li> <li>Sensores de G\u00e1s: Como o MQ-2 e MQ-135.</li> <li>Sensores de Press\u00e3o: Como o BMP180 e BMP280.</li> </ul>"},{"location":"aulas/iot/modulos/modulo12.html#2-interfacing-sensores-com-arduino","title":"2. Interfacing Sensores com Arduino","text":""},{"location":"aulas/iot/modulos/modulo12.html#21-conexoes-basicas-de-sensores","title":"2.1 Conex\u00f5es B\u00e1sicas de Sensores","text":"<p>A maneira como voc\u00ea conecta um sensor ao Arduino depende do tipo de sensor e das suas especifica\u00e7\u00f5es. A seguir, veremos exemplos de como conectar sensores comuns.</p>"},{"location":"aulas/iot/modulos/modulo12.html#22-sensores-digitais-vs-analogicos","title":"2.2 Sensores Digitais vs. Anal\u00f3gicos","text":"<ul> <li>Sensores Digitais: Enviam sinais digitais (HIGH ou LOW) para o Arduino. Exemplo: Sensor de movimento PIR.</li> <li>Sensores Anal\u00f3gicos: Enviam sinais anal\u00f3gicos que variam entre 0 e 5V. O Arduino utiliza um conversor anal\u00f3gico-digital (ADC) para interpretar esses sinais. Exemplo: LDR (Light Dependent Resistor).</li> </ul>"},{"location":"aulas/iot/modulos/modulo12.html#23-exemplo-de-conexao-de-um-ldr","title":"2.3 Exemplo de Conex\u00e3o de um LDR","text":"<p>Componentes Necess\u00e1rios:</p> <ul> <li>LDR (Light Dependent Resistor)</li> <li>Resistores (10k\u03a9)</li> <li>Cabos de Conex\u00e3o</li> <li>Protoboard</li> <li>Arduino</li> </ul> <p>Conex\u00e3o:</p> <ol> <li>Conecte uma extremidade do LDR ao pino 5V do Arduino.</li> <li>Conecte a outra extremidade do LDR a um terminal do resistor de 10k\u03a9.</li> <li>Conecte o outro terminal do resistor ao GND do Arduino.</li> <li>Conecte o ponto de jun\u00e7\u00e3o entre o LDR e o resistor ao pino anal\u00f3gico A0 do Arduino.</li> </ol>"},{"location":"aulas/iot/modulos/modulo12.html#3-leitura-de-dados-de-sensores","title":"3. Leitura de Dados de Sensores","text":""},{"location":"aulas/iot/modulos/modulo12.html#31-leitura-de-sensores-analogicos","title":"3.1 Leitura de Sensores Anal\u00f3gicos","text":"<p>Os sensores anal\u00f3gicos fornecem um valor cont\u00ednuo que pode ser lido pelo Arduino usando a fun\u00e7\u00e3o <code>analogRead()</code>.</p> <p>Exemplo de C\u00f3digo para Ler um LDR:</p> <p>\u02dc\u02dc\u02dccpp const int pinoLDR = A0;</p> <p>void setup() {     Serial.begin(9600);     pinMode(pinoLDR, INPUT); }</p> <p>void loop() {     int valorLDR = analogRead(pinoLDR);     Serial.print(\"Valor do LDR: \");     Serial.println(valorLDR);     delay(500); } \u02dc\u02dc\u02dc</p> <p>Explica\u00e7\u00e3o:</p> <ul> <li><code>analogRead(pinoLDR)</code>: L\u00ea o valor anal\u00f3gico do pino A0, retornando um valor entre 0 e 1023.</li> <li>Serial Monitor: Exibe o valor lido, permitindo monitorar a varia\u00e7\u00e3o da luz ambiente.</li> </ul>"},{"location":"aulas/iot/modulos/modulo12.html#32-leitura-de-sensores-digitais","title":"3.2 Leitura de Sensores Digitais","text":"<p>Sensores digitais enviam sinais HIGH ou LOW. A leitura \u00e9 feita usando a fun\u00e7\u00e3o <code>digitalRead()</code>.</p> <p>Exemplo de C\u00f3digo para Ler um Sensor PIR:</p> <p>\u02dc\u02dc\u02dccpp const int pinoPIR = 2; volatile bool movimentoDetectado = false;</p> <p>void setup() {     Serial.begin(9600);     pinMode(pinoPIR, INPUT); }</p> <p>void loop() {     int estadoPIR = digitalRead(pinoPIR);     if (estadoPIR == HIGH) {         if (!movimentoDetectado) {             Serial.println(\"Movimento Detectado!\");             movimentoDetectado = true;         }     } else {         if (movimentoDetectado) {             Serial.println(\"Movimento Terminado.\");             movimentoDetectado = false;         }     }     delay(100); } \u02dc\u02dc\u02dc</p> <p>Explica\u00e7\u00e3o:</p> <ul> <li><code>digitalRead(pinoPIR)</code>: L\u00ea o estado do pino 2, detectando movimento.</li> <li>Detec\u00e7\u00e3o de Mudan\u00e7a: Evita m\u00faltiplas mensagens ao verificar se o estado mudou.</li> </ul>"},{"location":"aulas/iot/modulos/modulo12.html#4-utilizando-bibliotecas-para-sensores-complexos","title":"4. Utilizando Bibliotecas para Sensores Complexos","text":"<p>Alguns sensores requerem o uso de bibliotecas espec\u00edficas para facilitar a comunica\u00e7\u00e3o e o processamento dos dados.</p>"},{"location":"aulas/iot/modulos/modulo12.html#41-biblioteca-dht-para-sensores-de-temperatura-e-umidade","title":"4.1 Biblioteca DHT para Sensores de Temperatura e Umidade","text":"<p>Os sensores DHT11 e DHT22 s\u00e3o populares para medir temperatura e umidade. A biblioteca <code>DHT</code> simplifica a leitura desses sensores.</p> <p>Instala\u00e7\u00e3o da Biblioteca DHT:</p> <ol> <li>Abra o IDE do Arduino.</li> <li>V\u00e1 para Sketch &gt; Include Library &gt; Manage Libraries...</li> <li>Procure por \"DHT sensor library\" e instale a biblioteca de Adafruit.</li> </ol>"},{"location":"aulas/iot/modulos/modulo12.html#42-exemplo-de-codigo-com-biblioteca-dht","title":"4.2 Exemplo de C\u00f3digo com Biblioteca DHT","text":"<p>\u02dc\u02dc\u02dccpp</p>"},{"location":"aulas/iot/modulos/modulo12.html#include-dhth","title":"include \"DHT.h\"","text":""},{"location":"aulas/iot/modulos/modulo12.html#define-dhtpin-2-pino-conectado-ao-sensor","title":"define DHTPIN 2     // Pino conectado ao sensor","text":""},{"location":"aulas/iot/modulos/modulo12.html#define-dhttype-dht22-dht-22-am2302","title":"define DHTTYPE DHT22   // DHT 22 (AM2302)","text":"<p>DHT dht(DHTPIN, DHTTYPE);</p> <p>void setup() {     Serial.begin(9600);     dht.begin(); }</p> <p>void loop() {     // Aguarda alguns segundos entre as leituras     delay(2000);</p> <pre><code>// L\u00ea a umidade\nfloat umidade = dht.readHumidity();\n// L\u00ea a temperatura em Celsius\nfloat temperatura = dht.readTemperature();\n\n// Verifica se alguma leitura falhou\nif (isnan(umidade) || isnan(temperatura)) {\n    Serial.println(\"Falha na leitura do sensor DHT!\");\n    return;\n}\n\nSerial.print(\"Umidade: \");\nSerial.print(umidade);\nSerial.print(\" %\\t\");\nSerial.print(\"Temperatura: \");\nSerial.print(temperatura);\nSerial.println(\" *C\");\n</code></pre> <p>} \u02dc\u02dc\u02dc</p> <p>Explica\u00e7\u00e3o:</p> <ul> <li>Inicializa\u00e7\u00e3o: Configura o sensor DHT22 no pino 2.</li> <li>Leitura de Dados: Obt\u00e9m valores de umidade e temperatura.</li> <li>Valida\u00e7\u00e3o: Verifica se as leituras s\u00e3o v\u00e1lidas antes de exibir.</li> </ul>"},{"location":"aulas/iot/modulos/modulo12.html#5-processamento-e-interpretacao-de-dados","title":"5. Processamento e Interpreta\u00e7\u00e3o de Dados","text":"<p>Ap\u00f3s a aquisi\u00e7\u00e3o dos dados, \u00e9 importante process\u00e1-los para obter informa\u00e7\u00f5es \u00fateis e tomar decis\u00f5es baseadas nesses dados.</p>"},{"location":"aulas/iot/modulos/modulo12.html#51-mapeamento-de-valores","title":"5.1 Mapeamento de Valores","text":"<p>O mapeamento \u00e9 usado para converter valores de um intervalo para outro.</p> <p>Exemplo: Mapeando Valores de Temperatura para Controle de LED:</p> <p>\u02dc\u02dc\u02dccpp const int pinoLED = 9;</p> <p>void setup() {     pinMode(pinoLED, OUTPUT);     Serial.begin(9600); }</p> <p>void loop() {     // Supondo que temperatura seja lida de um sensor     float temperatura = 25.0; // Valor de exemplo     // Mapeia temperatura de 0-50\u00b0C para 0-255 (PWM)     int intensidade = map(temperatura * 10, 0, 500, 0, 255);     analogWrite(pinoLED, intensidade);     Serial.print(\"Temperatura: \");     Serial.print(temperatura);     Serial.print(\" *C\\tLED Intensidade: \");     Serial.println(intensidade);     delay(1000); } \u02dc\u02dc\u02dc</p> <p>Explica\u00e7\u00e3o:</p> <ul> <li><code>map()</code>: Converte a temperatura em um valor PWM para controlar a intensidade do LED.</li> <li>Controle de LED: A intensidade do LED varia conforme a temperatura lida.</li> </ul>"},{"location":"aulas/iot/modulos/modulo12.html#52-filtragem-de-dados","title":"5.2 Filtragem de Dados","text":"<p>A filtragem \u00e9 usada para remover ru\u00eddos e obter leituras mais precisas.</p> <p>Exemplo: M\u00e9dia M\u00f3vel para Filtrar Ru\u00eddo em Leituras de Sensor:</p> <p>\u02dc\u02dc\u02dccpp const int pinoSensor = A0; const int tamanhoJanela = 10; int valores[tamanhoJanela]; int indice = 0; long soma = 0;</p> <p>void setup() {     Serial.begin(9600);     for(int i = 0; i &lt; tamanhoJanela; i++) {         valores[i] = 0;     } }</p> <p>void loop() {     // L\u00ea o novo valor do sensor     int novoValor = analogRead(pinoSensor);     // Subtrai o valor antigo da soma     soma -= valores[indice];     // Adiciona o novo valor \u00e0 soma     soma += novoValor;     // Armazena o novo valor na janela     valores[indice] = novoValor;     // Incrementa o \u00edndice e reinicia se necess\u00e1rio     indice = (indice + 1) % tamanhoJanela;     // Calcula a m\u00e9dia     float media = soma / (float)tamanhoJanela;     Serial.print(\"M\u00e9dia: \");     Serial.println(media);     delay(500); } \u02dc\u02dc\u02dc</p> <p>Explica\u00e7\u00e3o:</p> <ul> <li>Janela de M\u00e9dia: Mant\u00e9m os \u00faltimos 10 valores lidos.</li> <li>C\u00e1lculo da M\u00e9dia: Obt\u00e9m a m\u00e9dia dos valores para filtrar ru\u00eddos.</li> </ul>"},{"location":"aulas/iot/modulos/modulo12.html#6-exemplos-praticos","title":"6. Exemplos Pr\u00e1ticos","text":""},{"location":"aulas/iot/modulos/modulo12.html#61-monitoramento-de-temperatura-e-controle-de-ventilador","title":"6.1 Monitoramento de Temperatura e Controle de Ventilador","text":"<p>Este exemplo utiliza um sensor de temperatura para monitorar a temperatura ambiente e controla um ventilador (motor DC) com base nas leituras.</p> <p>\u02dc\u02dc\u02dccpp</p>"},{"location":"aulas/iot/modulos/modulo12.html#include-dhth_1","title":"include \"DHT.h\"","text":""},{"location":"aulas/iot/modulos/modulo12.html#define-dhtpin-2","title":"define DHTPIN 2","text":""},{"location":"aulas/iot/modulos/modulo12.html#define-dhttype-dht22","title":"define DHTTYPE DHT22","text":"<p>DHT dht(DHTPIN, DHTTYPE);</p> <p>const int IN1 = 9; const int IN2 = 8; const int ENA = 10;</p> <p>void setup() {     Serial.begin(9600);     dht.begin();     pinMode(IN1, OUTPUT);     pinMode(IN2, OUTPUT);     pinMode(ENA, OUTPUT); }</p> <p>void loop() {     delay(2000);     float temperatura = dht.readTemperature();     if (isnan(temperatura)) {         Serial.println(\"Falha na leitura do sensor DHT!\");         return;     }</p> <pre><code>Serial.print(\"Temperatura: \");\nSerial.print(temperatura);\nSerial.println(\" *C\");\n\nif (temperatura &gt; 25.0) {\n    // Liga o ventilador\n    digitalWrite(IN1, HIGH);\n    digitalWrite(IN2, LOW);\n    analogWrite(ENA, 200);\n    Serial.println(\"Ventilador Ligado.\");\n} else {\n    // Desliga o ventilador\n    digitalWrite(IN1, LOW);\n    digitalWrite(IN2, LOW);\n    analogWrite(ENA, 0);\n    Serial.println(\"Ventilador Desligado.\");\n}\n</code></pre> <p>} \u02dc\u02dc\u02dc</p> <p>Explica\u00e7\u00e3o:</p> <ul> <li>Leitura de Temperatura: Utiliza o sensor DHT22 para obter a temperatura ambiente.</li> <li>Controle do Ventilador: Liga o ventilador se a temperatura exceder 25\u00b0C e desliga caso contr\u00e1rio.</li> </ul>"},{"location":"aulas/iot/modulos/modulo12.html#62-sistema-de-alarme-com-sensor-de-gas","title":"6.2 Sistema de Alarme com Sensor de G\u00e1s","text":"<p>Este exemplo utiliza um sensor de g\u00e1s para detectar a presen\u00e7a de gases nocivos e aciona um alarme (LED e buzzer) quando n\u00edveis perigosos s\u00e3o detectados.</p> <p>\u02dc\u02dc\u02dccpp const int pinoG\u00e1s = A0; const int pinoLED = 13; const int pinoBuzzer = 12; const int limiarG\u00e1s = 300; // Valor de exemplo</p> <p>void setup() {     Serial.begin(9600);     pinMode(pinoLED, OUTPUT);     pinMode(pinoBuzzer, OUTPUT); }</p> <p>void loop() {     int valorG\u00e1s = analogRead(pinoG\u00e1s);     Serial.print(\"N\u00edvel de G\u00e1s: \");     Serial.println(valorG\u00e1s);</p> <pre><code>if (valorG\u00e1s &gt; limiarG\u00e1s) {\n    digitalWrite(pinoLED, HIGH);\n    digitalWrite(pinoBuzzer, HIGH);\n    Serial.println(\"Alerta! N\u00edvel de g\u00e1s perigoso!\");\n} else {\n    digitalWrite(pinoLED, LOW);\n    digitalWrite(pinoBuzzer, LOW);\n}\ndelay(1000);\n</code></pre> <p>} \u02dc\u02dc\u02dc</p> <p>Explica\u00e7\u00e3o:</p> <ul> <li>Leitura do Sensor de G\u00e1s: Monitora continuamente os n\u00edveis de g\u00e1s.</li> <li>Ativa\u00e7\u00e3o do Alarme: Aciona LED e buzzer quando o n\u00edvel de g\u00e1s ultrapassa o limiar definido.</li> </ul>"},{"location":"aulas/iot/modulos/modulo12.html#63-monitoramento-de-distancia-com-ultrassonico-e-display-lcd","title":"6.3 Monitoramento de Dist\u00e2ncia com Ultrass\u00f4nico e Display LCD","text":"<p>Este exemplo utiliza um sensor ultrass\u00f4nico para medir a dist\u00e2ncia at\u00e9 um objeto e exibe os resultados em um display LCD.</p> <p>\u02dc\u02dc\u02dccpp</p>"},{"location":"aulas/iot/modulos/modulo12.html#include","title":"include  <p>// Defini\u00e7\u00e3o dos pinos do LCD LiquidCrystal lcd(12, 11, 5, 4, 3, 2);</p> <p>// Defini\u00e7\u00e3o dos pinos do sensor ultrass\u00f4nico const int trigPin = 9; const int echoPin = 10;</p> <p>void setup() {     lcd.begin(16, 2);     pinMode(trigPin, OUTPUT);     pinMode(echoPin, INPUT);     lcd.print(\"Medindo Distancia\"); }</p> <p>void loop() {     // Limpa o pino Trig     digitalWrite(trigPin, LOW);     delayMicroseconds(2);</p> <pre><code>// Envia pulso de 10us\ndigitalWrite(trigPin, HIGH);\ndelayMicroseconds(10);\ndigitalWrite(trigPin, LOW);\n\n// Calcula a dura\u00e7\u00e3o do pulso\nlong duracao = pulseIn(echoPin, HIGH);\n\n// Calcula a dist\u00e2ncia em cent\u00edmetros\nfloat distancia = duracao * 0.034 / 2;\n\n// Exibe a dist\u00e2ncia no LCD\nlcd.clear();\nlcd.setCursor(0, 0);\nlcd.print(\"Distancia: \");\nlcd.print(distancia);\nlcd.print(\" cm\");\n\nSerial.print(\"Distancia: \");\nSerial.print(distancia);\nSerial.println(\" cm\");\n\ndelay(1000);\n</code></pre> <p>} \u02dc\u02dc\u02dc</p> <p>Explica\u00e7\u00e3o:</p> <ul> <li>Sensor Ultrass\u00f4nico: Emite um pulso sonoro e mede o tempo de retorno para calcular a dist\u00e2ncia.</li> <li>Display LCD: Exibe a dist\u00e2ncia medida em tempo real.</li> </ul>","text":""},{"location":"aulas/iot/modulos/modulo12.html#7-exercicios-praticos","title":"7. Exerc\u00edcios Pr\u00e1ticos","text":""},{"location":"aulas/iot/modulos/modulo12.html#exercicio-1-monitoramento-de-temperatura-e-acionamento-de-ventilador-com-hysteresis","title":"Exerc\u00edcio 1: Monitoramento de Temperatura e Acionamento de Ventilador com Hysteresis","text":"<ul> <li> <p>Tarefa: Modifique o exemplo de monitoramento de temperatura para incluir hysteresis, evitando que o ventilador ligue e desligue repetidamente em torno do ponto de corte.</p> </li> <li> <p>Dicas:</p> </li> <li>Defina dois limiares: um para ligar e outro para desligar o ventilador.</li> <li> <p>Utilize uma vari\u00e1vel para rastrear o estado atual do ventilador.</p> </li> <li> <p>Exemplo de C\u00f3digo:</p> </li> </ul> <p>\u02dc\u02dc\u02dccpp</p>"},{"location":"aulas/iot/modulos/modulo12.html#include-dhth_2","title":"include \"DHT.h\"","text":""},{"location":"aulas/iot/modulos/modulo12.html#define-dhtpin-2_1","title":"define DHTPIN 2","text":""},{"location":"aulas/iot/modulos/modulo12.html#define-dhttype-dht22_1","title":"define DHTTYPE DHT22 <p>DHT dht(DHTPIN, DHTTYPE);</p> <p>const int IN1 = 9; const int IN2 = 8; const int ENA = 10;</p> <p>const float limiarLigar = 25.0; const float limiarDesligar = 23.0; bool ventiladorLigado = false;</p> <p>void setup() {     Serial.begin(9600);     dht.begin();     pinMode(IN1, OUTPUT);     pinMode(IN2, OUTPUT);     pinMode(ENA, OUTPUT); }</p> <p>void loop() {     delay(2000);     float temperatura = dht.readTemperature();     if (isnan(temperatura)) {         Serial.println(\"Falha na leitura do sensor DHT!\");         return;     }</p> <pre><code>Serial.print(\"Temperatura: \");\nSerial.print(temperatura);\nSerial.println(\" *C\");\n\nif (!ventiladorLigado &amp;&amp; temperatura &gt; limiarLigar) {\n    // Liga o ventilador\n    digitalWrite(IN1, HIGH);\n    digitalWrite(IN2, LOW);\n    analogWrite(ENA, 200);\n    ventiladorLigado = true;\n    Serial.println(\"Ventilador Ligado.\");\n} else if (ventiladorLigado &amp;&amp; temperatura &lt; limiarDesligar) {\n    // Desliga o ventilador\n    digitalWrite(IN1, LOW);\n    digitalWrite(IN2, LOW);\n    analogWrite(ENA, 0);\n    ventiladorLigado = false;\n    Serial.println(\"Ventilador Desligado.\");\n}\n</code></pre> <p>} \u02dc\u02dc\u02dc</p>","text":""},{"location":"aulas/iot/modulos/modulo12.html#exercicio-2-sistema-de-irrigacao-automatica-com-sensor-de-umidade-do-solo","title":"Exerc\u00edcio 2: Sistema de Irriga\u00e7\u00e3o Autom\u00e1tica com Sensor de Umidade do Solo","text":"<ul> <li> <p>Tarefa: Desenvolva um sistema que l\u00ea a umidade do solo e ativa uma bomba de \u00e1gua quando a umidade estiver abaixo de um determinado limiar.</p> </li> <li> <p>Dicas:</p> </li> <li>Utilize um sensor de umidade do solo anal\u00f3gico.</li> <li> <p>Controle a bomba utilizando um rel\u00e9 ou driver de motor.</p> </li> <li> <p>Exemplo de C\u00f3digo:</p> </li> </ul> <p>\u02dc\u02dc\u02dccpp const int pinoUmidade = A0; const int pinoRel\u00e9 = 7; const int limiarUmidade = 400; // Valor de exemplo</p> <p>void setup() {     Serial.begin(9600);     pinMode(pinoRel\u00e9, OUTPUT);     digitalWrite(pinoRel\u00e9, LOW); // Bomba desligada inicialmente }</p> <p>void loop() {     int valorUmidade = analogRead(pinoUmidade);     Serial.print(\"Umidade do Solo: \");     Serial.println(valorUmidade);</p> <pre><code>if (valorUmidade &lt; limiarUmidade) {\n    digitalWrite(pinoRel\u00e9, HIGH); // Liga a bomba\n    Serial.println(\"Bomba Ligada.\");\n} else {\n    digitalWrite(pinoRel\u00e9, LOW); // Desliga a bomba\n    Serial.println(\"Bomba Desligada.\");\n}\ndelay(1000);\n</code></pre> <p>} \u02dc\u02dc\u02dc</p> <p>Explica\u00e7\u00e3o:</p> <ul> <li>Sensor de Umidade do Solo: Mede a umidade do solo em tempo real.</li> <li>Controle da Bomba: Liga a bomba quando a umidade est\u00e1 abaixo do limiar e desliga quando est\u00e1 acima.</li> </ul>"},{"location":"aulas/iot/modulos/modulo12.html#exercicio-3-interface-de-sensores-com-display-oled","title":"Exerc\u00edcio 3: Interface de Sensores com Display OLED","text":"<ul> <li> <p>Tarefa: Implemente um sistema que l\u00ea dados de m\u00faltiplos sensores (temperatura, umidade e dist\u00e2ncia) e exibe as informa\u00e7\u00f5es em um display OLED.</p> </li> <li> <p>Dicas:</p> </li> <li>Utilize a biblioteca <code>Adafruit_SSD1306</code> para controlar o display OLED.</li> <li> <p>Organize os dados de forma clara e leg\u00edvel no display.</p> </li> <li> <p>Exemplo de C\u00f3digo:</p> </li> </ul> <p>\u02dc\u02dc\u02dccpp</p>"},{"location":"aulas/iot/modulos/modulo12.html#include_1","title":"include","text":""},{"location":"aulas/iot/modulos/modulo12.html#include_2","title":"include","text":""},{"location":"aulas/iot/modulos/modulo12.html#include_3","title":"include","text":""},{"location":"aulas/iot/modulos/modulo12.html#include-dhth_3","title":"include \"DHT.h\"","text":""},{"location":"aulas/iot/modulos/modulo12.html#define-screen_width-128","title":"define SCREEN_WIDTH 128","text":""},{"location":"aulas/iot/modulos/modulo12.html#define-screen_height-64","title":"define SCREEN_HEIGHT 64","text":""},{"location":"aulas/iot/modulos/modulo12.html#define-oled_reset-1","title":"define OLED_RESET     -1 <p>Adafruit_SSD1306 display(SCREEN_WIDTH, SCREEN_HEIGHT, &amp;Wire, OLED_RESET);</p>","text":""},{"location":"aulas/iot/modulos/modulo12.html#define-dhtpin-2_2","title":"define DHTPIN 2","text":""},{"location":"aulas/iot/modulos/modulo12.html#define-dhttype-dht22_2","title":"define DHTTYPE DHT22 <p>DHT dht(DHTPIN, DHTTYPE);</p> <p>const int trigPin = 9; const int echoPin = 10;</p> <p>void setup() {     Serial.begin(9600);     dht.begin();</p> <pre><code>// Inicializa o display OLED\nif(!display.begin(SSD1306_SWITCHCAPVCC, 0x3C)) {\n    Serial.println(F(\"Falha ao inicializar o display OLED!\"));\n    for(;;);\n}\ndelay(1000);\ndisplay.clearDisplay();\ndisplay.setTextSize(1);\ndisplay.setTextColor(SSD1306_WHITE);\n</code></pre> <p>}</p> <p>void loop() {     // Leitura do sensor DHT22     float temperatura = dht.readTemperature();     float umidade = dht.readHumidity();</p> <pre><code>// Leitura do sensor ultrass\u00f4nico\ndigitalWrite(trigPin, LOW);\ndelayMicroseconds(2);\ndigitalWrite(trigPin, HIGH);\ndelayMicroseconds(10);\ndigitalWrite(trigPin, LOW);\nlong duracao = pulseIn(echoPin, HIGH);\nfloat distancia = duracao * 0.034 / 2;\n\n// Verifica se as leituras s\u00e3o v\u00e1lidas\nif (isnan(temperatura) || isnan(umidade)) {\n    Serial.println(\"Falha na leitura do sensor DHT!\");\n    return;\n}\n\n// Exibe os dados no display OLED\ndisplay.clearDisplay();\ndisplay.setCursor(0,0);\ndisplay.print(\"Temp: \");\ndisplay.print(temperatura);\ndisplay.println(\" C\");\n\ndisplay.print(\"Umid: \");\ndisplay.print(umidade);\ndisplay.println(\" %\");\n\ndisplay.print(\"Dist: \");\ndisplay.print(distancia);\ndisplay.println(\" cm\");\n\ndisplay.display();\n\nSerial.print(\"Temperatura: \");\nSerial.print(temperatura);\nSerial.print(\" *C\\tUmidade: \");\nSerial.print(umidade);\nSerial.print(\" %\\tDistancia: \");\nSerial.print(distancia);\nSerial.println(\" cm\");\n\ndelay(2000);\n</code></pre> <p>} \u02dc\u02dc\u02dc</p> <p>Explica\u00e7\u00e3o:</p> <ul> <li>Display OLED: Utiliza a biblioteca <code>Adafruit_SSD1306</code> para exibir informa\u00e7\u00f5es dos sensores.</li> <li>Organiza\u00e7\u00e3o de Dados: As informa\u00e7\u00f5es s\u00e3o organizadas de forma clara e atualizadas a cada 2 segundos.</li> </ul>","text":""},{"location":"aulas/iot/modulos/modulo12.html#8-conceitos-importantes","title":"8. Conceitos Importantes","text":""},{"location":"aulas/iot/modulos/modulo12.html#81-calibracao-de-sensores","title":"8.1 Calibra\u00e7\u00e3o de Sensores","text":"<ul> <li>Defini\u00e7\u00e3o: Ajustar os sensores para garantir que as leituras sejam precisas.</li> <li>M\u00e9todos:</li> <li>Comparar as leituras com instrumentos de refer\u00eancia.</li> <li>Ajustar valores de offset e escala no c\u00f3digo.</li> </ul>"},{"location":"aulas/iot/modulos/modulo12.html#82-uso-de-variaveis-volateis","title":"8.2 Uso de Vari\u00e1veis Vol\u00e1teis","text":"<ul> <li>Defini\u00e7\u00e3o: Vari\u00e1veis que podem ser modificadas por ISRs ou m\u00faltiplas threads.</li> <li>Uso: Declarar vari\u00e1veis compartilhadas entre o loop principal e ISRs como <code>volatile</code> para garantir leituras corretas.</li> </ul>"},{"location":"aulas/iot/modulos/modulo12.html#83-tecnicas-de-filtragem-de-dados","title":"8.3 T\u00e9cnicas de Filtragem de Dados","text":"<ul> <li>M\u00e9dia M\u00f3vel: Suaviza as leituras ao calcular a m\u00e9dia de um conjunto de valores.</li> <li>Filtro de Kalman: Avan\u00e7ado m\u00e9todo de filtragem que estima o estado de um sistema.</li> <li>Desvio Padr\u00e3o: Identifica e descarta leituras que se desviam significativamente da m\u00e9dia.</li> </ul>"},{"location":"aulas/iot/modulos/modulo12.html#84-gerenciamento-de-energia","title":"8.4 Gerenciamento de Energia","text":"<ul> <li>Import\u00e2ncia: Sensores e m\u00f3dulos adicionais podem aumentar o consumo de energia.</li> <li>Pr\u00e1ticas:</li> <li>Desligar sensores quando n\u00e3o estiverem em uso.</li> <li>Utilizar modos de baixo consumo do Arduino.</li> <li>Escolher sensores com baixo consumo de energia.</li> </ul>"},{"location":"aulas/iot/modulos/modulo12.html#85-boas-praticas-na-aquisicao-de-dados","title":"8.5 Boas Pr\u00e1ticas na Aquisi\u00e7\u00e3o de Dados","text":"<ul> <li>Consist\u00eancia: Realizar leituras em intervalos regulares.</li> <li>Valida\u00e7\u00e3o: Verificar a validade das leituras antes de utiliz\u00e1-las.</li> <li>Armazenamento: Utilizar estruturas de dados adequadas para armazenar e processar os dados coletados.</li> <li>Seguran\u00e7a: Proteger os circuitos contra sobrecargas e interfer\u00eancias.</li> </ul>"},{"location":"aulas/iot/modulos/modulo12.html#9-recursos-adicionais","title":"9. Recursos Adicionais","text":"<ul> <li> <p>Documenta\u00e7\u00e3o Oficial do Arduino:</p> </li> <li> <p>Sensor Library</p> </li> <li>LiquidCrystal Library</li> <li> <p>Adafruit SSD1306 Library</p> </li> <li> <p>Tutoriais e Guias:</p> </li> <li> <p>Guia Completo de Sensores no Arduino</p> </li> <li>Interfacing Sensors with Arduino</li> <li> <p>Processamento de Dados com Arduino</p> </li> <li> <p>V\u00eddeos Educacionais:</p> </li> <li> <p>Interfacing Sensors with Arduino</p> </li> <li>Arduino Sensor Calibration</li> <li>Data Acquisition Systems with Arduino</li> </ul>"},{"location":"aulas/iot/modulos/modulo12.html#10-exemplos-praticos","title":"10. Exemplos Pr\u00e1ticos","text":""},{"location":"aulas/iot/modulos/modulo12.html#101-sistema-de-monitoramento-ambiental-com-multiplos-sensores","title":"10.1 Sistema de Monitoramento Ambiental com M\u00faltiplos Sensores","text":"<p>\u02dc\u02dc\u02dccpp</p>"},{"location":"aulas/iot/modulos/modulo12.html#include-dhth_4","title":"include \"DHT.h\"","text":""},{"location":"aulas/iot/modulos/modulo12.html#include_4","title":"include","text":""},{"location":"aulas/iot/modulos/modulo12.html#include_5","title":"include","text":""},{"location":"aulas/iot/modulos/modulo12.html#define-screen_width-128_1","title":"define SCREEN_WIDTH 128","text":""},{"location":"aulas/iot/modulos/modulo12.html#define-screen_height-64_1","title":"define SCREEN_HEIGHT 64","text":""},{"location":"aulas/iot/modulos/modulo12.html#define-oled_reset-1_1","title":"define OLED_RESET     -1 <p>Adafruit_SSD1306 display(SCREEN_WIDTH, SCREEN_HEIGHT, &amp;Wire, OLED_RESET);</p>","text":""},{"location":"aulas/iot/modulos/modulo12.html#define-dhtpin-2_3","title":"define DHTPIN 2","text":""},{"location":"aulas/iot/modulos/modulo12.html#define-dhttype-dht22_3","title":"define DHTTYPE DHT22 <p>DHT dht(DHTPIN, DHTTYPE);</p> <p>const int trigPin = 9; const int echoPin = 10;</p> <p>void setup() {     Serial.begin(9600);     dht.begin();</p> <pre><code>// Inicializa o display OLED\nif(!display.begin(SSD1306_SWITCHCAPVCC, 0x3C)) {\n    Serial.println(F(\"Falha ao inicializar o display OLED!\"));\n    for(;;);\n}\ndelay(1000);\ndisplay.clearDisplay();\ndisplay.setTextSize(1);\ndisplay.setTextColor(SSD1306_WHITE);\n</code></pre> <p>}</p> <p>void loop() {     // Leitura do sensor DHT22     float temperatura = dht.readTemperature();     float umidade = dht.readHumidity();</p> <pre><code>// Leitura do sensor ultrass\u00f4nico\ndigitalWrite(trigPin, LOW);\ndelayMicroseconds(2);\ndigitalWrite(trigPin, HIGH);\ndelayMicroseconds(10);\ndigitalWrite(trigPin, LOW);\nlong duracao = pulseIn(echoPin, HIGH);\nfloat distancia = duracao * 0.034 / 2;\n\n// Verifica se as leituras s\u00e3o v\u00e1lidas\nif (isnan(temperatura) || isnan(umidade)) {\n    Serial.println(\"Falha na leitura do sensor DHT!\");\n    return;\n}\n\n// Exibe os dados no display OLED\ndisplay.clearDisplay();\ndisplay.setCursor(0,0);\ndisplay.print(\"Temp: \");\ndisplay.print(temperatura);\ndisplay.println(\" C\");\n\ndisplay.print(\"Umid: \");\ndisplay.print(umidade);\ndisplay.println(\" %\");\n\ndisplay.print(\"Dist: \");\ndisplay.print(distancia);\ndisplay.println(\" cm\");\n\ndisplay.display();\n\nSerial.print(\"Temperatura: \");\nSerial.print(temperatura);\nSerial.print(\" *C\\tUmidade: \");\nSerial.print(umidade);\nSerial.print(\" %\\tDistancia: \");\nSerial.print(distancia);\nSerial.println(\" cm\");\n\ndelay(2000);\n</code></pre> <p>} \u02dc\u02dc\u02dc</p> <p>Explica\u00e7\u00e3o:</p> <ul> <li>M\u00faltiplos Sensores: Integra um sensor de temperatura e umidade (DHT22) e um sensor de dist\u00e2ncia ultrass\u00f4nico.</li> <li>Display OLED: Exibe as leituras dos sensores em tempo real.</li> <li>Monitoramento Ambiental: Permite visualizar as condi\u00e7\u00f5es ambientais de forma clara e organizada.</li> </ul>","text":""},{"location":"aulas/iot/modulos/modulo12.html#102-sistema-de-alarme-de-incendio-com-sensor-de-gas-e-sirene","title":"10.2 Sistema de Alarme de Inc\u00eandio com Sensor de G\u00e1s e Sirene","text":"<p>\u02dc\u02dc\u02dccpp const int pinoGas = A0; const int pinoLED = 13; const int pinoSirene = 12; const int limiarGas = 300; // Valor de exemplo</p> <p>void setup() {     Serial.begin(9600);     pinMode(pinoLED, OUTPUT);     pinMode(pinoSirene, OUTPUT); }</p> <p>void loop() {     int valorGas = analogRead(pinoGas);     Serial.print(\"N\u00edvel de G\u00e1s: \");     Serial.println(valorGas);</p> <pre><code>if (valorGas &gt; limiarGas) {\n    digitalWrite(pinoLED, HIGH);\n    digitalWrite(pinoSirene, HIGH);\n    Serial.println(\"Alerta! Inc\u00eandio detectado!\");\n} else {\n    digitalWrite(pinoLED, LOW);\n    digitalWrite(pinoSirene, LOW);\n}\ndelay(1000);\n</code></pre> <p>} \u02dc\u02dc\u02dc</p> <p>Explica\u00e7\u00e3o:</p> <ul> <li>Sensor de G\u00e1s: Detecta a presen\u00e7a de gases inflam\u00e1veis.</li> <li>Atua\u00e7\u00e3o do Alarme: Aciona um LED e uma sirene quando n\u00edveis perigosos de g\u00e1s s\u00e3o detectados.</li> <li>Seguran\u00e7a: Proporciona uma resposta r\u00e1pida em caso de detec\u00e7\u00e3o de inc\u00eandio.</li> </ul>"},{"location":"aulas/iot/modulos/modulo12.html#103-interface-de-sensores-com-comunicacao-serial-e-parsing-de-dados","title":"10.3 Interface de Sensores com Comunica\u00e7\u00e3o Serial e Parsing de Dados","text":"<p>\u02dc\u02dc\u02dccpp</p>"},{"location":"aulas/iot/modulos/modulo12.html#include_6","title":"include  <p>const int pinoTemperatura = A0; const int pinoUmidade = A1; const int pinoDistancia = A2;</p> <p>void setup() {     Serial.begin(9600);     Serial.println(\"Sistema de Monitoramento Iniciado.\"); }</p> <p>void loop() {     // Leitura dos sensores     float temperatura = analogRead(pinoTemperatura) * (5.0 / 1023.0) * 100; // Exemplo de convers\u00e3o     float umidade = analogRead(pinoUmidade) * (5.0 / 1023.0) * 100; // Exemplo de convers\u00e3o     float distancia = analogRead(pinoDistancia) * (5.0 / 1023.0) * 200; // Exemplo de convers\u00e3o</p> <pre><code>// Cria um documento JSON\nStaticJsonDocument&lt;200&gt; doc;\ndoc[\"temperatura\"] = temperatura;\ndoc[\"umidade\"] = umidade;\ndoc[\"distancia\"] = distancia;\n\n// Serializa o JSON\nString output;\nserializeJson(doc, output);\nSerial.println(output);\n\ndelay(1000);\n</code></pre> <p>} \u02dc\u02dc\u02dc</p> <p>Explica\u00e7\u00e3o:</p> <ul> <li>Formato JSON: Estrutura os dados dos sensores em formato JSON para facilitar o parsing e a integra\u00e7\u00e3o com outros sistemas.</li> <li>ArduinoJson: Utiliza a biblioteca <code>ArduinoJson</code> para criar e serializar o documento JSON.</li> <li>Comunica\u00e7\u00e3o Eficiente: Facilita a transfer\u00eancia de dados para sistemas externos, como computadores ou servidores.</li> </ul>","text":""},{"location":"aulas/iot/modulos/modulo12.html#9-conceitos-importantes","title":"9. Conceitos Importantes","text":""},{"location":"aulas/iot/modulos/modulo12.html#91-calibracao-de-sensores","title":"9.1 Calibra\u00e7\u00e3o de Sensores","text":"<ul> <li>Defini\u00e7\u00e3o: Processo de ajustar os sensores para garantir que as leituras sejam precisas e consistentes.</li> <li>M\u00e9todos:</li> <li>Calibra\u00e7\u00e3o em Ambiente Controlado: Comparar as leituras do sensor com instrumentos de refer\u00eancia.</li> <li>Ajustes de Offset e Escala: Modificar os valores lidos para corresponder aos valores reais.</li> </ul>"},{"location":"aulas/iot/modulos/modulo12.html#92-uso-de-variaveis-volateis","title":"9.2 Uso de Vari\u00e1veis Vol\u00e1teis","text":"<ul> <li>Defini\u00e7\u00e3o: Vari\u00e1veis que podem ser modificadas por ISRs ou diferentes threads de execu\u00e7\u00e3o.</li> <li>Import\u00e2ncia: Garantem que o compilador n\u00e3o otimize ou ignore as atualiza\u00e7\u00f5es feitas em ISRs.</li> <li>Exemplo: <pre><code>volatile int contador = 0;\n</code></pre></li> </ul>"},{"location":"aulas/iot/modulos/modulo12.html#93-tecnicas-de-filtragem-de-dados","title":"9.3 T\u00e9cnicas de Filtragem de Dados","text":"<ul> <li>M\u00e9dia M\u00f3vel: Calcula a m\u00e9dia de um conjunto de leituras para suavizar flutua\u00e7\u00f5es.</li> <li>Filtro de Kalman: T\u00e9cnica avan\u00e7ada para estimar o estado de um sistema a partir de medi\u00e7\u00f5es ruidosas.</li> <li>Desvio Padr\u00e3o: Identifica e remove outliers das leituras.</li> </ul>"},{"location":"aulas/iot/modulos/modulo12.html#94-gerenciamento-de-energia","title":"9.4 Gerenciamento de Energia","text":"<ul> <li>Import\u00e2ncia: Sensores e m\u00f3dulos adicionais podem aumentar significativamente o consumo de energia do sistema.</li> <li>Boas Pr\u00e1ticas:</li> <li>Desligar Sensores Quando N\u00e3o Est\u00e3o em Uso: Economiza energia prolongando a vida \u00fatil da bateria.</li> <li>Utilizar Modos de Baixo Consumo: Aproveitar os modos de economia de energia do Arduino.</li> <li>Escolher Sensores Eficientes: Optar por sensores com baixo consumo de energia quando apropriado.</li> </ul>"},{"location":"aulas/iot/modulos/modulo12.html#95-boas-praticas-na-aquisicao-de-dados","title":"9.5 Boas Pr\u00e1ticas na Aquisi\u00e7\u00e3o de Dados","text":"<ul> <li>Consist\u00eancia nas Leituras: Realizar leituras em intervalos regulares para garantir dados consistentes.</li> <li>Valida\u00e7\u00e3o das Leituras: Verificar se os dados lidos s\u00e3o v\u00e1lidos antes de process\u00e1-los.</li> <li>Organiza\u00e7\u00e3o dos Dados: Utilizar estruturas de dados adequadas para armazenar e processar informa\u00e7\u00f5es.</li> <li>Seguran\u00e7a e Prote\u00e7\u00e3o: Proteger os circuitos contra sobrecargas, interfer\u00eancias e ru\u00eddos el\u00e9tricos.</li> </ul>"},{"location":"aulas/iot/modulos/modulo12.html#10-recursos-adicionais","title":"10. Recursos Adicionais","text":"<ul> <li> <p>Documenta\u00e7\u00e3o Oficial do Arduino:</p> </li> <li> <p>Arduino Sensor Libraries</p> </li> <li>ArduinoJson Library</li> <li> <p>LiquidCrystal Library</p> </li> <li> <p>Tutoriais e Guias:</p> </li> <li> <p>Interfacing Sensors with Arduino</p> </li> <li>Data Acquisition with Arduino</li> <li> <p>Using Arduino with JSON</p> </li> <li> <p>V\u00eddeos Educacionais:</p> </li> <li> <p>Arduino Sensor Integration Tutorial</p> </li> <li>Data Filtering Techniques with Arduino</li> <li>Energy Management in Arduino Projects</li> </ul>"},{"location":"aulas/iot/modulos/modulo12.html#11-conclusao-do-modulo","title":"11. Conclus\u00e3o do M\u00f3dulo","text":"<p>Neste m\u00f3dulo, voc\u00ea aprendeu:</p> <ul> <li>Os diferentes tipos de sensores dispon\u00edveis para Arduino e suas aplica\u00e7\u00f5es.</li> <li>Como conectar e configurar sensores anal\u00f3gicos e digitais com o Arduino.</li> <li>T\u00e9cnicas de leitura e interpreta\u00e7\u00e3o de dados de sensores.</li> <li>Utiliza\u00e7\u00e3o de bibliotecas espec\u00edficas para facilitar a comunica\u00e7\u00e3o com sensores complexos.</li> <li>M\u00e9todos de processamento e filtragem de dados para obter informa\u00e7\u00f5es precisas e \u00fateis.</li> <li>Integra\u00e7\u00e3o de sensores com componentes adicionais, como displays OLED e m\u00f3dulos de comunica\u00e7\u00e3o.</li> <li>Praticou com exemplos e exerc\u00edcios que refor\u00e7am o entendimento dos conceitos de sensores e aquisi\u00e7\u00e3o de dados.</li> </ul> <p>Voc\u00ea completou todos os m\u00f3dulos do curso \"Programa\u00e7\u00e3o em Arduino: Conceitos Fundamentais sem Hardware\". Parab\u00e9ns pelo empenho e dedica\u00e7\u00e3o!</p>"},{"location":"aulas/iot/modulos/modulo12.html#12-proximos-passos","title":"12. Pr\u00f3ximos Passos","text":"<ul> <li>Revisar todo o conte\u00fado do curso para consolidar o aprendizado.</li> <li>Explorar projetos avan\u00e7ados que combinam m\u00faltiplos conceitos aprendidos.</li> <li>Participar de comunidades e f\u00f3runs de Arduino para trocar experi\u00eancias e obter suporte cont\u00ednuo.</li> <li>Considerar cursos avan\u00e7ados ou especializa\u00e7\u00f5es em \u00e1reas espec\u00edficas de interesse, como rob\u00f3tica, IoT ou automa\u00e7\u00e3o industrial.</li> </ul> <p>Se tiver d\u00favidas ou precisar de assist\u00eancia, continue participando de comunidades de aprendizagem ou consulte os recursos adicionais fornecidos ao longo dos m\u00f3dulos.</p> <p>Parab\u00e9ns por concluir o curso! Continue explorando e criando projetos incr\u00edveis com Arduino!</p>"},{"location":"aulas/iot/modulos/modulo13.html","title":"M\u00f3dulo 13: Internet das Coisas (IoT) com Arduino","text":"<p>Bem-vindo ao M\u00f3dulo 13 do curso \"Programa\u00e7\u00e3o em Arduino: Conceitos Fundamentais sem Hardware\". Neste m\u00f3dulo, voc\u00ea ir\u00e1 explorar a Internet das Coisas (IoT) com o Arduino, aprendendo a conectar seus projetos \u00e0 internet para coletar, enviar e visualizar dados em tempo real. A integra\u00e7\u00e3o com a IoT amplia significativamente as possibilidades dos seus projetos, permitindo monitoramento remoto, automa\u00e7\u00e3o e intera\u00e7\u00e3o com outros dispositivos e servi\u00e7os online.</p>"},{"location":"aulas/iot/modulos/modulo13.html#objetivos-do-modulo","title":"Objetivos do M\u00f3dulo","text":"<ul> <li>Compreender os conceitos b\u00e1sicos de Internet das Coisas (IoT).</li> <li>Aprender a conectar o Arduino \u00e0 internet utilizando m\u00f3dulos Wi-Fi (ESP8266, ESP32) e Ethernet.</li> <li>Implementar comunica\u00e7\u00e3o com servi\u00e7os de nuvem para armazenamento e visualiza\u00e7\u00e3o de dados.</li> <li>Utilizar protocolos de comunica\u00e7\u00e3o como HTTP e MQTT para troca de informa\u00e7\u00f5es.</li> <li>Desenvolver projetos que integrem sensores, atuadores e comunica\u00e7\u00e3o com a internet.</li> <li>Resolver exerc\u00edcios pr\u00e1ticos para consolidar o conhecimento sobre IoT com Arduino.</li> </ul>"},{"location":"aulas/iot/modulos/modulo13.html#1-introducao-a-internet-das-coisas-iot","title":"1. Introdu\u00e7\u00e3o \u00e0 Internet das Coisas (IoT)","text":""},{"location":"aulas/iot/modulos/modulo13.html#11-o-que-e-iot","title":"1.1 O que \u00e9 IoT?","text":"<p>Internet das Coisas (IoT) refere-se \u00e0 interconex\u00e3o de dispositivos f\u00edsicos atrav\u00e9s da internet, permitindo que eles coletem e compartilhem dados. Com o Arduino, voc\u00ea pode criar dispositivos inteligentes que interagem com o ambiente e com outros dispositivos de forma aut\u00f4noma.</p>"},{"location":"aulas/iot/modulos/modulo13.html#12-importancia-da-iot","title":"1.2 Import\u00e2ncia da IoT","text":"<ul> <li>Monitoramento Remoto: Permite acompanhar o estado de dispositivos e sensores de qualquer lugar.</li> <li>Automa\u00e7\u00e3o: Facilita a cria\u00e7\u00e3o de sistemas automatizados que respondem a eventos sem interven\u00e7\u00e3o humana.</li> <li>Coleta de Dados: Gera grandes volumes de dados que podem ser analisados para tomar decis\u00f5es informadas.</li> <li>Interconectividade: Integra diferentes dispositivos e servi\u00e7os, ampliando as funcionalidades dos projetos.</li> </ul>"},{"location":"aulas/iot/modulos/modulo13.html#13-componentes-basicos-de-um-sistema-iot","title":"1.3 Componentes B\u00e1sicos de um Sistema IoT","text":"<ul> <li>Dispositivo: Arduino ou microcontrolador com conectividade \u00e0 internet.</li> <li>Sensores e Atuadores: Para coletar dados e interagir com o ambiente.</li> <li>Conex\u00e3o de Rede: Wi-Fi, Ethernet, LoRa, etc.</li> <li>Servi\u00e7os de Nuvem: Para armazenamento, processamento e visualiza\u00e7\u00e3o de dados.</li> <li>Interface de Usu\u00e1rio: Aplicativos m\u00f3veis, dashboards web, etc.</li> </ul>"},{"location":"aulas/iot/modulos/modulo13.html#2-conectando-o-arduino-a-internet","title":"2. Conectando o Arduino \u00e0 Internet","text":""},{"location":"aulas/iot/modulos/modulo13.html#21-modulos-de-conectividade","title":"2.1 M\u00f3dulos de Conectividade","text":"<ul> <li>ESP8266: M\u00f3dulo Wi-Fi de baixo custo, ideal para projetos IoT simples.</li> <li>ESP32: Vers\u00e3o avan\u00e7ada do ESP8266, com Bluetooth, mais GPIOs e maior desempenho.</li> <li>Ethernet Shield: Permite conex\u00e3o via cabo Ethernet, \u00fatil para ambientes com conex\u00e3o est\u00e1vel.</li> </ul>"},{"location":"aulas/iot/modulos/modulo13.html#22-configuracao-do-esp8266-com-arduino","title":"2.2 Configura\u00e7\u00e3o do ESP8266 com Arduino","text":"<p>Componentes Necess\u00e1rios:</p> <ul> <li>Arduino Uno</li> <li>M\u00f3dulo ESP8266</li> <li>Adaptador de n\u00edvel l\u00f3gico (opcional)</li> <li>Cabos de conex\u00e3o</li> <li>Fonte de alimenta\u00e7\u00e3o adequada</li> </ul> <p>Conex\u00e3o:</p> <ol> <li>VCC do ESP8266: Conectado ao 3.3V do Arduino.</li> <li>GND do ESP8266: Conectado ao GND do Arduino.</li> <li>TX do ESP8266: Conectado ao RX do Arduino (pino 0).</li> <li>RX do ESP8266: Conectado ao TX do Arduino (pino 1) atrav\u00e9s de um divisor de tens\u00e3o ou adaptador de n\u00edvel l\u00f3gico.</li> <li>CH_PD do ESP8266: Conectado ao 3.3V para ativar o m\u00f3dulo.</li> </ol>"},{"location":"aulas/iot/modulos/modulo13.html#23-exemplo-de-codigo-para-conexao-wi-fi-com-esp8266","title":"2.3 Exemplo de C\u00f3digo para Conex\u00e3o Wi-Fi com ESP8266","text":"<pre><code>#include &lt;SoftwareSerial.h&gt;\n\nSoftwareSerial esp8266(2, 3); // RX, TX\n\nconst char* ssid = \"Seu_SSID\";\nconst char* password = \"Sua_Senha\";\n\nvoid setup() {\n    Serial.begin(9600);\n    esp8266.begin(115200);\n\n    delay(1000);\n    Serial.println(\"Conectando ao Wi-Fi...\");\n    esp8266.println(\"AT+CWJAP=\\\"\" + String(ssid) + \"\\\",\\\"\" + String(password) + \"\\\"\");\n}\n\nvoid loop() {\n    if (esp8266.available()) {\n        Serial.write(esp8266.read());\n    }\n\n    if (Serial.available()) {\n        esp8266.write(Serial.read());\n    }\n}\n</code></pre> <p>Explica\u00e7\u00e3o:</p> <ul> <li>SoftwareSerial: Cria uma porta serial adicional para comunica\u00e7\u00e3o com o ESP8266.</li> <li>Conex\u00e3o Wi-Fi: Envia o comando AT para conectar o m\u00f3dulo ESP8266 \u00e0 rede Wi-Fi especificada.</li> <li>Monitoramento: Permite monitorar a comunica\u00e7\u00e3o entre o Arduino e o ESP8266 atrav\u00e9s do Monitor Serial.</li> </ul>"},{"location":"aulas/iot/modulos/modulo13.html#3-comunicacao-com-servicos-de-nuvem","title":"3. Comunica\u00e7\u00e3o com Servi\u00e7os de Nuvem","text":""},{"location":"aulas/iot/modulos/modulo13.html#31-utilizando-o-thingspeak","title":"3.1 Utilizando o ThingSpeak","text":"<p>ThingSpeak \u00e9 uma plataforma IoT que permite coletar, armazenar e visualizar dados de sensores.</p> <p>Passos para Utilizar o ThingSpeak:</p> <ol> <li>Criar uma Conta: Acesse ThingSpeak e crie uma conta gratuita.</li> <li>Criar um Canal: Adicione um novo canal para armazenar os dados do seu projeto.</li> <li>Obter a API Key: Cada canal possui uma chave de API para autentica\u00e7\u00e3o.</li> </ol>"},{"location":"aulas/iot/modulos/modulo13.html#32-exemplo-de-envio-de-dados-para-o-thingspeak","title":"3.2 Exemplo de Envio de Dados para o ThingSpeak","text":"<pre><code>#include &lt;ESP8266WiFi.h&gt;\n\nconst char* ssid = \"Seu_SSID\";\nconst char* password = \"Sua_Senha\";\nconst char* host = \"api.thingspeak.com\";\nconst char* writeAPIKey = \"SUA_API_KEY\";\n\nvoid setup() {\n    Serial.begin(115200);\n    delay(10);\n\n    // Conectando ao Wi-Fi\n    WiFi.begin(ssid, password);\n    Serial.println();\n    Serial.println(\"Conectando ao Wi-Fi...\");\n\n    while (WiFi.status() != WL_CONNECTED) {\n        delay(500);\n        Serial.print(\".\");\n    }\n\n    Serial.println(\"\");\n    Serial.println(\"Wi-Fi conectado.\");\n    Serial.println(\"Endere\u00e7o IP: \");\n    Serial.println(WiFi.localIP());\n}\n\nvoid loop() {\n    WiFiClient client;\n    const int httpPort = 80;\n\n    if (!client.connect(host, httpPort)) {\n        Serial.println(\"Falha na conex\u00e3o\");\n        return;\n    }\n\n    // Simula\u00e7\u00e3o de leitura de sensor\n    float temperatura = 25.5;\n\n    // Criando a requisi\u00e7\u00e3o HTTP\n    String url = \"/update?api_key=\" + String(writeAPIKey) + \"&amp;field1=\" + String(temperatura);\n\n    Serial.print(\"Requisi\u00e7\u00e3o: \");\n    Serial.println(url);\n\n    client.print(String(\"GET \") + url + \" HTTP/1.1\\r\\n\" +\n                 \"Host: \" + host + \"\\r\\n\" + \n                 \"Connection: close\\r\\n\\r\\n\");\n    delay(20000); // Envia dados a cada 20 segundos\n}\n</code></pre> <p>Explica\u00e7\u00e3o:</p> <ul> <li>Conex\u00e3o Wi-Fi: Estabelece a conex\u00e3o com a rede Wi-Fi.</li> <li>Requisi\u00e7\u00e3o HTTP: Envia os dados de temperatura para o ThingSpeak utilizando uma requisi\u00e7\u00e3o GET.</li> <li>Atualiza\u00e7\u00e3o de Dados: O loop envia a temperatura simulada a cada 20 segundos.</li> </ul>"},{"location":"aulas/iot/modulos/modulo13.html#33-visualizando-dados-no-thingspeak","title":"3.3 Visualizando Dados no ThingSpeak","text":"<p>Ap\u00f3s enviar os dados, acesse o painel do seu canal no ThingSpeak para visualizar gr\u00e1ficos e estat\u00edsticas em tempo real.</p>"},{"location":"aulas/iot/modulos/modulo13.html#4-utilizando-o-mqtt-para-comunicacao-iot","title":"4. Utilizando o MQTT para Comunica\u00e7\u00e3o IoT","text":""},{"location":"aulas/iot/modulos/modulo13.html#41-o-que-e-mqtt","title":"4.1 O que \u00e9 MQTT?","text":"<p>MQTT (Message Queuing Telemetry Transport) \u00e9 um protocolo de mensagem leve, ideal para aplica\u00e7\u00f5es IoT devido \u00e0 sua efici\u00eancia e baixo consumo de largura de banda.</p>"},{"location":"aulas/iot/modulos/modulo13.html#42-configuracao-do-mqtt-com-arduino","title":"4.2 Configura\u00e7\u00e3o do MQTT com Arduino","text":"<p>Componentes Necess\u00e1rios:</p> <ul> <li>Arduino com conectividade \u00e0 internet (ESP8266, ESP32)</li> <li>Servidor MQTT (pode ser um broker p\u00fablico ou configurado localmente)</li> <li>Biblioteca MQTT para Arduino (PubSubClient)</li> </ul>"},{"location":"aulas/iot/modulos/modulo13.html#43-exemplo-de-codigo-para-publicar-dados-no-mqtt","title":"4.3 Exemplo de C\u00f3digo para Publicar Dados no MQTT","text":"<pre><code>#include &lt;ESP8266WiFi.h&gt;\n#include &lt;PubSubClient.h&gt;\n\n// Configura\u00e7\u00f5es de rede\nconst char* ssid = \"Seu_SSID\";\nconst char* password = \"Sua_Senha\";\n\n// Configura\u00e7\u00f5es do MQTT\nconst char* mqtt_server = \"broker.hivemq.com\";\n\nWiFiClient espClient;\nPubSubClient client(espClient);\n\nvoid setup_wifi() {\n    delay(10);\n    Serial.println();\n    Serial.print(\"Conectando ao Wi-Fi \");\n    Serial.println(ssid);\n\n    WiFi.begin(ssid, password);\n\n    while (WiFi.status() != WL_CONNECTED) {\n        delay(500);\n        Serial.print(\".\");\n    }\n\n    Serial.println(\"\");\n    Serial.println(\"Wi-Fi conectado\");\n    Serial.println(\"Endere\u00e7o IP: \");\n    Serial.println(WiFi.localIP());\n}\n\nvoid reconnect() {\n    // Loop at\u00e9 reconectar\n    while (!client.connected()) {\n        Serial.print(\"Tentando conex\u00e3o MQTT...\");\n        if (client.connect(\"ArduinoClient\")) {\n            Serial.println(\"conectado\");\n        } else {\n            Serial.print(\"falhou, rc=\");\n            Serial.print(client.state());\n            Serial.println(\" tentando novamente em 5 segundos\");\n            delay(5000);\n        }\n    }\n}\n\nvoid setup() {\n    Serial.begin(115200);\n    setup_wifi();\n    client.setServer(mqtt_server, 1883);\n}\n\nvoid loop() {\n    if (!client.connected()) {\n        reconnect();\n    }\n    client.loop();\n\n    // Simula\u00e7\u00e3o de leitura de sensor\n    float temperatura = 26.3;\n    char msg[50];\n    snprintf(msg, 50, \"Temperatura: %.2f\", temperatura);\n\n    // Publica no t\u00f3pico \"arduino/temperatura\"\n    client.publish(\"arduino/temperatura\", msg);\n    Serial.println(\"Mensagem publicada\");\n\n    delay(10000); // Envia dados a cada 10 segundos\n}\n</code></pre> <p>Explica\u00e7\u00e3o:</p> <ul> <li>Biblioteca PubSubClient: Facilita a implementa\u00e7\u00e3o do protocolo MQTT no Arduino.</li> <li>Conex\u00e3o MQTT: Estabelece a conex\u00e3o com o broker MQTT especificado.</li> <li>Publica\u00e7\u00e3o de Mensagens: Envia mensagens de temperatura para o t\u00f3pico \"arduino/temperatura\" a cada 10 segundos.</li> </ul>"},{"location":"aulas/iot/modulos/modulo13.html#44-subscricao-a-topicos-mqtt","title":"4.4 Subscri\u00e7\u00e3o a T\u00f3picos MQTT","text":"<p>Al\u00e9m de publicar, o Arduino pode subscrever a t\u00f3picos para receber mensagens.</p> <pre><code>#include &lt;ESP8266WiFi.h&gt;\n#include &lt;PubSubClient.h&gt;\n\n// Configura\u00e7\u00f5es de rede\nconst char* ssid = \"Seu_SSID\";\nconst char* password = \"Sua_Senha\";\n\n// Configura\u00e7\u00f5es do MQTT\nconst char* mqtt_server = \"broker.hivemq.com\";\n\nWiFiClient espClient;\nPubSubClient client(espClient);\n\n// Callback quando uma mensagem \u00e9 recebida\nvoid callback(char* topic, byte* payload, unsigned int length) {\n    Serial.print(\"Mensagem recebida no t\u00f3pico: \");\n    Serial.println(topic);\n    Serial.print(\"Conte\u00fado: \");\n    for (int i = 0; i &lt; length; i++) {\n        Serial.print((char)payload[i]);\n    }\n    Serial.println();\n}\n\nvoid setup_wifi() {\n    delay(10);\n    Serial.println();\n    Serial.print(\"Conectando ao Wi-Fi \");\n    Serial.println(ssid);\n\n    WiFi.begin(ssid, password);\n\n    while (WiFi.status() != WL_CONNECTED) {\n        delay(500);\n        Serial.print(\".\");\n    }\n\n    Serial.println(\"\");\n    Serial.println(\"Wi-Fi conectado\");\n    Serial.println(\"Endere\u00e7o IP: \");\n    Serial.println(WiFi.localIP());\n}\n\nvoid reconnect() {\n    // Loop at\u00e9 reconectar\n    while (!client.connected()) {\n        Serial.print(\"Tentando conex\u00e3o MQTT...\");\n        if (client.connect(\"ArduinoClient\")) {\n            Serial.println(\"conectado\");\n            client.subscribe(\"arduino/comando\");\n        } else {\n            Serial.print(\"falhou, rc=\");\n            Serial.print(client.state());\n            Serial.println(\" tentando novamente em 5 segundos\");\n            delay(5000);\n        }\n    }\n}\n\nvoid setup() {\n    Serial.begin(115200);\n    setup_wifi();\n    client.setServer(mqtt_server, 1883);\n    client.setCallback(callback);\n}\n\nvoid loop() {\n    if (!client.connected()) {\n        reconnect();\n    }\n    client.loop();\n}\n</code></pre> <p>Explica\u00e7\u00e3o:</p> <ul> <li>Callback: Fun\u00e7\u00e3o chamada sempre que uma mensagem \u00e9 recebida no t\u00f3pico subscrito.</li> <li>Subscri\u00e7\u00e3o: Subscrive ao t\u00f3pico \"arduino/comando\" para receber comandos.</li> <li>Processamento de Mensagens: Exibe as mensagens recebidas no Monitor Serial.</li> </ul>"},{"location":"aulas/iot/modulos/modulo13.html#5-desenvolvimento-de-projetos-iot-com-arduino","title":"5. Desenvolvimento de Projetos IoT com Arduino","text":""},{"location":"aulas/iot/modulos/modulo13.html#51-sistema-de-monitoramento-de-ambiente-com-notificacoes","title":"5.1 Sistema de Monitoramento de Ambiente com Notifica\u00e7\u00f5es","text":"<p>Desenvolva um sistema que monitora temperatura e umidade, envia os dados para a nuvem e recebe notifica\u00e7\u00f5es quando os valores excedem determinados limiares.</p>"},{"location":"aulas/iot/modulos/modulo13.html#52-automacao-residencial","title":"5.2 Automa\u00e7\u00e3o Residencial","text":"<p>Crie um sistema de automa\u00e7\u00e3o para controlar luzes, ventiladores e outros dispositivos eletr\u00f4nicos atrav\u00e9s de comandos enviados pela internet ou aplicativos m\u00f3veis.</p>"},{"location":"aulas/iot/modulos/modulo13.html#53-integracao-com-assistentes-virtuais","title":"5.3 Integra\u00e7\u00e3o com Assistentes Virtuais","text":"<p>Integre o Arduino com assistentes virtuais como Alexa ou Google Assistant para controlar dispositivos por voz.</p>"},{"location":"aulas/iot/modulos/modulo13.html#6-conceitos-importantes","title":"6. Conceitos Importantes","text":""},{"location":"aulas/iot/modulos/modulo13.html#61-seguranca-na-iot","title":"6.1 Seguran\u00e7a na IoT","text":"<ul> <li>Autentica\u00e7\u00e3o e Autoriza\u00e7\u00e3o: Garantir que apenas dispositivos e usu\u00e1rios autorizados possam acessar os dados.</li> <li>Criptografia: Proteger os dados transmitidos para evitar intercepta\u00e7\u00f5es.</li> <li>Atualiza\u00e7\u00f5es de Firmware: Manter o software do Arduino e dos m\u00f3dulos de conectividade atualizado para corrigir vulnerabilidades.</li> </ul>"},{"location":"aulas/iot/modulos/modulo13.html#62-gerenciamento-de-energia","title":"6.2 Gerenciamento de Energia","text":"<ul> <li>Efici\u00eancia Energ\u00e9tica: Otimize o consumo de energia dos dispositivos conectados.</li> <li>Alimenta\u00e7\u00e3o de Baixo Consumo: Utilize modos de baixo consumo quando os dispositivos n\u00e3o estiverem ativos.</li> <li>Fontes de Energia Adequadas: Escolha fontes que atendam \u00e0s necessidades de energia dos dispositivos IoT.</li> </ul>"},{"location":"aulas/iot/modulos/modulo13.html#63-protocolos-de-comunicacao","title":"6.3 Protocolos de Comunica\u00e7\u00e3o","text":"<ul> <li>HTTP/HTTPS: Utilizados para comunica\u00e7\u00e3o web padr\u00e3o.</li> <li>MQTT: Ideal para aplica\u00e7\u00f5es que requerem comunica\u00e7\u00e3o leve e eficiente.</li> <li>WebSockets: Permite comunica\u00e7\u00e3o bidirecional em tempo real.</li> <li>CoAP: Protocolo de aplica\u00e7\u00e3o otimizado para dispositivos com recursos limitados.</li> </ul>"},{"location":"aulas/iot/modulos/modulo13.html#64-armazenamento-e-processamento-de-dados","title":"6.4 Armazenamento e Processamento de Dados","text":"<ul> <li>Servi\u00e7os de Nuvem: ThingSpeak, Adafruit IO, AWS IoT, Google Cloud IoT.</li> <li>Banco de Dados: Armazenar grandes volumes de dados para an\u00e1lise e visualiza\u00e7\u00e3o.</li> <li>An\u00e1lise de Dados: Utilizar ferramentas para interpretar os dados coletados e obter insights.</li> </ul>"},{"location":"aulas/iot/modulos/modulo13.html#65-boas-praticas-na-iot","title":"6.5 Boas Pr\u00e1ticas na IoT","text":"<ul> <li>Modularidade: Desenvolva sistemas modulares para facilitar atualiza\u00e7\u00f5es e manuten\u00e7\u00f5es.</li> <li>Escalabilidade: Planeje sistemas que possam ser facilmente escalados para incluir mais dispositivos.</li> <li>Resili\u00eancia: Assegure que o sistema continue operando mesmo em caso de falhas de alguns componentes.</li> <li>Documenta\u00e7\u00e3o: Mantenha uma documenta\u00e7\u00e3o detalhada dos projetos para facilitar futuras modifica\u00e7\u00f5es e integra\u00e7\u00f5es.</li> </ul>"},{"location":"aulas/iot/modulos/modulo13.html#7-recursos-adicionais","title":"7. Recursos Adicionais","text":"<ul> <li> <p>Documenta\u00e7\u00e3o Oficial do Arduino:</p> </li> <li> <p>ESP8266WiFi Library</p> </li> <li>PubSubClient Library</li> <li> <p>ArduinoJson Library</p> </li> <li> <p>Tutoriais e Guias:</p> </li> <li> <p>Introdu\u00e7\u00e3o \u00e0 IoT com Arduino</p> </li> <li>Utilizando MQTT com Arduino</li> <li> <p>Integra\u00e7\u00e3o do Arduino com Servi\u00e7os de Nuvem</p> </li> <li> <p>V\u00eddeos Educacionais:</p> </li> <li> <p>Arduino IoT Tutorial</p> </li> <li>Configurando MQTT com Arduino</li> <li>Projetos IoT com Arduino</li> </ul>"},{"location":"aulas/iot/modulos/modulo13.html#8-exemplos-praticos","title":"8. Exemplos Pr\u00e1ticos","text":""},{"location":"aulas/iot/modulos/modulo13.html#81-monitoramento-de-temperatura-e-umidade-com-notificacoes-via-mqtt","title":"8.1 Monitoramento de Temperatura e Umidade com Notifica\u00e7\u00f5es via MQTT","text":"<pre><code>#include &lt;ESP8266WiFi.h&gt;\n#include &lt;PubSubClient.h&gt;\n#include \"DHT.h\"\n\n// Configura\u00e7\u00f5es de rede\nconst char* ssid = \"Seu_SSID\";\nconst char* password = \"Sua_Senha\";\n\n// Configura\u00e7\u00f5es do MQTT\nconst char* mqtt_server = \"broker.hivemq.com\";\n\nWiFiClient espClient;\nPubSubClient client(espClient);\n\n// Configura\u00e7\u00f5es do DHT\n#define DHTPIN 2\n#define DHTTYPE DHT22\nDHT dht(DHTPIN, DHTTYPE);\n\n// Limiar para notifica\u00e7\u00f5es\nconst float limiarTemperatura = 30.0;\nconst float limiarUmidade = 70.0;\n\nvoid setup_wifi() {\n    delay(10);\n    Serial.println();\n    Serial.print(\"Conectando ao Wi-Fi \");\n    Serial.println(ssid);\n\n    WiFi.begin(ssid, password);\n\n    while (WiFi.status() != WL_CONNECTED) {\n        delay(500);\n        Serial.print(\".\");\n    }\n\n    Serial.println(\"\");\n    Serial.println(\"Wi-Fi conectado\");\n    Serial.println(\"Endere\u00e7o IP: \");\n    Serial.println(WiFi.localIP());\n}\n\nvoid callback(char* topic, byte* payload, unsigned int length) {\n    // Callback para mensagens recebidas (n\u00e3o utilizado neste exemplo)\n}\n\nvoid reconnect() {\n    while (!client.connected()) {\n        Serial.print(\"Tentando conex\u00e3o MQTT...\");\n        if (client.connect(\"ArduinoClient\")) {\n            Serial.println(\"conectado\");\n        } else {\n            Serial.print(\"Falhou, rc=\");\n            Serial.print(client.state());\n            Serial.println(\" tentando novamente em 5 segundos\");\n            delay(5000);\n        }\n    }\n}\n\nvoid setup() {\n    Serial.begin(115200);\n    setup_wifi();\n    client.setServer(mqtt_server, 1883);\n    client.setCallback(callback);\n    dht.begin();\n}\n\nvoid loop() {\n    if (!client.connected()) {\n        reconnect();\n    }\n    client.loop();\n\n    // Leitura dos sensores\n    float temperatura = dht.readTemperature();\n    float umidade = dht.readHumidity();\n\n    if (isnan(temperatura) || isnan(umidade)) {\n        Serial.println(\"Falha na leitura do sensor DHT!\");\n        return;\n    }\n\n    // Publica os dados\n    char msg[50];\n    snprintf(msg, 50, \"Temperatura: %.2f, Umidade: %.2f\", temperatura, umidade);\n    client.publish(\"arduino/ambiente\", msg);\n    Serial.println(\"Dados publicados no MQTT\");\n\n    // Envia notifica\u00e7\u00f5es se os limiares forem excedidos\n    if (temperatura &gt; limiarTemperatura) {\n        client.publish(\"arduino/alertas\", \"Temperatura alta!\");\n        Serial.println(\"Alerta: Temperatura alta!\");\n    }\n\n    if (umidade &gt; limiarUmidade) {\n        client.publish(\"arduino/alertas\", \"Umidade alta!\");\n        Serial.println(\"Alerta: Umidade alta!\");\n    }\n\n    delay(10000); // Aguarda 10 segundos antes da pr\u00f3xima leitura\n}\n</code></pre> <p>Explica\u00e7\u00e3o:</p> <ul> <li>Leitura de Sensores: Obt\u00e9m os valores de temperatura e umidade do sensor DHT22.</li> <li>Publica\u00e7\u00e3o MQTT: Envia os dados para o t\u00f3pico \"arduino/ambiente\".</li> <li>Notifica\u00e7\u00f5es: Publica alertas nos t\u00f3picos \"arduino/alertas\" se os valores excederem os limiares definidos.</li> </ul>"},{"location":"aulas/iot/modulos/modulo13.html#82-sistema-de-controle-de-luz-inteligente-com-arduino-e-mqtt","title":"8.2 Sistema de Controle de Luz Inteligente com Arduino e MQTT","text":"<pre><code>#include &lt;ESP8266WiFi.h&gt;\n#include &lt;PubSubClient.h&gt;\n\n// Configura\u00e7\u00f5es de rede\nconst char* ssid = \"Seu_SSID\";\nconst char* password = \"Sua_Senha\";\n\n// Configura\u00e7\u00f5es do MQTT\nconst char* mqtt_server = \"broker.hivemq.com\";\n\nWiFiClient espClient;\nPubSubClient client(espClient);\n\n// Pino do LED\nconst int pinoLED = 5;\n\n// Fun\u00e7\u00e3o de callback para receber mensagens\nvoid callback(char* topic, byte* payload, unsigned int length) {\n    String mensagem;\n    for (unsigned int i = 0; i &lt; length; i++) {\n        mensagem += (char)payload[i];\n    }\n    Serial.print(\"Mensagem recebida no t\u00f3pico [\");\n    Serial.print(topic);\n    Serial.print(\"]: \");\n    Serial.println(mensagem);\n\n    if (mensagem == \"ON\") {\n        digitalWrite(pinoLED, HIGH);\n    } else if (mensagem == \"OFF\") {\n        digitalWrite(pinoLED, LOW);\n    }\n}\n\nvoid setup_wifi() {\n    delay(10);\n    Serial.println();\n    Serial.print(\"Conectando ao Wi-Fi \");\n    Serial.println(ssid);\n\n    WiFi.begin(ssid, password);\n\n    while (WiFi.status() != WL_CONNECTED) {\n        delay(500);\n        Serial.print(\".\");\n    }\n\n    Serial.println(\"\");\n    Serial.println(\"Wi-Fi conectado\");\n    Serial.println(\"Endere\u00e7o IP: \");\n    Serial.println(WiFi.localIP());\n}\n\nvoid reconnect() {\n    while (!client.connected()) {\n        Serial.print(\"Tentando conex\u00e3o MQTT...\");\n        if (client.connect(\"ArduinoClient\")) {\n            Serial.println(\"conectado\");\n            client.subscribe(\"arduino/luz\");\n        } else {\n            Serial.print(\"Falhou, rc=\");\n            Serial.print(client.state());\n            Serial.println(\" tentando novamente em 5 segundos\");\n            delay(5000);\n        }\n    }\n}\n\nvoid setup() {\n    pinMode(pinoLED, OUTPUT);\n    digitalWrite(pinoLED, LOW);\n    Serial.begin(115200);\n    setup_wifi();\n    client.setServer(mqtt_server, 1883);\n    client.setCallback(callback);\n}\n\nvoid loop() {\n    if (!client.connected()) {\n        reconnect();\n    }\n    client.loop();\n}\n</code></pre> <p>Explica\u00e7\u00e3o:</p> <ul> <li>Subscri\u00e7\u00e3o MQTT: Subscreve ao t\u00f3pico \"arduino/luz\" para receber comandos de controle.</li> <li>Controle de LED: Liga ou desliga o LED com base nas mensagens recebidas (\"ON\" ou \"OFF\").</li> <li>Interface de Controle: Pode ser controlado atrav\u00e9s de aplicativos MQTT ou dashboards web.</li> </ul>"},{"location":"aulas/iot/modulos/modulo13.html#83-sistema-de-irrigacao-automatica-com-sensores-e-mqtt","title":"8.3 Sistema de Irriga\u00e7\u00e3o Autom\u00e1tica com Sensores e MQTT","text":"<pre><code>#include &lt;ESP8266WiFi.h&gt;\n#include &lt;PubSubClient.h&gt;\n#include \"DHT.h\"\n\n// Configura\u00e7\u00f5es de rede\nconst char* ssid = \"Seu_SSID\";\nconst char* password = \"Sua_Senha\";\n\n// Configura\u00e7\u00f5es do MQTT\nconst char* mqtt_server = \"broker.hivemq.com\";\n\nWiFiClient espClient;\nPubSubClient client(espClient);\n\n// Configura\u00e7\u00f5es do DHT\n#define DHTPIN 2\n#define DHTTYPE DHT22\nDHT dht(DHTPIN, DHTTYPE);\n\n// Pino do rel\u00e9\nconst int pinoRele = 5;\n\n// Limiar de umidade para irriga\u00e7\u00e3o\nconst float limiarUmidade = 30.0;\n\nvoid setup_wifi() {\n    delay(10);\n    Serial.println();\n    Serial.print(\"Conectando ao Wi-Fi \");\n    Serial.println(ssid);\n\n    WiFi.begin(ssid, password);\n\n    while (WiFi.status() != WL_CONNECTED) {\n        delay(500);\n        Serial.print(\".\");\n    }\n\n    Serial.println(\"\");\n    Serial.println(\"Wi-Fi conectado\");\n    Serial.println(\"Endere\u00e7o IP: \");\n    Serial.println(WiFi.localIP());\n}\n\nvoid reconnect() {\n    while (!client.connected()) {\n        Serial.print(\"Tentando conex\u00e3o MQTT...\");\n        if (client.connect(\"ArduinoClient\")) {\n            Serial.println(\"conectado\");\n        } else {\n            Serial.print(\"Falhou, rc=\");\n            Serial.print(client.state());\n            Serial.println(\" tentando novamente em 5 segundos\");\n            delay(5000);\n        }\n    }\n}\n\nvoid setup() {\n    pinMode(pinoRele, OUTPUT);\n    digitalWrite(pinoRele, LOW);\n    Serial.begin(115200);\n    setup_wifi();\n    client.setServer(mqtt_server, 1883);\n    dht.begin();\n}\n\nvoid loop() {\n    if (!client.connected()) {\n        reconnect();\n    }\n    client.loop();\n\n    // Leitura do sensor DHT22\n    float umidade = dht.readHumidity();\n\n    if (isnan(umidade)) {\n        Serial.println(\"Falha na leitura do sensor DHT!\");\n        return;\n    }\n\n    Serial.print(\"Umidade do Solo: \");\n    Serial.println(umidade);\n\n    // Publica a umidade no MQTT\n    char msg[50];\n    snprintf(msg, 50, \"Umidade: %.2f\", umidade);\n    client.publish(\"arduino/irrigacao\", msg);\n\n    // Controle da irriga\u00e7\u00e3o\n    if (umidade &lt; limiarUmidade) {\n        digitalWrite(pinoRele, HIGH); // Liga a bomba\n        Serial.println(\"Bomba Ligada.\");\n    } else {\n        digitalWrite(pinoRele, LOW); // Desliga a bomba\n        Serial.println(\"Bomba Desligada.\");\n    }\n\n    delay(10000); // Aguarda 10 segundos antes da pr\u00f3xima leitura\n}\n</code></pre> <p>Explica\u00e7\u00e3o:</p> <ul> <li>Leitura de Umidade: Obt\u00e9m a umidade do solo utilizando o sensor DHT22.</li> <li>Publica\u00e7\u00e3o MQTT: Envia a umidade para o t\u00f3pico \"arduino/irrigacao\".</li> <li>Controle da Bomba: Liga a bomba de irriga\u00e7\u00e3o se a umidade estiver abaixo do limiar definido e desliga caso contr\u00e1rio.</li> <li>Automatiza\u00e7\u00e3o: Permite que o sistema realize irriga\u00e7\u00e3o autom\u00e1tica com base nas condi\u00e7\u00f5es do solo.</li> </ul>"},{"location":"aulas/iot/modulos/modulo13.html#9-conceitos-importantes","title":"9. Conceitos Importantes","text":""},{"location":"aulas/iot/modulos/modulo13.html#91-seguranca-na-iot","title":"9.1 Seguran\u00e7a na IoT","text":"<ul> <li>Autentica\u00e7\u00e3o e Autoriza\u00e7\u00e3o: Implementar mecanismos para garantir que apenas dispositivos e usu\u00e1rios autorizados possam acessar os dados e controlar os dispositivos.</li> <li>Criptografia de Dados: Utilizar protocolos seguros (como HTTPS) para proteger os dados transmitidos entre o Arduino e os servi\u00e7os de nuvem.</li> <li>Atualiza\u00e7\u00f5es de Firmware: Manter o firmware do Arduino e dos m\u00f3dulos de conectividade atualizado para corrigir vulnerabilidades e melhorar a seguran\u00e7a.</li> </ul>"},{"location":"aulas/iot/modulos/modulo13.html#92-gerenciamento-de-energia","title":"9.2 Gerenciamento de Energia","text":"<ul> <li>Efici\u00eancia Energ\u00e9tica: Projetar sistemas que utilizem menos energia, prolongando a vida \u00fatil de baterias em dispositivos port\u00e1teis.</li> <li>Modos de Economia de Energia: Utilizar modos de baixo consumo quando o dispositivo n\u00e3o estiver ativo, reduzindo o consumo geral.</li> <li>Fontes de Energia Adequadas: Selecionar fontes de energia que atendam \u00e0s necessidades dos sensores e atuadores utilizados no projeto.</li> </ul>"},{"location":"aulas/iot/modulos/modulo13.html#93-protocolos-de-comunicacao","title":"9.3 Protocolos de Comunica\u00e7\u00e3o","text":"<ul> <li>HTTP/HTTPS: Utilizados para comunica\u00e7\u00e3o web padr\u00e3o, ideal para requisi\u00e7\u00f5es simples e integra\u00e7\u00e3o com APIs REST.</li> <li>MQTT: Protocolo de mensagens leve, ideal para aplica\u00e7\u00f5es IoT que requerem comunica\u00e7\u00e3o eficiente e em tempo real.</li> <li>WebSockets: Permite comunica\u00e7\u00e3o bidirecional em tempo real, \u00fatil para aplica\u00e7\u00f5es que necessitam de atualiza\u00e7\u00f5es instant\u00e2neas.</li> <li>CoAP: Protocolo de aplica\u00e7\u00e3o otimizado para dispositivos com recursos limitados, similar ao HTTP mas mais eficiente.</li> </ul>"},{"location":"aulas/iot/modulos/modulo13.html#94-armazenamento-e-processamento-de-dados","title":"9.4 Armazenamento e Processamento de Dados","text":"<ul> <li>Servi\u00e7os de Nuvem: Plataformas como ThingSpeak, Adafruit IO, AWS IoT e Google Cloud IoT permitem armazenar, processar e visualizar dados de sensores.</li> <li>Banco de Dados: Utilizar bancos de dados para armazenar grandes volumes de dados coletados, facilitando an\u00e1lises futuras.</li> <li>An\u00e1lise de Dados: Aplicar t\u00e9cnicas de an\u00e1lise para interpretar os dados coletados e extrair insights valiosos para o projeto.</li> </ul>"},{"location":"aulas/iot/modulos/modulo13.html#95-boas-praticas-na-iot","title":"9.5 Boas Pr\u00e1ticas na IoT","text":"<ul> <li>Modularidade e Escalabilidade: Desenvolver sistemas modulares que possam ser facilmente escalados para incluir mais dispositivos e funcionalidades.</li> <li>Resili\u00eancia e Redund\u00e2ncia: Assegurar que o sistema continue operando mesmo em caso de falhas de alguns componentes, implementando redund\u00e2ncias quando necess\u00e1rio.</li> <li>Documenta\u00e7\u00e3o Completa: Manter uma documenta\u00e7\u00e3o detalhada do projeto, facilitando manuten\u00e7\u00f5es e futuras expans\u00f5es.</li> <li>Prote\u00e7\u00e3o F\u00edsica: Garantir que os componentes eletr\u00f4nicos estejam protegidos contra danos f\u00edsicos e interfer\u00eancias ambientais.</li> </ul>"},{"location":"aulas/iot/modulos/modulo13.html#10-recursos-adicionais","title":"10. Recursos Adicionais","text":"<ul> <li> <p>Documenta\u00e7\u00e3o Oficial do Arduino:</p> </li> <li> <p>ESP8266WiFi Library</p> </li> <li>PubSubClient Library</li> <li> <p>ArduinoJson Library</p> </li> <li> <p>Tutoriais e Guias:</p> </li> <li> <p>Introdu\u00e7\u00e3o \u00e0 IoT com Arduino</p> </li> <li>Utilizando MQTT com Arduino</li> <li> <p>Integra\u00e7\u00e3o do Arduino com Servi\u00e7os de Nuvem</p> </li> <li> <p>V\u00eddeos Educacionais:</p> </li> <li> <p>Arduino IoT Tutorial</p> </li> <li>Configurando MQTT com Arduino</li> <li>Projetos IoT com Arduino</li> </ul>"},{"location":"aulas/iot/modulos/modulo13.html#11-conclusao-do-modulo","title":"11. Conclus\u00e3o do M\u00f3dulo","text":"<p>Neste m\u00f3dulo, voc\u00ea aprendeu:</p> <ul> <li>Os conceitos b\u00e1sicos e avan\u00e7ados de Internet das Coisas (IoT).</li> <li>Como conectar o Arduino \u00e0 internet utilizando m\u00f3dulos Wi-Fi e Ethernet.</li> <li>Implementa\u00e7\u00e3o de comunica\u00e7\u00e3o com servi\u00e7os de nuvem como ThingSpeak e MQTT.</li> <li>T\u00e9cnicas de publica\u00e7\u00e3o e subscri\u00e7\u00e3o de dados utilizando protocolos eficientes.</li> <li>Desenvolvimento de projetos IoT integrando sensores, atuadores e comunica\u00e7\u00e3o online.</li> <li>Import\u00e2ncia da seguran\u00e7a, gerenciamento de energia e boas pr\u00e1ticas na cria\u00e7\u00e3o de sistemas IoT.</li> <li>Praticou com exemplos e exerc\u00edcios que refor\u00e7am o entendimento dos conceitos de IoT com Arduino.</li> </ul> <p>Voc\u00ea completou todos os m\u00f3dulos do curso \"Programa\u00e7\u00e3o em Arduino: Conceitos Fundamentais sem Hardware\". Parab\u00e9ns pelo empenho e dedica\u00e7\u00e3o!</p>"},{"location":"aulas/iot/modulos/modulo13.html#12-proximos-passos","title":"12. Pr\u00f3ximos Passos","text":"<ul> <li>Revisar todo o conte\u00fado do curso para consolidar o aprendizado.</li> <li>Explorar projetos avan\u00e7ados que combinam m\u00faltiplos conceitos aprendidos, como rob\u00f3tica, automa\u00e7\u00e3o residencial ou sistemas de monitoramento ambiental.</li> <li>Participar de comunidades e f\u00f3runs de Arduino para trocar experi\u00eancias e obter suporte cont\u00ednuo.</li> <li>Considerar cursos avan\u00e7ados ou especializa\u00e7\u00f5es em \u00e1reas espec\u00edficas de interesse, como desenvolvimento de firmware, integra\u00e7\u00e3o com plataformas de IoT ou design de hardware.</li> <li>Desenvolver seu pr\u00f3prio portf\u00f3lio de projetos Arduino para demonstrar suas habilidades e conhecimentos adquiridos.</li> </ul> <p>Se tiver d\u00favidas ou precisar de assist\u00eancia, continue participando de comunidades de aprendizagem ou consulte os recursos adicionais fornecidos ao longo dos m\u00f3dulos.</p> <p>Parab\u00e9ns por concluir o curso! Continue explorando e criando projetos incr\u00edveis com Arduino!</p>"},{"location":"aulas/iot/modulos/modulo14.html","title":"M\u00f3dulo 14: Integra\u00e7\u00e3o com Assistentes Virtuais e Controle por Voz","text":"<p>Bem-vindo ao M\u00f3dulo 14 do curso \"Programa\u00e7\u00e3o em Arduino: Conceitos Fundamentais sem Hardware\". Neste m\u00f3dulo, voc\u00ea ir\u00e1 aprender a integrar o Arduino com assistentes virtuais como Amazon Alexa e Google Assistant, permitindo o controle por voz de dispositivos conectados. Esta integra\u00e7\u00e3o amplia as possibilidades dos seus projetos, tornando-os mais interativos e acess\u00edveis.</p>"},{"location":"aulas/iot/modulos/modulo14.html#objetivos-do-modulo","title":"Objetivos do M\u00f3dulo","text":"<ul> <li>Compreender os conceitos b\u00e1sicos de assistentes virtuais e controle por voz.</li> <li>Aprender a configurar o Arduino para comunica\u00e7\u00e3o com plataformas de assistentes virtuais.</li> <li>Implementar comandos de voz para controlar LEDs, motores e outros atuadores.</li> <li>Utilizar servi\u00e7os como IFTTT para facilitar a integra\u00e7\u00e3o entre o Arduino e assistentes virtuais.</li> <li>Desenvolver projetos que respondem a comandos de voz para realizar a\u00e7\u00f5es espec\u00edficas.</li> <li>Resolver exerc\u00edcios pr\u00e1ticos para consolidar o conhecimento sobre integra\u00e7\u00e3o com assistentes virtuais.</li> </ul>"},{"location":"aulas/iot/modulos/modulo14.html#1-introducao-a-integracao-com-assistentes-virtuais","title":"1. Introdu\u00e7\u00e3o \u00e0 Integra\u00e7\u00e3o com Assistentes Virtuais","text":""},{"location":"aulas/iot/modulos/modulo14.html#11-o-que-sao-assistentes-virtuais","title":"1.1 O que s\u00e3o Assistentes Virtuais?","text":"<p>Assistentes virtuais s\u00e3o programas baseados em intelig\u00eancia artificial que interagem com os usu\u00e1rios por meio de comandos de voz. Exemplos populares incluem Amazon Alexa, Google Assistant e Apple Siri. Eles permitem controlar dispositivos conectados, obter informa\u00e7\u00f5es, definir lembretes e muito mais.</p>"},{"location":"aulas/iot/modulos/modulo14.html#12-importancia-do-controle-por-voz","title":"1.2 Import\u00e2ncia do Controle por Voz","text":"<ul> <li>Conveni\u00eancia: Permite controlar dispositivos sem a necessidade de interfaces f\u00edsicas.</li> <li>Acessibilidade: Facilita o uso para pessoas com limita\u00e7\u00f5es f\u00edsicas.</li> <li>Automa\u00e7\u00e3o: Integra facilmente com sistemas de automa\u00e7\u00e3o residencial para criar ambientes inteligentes.</li> </ul>"},{"location":"aulas/iot/modulos/modulo14.html#13-componentes-basicos-para-integracao","title":"1.3 Componentes B\u00e1sicos para Integra\u00e7\u00e3o","text":"<ul> <li>Arduino com Conectividade \u00e0 Internet: Utilizando m\u00f3dulos como ESP8266 ou ESP32.</li> <li>Servi\u00e7os de Integra\u00e7\u00e3o: Como IFTTT (If This Then That).</li> <li>Assistente Virtual: Amazon Alexa, Google Assistant, etc.</li> <li>Plataforma de Comunica\u00e7\u00e3o: Webhooks, APIs REST.</li> </ul>"},{"location":"aulas/iot/modulos/modulo14.html#2-configurando-o-arduino-para-controle-por-voz","title":"2. Configurando o Arduino para Controle por Voz","text":""},{"location":"aulas/iot/modulos/modulo14.html#21-utilizando-o-ifttt-para-integracao","title":"2.1 Utilizando o IFTTT para Integra\u00e7\u00e3o","text":"<p>IFTTT \u00e9 um servi\u00e7o que conecta diferentes aplicativos e dispositivos por meio de \"applets\". Ele facilita a integra\u00e7\u00e3o entre o Arduino e assistentes virtuais sem a necessidade de programa\u00e7\u00e3o complexa.</p> <p>Passos para Utilizar o IFTTT:</p> <ol> <li>Criar uma Conta no IFTTT: Acesse IFTTT e crie uma conta gratuita.</li> <li>Criar um Applet: Defina um gatilho (trigger) e uma a\u00e7\u00e3o (action).</li> <li>Configurar Webhooks: Utilize o servi\u00e7o Webhooks para enviar requisi\u00e7\u00f5es HTTP ao Arduino.</li> </ol>"},{"location":"aulas/iot/modulos/modulo14.html#22-exemplo-de-integracao-com-amazon-alexa","title":"2.2 Exemplo de Integra\u00e7\u00e3o com Amazon Alexa","text":"<p>Objetivo: Controlar um LED conectado ao Arduino usando comandos de voz via Amazon Alexa.</p> <p>Componentes Necess\u00e1rios:</p> <ul> <li>Arduino Uno com m\u00f3dulo ESP8266 ou ESP32.</li> <li>LED e resistor de 220\u03a9.</li> <li>Cabos de conex\u00e3o.</li> <li>Conta na Amazon Alexa e no IFTTT.</li> </ul>"},{"location":"aulas/iot/modulos/modulo14.html#23-exemplo-de-codigo-para-controle-de-led-via-ifttt","title":"2.3 Exemplo de C\u00f3digo para Controle de LED via IFTTT","text":"<pre><code>#include &lt;ESP8266WiFi.h&gt;\n#include &lt;ESP8266HTTPClient.h&gt;\n\n// Configura\u00e7\u00f5es de rede\nconst char* ssid = \"Seu_SSID\";\nconst char* password = \"Sua_Senha\";\n\n// Endere\u00e7o do Webhook do IFTTT\nconst char* serverName = \"http://maker.ifttt.com/trigger/LED_ON/with/key/SUA_CHAVE_IFTTT\";\n\n// Pino do LED\nconst int pinoLED = 5;\n\nvoid setup() {\n    Serial.begin(115200);\n    pinMode(pinoLED, OUTPUT);\n    digitalWrite(pinoLED, LOW);\n\n    // Conecta ao Wi-Fi\n    WiFi.begin(ssid, password);\n    Serial.print(\"Conectando ao Wi-Fi\");\n    while (WiFi.status() != WL_CONNECTED) {\n        delay(500);\n        Serial.print(\".\");\n    }\n    Serial.println(\" Conectado!\");\n}\n\nvoid loop() {\n    if (WiFi.status() == WL_CONNECTED) {\n        HTTPClient http;\n\n        http.begin(serverName);\n        int httpResponseCode = http.GET();\n\n        if (httpResponseCode &gt; 0) {\n            Serial.print(\"C\u00f3digo de resposta HTTP: \");\n            Serial.println(httpResponseCode);\n            if (httpResponseCode == 200) {\n                digitalWrite(pinoLED, HIGH); // Liga o LED\n                delay(5000); // Mant\u00e9m o LED ligado por 5 segundos\n                digitalWrite(pinoLED, LOW); // Desliga o LED\n            }\n        } else {\n            Serial.print(\"Erro na requisi\u00e7\u00e3o: \");\n            Serial.println(httpResponseCode);\n        }\n        http.end();\n    } else {\n        Serial.println(\"Erro na conex\u00e3o Wi-Fi\");\n    }\n    delay(20000); // Aguarda 20 segundos antes da pr\u00f3xima requisi\u00e7\u00e3o\n}\n</code></pre> <p>Explica\u00e7\u00e3o:</p> <ul> <li>Conex\u00e3o Wi-Fi: O Arduino conecta-se \u00e0 rede Wi-Fi especificada.</li> <li>Requisi\u00e7\u00e3o HTTP: Envia uma requisi\u00e7\u00e3o GET para o Webhook do IFTTT quando acionado.</li> <li>Controle do LED: Liga o LED quando recebe uma resposta HTTP 200 (sucesso) e o desliga ap\u00f3s 5 segundos.</li> </ul>"},{"location":"aulas/iot/modulos/modulo14.html#3-implementando-comandos-de-voz-com-google-assistant","title":"3. Implementando Comandos de Voz com Google Assistant","text":""},{"location":"aulas/iot/modulos/modulo14.html#31-configuracao-do-ifttt-com-google-assistant","title":"3.1 Configura\u00e7\u00e3o do IFTTT com Google Assistant","text":"<p>Objetivo: Controlar um motor DC usando comandos de voz via Google Assistant.</p> <p>Passos:</p> <ol> <li>Criar um Applet no IFTTT:</li> <li>If This: Escolha o servi\u00e7o Google Assistant e defina o comando de voz (por exemplo, \"girar motor\").</li> <li> <p>Then That: Escolha o servi\u00e7o Webhooks e configure a URL do Arduino para acionar o motor.</p> </li> <li> <p>Configurar o Arduino para Receber Requisi\u00e7\u00f5es:</p> </li> <li>Utilize o mesmo m\u00e9todo mostrado no exemplo anterior para receber e interpretar as requisi\u00e7\u00f5es HTTP.</li> </ol>"},{"location":"aulas/iot/modulos/modulo14.html#32-exemplo-de-codigo-para-controle-de-motor-dc-via-ifttt","title":"3.2 Exemplo de C\u00f3digo para Controle de Motor DC via IFTTT","text":"<pre><code>#include &lt;ESP8266WiFi.h&gt;\n#include &lt;ESP8266HTTPClient.h&gt;\n\n// Configura\u00e7\u00f5es de rede\nconst char* ssid = \"Seu_SSID\";\nconst char* password = \"Sua_Senha\";\n\n// Endere\u00e7o do Webhook do IFTTT\nconst char* serverName = \"http://maker.ifttt.com/trigger/MOTOR_ON/with/key/SUA_CHAVE_IFTTT\";\n\n// Pinos do Motor DC\nconst int IN1 = D1;\nconst int IN2 = D2;\nconst int ENA = D3;\n\nvoid setup() {\n    Serial.begin(115200);\n    pinMode(IN1, OUTPUT);\n    pinMode(IN2, OUTPUT);\n    pinMode(ENA, OUTPUT);\n    digitalWrite(IN1, LOW);\n    digitalWrite(IN2, LOW);\n    analogWrite(ENA, 0);\n\n    // Conecta ao Wi-Fi\n    WiFi.begin(ssid, password);\n    Serial.print(\"Conectando ao Wi-Fi\");\n    while (WiFi.status() != WL_CONNECTED) {\n        delay(500);\n        Serial.print(\".\");\n    }\n    Serial.println(\" Conectado!\");\n}\n\nvoid loop() {\n    if (WiFi.status() == WL_CONNECTED) {\n        HTTPClient http;\n\n        http.begin(serverName);\n        int httpResponseCode = http.GET();\n\n        if (httpResponseCode &gt; 0) {\n            Serial.print(\"C\u00f3digo de resposta HTTP: \");\n            Serial.println(httpResponseCode);\n            if (httpResponseCode == 200) {\n                // Gira o motor para frente\n                digitalWrite(IN1, HIGH);\n                digitalWrite(IN2, LOW);\n                analogWrite(ENA, 200); // Velocidade do motor\n                delay(5000); // Mant\u00e9m o motor girando por 5 segundos\n\n                // Para o motor\n                digitalWrite(IN1, LOW);\n                digitalWrite(IN2, LOW);\n                analogWrite(ENA, 0);\n            }\n        } else {\n            Serial.print(\"Erro na requisi\u00e7\u00e3o: \");\n            Serial.println(httpResponseCode);\n        }\n        http.end();\n    } else {\n        Serial.println(\"Erro na conex\u00e3o Wi-Fi\");\n    }\n    delay(20000); // Aguarda 20 segundos antes da pr\u00f3xima requisi\u00e7\u00e3o\n}\n</code></pre> <p>Explica\u00e7\u00e3o:</p> <ul> <li>Controle Direcional: Define a dire\u00e7\u00e3o do motor DC ao configurar os pinos IN1 e IN2.</li> <li>Velocidade do Motor: Controlada pelo pino ENA utilizando PWM.</li> <li>Automa\u00e7\u00e3o: Gira o motor para frente por 5 segundos quando recebe uma requisi\u00e7\u00e3o v\u00e1lida.</li> </ul>"},{"location":"aulas/iot/modulos/modulo14.html#4-desenvolvendo-projetos-com-controle-por-voz","title":"4. Desenvolvendo Projetos com Controle por Voz","text":""},{"location":"aulas/iot/modulos/modulo14.html#41-controle-de-luzes-e-aparelhos-domesticos","title":"4.1 Controle de Luzes e Aparelhos Dom\u00e9sticos","text":"<p>Crie um sistema onde voc\u00ea pode ligar e desligar luzes, ventiladores e outros aparelhos eletr\u00f4nicos usando comandos de voz atrav\u00e9s do Alexa ou Google Assistant.</p>"},{"location":"aulas/iot/modulos/modulo14.html#42-automacao-de-portas-e-valvulas","title":"4.2 Automa\u00e7\u00e3o de Portas e V\u00e1lvulas","text":"<p>Implemente o controle de portas autom\u00e1ticas, cortinas e v\u00e1lvulas de irriga\u00e7\u00e3o por meio de comandos de voz, proporcionando maior comodidade e efici\u00eancia no gerenciamento do ambiente.</p>"},{"location":"aulas/iot/modulos/modulo14.html#43-monitoramento-e-resposta-a-eventos","title":"4.3 Monitoramento e Resposta a Eventos","text":"<p>Desenvolva sistemas que monitoram eventos espec\u00edficos (como detec\u00e7\u00e3o de movimento ou mudan\u00e7a de temperatura) e respondem automaticamente a esses eventos, podendo tamb\u00e9m enviar notifica\u00e7\u00f5es por meio de assistentes virtuais.</p>"},{"location":"aulas/iot/modulos/modulo14.html#5-conceitos-avancados-de-controle-por-voz","title":"5. Conceitos Avan\u00e7ados de Controle por Voz","text":""},{"location":"aulas/iot/modulos/modulo14.html#51-utilizando-apis-de-assistentes-virtuais","title":"5.1 Utilizando APIs de Assistentes Virtuais","text":"<p>Aprofunde-se no uso de APIs fornecidas por assistentes virtuais para criar intera\u00e7\u00f5es mais complexas e personalizadas entre o Arduino e os servi\u00e7os de voz.</p>"},{"location":"aulas/iot/modulos/modulo14.html#52-seguranca-e-autenticacao","title":"5.2 Seguran\u00e7a e Autentica\u00e7\u00e3o","text":"<p>Implemente m\u00e9todos de seguran\u00e7a para garantir que apenas comandos autorizados possam controlar os dispositivos conectados, protegendo seu sistema contra acessos n\u00e3o desejados.</p>"},{"location":"aulas/iot/modulos/modulo14.html#53-gerenciamento-de-multiplos-dispositivos","title":"5.3 Gerenciamento de M\u00faltiplos Dispositivos","text":"<p>Aprenda a controlar m\u00faltiplos dispositivos simultaneamente, permitindo uma automa\u00e7\u00e3o residencial mais abrangente e integrada.</p>"},{"location":"aulas/iot/modulos/modulo14.html#6-exemplos-praticos","title":"6. Exemplos Pr\u00e1ticos","text":""},{"location":"aulas/iot/modulos/modulo14.html#61-sistema-de-iluminacao-inteligente-com-controle-por-voz","title":"6.1 Sistema de Ilumina\u00e7\u00e3o Inteligente com Controle por Voz","text":"<p>Este exemplo demonstra como controlar m\u00faltiplos LEDs conectados ao Arduino utilizando comandos de voz via Amazon Alexa.</p> <pre><code>#include &lt;ESP8266WiFi.h&gt;\n#include &lt;ESP8266HTTPClient.h&gt;\n\n// Configura\u00e7\u00f5es de rede\nconst char* ssid = \"Seu_SSID\";\nconst char* password = \"Sua_Senha\";\n\n// Endere\u00e7o do Webhook do IFTTT para ligar as luzes\nconst char* serverOn = \"http://maker.ifttt.com/trigger/Luzes_ON/with/key/SUA_CHAVE_IFTTT\";\n// Endere\u00e7o do Webhook do IFTTT para desligar as luzes\nconst char* serverOff = \"http://maker.ifttt.com/trigger/Luzes_OFF/with/key/SUA_CHAVE_IFTTT\";\n\n// Pinos dos LEDs\nconst int led1 = D1;\nconst int led2 = D2;\n\nvoid setup() {\n    Serial.begin(115200);\n    pinMode(led1, OUTPUT);\n    pinMode(led2, OUTPUT);\n    digitalWrite(led1, LOW);\n    digitalWrite(led2, LOW);\n\n    // Conecta ao Wi-Fi\n    WiFi.begin(ssid, password);\n    Serial.print(\"Conectando ao Wi-Fi\");\n    while (WiFi.status() != WL_CONNECTED) {\n        delay(500);\n        Serial.print(\".\");\n    }\n    Serial.println(\" Conectado!\");\n}\n\nvoid ligarLuzes() {\n    HTTPClient http;\n    http.begin(serverOn);\n    int httpResponseCode = http.GET();\n\n    if (httpResponseCode == 200) {\n        digitalWrite(led1, HIGH);\n        digitalWrite(led2, HIGH);\n        Serial.println(\"Luzes Ligadas.\");\n    } else {\n        Serial.println(\"Falha ao ligar as luzes.\");\n    }\n    http.end();\n}\n\nvoid desligarLuzes() {\n    HTTPClient http;\n    http.begin(serverOff);\n    int httpResponseCode = http.GET();\n\n    if (httpResponseCode == 200) {\n        digitalWrite(led1, LOW);\n        digitalWrite(led2, LOW);\n        Serial.println(\"Luzes Desligadas.\");\n    } else {\n        Serial.println(\"Falha ao desligar as luzes.\");\n    }\n    http.end();\n}\n\nvoid loop() {\n    // Nenhuma a\u00e7\u00e3o no loop principal\n    delay(1000);\n}\n</code></pre> <p>Explica\u00e7\u00e3o:</p> <ul> <li>M\u00faltiplos LEDs: Controla dois LEDs simultaneamente.</li> <li>Webhooks Diferenciados: Utiliza Webhooks distintos para ligar e desligar as luzes.</li> <li>Automa\u00e7\u00e3o Residencial: Permite controlar a ilumina\u00e7\u00e3o da casa por meio de comandos de voz.</li> </ul>"},{"location":"aulas/iot/modulos/modulo14.html#62-controle-de-sistema-de-irrigacao-com-voz-e-sensor-de-umidade","title":"6.2 Controle de Sistema de Irriga\u00e7\u00e3o com Voz e Sensor de Umidade","text":"<p>Este exemplo integra controle por voz com sensores de umidade do solo para automatizar a irriga\u00e7\u00e3o de plantas.</p> <pre><code>#include &lt;ESP8266WiFi.h&gt;\n#include &lt;ESP8266HTTPClient.h&gt;\n#include \"DHT.h\"\n\n// Configura\u00e7\u00f5es de rede\nconst char* ssid = \"Seu_SSID\";\nconst char* password = \"Sua_Senha\";\n\n// Endere\u00e7o do Webhook do IFTTT para ligar a irriga\u00e7\u00e3o\nconst char* serverOn = \"http://maker.ifttt.com/trigger/Irrigacao_ON/with/key/SUA_CHAVE_IFTTT\";\n// Endere\u00e7o do Webhook do IFTTT para desligar a irriga\u00e7\u00e3o\nconst char* serverOff = \"http://maker.ifttt.com/trigger/Irrigacao_OFF/with/key/SUA_CHAVE_IFTTT\";\n\n// Configura\u00e7\u00f5es do DHT\n#define DHTPIN 2\n#define DHTTYPE DHT22\nDHT dht(DHTPIN, DHTTYPE);\n\n// Pino do rel\u00e9 da bomba\nconst int pinoRele = D1;\n\n// Limiar de umidade\nconst float limiarUmidade = 30.0;\n\nvoid setup() {\n    Serial.begin(115200);\n    pinMode(pinoRele, OUTPUT);\n    digitalWrite(pinoRele, LOW);\n    dht.begin();\n\n    // Conecta ao Wi-Fi\n    WiFi.begin(ssid, password);\n    Serial.print(\"Conectando ao Wi-Fi\");\n    while (WiFi.status() != WL_CONNECTED) {\n        delay(500);\n        Serial.print(\".\");\n    }\n    Serial.println(\" Conectado!\");\n}\n\nvoid ligarIrrigacao() {\n    HTTPClient http;\n    http.begin(serverOn);\n    int httpResponseCode = http.GET();\n\n    if (httpResponseCode == 200) {\n        digitalWrite(pinoRele, HIGH);\n        Serial.println(\"Irriga\u00e7\u00e3o Ligada.\");\n    } else {\n        Serial.println(\"Falha ao ligar a irriga\u00e7\u00e3o.\");\n    }\n    http.end();\n}\n\nvoid desligarIrrigacao() {\n    HTTPClient http;\n    http.begin(serverOff);\n    int httpResponseCode = http.GET();\n\n    if (httpResponseCode == 200) {\n        digitalWrite(pinoRele, LOW);\n        Serial.println(\"Irriga\u00e7\u00e3o Desligada.\");\n    } else {\n        Serial.println(\"Falha ao desligar a irriga\u00e7\u00e3o.\");\n    }\n    http.end();\n}\n\nvoid loop() {\n    float umidade = dht.readHumidity();\n\n    if (isnan(umidade)) {\n        Serial.println(\"Falha na leitura do sensor DHT!\");\n        return;\n    }\n\n    Serial.print(\"Umidade do Solo: \");\n    Serial.println(umidade);\n\n    if (umidade &lt; limiarUmidade) {\n        ligarIrrigacao();\n    } else {\n        desligarIrrigacao();\n    }\n\n    delay(10000); // Aguarda 10 segundos antes da pr\u00f3xima leitura\n}\n</code></pre> <p>Explica\u00e7\u00e3o:</p> <ul> <li>Sensor de Umidade: Monitora a umidade do solo.</li> <li>Controle Autom\u00e1tico: Liga a bomba de irriga\u00e7\u00e3o quando a umidade est\u00e1 abaixo do limiar e desliga quando est\u00e1 acima.</li> <li>Comando por Voz: Permite ativar ou desativar a irriga\u00e7\u00e3o manualmente via comandos de voz.</li> </ul>"},{"location":"aulas/iot/modulos/modulo14.html#63-sistema-de-seguranca-com-deteccao-de-movimento-e-controle-por-voz","title":"6.3 Sistema de Seguran\u00e7a com Detec\u00e7\u00e3o de Movimento e Controle por Voz","text":"<p>Este exemplo combina detec\u00e7\u00e3o de movimento com controle por voz para criar um sistema de seguran\u00e7a inteligente.</p> <pre><code>#include &lt;ESP8266WiFi.h&gt;\n#include &lt;ESP8266HTTPClient.h&gt;\n\n// Configura\u00e7\u00f5es de rede\nconst char* ssid = \"Seu_SSID\";\nconst char* password = \"Sua_Senha\";\n\n// Endere\u00e7o do Webhook do IFTTT para acionar o alarme\nconst char* serverAlarm = \"http://maker.ifttt.com/trigger/Alarme_ON/with/key/SUA_CHAVE_IFTTT\";\n\n// Pino do sensor PIR\nconst int pinoPIR = D2;\n// Pino do LED de Alarme\nconst int pinoLED = D1;\n\nvoid setup() {\n    Serial.begin(115200);\n    pinMode(pinoPIR, INPUT);\n    pinMode(pinoLED, OUTPUT);\n    digitalWrite(pinoLED, LOW);\n\n    // Conecta ao Wi-Fi\n    WiFi.begin(ssid, password);\n    Serial.print(\"Conectando ao Wi-Fi\");\n    while (WiFi.status() != WL_CONNECTED) {\n        delay(500);\n        Serial.print(\".\");\n    }\n    Serial.println(\" Conectado!\");\n}\n\nvoid acionarAlarme() {\n    HTTPClient http;\n    http.begin(serverAlarm);\n    int httpResponseCode = http.GET();\n\n    if (httpResponseCode == 200) {\n        digitalWrite(pinoLED, HIGH);\n        Serial.println(\"Alarme Acionado!\");\n    } else {\n        Serial.println(\"Falha ao acionar o alarme.\");\n    }\n    http.end();\n}\n\nvoid loop() {\n    int estadoPIR = digitalRead(pinoPIR);\n    if (estadoPIR == HIGH) {\n        acionarAlarme();\n        delay(10000); // Evita m\u00faltiplas acionamentos\n    } else {\n        digitalWrite(pinoLED, LOW);\n    }\n    delay(100);\n}\n</code></pre> <p>Explica\u00e7\u00e3o:</p> <ul> <li>Sensor PIR: Detecta movimento na \u00e1rea monitorada.</li> <li>Acionamento do Alarme: Liga um LED como sinal de alarme quando movimento \u00e9 detectado e envia uma notifica\u00e7\u00e3o via IFTTT.</li> <li>Controle por Voz: Permite desativar o alarme manualmente atrav\u00e9s de comandos de voz.</li> </ul>"},{"location":"aulas/iot/modulos/modulo14.html#7-exercicios-praticos","title":"7. Exerc\u00edcios Pr\u00e1ticos","text":""},{"location":"aulas/iot/modulos/modulo14.html#exercicio-1-controle-de-dispositivos-multiplos-por-voz","title":"Exerc\u00edcio 1: Controle de Dispositivos M\u00faltiplos por Voz","text":"<ul> <li> <p>Tarefa: Crie um projeto onde voc\u00ea pode controlar m\u00faltiplos dispositivos (como LEDs, ventiladores e motores) usando comandos de voz via Amazon Alexa ou Google Assistant.</p> </li> <li> <p>Dicas:</p> </li> <li>Utilize m\u00faltiplos Webhooks no IFTTT para diferentes comandos.</li> <li> <p>Organize o c\u00f3digo para gerenciar diferentes dispositivos com efici\u00eancia.</p> </li> <li> <p>Exemplo de C\u00f3digo:</p> </li> </ul> <pre><code>#include &lt;ESP8266WiFi.h&gt;\n#include &lt;ESP8266HTTPClient.h&gt;\n\n// Configura\u00e7\u00f5es de rede\nconst char* ssid = \"Seu_SSID\";\nconst char* password = \"Sua_Senha\";\n\n// Endere\u00e7os dos Webhooks do IFTTT\nconst char* serverLEDOn = \"http://maker.ifttt.com/trigger/LED_ON/with/key/SUA_CHAVE_IFTTT\";\nconst char* serverLEDOff = \"http://maker.ifttt.com/trigger/LED_OFF/with/key/SUA_CHAVE_IFTTT\";\nconst char* serverFanOn = \"http://maker.ifttt.com/trigger/FAN_ON/with/key/SUA_CHAVE_IFTTT\";\nconst char* serverFanOff = \"http://maker.ifttt.com/trigger/FAN_OFF/with/key/SUA_CHAVE_IFTTT\";\n\n// Pinos dos dispositivos\nconst int pinoLED = D1;\nconst int pinoFan = D2;\n\nvoid setup() {\n    Serial.begin(115200);\n    pinMode(pinoLED, OUTPUT);\n    pinMode(pinoFan, OUTPUT);\n    digitalWrite(pinoLED, LOW);\n    digitalWrite(pinoFan, LOW);\n\n    // Conecta ao Wi-Fi\n    WiFi.begin(ssid, password);\n    Serial.print(\"Conectando ao Wi-Fi\");\n    while (WiFi.status() != WL_CONNECTED) {\n        delay(500);\n        Serial.print(\".\");\n    }\n    Serial.println(\" Conectado!\");\n}\n\nvoid ligarLED() {\n    HTTPClient http;\n    http.begin(serverLEDOn);\n    int httpResponseCode = http.GET();\n\n    if (httpResponseCode == 200) {\n        digitalWrite(pinoLED, HIGH);\n        Serial.println(\"LED Ligado.\");\n    } else {\n        Serial.println(\"Falha ao ligar o LED.\");\n    }\n    http.end();\n}\n\nvoid desligarLED() {\n    HTTPClient http;\n    http.begin(serverLEDOff);\n    int httpResponseCode = http.GET();\n\n    if (httpResponseCode == 200) {\n        digitalWrite(pinoLED, LOW);\n        Serial.println(\"LED Desligado.\");\n    } else {\n        Serial.println(\"Falha ao desligar o LED.\");\n    }\n    http.end();\n}\n\nvoid ligarFan() {\n    HTTPClient http;\n    http.begin(serverFanOn);\n    int httpResponseCode = http.GET();\n\n    if (httpResponseCode == 200) {\n        digitalWrite(pinoFan, HIGH);\n        Serial.println(\"Ventilador Ligado.\");\n    } else {\n        Serial.println(\"Falha ao ligar o ventilador.\");\n    }\n    http.end();\n}\n\nvoid desligarFan() {\n    HTTPClient http;\n    http.begin(serverFanOff);\n    int httpResponseCode = http.GET();\n\n    if (httpResponseCode == 200) {\n        digitalWrite(pinoFan, LOW);\n        Serial.println(\"Ventilador Desligado.\");\n    } else {\n        Serial.println(\"Falha ao desligar o ventilador.\");\n    }\n    http.end();\n}\n\nvoid loop() {\n    // Nenhuma a\u00e7\u00e3o no loop principal\n    delay(1000);\n}\n</code></pre>"},{"location":"aulas/iot/modulos/modulo14.html#exercicio-2-sistema-de-alerta-de-seguranca-com-comandos-de-voz","title":"Exerc\u00edcio 2: Sistema de Alerta de Seguran\u00e7a com Comandos de Voz","text":"<ul> <li> <p>Tarefa: Desenvolva um sistema que envia alertas de seguran\u00e7a via assistente virtual quando sensores de movimento ou de g\u00e1s detectam atividades suspeitas, al\u00e9m de permitir o controle manual via comandos de voz.</p> </li> <li> <p>Dicas:</p> </li> <li>Integre m\u00faltiplos sensores (PIR e sensor de g\u00e1s).</li> <li>Utilize Webhooks diferentes para cada tipo de alerta.</li> <li> <p>Adicione feedback visual (LEDs) e auditivo (buzzer) para alertas.</p> </li> <li> <p>Exemplo de C\u00f3digo:</p> </li> </ul> <pre><code>#include &lt;ESP8266WiFi.h&gt;\n#include &lt;ESP8266HTTPClient.h&gt;\n\n// Configura\u00e7\u00f5es de rede\nconst char* ssid = \"Seu_SSID\";\nconst char* password = \"Sua_Senha\";\n\n// Endere\u00e7os dos Webhooks do IFTTT\nconst char* serverAlarmeMovimento = \"http://maker.ifttt.com/trigger/Alarme_Movimento/with/key/SUA_CHAVE_IFTTT\";\nconst char* serverAlarmeGas = \"http://maker.ifttt.com/trigger/Alarme_Gas/with/key/SUA_CHAVE_IFTTT\";\n\n// Pinos dos sensores e atuadores\nconst int pinoPIR = D1;\nconst int pinoGas = A0;\nconst int pinoLED = D2;\nconst int pinoBuzzer = D3;\n\n// Limiar de g\u00e1s\nconst int limiarGas = 300;\n\nvoid setup() {\n    Serial.begin(115200);\n    pinMode(pinoPIR, INPUT);\n    pinMode(pinoGas, INPUT);\n    pinMode(pinoLED, OUTPUT);\n    pinMode(pinoBuzzer, OUTPUT);\n    digitalWrite(pinoLED, LOW);\n    digitalWrite(pinoBuzzer, LOW);\n\n    // Conecta ao Wi-Fi\n    WiFi.begin(ssid, password);\n    Serial.print(\"Conectando ao Wi-Fi\");\n    while (WiFi.status() != WL_CONNECTED) {\n        delay(500);\n        Serial.print(\".\");\n    }\n    Serial.println(\" Conectado!\");\n}\n\nvoid acionarAlarmeMovimento() {\n    HTTPClient http;\n    http.begin(serverAlarmeMovimento);\n    int httpResponseCode = http.GET();\n\n    if (httpResponseCode == 200) {\n        digitalWrite(pinoLED, HIGH);\n        digitalWrite(pinoBuzzer, HIGH);\n        Serial.println(\"Alarme de Movimento Acionado!\");\n    } else {\n        Serial.println(\"Falha ao acionar o alarme de movimento.\");\n    }\n    http.end();\n}\n\nvoid acionarAlarmeGas() {\n    HTTPClient http;\n    http.begin(serverAlarmeGas);\n    int httpResponseCode = http.GET();\n\n    if (httpResponseCode == 200) {\n        digitalWrite(pinoLED, HIGH);\n        digitalWrite(pinoBuzzer, HIGH);\n        Serial.println(\"Alarme de G\u00e1s Acionado!\");\n    } else {\n        Serial.println(\"Falha ao acionar o alarme de g\u00e1s.\");\n    }\n    http.end();\n}\n\nvoid loop() {\n    // Verifica movimento\n    int estadoPIR = digitalRead(pinoPIR);\n    if (estadoPIR == HIGH) {\n        acionarAlarmeMovimento();\n        delay(10000); // Evita m\u00faltiplos acionamentos\n    } else {\n        digitalWrite(pinoLED, LOW);\n        digitalWrite(pinoBuzzer, LOW);\n    }\n\n    // Verifica g\u00e1s\n    int valorGas = analogRead(pinoGas);\n    if (valorGas &gt; limiarGas) {\n        acionarAlarmeGas();\n        delay(10000); // Evita m\u00faltiplos acionamentos\n    } else {\n        digitalWrite(pinoLED, LOW);\n        digitalWrite(pinoBuzzer, LOW);\n    }\n\n    delay(100);\n}\n</code></pre> <p>Explica\u00e7\u00e3o:</p> <ul> <li>M\u00faltiplos Sensores: Monitora movimento e n\u00edveis de g\u00e1s simultaneamente.</li> <li>Alertas Diferenciados: Aciona alarmes distintos para cada tipo de detec\u00e7\u00e3o.</li> <li>Feedback Visual e Auditivo: Utiliza LEDs e buzzers para indicar alertas.</li> </ul>"},{"location":"aulas/iot/modulos/modulo14.html#exercicio-3-automacao-de-ambientes-com-controle-por-voz-e-sensores","title":"Exerc\u00edcio 3: Automa\u00e7\u00e3o de Ambientes com Controle por Voz e Sensores","text":"<ul> <li> <p>Tarefa: Desenvolva um sistema de automa\u00e7\u00e3o que ajusta a ilumina\u00e7\u00e3o e a temperatura de um ambiente com base em comandos de voz e leituras de sensores de luminosidade e temperatura.</p> </li> <li> <p>Dicas:</p> </li> <li>Integre sensores de luz (LDR) e temperatura (DHT22).</li> <li>Utilize comandos de voz para ajustar configura\u00e7\u00f5es manualmente.</li> <li> <p>Automatize ajustes com base nas leituras dos sensores.</p> </li> <li> <p>Exemplo de C\u00f3digo:</p> </li> </ul> <pre><code>#include &lt;ESP8266WiFi.h&gt;\n#include &lt;ESP8266HTTPClient.h&gt;\n#include \"DHT.h\"\n\n// Configura\u00e7\u00f5es de rede\nconst char* ssid = \"Seu_SSID\";\nconst char* password = \"Sua_Senha\";\n\n// Endere\u00e7os dos Webhooks do IFTTT\nconst char* serverLuzOn = \"http://maker.ifttt.com/trigger/Luz_ON/with/key/SUA_CHAVE_IFTTT\";\nconst char* serverLuzOff = \"http://maker.ifttt.com/trigger/Luz_OFF/with/key/SUA_CHAVE_IFTTT\";\nconst char* serverTemperatura = \"http://maker.ifttt.com/trigger/Temperatura_Ajustada/with/key/SUA_CHAVE_IFTTT\";\n\n// Configura\u00e7\u00f5es do DHT\n#define DHTPIN 2\n#define DHTTYPE DHT22\nDHT dht(DHTPIN, DHTTYPE);\n\n// Pinos dos atuadores\nconst int pinoLuz = D1;\nconst int pinoVentilador = D2;\n\nvoid setup() {\n    Serial.begin(115200);\n    pinMode(pinoLuz, OUTPUT);\n    pinMode(pinoVentilador, OUTPUT);\n    digitalWrite(pinoLuz, LOW);\n    digitalWrite(pinoVentilador, LOW);\n    dht.begin();\n\n    // Conecta ao Wi-Fi\n    WiFi.begin(ssid, password);\n    Serial.print(\"Conectando ao Wi-Fi\");\n    while (WiFi.status() != WL_CONNECTED) {\n        delay(500);\n        Serial.print(\".\");\n    }\n    Serial.println(\" Conectado!\");\n}\n\nvoid ligarLuz() {\n    HTTPClient http;\n    http.begin(serverLuzOn);\n    int httpResponseCode = http.GET();\n\n    if (httpResponseCode == 200) {\n        digitalWrite(pinoLuz, HIGH);\n        Serial.println(\"Luz Ligada.\");\n    } else {\n        Serial.println(\"Falha ao ligar a luz.\");\n    }\n    http.end();\n}\n\nvoid desligarLuz() {\n    HTTPClient http;\n    http.begin(serverLuzOff);\n    int httpResponseCode = http.GET();\n\n    if (httpResponseCode == 200) {\n        digitalWrite(pinoLuz, LOW);\n        Serial.println(\"Luz Desligada.\");\n    } else {\n        Serial.println(\"Falha ao desligar a luz.\");\n    }\n    http.end();\n}\n\nvoid ajustarTemperatura(float temperatura) {\n    HTTPClient http;\n    String url = String(serverTemperatura) + \"?value=\" + String(temperatura);\n    http.begin(url.c_str());\n    int httpResponseCode = http.GET();\n\n    if (httpResponseCode == 200) {\n        if (temperatura &gt; 25.0) {\n            digitalWrite(pinoVentilador, HIGH);\n            Serial.println(\"Ventilador Ligado.\");\n        } else {\n            digitalWrite(pinoVentilador, LOW);\n            Serial.println(\"Ventilador Desligado.\");\n        }\n    } else {\n        Serial.println(\"Falha ao ajustar a temperatura.\");\n    }\n    http.end();\n}\n\nvoid loop() {\n    // Leitura dos sensores\n    float temperatura = dht.readTemperature();\n    int valorLDR = analogRead(A0);\n\n    if (isnan(temperatura)) {\n        Serial.println(\"Falha na leitura do sensor DHT!\");\n        return;\n    }\n\n    Serial.print(\"Temperatura: \");\n    Serial.print(temperatura);\n    Serial.print(\" *C\\tLuz: \");\n    Serial.println(valorLDR);\n\n    // Automatiza\u00e7\u00e3o com base nos sensores\n    if (valorLDR &lt; 300) { // Ambiente escuro\n        ligarLuz();\n    } else {\n        desligarLuz();\n    }\n\n    if (temperatura &gt; 25.0) {\n        ajustarTemperatura(temperatura);\n    } else {\n        ajustarTemperatura(temperatura);\n    }\n\n    delay(5000); // Aguarda 5 segundos antes da pr\u00f3xima leitura\n}\n</code></pre> <p>Explica\u00e7\u00e3o:</p> <ul> <li>Sensores Integrados: Utiliza sensores de luminosidade e temperatura para automatizar dispositivos.</li> <li>Controle por Voz e Autom\u00e1tico: Permite tanto comandos de voz quanto ajustes autom\u00e1ticos com base nas leituras dos sensores.</li> <li>Feedback via Serial: Monitora as a\u00e7\u00f5es no Monitor Serial para depura\u00e7\u00e3o e verifica\u00e7\u00e3o.</li> </ul>"},{"location":"aulas/iot/modulos/modulo14.html#8-conceitos-importantes","title":"8. Conceitos Importantes","text":""},{"location":"aulas/iot/modulos/modulo14.html#81-seguranca-na-integracao-com-assistentes-virtuais","title":"8.1 Seguran\u00e7a na Integra\u00e7\u00e3o com Assistentes Virtuais","text":"<ul> <li>Autentica\u00e7\u00e3o: Utilize chaves API seguras e mantenha-as confidenciais.</li> <li>Criptografia: Assegure que as comunica\u00e7\u00f5es entre o Arduino e os servi\u00e7os de nuvem sejam criptografadas.</li> <li>Permiss\u00f5es Restritas: Garanta que apenas os comandos necess\u00e1rios sejam permitidos para evitar abusos.</li> </ul>"},{"location":"aulas/iot/modulos/modulo14.html#82-latencia-e-tempo-de-resposta","title":"8.2 Lat\u00eancia e Tempo de Resposta","text":"<ul> <li>Import\u00e2ncia: A lat\u00eancia pode afetar a experi\u00eancia do usu\u00e1rio ao controlar dispositivos por voz.</li> <li>Redu\u00e7\u00e3o de Lat\u00eancia: Utilize conex\u00f5es Wi-Fi est\u00e1veis e otimize o c\u00f3digo para respostas r\u00e1pidas.</li> </ul>"},{"location":"aulas/iot/modulos/modulo14.html#83-gerenciamento-de-estados","title":"8.3 Gerenciamento de Estados","text":"<ul> <li>Estados dos Dispositivos: Mantenha o controle dos estados atuais dos dispositivos para evitar comandos redundantes.</li> <li>Sincroniza\u00e7\u00e3o: Assegure que os estados dos dispositivos estejam sincronizados entre o Arduino e a interface do usu\u00e1rio.</li> </ul>"},{"location":"aulas/iot/modulos/modulo14.html#84-escalabilidade","title":"8.4 Escalabilidade","text":"<ul> <li>M\u00faltiplos Dispositivos: Planeje sistemas que possam expandir para controlar m\u00faltiplos dispositivos sem complica\u00e7\u00f5es.</li> <li>Organiza\u00e7\u00e3o do C\u00f3digo: Utilize estruturas de c\u00f3digo modulares para facilitar a manuten\u00e7\u00e3o e expans\u00e3o.</li> </ul>"},{"location":"aulas/iot/modulos/modulo14.html#85-boas-praticas-na-integracao-com-assistentes-virtuais","title":"8.5 Boas Pr\u00e1ticas na Integra\u00e7\u00e3o com Assistentes Virtuais","text":"<ul> <li>Testes Rigorosos: Teste exaustivamente os comandos de voz para garantir que respondam conforme esperado.</li> <li>Feedback ao Usu\u00e1rio: Forne\u00e7a feedback visual ou auditivo para confirmar a execu\u00e7\u00e3o dos comandos.</li> <li>Documenta\u00e7\u00e3o: Mantenha uma documenta\u00e7\u00e3o clara dos comandos dispon\u00edveis e das funcionalidades implementadas.</li> </ul>"},{"location":"aulas/iot/modulos/modulo14.html#9-recursos-adicionais","title":"9. Recursos Adicionais","text":"<ul> <li> <p>Documenta\u00e7\u00e3o Oficial do Arduino:</p> </li> <li> <p>ESP8266WiFi Library</p> </li> <li>PubSubClient Library</li> <li>ArduinoJson Library</li> <li> <p>IFTTT Webhooks</p> </li> <li> <p>Tutoriais e Guias:</p> </li> <li> <p>Integra\u00e7\u00e3o do Arduino com Amazon Alexa</p> </li> <li>Utilizando IFTTT com Arduino</li> <li> <p>Controle por Voz com Google Assistant e Arduino</p> </li> <li> <p>V\u00eddeos Educacionais:</p> </li> <li> <p>Controlando o Arduino com Alexa</p> </li> <li>Integra\u00e7\u00e3o Arduino e Google Assistant</li> <li>Uso de IFTTT com Arduino</li> </ul>"},{"location":"aulas/iot/modulos/modulo14.html#10-exemplos-praticos","title":"10. Exemplos Pr\u00e1ticos","text":""},{"location":"aulas/iot/modulos/modulo14.html#101-sistema-de-controle-de-iluminacao-com-alexa","title":"10.1 Sistema de Controle de Ilumina\u00e7\u00e3o com Alexa","text":"<pre><code>#include &lt;ESP8266WiFi.h&gt;\n#include &lt;ESP8266HTTPClient.h&gt;\n\n// Configura\u00e7\u00f5es de rede\nconst char* ssid = \"Seu_SSID\";\nconst char* password = \"Sua_Senha\";\n\n// Endere\u00e7o do Webhook do IFTTT para ligar a luz\nconst char* serverOn = \"http://maker.ifttt.com/trigger/Luz_ON/with/key/SUA_CHAVE_IFTTT\";\n// Endere\u00e7o do Webhook do IFTTT para desligar a luz\nconst char* serverOff = \"http://maker.ifttt.com/trigger/Luz_OFF/with/key/SUA_CHAVE_IFTTT\";\n\n// Pino do LED\nconst int pinoLED = D1;\n\nvoid setup() {\n    Serial.begin(115200);\n    pinMode(pinoLED, OUTPUT);\n    digitalWrite(pinoLED, LOW);\n\n    // Conecta ao Wi-Fi\n    WiFi.begin(ssid, password);\n    Serial.print(\"Conectando ao Wi-Fi\");\n    while (WiFi.status() != WL_CONNECTED) {\n        delay(500);\n        Serial.print(\".\");\n    }\n    Serial.println(\" Conectado!\");\n}\n\nvoid ligarLuz() {\n    HTTPClient http;\n    http.begin(serverOn);\n    int httpResponseCode = http.GET();\n\n    if (httpResponseCode == 200) {\n        digitalWrite(pinoLED, HIGH);\n        Serial.println(\"Luz Ligada.\");\n    } else {\n        Serial.println(\"Falha ao ligar a luz.\");\n    }\n    http.end();\n}\n\nvoid desligarLuz() {\n    HTTPClient http;\n    http.begin(serverOff);\n    int httpResponseCode = http.GET();\n\n    if (httpResponseCode == 200) {\n        digitalWrite(pinoLED, LOW);\n        Serial.println(\"Luz Desligada.\");\n    } else {\n        Serial.println(\"Falha ao desligar a luz.\");\n    }\n    http.end();\n}\n\nvoid loop() {\n    // Nenhuma a\u00e7\u00e3o no loop principal\n    delay(1000);\n}\n</code></pre> <p>Explica\u00e7\u00e3o:</p> <ul> <li>Controle Simples: Permite ligar e desligar um LED conectado ao Arduino usando comandos de voz via Alexa.</li> <li>Webhooks IFTTT: Utiliza Webhooks diferentes para cada a\u00e7\u00e3o (ligar/desligar).</li> </ul>"},{"location":"aulas/iot/modulos/modulo14.html#102-sistema-de-monitoramento-com-alertas-por-voz","title":"10.2 Sistema de Monitoramento com Alertas por Voz","text":"<pre><code>#include &lt;ESP8266WiFi.h&gt;\n#include &lt;ESP8266HTTPClient.h&gt;\n#include \"DHT.h\"\n\n// Configura\u00e7\u00f5es de rede\nconst char* ssid = \"Seu_SSID\";\nconst char* password = \"Sua_Senha\";\n\n// Endere\u00e7o do Webhook do IFTTT para enviar alertas\nconst char* serverAlerta = \"http://maker.ifttt.com/trigger/Alerta_Temp/with/key/SUA_CHAVE_IFTTT\";\n\n// Configura\u00e7\u00f5es do DHT\n#define DHTPIN 2\n#define DHTTYPE DHT22\nDHT dht(DHTPIN, DHTTYPE);\n\n// Pino do LED de Alerta\nconst int pinoLED = D1;\n\nvoid setup() {\n    Serial.begin(115200);\n    pinMode(pinoLED, OUTPUT);\n    digitalWrite(pinoLED, LOW);\n    dht.begin();\n\n    // Conecta ao Wi-Fi\n    WiFi.begin(ssid, password);\n    Serial.print(\"Conectando ao Wi-Fi\");\n    while (WiFi.status() != WL_CONNECTED) {\n        delay(500);\n        Serial.print(\".\");\n    }\n    Serial.println(\" Conectado!\");\n}\n\nvoid enviarAlerta(float temperatura) {\n    HTTPClient http;\n    String url = String(serverAlerta) + \"?value=\" + String(temperatura);\n    http.begin(url.c_str());\n    int httpResponseCode = http.GET();\n\n    if (httpResponseCode == 200) {\n        digitalWrite(pinoLED, HIGH);\n        Serial.println(\"Alerta de Temperatura Enviado!\");\n        delay(5000);\n        digitalWrite(pinoLED, LOW);\n    } else {\n        Serial.println(\"Falha ao enviar o alerta.\");\n    }\n    http.end();\n}\n\nvoid loop() {\n    float temperatura = dht.readTemperature();\n\n    if (isnan(temperatura)) {\n        Serial.println(\"Falha na leitura do sensor DHT!\");\n        return;\n    }\n\n    Serial.print(\"Temperatura: \");\n    Serial.print(temperatura);\n    Serial.println(\" *C\");\n\n    if (temperatura &gt; 30.0) { // Limiar de temperatura\n        enviarAlerta(temperatura);\n    }\n\n    delay(10000); // Aguarda 10 segundos antes da pr\u00f3xima leitura\n}\n</code></pre> <p>Explica\u00e7\u00e3o:</p> <ul> <li>Monitoramento Cont\u00ednuo: L\u00ea a temperatura do ambiente em intervalos regulares.</li> <li>Envio de Alertas: Envia um alerta via IFTTT e aciona um LED quando a temperatura excede o limiar definido.</li> <li>Feedback Visual: Indica o envio do alerta atrav\u00e9s do LED.</li> </ul>"},{"location":"aulas/iot/modulos/modulo14.html#103-controle-de-ventilador-com-voz-e-sensor-de-temperatura","title":"10.3 Controle de Ventilador com Voz e Sensor de Temperatura","text":"<pre><code>#include &lt;ESP8266WiFi.h&gt;\n#include &lt;ESP8266HTTPClient.h&gt;\n#include \"DHT.h\"\n\n// Configura\u00e7\u00f5es de rede\nconst char* ssid = \"Seu_SSID\";\nconst char* password = \"Sua_Senha\";\n\n// Endere\u00e7o do Webhook do IFTTT para ligar o ventilador\nconst char* serverVentiladorOn = \"http://maker.ifttt.com/trigger/Ventilador_ON/with/key/SUA_CHAVE_IFTTT\";\n// Endere\u00e7o do Webhook do IFTTT para desligar o ventilador\nconst char* serverVentiladorOff = \"http://maker.ifttt.com/trigger/Ventilador_OFF/with/key/SUA_CHAVE_IFTTT\";\n\n// Configura\u00e7\u00f5es do DHT\n#define DHTPIN 2\n#define DHTTYPE DHT22\nDHT dht(DHTPIN, DHTTYPE);\n\n// Pino do ventilador (controlado por rel\u00e9)\nconst int pinoVentilador = D1;\n\nvoid setup() {\n    Serial.begin(115200);\n    pinMode(pinoVentilador, OUTPUT);\n    digitalWrite(pinoVentilador, LOW);\n    dht.begin();\n\n    // Conecta ao Wi-Fi\n    WiFi.begin(ssid, password);\n    Serial.print(\"Conectando ao Wi-Fi\");\n    while (WiFi.status() != WL_CONNECTED) {\n        delay(500);\n        Serial.print(\".\");\n    }\n    Serial.println(\" Conectado!\");\n}\n\nvoid ligarVentilador() {\n    HTTPClient http;\n    http.begin(serverVentiladorOn);\n    int httpResponseCode = http.GET();\n\n    if (httpResponseCode == 200) {\n        digitalWrite(pinoVentilador, HIGH);\n        Serial.println(\"Ventilador Ligado.\");\n    } else {\n        Serial.println(\"Falha ao ligar o ventilador.\");\n    }\n    http.end();\n}\n\nvoid desligarVentilador() {\n    HTTPClient http;\n    http.begin(serverVentiladorOff);\n    int httpResponseCode = http.GET();\n\n    if (httpResponseCode == 200) {\n        digitalWrite(pinoVentilador, LOW);\n        Serial.println(\"Ventilador Desligado.\");\n    } else {\n        Serial.println(\"Falha ao desligar o ventilador.\");\n    }\n    http.end();\n}\n\nvoid loop() {\n    float temperatura = dht.readTemperature();\n\n    if (isnan(temperatura)) {\n        Serial.println(\"Falha na leitura do sensor DHT!\");\n        return;\n    }\n\n    Serial.print(\"Temperatura: \");\n    Serial.print(temperatura);\n    Serial.println(\" *C\");\n\n    // Controle autom\u00e1tico com base na temperatura\n    if (temperatura &gt; 28.0) { // Limiar para ligar o ventilador\n        ligarVentilador();\n    } else if (temperatura &lt; 25.0) { // Limiar para desligar o ventilador\n        desligarVentilador();\n    }\n\n    delay(10000); // Aguarda 10 segundos antes da pr\u00f3xima leitura\n}\n</code></pre> <p>Explica\u00e7\u00e3o:</p> <ul> <li>Controle Autom\u00e1tico e Manual: Liga o ventilador automaticamente com base na temperatura e permite controle manual via comandos de voz.</li> <li>Rel\u00e9 para Ventilador: Utiliza um rel\u00e9 para controlar a alimenta\u00e7\u00e3o do ventilador de forma segura.</li> <li>Feedback via Serial: Monitora as a\u00e7\u00f5es no Monitor Serial para depura\u00e7\u00e3o e verifica\u00e7\u00e3o.</li> </ul>"},{"location":"aulas/iot/modulos/modulo14.html#9-conceitos-importantes","title":"9. Conceitos Importantes","text":""},{"location":"aulas/iot/modulos/modulo14.html#91-apis-de-assistentes-virtuais","title":"9.1 APIs de Assistentes Virtuais","text":"<ul> <li>Defini\u00e7\u00e3o: Interfaces que permitem a comunica\u00e7\u00e3o entre o Arduino e assistentes virtuais, facilitando o envio e recebimento de comandos.</li> <li>Uso: Permite a cria\u00e7\u00e3o de funcionalidades personalizadas e integra\u00e7\u00f5es avan\u00e7adas.</li> </ul>"},{"location":"aulas/iot/modulos/modulo14.html#92-webhooks-e-endpoints","title":"9.2 Webhooks e Endpoints","text":"<ul> <li>Webhooks: URLs que recebem requisi\u00e7\u00f5es HTTP para acionar a\u00e7\u00f5es espec\u00edficas.</li> <li>Endpoints: Pontos de acesso onde o Arduino pode enviar ou receber dados para interagir com servi\u00e7os externos.</li> </ul>"},{"location":"aulas/iot/modulos/modulo14.html#93-seguranca-na-comunicacao","title":"9.3 Seguran\u00e7a na Comunica\u00e7\u00e3o","text":"<ul> <li>Autentica\u00e7\u00e3o: Utilize chaves API e tokens para autenticar as requisi\u00e7\u00f5es.</li> <li>Criptografia: Sempre que poss\u00edvel, utilize HTTPS para proteger os dados transmitidos.</li> <li>Valida\u00e7\u00e3o de Dados: Verifique e valide os dados recebidos para evitar comandos maliciosos.</li> </ul>"},{"location":"aulas/iot/modulos/modulo14.html#94-latencia-e-resposta-em-tempo-real","title":"9.4 Lat\u00eancia e Resposta em Tempo Real","text":"<ul> <li>Import\u00e2ncia: Reduzir a lat\u00eancia \u00e9 crucial para uma experi\u00eancia de usu\u00e1rio fluida e responsiva.</li> <li>Otimiza\u00e7\u00e3o: Utilize conex\u00f5es de rede est\u00e1veis e minimize o processamento dentro das requisi\u00e7\u00f5es.</li> </ul>"},{"location":"aulas/iot/modulos/modulo14.html#95-boas-praticas-na-integracao-com-assistentes-virtuais","title":"9.5 Boas Pr\u00e1ticas na Integra\u00e7\u00e3o com Assistentes Virtuais","text":"<ul> <li>Modularidade: Mantenha o c\u00f3digo organizado e modular para facilitar manuten\u00e7\u00f5es e expans\u00f5es.</li> <li>Feedback ao Usu\u00e1rio: Forne\u00e7a feedback visual ou auditivo para confirmar a execu\u00e7\u00e3o dos comandos.</li> <li>Documenta\u00e7\u00e3o: Documente os comandos e funcionalidades implementadas para facilitar o uso e futuras modifica\u00e7\u00f5es.</li> </ul>"},{"location":"aulas/iot/modulos/modulo14.html#10-recursos-adicionais","title":"10. Recursos Adicionais","text":"<ul> <li> <p>Documenta\u00e7\u00e3o Oficial do Arduino:</p> </li> <li> <p>ESP8266WiFi Library</p> </li> <li>PubSubClient Library</li> <li>ArduinoJson Library</li> <li> <p>IFTTT Webhooks</p> </li> <li> <p>Tutoriais e Guias:</p> </li> <li> <p>Controlando o Arduino com Amazon Alexa</p> </li> <li>Integra\u00e7\u00e3o Arduino e Google Assistant</li> <li> <p>Uso de IFTTT com Arduino</p> </li> <li> <p>V\u00eddeos Educacionais:</p> </li> <li> <p>Controlando o Arduino com Alexa</p> </li> <li>Integra\u00e7\u00e3o Arduino e Google Assistant</li> <li>Uso de IFTTT com Arduino</li> </ul>"},{"location":"aulas/iot/modulos/modulo14.html#11-conclusao-do-modulo","title":"11. Conclus\u00e3o do M\u00f3dulo","text":"<p>Neste m\u00f3dulo, voc\u00ea aprendeu:</p> <ul> <li>Conceitos B\u00e1sicos e Avan\u00e7ados: Entendeu os fundamentos dos assistentes virtuais e como integr\u00e1-los com o Arduino.</li> <li>Configura\u00e7\u00e3o e Integra\u00e7\u00e3o: Aprendeu a configurar o Arduino para comunica\u00e7\u00e3o com plataformas como Amazon Alexa e Google Assistant atrav\u00e9s do IFTTT.</li> <li>Implementa\u00e7\u00e3o de Comandos de Voz: Implementou comandos de voz para controlar dispositivos conectados, como LEDs e motores.</li> <li>Projetos Pr\u00e1ticos: Desenvolveu projetos que respondem a comandos de voz e utilizam sensores para automa\u00e7\u00e3o inteligente.</li> <li>Seguran\u00e7a e Boas Pr\u00e1ticas: Compreendeu a import\u00e2ncia da seguran\u00e7a na comunica\u00e7\u00e3o e as melhores pr\u00e1ticas para integra\u00e7\u00e3o eficiente.</li> </ul> <p>Voc\u00ea completou todos os m\u00f3dulos do curso \"Programa\u00e7\u00e3o em Arduino: Conceitos Fundamentais sem Hardware\". Parab\u00e9ns pelo empenho e dedica\u00e7\u00e3o!</p>"},{"location":"aulas/iot/modulos/modulo14.html#12-proximos-passos","title":"12. Pr\u00f3ximos Passos","text":"<ul> <li>Revisar todo o conte\u00fado do curso para consolidar o aprendizado.</li> <li>Explorar projetos avan\u00e7ados que combinam m\u00faltiplos conceitos aprendidos, como rob\u00f3tica, automa\u00e7\u00e3o residencial ou sistemas de monitoramento ambiental.</li> <li>Participar de comunidades e f\u00f3runs de Arduino para trocar experi\u00eancias e obter suporte cont\u00ednuo.</li> <li>Considerar cursos avan\u00e7ados ou especializa\u00e7\u00f5es em \u00e1reas espec\u00edficas de interesse, como desenvolvimento de firmware, integra\u00e7\u00e3o com plataformas de IoT ou design de hardware.</li> <li>Desenvolver seu pr\u00f3prio portf\u00f3lio de projetos Arduino para demonstrar suas habilidades e conhecimentos adquiridos.</li> </ul> <p>Se tiver d\u00favidas ou precisar de assist\u00eancia, continue participando de comunidades de aprendizagem ou consulte os recursos adicionais fornecidos ao longo dos m\u00f3dulos.</p> <p>Parab\u00e9ns por concluir o curso! Continue explorando e criando projetos incr\u00edveis com Arduino!</p>"},{"location":"aulas/iot/modulos/modulo15.html","title":"M\u00f3dulo 15: Rob\u00f3tica com Arduino","text":"<p>Bem-vindo ao M\u00f3dulo 16 do curso \"Programa\u00e7\u00e3o em Arduino: Conceitos Fundamentais sem Hardware\". Neste m\u00f3dulo, voc\u00ea ir\u00e1 explorar o fascinante mundo da rob\u00f3tica utilizando o Arduino como c\u00e9rebro dos seus projetos. Voc\u00ea aprender\u00e1 a construir e programar rob\u00f4s que podem interagir com o ambiente, tomar decis\u00f5es aut\u00f4nomas e executar tarefas espec\u00edficas. Este m\u00f3dulo abrange desde os conceitos b\u00e1sicos de rob\u00f3tica at\u00e9 a implementa\u00e7\u00e3o de funcionalidades avan\u00e7adas, proporcionando uma compreens\u00e3o completa para criar rob\u00f4s funcionais e inteligentes.</p>"},{"location":"aulas/iot/modulos/modulo15.html#objetivos-do-modulo","title":"Objetivos do M\u00f3dulo","text":"<ul> <li>Compreender os fundamentos da rob\u00f3tica e os componentes essenciais de um rob\u00f4.</li> <li>Aprender a conectar e controlar motores e servos para movimenta\u00e7\u00e3o.</li> <li>Implementar sensores para permitir que o rob\u00f4 perceba o ambiente.</li> <li>Desenvolver algoritmos de controle para navega\u00e7\u00e3o e tomada de decis\u00f5es.</li> <li>Integrar comunica\u00e7\u00e3o sem fio para controle remoto e monitoramento.</li> <li>Resolver exerc\u00edcios pr\u00e1ticos para consolidar o conhecimento sobre rob\u00f3tica com Arduino.</li> </ul>"},{"location":"aulas/iot/modulos/modulo15.html#1-introducao-a-robotica-com-arduino","title":"1. Introdu\u00e7\u00e3o \u00e0 Rob\u00f3tica com Arduino","text":""},{"location":"aulas/iot/modulos/modulo15.html#11-o-que-e-robotica","title":"1.1 O que \u00e9 Rob\u00f3tica?","text":"<p>Rob\u00f3tica \u00e9 a \u00e1rea da tecnologia que envolve o design, constru\u00e7\u00e3o, opera\u00e7\u00e3o e uso de rob\u00f4s. Rob\u00f4s s\u00e3o m\u00e1quinas program\u00e1veis que podem executar uma s\u00e9rie de tarefas automaticamente ou sob controle humano. Com o Arduino, voc\u00ea pode construir rob\u00f4s personalizados que atendem a necessidades espec\u00edficas, desde simples ve\u00edculos movidos a controle remoto at\u00e9 rob\u00f4s aut\u00f4nomos complexos.</p>"},{"location":"aulas/iot/modulos/modulo15.html#12-importancia-da-robotica","title":"1.2 Import\u00e2ncia da Rob\u00f3tica","text":"<ul> <li>Automa\u00e7\u00e3o: Realiza tarefas repetitivas ou perigosas sem interven\u00e7\u00e3o humana.</li> <li>Educa\u00e7\u00e3o: Ferramenta poderosa para ensinar programa\u00e7\u00e3o, eletr\u00f4nica e engenharia.</li> <li>Inova\u00e7\u00e3o: Facilita o desenvolvimento de solu\u00e7\u00f5es criativas para problemas do mundo real.</li> <li>Intera\u00e7\u00e3o com o Ambiente: Rob\u00f4s podem coletar dados, realizar inspe\u00e7\u00f5es e interagir com objetos de forma precisa.</li> </ul>"},{"location":"aulas/iot/modulos/modulo15.html#13-componentes-basicos-de-um-robo-com-arduino","title":"1.3 Componentes B\u00e1sicos de um Rob\u00f4 com Arduino","text":"<ul> <li>Arduino Board: O c\u00e9rebro do rob\u00f4, respons\u00e1vel pelo processamento e controle.</li> <li>Motores e Servos: Para movimenta\u00e7\u00e3o e controle de partes m\u00f3veis.</li> <li>Sensores: Para percep\u00e7\u00e3o do ambiente (dist\u00e2ncia, luz, temperatura, etc.).</li> <li>Chassi e Estrutura: A base f\u00edsica do rob\u00f4.</li> <li>Fonte de Alimenta\u00e7\u00e3o: Baterias ou adaptadores para fornecer energia.</li> <li>M\u00f3dulos de Comunica\u00e7\u00e3o: Wi-Fi, Bluetooth ou RF para controle remoto.</li> </ul>"},{"location":"aulas/iot/modulos/modulo15.html#2-componentes-e-hardware-para-robotica","title":"2. Componentes e Hardware para Rob\u00f3tica","text":""},{"location":"aulas/iot/modulos/modulo15.html#21-motores-e-servos","title":"2.1 Motores e Servos","text":"<ul> <li>Motores DC: Utilizados para movimenta\u00e7\u00e3o cont\u00ednua, como rodas de um rob\u00f4 m\u00f3vel.</li> <li>Servos: Precisos e controlados por posi\u00e7\u00e3o, ideais para bra\u00e7os rob\u00f3ticos ou mecanismos que requerem movimentos espec\u00edficos.</li> <li>Drivers de Motor: Controlam a dire\u00e7\u00e3o e velocidade dos motores DC (exemplo: L298N).</li> </ul>"},{"location":"aulas/iot/modulos/modulo15.html#22-sensores-comuns-em-robotica","title":"2.2 Sensores Comuns em Rob\u00f3tica","text":"<ul> <li>Sensor Ultrass\u00f4nico (HC-SR04): Mede dist\u00e2ncia at\u00e9 obst\u00e1culos.</li> <li>Sensor de Linha (IR): Detecta linhas no ch\u00e3o para seguimento de trajet\u00f3ria.</li> <li>Aceler\u00f4metro e Girosc\u00f3pio (MPU6050): Detecta movimento e orienta\u00e7\u00e3o.</li> <li>Sensor de Luz (LDR): Mede intensidade de luz ambiente.</li> </ul>"},{"location":"aulas/iot/modulos/modulo15.html#23-chassi-e-estrutura","title":"2.3 Chassi e Estrutura","text":"<ul> <li>Chassis de Rob\u00f4: Dispon\u00edvel em kits ou personalizado para atender \u00e0s necessidades do projeto.</li> <li>Rod\u00edzios e Trilhos: Para movimenta\u00e7\u00e3o suave e controle de dire\u00e7\u00e3o.</li> <li>Placas de Montagem: Facilitam a fixa\u00e7\u00e3o de componentes eletr\u00f4nicos e mec\u00e2nicos.</li> </ul>"},{"location":"aulas/iot/modulos/modulo15.html#24-fonte-de-alimentacao","title":"2.4 Fonte de Alimenta\u00e7\u00e3o","text":"<ul> <li>Baterias Recarreg\u00e1veis: Fornecem mobilidade ao rob\u00f4.</li> <li>Adaptadores de Energia: Conectam o rob\u00f4 a uma fonte de energia fixa.</li> <li>Gerenciamento de Energia: Reguladores de tens\u00e3o e circuitos de prote\u00e7\u00e3o para garantir estabilidade.</li> </ul>"},{"location":"aulas/iot/modulos/modulo15.html#3-montagem-do-robo-basico","title":"3. Montagem do Rob\u00f4 B\u00e1sico","text":""},{"location":"aulas/iot/modulos/modulo15.html#31-componentes-necessarios","title":"3.1 Componentes Necess\u00e1rios","text":"<ul> <li>Arduino Uno ou Mega</li> <li>Driver de Motor L298N</li> <li>Motores DC (2 unidades)</li> <li>Sensor Ultrass\u00f4nico HC-SR04</li> <li>Sensor de Linha IR</li> <li>Chassi de Rob\u00f4</li> <li>Fonte de Alimenta\u00e7\u00e3o (baterias)</li> <li>Cabos de Conex\u00e3o</li> <li>Protoboard</li> </ul>"},{"location":"aulas/iot/modulos/modulo15.html#32-passo-a-passo-da-montagem","title":"3.2 Passo a Passo da Montagem","text":"<ol> <li>Montagem do Chassi:</li> <li>Fixe os motores DC no chassi.</li> <li> <p>Instale os rod\u00edzios nas eixos dos motores.</p> </li> <li> <p>Conex\u00e3o do Driver de Motor:</p> </li> <li>Conecte os motores DC aos terminais de sa\u00edda do L298N.</li> <li>Conecte os pinos IN1, IN2, IN3 e IN4 do L298N aos pinos digitais do Arduino.</li> <li> <p>Conecte o pino ENA e ENB aos pinos PWM do Arduino para controle de velocidade.</p> </li> <li> <p>Instala\u00e7\u00e3o dos Sensores:</p> </li> <li>Monte o sensor ultrass\u00f4nico na frente do rob\u00f4 para detec\u00e7\u00e3o de obst\u00e1culos.</li> <li> <p>Posicione o sensor de linha na parte inferior do chassi para seguimento de trajet\u00f3rias.</p> </li> <li> <p>Conex\u00e3o dos Sensores ao Arduino:</p> </li> <li>Conecte os pinos VCC e GND dos sensores ao Arduino.</li> <li> <p>Conecte os pinos de sinal dos sensores aos pinos anal\u00f3gicos ou digitais correspondentes.</p> </li> <li> <p>Fonte de Alimenta\u00e7\u00e3o:</p> </li> <li>Conecte as baterias ao L298N para alimentar os motores e o Arduino.</li> <li>Assegure-se de que as conex\u00f5es de energia estejam seguras e protegidas.</li> </ol>"},{"location":"aulas/iot/modulos/modulo15.html#4-programacao-do-robo","title":"4. Programa\u00e7\u00e3o do Rob\u00f4","text":""},{"location":"aulas/iot/modulos/modulo15.html#41-controle-de-movimentacao-basico","title":"4.1 Controle de Movimenta\u00e7\u00e3o B\u00e1sico","text":"<p>O primeiro passo na programa\u00e7\u00e3o do rob\u00f4 \u00e9 controlar a movimenta\u00e7\u00e3o dos motores. Vamos criar um c\u00f3digo simples que permite ao rob\u00f4 avan\u00e7ar, retroceder, girar \u00e0 esquerda e \u00e0 direita.</p> <pre><code>const int IN1 = 9;\nconst int IN2 = 8;\nconst int ENA = 10;\nconst int IN3 = 7;\nconst int IN4 = 6;\nconst int ENB = 5;\n\nvoid setup() {\n    pinMode(IN1, OUTPUT);\n    pinMode(IN2, OUTPUT);\n    pinMode(ENA, OUTPUT);\n    pinMode(IN3, OUTPUT);\n    pinMode(IN4, OUTPUT);\n    pinMode(ENB, OUTPUT);\n}\n\nvoid loop() {\n    // Avan\u00e7ar\n    digitalWrite(IN1, HIGH);\n    digitalWrite(IN2, LOW);\n    digitalWrite(IN3, HIGH);\n    digitalWrite(IN4, LOW);\n    analogWrite(ENA, 200);\n    analogWrite(ENB, 200);\n    delay(2000);\n\n    // Parar\n    digitalWrite(IN1, LOW);\n    digitalWrite(IN2, LOW);\n    digitalWrite(IN3, LOW);\n    digitalWrite(IN4, LOW);\n    delay(1000);\n\n    // Retroceder\n    digitalWrite(IN1, LOW);\n    digitalWrite(IN2, HIGH);\n    digitalWrite(IN3, LOW);\n    digitalWrite(IN4, HIGH);\n    analogWrite(ENA, 200);\n    analogWrite(ENB, 200);\n    delay(2000);\n\n    // Parar\n    digitalWrite(IN1, LOW);\n    digitalWrite(IN2, LOW);\n    digitalWrite(IN3, LOW);\n    digitalWrite(IN4, LOW);\n    delay(1000);\n\n    // Girar \u00e0 Esquerda\n    digitalWrite(IN1, LOW);\n    digitalWrite(IN2, HIGH);\n    digitalWrite(IN3, HIGH);\n    digitalWrite(IN4, LOW);\n    analogWrite(ENA, 200);\n    analogWrite(ENB, 200);\n    delay(1500);\n\n    // Parar\n    digitalWrite(IN1, LOW);\n    digitalWrite(IN2, LOW);\n    digitalWrite(IN3, LOW);\n    digitalWrite(IN4, LOW);\n    delay(1000);\n\n    // Girar \u00e0 Direita\n    digitalWrite(IN1, HIGH);\n    digitalWrite(IN2, LOW);\n    digitalWrite(IN3, LOW);\n    digitalWrite(IN4, HIGH);\n    analogWrite(ENA, 200);\n    analogWrite(ENB, 200);\n    delay(1500);\n\n    // Parar\n    digitalWrite(IN1, LOW);\n    digitalWrite(IN2, LOW);\n    digitalWrite(IN3, LOW);\n    digitalWrite(IN4, LOW);\n    delay(1000);\n}\n</code></pre> <p>Explica\u00e7\u00e3o:</p> <ul> <li>Dire\u00e7\u00e3o do Motor: Controlada pelos pinos IN1, IN2, IN3 e IN4. Configurar IN1 alto e IN2 baixo faz um motor girar em uma dire\u00e7\u00e3o, enquanto IN1 baixo e IN2 alto faz girar na dire\u00e7\u00e3o oposta.</li> <li>Controle de Velocidade: Utiliza PWM nos pinos ENA e ENB para ajustar a velocidade dos motores DC.</li> <li>Sequ\u00eancia de Movimentos: O loop principal faz o rob\u00f4 avan\u00e7ar, parar, retroceder, parar, girar \u00e0 esquerda, parar, girar \u00e0 direita e parar novamente.</li> </ul>"},{"location":"aulas/iot/modulos/modulo15.html#42-implementacao-de-sensores-para-navegacao","title":"4.2 Implementa\u00e7\u00e3o de Sensores para Navega\u00e7\u00e3o","text":"<p>Agora, vamos integrar os sensores ao rob\u00f4 para permitir que ele navegue de forma aut\u00f4noma, evitando obst\u00e1culos e seguindo linhas.</p> <p>Exemplo de C\u00f3digo com Sensor Ultrass\u00f4nico:</p> <pre><code>const int trigPin = A0;\nconst int echoPin = A1;\nconst int IN1 = 9;\nconst int IN2 = 8;\nconst int ENA = 10;\nconst int IN3 = 7;\nconst int IN4 = 6;\nconst int ENB = 5;\n\nlong duration;\nint distance;\n\nvoid setup() {\n    pinMode(trigPin, OUTPUT);\n    pinMode(echoPin, INPUT);\n    pinMode(IN1, OUTPUT);\n    pinMode(IN2, OUTPUT);\n    pinMode(ENA, OUTPUT);\n    pinMode(IN3, OUTPUT);\n    pinMode(IN4, OUTPUT);\n    pinMode(ENB, OUTPUT);\n    Serial.begin(9600);\n}\n\nvoid loop() {\n    // Emite um pulso ultrass\u00f4nico\n    digitalWrite(trigPin, LOW);\n    delayMicroseconds(2);\n    digitalWrite(trigPin, HIGH);\n    delayMicroseconds(10);\n    digitalWrite(trigPin, LOW);\n\n    // Calcula a dura\u00e7\u00e3o do pulso\n    duration = pulseIn(echoPin, HIGH);\n\n    // Calcula a dist\u00e2ncia em cm\n    distance = duration * 0.034 / 2;\n\n    Serial.print(\"Dist\u00e2ncia: \");\n    Serial.println(distance);\n\n    if (distance &lt; 20) { // Se um obst\u00e1culo estiver a menos de 20 cm\n        // Parar os motores\n        digitalWrite(IN1, LOW);\n        digitalWrite(IN2, LOW);\n        digitalWrite(IN3, LOW);\n        digitalWrite(IN4, LOW);\n        analogWrite(ENA, 0);\n        analogWrite(ENB, 0);\n        delay(1000);\n\n        // Girar \u00e0 direita para evitar o obst\u00e1culo\n        digitalWrite(IN1, HIGH);\n        digitalWrite(IN2, LOW);\n        digitalWrite(IN3, LOW);\n        digitalWrite(IN4, HIGH);\n        analogWrite(ENA, 200);\n        analogWrite(ENB, 200);\n        delay(1500);\n    } else {\n        // Avan\u00e7ar normalmente\n        digitalWrite(IN1, HIGH);\n        digitalWrite(IN2, LOW);\n        digitalWrite(IN3, HIGH);\n        digitalWrite(IN4, LOW);\n        analogWrite(ENA, 200);\n        analogWrite(ENB, 200);\n    }\n}\n</code></pre> <p>Explica\u00e7\u00e3o:</p> <ul> <li>Sensor Ultrass\u00f4nico: Mede a dist\u00e2ncia at\u00e9 obst\u00e1culos na frente do rob\u00f4.</li> <li>Evitar Obst\u00e1culos: Se um obst\u00e1culo for detectado a menos de 20 cm, o rob\u00f4 para e gira \u00e0 direita para evitar a colis\u00e3o.</li> <li>Movimenta\u00e7\u00e3o Aut\u00f4noma: O rob\u00f4 continua avan\u00e7ando quando n\u00e3o h\u00e1 obst\u00e1culos detectados.</li> </ul>"},{"location":"aulas/iot/modulos/modulo15.html#43-controle-remoto-via-bluetooth","title":"4.3 Controle Remoto via Bluetooth","text":"<p>Para adicionar controle manual ao seu rob\u00f4, podemos integrar um m\u00f3dulo Bluetooth que permitir\u00e1 controlar os movimentos via smartphone.</p> <p>Exemplo de C\u00f3digo para Controle Bluetooth:</p> <pre><code>#include &lt;SoftwareSerial.h&gt;\n\nSoftwareSerial bluetooth(10, 11); // RX, TX\n\nconst int IN1 = 9;\nconst int IN2 = 8;\nconst int IN3 = 7;\nconst int IN4 = 6;\nconst int ENA = 5;\nconst int ENB = 4;\n\nvoid setup() {\n    Serial.begin(9600);\n    bluetooth.begin(9600);\n\n    pinMode(IN1, OUTPUT);\n    pinMode(IN2, OUTPUT);\n    pinMode(IN3, OUTPUT);\n    pinMode(IN4, OUTPUT);\n    pinMode(ENA, OUTPUT);\n    pinMode(ENB, OUTPUT);\n}\n\nvoid loop() {\n    if (bluetooth.available()) {\n        char comando = bluetooth.read();\n        Serial.println(comando);\n\n        switch (comando) {\n            case 'F': // Avan\u00e7ar\n                digitalWrite(IN1, HIGH);\n                digitalWrite(IN2, LOW);\n                digitalWrite(IN3, HIGH);\n                digitalWrite(IN4, LOW);\n                analogWrite(ENA, 200);\n                analogWrite(ENB, 200);\n                break;\n            case 'B': // Retroceder\n                digitalWrite(IN1, LOW);\n                digitalWrite(IN2, HIGH);\n                digitalWrite(IN3, LOW);\n                digitalWrite(IN4, HIGH);\n                analogWrite(ENA, 200);\n                analogWrite(ENB, 200);\n                break;\n            case 'L': // Girar \u00e0 esquerda\n                digitalWrite(IN1, LOW);\n                digitalWrite(IN2, HIGH);\n                digitalWrite(IN3, HIGH);\n                digitalWrite(IN4, LOW);\n                analogWrite(ENA, 200);\n                analogWrite(ENB, 200);\n                break;\n            case 'R': // Girar \u00e0 direita\n                digitalWrite(IN1, HIGH);\n                digitalWrite(IN2, LOW);\n                digitalWrite(IN3, LOW);\n                digitalWrite(IN4, HIGH);\n                analogWrite(ENA, 200);\n                analogWrite(ENB, 200);\n                break;\n            case 'S': // Parar\n                digitalWrite(IN1, LOW);\n                digitalWrite(IN2, LOW);\n                digitalWrite(IN3, LOW);\n                digitalWrite(IN4, LOW);\n                analogWrite(ENA, 0);\n                analogWrite(ENB, 0);\n                break;\n        }\n    }\n}\n</code></pre> <p>Explica\u00e7\u00e3o:</p> <ul> <li>SoftwareSerial: Cria uma porta serial adicional para comunica\u00e7\u00e3o com o m\u00f3dulo Bluetooth.</li> <li>Comandos de Controle: Define comandos ('F' para avan\u00e7ar, 'B' para retroceder, 'L' para girar \u00e0 esquerda, 'R' para girar \u00e0 direita, 'S' para parar) que podem ser enviados via aplicativo de controle Bluetooth no smartphone.</li> <li>Controle Manual: Permite que o usu\u00e1rio controle o rob\u00f4 remotamente atrav\u00e9s de um dispositivo Bluetooth.</li> </ul>"},{"location":"aulas/iot/modulos/modulo15.html#5-desenvolvimento-de-projetos-roboticos","title":"5. Desenvolvimento de Projetos Rob\u00f3ticos","text":""},{"location":"aulas/iot/modulos/modulo15.html#51-robo-seguidor-de-linha","title":"5.1 Rob\u00f4 Seguidor de Linha","text":"<p>Desenvolva um rob\u00f4 que segue uma linha no ch\u00e3o utilizando sensores de linha IR. Este projeto ensina a integrar sensores para navega\u00e7\u00e3o precisa.</p>"},{"location":"aulas/iot/modulos/modulo15.html#52-braco-robotico-controlado-por-servo","title":"5.2 Bra\u00e7o Rob\u00f3tico Controlado por Servo","text":"<p>Construa um bra\u00e7o rob\u00f3tico que pode ser controlado para mover objetos, utilizando servos para articula\u00e7\u00f5es e sensores para precis\u00e3o.</p>"},{"location":"aulas/iot/modulos/modulo15.html#53-robo-autonomo-com-navegacao-inteligente","title":"5.3 Rob\u00f4 Aut\u00f4nomo com Navega\u00e7\u00e3o Inteligente","text":"<p>Crie um rob\u00f4 que navega autonomamente por um ambiente complexo, evitando obst\u00e1culos e mapeando o espa\u00e7o utilizando m\u00faltiplos sensores.</p>"},{"location":"aulas/iot/modulos/modulo15.html#6-conceitos-importantes","title":"6. Conceitos Importantes","text":""},{"location":"aulas/iot/modulos/modulo15.html#61-algoritmos-de-controle","title":"6.1 Algoritmos de Controle","text":"<ul> <li>PID (Proporcional, Integral, Derivativo): Algoritmo usado para controlar a velocidade e posi\u00e7\u00e3o de motores de forma precisa.</li> <li>FSM (M\u00e1quina de Estados Finitos): Modelo para gerenciar diferentes estados e transi\u00e7\u00f5es em sistemas de controle.</li> </ul>"},{"location":"aulas/iot/modulos/modulo15.html#62-processamento-de-sinais","title":"6.2 Processamento de Sinais","text":"<ul> <li>Filtragem: Remo\u00e7\u00e3o de ru\u00eddos das leituras dos sensores para obter dados mais precisos.</li> <li>Debouncing: T\u00e9cnica para evitar m\u00faltiplas leituras r\u00e1pidas indesejadas de sensores digitais.</li> </ul>"},{"location":"aulas/iot/modulos/modulo15.html#63-integracao-de-sensores-e-atuadores","title":"6.3 Integra\u00e7\u00e3o de Sensores e Atuadores","text":"<ul> <li>Sincroniza\u00e7\u00e3o: Garantir que os sensores e atuadores trabalhem de forma coordenada para realizar tarefas complexas.</li> <li>Calibra\u00e7\u00e3o: Ajustar sensores para garantir leituras precisas e confi\u00e1veis.</li> </ul>"},{"location":"aulas/iot/modulos/modulo15.html#64-comunicacao-entre-componentes","title":"6.4 Comunica\u00e7\u00e3o entre Componentes","text":"<ul> <li>I2C e SPI: Protocolos de comunica\u00e7\u00e3o para conectar m\u00faltiplos dispositivos e sensores ao Arduino.</li> <li>UART: Comunica\u00e7\u00e3o serial para interligar m\u00f3dulos como Bluetooth e GPS.</li> </ul>"},{"location":"aulas/iot/modulos/modulo15.html#65-boas-praticas-na-construcao-de-robos","title":"6.5 Boas Pr\u00e1ticas na Constru\u00e7\u00e3o de Rob\u00f4s","text":"<ul> <li>Organiza\u00e7\u00e3o dos Cabos: Mant\u00e9m o sistema limpo e evita curtos-circuitos.</li> <li>Montagem Segura: Assegura que todos os componentes estejam firmemente fixados para evitar movimentos indesejados.</li> <li>Teste Modular: Teste cada m\u00f3dulo (movimenta\u00e7\u00e3o, sensores, comunica\u00e7\u00e3o) separadamente antes da integra\u00e7\u00e3o completa.</li> </ul>"},{"location":"aulas/iot/modulos/modulo15.html#7-recursos-adicionais","title":"7. Recursos Adicionais","text":"<ul> <li> <p>Documenta\u00e7\u00e3o Oficial do Arduino:</p> </li> <li> <p>Motor Shield Library</p> </li> <li>Servo Library</li> <li>Wire Library (I2C)</li> <li> <p>SPI Library</p> </li> <li> <p>Tutoriais e Guias:</p> </li> <li> <p>Construindo um Rob\u00f4 Seguidor de Linha com Arduino</p> </li> <li>Bra\u00e7o Rob\u00f3tico com Arduino e Servos</li> <li> <p>Rob\u00f4 Aut\u00f4nomo com Navega\u00e7\u00e3o Inteligente</p> </li> <li> <p>V\u00eddeos Educacionais:</p> </li> <li> <p>Tutorial de Rob\u00f3tica com Arduino</p> </li> <li>Controle de Motores e Servos para Rob\u00f4s</li> <li>Integrando Sensores em Projetos Rob\u00f3ticos</li> </ul>"},{"location":"aulas/iot/modulos/modulo15.html#8-exemplos-praticos","title":"8. Exemplos Pr\u00e1ticos","text":""},{"location":"aulas/iot/modulos/modulo15.html#81-robo-seguidor-de-linha-com-pid","title":"8.1 Rob\u00f4 Seguidor de Linha com PID","text":"<p>Este exemplo demonstra como implementar um rob\u00f4 seguidor de linha utilizando sensores IR e controle PID para uma navega\u00e7\u00e3o mais precisa.</p> <pre><code>#include &lt;PID_v1.h&gt;\n\n// Pinos dos sensores de linha\nconst int sensorEsquerdo = A0;\nconst int sensorDireito = A1;\n\n// Pinos dos motores\nconst int IN1 = 9;\nconst int IN2 = 8;\nconst int ENA = 10;\nconst int IN3 = 7;\nconst int IN4 = 6;\nconst int ENB = 5;\n\n// Vari\u00e1veis para PID\ndouble Setpoint, Input, Output;\ndouble Kp=2, Ki=5, Kd=1;\n\n// Cria\u00e7\u00e3o do objeto PID\nPID myPID(&amp;Input, &amp;Output, &amp;Setpoint, Kp, Ki, Kd, DIRECT);\n\nvoid setup() {\n    pinMode(sensorEsquerdo, INPUT);\n    pinMode(sensorDireito, INPUT);\n\n    pinMode(IN1, OUTPUT);\n    pinMode(IN2, OUTPUT);\n    pinMode(IN3, OUTPUT);\n    pinMode(IN4, OUTPUT);\n    pinMode(ENA, OUTPUT);\n    pinMode(ENB, OUTPUT);\n\n    // Define o ponto de ajuste para 0 (linha central)\n    Setpoint = 0;\n\n    // Inicializa o PID\n    myPID.SetMode(AUTOMATIC);\n}\n\nvoid loop() {\n    int leituraEsquerda = analogRead(sensorEsquerdo);\n    int leituraDireita = analogRead(sensorDireito);\n\n    // Calcula o erro: diferen\u00e7a entre as leituras dos sensores\n    Input = leituraEsquerda - leituraDireita;\n\n    // Atualiza o PID\n    myPID.Compute();\n\n    // Ajusta a velocidade dos motores com base na sa\u00edda do PID\n    int velocidadeEsquerda = 200 + Output;\n    int velocidadeDireita = 200 - Output;\n\n    // Limita os valores de PWM para 0-255\n    velocidadeEsquerda = constrain(velocidadeEsquerda, 0, 255);\n    velocidadeDireita = constrain(velocidadeDireita, 0, 255);\n\n    // Define a dire\u00e7\u00e3o dos motores\n    if (velocidadeEsquerda &gt; 200) {\n        digitalWrite(IN1, HIGH);\n        digitalWrite(IN2, LOW);\n    } else {\n        digitalWrite(IN1, LOW);\n        digitalWrite(IN2, HIGH);\n    }\n\n    if (velocidadeDireita &gt; 200) {\n        digitalWrite(IN3, HIGH);\n        digitalWrite(IN4, LOW);\n    } else {\n        digitalWrite(IN3, LOW);\n        digitalWrite(IN4, HIGH);\n    }\n\n    // Aplica a velocidade\n    analogWrite(ENA, velocidadeEsquerda);\n    analogWrite(ENB, velocidadeDireita);\n\n    delay(100);\n}\n</code></pre> <p>Explica\u00e7\u00e3o:</p> <ul> <li>Controle PID: Utiliza o algoritmo PID para ajustar a velocidade dos motores com base no erro de alinhamento detectado pelos sensores de linha.</li> <li>Leitura dos Sensores: Obt\u00e9m as leituras dos sensores de linha IR para determinar a posi\u00e7\u00e3o relativa do rob\u00f4 em rela\u00e7\u00e3o \u00e0 linha.</li> <li>Ajuste de Velocidade: Calcula a diferen\u00e7a entre as leituras para determinar a dire\u00e7\u00e3o e a magnitude do ajuste necess\u00e1rio.</li> <li>Movimenta\u00e7\u00e3o Suave: Permite que o rob\u00f4 siga a linha de forma mais precisa e est\u00e1vel.</li> </ul>"},{"location":"aulas/iot/modulos/modulo15.html#82-braco-robotico-controlado-por-servo","title":"8.2 Bra\u00e7o Rob\u00f3tico Controlado por Servo","text":"<p>Este exemplo demonstra como construir e controlar um bra\u00e7o rob\u00f3tico utilizando servos para as articula\u00e7\u00f5es.</p> <pre><code>#include &lt;Servo.h&gt;\n\n// Defini\u00e7\u00e3o dos servos\nServo base;\nServo ombro;\nServo cotovelo;\nServo garra;\n\n// Pinos dos servos\nconst int pinoBase = 3;\nconst int pinoOmbro = 5;\nconst int pinoCotovelo = 6;\nconst int pinoGarra = 9;\n\nvoid setup() {\n    // Anexa os servos aos pinos\n    base.attach(pinoBase);\n    ombro.attach(pinoOmbro);\n    cotovelo.attach(pinoCotovelo);\n    garra.attach(pinoGarra);\n\n    // Inicializa as posi\u00e7\u00f5es\n    base.write(90);\n    ombro.write(90);\n    cotovelo.write(90);\n    garra.write(10);\n}\n\nvoid loop() {\n    // Movimenta a base para a esquerda\n    base.write(60);\n    delay(1000);\n\n    // Movimenta a base para a direita\n    base.write(120);\n    delay(1000);\n\n    // Movimenta o ombro para cima\n    ombro.write(60);\n    delay(1000);\n\n    // Movimenta o ombro para baixo\n    ombro.write(120);\n    delay(1000);\n\n    // Movimenta o cotovelo para cima\n    cotovelo.write(60);\n    delay(1000);\n\n    // Movimenta o cotovelo para baixo\n    cotovelo.write(120);\n    delay(1000);\n\n    // Abre a garra\n    garra.write(10);\n    delay(1000);\n\n    // Fecha a garra\n    garra.write(80);\n    delay(1000);\n}\n</code></pre> <p>Explica\u00e7\u00e3o:</p> <ul> <li>Servos para Articula\u00e7\u00f5es: Utiliza servos para controlar a base, ombro, cotovelo e garra do bra\u00e7o rob\u00f3tico.</li> <li>Movimenta\u00e7\u00e3o Coordenada: Define movimentos sequenciais para cada articula\u00e7\u00e3o, permitindo que o bra\u00e7o execute a\u00e7\u00f5es como pegar e mover objetos.</li> <li>Controle Simples: Movimenta os servos entre posi\u00e7\u00f5es predefinidas para demonstrar o funcionamento b\u00e1sico do bra\u00e7o.</li> </ul>"},{"location":"aulas/iot/modulos/modulo15.html#83-robo-autonomo-com-navegacao-inteligente","title":"8.3 Rob\u00f4 Aut\u00f4nomo com Navega\u00e7\u00e3o Inteligente","text":"<p>Este exemplo integra m\u00faltiplos sensores e algoritmos avan\u00e7ados para criar um rob\u00f4 aut\u00f4nomo que navega por um ambiente complexo.</p> <pre><code>#include &lt;Servo.h&gt;\n#include &lt;Wire.h&gt;\n#include &lt;Adafruit_Sensor.h&gt;\n#include &lt;Adafruit_MPU6050.h&gt;\n\n// Defini\u00e7\u00e3o dos servos para dire\u00e7\u00e3o\nServo servoEsquerdo;\nServo servoDireito;\n\n// Pinos dos servos\nconst int pinoServoEsquerdo = 3;\nconst int pinoServoDireito = 5;\n\n// Defini\u00e7\u00e3o dos sensores\nAdafruit_MPU6050 mpu;\n\n// Pinos dos sensores de dist\u00e2ncia\nconst int trigPin = A0;\nconst int echoPin = A1;\n\nlong duration;\nint distance;\n\nvoid setup() {\n    Serial.begin(9600);\n\n    // Inicializa os servos\n    servoEsquerdo.attach(pinoServoEsquerdo);\n    servoDireito.attach(pinoServoDireito);\n\n    // Inicializa os sensores ultrass\u00f4nicos\n    pinMode(trigPin, OUTPUT);\n    pinMode(echoPin, INPUT);\n\n    // Inicializa o MPU6050\n    if (!mpu.begin()) {\n        Serial.println(\"Falha ao inicializar o MPU6050!\");\n        while (1);\n    }\n    mpu.setAccelerometerRange(MPU6050_RANGE_8_G);\n    mpu.setGyroRange(MPU6050_RANGE_500_DEG);\n    mpu.setFilterBandwidth(MPU6050_BAND_21_HZ);\n\n    // Define a posi\u00e7\u00e3o inicial dos servos\n    servoEsquerdo.write(90);\n    servoDireito.write(90);\n}\n\nvoid loop() {\n    // Leitura do sensor ultrass\u00f4nico\n    digitalWrite(trigPin, LOW);\n    delayMicroseconds(2);\n    digitalWrite(trigPin, HIGH);\n    delayMicroseconds(10);\n    digitalWrite(trigPin, LOW);\n\n    duration = pulseIn(echoPin, HIGH);\n    distance = duration * 0.034 / 2;\n\n    Serial.print(\"Dist\u00e2ncia: \");\n    Serial.println(distance);\n\n    // Leitura do MPU6050\n    sensors_event_t a, g, temp;\n    mpu.getEvent(&amp;a, &amp;g, &amp;temp);\n\n    Serial.print(\"Aceler\u00f4metro X: \"); Serial.println(a.acceleration.x);\n    Serial.print(\"Girosc\u00f3pio Z: \"); Serial.println(g.gyro.z);\n\n    // Decis\u00e3o de movimento baseada nos sensores\n    if (distance &lt; 20) {\n        // Obst\u00e1culo detectado, girar \u00e0 direita\n        servoEsquerdo.write(60);\n        servoDireito.write(120);\n        delay(1000);\n    } else {\n        // Avan\u00e7ar\n        servoEsquerdo.write(90);\n        servoDireito.write(90);\n    }\n\n    delay(500);\n}\n</code></pre> <p>Explica\u00e7\u00e3o:</p> <ul> <li>MPU6050: Utiliza um aceler\u00f4metro e girosc\u00f3pio para detectar movimentos e inclina\u00e7\u00f5es, ajudando na estabiliza\u00e7\u00e3o e navega\u00e7\u00e3o do rob\u00f4.</li> <li>Sensor Ultrass\u00f4nico: Detecta obst\u00e1culos \u00e0 frente do rob\u00f4, permitindo que ele tome decis\u00f5es para evit\u00e1-los.</li> <li>Controle de Dire\u00e7\u00e3o Inteligente: Ajusta a dire\u00e7\u00e3o dos servos com base nas leituras dos sensores para navegar de forma aut\u00f4noma pelo ambiente.</li> </ul>"},{"location":"aulas/iot/modulos/modulo15.html#9-conceitos-importantes","title":"9. Conceitos Importantes","text":""},{"location":"aulas/iot/modulos/modulo15.html#91-algoritmos-de-navegacao","title":"9.1 Algoritmos de Navega\u00e7\u00e3o","text":"<ul> <li>Navega\u00e7\u00e3o Baseada em Sensores: Utiliza dados de sensores para tomar decis\u00f5es de movimenta\u00e7\u00e3o e evitar obst\u00e1culos.</li> <li>Mapeamento e Localiza\u00e7\u00e3o: T\u00e9cnicas para criar mapas do ambiente e determinar a posi\u00e7\u00e3o do rob\u00f4 dentro dele.</li> <li>Planejamento de Trajet\u00f3ria: Algoritmos para determinar o melhor caminho a ser seguido pelo rob\u00f4.</li> </ul>"},{"location":"aulas/iot/modulos/modulo15.html#92-controle-de-movimento","title":"9.2 Controle de Movimento","text":"<ul> <li>Controle de Velocidade: Ajuste preciso da velocidade dos motores para movimentos suaves e est\u00e1veis.</li> <li>Dire\u00e7\u00e3o e Orienta\u00e7\u00e3o: T\u00e9cnicas para controlar a dire\u00e7\u00e3o do rob\u00f4 e manter sua orienta\u00e7\u00e3o correta.</li> <li>Estabiliza\u00e7\u00e3o: Uso de sensores como aceler\u00f4metros e girosc\u00f3pios para manter o rob\u00f4 equilibrado.</li> </ul>"},{"location":"aulas/iot/modulos/modulo15.html#93-integracao-de-multiplos-sensores","title":"9.3 Integra\u00e7\u00e3o de M\u00faltiplos Sensores","text":"<ul> <li>Sincroniza\u00e7\u00e3o de Dados: Coordena\u00e7\u00e3o das leituras de m\u00faltiplos sensores para obter uma vis\u00e3o abrangente do ambiente.</li> <li>Fus\u00e3o de Sensores: Combina\u00e7\u00e3o de dados de diferentes sensores para melhorar a precis\u00e3o e confiabilidade das informa\u00e7\u00f5es.</li> </ul>"},{"location":"aulas/iot/modulos/modulo15.html#94-comunicacao-entre-componentes","title":"9.4 Comunica\u00e7\u00e3o entre Componentes","text":"<ul> <li>I2C e SPI: Protocolos para comunica\u00e7\u00e3o entre o Arduino e sensores avan\u00e7ados como o MPU6050.</li> <li>Serial Communication: Comunica\u00e7\u00e3o serial para interligar m\u00f3dulos adicionais como Bluetooth e GPS.</li> </ul>"},{"location":"aulas/iot/modulos/modulo15.html#95-boas-praticas-na-construcao-de-robos","title":"9.5 Boas Pr\u00e1ticas na Constru\u00e7\u00e3o de Rob\u00f4s","text":"<ul> <li>Modularidade: Desenvolver sistemas modulares para facilitar atualiza\u00e7\u00f5es e manuten\u00e7\u00f5es.</li> <li>Organiza\u00e7\u00e3o de Cabos: Manter os cabos organizados para evitar interfer\u00eancias e facilitar a depura\u00e7\u00e3o.</li> <li>Teste e Depura\u00e7\u00e3o: Testar cada componente separadamente antes da integra\u00e7\u00e3o completa para identificar e resolver problemas rapidamente.</li> </ul>"},{"location":"aulas/iot/modulos/modulo15.html#10-recursos-adicionais","title":"10. Recursos Adicionais","text":"<ul> <li> <p>Documenta\u00e7\u00e3o Oficial do Arduino:</p> </li> <li> <p>Motor Shield Library</p> </li> <li>Servo Library</li> <li>Wire Library (I2C)</li> <li> <p>Adafruit MPU6050 Library</p> </li> <li> <p>Tutoriais e Guias:</p> </li> <li> <p>Construindo um Rob\u00f4 Seguidor de Linha com PID</p> </li> <li>Bra\u00e7o Rob\u00f3tico com Arduino e Servos</li> <li> <p>Rob\u00f4 Aut\u00f4nomo com Navega\u00e7\u00e3o Inteligente</p> </li> <li> <p>V\u00eddeos Educacionais:</p> </li> <li> <p>Tutorial de Rob\u00f3tica com Arduino</p> </li> <li>Controle de Motores e Servos para Rob\u00f4s</li> <li>Integrando Sensores em Projetos Rob\u00f3ticos</li> </ul>"},{"location":"aulas/iot/modulos/modulo15.html#11-conclusao-do-modulo","title":"11. Conclus\u00e3o do M\u00f3dulo","text":"<p>Neste m\u00f3dulo, voc\u00ea aprendeu:</p> <ul> <li>Fundamentos da Rob\u00f3tica: Entendeu os componentes essenciais e como eles interagem para formar um rob\u00f4 funcional.</li> <li>Controle de Movimenta\u00e7\u00e3o: Aprendeu a controlar motores e servos para movimenta\u00e7\u00e3o precisa.</li> <li>Integra\u00e7\u00e3o de Sensores: Implementou sensores para percep\u00e7\u00e3o do ambiente e navega\u00e7\u00e3o aut\u00f4noma.</li> <li>Algoritmos de Controle: Utilizou algoritmos como PID para melhorar a precis\u00e3o e estabilidade do rob\u00f4.</li> <li>Projetos Pr\u00e1ticos: Desenvolveu projetos como rob\u00f4s seguidores de linha, bra\u00e7os rob\u00f3ticos e rob\u00f4s aut\u00f4nomos com navega\u00e7\u00e3o inteligente.</li> <li>Boas Pr\u00e1ticas: Compreendeu a import\u00e2ncia da organiza\u00e7\u00e3o, modularidade e teste na constru\u00e7\u00e3o de rob\u00f4s.</li> </ul> <p>Voc\u00ea est\u00e1 agora preparado para avan\u00e7ar para projetos mais complexos e integrar rob\u00f4s com outras tecnologias, ampliando ainda mais as possibilidades dos seus projetos com Arduino.</p>"},{"location":"aulas/iot/modulos/modulo15.html#12-proximos-passos","title":"12. Pr\u00f3ximos Passos","text":"<ul> <li>Revisar todo o conte\u00fado do curso para consolidar o aprendizado.</li> <li>Explorar projetos avan\u00e7ados que combinam m\u00faltiplos conceitos aprendidos, como integra\u00e7\u00e3o com IoT, automa\u00e7\u00e3o residencial ou sistemas de monitoramento ambiental.</li> <li>Participar de comunidades e f\u00f3runs de Arduino para trocar experi\u00eancias e obter suporte cont\u00ednuo.</li> <li>Considerar cursos avan\u00e7ados ou especializa\u00e7\u00f5es em \u00e1reas espec\u00edficas de interesse, como rob\u00f3tica avan\u00e7ada, intelig\u00eancia artificial ou design de hardware.</li> <li>Desenvolver seu pr\u00f3prio portf\u00f3lio de projetos Arduino para demonstrar suas habilidades e conhecimentos adquiridos.</li> </ul> <p>Se tiver d\u00favidas ou precisar de assist\u00eancia, continue participando de comunidades de aprendizagem ou consulte os recursos adicionais fornecidos ao longo dos m\u00f3dulos.</p> <p>**Parab\u00e9ns por concluir o curso! Continue explorando e criando projetos incr\u00edveis com Arduino!</p>"},{"location":"aulas/iot/modulos/modulo16.html","title":"M\u00f3dulo 16: Controle Avan\u00e7ado e Algoritmos de Controle","text":"<p>Bem-vindo ao M\u00f3dulo 15 do curso \"Programa\u00e7\u00e3o em Arduino: Conceitos Fundamentais sem Hardware\". Neste m\u00f3dulo, voc\u00ea ir\u00e1 explorar t\u00e9cnicas avan\u00e7adas de controle e algoritmos de controle que permitem ao Arduino gerenciar sistemas complexos de maneira eficiente e precisa. Abordaremos desde os fundamentos do controle PID at\u00e9 a implementa\u00e7\u00e3o de m\u00e1quinas de estados finitos (FSM), proporcionando ferramentas essenciais para o desenvolvimento de projetos mais sofisticados e robustos.</p>"},{"location":"aulas/iot/modulos/modulo16.html#objetivos-do-modulo","title":"Objetivos do M\u00f3dulo","text":"<ul> <li>Compreender os fundamentos dos algoritmos de controle PID e FSM.</li> <li>Implementar controle PID no Arduino para aplica\u00e7\u00f5es como regula\u00e7\u00e3o de temperatura e velocidade de motores.</li> <li>Desenvolver m\u00e1quinas de estados finitos para gerenciar diferentes modos de opera\u00e7\u00e3o em sistemas automatizados.</li> <li>Aplicar t\u00e9cnicas avan\u00e7adas de filtragem de dados para melhorar a precis\u00e3o das leituras dos sensores.</li> <li>Resolver exerc\u00edcios pr\u00e1ticos para consolidar o conhecimento sobre controle avan\u00e7ado com Arduino.</li> </ul>"},{"location":"aulas/iot/modulos/modulo16.html#1-introducao-aos-algoritmos-de-controle","title":"1. Introdu\u00e7\u00e3o aos Algoritmos de Controle","text":""},{"location":"aulas/iot/modulos/modulo16.html#11-o-que-e-um-algoritmo-de-controle","title":"1.1 O que \u00e9 um Algoritmo de Controle?","text":"<p>Algoritmos de controle s\u00e3o procedimentos matem\u00e1ticos utilizados para regular o comportamento de sistemas din\u00e2micos. Eles processam informa\u00e7\u00f5es de entrada (como dados de sensores) e determinam as a\u00e7\u00f5es de sa\u00edda necess\u00e1rias para atingir um objetivo espec\u00edfico, como manter uma temperatura constante ou controlar a velocidade de um motor.</p>"},{"location":"aulas/iot/modulos/modulo16.html#12-importancia-dos-algoritmos-de-controle","title":"1.2 Import\u00e2ncia dos Algoritmos de Controle","text":"<ul> <li>Precis\u00e3o e Estabilidade: Garantem que o sistema opere de forma precisa e est\u00e1vel, mesmo diante de varia\u00e7\u00f5es externas.</li> <li>Automa\u00e7\u00e3o: Permitem que sistemas automatizados respondam de maneira inteligente a mudan\u00e7as no ambiente.</li> <li>Efici\u00eancia: Otimizam o desempenho do sistema, reduzindo desperd\u00edcios e melhorando a efici\u00eancia energ\u00e9tica.</li> </ul>"},{"location":"aulas/iot/modulos/modulo16.html#13-tipos-de-algoritmos-de-controle","title":"1.3 Tipos de Algoritmos de Controle","text":"<ul> <li>Controle P (Proporcional): Ajusta a sa\u00edda proporcionalmente ao erro atual.</li> <li>Controle PI (Proporcional-Integral): Combina controle proporcional com a soma do erro ao longo do tempo.</li> <li>Controle PID (Proporcional-Integral-Derivativo): Adiciona um termo derivativo para prever futuras tend\u00eancias do erro.</li> <li>M\u00e1quinas de Estados Finitos (FSM): Gerenciam diferentes estados e transi\u00e7\u00f5es de um sistema com base em eventos ou condi\u00e7\u00f5es.</li> </ul>"},{"location":"aulas/iot/modulos/modulo16.html#2-controle-pid-no-arduino","title":"2. Controle PID no Arduino","text":""},{"location":"aulas/iot/modulos/modulo16.html#21-fundamentos-do-controle-pid","title":"2.1 Fundamentos do Controle PID","text":"<p>O controle PID \u00e9 uma t\u00e9cnica amplamente utilizada para regular sistemas din\u00e2micos. Ele consiste em tr\u00eas componentes:</p> <ul> <li>Proporcional (P): Reage ao erro atual.</li> <li>Integral (I): Reage \u00e0 soma dos erros passados.</li> <li>Derivativo (D): Reage \u00e0 taxa de varia\u00e7\u00e3o do erro.</li> </ul>"},{"location":"aulas/iot/modulos/modulo16.html#22-implementacao-do-controle-pid","title":"2.2 Implementa\u00e7\u00e3o do Controle PID","text":"<p>Para implementar o controle PID no Arduino, utilizaremos a biblioteca PID_v1, que facilita o processo de ajuste e aplica\u00e7\u00e3o do algoritmo.</p>"},{"location":"aulas/iot/modulos/modulo16.html#23-exemplo-de-codigo-para-controle-de-temperatura-com-pid","title":"2.3 Exemplo de C\u00f3digo para Controle de Temperatura com PID","text":"<pre><code>#include &lt;PID_v1.h&gt;\n\n// Defini\u00e7\u00e3o dos pinos\nconst int pinoSensor = A0; // Sensor de temperatura\nconst int pinoAquecedor = 9; // Atuador (exemplo: aquecedor)\n\n// Vari\u00e1veis para leitura do sensor\ndouble Setpoint, Input, Output;\n\n// Par\u00e2metros do PID\ndouble Kp = 2.0, Ki = 5.0, Kd = 1.0;\n\n// Cria\u00e7\u00e3o do objeto PID\nPID myPID(&amp;Input, &amp;Output, &amp;Setpoint, Kp, Ki, Kd, DIRECT);\n\nvoid setup() {\n    Serial.begin(9600);\n    pinMode(pinoAquecedor, OUTPUT);\n\n    // Define o ponto de ajuste (temperatura desejada)\n    Setpoint = 25.0; // 25\u00b0C\n\n    // Inicializa o PID\n    myPID.SetMode(AUTOMATIC);\n}\n\nvoid loop() {\n    // Leitura do sensor de temperatura\n    int leituraAnalogica = analogRead(pinoSensor);\n    Input = leituraAnalogica * (5.0 / 1023.0) * 100; // Convers\u00e3o exemplo\n\n    // Computa o PID\n    myPID.Compute();\n\n    // Controla o aquecedor\n    analogWrite(pinoAquecedor, Output);\n\n    // Exibe os valores no Monitor Serial\n    Serial.print(\"Temperatura: \");\n    Serial.print(Input);\n    Serial.print(\"\u00b0C\\tOutput: \");\n    Serial.println(Output);\n\n    delay(1000);\n}\n</code></pre> <p>Explica\u00e7\u00e3o:</p> <ul> <li>Leitura do Sensor: Obt\u00e9m a temperatura atual do sensor conectado ao pino A0.</li> <li>Algoritmo PID: Calcula a sa\u00edda necess\u00e1ria para ajustar a temperatura em dire\u00e7\u00e3o ao ponto de ajuste definido.</li> <li>Controle do Atuador: Ajusta a pot\u00eancia do aquecedor com base na sa\u00edda do PID.</li> <li>Monitoramento: Exibe a temperatura e a sa\u00edda do PID no Monitor Serial para an\u00e1lise e ajustes.</li> </ul>"},{"location":"aulas/iot/modulos/modulo16.html#3-maquinas-de-estados-finitos-fsm","title":"3. M\u00e1quinas de Estados Finitos (FSM)","text":""},{"location":"aulas/iot/modulos/modulo16.html#31-conceitos-basicos-de-fsm","title":"3.1 Conceitos B\u00e1sicos de FSM","text":"<p>Uma M\u00e1quina de Estados Finitos (FSM) \u00e9 um modelo computacional usado para projetar algoritmos que podem estar em um n\u00famero finito de estados. As transi\u00e7\u00f5es entre esses estados s\u00e3o determinadas por eventos ou condi\u00e7\u00f5es espec\u00edficas.</p>"},{"location":"aulas/iot/modulos/modulo16.html#32-implementacao-de-fsm-no-arduino","title":"3.2 Implementa\u00e7\u00e3o de FSM no Arduino","text":"<p>FSMs s\u00e3o \u00fateis para gerenciar diferentes modos de opera\u00e7\u00e3o em sistemas complexos, como rob\u00f4s que precisam alternar entre modos de movimento, detec\u00e7\u00e3o e resposta.</p>"},{"location":"aulas/iot/modulos/modulo16.html#33-exemplo-de-codigo-para-fsm-em-um-sistema-de-iluminacao-automatica","title":"3.3 Exemplo de C\u00f3digo para FSM em um Sistema de Ilumina\u00e7\u00e3o Autom\u00e1tica","text":"<pre><code>enum Estado {\n    APAGADO,\n    LIGANDO,\n    LIGADO,\n    DESLIGANDO\n};\n\nEstado estadoAtual = APAGADO;\n\nconst int pinoLuz = 8;\nconst int tempoTransicao = 2000; // 2 segundos\n\nunsigned long tempoInicio;\n\nvoid setup() {\n    pinMode(pinoLuz, OUTPUT);\n    digitalWrite(pinoLuz, LOW);\n}\n\nvoid loop() {\n    switch (estadoAtual) {\n        case APAGADO:\n            // Aguarda comando para ligar\n            if (/* condi\u00e7\u00e3o para ligar */) {\n                estadoAtual = LIGANDO;\n                tempoInicio = millis();\n            }\n            break;\n\n        case LIGANDO:\n            digitalWrite(pinoLuz, HIGH);\n            if (millis() - tempoInicio &gt;= tempoTransicao) {\n                estadoAtual = LIGADO;\n            }\n            break;\n\n        case LIGADO:\n            // Aguarda comando para desligar\n            if (/* condi\u00e7\u00e3o para desligar */) {\n                estadoAtual = DESLIGANDO;\n                tempoInicio = millis();\n            }\n            break;\n\n        case DESLIGANDO:\n            digitalWrite(pinoLuz, LOW);\n            if (millis() - tempoInicio &gt;= tempoTransicao) {\n                estadoAtual = APAGADO;\n            }\n            break;\n    }\n}\n</code></pre> <p>Explica\u00e7\u00e3o:</p> <ul> <li>Estados Definidos: APAGADO, LIGANDO, LIGADO e DESLIGANDO representam os diferentes modos do sistema de ilumina\u00e7\u00e3o.</li> <li>Transi\u00e7\u00f5es: As mudan\u00e7as de estado s\u00e3o acionadas por condi\u00e7\u00f5es espec\u00edficas, como um bot\u00e3o sendo pressionado.</li> <li>Temporiza\u00e7\u00e3o: Utiliza <code>millis()</code> para gerenciar o tempo de transi\u00e7\u00e3o entre os estados.</li> </ul>"},{"location":"aulas/iot/modulos/modulo16.html#4-filtragem-avancada-de-dados","title":"4. Filtragem Avan\u00e7ada de Dados","text":""},{"location":"aulas/iot/modulos/modulo16.html#41-filtros-passa-baixa-passa-alta-e-passa-banda","title":"4.1 Filtros Passa-Baixa, Passa-Alta e Passa-Banda","text":"<p>Filtros s\u00e3o utilizados para remover ru\u00eddos e melhorar a qualidade dos dados dos sensores.</p> <ul> <li>Passa-Baixa: Permite a passagem de frequ\u00eancias abaixo de um determinado corte, atenuando as acima.</li> <li>Passa-Alta: Permite a passagem de frequ\u00eancias acima de um determinado corte, atenuando as abaixo.</li> <li>Passa-Banda: Permite a passagem de uma faixa espec\u00edfica de frequ\u00eancias, atenuando as fora dessa faixa.</li> </ul>"},{"location":"aulas/iot/modulos/modulo16.html#42-implementacao-de-filtros-digitais-no-arduino","title":"4.2 Implementa\u00e7\u00e3o de Filtros Digitais no Arduino","text":"<p>Os filtros digitais podem ser implementados diretamente no c\u00f3digo do Arduino para processar os dados dos sensores em tempo real.</p>"},{"location":"aulas/iot/modulos/modulo16.html#43-exemplo-de-codigo-para-filtro-de-media-movel","title":"4.3 Exemplo de C\u00f3digo para Filtro de M\u00e9dia M\u00f3vel","text":"<pre><code>const int pinoSensor = A0;\nconst int tamanhoJanela = 5;\nint leituras[tamanhoJanela];\nint indice = 0;\nlong soma = 0;\nfloat media = 0;\n\nvoid setup() {\n    Serial.begin(9600);\n    for (int i = 0; i &lt; tamanhoJanela; i++) {\n        leituras[i] = 0;\n    }\n}\n\nvoid loop() {\n    // Leitura atual\n    int leitura = analogRead(pinoSensor);\n\n    // Subtrai a leitura que ser\u00e1 descartada\n    soma = soma - leituras[indice];\n\n    // Adiciona a nova leitura\n    leituras[indice] = leitura;\n    soma = soma + leituras[indice];\n\n    // Avan\u00e7a o \u00edndice e reinicia se necess\u00e1rio\n    indice = (indice + 1) % tamanhoJanela;\n\n    // Calcula a m\u00e9dia\n    media = soma / (float)tamanhoJanela;\n\n    // Exibe a m\u00e9dia\n    Serial.print(\"M\u00e9dia: \");\n    Serial.println(media);\n\n    delay(500);\n}\n</code></pre> <p>Explica\u00e7\u00e3o:</p> <ul> <li>Janela de M\u00e9dia: Calcula a m\u00e9dia das \u00faltimas 5 leituras para suavizar os dados.</li> <li>Atualiza\u00e7\u00e3o da Soma: Subtrai a leitura mais antiga e adiciona a nova para manter a soma atualizada.</li> <li>C\u00e1lculo da M\u00e9dia: Divide a soma pelo tamanho da janela para obter a m\u00e9dia m\u00f3vel.</li> <li>Aplica\u00e7\u00e3o Pr\u00e1tica: Reduz flutua\u00e7\u00f5es r\u00e1pidas nos dados dos sensores, melhorando a precis\u00e3o das medi\u00e7\u00f5es.</li> </ul>"},{"location":"aulas/iot/modulos/modulo16.html#5-exercicios-praticos","title":"5. Exerc\u00edcios Pr\u00e1ticos","text":""},{"location":"aulas/iot/modulos/modulo16.html#exercicio-1-implementar-um-controle-pid-para-velocidade-de-motor-dc","title":"Exerc\u00edcio 1: Implementar um Controle PID para Velocidade de Motor DC","text":"<ul> <li> <p>Tarefa: Desenvolva um sistema que regula a velocidade de um motor DC utilizando controle PID. Ajuste os par\u00e2metros PID para alcan\u00e7ar uma resposta est\u00e1vel e eficiente.</p> </li> <li> <p>Dicas:</p> </li> <li>Utilize um encoder para medir a velocidade real do motor.</li> <li>Teste diferentes valores de Kp, Ki e Kd para encontrar os melhores ajustes.</li> <li> <p>Monitore a velocidade e o erro no Monitor Serial para ajustes finos.</p> </li> <li> <p>Exemplo de C\u00f3digo:   Utilize o exemplo de controle de temperatura apresentado na se\u00e7\u00e3o 2.3, adaptando-o para controlar a velocidade do motor com base nas leituras do encoder.</p> </li> </ul>"},{"location":"aulas/iot/modulos/modulo16.html#exercicio-2-desenvolver-uma-maquina-de-estados-para-um-sistema-de-alarme","title":"Exerc\u00edcio 2: Desenvolver uma M\u00e1quina de Estados para um Sistema de Alarme","text":"<ul> <li> <p>Tarefa: Crie uma m\u00e1quina de estados finitos para gerenciar um sistema de alarme que alterna entre os estados APAGADO, ARMADO e ALARMANDO com base em detec\u00e7\u00f5es de sensores de movimento e bot\u00f5es de controle.</p> </li> <li> <p>Dicas:</p> </li> <li>Defina claramente os estados e as transi\u00e7\u00f5es entre eles.</li> <li>Utilize vari\u00e1veis globais para manter o estado atual.</li> <li> <p>Implemente fun\u00e7\u00f5es para cada transi\u00e7\u00e3o de estado.</p> </li> <li> <p>Exemplo de C\u00f3digo:   Utilize o exemplo de FSM apresentado na se\u00e7\u00e3o 3.3, adaptando-o para incluir um estado ARMADO e condi\u00e7\u00f5es de transi\u00e7\u00e3o baseadas em sensores de movimento.</p> </li> </ul>"},{"location":"aulas/iot/modulos/modulo16.html#exercicio-3-aplicar-filtros-digitais-em-leituras-de-sensores","title":"Exerc\u00edcio 3: Aplicar Filtros Digitais em Leituras de Sensores","text":"<ul> <li> <p>Tarefa: Implemente diferentes tipos de filtros (m\u00e9dia m\u00f3vel, passa-baixa) nas leituras de um sensor de temperatura para melhorar a precis\u00e3o dos dados.</p> </li> <li> <p>Dicas:</p> </li> <li>Compare os resultados dos diferentes filtros.</li> <li>Ajuste o tamanho da janela de m\u00e9dia m\u00f3vel para observar os efeitos.</li> <li> <p>Visualize as leituras filtradas e n\u00e3o filtradas no Monitor Serial.</p> </li> <li> <p>Exemplo de C\u00f3digo:   Utilize o exemplo de filtro de m\u00e9dia m\u00f3vel apresentado na se\u00e7\u00e3o 4.3 e experimente implementar um filtro passa-baixa simples para comparar os resultados.</p> </li> </ul>"},{"location":"aulas/iot/modulos/modulo16.html#6-conceitos-importantes","title":"6. Conceitos Importantes","text":""},{"location":"aulas/iot/modulos/modulo16.html#61-algoritmos-de-controle-pid","title":"6.1 Algoritmos de Controle PID","text":"<ul> <li>Defini\u00e7\u00e3o: Algoritmo que ajusta a sa\u00edda de um sistema com base no erro atual, acumulado e na taxa de varia\u00e7\u00e3o do erro.</li> <li>Aplica\u00e7\u00f5es: Controle de temperatura, velocidade de motores, posi\u00e7\u00e3o de servos.</li> <li>Ajuste de Par\u00e2metros: Import\u00e2ncia de ajustar corretamente Kp, Ki e Kd para obter uma resposta adequada.</li> </ul>"},{"location":"aulas/iot/modulos/modulo16.html#62-maquinas-de-estados-finitos-fsm","title":"6.2 M\u00e1quinas de Estados Finitos (FSM)","text":"<ul> <li>Defini\u00e7\u00e3o: Modelo de computa\u00e7\u00e3o que consiste em um n\u00famero finito de estados e transi\u00e7\u00f5es entre eles baseadas em eventos ou condi\u00e7\u00f5es.</li> <li>Vantagens: Facilita o gerenciamento de sistemas complexos com m\u00faltiplos modos de opera\u00e7\u00e3o.</li> <li>Implementa\u00e7\u00e3o: Utiliza\u00e7\u00e3o de estruturas de controle como <code>switch-case</code> no Arduino para gerenciar estados.</li> </ul>"},{"location":"aulas/iot/modulos/modulo16.html#63-filtragem-de-dados","title":"6.3 Filtragem de Dados","text":"<ul> <li>Objetivo: Remover ru\u00eddos e melhorar a qualidade dos dados coletados dos sensores.</li> <li>T\u00e9cnicas: M\u00e9dia m\u00f3vel, filtros passa-baixa, filtros Kalman.</li> <li>Aplica\u00e7\u00f5es: Processamento de sinais de sensores, estabiliza\u00e7\u00e3o de leituras.</li> </ul>"},{"location":"aulas/iot/modulos/modulo16.html#64-controle-de-movimento-avancado","title":"6.4 Controle de Movimento Avan\u00e7ado","text":"<ul> <li>Trajet\u00f3rias Suaves: Planejamento de movimentos que evitam oscila\u00e7\u00f5es e movimentos bruscos.</li> <li>Controle de Acelera\u00e7\u00e3o: Ajuste gradual da velocidade para evitar sobrecargas nos atuadores.</li> <li>Sincroniza\u00e7\u00e3o de Atuadores: Coordena\u00e7\u00e3o de m\u00faltiplos motores e servos para movimentos complexos.</li> </ul>"},{"location":"aulas/iot/modulos/modulo16.html#65-boas-praticas-no-uso-de-algoritmos-de-controle","title":"6.5 Boas Pr\u00e1ticas no Uso de Algoritmos de Controle","text":"<ul> <li>Teste e Valida\u00e7\u00e3o: Testar os algoritmos em diferentes condi\u00e7\u00f5es para garantir robustez.</li> <li>Monitoramento: Utilizar o Monitor Serial para acompanhar o comportamento dos algoritmos em tempo real.</li> <li>Documenta\u00e7\u00e3o: Manter registros claros dos par\u00e2metros utilizados e dos resultados obtidos durante os testes.</li> </ul>"},{"location":"aulas/iot/modulos/modulo16.html#7-recursos-adicionais","title":"7. Recursos Adicionais","text":"<ul> <li> <p>Documenta\u00e7\u00e3o Oficial do Arduino:</p> </li> <li> <p>PID Library</p> </li> <li>Servo Library</li> <li> <p>State Machine Library</p> </li> <li> <p>Tutoriais e Guias:</p> </li> <li> <p>Implementando Controle PID no Arduino</p> </li> <li>M\u00e1quinas de Estados Finitos com Arduino</li> <li> <p>Filtragem de Dados em Projetos Arduino</p> </li> <li> <p>V\u00eddeos Educacionais:</p> </li> <li> <p>Controle PID com Arduino</p> </li> <li>M\u00e1quinas de Estados Finitos para Iniciantes</li> <li>T\u00e9cnicas de Filtragem de Dados no Arduino</li> </ul>"},{"location":"aulas/iot/modulos/modulo16.html#8-exemplos-praticos","title":"8. Exemplos Pr\u00e1ticos","text":""},{"location":"aulas/iot/modulos/modulo16.html#81-controle-de-temperatura-com-pid","title":"8.1 Controle de Temperatura com PID","text":"<p>Este exemplo demonstra como implementar um controlador PID para regular a temperatura de um ambiente utilizando um sensor de temperatura e um atuador (como um aquecedor).</p> <pre><code>#include &lt;PID_v1.h&gt;\n\n// Defini\u00e7\u00e3o dos pinos\nconst int pinoSensor = A0; // Sensor de temperatura\nconst int pinoAquecedor = 9; // Atuador (exemplo: aquecedor)\n\n// Vari\u00e1veis para leitura do sensor\ndouble Setpoint, Input, Output;\n\n// Par\u00e2metros do PID\ndouble Kp = 2.0, Ki = 5.0, Kd = 1.0;\n\n// Cria\u00e7\u00e3o do objeto PID\nPID myPID(&amp;Input, &amp;Output, &amp;Setpoint, Kp, Ki, Kd, DIRECT);\n\nvoid setup() {\n    Serial.begin(9600);\n    pinMode(pinoAquecedor, OUTPUT);\n\n    // Define o ponto de ajuste (temperatura desejada)\n    Setpoint = 25.0; // 25\u00b0C\n\n    // Inicializa o PID\n    myPID.SetMode(AUTOMATIC);\n}\n\nvoid loop() {\n    // Leitura do sensor de temperatura\n    int leituraAnalogica = analogRead(pinoSensor);\n    Input = leituraAnalogica * (5.0 / 1023.0) * 100; // Convers\u00e3o exemplo\n\n    // Computa o PID\n    myPID.Compute();\n\n    // Controla o aquecedor\n    analogWrite(pinoAquecedor, Output);\n\n    // Exibe os valores no Monitor Serial\n    Serial.print(\"Temperatura: \");\n    Serial.print(Input);\n    Serial.print(\"\u00b0C\\tOutput: \");\n    Serial.println(Output);\n\n    delay(1000);\n}\n</code></pre> <p>Explica\u00e7\u00e3o:</p> <ul> <li>Leitura do Sensor: Obt\u00e9m a temperatura atual do sensor conectado ao pino A0.</li> <li>Algoritmo PID: Calcula a sa\u00edda necess\u00e1ria para ajustar a temperatura em dire\u00e7\u00e3o ao ponto de ajuste definido.</li> <li>Controle do Atuador: Ajusta a pot\u00eancia do aquecedor com base na sa\u00edda do PID.</li> <li>Monitoramento: Exibe a temperatura e a sa\u00edda do PID no Monitor Serial para an\u00e1lise e ajustes.</li> </ul>"},{"location":"aulas/iot/modulos/modulo16.html#82-maquina-de-estados-para-sistema-de-alarme","title":"8.2 M\u00e1quina de Estados para Sistema de Alarme","text":"<p>Este exemplo demonstra como utilizar uma m\u00e1quina de estados finitos para gerenciar um sistema de alarme com diferentes modos de opera\u00e7\u00e3o.</p> <pre><code>enum Estado {\n    APAGADO,\n    ARMADO,\n    ALARMANDO\n};\n\nEstado estadoAtual = APAGADO;\n\nconst int pinoSensor = 7; // Sensor de movimento\nconst int pinoAlarme = 8; // Atuador (exemplo: buzzer)\nconst int pinoBotao = 2; // Bot\u00e3o de controle\n\nunsigned long tempoInicio;\n\nvoid setup() {\n    Serial.begin(9600);\n    pinMode(pinoSensor, INPUT);\n    pinMode(pinoAlarme, OUTPUT);\n    pinMode(pinoBotao, INPUT_PULLUP);\n}\n\nvoid loop() {\n    bool botaoPressionado = digitalRead(pinoBotao) == LOW;\n    bool movimentoDetectado = digitalRead(pinoSensor) == HIGH;\n\n    switch (estadoAtual) {\n        case APAGADO:\n            if (botaoPressionado) {\n                estadoAtual = ARMADO;\n                Serial.println(\"Sistema Armado.\");\n            }\n            break;\n\n        case ARMADO:\n            if (movimentoDetectado) {\n                estadoAtual = ALARMANDO;\n                tempoInicio = millis();\n                Serial.println(\"Movimento Detectado! Alarme Ativado!\");\n            }\n            if (botaoPressionado) {\n                estadoAtual = APAGADO;\n                Serial.println(\"Sistema Desarmado.\");\n            }\n            break;\n\n        case ALARMANDO:\n            digitalWrite(pinoAlarme, HIGH);\n            if (millis() - tempoInicio &gt;= 5000) { // Alarme por 5 segundos\n                digitalWrite(pinoAlarme, LOW);\n                estadoAtual = APAGADO;\n                Serial.println(\"Alarme Desativado.\");\n            }\n            break;\n    }\n}\n</code></pre> <p>Explica\u00e7\u00e3o:</p> <ul> <li>Estados Definidos: APAGADO, ARMADO e ALARMANDO representam os diferentes modos do sistema de alarme.</li> <li>Transi\u00e7\u00f5es: Mudan\u00e7as de estado s\u00e3o acionadas pelo bot\u00e3o de controle e pela detec\u00e7\u00e3o de movimento.</li> <li>Acionamento do Alarme: Quando em estado ALARMANDO, o alarme \u00e9 ativado por 5 segundos antes de retornar ao estado APAGADO.</li> </ul>"},{"location":"aulas/iot/modulos/modulo16.html#83-aplicacao-de-filtros-passa-baixa-em-leituras-de-sensor","title":"8.3 Aplica\u00e7\u00e3o de Filtros Passa-Baixa em Leituras de Sensor","text":"<p>Este exemplo demonstra como implementar um filtro passa-baixa para suavizar as leituras de um sensor de temperatura.</p> <pre><code>const int pinoSensor = A0;\nconst float alpha = 0.1; // Constante do filtro (0 &lt; alpha &lt; 1)\nfloat temperaturaFiltrada = 0.0;\n\nvoid setup() {\n    Serial.begin(9600);\n}\n\nvoid loop() {\n    // Leitura do sensor de temperatura\n    int leitura = analogRead(pinoSensor);\n    float temperatura = leitura * (5.0 / 1023.0) * 100; // Convers\u00e3o exemplo\n\n    // Aplica\u00e7\u00e3o do filtro passa-baixa\n    temperaturaFiltrada = alpha * temperatura + (1 - alpha) * temperaturaFiltrada;\n\n    // Exibe as temperaturas no Monitor Serial\n    Serial.print(\"Temperatura Bruta: \");\n    Serial.print(temperatura);\n    Serial.print(\"\u00b0C\\tTemperatura Filtrada: \");\n    Serial.println(temperaturaFiltrada);\n\n    delay(1000);\n}\n</code></pre> <p>Explica\u00e7\u00e3o:</p> <ul> <li>Filtro Passa-Baixa: Suaviza as leituras removendo varia\u00e7\u00f5es r\u00e1pidas e ru\u00eddos.</li> <li>Constante Alpha: Determina a influ\u00eancia das leituras atuais em rela\u00e7\u00e3o \u00e0s passadas. Valores menores resultam em maior suaviza\u00e7\u00e3o.</li> <li>Monitoramento: Compara a temperatura bruta com a filtrada no Monitor Serial para observar os efeitos do filtro.</li> </ul>"},{"location":"aulas/iot/modulos/modulo16.html#9-conceitos-importantes","title":"9. Conceitos Importantes","text":""},{"location":"aulas/iot/modulos/modulo16.html#91-algoritmos-de-controle-pid","title":"9.1 Algoritmos de Controle PID","text":"<ul> <li>Defini\u00e7\u00e3o: Algoritmo que ajusta a sa\u00edda de um sistema com base no erro atual, acumulado e na taxa de varia\u00e7\u00e3o do erro.</li> <li>Aplica\u00e7\u00f5es: Controle de temperatura, velocidade de motores, posi\u00e7\u00e3o de servos.</li> <li>Ajuste de Par\u00e2metros: Import\u00e2ncia de ajustar corretamente Kp, Ki e Kd para obter uma resposta adequada.</li> </ul>"},{"location":"aulas/iot/modulos/modulo16.html#92-maquinas-de-estados-finitos-fsm","title":"9.2 M\u00e1quinas de Estados Finitos (FSM)","text":"<ul> <li>Defini\u00e7\u00e3o: Modelo de computa\u00e7\u00e3o que consiste em um n\u00famero finito de estados e transi\u00e7\u00f5es entre eles baseadas em eventos ou condi\u00e7\u00f5es.</li> <li>Vantagens: Facilita o gerenciamento de sistemas complexos com m\u00faltiplos modos de opera\u00e7\u00e3o.</li> <li>Implementa\u00e7\u00e3o: Utiliza\u00e7\u00e3o de estruturas de controle como <code>switch-case</code> no Arduino para gerenciar estados.</li> </ul>"},{"location":"aulas/iot/modulos/modulo16.html#93-filtragem-de-dados","title":"9.3 Filtragem de Dados","text":"<ul> <li>Objetivo: Remover ru\u00eddos e melhorar a qualidade dos dados coletados dos sensores.</li> <li>T\u00e9cnicas: M\u00e9dia m\u00f3vel, filtros passa-baixa, filtros Kalman.</li> <li>Aplica\u00e7\u00f5es: Processamento de sinais de sensores, estabiliza\u00e7\u00e3o de leituras.</li> </ul>"},{"location":"aulas/iot/modulos/modulo16.html#94-controle-de-movimento-avancado","title":"9.4 Controle de Movimento Avan\u00e7ado","text":"<ul> <li>Trajet\u00f3rias Suaves: Planejamento de movimentos que evitam oscila\u00e7\u00f5es e movimentos bruscos.</li> <li>Controle de Acelera\u00e7\u00e3o: Ajuste gradual da velocidade para evitar sobrecargas nos atuadores.</li> <li>Sincroniza\u00e7\u00e3o de Atuadores: Coordena\u00e7\u00e3o de m\u00faltiplos motores e servos para movimentos complexos.</li> </ul>"},{"location":"aulas/iot/modulos/modulo16.html#95-boas-praticas-no-uso-de-algoritmos-de-controle","title":"9.5 Boas Pr\u00e1ticas no Uso de Algoritmos de Controle","text":"<ul> <li>Teste e Valida\u00e7\u00e3o: Testar os algoritmos em diferentes condi\u00e7\u00f5es para garantir robustez.</li> <li>Monitoramento: Utilizar o Monitor Serial para acompanhar o comportamento dos algoritmos em tempo real.</li> <li>Documenta\u00e7\u00e3o: Manter registros claros dos par\u00e2metros utilizados e dos resultados obtidos durante os testes.</li> </ul>"},{"location":"aulas/iot/modulos/modulo16.html#10-recursos-adicionais","title":"10. Recursos Adicionais","text":"<ul> <li> <p>Documenta\u00e7\u00e3o Oficial do Arduino:</p> </li> <li> <p>PID Library</p> </li> <li>Servo Library</li> <li> <p>State Machine Library</p> </li> <li> <p>Tutoriais e Guias:</p> </li> <li> <p>Implementando Controle PID no Arduino</p> </li> <li>M\u00e1quinas de Estados Finitos com Arduino</li> <li> <p>Filtragem de Dados em Projetos Arduino</p> </li> <li> <p>V\u00eddeos Educacionais:</p> </li> <li> <p>Controle PID com Arduino</p> </li> <li>M\u00e1quinas de Estados Finitos para Iniciantes</li> <li>T\u00e9cnicas de Filtragem de Dados no Arduino</li> </ul>"},{"location":"aulas/iot/modulos/modulo16.html#11-conclusao-do-modulo","title":"11. Conclus\u00e3o do M\u00f3dulo","text":"<p>Neste m\u00f3dulo, voc\u00ea aprendeu:</p> <ul> <li>Algoritmos de Controle PID: Entendeu os fundamentos do controle PID e como implement\u00e1-lo no Arduino para regular sistemas din\u00e2micos.</li> <li>M\u00e1quinas de Estados Finitos (FSM): Aprendeu a gerenciar diferentes modos de opera\u00e7\u00e3o em sistemas automatizados utilizando FSM.</li> <li>Filtragem Avan\u00e7ada de Dados: Aplicou t\u00e9cnicas de filtragem para melhorar a precis\u00e3o das leituras dos sensores.</li> <li>Controle de Movimento Avan\u00e7ado: Desenvolveu habilidades para planejar e executar movimentos suaves e coordenados em projetos com m\u00faltiplos atuadores.</li> <li>Boas Pr\u00e1ticas: Compreendeu a import\u00e2ncia do teste, monitoramento e documenta\u00e7\u00e3o na implementa\u00e7\u00e3o de algoritmos de controle.</li> </ul> <p>Com este conhecimento, voc\u00ea est\u00e1 preparado para desenvolver sistemas mais sofisticados e eficientes, capazes de responder de maneira inteligente a diferentes condi\u00e7\u00f5es e desafios.</p>"},{"location":"aulas/iot/modulos/modulo16.html#12-proximos-passos","title":"12. Pr\u00f3ximos Passos","text":"<ul> <li>Revisar todo o conte\u00fado do m\u00f3dulo para consolidar o aprendizado.</li> <li>Explorar projetos avan\u00e7ados que combinam algoritmos de controle com outros conceitos aprendidos, como rob\u00f3tica e IoT.</li> <li>Participar de comunidades e f\u00f3runs de Arduino para trocar experi\u00eancias e obter suporte cont\u00ednuo.</li> <li>Considerar cursos avan\u00e7ados ou especializa\u00e7\u00f5es em \u00e1reas espec\u00edficas de interesse, como controle autom\u00e1tico, processamento de sinais ou design de sistemas embarcados.</li> <li>Desenvolver seu pr\u00f3prio portf\u00f3lio de projetos Arduino, aplicando os conceitos de controle avan\u00e7ado para resolver problemas reais.</li> </ul> <p>Se tiver d\u00favidas ou precisar de assist\u00eancia, continue participando de comunidades de aprendizagem ou consulte os recursos adicionais fornecidos ao longo dos m\u00f3dulos.</p> <p>**Parab\u00e9ns por concluir o M\u00f3dulo 15! Continue explorando e criando projetos incr\u00edveis com Arduino!</p>"},{"location":"aulas/iot/modulos/modulo17.html","title":"M\u00f3dulo 17: Gest\u00e3o de Energia e Efici\u00eancia em Projetos Arduino","text":"<p>Bem-vindo ao M\u00f3dulo 17 do curso \"Programa\u00e7\u00e3o em Arduino: Conceitos Fundamentais sem Hardware\". Neste m\u00f3dulo, voc\u00ea ir\u00e1 aprender sobre gest\u00e3o de energia e efici\u00eancia energ\u00e9tica em projetos Arduino. Com o crescimento dos dispositivos IoT e a necessidade de solu\u00e7\u00f5es sustent\u00e1veis, entender como otimizar o consumo de energia dos seus projetos \u00e9 essencial. Este m\u00f3dulo aborda t\u00e9cnicas e pr\u00e1ticas para reduzir o consumo de energia, prolongar a vida \u00fatil das baterias e garantir que seus projetos sejam mais sustent\u00e1veis e eficientes.</p>"},{"location":"aulas/iot/modulos/modulo17.html#objetivos-do-modulo","title":"Objetivos do M\u00f3dulo","text":"<ul> <li>Compreender os fundamentos do consumo de energia em projetos Arduino.</li> <li>Aprender a medir e analisar o consumo de energia de um circuito.</li> <li>Implementar modos de economia de energia no Arduino para prolongar a vida \u00fatil das baterias.</li> <li>Selecionar componentes de baixo consumo e otimizar o uso de energia em projetos.</li> <li>Aplicar t\u00e9cnicas de gerenciamento de energia em projetos IoT.</li> <li>Resolver exerc\u00edcios pr\u00e1ticos para consolidar o conhecimento sobre gest\u00e3o de energia e efici\u00eancia.</li> </ul>"},{"location":"aulas/iot/modulos/modulo17.html#1-introducao-a-gestao-de-energia","title":"1. Introdu\u00e7\u00e3o \u00e0 Gest\u00e3o de Energia","text":""},{"location":"aulas/iot/modulos/modulo17.html#11-importancia-da-gestao-de-energia","title":"1.1 Import\u00e2ncia da Gest\u00e3o de Energia","text":"<p>A gest\u00e3o de energia em projetos Arduino \u00e9 crucial para:</p> <ul> <li>Prolongar a Vida \u00datil: Reduzir o consumo de energia permite que dispositivos alimentados por bateria funcionem por mais tempo.</li> <li>Sustentabilidade: Projetos eficientes energeticamente contribuem para a sustentabilidade ambiental.</li> <li>Desempenho e Estabilidade: Sistemas com gerenciamento de energia adequado evitam sobrecargas e falhas devido \u00e0 falta de energia.</li> </ul>"},{"location":"aulas/iot/modulos/modulo17.html#12-fontes-de-energia-para-arduino","title":"1.2 Fontes de Energia para Arduino","text":"<ul> <li>Baterias Recarreg\u00e1veis: Li-Ion, Li-Po, NiMH, alcalinas.</li> <li>Adaptadores de Energia: Conectados \u00e0 rede el\u00e9trica.</li> <li>Energia Solar: Utiliza\u00e7\u00e3o de pain\u00e9is solares para projetos sustent\u00e1veis.</li> <li>Supercapacitores: Para armazenamento de energia de alta pot\u00eancia em curto prazo.</li> </ul>"},{"location":"aulas/iot/modulos/modulo17.html#2-medicao-e-analise-do-consumo-de-energia","title":"2. Medi\u00e7\u00e3o e An\u00e1lise do Consumo de Energia","text":""},{"location":"aulas/iot/modulos/modulo17.html#21-ferramentas-para-medir-consumo-de-energia","title":"2.1 Ferramentas para Medir Consumo de Energia","text":"<ul> <li>Mult\u00edmetros: Medem corrente, tens\u00e3o e resist\u00eancia.</li> <li>Shunts de Corrente: Resistores de baixa resist\u00eancia usados para medir correntes elevadas.</li> <li>Sensores de Corrente: Como o ACS712, que fornece uma sa\u00edda anal\u00f3gica proporcional \u00e0 corrente.</li> <li>Analisadores de Energia: Ferramentas avan\u00e7adas para an\u00e1lise detalhada do consumo energ\u00e9tico.</li> </ul>"},{"location":"aulas/iot/modulos/modulo17.html#22-exemplo-de-codigo-para-medicao-de-corrente-com-acs712","title":"2.2 Exemplo de C\u00f3digo para Medi\u00e7\u00e3o de Corrente com ACS712","text":"<pre><code>const int pinoSensorCorrente = A0; // Pino anal\u00f3gico conectado ao ACS712\nconst float fatorConversao = 5.0 / 1023.0; // Tens\u00e3o de refer\u00eancia / resolu\u00e7\u00e3o ADC\n\nvoid setup() {\n    Serial.begin(9600);\n    pinMode(pinoSensorCorrente, INPUT);\n}\n\nvoid loop() {\n    int leitura = analogRead(pinoSensorCorrente);\n    float tensao = leitura * fatorConversao;\n    float corrente = (tensao - 2.5) / 0.185; // 2.5V \u00e9 o ponto de refer\u00eancia, 0.185 V/A para ACS712 5A\n\n    Serial.print(\"Corrente: \");\n    Serial.print(corrente);\n    Serial.println(\" A\");\n\n    delay(1000);\n}\n</code></pre> <p>Explica\u00e7\u00e3o:</p> <ul> <li>Leitura do Sensor: O sensor ACS712 fornece uma tens\u00e3o que varia com a corrente. O ponto de refer\u00eancia \u00e9 2.5V no meio da faixa.</li> <li>C\u00e1lculo da Corrente: Subtrai-se 2.5V da leitura e divide-se pelo fator de convers\u00e3o espec\u00edfico do sensor (0.185 V/A para o modelo 5A).</li> <li>Monitoramento: Exibe a corrente medida no Monitor Serial para an\u00e1lise.</li> </ul>"},{"location":"aulas/iot/modulos/modulo17.html#3-modos-de-economia-de-energia-no-arduino","title":"3. Modos de Economia de Energia no Arduino","text":""},{"location":"aulas/iot/modulos/modulo17.html#31-sleep-modes-do-arduino","title":"3.1 Sleep Modes do Arduino","text":"<p>O Arduino possui diferentes modos de opera\u00e7\u00e3o para reduzir o consumo de energia quando n\u00e3o est\u00e1 ativo:</p> <ul> <li>Idle Mode: Reduz algumas fun\u00e7\u00f5es sem interromper completamente o funcionamento.</li> <li>ADC Noise Reduction Mode: Minimiza o ru\u00eddo durante leituras anal\u00f3gicas.</li> <li>Power-save Mode: Desativa timers e mant\u00e9m apenas as interrup\u00e7\u00f5es essenciais.</li> <li>Standby e Power-down Modes: Minimiza o consumo ao m\u00e1ximo, desativando quase todos os componentes internos.</li> </ul>"},{"location":"aulas/iot/modulos/modulo17.html#32-implementacao-do-sleep-mode-no-arduino","title":"3.2 Implementa\u00e7\u00e3o do Sleep Mode no Arduino","text":"<p>Para implementar o modo de sleep no Arduino, utilizaremos a biblioteca LowPower.</p>"},{"location":"aulas/iot/modulos/modulo17.html#33-exemplo-de-codigo-para-sleep-mode-com-lowpower","title":"3.3 Exemplo de C\u00f3digo para Sleep Mode com LowPower","text":"<pre><code>#include &lt;LowPower.h&gt;\n\nconst int pinoBotao = 2; // Pino conectado a um bot\u00e3o\n\nvoid setup() {\n    pinMode(pinoBotao, INPUT_PULLUP);\n    Serial.begin(9600);\n    Serial.println(\"Sistema Inativo. Pressione o bot\u00e3o para acordar.\");\n}\n\nvoid loop() {\n    // Entra em modo de sleep por 8 segundos\n    LowPower.powerDown(SLEEP_8S, ADC_OFF, BOD_OFF);\n\n    // Verifica se o bot\u00e3o foi pressionado\n    if (digitalRead(pinoBotao) == LOW) {\n        Serial.println(\"Bot\u00e3o Pressionado! Sistema Ativo.\");\n        // C\u00f3digo para executar quando acordar\n        delay(1000); // Tempo para estabilizar\n    }\n}\n</code></pre> <p>Explica\u00e7\u00e3o:</p> <ul> <li>Biblioteca LowPower: Facilita a implementa\u00e7\u00e3o dos modos de sleep no Arduino.</li> <li>Modo powerDown: Reduz o consumo ao m\u00ednimo, mantendo apenas as interrup\u00e7\u00f5es essenciais.</li> <li>Despertar com Interrup\u00e7\u00e3o: No exemplo, o bot\u00e3o pressiona para acordar o sistema.</li> </ul>"},{"location":"aulas/iot/modulos/modulo17.html#4-selecao-de-componentes-de-baixo-consumo","title":"4. Sele\u00e7\u00e3o de Componentes de Baixo Consumo","text":""},{"location":"aulas/iot/modulos/modulo17.html#41-sensores-e-atuadores-eficientes","title":"4.1 Sensores e Atuadores Eficientes","text":"<ul> <li>Sensores de Baixo Consumo: Optar por sensores que possuem modos de baixa pot\u00eancia ou que consomem menos energia.</li> <li>Motores e Servos Eficientes: Selecionar motores com baixo consumo e que podem ser controlados eficientemente com PWM.</li> </ul>"},{"location":"aulas/iot/modulos/modulo17.html#42-reguladores-de-tensao-e-conversores-dc-dc","title":"4.2 Reguladores de Tens\u00e3o e Conversores DC-DC","text":"<ul> <li>Reguladores de Baixa Queda (LDO): Minimiza a dissipa\u00e7\u00e3o de energia ao converter tens\u00f5es.</li> <li>Conversores Buck e Boost: Mais eficientes que os LDOs para convers\u00f5es de tens\u00e3o maiores.</li> </ul>"},{"location":"aulas/iot/modulos/modulo17.html#43-exemplos-de-componentes-de-baixo-consumo","title":"4.3 Exemplos de Componentes de Baixo Consumo","text":"<ul> <li>OLED Displays: Menor consumo comparado a displays LCD tradicionais.</li> <li>M\u00f3dulos de Comunica\u00e7\u00e3o de Baixo Consumo: Como o ESP32 em modos de sleep ou LoRa para comunica\u00e7\u00e3o eficiente.</li> </ul>"},{"location":"aulas/iot/modulos/modulo17.html#5-gerenciamento-de-energia-em-projetos-iot","title":"5. Gerenciamento de Energia em Projetos IoT","text":""},{"location":"aulas/iot/modulos/modulo17.html#51-estrategias-para-dispositivos-alimentados-por-bateria","title":"5.1 Estrat\u00e9gias para Dispositivos Alimentados por Bateria","text":"<ul> <li>Uso de Sleep Modes: Minimizar o tempo ativo do microcontrolador.</li> <li>Transmiss\u00f5es Eficientes: Reduzir a frequ\u00eancia de comunica\u00e7\u00e3o sem fio.</li> <li>Componentes de Baixo Consumo: Selecionar sensores e atuadores que consomem menos energia.</li> </ul>"},{"location":"aulas/iot/modulos/modulo17.html#52-otimizacao-de-comunicacao-sem-fio","title":"5.2 Otimiza\u00e7\u00e3o de Comunica\u00e7\u00e3o Sem Fio","text":"<ul> <li>Protocolos de Baixo Consumo: Utilizar protocolos como MQTT com QoS apropriado ou LoRa para comunica\u00e7\u00f5es de longo alcance com baixo consumo.</li> <li>Duty Cycling: Alternar entre estados ativos e inativos de forma eficiente para reduzir o consumo geral.</li> </ul>"},{"location":"aulas/iot/modulos/modulo17.html#53-exemplo-de-projeto-iot-com-gestao-de-energia","title":"5.3 Exemplo de Projeto IoT com Gest\u00e3o de Energia","text":"<p>Desenvolva um sistema de monitoramento ambiental que coleta dados de sensores, envia informa\u00e7\u00f5es para a nuvem e entra em modo de sleep entre as transmiss\u00f5es para economizar energia.</p> <pre><code>#include &lt;Wire.h&gt;\n#include &lt;SPI.h&gt;\n#include &lt;LowPower.h&gt;\n#include &lt;WiFiNINA.h&gt;\n#include &lt;MQTT.h&gt;\n\n// Defini\u00e7\u00f5es de rede\nconst char* ssid = \"Seu_SSID\";\nconst char* password = \"Sua_Senha\";\n\n// Defini\u00e7\u00f5es do MQTT\nconst char* broker = \"broker.hivemq.com\";\nconst int port = 1883;\nconst char* topic = \"arduino/monitoramento\";\n\n// Pinos dos sensores\nconst int pinoSensorTemp = A0;\nconst int pinoSensorUmid = A1;\n\n// Inst\u00e2ncia do cliente MQTT\nWiFiClient net;\nMQTTClient client;\n\nvoid messageReceived(String &amp;topic, String &amp;payload) {\n    // N\u00e3o utilizado neste exemplo\n}\n\nvoid setup() {\n    Serial.begin(9600);\n    pinMode(pinoSensorTemp, INPUT);\n    pinMode(pinoSensorUmid, INPUT);\n\n    // Conecta ao Wi-Fi\n    WiFi.begin(ssid, password);\n    while (WiFi.status() != WL_CONNECTED) {\n        delay(500);\n        Serial.print(\".\");\n    }\n    Serial.println(\"Conectado ao Wi-Fi\");\n\n    // Conecta ao broker MQTT\n    client.begin(broker, port, net);\n    while (!client.connect(\"ArduinoClient\")) {\n        Serial.print(\".\");\n        delay(1000);\n    }\n    Serial.println(\"Conectado ao MQTT broker\");\n    client.onMessage(messageReceived);\n}\n\nvoid loop() {\n    // Leitura dos sensores\n    int leituraTemp = analogRead(pinoSensorTemp);\n    int leituraUmid = analogRead(pinoSensorUmid);\n\n    // Convers\u00e3o das leituras\n    float temperatura = leituraTemp * (5.0 / 1023.0) * 100; // Exemplo\n    float umidade = leituraUmid * (5.0 / 1023.0) * 100; // Exemplo\n\n    // Publica os dados no MQTT\n    String mensagem = \"Temperatura: \" + String(temperatura) + \"C, Umidade: \" + String(umidade) + \"%\";\n    client.publish(topic, mensagem);\n    Serial.println(\"Dados enviados: \" + mensagem);\n\n    // Desconecta do MQTT\n    client.disconnect();\n\n    // Entra em modo de sleep por 8 segundos\n    LowPower.powerDown(SLEEP_8S, ADC_OFF, BOD_OFF);\n}\n</code></pre> <p>Explica\u00e7\u00e3o:</p> <ul> <li>Conex\u00e3o ao Wi-Fi e MQTT: Estabelece conex\u00e3o com a rede Wi-Fi e o broker MQTT para envio de dados.</li> <li>Leitura e Convers\u00e3o de Sensores: L\u00ea os valores anal\u00f3gicos dos sensores e converte para unidades compreens\u00edveis.</li> <li>Publica\u00e7\u00e3o MQTT: Envia os dados para o t\u00f3pico especificado no broker MQTT.</li> <li>Modo de Sleep: Ap\u00f3s enviar os dados, o Arduino entra em modo de sleep por 8 segundos para economizar energia antes de repetir o processo.</li> </ul>"},{"location":"aulas/iot/modulos/modulo17.html#6-conceitos-importantes","title":"6. Conceitos Importantes","text":""},{"location":"aulas/iot/modulos/modulo17.html#61-eficiencia-energetica","title":"6.1 Efici\u00eancia Energ\u00e9tica","text":"<ul> <li>Defini\u00e7\u00e3o: Maximizar o desempenho do sistema enquanto minimiza o consumo de energia.</li> <li>T\u00e9cnicas: Uso de componentes de baixo consumo, otimiza\u00e7\u00e3o do c\u00f3digo para reduzir ciclos de processamento, e gerenciamento eficaz dos modos de opera\u00e7\u00e3o.</li> </ul>"},{"location":"aulas/iot/modulos/modulo17.html#62-modos-de-economia-de-energia","title":"6.2 Modos de Economia de Energia","text":"<ul> <li>Sleep Modes: Reduzem o consumo desligando partes do sistema que n\u00e3o est\u00e3o em uso.</li> <li>Wake-up Sources: Fontes que podem despertar o microcontrolador do modo de sleep, como interrup\u00e7\u00f5es de bot\u00f5es ou sensores.</li> <li>Duty Cycling: Alternar entre estados ativos e inativos para minimizar o consumo total.</li> </ul>"},{"location":"aulas/iot/modulos/modulo17.html#63-selecao-de-componentes","title":"6.3 Sele\u00e7\u00e3o de Componentes","text":"<ul> <li>Sensores e Atuadores: Escolher dispositivos que oferecem baixo consumo de energia sem comprometer o desempenho necess\u00e1rio.</li> <li>Reguladores de Tens\u00e3o: Utilizar reguladores eficientes para reduzir a dissipa\u00e7\u00e3o de energia.</li> <li>Displays e Interfaces: Optar por displays OLED ou LCD de baixo consumo e minimizar o uso de interfaces que demandam energia constante.</li> </ul>"},{"location":"aulas/iot/modulos/modulo17.html#64-gerenciamento-de-energia-em-projetos-iot","title":"6.4 Gerenciamento de Energia em Projetos IoT","text":"<ul> <li>Otimizando Transmiss\u00f5es: Reduzir a frequ\u00eancia de envio de dados e utilizar protocolos eficientes para comunica\u00e7\u00e3o.</li> <li>Armazenamento de Energia: Utilizar baterias de alta capacidade e considerar fontes de energia alternativas como pain\u00e9is solares.</li> <li>Monitoramento do Consumo: Implementar sistemas que monitoram o consumo de energia em tempo real para identificar e eliminar desperd\u00edcios.</li> </ul>"},{"location":"aulas/iot/modulos/modulo17.html#65-boas-praticas-na-gestao-de-energia","title":"6.5 Boas Pr\u00e1ticas na Gest\u00e3o de Energia","text":"<ul> <li>Teste e Medi\u00e7\u00e3o: Sempre medir o consumo de energia antes e depois de implementar t\u00e9cnicas de economia.</li> <li>Documenta\u00e7\u00e3o: Manter registros detalhados das t\u00e9cnicas e componentes utilizados para facilitar futuras otimiza\u00e7\u00f5es.</li> <li>Otimiza\u00e7\u00e3o Cont\u00ednua: Revisar e melhorar continuamente o gerenciamento de energia conforme o projeto evolui.</li> </ul>"},{"location":"aulas/iot/modulos/modulo17.html#7-recursos-adicionais","title":"7. Recursos Adicionais","text":"<ul> <li> <p>Documenta\u00e7\u00e3o Oficial do Arduino:</p> </li> <li> <p>LowPower Library</p> </li> <li>Energy Consumption Basics</li> <li> <p>ADC Precision</p> </li> <li> <p>Tutoriais e Guias:</p> </li> <li> <p>Gerenciamento de Energia com Arduino</p> </li> <li>Implementando Sleep Modes no Arduino</li> <li> <p>Medi\u00e7\u00e3o de Consumo de Energia com Arduino</p> </li> <li> <p>V\u00eddeos Educacionais:</p> </li> <li> <p>Economizando Energia no Arduino</p> </li> <li>Sleep Modes e Gest\u00e3o de Energia</li> <li>Otimizando Projetos Arduino para IoT</li> </ul>"},{"location":"aulas/iot/modulos/modulo17.html#8-exemplos-praticos","title":"8. Exemplos Pr\u00e1ticos","text":""},{"location":"aulas/iot/modulos/modulo17.html#81-implementacao-de-sleep-mode-com-despertar-por-interrupcao","title":"8.1 Implementa\u00e7\u00e3o de Sleep Mode com Despertar por Interrup\u00e7\u00e3o","text":"<p>Este exemplo demonstra como colocar o Arduino em modo de sleep e acord\u00e1-lo usando uma interrup\u00e7\u00e3o externa, como um bot\u00e3o.</p> <pre><code>#include &lt;LowPower.h&gt;\n\nconst int pinoBotao = 2; // Pino conectado a um bot\u00e3o\n\nvoid despertar() {\n    // Fun\u00e7\u00e3o vazia para a interrup\u00e7\u00e3o\n}\n\nvoid setup() {\n    pinMode(pinoBotao, INPUT_PULLUP);\n    Serial.begin(9600);\n    Serial.println(\"Sistema em Sleep. Pressione o bot\u00e3o para acordar.\");\n}\n\nvoid loop() {\n    // Configura a interrup\u00e7\u00e3o na borda de descida do bot\u00e3o\n    attachInterrupt(digitalPinToInterrupt(pinoBotao), despertar, FALLING);\n\n    // Entra em modo de sleep por 8 segundos ou at\u00e9 interrup\u00e7\u00e3o\n    LowPower.powerDown(SLEEP_FOREVER, ADC_OFF, BOD_OFF);\n\n    // Desconecta a interrup\u00e7\u00e3o ap\u00f3s acordar\n    detachInterrupt(digitalPinToInterrupt(pinoBotao));\n\n    // Executa a\u00e7\u00f5es ap\u00f3s acordar\n    Serial.println(\"Sistema Acordado!\");\n    delay(1000); // Tempo para estabilizar\n}\n</code></pre> <p>Explica\u00e7\u00e3o:</p> <ul> <li>Interrup\u00e7\u00e3o Externa: O bot\u00e3o pressiona para gerar uma interrup\u00e7\u00e3o que acorda o Arduino do modo de sleep.</li> <li>Fun\u00e7\u00e3o de Despertar: Uma fun\u00e7\u00e3o vazia que serve apenas para despertar o sistema.</li> <li>Modo SLEEP_FOREVER: Mant\u00e9m o Arduino em modo de sleep at\u00e9 que uma interrup\u00e7\u00e3o ocorra.</li> <li>Desconex\u00e3o da Interrup\u00e7\u00e3o: Ap\u00f3s acordar, a interrup\u00e7\u00e3o \u00e9 removida para evitar m\u00faltiplos acordes indesejados.</li> </ul>"},{"location":"aulas/iot/modulos/modulo17.html#82-projeto-de-monitoramento-de-bateria-com-alerta-de-baixo-nivel","title":"8.2 Projeto de Monitoramento de Bateria com Alerta de Baixo N\u00edvel","text":"<p>Este exemplo implementa um sistema que monitora o n\u00edvel de bateria e envia um alerta quando o n\u00edvel est\u00e1 baixo.</p> <pre><code>#include &lt;LowPower.h&gt;\n#include &lt;WiFiNINA.h&gt;\n#include &lt;MQTT.h&gt;\n\n// Defini\u00e7\u00f5es de rede\nconst char* ssid = \"Seu_SSID\";\nconst char* password = \"Sua_Senha\";\n\n// Defini\u00e7\u00f5es do MQTT\nconst char* broker = \"broker.hivemq.com\";\nconst int port = 1883;\nconst char* topicAlerta = \"arduino/alertas\";\n\n// Pinos\nconst int pinoSensorBateria = A0;\nconst int pinoLEDAlerta = 13;\n\n// Limiar de bateria\nconst float limiarBateria = 3.3; // Exemplo para uma bateria de 3.3V\n\n// Inst\u00e2ncia do cliente MQTT\nWiFiClient net;\nMQTTClient client;\n\nvoid setup() {\n    pinMode(pinoLEDAlerta, OUTPUT);\n    digitalWrite(pinoLEDAlerta, LOW);\n\n    Serial.begin(9600);\n\n    // Conecta ao Wi-Fi\n    WiFi.begin(ssid, password);\n    while (WiFi.status() != WL_CONNECTED) {\n        delay(500);\n        Serial.print(\".\");\n    }\n    Serial.println(\"\\nConectado ao Wi-Fi\");\n\n    // Conecta ao broker MQTT\n    client.begin(broker, port, net);\n    while (!client.connect(\"ArduinoClient\")) {\n        Serial.print(\".\");\n        delay(1000);\n    }\n    Serial.println(\"\\nConectado ao MQTT broker\");\n}\n\nvoid loop() {\n    // Leitura do sensor de bateria\n    int leitura = analogRead(pinoSensorBateria);\n    float tensao = leitura * (5.0 / 1023.0); // Convers\u00e3o exemplo\n\n    Serial.print(\"Tens\u00e3o da Bateria: \");\n    Serial.print(tensao);\n    Serial.println(\" V\");\n\n    // Verifica se a tens\u00e3o est\u00e1 abaixo do limiar\n    if (tensao &lt; limiarBateria) {\n        // Aciona o LED de alerta\n        digitalWrite(pinoLEDAlerta, HIGH);\n\n        // Envia alerta via MQTT\n        String mensagem = \"Alerta: N\u00edvel de bateria baixo!\";\n        client.publish(topicAlerta, mensagem);\n        Serial.println(\"Alerta enviado: N\u00edvel de bateria baixo!\");\n    } else {\n        // Desativa o LED de alerta\n        digitalWrite(pinoLEDAlerta, LOW);\n    }\n\n    // Desconecta do MQTT\n    client.disconnect();\n\n    // Entra em modo de sleep por 8 segundos para economizar energia\n    LowPower.powerDown(SLEEP_8S, ADC_OFF, BOD_OFF);\n}\n</code></pre> <p>Explica\u00e7\u00e3o:</p> <ul> <li>Monitoramento de Tens\u00e3o: L\u00ea a tens\u00e3o da bateria atrav\u00e9s de um sensor anal\u00f3gico.</li> <li>Alerta de Baixo N\u00edvel: Aciona um LED e envia uma mensagem MQTT quando a tens\u00e3o est\u00e1 abaixo do limiar definido.</li> <li>Economia de Energia: O Arduino entra em modo de sleep por 8 segundos entre as leituras para reduzir o consumo energ\u00e9tico.</li> </ul>"},{"location":"aulas/iot/modulos/modulo17.html#83-otimizacao-de-codigo-para-reduzir-o-consumo-de-energia","title":"8.3 Otimiza\u00e7\u00e3o de C\u00f3digo para Reduzir o Consumo de Energia","text":"<p>Este exemplo mostra como otimizar o c\u00f3digo do Arduino para reduzir o consumo de energia, minimizando o uso de loops intensivos e desligando perif\u00e9ricos desnecess\u00e1rios.</p> <pre><code>#include &lt;LowPower.h&gt;\n\nconst int pinoLED = 13;\n\nvoid setup() {\n    pinMode(pinoLED, OUTPUT);\n    digitalWrite(pinoLED, LOW);\n}\n\nvoid loop() {\n    // Liga o LED por 1 segundo\n    digitalWrite(pinoLED, HIGH);\n    delay(1000);\n\n    // Desliga o LED\n    digitalWrite(pinoLED, LOW);\n\n    // Entra em modo de sleep por 8 segundos\n    LowPower.powerDown(SLEEP_8S, ADC_OFF, BOD_OFF);\n}\n</code></pre> <p>Explica\u00e7\u00e3o:</p> <ul> <li>Minimiza\u00e7\u00e3o de Processamento Ativo: Evita loops intensivos que mant\u00eam o microcontrolador ativo continuamente.</li> <li>Desligamento de Perif\u00e9ricos: Desliga componentes que n\u00e3o est\u00e3o em uso para reduzir o consumo de energia.</li> <li>Uso de Delays com Sleep: Utiliza delays acompanhados de modos de sleep para manter o Arduino inativo durante per\u00edodos de espera.</li> </ul>"},{"location":"aulas/iot/modulos/modulo17.html#9-conceitos-importantes","title":"9. Conceitos Importantes","text":""},{"location":"aulas/iot/modulos/modulo17.html#91-eficiencia-energetica","title":"9.1 Efici\u00eancia Energ\u00e9tica","text":"<ul> <li>Defini\u00e7\u00e3o: Maximizar o desempenho do sistema enquanto minimiza o consumo de energia.</li> <li>T\u00e9cnicas: Uso de componentes de baixo consumo, otimiza\u00e7\u00e3o do c\u00f3digo para reduzir ciclos de processamento, e gerenciamento eficaz dos modos de opera\u00e7\u00e3o.</li> </ul>"},{"location":"aulas/iot/modulos/modulo17.html#92-modos-de-economia-de-energia","title":"9.2 Modos de Economia de Energia","text":"<ul> <li>Sleep Modes: Reduzem o consumo desligando partes do sistema que n\u00e3o est\u00e3o em uso.</li> <li>Wake-up Sources: Fontes que podem despertar o microcontrolador do modo de sleep, como interrup\u00e7\u00f5es de bot\u00f5es ou sensores.</li> <li>Duty Cycling: Alternar entre estados ativos e inativos para minimizar o consumo total.</li> </ul>"},{"location":"aulas/iot/modulos/modulo17.html#93-selecao-de-componentes","title":"9.3 Sele\u00e7\u00e3o de Componentes","text":"<ul> <li>Sensores e Atuadores: Escolher dispositivos que oferecem baixo consumo de energia sem comprometer o desempenho necess\u00e1rio.</li> <li>Reguladores de Tens\u00e3o: Utilizar reguladores eficientes para reduzir a dissipa\u00e7\u00e3o de energia.</li> <li>Displays e Interfaces: Optar por displays OLED ou LCD de baixo consumo e minimizar o uso de interfaces que demandam energia constante.</li> </ul>"},{"location":"aulas/iot/modulos/modulo17.html#94-gerenciamento-de-energia-em-projetos-iot","title":"9.4 Gerenciamento de Energia em Projetos IoT","text":"<ul> <li>Otimizando Transmiss\u00f5es: Reduzir a frequ\u00eancia de envio de dados e utilizar protocolos eficientes para comunica\u00e7\u00e3o.</li> <li>Armazenamento de Energia: Utilizar baterias de alta capacidade e considerar fontes de energia alternativas como pain\u00e9is solares.</li> <li>Monitoramento do Consumo: Implementar sistemas que monitoram o consumo de energia em tempo real para identificar e eliminar desperd\u00edcios.</li> </ul>"},{"location":"aulas/iot/modulos/modulo17.html#95-boas-praticas-na-gestao-de-energia","title":"9.5 Boas Pr\u00e1ticas na Gest\u00e3o de Energia","text":"<ul> <li>Teste e Medi\u00e7\u00e3o: Sempre medir o consumo de energia antes e depois de implementar t\u00e9cnicas de economia.</li> <li>Documenta\u00e7\u00e3o: Manter registros detalhados das t\u00e9cnicas e componentes utilizados para facilitar futuras otimiza\u00e7\u00f5es.</li> <li>Otimiza\u00e7\u00e3o Cont\u00ednua: Revisar e melhorar continuamente o gerenciamento de energia conforme o projeto evolui.</li> </ul>"},{"location":"aulas/iot/modulos/modulo17.html#10-recursos-adicionais","title":"10. Recursos Adicionais","text":"<ul> <li> <p>Documenta\u00e7\u00e3o Oficial do Arduino:</p> </li> <li> <p>LowPower Library</p> </li> <li>Energy Consumption Basics</li> <li> <p>ADC Precision</p> </li> <li> <p>Tutoriais e Guias:</p> </li> <li> <p>Gerenciamento de Energia com Arduino</p> </li> <li>Implementando Sleep Modes no Arduino</li> <li> <p>Medi\u00e7\u00e3o de Consumo de Energia com Arduino</p> </li> <li> <p>V\u00eddeos Educacionais:</p> </li> <li> <p>Economizando Energia no Arduino</p> </li> <li>Sleep Modes e Gest\u00e3o de Energia</li> <li>Otimizando Projetos Arduino para IoT</li> </ul>"},{"location":"aulas/iot/modulos/modulo17.html#11-conclusao-do-modulo","title":"11. Conclus\u00e3o do M\u00f3dulo","text":"<p>Neste m\u00f3dulo, voc\u00ea aprendeu:</p> <ul> <li>Fundamentos da Gest\u00e3o de Energia: Compreendeu a import\u00e2ncia de gerenciar o consumo energ\u00e9tico em projetos Arduino.</li> <li>Medi\u00e7\u00e3o de Consumo: Aprendeu a medir e analisar o consumo de energia utilizando ferramentas e sensores.</li> <li>Implementa\u00e7\u00e3o de Sleep Modes: Aplicou modos de sleep para reduzir o consumo de energia quando o Arduino n\u00e3o est\u00e1 ativo.</li> <li>Sele\u00e7\u00e3o de Componentes Eficientes: Selecionou componentes de baixo consumo para otimizar seus projetos.</li> <li>Gerenciamento de Energia em IoT: Desenvolveu estrat\u00e9gias para projetos IoT eficientes energeticamente.</li> <li>Boas Pr\u00e1ticas: Entendeu a import\u00e2ncia de testar, documentar e otimizar continuamente o consumo de energia.</li> </ul> <p>Com este conhecimento, voc\u00ea est\u00e1 preparado para desenvolver projetos mais sustent\u00e1veis, eficientes e com maior autonomia, utilizando as melhores pr\u00e1ticas de gest\u00e3o de energia.</p>"},{"location":"aulas/iot/modulos/modulo17.html#12-proximos-passos","title":"12. Pr\u00f3ximos Passos","text":"<ul> <li>Revisar todo o conte\u00fado do m\u00f3dulo para consolidar o aprendizado.</li> <li>Explorar projetos avan\u00e7ados que combinam gest\u00e3o de energia com outros conceitos aprendidos, como IoT e rob\u00f3tica.</li> <li>Participar de comunidades e f\u00f3runs de Arduino para trocar experi\u00eancias e obter suporte cont\u00ednuo.</li> <li>Considerar cursos avan\u00e7ados ou especializa\u00e7\u00f5es em \u00e1reas espec\u00edficas de interesse, como design de sistemas de energia ou otimiza\u00e7\u00e3o de desempenho.</li> <li>Desenvolver seu pr\u00f3prio portf\u00f3lio de projetos Arduino, aplicando t\u00e9cnicas de gest\u00e3o de energia para resolver problemas reais.</li> </ul> <p>Se tiver d\u00favidas ou precisar de assist\u00eancia, continue participando de comunidades de aprendizagem ou consulte os recursos adicionais fornecidos ao longo dos m\u00f3dulos.</p> <p>**Parab\u00e9ns por concluir o M\u00f3dulo 17! Continue explorando e criando projetos incr\u00edveis com Arduino!</p>"},{"location":"aulas/iot/modulos/modulo18.html","title":"M\u00f3dulo 19: An\u00e1lise de Dados e Visualiza\u00e7\u00e3o","text":"<p>Bem-vindo ao M\u00f3dulo 19 do curso \"Programa\u00e7\u00e3o em Arduino: Conceitos Fundamentais sem Hardware\". Neste m\u00f3dulo, voc\u00ea ir\u00e1 aprender sobre an\u00e1lise de dados e visualiza\u00e7\u00e3o em projetos Arduino. Com a crescente quantidade de dados gerados por sensores e dispositivos conectados, \u00e9 essencial saber como coletar, armazenar, analisar e apresentar esses dados de maneira eficaz. Este m\u00f3dulo abordar\u00e1 t\u00e9cnicas e ferramentas para transformar dados brutos em informa\u00e7\u00f5es \u00fateis e visualmente atraentes.</p>"},{"location":"aulas/iot/modulos/modulo18.html#objetivos-do-modulo","title":"Objetivos do M\u00f3dulo","text":"<ul> <li>Compreender os m\u00e9todos de coleta e armazenamento de dados em projetos Arduino.</li> <li>Aprender t\u00e9cnicas b\u00e1sicas de an\u00e1lise de dados para identificar padr\u00f5es e tend\u00eancias.</li> <li>Implementar ferramentas de visualiza\u00e7\u00e3o para apresentar os dados de forma clara e compreens\u00edvel.</li> <li>Utilizar linguagens de programa\u00e7\u00e3o como Python para an\u00e1lise avan\u00e7ada de dados coletados pelo Arduino.</li> <li>Resolver exerc\u00edcios pr\u00e1ticos para consolidar o conhecimento sobre an\u00e1lise de dados e visualiza\u00e7\u00e3o.</li> </ul>"},{"location":"aulas/iot/modulos/modulo18.html#1-coleta-e-armazenamento-de-dados","title":"1. Coleta e Armazenamento de Dados","text":""},{"location":"aulas/iot/modulos/modulo18.html#11-metodos-de-coleta-de-dados","title":"1.1 M\u00e9todos de Coleta de Dados","text":"<p>A coleta de dados em projetos Arduino pode ser realizada de diversas formas, dependendo dos sensores utilizados e dos requisitos do projeto. Alguns m\u00e9todos comuns incluem:</p> <ul> <li>Leituras Cont\u00ednuas: Coleta de dados em intervalos regulares usando loops ou temporizadores.</li> <li>Interrup\u00e7\u00f5es: Coleta de dados baseada em eventos espec\u00edficos, como a detec\u00e7\u00e3o de um sinal ou a mudan\u00e7a de estado de um sensor.</li> <li>Streaming de Dados: Envio cont\u00ednuo de dados para uma interface externa, como um computador ou um servi\u00e7o de nuvem.</li> </ul>"},{"location":"aulas/iot/modulos/modulo18.html#12-armazenamento-de-dados","title":"1.2 Armazenamento de Dados","text":"<p>Os dados coletados podem ser armazenados localmente ou enviados para a nuvem para posterior an\u00e1lise. Algumas op\u00e7\u00f5es incluem:</p> <ul> <li>Cart\u00f5es SD: Utilizados para armazenar grandes quantidades de dados localmente.</li> <li>EEPROM: Mem\u00f3ria interna do Arduino para armazenar pequenas quantidades de dados.</li> <li>Servi\u00e7os de Nuvem: Plataformas como Google Sheets, Firebase ou ThingSpeak para armazenar e acessar dados remotamente.</li> </ul>"},{"location":"aulas/iot/modulos/modulo18.html#13-exemplo-de-codigo-para-armazenamento-de-dados-em-cartao-sd","title":"1.3 Exemplo de C\u00f3digo para Armazenamento de Dados em Cart\u00e3o SD","text":"<pre><code>#include &lt;SPI.h&gt;\n#include &lt;SD.h&gt;\n\nconst int pinoCS = 10; // Pino de sele\u00e7\u00e3o do cart\u00e3o SD\nFile arquivo;\n\nvoid setup() {\n    Serial.begin(9600);\n    while (!Serial) {}\n\n    Serial.print(\"Inicializando cart\u00e3o SD...\");\n    if (!SD.begin(pinoCS)) {\n        Serial.println(\"Falha na inicializa\u00e7\u00e3o!\");\n        while (1);\n    }\n    Serial.println(\"Cart\u00e3o SD inicializado.\");\n\n    // Abre o arquivo para escrita\n    arquivo = SD.open(\"dados.txt\", FILE_WRITE);\n    if (arquivo) {\n        Serial.println(\"Arquivo aberto com sucesso.\");\n        arquivo.println(\"Tempo (ms), Temperatura (C)\");\n        arquivo.close();\n    } else {\n        Serial.println(\"Falha ao abrir o arquivo.\");\n    }\n}\n\nvoid loop() {\n    // Exemplo de coleta de dados\n    unsigned long tempo = millis();\n    float temperatura = analogRead(A0) * (5.0 / 1023.0) * 100; // Convers\u00e3o exemplo\n\n    // Abre o arquivo para adicionar dados\n    arquivo = SD.open(\"dados.txt\", FILE_WRITE);\n    if (arquivo) {\n        arquivo.print(tempo);\n        arquivo.print(\", \");\n        arquivo.println(temperatura);\n        arquivo.close();\n        Serial.println(\"Dados registrados.\");\n    } else {\n        Serial.println(\"Falha ao abrir o arquivo para escrita.\");\n    }\n\n    delay(1000); // Intervalo de 1 segundo entre as leituras\n}\n</code></pre> <p>Explica\u00e7\u00e3o:</p> <ul> <li>Inicializa\u00e7\u00e3o do Cart\u00e3o SD: Configura e verifica a conex\u00e3o com o cart\u00e3o SD.</li> <li>Cria\u00e7\u00e3o e Abertura do Arquivo: Cria ou abre o arquivo \"dados.txt\" para escrever os dados coletados.</li> <li>Registro de Dados: Escreve o tempo e a temperatura no arquivo a cada segundo.</li> <li>Monitoramento: Exibe mensagens no Monitor Serial para indicar o status da grava\u00e7\u00e3o de dados.</li> </ul>"},{"location":"aulas/iot/modulos/modulo18.html#2-analise-de-dados","title":"2. An\u00e1lise de Dados","text":""},{"location":"aulas/iot/modulos/modulo18.html#21-tecnicas-basicas-de-analise-de-dados","title":"2.1 T\u00e9cnicas B\u00e1sicas de An\u00e1lise de Dados","text":"<p>A an\u00e1lise de dados envolve a aplica\u00e7\u00e3o de t\u00e9cnicas para transformar dados brutos em informa\u00e7\u00f5es \u00fateis. Algumas t\u00e9cnicas b\u00e1sicas incluem:</p> <ul> <li>C\u00e1lculo de M\u00e9dia e Mediana: Identifica valores centrais nos dados.</li> <li>Desvio Padr\u00e3o: Mede a dispers\u00e3o dos dados em rela\u00e7\u00e3o \u00e0 m\u00e9dia.</li> <li>Identifica\u00e7\u00e3o de Tend\u00eancias: Detecta padr\u00f5es ou tend\u00eancias ao longo do tempo.</li> </ul>"},{"location":"aulas/iot/modulos/modulo18.html#22-utilizacao-de-python-para-analise-de-dados-do-arduino","title":"2.2 Utiliza\u00e7\u00e3o de Python para An\u00e1lise de Dados do Arduino","text":"<p>Python \u00e9 uma linguagem poderosa para an\u00e1lise de dados, oferecendo bibliotecas como Pandas e Matplotlib para manipula\u00e7\u00e3o e visualiza\u00e7\u00e3o de dados.</p>"},{"location":"aulas/iot/modulos/modulo18.html#23-exemplo-de-codigo-em-python-para-analise-de-dados","title":"2.3 Exemplo de C\u00f3digo em Python para An\u00e1lise de Dados","text":"<pre><code>import pandas as pd\nimport matplotlib.pyplot as plt\n\n# Carrega os dados do arquivo CSV\ndados = pd.read_csv('dados.txt', sep=',', names=['Tempo', 'Temperatura'])\n\n# Calcula estat\u00edsticas b\u00e1sicas\nmedia_temp = dados['Temperatura'].mean()\nmediana_temp = dados['Temperatura'].median()\ndesvio_temp = dados['Temperatura'].std()\n\nprint(f\"Temperatura M\u00e9dia: {media_temp:.2f}\u00b0C\")\nprint(f\"Temperatura Mediana: {mediana_temp:.2f}\u00b0C\")\nprint(f\"Desvio Padr\u00e3o: {desvio_temp:.2f}\u00b0C\")\n\n# Plotagem dos dados\nplt.figure(figsize=(10,5))\nplt.plot(dados['Tempo'], dados['Temperatura'], label='Temperatura')\nplt.axhline(media_temp, color='r', linestyle='--', label='M\u00e9dia')\nplt.title('Monitoramento de Temperatura')\nplt.xlabel('Tempo (ms)')\nplt.ylabel('Temperatura (C)')\nplt.legend()\nplt.show()\n</code></pre> <p>Explica\u00e7\u00e3o:</p> <ul> <li>Carregamento de Dados: Utiliza o Pandas para ler o arquivo \"dados.txt\" e organizar os dados em um DataFrame.</li> <li>C\u00e1lculo de Estat\u00edsticas: Calcula a m\u00e9dia, mediana e desvio padr\u00e3o das temperaturas registradas.</li> <li>Visualiza\u00e7\u00e3o: Utiliza o Matplotlib para plotar a temperatura ao longo do tempo, destacando a m\u00e9dia.</li> </ul>"},{"location":"aulas/iot/modulos/modulo18.html#3-visualizacao-de-dados","title":"3. Visualiza\u00e7\u00e3o de Dados","text":""},{"location":"aulas/iot/modulos/modulo18.html#31-ferramentas-de-visualizacao","title":"3.1 Ferramentas de Visualiza\u00e7\u00e3o","text":"<p>A visualiza\u00e7\u00e3o de dados permite apresentar informa\u00e7\u00f5es de forma clara e compreens\u00edvel. Algumas ferramentas populares incluem:</p> <ul> <li>Matplotlib: Biblioteca de plotagem para Python.</li> <li>Grafana: Plataforma de visualiza\u00e7\u00e3o para m\u00e9tricas de s\u00e9ries temporais.</li> <li>Tableau: Ferramenta avan\u00e7ada de visualiza\u00e7\u00e3o de dados (n\u00e3o necessariamente gratuita).</li> </ul>"},{"location":"aulas/iot/modulos/modulo18.html#32-criacao-de-dashboards-com-grafana","title":"3.2 Cria\u00e7\u00e3o de Dashboards com Grafana","text":"<p>Grafana \u00e9 uma ferramenta poderosa para criar dashboards interativos, permitindo a visualiza\u00e7\u00e3o de dados em tempo real a partir de diversas fontes.</p>"},{"location":"aulas/iot/modulos/modulo18.html#33-exemplo-de-configuracao-do-grafana-para-dados-arduino","title":"3.3 Exemplo de Configura\u00e7\u00e3o do Grafana para Dados Arduino","text":"<pre><code>1. **Instala\u00e7\u00e3o do Grafana:**\n   - Baixe e instale o Grafana a partir do [site oficial](https://grafana.com/get).\n\n2. **Configura\u00e7\u00e3o da Fonte de Dados:**\n   - Abra o Grafana e adicione uma nova fonte de dados (por exemplo, InfluxDB ou MySQL) onde os dados do Arduino est\u00e3o armazenados.\n\n3. **Cria\u00e7\u00e3o de Painel:**\n   - Crie um novo dashboard e adicione pain\u00e9is de gr\u00e1ficos.\n   - Configure os pain\u00e9is para exibir as m\u00e9tricas desejadas, como temperatura e umidade ao longo do tempo.\n\n4. **Personaliza\u00e7\u00e3o:**\n   - Ajuste os estilos dos gr\u00e1ficos, cores e intervalos de tempo para melhor visualiza\u00e7\u00e3o.\n\n5. **Monitoramento em Tempo Real:**\n   - Utilize a funcionalidade de atualiza\u00e7\u00e3o autom\u00e1tica do Grafana para monitorar os dados em tempo real.\n</code></pre> <p>Explica\u00e7\u00e3o:</p> <ul> <li>Instala\u00e7\u00e3o e Configura\u00e7\u00e3o: Guia passo a passo para instalar e configurar o Grafana.</li> <li>Fonte de Dados: Explica como conectar o Grafana \u00e0 fonte de dados onde os dados do Arduino s\u00e3o armazenados.</li> <li>Cria\u00e7\u00e3o de Pain\u00e9is: Detalha como criar gr\u00e1ficos e personalizar dashboards para visualizar os dados coletados.</li> <li>Monitoramento: Demonstra como configurar atualiza\u00e7\u00f5es autom\u00e1ticas para monitorar os dados em tempo real.</li> </ul>"},{"location":"aulas/iot/modulos/modulo18.html#4-relatorios-e-monitoramento-em-tempo-real","title":"4. Relat\u00f3rios e Monitoramento em Tempo Real","text":""},{"location":"aulas/iot/modulos/modulo18.html#41-geracao-de-relatorios-automaticos","title":"4.1 Gera\u00e7\u00e3o de Relat\u00f3rios Autom\u00e1ticos","text":"<p>Automatizar a gera\u00e7\u00e3o de relat\u00f3rios permite a documenta\u00e7\u00e3o cont\u00ednua do desempenho e condi\u00e7\u00f5es monitoradas pelos projetos Arduino.</p>"},{"location":"aulas/iot/modulos/modulo18.html#42-configuracao-de-alertas-e-notificacoes","title":"4.2 Configura\u00e7\u00e3o de Alertas e Notifica\u00e7\u00f5es","text":"<p>Implementar alertas ajuda a responder rapidamente a condi\u00e7\u00f5es cr\u00edticas detectadas pelos sensores, como temperaturas excessivas ou n\u00edveis de umidade fora do normal.</p>"},{"location":"aulas/iot/modulos/modulo18.html#43-exemplo-de-codigo-para-envio-de-alertas-via-email-com-arduino","title":"4.3 Exemplo de C\u00f3digo para Envio de Alertas via Email com Arduino","text":"<pre><code>#include &lt;SPI.h&gt;\n#include &lt;WiFiNINA.h&gt;\n#include &lt;SMTPClient.h&gt;\n\n// Defini\u00e7\u00f5es de rede\nchar ssid[] = \"Seu_SSID\";\nchar pass[] = \"Sua_Senha\";\n\n// Defini\u00e7\u00f5es do SMTP\nconst char* smtpServer = \"smtp.gmail.com\";\nconst int smtpPort = 587;\nconst char* emailUsuario = \"seu_email@gmail.com\";\nconst char* emailSenha = \"sua_senha\";\nconst char* emailDestino = \"destino_email@gmail.com\";\n\nSMTPClient smtpClient;\n\nconst int pinoSensorTemp = A0;\nconst float limiarTemp = 30.0; // Temperatura de alerta\n\nvoid setup() {\n    Serial.begin(9600);\n    pinMode(pinoSensorTemp, INPUT);\n\n    // Conecta ao Wi-Fi\n    while (WiFi.begin(ssid, pass) != WL_CONNECTED) {\n        Serial.print(\".\");\n        delay(1000);\n    }\n    Serial.println(\"\\nConectado ao Wi-Fi\");\n}\n\nvoid loop() {\n    // Leitura do sensor de temperatura\n    int leitura = analogRead(pinoSensorTemp);\n    float tensao = leitura * (5.0 / 1023.0); // Convers\u00e3o exemplo\n\n    Serial.print(\"Tens\u00e3o da Bateria: \");\n    Serial.print(tensao);\n    Serial.println(\" V\");\n\n    // Verifica se a tens\u00e3o est\u00e1 abaixo do limiar\n    if (tensao &lt; limiarTemp) {\n        // Aciona o LED de alerta\n        digitalWrite(pinoLEDAlerta, HIGH);\n\n        // Envia alerta via MQTT\n        String mensagem = \"Alerta: N\u00edvel de bateria baixo!\";\n        client.publish(topicAlerta, mensagem);\n        Serial.println(\"Alerta enviado: N\u00edvel de bateria baixo!\");\n    } else {\n        // Desativa o LED de alerta\n        digitalWrite(pinoLEDAlerta, LOW);\n    }\n\n    // Desconecta do MQTT\n    client.disconnect();\n\n    // Entra em modo de sleep por 8 segundos para economizar energia\n    LowPower.powerDown(SLEEP_8S, ADC_OFF, BOD_OFF);\n}\n</code></pre> <p>Explica\u00e7\u00e3o:</p> <ul> <li>Monitoramento de Tens\u00e3o: L\u00ea a tens\u00e3o da bateria atrav\u00e9s de um sensor anal\u00f3gico.</li> <li>Alerta de Baixo N\u00edvel: Aciona um LED e envia uma mensagem MQTT quando a tens\u00e3o est\u00e1 abaixo do limiar definido.</li> <li>Economia de Energia: O Arduino entra em modo de sleep por 8 segundos entre as leituras para reduzir o consumo energ\u00e9tico.</li> </ul>"},{"location":"aulas/iot/modulos/modulo18.html#5-exercicios-praticos","title":"5. Exerc\u00edcios Pr\u00e1ticos","text":""},{"location":"aulas/iot/modulos/modulo18.html#exercicio-1-coletar-e-armazenar-dados-em-um-cartao-sd","title":"Exerc\u00edcio 1: Coletar e Armazenar Dados em um Cart\u00e3o SD","text":"<ul> <li> <p>Tarefa: Desenvolva um sistema que coleta dados de temperatura e umidade e os armazena em um cart\u00e3o SD.</p> </li> <li> <p>Dicas:</p> </li> <li>Utilize sensores como DHT22 para coletar dados ambientais.</li> <li>Formate os dados em formato CSV para facilitar a an\u00e1lise.</li> <li> <p>Implemente a grava\u00e7\u00e3o cont\u00ednua de dados no cart\u00e3o SD.</p> </li> <li> <p>Exemplo de C\u00f3digo: Utilize o exemplo de armazenamento de dados em cart\u00e3o SD apresentado na se\u00e7\u00e3o 1.3, adaptando-o para incluir a leitura de um sensor de umidade.</p> </li> </ul>"},{"location":"aulas/iot/modulos/modulo18.html#exercicio-2-analisar-dados-com-python","title":"Exerc\u00edcio 2: Analisar Dados com Python","text":"<ul> <li> <p>Tarefa: Importe os dados coletados do cart\u00e3o SD para um script Python e realize uma an\u00e1lise b\u00e1sica, calculando m\u00e9dia, mediana e desvio padr\u00e3o das temperaturas.</p> </li> <li> <p>Dicas:</p> </li> <li>Utilize a biblioteca Pandas para manipula\u00e7\u00e3o de dados.</li> <li>Visualize os dados utilizando gr\u00e1ficos de linha com Matplotlib.</li> <li> <p>Identifique tend\u00eancias ou picos nos dados coletados.</p> </li> <li> <p>Exemplo de C\u00f3digo: Utilize o exemplo de an\u00e1lise de dados em Python apresentado na se\u00e7\u00e3o 2.3, adaptando-o para trabalhar com os dados coletados.</p> </li> </ul>"},{"location":"aulas/iot/modulos/modulo18.html#exercicio-3-criar-um-dashboard-interativo-com-grafana","title":"Exerc\u00edcio 3: Criar um Dashboard Interativo com Grafana","text":"<ul> <li> <p>Tarefa: Configure o Grafana para criar um dashboard que visualize os dados de temperatura e umidade coletados pelo Arduino em tempo real.</p> </li> <li> <p>Dicas:</p> </li> <li>Configure uma fonte de dados adequada (como InfluxDB ou MySQL) no Grafana.</li> <li>Crie gr\u00e1ficos de linha para monitorar as m\u00e9tricas ao longo do tempo.</li> <li> <p>Personalize o layout do dashboard para facilitar a interpreta\u00e7\u00e3o dos dados.</p> </li> <li> <p>Exemplo de Configura\u00e7\u00e3o: Siga o guia apresentado na se\u00e7\u00e3o 3.3 para configurar o Grafana e criar pain\u00e9is de visualiza\u00e7\u00e3o dos dados coletados.</p> </li> </ul>"},{"location":"aulas/iot/modulos/modulo18.html#6-conceitos-importantes","title":"6. Conceitos Importantes","text":""},{"location":"aulas/iot/modulos/modulo18.html#61-analise-de-dados","title":"6.1 An\u00e1lise de Dados","text":"<ul> <li>Defini\u00e7\u00e3o: Processo de inspe\u00e7\u00e3o, limpeza e modelagem de dados com o objetivo de descobrir informa\u00e7\u00f5es \u00fateis, informar conclus\u00f5es e apoiar a tomada de decis\u00f5es.</li> <li>Import\u00e2ncia: Permite transformar dados brutos em insights acion\u00e1veis, melhorando a efici\u00eancia e efic\u00e1cia dos projetos.</li> </ul>"},{"location":"aulas/iot/modulos/modulo18.html#62-visualizacao-de-dados","title":"6.2 Visualiza\u00e7\u00e3o de Dados","text":"<ul> <li>Defini\u00e7\u00e3o: Representa\u00e7\u00e3o gr\u00e1fica dos dados para facilitar a compreens\u00e3o e comunica\u00e7\u00e3o das informa\u00e7\u00f5es.</li> <li>Ferramentas: Bibliotecas como Matplotlib, plataformas como Grafana e ferramentas de BI como Tableau.</li> </ul>"},{"location":"aulas/iot/modulos/modulo18.html#63-tecnicas-de-filtragem-de-dados","title":"6.3 T\u00e9cnicas de Filtragem de Dados","text":"<ul> <li>M\u00e9dia M\u00f3vel: Suaviza as flutua\u00e7\u00f5es nos dados calculando a m\u00e9dia de um conjunto de pontos de dados.</li> <li>Filtros Passa-Baixa: Permitem a passagem de frequ\u00eancias baixas e atenuam as altas, reduzindo o ru\u00eddo nos dados.</li> </ul>"},{"location":"aulas/iot/modulos/modulo18.html#64-integracao-com-linguagens-de-programacao-para-analise","title":"6.4 Integra\u00e7\u00e3o com Linguagens de Programa\u00e7\u00e3o para An\u00e1lise","text":"<ul> <li>Python: Utilizada amplamente para an\u00e1lise de dados devido \u00e0 sua simplicidade e \u00e0s poderosas bibliotecas dispon\u00edveis.</li> <li>R: Outra linguagem popular para an\u00e1lise estat\u00edstica e visualiza\u00e7\u00e3o de dados.</li> </ul>"},{"location":"aulas/iot/modulos/modulo18.html#65-boas-praticas-na-analise-e-visualizacao-de-dados","title":"6.5 Boas Pr\u00e1ticas na An\u00e1lise e Visualiza\u00e7\u00e3o de Dados","text":"<ul> <li>Organiza\u00e7\u00e3o dos Dados: Manter os dados bem estruturados e organizados facilita a an\u00e1lise e a visualiza\u00e7\u00e3o.</li> <li>Documenta\u00e7\u00e3o: Registrar os processos e m\u00e9todos utilizados na an\u00e1lise para futuras refer\u00eancias e replica\u00e7\u00f5es.</li> <li>Visualiza\u00e7\u00f5es Claras: Criar gr\u00e1ficos e dashboards que comuniquem efetivamente as informa\u00e7\u00f5es sem sobrecarregar o usu\u00e1rio com dados desnecess\u00e1rios.</li> </ul>"},{"location":"aulas/iot/modulos/modulo18.html#7-recursos-adicionais","title":"7. Recursos Adicionais","text":"<ul> <li> <p>Documenta\u00e7\u00e3o Oficial do Arduino:</p> </li> <li> <p>SD Library</p> </li> <li>DHT Sensor Library</li> <li>ArduinoBLE Library</li> <li> <p>SPI Library</p> </li> <li> <p>Tutoriais e Guias:</p> </li> <li> <p>Coletando e Armazenando Dados com Arduino e SD Card</p> </li> <li>An\u00e1lise de Dados com Python para Projetos Arduino</li> <li> <p>Criando Dashboards Interativos com Grafana</p> </li> <li> <p>V\u00eddeos Educacionais:</p> </li> <li> <p>Coletando e Armazenando Dados com Arduino e SD Card</p> </li> <li>An\u00e1lise de Dados com Python</li> <li>Criando Dashboards com Grafana</li> </ul>"},{"location":"aulas/iot/modulos/modulo18.html#8-exemplos-praticos","title":"8. Exemplos Pr\u00e1ticos","text":""},{"location":"aulas/iot/modulos/modulo18.html#81-sistema-de-monitoramento-ambiental-completo","title":"8.1 Sistema de Monitoramento Ambiental Completo","text":"<p>Este exemplo integra a coleta de dados, armazenamento, an\u00e1lise e visualiza\u00e7\u00e3o para criar um sistema de monitoramento ambiental completo.</p> <pre><code>#include &lt;SPI.h&gt;\n#include &lt;SD.h&gt;\n#include &lt;DHT.h&gt;\n#include &lt;WiFiNINA.h&gt;\n#include &lt;MQTTClient.h&gt;\n\n#define DHTPIN 2\n#define DHTTYPE DHT22\nDHT dht(DHTPIN, DHTTYPE);\n\nconst int pinoCS = 10; // Pino de sele\u00e7\u00e3o do cart\u00e3o SD\nFile arquivo;\n\nconst char* ssid = \"Seu_SSID\";\nconst char* password = \"Sua_Senha\";\nconst char* broker = \"broker.hivemq.com\";\nconst int port = 1883;\nconst char* topic = \"arduino/monitoramento\";\n\nWiFiClient net;\nMQTTClient client;\n\nvoid setup() {\n    Serial.begin(9600);\n    while (!Serial);\n\n    pinMode(pinoCS, OUTPUT);\n    if (!SD.begin(pinoCS)) {\n        Serial.println(\"Falha na inicializa\u00e7\u00e3o do cart\u00e3o SD!\");\n        while (1);\n    }\n    Serial.println(\"Cart\u00e3o SD inicializado.\");\n\n    arquivo = SD.open(\"dados.csv\", FILE_WRITE);\n    if (arquivo) {\n        arquivo.println(\"Tempo,Temperatura,Umidade\");\n        arquivo.close();\n    } else {\n        Serial.println(\"Falha ao abrir o arquivo.\");\n    }\n\n    dht.begin();\n\n    // Conecta ao Wi-Fi\n    WiFi.begin(ssid, password);\n    while (WiFi.status() != WL_CONNECTED) {\n        delay(500);\n        Serial.print(\".\");\n    }\n    Serial.println(\"\\nConectado ao Wi-Fi\");\n\n    // Conecta ao MQTT broker\n    client.begin(broker, port, net);\n    while (!client.connect(\"ArduinoClient\")) {\n        Serial.print(\".\");\n        delay(1000);\n    }\n    Serial.println(\"\\nConectado ao MQTT broker\");\n}\n\nvoid loop() {\n    // Leitura dos sensores\n    unsigned long tempo = millis();\n    float temperatura = dht.readTemperature();\n    float umidade = dht.readHumidity();\n\n    if (isnan(temperatura) || isnan(umidade)) {\n        Serial.println(\"Falha na leitura dos sensores DHT!\");\n        return;\n    }\n\n    // Armazenamento dos dados no cart\u00e3o SD\n    arquivo = SD.open(\"dados.csv\", FILE_WRITE);\n    if (arquivo) {\n        arquivo.print(tempo);\n        arquivo.print(\",\");\n        arquivo.print(temperatura);\n        arquivo.print(\",\");\n        arquivo.println(umidade);\n        arquivo.close();\n        Serial.println(\"Dados registrados no cart\u00e3o SD.\");\n    } else {\n        Serial.println(\"Falha ao abrir o arquivo para escrita.\");\n    }\n\n    // Envio dos dados via MQTT\n    String mensagem = \"Tempo: \" + String(tempo) + \" ms, Temperatura: \" + String(temperatura) + \"\u00b0C, Umidade: \" + String(umidade) + \"%\";\n    client.publish(topic, mensagem);\n    Serial.println(\"Dados enviados via MQTT: \" + mensagem);\n\n    delay(60000); // Aguarda 1 minuto antes da pr\u00f3xima leitura\n}\n</code></pre> <p>Explica\u00e7\u00e3o:</p> <ul> <li>Coleta de Dados: L\u00ea a temperatura e umidade do sensor DHT22.</li> <li>Armazenamento Local: Grava os dados no cart\u00e3o SD em formato CSV para f\u00e1cil importa\u00e7\u00e3o e an\u00e1lise.</li> <li>Envio de Dados via MQTT: Transmite os dados para um broker MQTT, permitindo a integra\u00e7\u00e3o com dashboards e sistemas de monitoramento.</li> <li>Monitoramento Cont\u00ednuo: Realiza a coleta e envio de dados a cada minuto.</li> </ul>"},{"location":"aulas/iot/modulos/modulo18.html#82-analise-de-dados-com-pandas-e-visualizacao-com-matplotlib","title":"8.2 An\u00e1lise de Dados com Pandas e Visualiza\u00e7\u00e3o com Matplotlib","text":"<p>Este exemplo demonstra como importar os dados coletados do cart\u00e3o SD para um script Python, realizar an\u00e1lises estat\u00edsticas b\u00e1sicas e visualizar os resultados.</p> <pre><code>import pandas as pd\nimport matplotlib.pyplot as plt\n\n# Carrega os dados do arquivo CSV\ndados = pd.read_csv('dados.csv')\n\n# Exibe as primeiras linhas do DataFrame\nprint(dados.head())\n\n# Calcula estat\u00edsticas b\u00e1sicas\nmedia_temp = dados['Temperatura'].mean()\nmediana_temp = dados['Temperatura'].median()\ndesvio_temp = dados['Temperatura'].std()\n\nmedia_umid = dados['Umidade'].mean()\nmediana_umid = dados['Umidade'].median()\ndesvio_umid = dados['Umidade'].std()\n\nprint(f\"Temperatura M\u00e9dia: {media_temp:.2f}\u00b0C\")\nprint(f\"Temperatura Mediana: {mediana_temp:.2f}\u00b0C\")\nprint(f\"Desvio Padr\u00e3o da Temperatura: {desvio_temp:.2f}\u00b0C\")\n\nprint(f\"Umidade M\u00e9dia: {media_umid:.2f}%\")\nprint(f\"Umidade Mediana: {mediana_umid:.2f}%\")\nprint(f\"Desvio Padr\u00e3o da Umidade: {desvio_umid:.2f}%\")\n\n# Plotagem dos dados\nplt.figure(figsize=(12,6))\n\nplt.subplot(2,1,1)\nplt.plot(dados['Tempo'], dados['Temperatura'], label='Temperatura')\nplt.axhline(media_temp, color='r', linestyle='--', label='M\u00e9dia')\nplt.title('Monitoramento de Temperatura')\nplt.xlabel('Tempo (ms)')\nplt.ylabel('Temperatura (C)')\nplt.legend()\n\nplt.subplot(2,1,2)\nplt.plot(dados['Tempo'], dados['Umidade'], label='Umidade', color='g')\nplt.axhline(media_umid, color='r', linestyle='--', label='M\u00e9dia')\nplt.title('Monitoramento de Umidade')\nplt.xlabel('Tempo (ms)')\nplt.ylabel('Umidade (%)')\nplt.legend()\n\nplt.tight_layout()\nplt.show()\n</code></pre> <p>Explica\u00e7\u00e3o:</p> <ul> <li>Importa\u00e7\u00e3o de Dados: Utiliza o Pandas para ler o arquivo CSV contendo os dados de tempo, temperatura e umidade.</li> <li>An\u00e1lise Estat\u00edstica: Calcula a m\u00e9dia, mediana e desvio padr\u00e3o para cada m\u00e9trica.</li> <li>Visualiza\u00e7\u00e3o: Cria gr\u00e1ficos de linha para visualizar as tend\u00eancias de temperatura e umidade ao longo do tempo, destacando a m\u00e9dia.</li> </ul>"},{"location":"aulas/iot/modulos/modulo18.html#7-conceitos-importantes","title":"7. Conceitos Importantes","text":""},{"location":"aulas/iot/modulos/modulo18.html#71-analise-de-dados","title":"7.1 An\u00e1lise de Dados","text":"<ul> <li>Defini\u00e7\u00e3o: Processo de inspe\u00e7\u00e3o, limpeza e modelagem de dados com o objetivo de descobrir informa\u00e7\u00f5es \u00fateis, informar conclus\u00f5es e apoiar a tomada de decis\u00f5es.</li> <li>Import\u00e2ncia: Permite transformar dados brutos em insights acion\u00e1veis, melhorando a efici\u00eancia e efic\u00e1cia dos projetos.</li> </ul>"},{"location":"aulas/iot/modulos/modulo18.html#72-visualizacao-de-dados","title":"7.2 Visualiza\u00e7\u00e3o de Dados","text":"<ul> <li>Defini\u00e7\u00e3o: Representa\u00e7\u00e3o gr\u00e1fica dos dados para facilitar a compreens\u00e3o e comunica\u00e7\u00e3o das informa\u00e7\u00f5es.</li> <li>Ferramentas: Bibliotecas como Matplotlib, plataformas como Grafana e ferramentas de BI como Tableau.</li> </ul>"},{"location":"aulas/iot/modulos/modulo18.html#73-tecnicas-de-filtragem-de-dados","title":"7.3 T\u00e9cnicas de Filtragem de Dados","text":"<ul> <li>M\u00e9dia M\u00f3vel: Suaviza as flutua\u00e7\u00f5es nos dados calculando a m\u00e9dia de um conjunto de pontos de dados.</li> <li>Filtros Passa-Baixa: Permitem a passagem de frequ\u00eancias baixas e atenuam as altas, reduzindo o ru\u00eddo nos dados.</li> </ul>"},{"location":"aulas/iot/modulos/modulo18.html#74-integracao-com-linguagens-de-programacao-para-analise","title":"7.4 Integra\u00e7\u00e3o com Linguagens de Programa\u00e7\u00e3o para An\u00e1lise","text":"<ul> <li>Python: Utilizada amplamente para an\u00e1lise de dados devido \u00e0 sua simplicidade e \u00e0s poderosas bibliotecas dispon\u00edveis.</li> <li>R: Outra linguagem popular para an\u00e1lise estat\u00edstica e visualiza\u00e7\u00e3o de dados.</li> </ul>"},{"location":"aulas/iot/modulos/modulo18.html#75-boas-praticas-na-analise-e-visualizacao-de-dados","title":"7.5 Boas Pr\u00e1ticas na An\u00e1lise e Visualiza\u00e7\u00e3o de Dados","text":"<ul> <li>Organiza\u00e7\u00e3o dos Dados: Manter os dados bem estruturados e organizados facilita a an\u00e1lise e a visualiza\u00e7\u00e3o.</li> <li>Documenta\u00e7\u00e3o: Registrar os processos e m\u00e9todos utilizados na an\u00e1lise para futuras refer\u00eancias e replica\u00e7\u00f5es.</li> <li>Visualiza\u00e7\u00f5es Claras: Criar gr\u00e1ficos e dashboards que comuniquem efetivamente as informa\u00e7\u00f5es sem sobrecarregar o usu\u00e1rio com dados desnecess\u00e1rios.</li> </ul>"},{"location":"aulas/iot/modulos/modulo18.html#8-recursos-adicionais","title":"8. Recursos Adicionais","text":"<ul> <li> <p>Documenta\u00e7\u00e3o Oficial do Arduino:</p> </li> <li> <p>SD Library</p> </li> <li>DHT Sensor Library</li> <li>ArduinoBLE Library</li> <li> <p>SPI Library</p> </li> <li> <p>Tutoriais e Guias:</p> </li> <li> <p>Coletando e Armazenando Dados com Arduino e SD Card</p> </li> <li>An\u00e1lise de Dados com Python para Projetos Arduino</li> <li> <p>Criando Dashboards Interativos com Grafana</p> </li> <li> <p>V\u00eddeos Educacionais:</p> </li> <li> <p>Coletando e Armazenando Dados com Arduino e SD Card</p> </li> <li>An\u00e1lise de Dados com Python</li> <li>Criando Dashboards com Grafana</li> </ul>"},{"location":"aulas/iot/modulos/modulo18.html#9-exemplos-praticos","title":"9. Exemplos Pr\u00e1ticos","text":""},{"location":"aulas/iot/modulos/modulo18.html#91-sistema-de-monitoramento-ambiental-completo","title":"9.1 Sistema de Monitoramento Ambiental Completo","text":"<p>Este exemplo integra a coleta de dados, armazenamento, an\u00e1lise e visualiza\u00e7\u00e3o para criar um sistema de monitoramento ambiental completo.</p> <pre><code>#include &lt;SPI.h&gt;\n#include &lt;SD.h&gt;\n#include &lt;DHT.h&gt;\n#include &lt;WiFiNINA.h&gt;\n#include &lt;MQTTClient.h&gt;\n\n#define DHTPIN 2\n#define DHTTYPE DHT22\nDHT dht(DHTPIN, DHTTYPE);\n\nconst int pinoCS = 10; // Pino de sele\u00e7\u00e3o do cart\u00e3o SD\nFile arquivo;\n\nconst char* ssid = \"Seu_SSID\";\nconst char* password = \"Sua_Senha\";\nconst char* broker = \"broker.hivemq.com\";\nconst int port = 1883;\nconst char* topic = \"arduino/monitoramento\";\n\nWiFiClient net;\nMQTTClient client;\n\nvoid setup() {\n    Serial.begin(9600);\n    while (!Serial);\n\n    pinMode(pinoCS, OUTPUT);\n    if (!SD.begin(pinoCS)) {\n        Serial.println(\"Falha na inicializa\u00e7\u00e3o do cart\u00e3o SD!\");\n        while (1);\n    }\n    Serial.println(\"Cart\u00e3o SD inicializado.\");\n\n    arquivo = SD.open(\"dados.csv\", FILE_WRITE);\n    if (arquivo) {\n        arquivo.println(\"Tempo,Temperatura,Umidade\");\n        arquivo.close();\n    } else {\n        Serial.println(\"Falha ao abrir o arquivo.\");\n    }\n\n    dht.begin();\n\n    // Conecta ao Wi-Fi\n    WiFi.begin(ssid, password);\n    while (WiFi.status() != WL_CONNECTED) {\n        delay(500);\n        Serial.print(\".\");\n    }\n    Serial.println(\"\\nConectado ao Wi-Fi\");\n\n    // Conecta ao MQTT broker\n    client.begin(broker, port, net);\n    while (!client.connect(\"ArduinoClient\")) {\n        Serial.print(\".\");\n        delay(1000);\n    }\n    Serial.println(\"\\nConectado ao MQTT broker\");\n}\n\nvoid loop() {\n    // Leitura dos sensores\n    unsigned long tempo = millis();\n    float temperatura = dht.readTemperature();\n    float umidade = dht.readHumidity();\n\n    if (isnan(temperatura) || isnan(umidade)) {\n        Serial.println(\"Falha na leitura dos sensores DHT!\");\n        return;\n    }\n\n    // Armazenamento dos dados no cart\u00e3o SD\n    arquivo = SD.open(\"dados.csv\", FILE_WRITE);\n    if (arquivo) {\n        arquivo.print(tempo);\n        arquivo.print(\",\");\n        arquivo.print(temperatura);\n        arquivo.print(\",\");\n        arquivo.println(umidade);\n        arquivo.close();\n        Serial.println(\"Dados registrados no cart\u00e3o SD.\");\n    } else {\n        Serial.println(\"Falha ao abrir o arquivo para escrita.\");\n    }\n\n    // Envio dos dados via MQTT\n    String mensagem = \"Tempo: \" + String(tempo) + \" ms, Temperatura: \" + String(temperatura) + \"\u00b0C, Umidade: \" + String(umidade) + \"%\";\n    client.publish(topic, mensagem);\n    Serial.println(\"Dados enviados via MQTT: \" + mensagem);\n\n    delay(60000); // Aguarda 1 minuto antes da pr\u00f3xima leitura\n}\n</code></pre> <p>Explica\u00e7\u00e3o:</p> <ul> <li>Coleta de Dados: L\u00ea a temperatura e umidade do sensor DHT22.</li> <li>Armazenamento Local: Grava os dados no cart\u00e3o SD em formato CSV para f\u00e1cil importa\u00e7\u00e3o e an\u00e1lise.</li> <li>Envio de Dados via MQTT: Transmite os dados para um broker MQTT, permitindo a integra\u00e7\u00e3o com dashboards e sistemas de monitoramento.</li> <li>Monitoramento Cont\u00ednuo: Realiza a coleta e envio de dados a cada minuto.</li> </ul>"},{"location":"aulas/iot/modulos/modulo18.html#92-analise-de-dados-com-pandas-e-visualizacao-com-matplotlib","title":"9.2 An\u00e1lise de Dados com Pandas e Visualiza\u00e7\u00e3o com Matplotlib","text":"<p>Este exemplo demonstra como importar os dados coletados do cart\u00e3o SD para um script Python, realizar an\u00e1lises estat\u00edsticas b\u00e1sicas e visualizar os resultados.</p> <pre><code>import pandas as pd\nimport matplotlib.pyplot as plt\n\n# Carrega os dados do arquivo CSV\ndados = pd.read_csv('dados.csv')\n\n# Exibe as primeiras linhas do DataFrame\nprint(dados.head())\n\n# Calcula estat\u00edsticas b\u00e1sicas\nmedia_temp = dados['Temperatura'].mean()\nmediana_temp = dados['Temperatura'].median()\ndesvio_temp = dados['Temperatura'].std()\n\nmedia_umid = dados['Umidade'].mean()\nmediana_umid = dados['Umidade'].median()\ndesvio_umid = dados['Umidade'].std()\n\nprint(f\"Temperatura M\u00e9dia: {media_temp:.2f}\u00b0C\")\nprint(f\"Temperatura Mediana: {mediana_temp:.2f}\u00b0C\")\nprint(f\"Desvio Padr\u00e3o da Temperatura: {desvio_temp:.2f}\u00b0C\")\n\nprint(f\"Umidade M\u00e9dia: {media_umid:.2f}%\")\nprint(f\"Umidade Mediana: {mediana_umid:.2f}%\")\nprint(f\"Desvio Padr\u00e3o da Umidade: {desvio_umid:.2f}%\")\n\n# Plotagem dos dados\nplt.figure(figsize=(12,6))\n\nplt.subplot(2,1,1)\nplt.plot(dados['Tempo'], dados['Temperatura'], label='Temperatura')\nplt.axhline(media_temp, color='r', linestyle='--', label='M\u00e9dia')\nplt.title('Monitoramento de Temperatura')\nplt.xlabel('Tempo (ms)')\nplt.ylabel('Temperatura (C)')\nplt.legend()\n\nplt.subplot(2,1,2)\nplt.plot(dados['Tempo'], dados['Umidade'], label='Umidade', color='g')\nplt.axhline(media_umid, color='r', linestyle='--', label='M\u00e9dia')\nplt.title('Monitoramento de Umidade')\nplt.xlabel('Tempo (ms)')\nplt.ylabel('Umidade (%)')\nplt.legend()\n\nplt.tight_layout()\nplt.show()\n</code></pre> <p>Explica\u00e7\u00e3o:</p> <ul> <li>Importa\u00e7\u00e3o de Dados: Utiliza o Pandas para ler o arquivo CSV contendo os dados de tempo, temperatura e umidade.</li> <li>An\u00e1lise Estat\u00edstica: Calcula a m\u00e9dia, mediana e desvio padr\u00e3o para cada m\u00e9trica.</li> <li>Visualiza\u00e7\u00e3o: Cria gr\u00e1ficos de linha para visualizar as tend\u00eancias de temperatura e umidade ao longo do tempo, destacando a m\u00e9dia.</li> </ul>"},{"location":"aulas/iot/modulos/modulo18.html#7-conceitos-importantes_1","title":"7. Conceitos Importantes","text":""},{"location":"aulas/iot/modulos/modulo18.html#71-analise-de-dados_1","title":"7.1 An\u00e1lise de Dados","text":"<ul> <li>Defini\u00e7\u00e3o: Processo de inspe\u00e7\u00e3o, limpeza e modelagem de dados com o objetivo de descobrir informa\u00e7\u00f5es \u00fateis, informar conclus\u00f5es e apoiar a tomada de decis\u00f5es.</li> <li>Import\u00e2ncia: Permite transformar dados brutos em insights acion\u00e1veis, melhorando a efici\u00eancia e efic\u00e1cia dos projetos.</li> </ul>"},{"location":"aulas/iot/modulos/modulo18.html#72-visualizacao-de-dados_1","title":"7.2 Visualiza\u00e7\u00e3o de Dados","text":"<ul> <li>Defini\u00e7\u00e3o: Representa\u00e7\u00e3o gr\u00e1fica dos dados para facilitar a compreens\u00e3o e comunica\u00e7\u00e3o das informa\u00e7\u00f5es.</li> <li>Ferramentas: Bibliotecas como Matplotlib, plataformas como Grafana e ferramentas de BI como Tableau.</li> </ul>"},{"location":"aulas/iot/modulos/modulo18.html#73-tecnicas-de-filtragem-de-dados_1","title":"7.3 T\u00e9cnicas de Filtragem de Dados","text":"<ul> <li>M\u00e9dia M\u00f3vel: Suaviza as flutua\u00e7\u00f5es nos dados calculando a m\u00e9dia de um conjunto de pontos de dados.</li> <li>Filtros Passa-Baixa: Permitem a passagem de frequ\u00eancias baixas e atenuam as altas, reduzindo o ru\u00eddo nos dados.</li> </ul>"},{"location":"aulas/iot/modulos/modulo18.html#74-integracao-com-linguagens-de-programacao-para-analise_1","title":"7.4 Integra\u00e7\u00e3o com Linguagens de Programa\u00e7\u00e3o para An\u00e1lise","text":"<ul> <li>Python: Utilizada amplamente para an\u00e1lise de dados devido \u00e0 sua simplicidade e \u00e0s poderosas bibliotecas dispon\u00edveis.</li> <li>R: Outra linguagem popular para an\u00e1lise estat\u00edstica e visualiza\u00e7\u00e3o de dados.</li> </ul>"},{"location":"aulas/iot/modulos/modulo18.html#75-boas-praticas-na-analise-e-visualizacao-de-dados_1","title":"7.5 Boas Pr\u00e1ticas na An\u00e1lise e Visualiza\u00e7\u00e3o de Dados","text":"<ul> <li>Organiza\u00e7\u00e3o dos Dados: Manter os dados bem estruturados e organizados facilita a an\u00e1lise e a visualiza\u00e7\u00e3o.</li> <li>Documenta\u00e7\u00e3o: Registrar os processos e m\u00e9todos utilizados na an\u00e1lise para futuras refer\u00eancias e replica\u00e7\u00f5es.</li> <li>Visualiza\u00e7\u00f5es Claras: Criar gr\u00e1ficos e dashboards que comuniquem efetivamente as informa\u00e7\u00f5es sem sobrecarregar o usu\u00e1rio com dados desnecess\u00e1rios.</li> </ul>"},{"location":"aulas/iot/modulos/modulo18.html#8-recursos-adicionais_1","title":"8. Recursos Adicionais","text":"<ul> <li> <p>Documenta\u00e7\u00e3o Oficial do Arduino:</p> </li> <li> <p>SD Library</p> </li> <li>DHT Sensor Library</li> <li>ArduinoBLE Library</li> <li> <p>SPI Library</p> </li> <li> <p>Tutoriais e Guias:</p> </li> <li> <p>Coletando e Armazenando Dados com Arduino e SD Card</p> </li> <li>An\u00e1lise de Dados com Python para Projetos Arduino</li> <li> <p>Criando Dashboards Interativos com Grafana</p> </li> <li> <p>V\u00eddeos Educacionais:</p> </li> <li> <p>Coletando e Armazenando Dados com Arduino e SD Card</p> </li> <li>An\u00e1lise de Dados com Python</li> <li>Criando Dashboards com Grafana</li> </ul>"},{"location":"aulas/iot/modulos/modulo18.html#9-exemplos-praticos_1","title":"9. Exemplos Pr\u00e1ticos","text":""},{"location":"aulas/iot/modulos/modulo18.html#91-sistema-de-monitoramento-ambiental-completo_1","title":"9.1 Sistema de Monitoramento Ambiental Completo","text":"<p>Este exemplo integra a coleta de dados, armazenamento, an\u00e1lise e visualiza\u00e7\u00e3o para criar um sistema de monitoramento ambiental completo.</p> <pre><code>#include &lt;SPI.h&gt;\n#include &lt;SD.h&gt;\n#include &lt;DHT.h&gt;\n#include &lt;WiFiNINA.h&gt;\n#include &lt;MQTTClient.h&gt;\n\n#define DHTPIN 2\n#define DHTTYPE DHT22\nDHT dht(DHTPIN, DHTTYPE);\n\nconst int pinoCS = 10; // Pino de sele\u00e7\u00e3o do cart\u00e3o SD\nFile arquivo;\n\nconst char* ssid = \"Seu_SSID\";\nconst char* password = \"Sua_Senha\";\nconst char* broker = \"broker.hivemq.com\";\nconst int port = 1883;\nconst char* topic = \"arduino/monitoramento\";\n\nWiFiClient net;\nMQTTClient client;\n\nvoid setup() {\n    Serial.begin(9600);\n    while (!Serial);\n\n    pinMode(pinoCS, OUTPUT);\n    if (!SD.begin(pinoCS)) {\n        Serial.println(\"Falha na inicializa\u00e7\u00e3o do cart\u00e3o SD!\");\n        while (1);\n    }\n    Serial.println(\"Cart\u00e3o SD inicializado.\");\n\n    arquivo = SD.open(\"dados.csv\", FILE_WRITE);\n    if (arquivo) {\n        arquivo.println(\"Tempo,Temperatura,Umidade\");\n        arquivo.close();\n    } else {\n        Serial.println(\"Falha ao abrir o arquivo.\");\n    }\n\n    dht.begin();\n\n    // Conecta ao Wi-Fi\n    WiFi.begin(ssid, password);\n    while (WiFi.status() != WL_CONNECTED) {\n        delay(500);\n        Serial.print(\".\");\n    }\n    Serial.println(\"\\nConectado ao Wi-Fi\");\n\n    // Conecta ao MQTT broker\n    client.begin(broker, port, net);\n    while (!client.connect(\"ArduinoClient\")) {\n        Serial.print(\".\");\n        delay(1000);\n    }\n    Serial.println(\"\\nConectado ao MQTT broker\");\n}\n\nvoid loop() {\n    // Leitura dos sensores\n    unsigned long tempo = millis();\n    float temperatura = dht.readTemperature();\n    float umidade = dht.readHumidity();\n\n    if (isnan(temperatura) || isnan(umidade)) {\n        Serial.println(\"Falha na leitura dos sensores DHT!\");\n        return;\n    }\n\n    // Armazenamento dos dados no cart\u00e3o SD\n    arquivo = SD.open(\"dados.csv\", FILE_WRITE);\n    if (arquivo) {\n        arquivo.print(tempo);\n        arquivo.print(\",\");\n        arquivo.print(temperatura);\n        arquivo.print(\",\");\n        arquivo.println(umidade);\n        arquivo.close();\n        Serial.println(\"Dados registrados no cart\u00e3o SD.\");\n    } else {\n        Serial.println(\"Falha ao abrir o arquivo para escrita.\");\n    }\n\n    // Envio dos dados via MQTT\n    String mensagem = \"Tempo: \" + String(tempo) + \" ms, Temperatura: \" + String(temperatura) + \"\u00b0C, Umidade: \" + String(umidade) + \"%\";\n    client.publish(topic, mensagem);\n    Serial.println(\"Dados enviados via MQTT: \" + mensagem);\n\n    delay(60000); // Aguarda 1 minuto antes da pr\u00f3xima leitura\n}\n</code></pre> <p>Explica\u00e7\u00e3o:</p> <ul> <li>Coleta de Dados: L\u00ea a temperatura e umidade do sensor DHT22.</li> <li>Armazenamento Local: Grava os dados no cart\u00e3o SD em formato CSV para f\u00e1cil importa\u00e7\u00e3o e an\u00e1lise.</li> <li>Envio de Dados via MQTT: Transmite os dados para um broker MQTT, permitindo a integra\u00e7\u00e3o com dashboards e sistemas de monitoramento.</li> <li>Monitoramento Cont\u00ednuo: Realiza a coleta e envio de dados a cada minuto.</li> </ul>"},{"location":"aulas/iot/modulos/modulo18.html#92-analise-de-dados-com-pandas-e-visualizacao-com-matplotlib_1","title":"9.2 An\u00e1lise de Dados com Pandas e Visualiza\u00e7\u00e3o com Matplotlib","text":"<p>Este exemplo demonstra como importar os dados coletados do cart\u00e3o SD para um script Python, realizar an\u00e1lises estat\u00edsticas b\u00e1sicas e visualizar os resultados.</p> <pre><code>import pandas as pd\nimport matplotlib.pyplot as plt\n\n# Carrega os dados do arquivo CSV\ndados = pd.read_csv('dados.csv')\n\n# Exibe as primeiras linhas do DataFrame\nprint(dados.head())\n\n# Calcula estat\u00edsticas b\u00e1sicas\nmedia_temp = dados['Temperatura'].mean()\nmediana_temp = dados['Temperatura'].median()\ndesvio_temp = dados['Temperatura'].std()\n\nmedia_umid = dados['Umidade'].mean()\nmediana_umid = dados['Umidade'].median()\ndesvio_umid = dados['Umidade'].std()\n\nprint(f\"Temperatura M\u00e9dia: {media_temp:.2f}\u00b0C\")\nprint(f\"Temperatura Mediana: {mediana_temp:.2f}\u00b0C\")\nprint(f\"Desvio Padr\u00e3o da Temperatura: {desvio_temp:.2f}\u00b0C\")\n\nprint(f\"Umidade M\u00e9dia: {media_umid:.2f}%\")\nprint(f\"Umidade Mediana: {mediana_umid:.2f}%\")\nprint(f\"Desvio Padr\u00e3o da Umidade: {desvio_umid:.2f}%\")\n\n# Plotagem dos dados\nplt.figure(figsize=(12,6))\n\nplt.subplot(2,1,1)\nplt.plot(dados['Tempo'], dados['Temperatura'], label='Temperatura')\nplt.axhline(media_temp, color='r', linestyle='--', label='M\u00e9dia')\nplt.title('Monitoramento de Temperatura')\nplt.xlabel('Tempo (ms)')\nplt.ylabel('Temperatura (C)')\nplt.legend()\n\nplt.subplot(2,1,2)\nplt.plot(dados['Tempo'], dados['Umidade'], label='Umidade', color='g')\nplt.axhline(media_umid, color='r', linestyle='--', label='M\u00e9dia')\nplt.title('Monitoramento de Umidade')\nplt.xlabel('Tempo (ms)')\nplt.ylabel('Umidade (%)')\nplt.legend()\n\nplt.tight_layout()\nplt.show()\n</code></pre> <p>Explica\u00e7\u00e3o:</p> <ul> <li>Importa\u00e7\u00e3o de Dados: Utiliza o Pandas para ler o arquivo CSV contendo os dados de tempo, temperatura e umidade.</li> <li>An\u00e1lise Estat\u00edstica: Calcula a m\u00e9dia, mediana e desvio padr\u00e3o para cada m\u00e9trica.</li> <li>Visualiza\u00e7\u00e3o: Cria gr\u00e1ficos de linha para visualizar as tend\u00eancias de temperatura e umidade ao longo do tempo, destacando a m\u00e9dia.</li> </ul>"},{"location":"aulas/iot/modulos/modulo18.html#10-conceitos-importantes","title":"10. Conceitos Importantes","text":""},{"location":"aulas/iot/modulos/modulo18.html#101-analise-de-dados","title":"10.1 An\u00e1lise de Dados","text":"<ul> <li>Defini\u00e7\u00e3o: Processo de inspe\u00e7\u00e3o, limpeza e modelagem de dados com o objetivo de descobrir informa\u00e7\u00f5es \u00fateis, informar conclus\u00f5es e apoiar a tomada de decis\u00f5es.</li> <li>Import\u00e2ncia: Permite transformar dados brutos em insights acion\u00e1veis, melhorando a efici\u00eancia e efic\u00e1cia dos projetos.</li> </ul>"},{"location":"aulas/iot/modulos/modulo18.html#102-visualizacao-de-dados","title":"10.2 Visualiza\u00e7\u00e3o de Dados","text":"<ul> <li>Defini\u00e7\u00e3o: Representa\u00e7\u00e3o gr\u00e1fica dos dados para facilitar a compreens\u00e3o e comunica\u00e7\u00e3o das informa\u00e7\u00f5es.</li> <li>Ferramentas: Bibliotecas como Matplotlib, plataformas como Grafana e ferramentas de BI como Tableau.</li> </ul>"},{"location":"aulas/iot/modulos/modulo18.html#103-tecnicas-de-filtragem-de-dados","title":"10.3 T\u00e9cnicas de Filtragem de Dados","text":"<ul> <li>M\u00e9dia M\u00f3vel: Suaviza as flutua\u00e7\u00f5es nos dados calculando a m\u00e9dia de um conjunto de pontos de dados.</li> <li>Filtros Passa-Baixa: Permitem a passagem de frequ\u00eancias baixas e atenuam as altas, reduzindo o ru\u00eddo nos dados.</li> </ul>"},{"location":"aulas/iot/modulos/modulo18.html#104-integracao-com-linguagens-de-programacao-para-analise","title":"10.4 Integra\u00e7\u00e3o com Linguagens de Programa\u00e7\u00e3o para An\u00e1lise","text":"<ul> <li>Python: Utilizada amplamente para an\u00e1lise de dados devido \u00e0 sua simplicidade e \u00e0s poderosas bibliotecas dispon\u00edveis.</li> <li>R: Outra linguagem popular para an\u00e1lise estat\u00edstica e visualiza\u00e7\u00e3o de dados.</li> </ul>"},{"location":"aulas/iot/modulos/modulo18.html#105-boas-praticas-na-analise-e-visualizacao-de-dados","title":"10.5 Boas Pr\u00e1ticas na An\u00e1lise e Visualiza\u00e7\u00e3o de Dados","text":"<ul> <li>Organiza\u00e7\u00e3o dos Dados: Manter os dados bem estruturados e organizados facilita a an\u00e1lise e a visualiza\u00e7\u00e3o.</li> <li>Documenta\u00e7\u00e3o: Registrar os processos e m\u00e9todos utilizados na an\u00e1lise para futuras refer\u00eancias e replica\u00e7\u00f5es.</li> <li>Visualiza\u00e7\u00f5es Claras: Criar gr\u00e1ficos e dashboards que comuniquem efetivamente as informa\u00e7\u00f5es sem sobrecarregar o usu\u00e1rio com dados desnecess\u00e1rios.</li> </ul>"},{"location":"aulas/iot/modulos/modulo18.html#11-recursos-adicionais","title":"11. Recursos Adicionais","text":"<ul> <li> <p>Documenta\u00e7\u00e3o Oficial do Arduino:</p> </li> <li> <p>SD Library</p> </li> <li>DHT Sensor Library</li> <li>ArduinoBLE Library</li> <li> <p>SPI Library</p> </li> <li> <p>Tutoriais e Guias:</p> </li> <li> <p>Coletando e Armazenando Dados com Arduino e SD Card</p> </li> <li>An\u00e1lise de Dados com Python para Projetos Arduino</li> <li> <p>Criando Dashboards Interativos com Grafana</p> </li> <li> <p>V\u00eddeos Educacionais:</p> </li> <li> <p>Coletando e Armazenando Dados com Arduino e SD Card</p> </li> <li>An\u00e1lise de Dados com Python</li> <li>Criando Dashboards com Grafana</li> </ul>"},{"location":"aulas/iot/modulos/modulo18.html#12-exemplos-praticos","title":"12. Exemplos Pr\u00e1ticos","text":""},{"location":"aulas/iot/modulos/modulo18.html#121-sistema-de-monitoramento-ambiental-completo","title":"12.1 Sistema de Monitoramento Ambiental Completo","text":"<p>Este exemplo integra a coleta de dados, armazenamento, an\u00e1lise e visualiza\u00e7\u00e3o para criar um sistema de monitoramento ambiental completo.</p> <pre><code>#include &lt;SPI.h&gt;\n#include &lt;SD.h&gt;\n#include &lt;DHT.h&gt;\n#include &lt;WiFiNINA.h&gt;\n#include &lt;MQTTClient.h&gt;\n\n#define DHTPIN 2\n#define DHTTYPE DHT22\nDHT dht(DHTPIN, DHTTYPE);\n\nconst int pinoCS = 10; // Pino de sele\u00e7\u00e3o do cart\u00e3o SD\nFile arquivo;\n\nconst char* ssid = \"Seu_SSID\";\nconst char* password = \"Sua_Senha\";\nconst char* broker = \"broker.hivemq.com\";\nconst int port = 1883;\nconst char* topic = \"arduino/monitoramento\";\n\nWiFiClient net;\nMQTTClient client;\n\nvoid setup() {\n    Serial.begin(9600);\n    while (!Serial);\n\n    pinMode(pinoCS, OUTPUT);\n    if (!SD.begin(pinoCS)) {\n        Serial.println(\"Falha na inicializa\u00e7\u00e3o do cart\u00e3o SD!\");\n        while (1);\n    }\n    Serial.println(\"Cart\u00e3o SD inicializado.\");\n\n    arquivo = SD.open(\"dados.csv\", FILE_WRITE);\n    if (arquivo) {\n        arquivo.println(\"Tempo,Temperatura,Umidade\");\n        arquivo.close();\n    } else {\n        Serial.println(\"Falha ao abrir o arquivo.\");\n    }\n\n    dht.begin();\n\n    // Conecta ao Wi-Fi\n    WiFi.begin(ssid, password);\n    while (WiFi.status() != WL_CONNECTED) {\n        delay(500);\n        Serial.print(\".\");\n    }\n    Serial.println(\"\\nConectado ao Wi-Fi\");\n\n    // Conecta ao MQTT broker\n    client.begin(broker, port, net);\n    while (!client.connect(\"ArduinoClient\")) {\n        Serial.print(\".\");\n        delay(1000);\n    }\n    Serial.println(\"\\nConectado ao MQTT broker\");\n}\n\nvoid loop() {\n    // Leitura dos sensores\n    unsigned long tempo = millis();\n    float temperatura = dht.readTemperature();\n    float umidade = dht.readHumidity();\n\n    if (isnan(temperatura) || isnan(umidade)) {\n        Serial.println(\"Falha na leitura dos sensores DHT!\");\n        return;\n    }\n\n    // Armazenamento dos dados no cart\u00e3o SD\n    arquivo = SD.open(\"dados.csv\", FILE_WRITE);\n    if (arquivo) {\n        arquivo.print(tempo);\n        arquivo.print(\",\");\n        arquivo.print(temperatura);\n        arquivo.print(\",\");\n        arquivo.println(umidade);\n        arquivo.close();\n        Serial.println(\"Dados registrados no cart\u00e3o SD.\");\n    } else {\n        Serial.println(\"Falha ao abrir o arquivo para escrita.\");\n    }\n\n    // Envio dos dados via MQTT\n    String mensagem = \"Tempo: \" + String(tempo) + \" ms, Temperatura: \" + String(temperatura) + \"\u00b0C, Umidade: \" + String(umidade) + \"%\";\n    client.publish(topic, mensagem);\n    Serial.println(\"Dados enviados via MQTT: \" + mensagem);\n\n    delay(60000); // Aguarda 1 minuto antes da pr\u00f3xima leitura\n}\n</code></pre> <p>Explica\u00e7\u00e3o:</p> <ul> <li>Coleta de Dados: L\u00ea a temperatura e umidade do sensor DHT22.</li> <li>Armazenamento Local: Grava os dados no cart\u00e3o SD em formato CSV para f\u00e1cil importa\u00e7\u00e3o e an\u00e1lise.</li> <li>Envio de Dados via MQTT: Transmite os dados para um broker MQTT, permitindo a integra\u00e7\u00e3o com dashboards e sistemas de monitoramento.</li> <li>Monitoramento Cont\u00ednuo: Realiza a coleta e envio de dados a cada minuto.</li> </ul>"},{"location":"aulas/iot/modulos/modulo18.html#122-analise-de-dados-com-pandas-e-visualizacao-com-matplotlib","title":"12.2 An\u00e1lise de Dados com Pandas e Visualiza\u00e7\u00e3o com Matplotlib","text":"<p>Este exemplo demonstra como importar os dados coletados do cart\u00e3o SD para um script Python, realizar an\u00e1lises estat\u00edsticas b\u00e1sicas e visualizar os resultados.</p> <pre><code>import pandas as pd\nimport matplotlib.pyplot as plt\n\n# Carrega os dados do arquivo CSV\ndados = pd.read_csv('dados.csv')\n\n# Exibe as primeiras linhas do DataFrame\nprint(dados.head())\n\n# Calcula estat\u00edsticas b\u00e1sicas\nmedia_temp = dados['Temperatura'].mean()\nmediana_temp = dados['Temperatura'].median()\ndesvio_temp = dados['Temperatura'].std()\n\nmedia_umid = dados['Umidade'].mean()\nmediana_umid = dados['Umidade'].median()\ndesvio_umid = dados['Umidade'].std()\n\nprint(f\"Temperatura M\u00e9dia: {media_temp:.2f}\u00b0C\")\nprint(f\"Temperatura Mediana: {mediana_temp:.2f}\u00b0C\")\nprint(f\"Desvio Padr\u00e3o da Temperatura: {desvio_temp:.2f}\u00b0C\")\n\nprint(f\"Umidade M\u00e9dia: {media_umid:.2f}%\")\nprint(f\"Umidade Mediana: {mediana_umid:.2f}%\")\nprint(f\"Desvio Padr\u00e3o da Umidade: {desvio_umid:.2f}%\")\n\n# Plotagem dos dados\nplt.figure(figsize=(12,6))\n\nplt.subplot(2,1,1)\nplt.plot(dados['Tempo'], dados['Temperatura'], label='Temperatura')\nplt.axhline(media_temp, color='r', linestyle='--', label='M\u00e9dia')\nplt.title('Monitoramento de Temperatura')\nplt.xlabel('Tempo (ms)')\nplt.ylabel('Temperatura (C)')\nplt.legend()\n\nplt.subplot(2,1,2)\nplt.plot(dados['Tempo'], dados['Umidade'], label='Umidade', color='g')\nplt.axhline(media_umid, color='r', linestyle='--', label='M\u00e9dia')\nplt.title('Monitoramento de Umidade')\nplt.xlabel('Tempo (ms)')\nplt.ylabel('Umidade (%)')\nplt.legend()\n\nplt.tight_layout()\nplt.show()\n</code></pre> <p>Explica\u00e7\u00e3o:</p> <ul> <li>Importa\u00e7\u00e3o de Dados: Utiliza o Pandas para ler o arquivo CSV contendo os dados de tempo, temperatura e umidade.</li> <li>An\u00e1lise Estat\u00edstica: Calcula a m\u00e9dia, mediana e desvio padr\u00e3o para cada m\u00e9trica.</li> <li>Visualiza\u00e7\u00e3o: Cria gr\u00e1ficos de linha para visualizar as tend\u00eancias de temperatura e umidade ao longo do tempo, destacando a m\u00e9dia.</li> </ul>"},{"location":"aulas/iot/modulos/modulo18.html#11-conclusao-do-modulo","title":"11. Conclus\u00e3o do M\u00f3dulo","text":"<p>Neste m\u00f3dulo, voc\u00ea aprendeu:</p> <ul> <li>M\u00e9todos de Coleta e Armazenamento de Dados: Entendeu diferentes formas de coletar dados com Arduino e armazen\u00e1-los localmente ou na nuvem.</li> <li>T\u00e9cnicas de An\u00e1lise de Dados: Aprendeu como aplicar t\u00e9cnicas b\u00e1sicas para identificar padr\u00f5es e tend\u00eancias nos dados coletados.</li> <li>Ferramentas de Visualiza\u00e7\u00e3o: Utilizou ferramentas como Matplotlib e Grafana para criar representa\u00e7\u00f5es gr\u00e1ficas dos dados.</li> <li>Integra\u00e7\u00e3o com Python: Compreendeu como utilizar Python para an\u00e1lises mais avan\u00e7adas e personalizadas.</li> <li>Boas Pr\u00e1ticas: Entendeu a import\u00e2ncia de organizar, documentar e visualizar os dados de maneira eficaz para obter insights valiosos.</li> </ul> <p>Com este conhecimento, voc\u00ea est\u00e1 preparado para transformar os dados coletados pelos seus projetos Arduino em informa\u00e7\u00f5es \u00fateis e visualmente atraentes, melhorando a tomada de decis\u00f5es e a efici\u00eancia dos seus sistemas.</p>"},{"location":"aulas/iot/modulos/modulo18.html#12-proximos-passos","title":"12. Pr\u00f3ximos Passos","text":"<ul> <li>Revisar todo o conte\u00fado do m\u00f3dulo para consolidar o aprendizado.</li> <li>Explorar projetos avan\u00e7ados que combinam an\u00e1lise de dados com outros conceitos aprendidos, como IoT, automa\u00e7\u00e3o residencial ou rob\u00f3tica.</li> <li>Participar de comunidades e f\u00f3runs de Arduino para trocar experi\u00eancias e obter suporte cont\u00ednuo.</li> <li>Considerar cursos avan\u00e7ados ou especializa\u00e7\u00f5es em \u00e1reas espec\u00edficas de interesse, como ci\u00eancia de dados, intelig\u00eancia artificial aplicada ou visualiza\u00e7\u00e3o de dados avan\u00e7ada.</li> <li>Desenvolver seu pr\u00f3prio portf\u00f3lio de projetos Arduino, aplicando t\u00e9cnicas de an\u00e1lise de dados e visualiza\u00e7\u00e3o para resolver problemas reais.</li> </ul> <p>Se tiver d\u00favidas ou precisar de assist\u00eancia, continue participando de comunidades de aprendizagem ou consulte os recursos adicionais fornecidos ao longo dos m\u00f3dulos.</p> <p>**Parab\u00e9ns por concluir o M\u00f3dulo 19! Continue explorando e criando projetos incr\u00edveis com Arduino!</p>"},{"location":"aulas/iot/modulos/modulo2.html","title":"M\u00f3dulo 2: Operadores e Express\u00f5es","text":"<p>Bem-vindo ao M\u00f3dulo 2 do curso \"Programa\u00e7\u00e3o em Arduino: Conceitos Fundamentais sem Hardware\". Neste m\u00f3dulo, voc\u00ea explorar\u00e1 os operadores e express\u00f5es na linguagem de programa\u00e7\u00e3o Arduino (C/C++). Compreender os diferentes tipos de operadores e como eles interagem em express\u00f5es \u00e9 essencial para desenvolver programas eficientes e funcionais.</p>"},{"location":"aulas/iot/modulos/modulo2.html#objetivos-do-modulo","title":"Objetivos do M\u00f3dulo","text":"<ul> <li>Compreender os diferentes tipos de operadores dispon\u00edveis em Arduino.</li> <li>Aplicar operadores aritm\u00e9ticos, relacionais, l\u00f3gicos, de atribui\u00e7\u00e3o e incrementais/decrementais.</li> <li>Entender a preced\u00eancia e associatividade de operadores.</li> <li>Construir express\u00f5es complexas utilizando m\u00faltiplos operadores.</li> <li>Resolver exerc\u00edcios pr\u00e1ticos para consolidar o conhecimento sobre operadores e express\u00f5es.</li> </ul>"},{"location":"aulas/iot/modulos/modulo2.html#1-introducao-aos-operadores-e-expressoes","title":"1. Introdu\u00e7\u00e3o aos Operadores e Express\u00f5es","text":""},{"location":"aulas/iot/modulos/modulo2.html#11-o-que-sao-operadores","title":"1.1 O que s\u00e3o Operadores?","text":"<p>Operadores s\u00e3o s\u00edmbolos ou palavras reservadas que informam ao compilador para realizar opera\u00e7\u00f5es espec\u00edficas entre os operandos (valores ou vari\u00e1veis). Eles s\u00e3o fundamentais para criar express\u00f5es que manipulam dados.</p>"},{"location":"aulas/iot/modulos/modulo2.html#12-o-que-sao-expressoes","title":"1.2 O que s\u00e3o Express\u00f5es?","text":"<p>Uma express\u00e3o \u00e9 uma combina\u00e7\u00e3o de operadores e operandos que o compilador avalia para produzir um novo valor. Por exemplo, <code>a + b</code> \u00e9 uma express\u00e3o que soma os valores de <code>a</code> e <code>b</code>.</p>"},{"location":"aulas/iot/modulos/modulo2.html#2-tipos-de-operadores","title":"2. Tipos de Operadores","text":""},{"location":"aulas/iot/modulos/modulo2.html#21-operadores-aritmeticos","title":"2.1 Operadores Aritm\u00e9ticos","text":"<p>Operadores utilizados para realizar opera\u00e7\u00f5es matem\u00e1ticas b\u00e1sicas.</p> <ul> <li>Adi\u00e7\u00e3o (<code>+</code>)</li> </ul> <p>Soma dois operandos.</p> <pre><code>int soma = a + b;\n</code></pre> <ul> <li>Subtra\u00e7\u00e3o (<code>-</code>)</li> </ul> <p>Subtrai o segundo operando do primeiro.</p> <pre><code>int subtracao = a - b;\n</code></pre> <ul> <li>Multiplica\u00e7\u00e3o (<code>*</code>)</li> </ul> <p>Multiplica dois operandos.</p> <pre><code>int multiplicacao = a * b;\n</code></pre> <ul> <li>Divis\u00e3o (<code>/</code>)</li> </ul> <p>Divide o primeiro operando pelo segundo.</p> <pre><code>int divisao = a / b;\n</code></pre> <ul> <li>M\u00f3dulo (<code>%</code>)</li> </ul> <p>Retorna o resto da divis\u00e3o do primeiro operando pelo segundo.</p> <pre><code>int resto = a % b;\n</code></pre>"},{"location":"aulas/iot/modulos/modulo2.html#22-operadores-relacionais","title":"2.2 Operadores Relacionais","text":"<p>Operadores que comparam dois operandos e retornam um valor booleano (<code>true</code> ou <code>false</code>).</p> <ul> <li>Igual a (<code>==</code>)</li> </ul> <p>Verifica se os operandos s\u00e3o iguais.</p> <pre><code>bool igual = (a == b);\n</code></pre> <ul> <li>Diferente de (<code>!=</code>)</li> </ul> <p>Verifica se os operandos s\u00e3o diferentes.</p> <pre><code>bool diferente = (a != b);\n</code></pre> <ul> <li>Maior que (<code>&gt;</code>)</li> </ul> <p>Verifica se o primeiro operando \u00e9 maior que o segundo.</p> <pre><code>bool maior = (a &gt; b);\n</code></pre> <ul> <li>Menor que (<code>&lt;</code>)</li> </ul> <p>Verifica se o primeiro operando \u00e9 menor que o segundo.</p> <pre><code>bool menor = (a &lt; b);\n</code></pre> <ul> <li>Maior ou igual a (<code>&gt;=</code>)</li> </ul> <p>Verifica se o primeiro operando \u00e9 maior ou igual ao segundo.</p> <pre><code>bool maiorIgual = (a &gt;= b);\n</code></pre> <ul> <li>Menor ou igual a (<code>&lt;=</code>)</li> </ul> <p>Verifica se o primeiro operando \u00e9 menor ou igual ao segundo.</p> <pre><code>bool menorIgual = (a &lt;= b);\n</code></pre>"},{"location":"aulas/iot/modulos/modulo2.html#23-operadores-logicos","title":"2.3 Operadores L\u00f3gicos","text":"<p>Operadores que combinam express\u00f5es booleanas.</p> <ul> <li>AND L\u00f3gico (<code>&amp;&amp;</code>)</li> </ul> <p>Retorna <code>true</code> se ambas as express\u00f5es forem verdadeiras.</p> <pre><code>bool resultado = (a &gt; b) &amp;&amp; (c &lt; d);\n</code></pre> <ul> <li>OR L\u00f3gico (<code>||</code>)</li> </ul> <p>Retorna <code>true</code> se pelo menos uma das express\u00f5es for verdadeira.</p> <pre><code>bool resultado = (a &gt; b) || (c &lt; d);\n</code></pre> <ul> <li>NOT L\u00f3gico (<code>!</code>)</li> </ul> <p>Inverte o valor l\u00f3gico da express\u00e3o.</p> <pre><code>bool resultado = !(a &gt; b);\n</code></pre>"},{"location":"aulas/iot/modulos/modulo2.html#24-operadores-de-atribuicao","title":"2.4 Operadores de Atribui\u00e7\u00e3o","text":"<p>Operadores que atribuem valores \u00e0s vari\u00e1veis.</p> <ul> <li>Atribui\u00e7\u00e3o Simples (<code>=</code>)</li> </ul> <p>Atribui o valor do operando direito ao operando esquerdo.</p> <pre><code>int a = 5;\n</code></pre> <ul> <li>Atribui\u00e7\u00e3o com Adi\u00e7\u00e3o (<code>+=</code>)</li> </ul> <p>Adiciona o valor do operando direito ao operando esquerdo e atribui o resultado ao operando esquerdo.</p> <pre><code>a += 3; // Equivale a a = a + 3;\n</code></pre> <ul> <li>Atribui\u00e7\u00e3o com Subtra\u00e7\u00e3o (<code>-=</code>)</li> </ul> <p>Subtrai o valor do operando direito do operando esquerdo e atribui o resultado ao operando esquerdo.</p> <pre><code>a -= 2; // Equivale a a = a - 2;\n</code></pre> <ul> <li>Atribui\u00e7\u00e3o com Multiplica\u00e7\u00e3o (<code>*=</code>)</li> </ul> <p>Multiplica o operando esquerdo pelo operando direito e atribui o resultado ao operando esquerdo.</p> <pre><code>a *= 4; // Equivale a a = a * 4;\n</code></pre> <ul> <li>Atribui\u00e7\u00e3o com Divis\u00e3o (<code>/=</code>)</li> </ul> <p>Divide o operando esquerdo pelo operando direito e atribui o resultado ao operando esquerdo.</p> <pre><code>a /= 2; // Equivale a a = a / 2;\n</code></pre> <ul> <li>Atribui\u00e7\u00e3o com M\u00f3dulo (<code>%=</code>)</li> </ul> <p>Calcula o m\u00f3dulo do operando esquerdo pelo operando direito e atribui o resultado ao operando esquerdo.</p> <pre><code>a %= 3; // Equivale a a = a % 3;\n</code></pre>"},{"location":"aulas/iot/modulos/modulo2.html#25-operadores-incrementais-e-decrementais","title":"2.5 Operadores Incrementais e Decrementais","text":"<p>Operadores que aumentam ou diminuem o valor de uma vari\u00e1vel em 1.</p> <ul> <li>Incremento (<code>++</code>)</li> </ul> <p>Aumenta o valor da vari\u00e1vel em 1.</p> <pre><code>a++; // Equivale a a = a + 1;\n</code></pre> <ul> <li>Decremento (<code>--</code>)</li> </ul> <p>Diminui o valor da vari\u00e1vel em 1.</p> <pre><code>a--; // Equivale a a = a - 1;\n</code></pre>"},{"location":"aulas/iot/modulos/modulo2.html#26-operadores-bitwise","title":"2.6 Operadores Bitwise","text":"<p>Operadores que realizam opera\u00e7\u00f5es bit a bit.</p> <ul> <li>AND Bitwise (<code>&amp;</code>)</li> </ul> <p>Retorna 1 apenas se ambos os bits forem 1.</p> <pre><code>int resultado = a &amp; b;\n</code></pre> <ul> <li>OR Bitwise (<code>|</code>)</li> </ul> <p>Retorna 1 se pelo menos um dos bits for 1.</p> <pre><code>int resultado = a | b;\n</code></pre> <ul> <li>XOR Bitwise (<code>^</code>)</li> </ul> <p>Retorna 1 se os bits forem diferentes.</p> <pre><code>int resultado = a ^ b;\n</code></pre> <ul> <li>NOT Bitwise (<code>~</code>)</li> </ul> <p>Inverte todos os bits.</p> <pre><code>int resultado = ~a;\n</code></pre> <ul> <li>Shift Left (<code>&lt;&lt;</code>)</li> </ul> <p>Desloca os bits para a esquerda, preenchendo com zeros.</p> <pre><code>int resultado = a &lt;&lt; 2;\n</code></pre> <ul> <li>Shift Right (<code>&gt;&gt;</code>)</li> </ul> <p>Desloca os bits para a direita.</p> <pre><code>int resultado = a &gt;&gt; 1;\n</code></pre>"},{"location":"aulas/iot/modulos/modulo2.html#3-precedencia-e-associatividade-de-operadores","title":"3. Preced\u00eancia e Associatividade de Operadores","text":"<p>A preced\u00eancia de operadores determina a ordem em que os operadores s\u00e3o avaliados em uma express\u00e3o. A associatividade determina a ordem em que os operadores com a mesma preced\u00eancia s\u00e3o avaliados.</p>"},{"location":"aulas/iot/modulos/modulo2.html#31-tabela-de-precedencia","title":"3.1 Tabela de Preced\u00eancia","text":"<p>Abaixo est\u00e1 uma tabela simplificada de preced\u00eancia de operadores em C/C++:</p> <ol> <li>Operadores de Incremento e Decremento: <code>++</code>, <code>--</code></li> <li>Operadores Multiplica\u00e7\u00e3o, Divis\u00e3o e M\u00f3dulo: <code>*</code>, <code>/</code>, <code>%</code></li> <li>Operadores Adi\u00e7\u00e3o e Subtra\u00e7\u00e3o: <code>+</code>, <code>-</code></li> <li>Operadores Relacionais: <code>&gt;</code>, <code>&lt;</code>, <code>&gt;=</code>, <code>&lt;=</code></li> <li>Operadores de Igualdade: <code>==</code>, <code>!=</code></li> <li>Operadores L\u00f3gicos AND: <code>&amp;&amp;</code></li> <li>Operadores L\u00f3gicos OR: <code>||</code></li> <li>Operadores de Atribui\u00e7\u00e3o: <code>=</code>, <code>+=</code>, <code>-=</code>, etc.</li> </ol>"},{"location":"aulas/iot/modulos/modulo2.html#32-associatividade","title":"3.2 Associatividade","text":"<p>A associatividade determina a ordem em que os operadores com a mesma preced\u00eancia s\u00e3o avaliados:</p> <ul> <li>Associatividade da Esquerda para a Direita:</li> </ul> <p>A maioria dos operadores possui associatividade da esquerda para a direita. Por exemplo:</p> <pre><code>int resultado = a + b - c;\n// \u00c9 interpretado como (a + b) - c\n</code></pre> <ul> <li>Associatividade da Direita para a Esquerda:</li> </ul> <p>Operadores de atribui\u00e7\u00e3o possuem associatividade da direita para a esquerda. Por exemplo:</p> <pre><code>a = b = c;\n// \u00c9 interpretado como a = (b = c)\n</code></pre>"},{"location":"aulas/iot/modulos/modulo2.html#33-exemplos-praticos","title":"3.3 Exemplos Pr\u00e1ticos","text":"<ul> <li>Exemplo 1:</li> </ul> <pre><code>int a = 5 + 3 * 2;\n</code></pre> <p>Explica\u00e7\u00e3o:</p> <ul> <li>A multiplica\u00e7\u00e3o (<code>3 * 2</code>) tem maior preced\u00eancia que a adi\u00e7\u00e3o (<code>5 +</code>), ent\u00e3o \u00e9 avaliada primeiro.</li> <li><code>a = 5 + 6;</code></li> <li> <p><code>a = 11;</code></p> </li> <li> <p>Exemplo 2:</p> </li> </ul> <pre><code>bool resultado = (a &gt; b) &amp;&amp; (c &lt; d);\n</code></pre> <p>Explica\u00e7\u00e3o:</p> <ul> <li>As express\u00f5es dentro dos par\u00eanteses s\u00e3o avaliadas primeiro devido \u00e0 preced\u00eancia dos par\u00eanteses.</li> <li><code>resultado</code> ser\u00e1 <code>true</code> somente se ambas as compara\u00e7\u00f5es forem verdadeiras.</li> </ul>"},{"location":"aulas/iot/modulos/modulo2.html#4-exemplos-praticos","title":"4. Exemplos Pr\u00e1ticos","text":""},{"location":"aulas/iot/modulos/modulo2.html#41-calculadora-simples","title":"4.1 Calculadora Simples","text":"<p>Vamos criar um programa que realiza opera\u00e7\u00f5es aritm\u00e9ticas b\u00e1sicas com base em dois n\u00fameros fornecidos pelo usu\u00e1rio.</p> <pre><code>int num1;\nint num2;\nchar operacao;\n\nvoid setup() {\n  Serial.begin(9600);\n  Serial.println(\"Calculadora Simples\");\n  Serial.println(\"Digite o primeiro n\u00famero:\");\n}\n\nvoid loop() {\n  if (Serial.available() &gt; 0) {\n    num1 = Serial.parseInt();\n    Serial.println(\"Digite a opera\u00e7\u00e3o (+, -, *, /):\");\n\n    while (Serial.available() == 0) {\n      // Aguarda a opera\u00e7\u00e3o\n    }\n\n    operacao = (char)Serial.read();\n    Serial.println(\"Digite o segundo n\u00famero:\");\n\n    while (Serial.available() == 0) {\n      // Aguarda o segundo n\u00famero\n    }\n\n    num2 = Serial.parseInt();\n\n    float resultado;\n\n    switch (operacao) {\n      case '+':\n        resultado = num1 + num2;\n        Serial.print(\"Resultado: \");\n        Serial.println(resultado);\n        break;\n      case '-':\n        resultado = num1 - num2;\n        Serial.print(\"Resultado: \");\n        Serial.println(resultado);\n        break;\n      case '*':\n        resultado = num1 * num2;\n        Serial.print(\"Resultado: \");\n        Serial.println(resultado);\n        break;\n      case '/':\n        if (num2 != 0) {\n          resultado = (float)num1 / num2;\n          Serial.print(\"Resultado: \");\n          Serial.println(resultado);\n        } else {\n          Serial.println(\"Erro: Divis\u00e3o por zero.\");\n        }\n        break;\n      default:\n        Serial.println(\"Opera\u00e7\u00e3o inv\u00e1lida.\");\n    }\n\n    Serial.println(\"Digite o primeiro n\u00famero para uma nova opera\u00e7\u00e3o:\");\n  }\n}\n</code></pre> <p>Explica\u00e7\u00e3o do C\u00f3digo:</p> <ul> <li>O programa solicita ao usu\u00e1rio que insira dois n\u00fameros e uma opera\u00e7\u00e3o aritm\u00e9tica.</li> <li>Utiliza estruturas de controle (<code>switch-case</code>) para determinar qual opera\u00e7\u00e3o realizar.</li> <li>Exibe o resultado no Monitor Serial.</li> <li>Cuida da divis\u00e3o por zero, exibindo uma mensagem de erro se necess\u00e1rio.</li> </ul>"},{"location":"aulas/iot/modulos/modulo2.html#5-exercicios-praticos","title":"5. Exerc\u00edcios Pr\u00e1ticos","text":""},{"location":"aulas/iot/modulos/modulo2.html#exercicio-1-calculadora-avancada","title":"Exerc\u00edcio 1: Calculadora Avan\u00e7ada","text":"<ul> <li> <p>Tarefa: Expanda a calculadora simples para incluir opera\u00e7\u00f5es de m\u00f3dulo (<code>%</code>) e exponencia\u00e7\u00e3o (<code>^</code>).</p> </li> <li> <p>Dicas:</p> </li> <li> <p>Para exponencia\u00e7\u00e3o, voc\u00ea pode usar a fun\u00e7\u00e3o <code>pow()</code> da biblioteca <code>math.h</code>.</p> </li> </ul> <pre><code>#include &lt;math.h&gt;\n\n// Dentro do switch-case\ncase '^':\n  resultado = pow(num1, num2);\n  Serial.print(\"Resultado: \");\n  Serial.println(resultado);\n  break;\n</code></pre>"},{"location":"aulas/iot/modulos/modulo2.html#exercicio-2-operador-ternario","title":"Exerc\u00edcio 2: Operador Tern\u00e1rio","text":"<ul> <li> <p>Tarefa: Escreva um programa que verifica se um n\u00famero fornecido \u00e9 positivo ou negativo usando o operador tern\u00e1rio (<code>? :</code>).</p> </li> <li> <p>Exemplo de C\u00f3digo:</p> </li> </ul> <pre><code>int numero;\n\nvoid setup() {\n  Serial.begin(9600);\n  Serial.println(\"Digite um n\u00famero:\");\n}\n\nvoid loop() {\n  if (Serial.available() &gt; 0) {\n    numero = Serial.parseInt();\n    String resultado = (numero &gt;= 0) ? \"Positivo\" : \"Negativo\";\n    Serial.print(\"O n\u00famero \u00e9: \");\n    Serial.println(resultado);\n    Serial.println(\"Digite outro n\u00famero:\");\n  }\n}\n</code></pre>"},{"location":"aulas/iot/modulos/modulo2.html#exercicio-3-precedencia-de-operadores","title":"Exerc\u00edcio 3: Preced\u00eancia de Operadores","text":"<ul> <li>Tarefa: Crie um programa que recebe tr\u00eas n\u00fameros e realiza a seguinte opera\u00e7\u00e3o:</li> </ul> <p><code>resultado = a + b * c;</code></p> <p>Imprima o resultado e explique a ordem de avalia\u00e7\u00e3o dos operadores.</p>"},{"location":"aulas/iot/modulos/modulo2.html#6-conceitos-importantes","title":"6. Conceitos Importantes","text":""},{"location":"aulas/iot/modulos/modulo2.html#61-parenteses-em-expressoes","title":"6.1 Par\u00eanteses em Express\u00f5es","text":"<p>Os par\u00eanteses <code>()</code> podem ser usados para alterar a preced\u00eancia de operadores, garantindo que determinadas opera\u00e7\u00f5es sejam realizadas primeiro.</p> <pre><code>int resultado = (a + b) * c;\n</code></pre> <p>Explica\u00e7\u00e3o:</p> <ul> <li>Com os par\u00eanteses, a adi\u00e7\u00e3o <code>a + b</code> \u00e9 realizada antes da multiplica\u00e7\u00e3o pelo <code>c</code>.</li> <li>Isso pode mudar o resultado final da express\u00e3o.</li> </ul>"},{"location":"aulas/iot/modulos/modulo2.html#62-operador-incremental-pre-e-pos","title":"6.2 Operador Incremental Pr\u00e9 e P\u00f3s","text":"<p>Os operadores incrementais (<code>++</code>) e decrementais (<code>--</code>) podem ser usados antes ou depois da vari\u00e1vel, influenciando o valor retornado pela express\u00e3o.</p> <ul> <li>Pr\u00e9-incremento (<code>++a</code>):</li> </ul> <p>Incrementa a vari\u00e1vel antes de retornar seu valor.</p> <pre><code>int a = 5;\nint b = ++a; // a = 6, b = 6\n</code></pre> <ul> <li>P\u00f3s-incremento (<code>a++</code>):</li> </ul> <p>Retorna o valor atual da vari\u00e1vel antes de increment\u00e1-la.</p> <pre><code>int a = 5;\nint b = a++; // a = 6, b = 5\n</code></pre>"},{"location":"aulas/iot/modulos/modulo2.html#63-cuidado-com-a-precedencia","title":"6.3 Cuidado com a Preced\u00eancia","text":"<p>Ao combinar diferentes tipos de operadores em uma express\u00e3o, \u00e9 crucial entender a preced\u00eancia para evitar resultados inesperados.</p> <p>Exemplo:</p> <pre><code>int a = 5;\nint b = 2;\nint c = 3;\n\nint resultado = a + b * c; // resultado = 5 + (2 * 3) = 11\n</code></pre>"},{"location":"aulas/iot/modulos/modulo3.html","title":"M\u00f3dulo 3: Estruturas de Controle de Fluxo","text":"<p>Bem-vindo ao M\u00f3dulo 3 do curso \"Programa\u00e7\u00e3o em Arduino: Conceitos Fundamentais sem Hardware\". Neste m\u00f3dulo, voc\u00ea ir\u00e1 explorar as estruturas de controle de fluxo na linguagem de programa\u00e7\u00e3o Arduino (C/C++). Estas estruturas s\u00e3o essenciais para criar programas que possam tomar decis\u00f5es e executar tarefas repetitivas de forma eficiente.</p>"},{"location":"aulas/iot/modulos/modulo3.html#objetivos-do-modulo","title":"Objetivos do M\u00f3dulo","text":"<ul> <li>Compreender as estruturas de controle de fluxo: condicionais (<code>if</code>, <code>else</code>, <code>switch-case</code>) e loops (<code>for</code>, <code>while</code>, <code>do-while</code>).</li> <li>Aplicar condicionais para tomar decis\u00f5es baseadas em condi\u00e7\u00f5es l\u00f3gicas.</li> <li>Utilizar loops para executar tarefas repetitivas.</li> <li>Entender a diferen\u00e7a entre diferentes tipos de loops e quando utiliz\u00e1-los.</li> <li>Resolver exerc\u00edcios pr\u00e1ticos para consolidar o conhecimento sobre estruturas de controle de fluxo.</li> </ul>"},{"location":"aulas/iot/modulos/modulo3.html#1-introducao-as-estruturas-de-controle-de-fluxo","title":"1. Introdu\u00e7\u00e3o \u00e0s Estruturas de Controle de Fluxo","text":"<p>As estruturas de controle de fluxo permitem que o programa desvie seu caminho de execu\u00e7\u00e3o com base em condi\u00e7\u00f5es ou repita certas partes do c\u00f3digo v\u00e1rias vezes. Elas s\u00e3o fundamentais para criar programas din\u00e2micos e eficientes.</p>"},{"location":"aulas/iot/modulos/modulo3.html#11-por-que-usar-estruturas-de-controle-de-fluxo","title":"1.1 Por que Usar Estruturas de Controle de Fluxo?","text":"<p>Sem estruturas de controle de fluxo, os programas seriam lineares e incapazes de responder a diferentes situa\u00e7\u00f5es ou de realizar tarefas repetitivas de forma eficiente. Elas permitem:</p> <ul> <li>Tomada de Decis\u00e3o: Executar diferentes blocos de c\u00f3digo com base em condi\u00e7\u00f5es.</li> <li>Repeti\u00e7\u00e3o: Executar blocos de c\u00f3digo m\u00faltiplas vezes sem duplica\u00e7\u00e3o.</li> <li>Organiza\u00e7\u00e3o: Melhorar a legibilidade e manuten\u00e7\u00e3o do c\u00f3digo.</li> </ul>"},{"location":"aulas/iot/modulos/modulo3.html#2-condicionais-if-else-e-switch-case","title":"2. Condicionais: <code>if</code>, <code>else</code> e <code>switch-case</code>","text":""},{"location":"aulas/iot/modulos/modulo3.html#21-estrutura-if-e-else","title":"2.1 Estrutura <code>if</code> e <code>else</code>","text":"<p>A estrutura <code>if</code> \u00e9 usada para executar um bloco de c\u00f3digo se uma condi\u00e7\u00e3o espec\u00edfica for verdadeira. A estrutura <code>else</code> pode ser usada para executar um bloco de c\u00f3digo alternativo se a condi\u00e7\u00e3o for falsa.</p>"},{"location":"aulas/iot/modulos/modulo3.html#sintaxe-do-if","title":"Sintaxe do <code>if</code>:","text":"<pre><code>if (condi\u00e7\u00e3o) {\n    // C\u00f3digo a ser executado se a condi\u00e7\u00e3o for verdadeira\n}\n</code></pre>"},{"location":"aulas/iot/modulos/modulo3.html#sintaxe-do-if-else","title":"Sintaxe do <code>if-else</code>:","text":"<pre><code>if (condi\u00e7\u00e3o) {\n    // C\u00f3digo a ser executado se a condi\u00e7\u00e3o for verdadeira\n} else {\n    // C\u00f3digo a ser executado se a condi\u00e7\u00e3o for falsa\n}\n</code></pre>"},{"location":"aulas/iot/modulos/modulo3.html#exemplo-pratico","title":"Exemplo Pr\u00e1tico:","text":"<pre><code>int idade = 20;\n\nvoid setup() {\n  Serial.begin(9600);\n\n  if (idade &gt;= 18) {\n    Serial.println(\"Voc\u00ea \u00e9 maior de idade.\");\n  } else {\n    Serial.println(\"Voc\u00ea \u00e9 menor de idade.\");\n  }\n}\n\nvoid loop() {\n  // N\u00e3o h\u00e1 c\u00f3digo no loop\n}\n</code></pre> <p>Explica\u00e7\u00e3o:</p> <ul> <li>Se a vari\u00e1vel <code>idade</code> for maior ou igual a 18, o Monitor Serial exibir\u00e1 \"Voc\u00ea \u00e9 maior de idade.\".</li> <li>Caso contr\u00e1rio, exibir\u00e1 \"Voc\u00ea \u00e9 menor de idade.\".</li> </ul>"},{"location":"aulas/iot/modulos/modulo3.html#22-estrutura-switch-case","title":"2.2 Estrutura <code>switch-case</code>","text":"<p>A estrutura <code>switch-case</code> \u00e9 uma forma mais organizada de lidar com m\u00faltiplas condi\u00e7\u00f5es baseadas no valor de uma \u00fanica vari\u00e1vel.</p>"},{"location":"aulas/iot/modulos/modulo3.html#sintaxe-do-switch-case","title":"Sintaxe do <code>switch-case</code>:","text":"<pre><code>switch (express\u00e3o) {\n    case valor1:\n        // C\u00f3digo a ser executado se express\u00e3o == valor1\n        break;\n    case valor2:\n        // C\u00f3digo a ser executado se express\u00e3o == valor2\n        break;\n    ...\n    default:\n        // C\u00f3digo a ser executado se express\u00e3o n\u00e3o corresponder a nenhum caso\n}\n</code></pre>"},{"location":"aulas/iot/modulos/modulo3.html#exemplo-pratico_1","title":"Exemplo Pr\u00e1tico:","text":"<pre><code>char opcao = 'B';\n\nvoid setup() {\n  Serial.begin(9600);\n\n  switch (opcao) {\n    case 'A':\n      Serial.println(\"Op\u00e7\u00e3o A selecionada.\");\n      break;\n    case 'B':\n      Serial.println(\"Op\u00e7\u00e3o B selecionada.\");\n      break;\n    case 'C':\n      Serial.println(\"Op\u00e7\u00e3o C selecionada.\");\n      break;\n    default:\n      Serial.println(\"Op\u00e7\u00e3o inv\u00e1lida.\");\n  }\n}\n\nvoid loop() {\n  // N\u00e3o h\u00e1 c\u00f3digo no loop\n}\n</code></pre> <p>Explica\u00e7\u00e3o:</p> <ul> <li>O programa verifica o valor da vari\u00e1vel <code>opcao</code>.</li> <li>Se <code>opcao</code> for 'A', 'B' ou 'C', imprime a mensagem correspondente.</li> <li>Se n\u00e3o corresponder a nenhum dos casos, executa o bloco <code>default</code>.</li> </ul>"},{"location":"aulas/iot/modulos/modulo3.html#23-exemplos-de-uso","title":"2.3 Exemplos de Uso","text":""},{"location":"aulas/iot/modulos/modulo3.html#exemplo-1-verificar-nota","title":"Exemplo 1: Verificar Nota","text":"<pre><code>int nota = 85;\n\nvoid setup() {\n  Serial.begin(9600);\n\n  if (nota &gt;= 90) {\n    Serial.println(\"A\");\n  } else if (nota &gt;= 80) {\n    Serial.println(\"B\");\n  } else if (nota &gt;= 70) {\n    Serial.println(\"C\");\n  } else if (nota &gt;= 60) {\n    Serial.println(\"D\");\n  } else {\n    Serial.println(\"F\");\n  }\n}\n\nvoid loop() {\n  // N\u00e3o h\u00e1 c\u00f3digo no loop\n}\n</code></pre> <p>Explica\u00e7\u00e3o:</p> <ul> <li>Dependendo do valor da vari\u00e1vel <code>nota</code>, uma letra correspondente \u00e0 faixa de nota \u00e9 exibida.</li> </ul>"},{"location":"aulas/iot/modulos/modulo3.html#exemplo-2-selecao-de-dia-da-semana","title":"Exemplo 2: Sele\u00e7\u00e3o de Dia da Semana","text":"<pre><code>int dia = 3;\n\nvoid setup() {\n  Serial.begin(9600);\n\n  switch (dia) {\n    case 1:\n      Serial.println(\"Domingo\");\n      break;\n    case 2:\n      Serial.println(\"Segunda-feira\");\n      break;\n    case 3:\n      Serial.println(\"Ter\u00e7a-feira\");\n      break;\n    case 4:\n      Serial.println(\"Quarta-feira\");\n      break;\n    case 5:\n      Serial.println(\"Quinta-feira\");\n      break;\n    case 6:\n      Serial.println(\"Sexta-feira\");\n      break;\n    case 7:\n      Serial.println(\"S\u00e1bado\");\n      break;\n    default:\n      Serial.println(\"Dia inv\u00e1lido\");\n  }\n}\n\nvoid loop() {\n  // N\u00e3o h\u00e1 c\u00f3digo no loop\n}\n</code></pre> <p>Explica\u00e7\u00e3o:</p> <ul> <li>O programa imprime o nome do dia da semana com base no valor da vari\u00e1vel <code>dia</code>.</li> </ul>"},{"location":"aulas/iot/modulos/modulo3.html#3-lacos-de-repeticao-for-while-e-do-while","title":"3. La\u00e7os de Repeti\u00e7\u00e3o: <code>for</code>, <code>while</code> e <code>do-while</code>","text":""},{"location":"aulas/iot/modulos/modulo3.html#31-estrutura-for","title":"3.1 Estrutura <code>for</code>","text":"<p>O la\u00e7o <code>for</code> \u00e9 usado quando o n\u00famero de itera\u00e7\u00f5es \u00e9 conhecido previamente. Ele consiste em tr\u00eas partes: inicializa\u00e7\u00e3o, condi\u00e7\u00e3o e incremento/decremento.</p>"},{"location":"aulas/iot/modulos/modulo3.html#sintaxe-do-for","title":"Sintaxe do <code>for</code>:","text":"<pre><code>for (inicializa\u00e7\u00e3o; condi\u00e7\u00e3o; incremento) {\n    // C\u00f3digo a ser repetido\n}\n</code></pre>"},{"location":"aulas/iot/modulos/modulo3.html#exemplo-pratico_2","title":"Exemplo Pr\u00e1tico:","text":"<pre><code>void setup() {\n  Serial.begin(9600);\n\n  for (int i = 1; i &lt;= 5; i++) {\n    Serial.print(\"Contagem: \");\n    Serial.println(i);\n  }\n}\n\nvoid loop() {\n  // N\u00e3o h\u00e1 c\u00f3digo no loop\n}\n</code></pre> <p>Explica\u00e7\u00e3o:</p> <ul> <li>O la\u00e7o inicia com <code>i = 1</code>.</li> <li>Enquanto <code>i &lt;= 5</code>, executa o bloco de c\u00f3digo.</li> <li>Ap\u00f3s cada itera\u00e7\u00e3o, incrementa <code>i</code> em 1.</li> </ul>"},{"location":"aulas/iot/modulos/modulo3.html#32-estrutura-while","title":"3.2 Estrutura <code>while</code>","text":"<p>O la\u00e7o <code>while</code> \u00e9 usado quando o n\u00famero de itera\u00e7\u00f5es n\u00e3o \u00e9 conhecido e depende de uma condi\u00e7\u00e3o ser verdadeira.</p>"},{"location":"aulas/iot/modulos/modulo3.html#sintaxe-do-while","title":"Sintaxe do <code>while</code>:","text":"<pre><code>while (condi\u00e7\u00e3o) {\n    // C\u00f3digo a ser repetido\n}\n</code></pre>"},{"location":"aulas/iot/modulos/modulo3.html#exemplo-pratico_3","title":"Exemplo Pr\u00e1tico:","text":"<pre><code>int contador = 1;\n\nvoid setup() {\n  Serial.begin(9600);\n\n  while (contador &lt;= 5) {\n    Serial.print(\"Contagem: \");\n    Serial.println(contador);\n    contador++;\n  }\n}\n\nvoid loop() {\n  // N\u00e3o h\u00e1 c\u00f3digo no loop\n}\n</code></pre> <p>Explica\u00e7\u00e3o:</p> <ul> <li>Enquanto <code>contador &lt;= 5</code>, o bloco de c\u00f3digo \u00e9 executado.</li> <li>Incrementa <code>contador</code> em cada itera\u00e7\u00e3o para evitar um loop infinito.</li> </ul>"},{"location":"aulas/iot/modulos/modulo3.html#33-estrutura-do-while","title":"3.3 Estrutura <code>do-while</code>","text":"<p>O la\u00e7o <code>do-while</code> \u00e9 similar ao <code>while</code>, mas garante que o bloco de c\u00f3digo seja executado pelo menos uma vez antes de verificar a condi\u00e7\u00e3o.</p>"},{"location":"aulas/iot/modulos/modulo3.html#sintaxe-do-do-while","title":"Sintaxe do <code>do-while</code>:","text":"<pre><code>do {\n    // C\u00f3digo a ser repetido\n} while (condi\u00e7\u00e3o);\n</code></pre>"},{"location":"aulas/iot/modulos/modulo3.html#exemplo-pratico_4","title":"Exemplo Pr\u00e1tico:","text":"<pre><code>int contador = 1;\n\nvoid setup() {\n  Serial.begin(9600);\n\n  do {\n    Serial.print(\"Contagem: \");\n    Serial.println(contador);\n    contador++;\n  } while (contador &lt;= 5);\n}\n\nvoid loop() {\n  // N\u00e3o h\u00e1 c\u00f3digo no loop\n}\n</code></pre> <p>Explica\u00e7\u00e3o:</p> <ul> <li>O bloco de c\u00f3digo dentro do <code>do</code> \u00e9 executado primeiro.</li> <li>Depois, a condi\u00e7\u00e3o \u00e9 verificada para determinar se o la\u00e7o deve continuar.</li> </ul>"},{"location":"aulas/iot/modulos/modulo3.html#34-comparacao-entre-for-while-e-do-while","title":"3.4 Compara\u00e7\u00e3o entre <code>for</code>, <code>while</code> e <code>do-while</code>","text":"<ul> <li><code>for</code>: Ideal quando o n\u00famero de itera\u00e7\u00f5es \u00e9 conhecido.</li> <li><code>while</code>: \u00datil quando o n\u00famero de itera\u00e7\u00f5es depende de uma condi\u00e7\u00e3o que pode mudar dinamicamente.</li> <li><code>do-while</code>: Garante que o bloco de c\u00f3digo seja executado pelo menos uma vez.</li> </ul>"},{"location":"aulas/iot/modulos/modulo3.html#35-exemplos-de-uso","title":"3.5 Exemplos de Uso","text":""},{"location":"aulas/iot/modulos/modulo3.html#exemplo-1-sequencia-de-fibonacci-com-for","title":"Exemplo 1: Sequ\u00eancia de Fibonacci com <code>for</code>","text":"<pre><code>int n = 10;\n\nvoid setup() {\n  Serial.begin(9600);\n\n  int a = 0, b = 1, c;\n  Serial.println(\"Sequ\u00eancia de Fibonacci:\");\n\n  for (int i = 0; i &lt; n; i++) {\n    Serial.println(a);\n    c = a + b;\n    a = b;\n    b = c;\n  }\n}\n\nvoid loop() {\n  // N\u00e3o h\u00e1 c\u00f3digo no loop\n}\n</code></pre> <p>Explica\u00e7\u00e3o:</p> <ul> <li>Imprime os primeiros <code>n</code> n\u00fameros da sequ\u00eancia de Fibonacci usando um la\u00e7o <code>for</code>.</li> </ul>"},{"location":"aulas/iot/modulos/modulo3.html#exemplo-2-verificar-se-um-numero-e-primo-com-while","title":"Exemplo 2: Verificar se um N\u00famero \u00e9 Primo com <code>while</code>","text":"<pre><code>int numero = 29;\nbool isPrimo = true;\nint i = 2;\n\nvoid setup() {\n  Serial.begin(9600);\n\n  if (numero &lt;= 1) {\n    isPrimo = false;\n  }\n\n  while (i &lt;= numero / 2) {\n    if (numero % i == 0) {\n      isPrimo = false;\n      break;\n    }\n    i++;\n  }\n\n  if (isPrimo) {\n    Serial.println(numero);\n    Serial.println(\" \u00e9 um n\u00famero primo.\");\n  } else {\n    Serial.println(numero);\n    Serial.println(\" n\u00e3o \u00e9 um n\u00famero primo.\");\n  }\n}\n\nvoid loop() {\n  // N\u00e3o h\u00e1 c\u00f3digo no loop\n}\n</code></pre> <p>Explica\u00e7\u00e3o:</p> <ul> <li>Verifica se <code>numero</code> \u00e9 primo utilizando um la\u00e7o <code>while</code>.</li> <li>Se encontrar um divisor, define <code>isPrimo</code> como <code>false</code> e sai do la\u00e7o.</li> </ul>"},{"location":"aulas/iot/modulos/modulo3.html#exemplo-3-solicitar-entradas-do-usuario-com-do-while","title":"Exemplo 3: Solicitar Entradas do Usu\u00e1rio com <code>do-while</code>","text":"<pre><code>int numero;\n\nvoid setup() {\n  Serial.begin(9600);\n\n  do {\n    Serial.println(\"Digite um n\u00famero positivo:\");\n    while (Serial.available() == 0) {\n      // Aguarda a entrada do usu\u00e1rio\n    }\n    numero = Serial.parseInt();\n  } while (numero &lt;= 0);\n\n  Serial.print(\"Voc\u00ea digitou: \");\n  Serial.println(numero);\n}\n\nvoid loop() {\n  // N\u00e3o h\u00e1 c\u00f3digo no loop\n}\n</code></pre> <p>Explica\u00e7\u00e3o:</p> <ul> <li>Solicita ao usu\u00e1rio que digite um n\u00famero positivo.</li> <li>Repete a solicita\u00e7\u00e3o at\u00e9 que o usu\u00e1rio insira um n\u00famero maior que 0.</li> </ul>"},{"location":"aulas/iot/modulos/modulo3.html#4-exemplos-praticos","title":"4. Exemplos Pr\u00e1ticos","text":""},{"location":"aulas/iot/modulos/modulo3.html#41-sequencia-de-fibonacci","title":"4.1 Sequ\u00eancia de Fibonacci","text":"<p>Vamos criar um programa que imprime a sequ\u00eancia de Fibonacci at\u00e9 o N-\u00e9simo termo.</p> <pre><code>int n = 10;\n\nvoid setup() {\n  Serial.begin(9600);\n\n  int a = 0, b = 1, c;\n  Serial.println(\"Sequ\u00eancia de Fibonacci:\");\n\n  for (int i = 0; i &lt; n; i++) {\n    Serial.println(a);\n    c = a + b;\n    a = b;\n    b = c;\n  }\n}\n\nvoid loop() {\n  // N\u00e3o h\u00e1 c\u00f3digo no loop\n}\n</code></pre>"},{"location":"aulas/iot/modulos/modulo3.html#42-verificar-numero-primo","title":"4.2 Verificar N\u00famero Primo","text":"<p>Crie um programa que verifica se um n\u00famero fornecido pelo usu\u00e1rio \u00e9 primo.</p> <pre><code>int numero = 29;\nbool isPrimo = true;\nint i = 2;\n\nvoid setup() {\n  Serial.begin(9600);\n\n  if (numero &lt;= 1) {\n    isPrimo = false;\n  }\n\n  while (i &lt;= numero / 2) {\n    if (numero % i == 0) {\n      isPrimo = false;\n      break;\n    }\n    i++;\n  }\n\n  if (isPrimo) {\n    Serial.println(numero);\n    Serial.println(\" \u00e9 um n\u00famero primo.\");\n  } else {\n    Serial.println(numero);\n    Serial.println(\" n\u00e3o \u00e9 um n\u00famero primo.\");\n  }\n}\n\nvoid loop() {\n  // N\u00e3o h\u00e1 c\u00f3digo no loop\n}\n</code></pre>"},{"location":"aulas/iot/modulos/modulo3.html#43-calculadora-de-numeros-positivos","title":"4.3 Calculadora de N\u00fameros Positivos","text":"<p>Escreva um programa que solicita ao usu\u00e1rio que digite n\u00fameros positivos at\u00e9 que um n\u00famero negativo seja inserido.</p> <pre><code>int numero;\n\nvoid setup() {\n  Serial.begin(9600);\n\n  do {\n    Serial.println(\"Digite um n\u00famero positivo:\");\n    while (Serial.available() == 0) {\n      // Aguarda a entrada do usu\u00e1rio\n    }\n    numero = Serial.parseInt();\n    if (numero &gt; 0) {\n      Serial.print(\"Voc\u00ea digitou: \");\n      Serial.println(numero);\n    }\n  } while (numero &gt;= 0);\n\n  Serial.println(\"N\u00famero negativo detectado. Programa encerrado.\");\n}\n\nvoid loop() {\n  // N\u00e3o h\u00e1 c\u00f3digo no loop\n}\n</code></pre>"},{"location":"aulas/iot/modulos/modulo3.html#5-exercicios-praticos","title":"5. Exerc\u00edcios Pr\u00e1ticos","text":""},{"location":"aulas/iot/modulos/modulo3.html#exercicio-1-sequencia-de-fatorial","title":"Exerc\u00edcio 1: Sequ\u00eancia de Fatorial","text":"<ul> <li> <p>Tarefa: Crie um programa que imprime o fatorial de um n\u00famero fornecido pelo usu\u00e1rio.</p> </li> <li> <p>Dicas:</p> </li> <li> <p>Utilize um la\u00e7o <code>for</code> para calcular o fatorial.</p> </li> </ul> <pre><code>long fatorial = 1;\nint numero = 5;\n\nfor (int i = 1; i &lt;= numero; i++) {\n  fatorial *= i;\n}\n\nSerial.print(\"Fatorial de \");\nSerial.print(numero);\nSerial.print(\" \u00e9 \");\nSerial.println(fatorial);\n</code></pre>"},{"location":"aulas/iot/modulos/modulo3.html#exercicio-2-contagem-regressiva","title":"Exerc\u00edcio 2: Contagem Regressiva","text":"<ul> <li> <p>Tarefa: Escreva um programa que realiza uma contagem regressiva de 10 at\u00e9 0 utilizando um la\u00e7o <code>while</code>.</p> </li> <li> <p>Exemplo de C\u00f3digo:</p> </li> </ul> <pre><code>int contador = 10;\n\nvoid setup() {\n  Serial.begin(9600);\n\n  while (contador &gt;= 0) {\n    Serial.println(contador);\n    contador--;\n    delay(1000); // Aguarda 1 segundo\n  }\n\n  Serial.println(\"Contagem finalizada!\");\n}\n\nvoid loop() {\n  // N\u00e3o h\u00e1 c\u00f3digo no loop\n}\n</code></pre>"},{"location":"aulas/iot/modulos/modulo3.html#exercicio-3-verificacao-de-paridade","title":"Exerc\u00edcio 3: Verifica\u00e7\u00e3o de Paridade","text":"<ul> <li> <p>Tarefa: Desenvolva um programa que solicita ao usu\u00e1rio um n\u00famero e verifica se ele \u00e9 par ou \u00edmpar usando uma estrutura <code>if-else</code>.</p> </li> <li> <p>Exemplo de C\u00f3digo:</p> </li> </ul> <pre><code>int numero;\n\nvoid setup() {\n  Serial.begin(9600);\n  Serial.println(\"Digite um n\u00famero:\");\n}\n\nvoid loop() {\n  if (Serial.available() &gt; 0) {\n    numero = Serial.parseInt();\n\n    if (numero % 2 == 0) {\n      Serial.print(numero);\n      Serial.println(\" \u00e9 um n\u00famero par.\");\n    } else {\n      Serial.print(numero);\n      Serial.println(\" \u00e9 um n\u00famero \u00edmpar.\");\n    }\n\n    Serial.println(\"Digite outro n\u00famero:\");\n  }\n}\n</code></pre>"},{"location":"aulas/iot/modulos/modulo3.html#6-conceitos-importantes","title":"6. Conceitos Importantes","text":""},{"location":"aulas/iot/modulos/modulo3.html#61-controle-de-fluxo","title":"6.1 Controle de Fluxo","text":"<p>Controlar o fluxo de execu\u00e7\u00e3o do programa \u00e9 essencial para criar programas que respondem a diferentes condi\u00e7\u00f5es e realizam tarefas de forma eficiente.</p>"},{"location":"aulas/iot/modulos/modulo3.html#62-evitar-loops-infinitos","title":"6.2 Evitar Loops Infinitos","text":"<p>Certifique-se de que os loops (<code>for</code>, <code>while</code>, <code>do-while</code>) tenham condi\u00e7\u00f5es que eventualmente se tornar\u00e3o falsas, evitando que o programa fique travado em um loop infinito.</p> <p>Exemplo de Loop Infinito:</p> <pre><code>while (true) {\n    // C\u00f3digo que nunca termina\n}\n</code></pre>"},{"location":"aulas/iot/modulos/modulo3.html#63-uso-adequado-de-break-e-continue","title":"6.3 Uso Adequado de <code>break</code> e <code>continue</code>","text":"<ul> <li><code>break</code>: Sai imediatamente do loop ou da estrutura <code>switch-case</code>.</li> <li><code>continue</code>: Pula para a pr\u00f3xima itera\u00e7\u00e3o do loop, ignorando o restante do c\u00f3digo no bloco atual.</li> </ul> <p>Exemplo de Uso de <code>break</code>:</p> <pre><code>for (int i = 0; i &lt; 10; i++) {\n    if (i == 5) {\n        break; // Sai do loop quando i \u00e9 5\n    }\n    Serial.println(i);\n}\n</code></pre> <p>Exemplo de Uso de <code>continue</code>:</p> <pre><code>for (int i = 0; i &lt; 10; i++) {\n    if (i % 2 == 0) {\n        continue; // Pula os n\u00fameros pares\n    }\n    Serial.println(i); // Imprime apenas os n\u00fameros \u00edmpares\n}\n</code></pre>"},{"location":"aulas/iot/modulos/modulo3.html#64-melhores-praticas","title":"6.4 Melhores Pr\u00e1ticas","text":"<ul> <li>Nomea\u00e7\u00e3o de Vari\u00e1veis: Use nomes significativos que reflitam o prop\u00f3sito da vari\u00e1vel.</li> </ul> <pre><code>int contador; // Melhor que 'c' ou 'x'\n</code></pre> <ul> <li>Indenta\u00e7\u00e3o Consistente: Ajuda a manter o c\u00f3digo leg\u00edvel e organizado.</li> </ul> <pre><code>if (condicao) {\n      // C\u00f3digo\n} else {\n      // Outro c\u00f3digo\n}\n</code></pre> <ul> <li>Evitar Repeti\u00e7\u00e3o de C\u00f3digo: Utilize fun\u00e7\u00f5es para reutilizar blocos de c\u00f3digo que se repetem</li> </ul>"},{"location":"aulas/iot/modulos/modulo4.html","title":"M\u00f3dulo 4: Fun\u00e7\u00f5es e Modulariza\u00e7\u00e3o","text":"<p>Bem-vindo ao M\u00f3dulo 4 do curso \"Programa\u00e7\u00e3o em Arduino: Conceitos Fundamentais sem Hardware\". Neste m\u00f3dulo, voc\u00ea ir\u00e1 aprofundar seu conhecimento sobre fun\u00e7\u00f5es na linguagem de programa\u00e7\u00e3o Arduino (C/C++) e aprender\u00e1 sobre modulariza\u00e7\u00e3o de c\u00f3digo. Compreender como criar e utilizar fun\u00e7\u00f5es de forma eficiente \u00e9 essencial para escrever c\u00f3digos mais organizados, reutiliz\u00e1veis e f\u00e1ceis de manter.</p>"},{"location":"aulas/iot/modulos/modulo4.html#objetivos-do-modulo","title":"Objetivos do M\u00f3dulo","text":"<ul> <li>Compreender o conceito de fun\u00e7\u00f5es e sua import\u00e2ncia na programa\u00e7\u00e3o.</li> <li>Aprender a definir e chamar fun\u00e7\u00f5es em Arduino.</li> <li>Trabalhar com par\u00e2metros e valores de retorno em fun\u00e7\u00f5es.</li> <li>Entender o escopo de vari\u00e1veis e a diferen\u00e7a entre vari\u00e1veis locais e globais.</li> <li>Implementar modulariza\u00e7\u00e3o de c\u00f3digo para melhorar a organiza\u00e7\u00e3o e reutiliza\u00e7\u00e3o.</li> <li>Resolver exerc\u00edcios pr\u00e1ticos para consolidar o conhecimento sobre fun\u00e7\u00f5es e modulariza\u00e7\u00e3o.</li> </ul>"},{"location":"aulas/iot/modulos/modulo4.html#1-introducao-as-funcoes","title":"1. Introdu\u00e7\u00e3o \u00e0s Fun\u00e7\u00f5es","text":""},{"location":"aulas/iot/modulos/modulo4.html#11-o-que-sao-funcoes","title":"1.1 O que s\u00e3o Fun\u00e7\u00f5es?","text":"<p>Fun\u00e7\u00f5es s\u00e3o blocos de c\u00f3digo que realizam tarefas espec\u00edficas e podem ser reutilizadas em diferentes partes de um programa. Elas ajudam a dividir um programa em partes menores e mais gerenci\u00e1veis, facilitando o desenvolvimento e a manuten\u00e7\u00e3o do c\u00f3digo.</p>"},{"location":"aulas/iot/modulos/modulo4.html#12-beneficios-do-uso-de-funcoes","title":"1.2 Benef\u00edcios do Uso de Fun\u00e7\u00f5es","text":"<ul> <li>Reutiliza\u00e7\u00e3o de C\u00f3digo: Escreva o c\u00f3digo uma vez e use-o m\u00faltiplas vezes.</li> <li>Organiza\u00e7\u00e3o: Separe o c\u00f3digo em blocos l\u00f3gicos para melhorar a legibilidade.</li> <li>Manuten\u00e7\u00e3o: Facilite a corre\u00e7\u00e3o e atualiza\u00e7\u00e3o do c\u00f3digo.</li> <li>Abstra\u00e7\u00e3o: Simplifique a complexidade do programa escondendo detalhes de implementa\u00e7\u00e3o.</li> </ul>"},{"location":"aulas/iot/modulos/modulo4.html#2-definindo-e-chamando-funcoes","title":"2. Definindo e Chamando Fun\u00e7\u00f5es","text":""},{"location":"aulas/iot/modulos/modulo4.html#21-definicao-de-funcoes","title":"2.1 Defini\u00e7\u00e3o de Fun\u00e7\u00f5es","text":"<p>Para definir uma fun\u00e7\u00e3o em Arduino, voc\u00ea especifica o tipo de retorno, o nome da fun\u00e7\u00e3o e, opcionalmente, os par\u00e2metros que ela recebe.</p> <p>Sintaxe:</p> <pre><code>tipo_retorno nome_funcao(tipo_parametro1 param1, tipo_parametro2 param2, ...) {\n    // Corpo da fun\u00e7\u00e3o\n}\n</code></pre> <p>Exemplo:</p> <pre><code>void saudacao() {\n    Serial.println(\"Bem-vindo ao curso de Arduino!\");\n}\n</code></pre>"},{"location":"aulas/iot/modulos/modulo4.html#22-chamando-funcoes","title":"2.2 Chamando Fun\u00e7\u00f5es","text":"<p>Ap\u00f3s definir uma fun\u00e7\u00e3o, voc\u00ea pode cham\u00e1-la em qualquer parte do seu c\u00f3digo (desde que esteja no escopo correto).</p> <p>Exemplo de Chamada:</p> <pre><code>void setup() {\n    Serial.begin(9600);\n    saudacao(); // Chamada da fun\u00e7\u00e3o saudacao\n}\n\nvoid loop() {\n    // C\u00f3digo do loop\n}\n</code></pre> <p>Explica\u00e7\u00e3o:</p> <ul> <li>A fun\u00e7\u00e3o <code>saudacao()</code> \u00e9 chamada dentro da fun\u00e7\u00e3o <code>setup()</code>.</li> <li>Quando o programa \u00e9 executado, o texto \"Bem-vindo ao curso de Arduino!\" ser\u00e1 impresso no Monitor Serial uma vez no in\u00edcio.</li> </ul>"},{"location":"aulas/iot/modulos/modulo4.html#3-parametros-e-valores-de-retorno","title":"3. Par\u00e2metros e Valores de Retorno","text":""},{"location":"aulas/iot/modulos/modulo4.html#31-funcoes-com-parametros","title":"3.1 Fun\u00e7\u00f5es com Par\u00e2metros","text":"<p>Par\u00e2metros permitem que voc\u00ea passe informa\u00e7\u00f5es para as fun\u00e7\u00f5es, tornando-as mais flex\u00edveis e reutiliz\u00e1veis.</p> <p>Sintaxe:</p> <pre><code>void nome_funcao(tipo_parametro1 param1, tipo_parametro2 param2) {\n    // Corpo da fun\u00e7\u00e3o\n}\n</code></pre> <p>Exemplo:</p> <pre><code>void imprimirMensagem(String mensagem) {\n    Serial.println(mensagem);\n}\n\nvoid setup() {\n    Serial.begin(9600);\n    imprimirMensagem(\"Ol\u00e1, Arduino!\");\n}\n\nvoid loop() {\n    // C\u00f3digo do loop\n}\n</code></pre> <p>Explica\u00e7\u00e3o:</p> <ul> <li>A fun\u00e7\u00e3o <code>imprimirMensagem</code> recebe uma <code>String</code> como par\u00e2metro e imprime no Monitor Serial.</li> <li>Isso permite que voc\u00ea passe diferentes mensagens para a fun\u00e7\u00e3o sem precisar alter\u00e1-la.</li> </ul>"},{"location":"aulas/iot/modulos/modulo4.html#32-funcoes-com-retorno","title":"3.2 Fun\u00e7\u00f5es com Retorno","text":"<p>Fun\u00e7\u00f5es podem retornar valores que podem ser utilizados em outras partes do programa.</p> <p>Sintaxe:</p> <pre><code>tipo_retorno nome_funcao(tipo_parametro1 param1, tipo_parametro2 param2) {\n    // Corpo da fun\u00e7\u00e3o\n    return valor;\n}\n</code></pre> <p>Exemplo:</p> <pre><code>int soma(int a, int b) {\n    return a + b;\n}\n\nvoid setup() {\n    Serial.begin(9600);\n    int resultado = soma(5, 3);\n    Serial.print(\"Resultado da soma: \");\n    Serial.println(resultado);\n}\n\nvoid loop() {\n    // C\u00f3digo do loop\n}\n</code></pre> <p>Explica\u00e7\u00e3o:</p> <ul> <li>A fun\u00e7\u00e3o <code>soma</code> recebe dois inteiros como par\u00e2metros e retorna a soma deles.</li> <li>O valor retornado \u00e9 armazenado na vari\u00e1vel <code>resultado</code> e impresso no Monitor Serial.</li> </ul>"},{"location":"aulas/iot/modulos/modulo4.html#4-escopo-de-variaveis","title":"4. Escopo de Vari\u00e1veis","text":""},{"location":"aulas/iot/modulos/modulo4.html#41-variaveis-locais","title":"4.1 Vari\u00e1veis Locais","text":"<p>Vari\u00e1veis declaradas dentro de uma fun\u00e7\u00e3o s\u00e3o chamadas de vari\u00e1veis locais e s\u00f3 podem ser acessadas dentro dessa fun\u00e7\u00e3o.</p> <p>Exemplo:</p> <pre><code>void setup() {\n    Serial.begin(9600);\n    int numero = 10; // Vari\u00e1vel local\n    Serial.println(numero);\n}\n\nvoid loop() {\n    // N\u00e3o h\u00e1 c\u00f3digo no loop\n}\n</code></pre> <p>Explica\u00e7\u00e3o:</p> <ul> <li>A vari\u00e1vel <code>numero</code> s\u00f3 existe dentro da fun\u00e7\u00e3o <code>setup()</code>.</li> <li>Tentativas de acessar <code>numero</code> fora de <code>setup()</code> resultar\u00e3o em erro.</li> </ul>"},{"location":"aulas/iot/modulos/modulo4.html#42-variaveis-globais","title":"4.2 Vari\u00e1veis Globais","text":"<p>Vari\u00e1veis declaradas fora de todas as fun\u00e7\u00f5es s\u00e3o chamadas de vari\u00e1veis globais e podem ser acessadas por qualquer fun\u00e7\u00e3o no programa.</p> <p>Exemplo:</p> <pre><code>int contador = 0; // Vari\u00e1vel global\n\nvoid setup() {\n    Serial.begin(9600);\n    Serial.println(contador);\n}\n\nvoid loop() {\n    contador++;\n    Serial.println(contador);\n    delay(1000);\n}\n</code></pre> <p>Explica\u00e7\u00e3o:</p> <ul> <li>A vari\u00e1vel <code>contador</code> \u00e9 acess\u00edvel tanto em <code>setup()</code> quanto em <code>loop()</code>.</li> <li>O valor de <code>contador</code> \u00e9 incrementado e impresso a cada segundo.</li> </ul>"},{"location":"aulas/iot/modulos/modulo4.html#5-modularizacao-de-codigo","title":"5. Modulariza\u00e7\u00e3o de C\u00f3digo","text":""},{"location":"aulas/iot/modulos/modulo4.html#51-por-que-modularizar","title":"5.1 Por que Modularizar?","text":"<p>Modularizar significa dividir o c\u00f3digo em m\u00f3dulos ou fun\u00e7\u00f5es menores que realizam tarefas espec\u00edficas. Isso melhora a legibilidade, facilita a manuten\u00e7\u00e3o e permite a reutiliza\u00e7\u00e3o de c\u00f3digo.</p>"},{"location":"aulas/iot/modulos/modulo4.html#52-exemplos-de-modularizacao","title":"5.2 Exemplos de Modulariza\u00e7\u00e3o","text":"<p>Exemplo 1: Separar C\u00e1lculo da Impress\u00e3o</p> <pre><code>int calcularSoma(int a, int b) {\n    return a + b;\n}\n\nvoid imprimirSoma(int a, int b) {\n    int resultado = calcularSoma(a, b);\n    Serial.print(\"A soma de \");\n    Serial.print(a);\n    Serial.print(\" e \");\n    Serial.print(b);\n    Serial.print(\" \u00e9: \");\n    Serial.println(resultado);\n}\n\nvoid setup() {\n    Serial.begin(9600);\n    imprimirSoma(5, 7);\n}\n\nvoid loop() {\n    // N\u00e3o h\u00e1 c\u00f3digo no loop\n}\n</code></pre> <p>Explica\u00e7\u00e3o:</p> <ul> <li>A fun\u00e7\u00e3o <code>calcularSoma</code> realiza o c\u00e1lculo da soma.</li> <li>A fun\u00e7\u00e3o <code>imprimirSoma</code> gerencia a impress\u00e3o do resultado.</li> <li>Isso separa as responsabilidades, tornando o c\u00f3digo mais organizado.</li> </ul> <p>Exemplo 2: Controle de LEDs com Fun\u00e7\u00f5es</p> <pre><code>const int ledVerde = 9;\nconst int ledVermelho = 10;\n\nvoid ligarLedVerde() {\n    digitalWrite(ledVerde, HIGH);\n}\n\nvoid desligarLedVerde() {\n    digitalWrite(ledVerde, LOW);\n}\n\nvoid ligarLedVermelho() {\n    digitalWrite(ledVermelho, HIGH);\n}\n\nvoid desligarLedVermelho() {\n    digitalWrite(ledVermelho, LOW);\n}\n\nvoid setup() {\n    pinMode(ledVerde, OUTPUT);\n    pinMode(ledVermelho, OUTPUT);\n}\n\nvoid loop() {\n    ligarLedVerde();\n    delay(1000);\n    desligarLedVerde();\n    ligarLedVermelho();\n    delay(1000);\n    desligarLedVermelho();\n}\n</code></pre> <p>Explica\u00e7\u00e3o:</p> <ul> <li>Fun\u00e7\u00f5es espec\u00edficas para ligar e desligar LEDs verde e vermelho.</li> <li>Facilita a manipula\u00e7\u00e3o dos LEDs sem repetir o c\u00f3digo.</li> </ul>"},{"location":"aulas/iot/modulos/modulo4.html#6-exemplos-praticos","title":"6. Exemplos Pr\u00e1ticos","text":""},{"location":"aulas/iot/modulos/modulo4.html#61-funcao-para-calcular-fatorial","title":"6.1 Fun\u00e7\u00e3o para Calcular Fatorial","text":"<pre><code>long calcularFatorial(int numero) {\n    if (numero &lt; 0) return -1; // Retorna -1 para n\u00fameros negativos\n    long fatorial = 1;\n    for (int i = 1; i &lt;= numero; i++) {\n        fatorial *= i;\n    }\n    return fatorial;\n}\n\nvoid setup() {\n    Serial.begin(9600);\n    int num = 5;\n    long resultado = calcularFatorial(num);\n    if (resultado != -1) {\n        Serial.print(\"Fatorial de \");\n        Serial.print(num);\n        Serial.print(\" \u00e9 \");\n        Serial.println(resultado);\n    } else {\n        Serial.println(\"Erro: Fatorial de n\u00famero negativo n\u00e3o existe.\");\n    }\n}\n\nvoid loop() {\n    // N\u00e3o h\u00e1 c\u00f3digo no loop\n}\n</code></pre> <p>Explica\u00e7\u00e3o:</p> <ul> <li>A fun\u00e7\u00e3o <code>calcularFatorial</code> retorna o fatorial de um n\u00famero.</li> <li>Verifica se o n\u00famero \u00e9 negativo e retorna erro se for.</li> <li>O resultado \u00e9 impresso no Monitor Serial.</li> </ul>"},{"location":"aulas/iot/modulos/modulo4.html#62-funcao-para-verificar-palindromo","title":"6.2 Fun\u00e7\u00e3o para Verificar Pal\u00edndromo","text":"<pre><code>bool ehPalindromo(String palavra) {\n    int inicio = 0;\n    int fim = palavra.length() - 1;\n    while (inicio &lt; fim) {\n        if (tolower(palavra[inicio]) != tolower(palavra[fim])) {\n            return false;\n        }\n        inicio++;\n        fim--;\n    }\n    return true;\n}\n\nvoid setup() {\n    Serial.begin(9600);\n    String palavra = \"Radar\";\n    if (ehPalindromo(palavra)) {\n        Serial.println(palavra + \" \u00e9 um pal\u00edndromo.\");\n    } else {\n        Serial.println(palavra + \" n\u00e3o \u00e9 um pal\u00edndromo.\");\n    }\n}\n\nvoid loop() {\n    // N\u00e3o h\u00e1 c\u00f3digo no loop\n}\n</code></pre> <p>Explica\u00e7\u00e3o:</p> <ul> <li>A fun\u00e7\u00e3o <code>ehPalindromo</code> verifica se uma palavra \u00e9 um pal\u00edndromo.</li> <li>Compara caracteres do in\u00edcio e fim da string.</li> <li>Ignora diferen\u00e7as de mai\u00fasculas e min\u00fasculas.</li> </ul>"},{"location":"aulas/iot/modulos/modulo4.html#63-funcao-para-converter-celsius-em-fahrenheit","title":"6.3 Fun\u00e7\u00e3o para Converter Celsius em Fahrenheit","text":"<pre><code>float celsiusParaFahrenheit(float celsius) {\n    return (celsius * 9.0 / 5.0) + 32.0;\n}\n\nvoid setup() {\n    Serial.begin(9600);\n    float tempC = 25.0;\n    float tempF = celsiusParaFahrenheit(tempC);\n    Serial.print(tempC);\n    Serial.print(\"\u00b0C \u00e9 igual a \");\n    Serial.print(tempF);\n    Serial.println(\"\u00b0F.\");\n}\n\nvoid loop() {\n    // N\u00e3o h\u00e1 c\u00f3digo no loop\n}\n</code></pre> <p>Explica\u00e7\u00e3o:</p> <ul> <li>A fun\u00e7\u00e3o <code>celsiusParaFahrenheit</code> converte uma temperatura de Celsius para Fahrenheit.</li> <li>O resultado \u00e9 impresso no Monitor Serial.</li> </ul>"},{"location":"aulas/iot/modulos/modulo4.html#7-exercicios-praticos","title":"7. Exerc\u00edcios Pr\u00e1ticos","text":""},{"location":"aulas/iot/modulos/modulo4.html#exercicio-1-funcao-para-calcular-media","title":"Exerc\u00edcio 1: Fun\u00e7\u00e3o para Calcular M\u00e9dia","text":"<ul> <li> <p>Tarefa: Crie uma fun\u00e7\u00e3o que calcula a m\u00e9dia de tr\u00eas n\u00fameros fornecidos pelo usu\u00e1rio e imprime o resultado.</p> </li> <li> <p>Dicas:</p> </li> <li> <p>Utilize uma fun\u00e7\u00e3o que recebe tr\u00eas par\u00e2metros e retorna a m\u00e9dia.</p> </li> </ul> <pre><code>float calcularMedia(float a, float b, float c) {\n    return (a + b + c) / 3.0;\n}\n\nvoid setup() {\n    Serial.begin(9600);\n    float num1 = 7.5;\n    float num2 = 8.0;\n    float num3 = 9.5;\n    float media = calcularMedia(num1, num2, num3);\n    Serial.print(\"A m\u00e9dia \u00e9: \");\n    Serial.println(media);\n}\n\nvoid loop() {\n    // N\u00e3o h\u00e1 c\u00f3digo no loop\n}\n</code></pre>"},{"location":"aulas/iot/modulos/modulo4.html#exercicio-2-funcao-para-determinar-o-maior-numero","title":"Exerc\u00edcio 2: Fun\u00e7\u00e3o para Determinar o Maior N\u00famero","text":"<ul> <li> <p>Tarefa: Escreva uma fun\u00e7\u00e3o que recebe dois n\u00fameros e retorna o maior deles. Use essa fun\u00e7\u00e3o no seu programa para comparar dois n\u00fameros fornecidos pelo usu\u00e1rio.</p> </li> <li> <p>Exemplo de C\u00f3digo:</p> </li> </ul> <pre><code>int encontrarMaior(int a, int b) {\n    if (a &gt; b) {\n        return a;\n    } else {\n        return b;\n    }\n}\n\nvoid setup() {\n    Serial.begin(9600);\n    int num1 = 15;\n    int num2 = 20;\n    int maior = encontrarMaior(num1, num2);\n    Serial.print(\"O maior n\u00famero \u00e9: \");\n    Serial.println(maior);\n}\n\nvoid loop() {\n    // N\u00e3o h\u00e1 c\u00f3digo no loop\n}\n</code></pre>"},{"location":"aulas/iot/modulos/modulo4.html#exercicio-3-funcao-para-verificar-numero-par-ou-impar","title":"Exerc\u00edcio 3: Fun\u00e7\u00e3o para Verificar N\u00famero Par ou \u00cdmpar","text":"<ul> <li> <p>Tarefa: Desenvolva uma fun\u00e7\u00e3o que recebe um n\u00famero inteiro e retorna <code>true</code> se o n\u00famero for par ou <code>false</code> se for \u00edmpar. Utilize essa fun\u00e7\u00e3o para verificar a paridade de um n\u00famero fornecido pelo usu\u00e1rio.</p> </li> <li> <p>Exemplo de C\u00f3digo:</p> </li> </ul> <pre><code>bool ehPar(int numero) {\n    return (numero % 2 == 0);\n}\n\nvoid setup() {\n    Serial.begin(9600);\n    int num = 7;\n    if (ehPar(num)) {\n        Serial.println(\"O n\u00famero \u00e9 par.\");\n    } else {\n        Serial.println(\"O n\u00famero \u00e9 \u00edmpar.\");\n    }\n}\n\nvoid loop() {\n    // N\u00e3o h\u00e1 c\u00f3digo no loop\n}\n</code></pre>"},{"location":"aulas/iot/modulos/modulo4.html#8-conceitos-importantes","title":"8. Conceitos Importantes","text":""},{"location":"aulas/iot/modulos/modulo4.html#81-recursao","title":"8.1 Recurs\u00e3o","text":"<p>A recurs\u00e3o ocorre quando uma fun\u00e7\u00e3o chama a si mesma para resolver um problema. \u00c9 uma t\u00e9cnica poderosa, mas deve ser usada com cuidado para evitar loops infinitos.</p> <p>Exemplo de Fun\u00e7\u00e3o Recursiva para Calcular Fatorial:</p> <pre><code>long fatorialRecursivo(int numero) {\n    if (numero &lt;= 1) {\n        return 1;\n    } else {\n        return numero * fatorialRecursivo(numero - 1);\n    }\n}\n\nvoid setup() {\n    Serial.begin(9600);\n    int num = 5;\n    long resultado = fatorialRecursivo(num);\n    Serial.print(\"Fatorial de \");\n    Serial.print(num);\n    Serial.print(\" \u00e9 \");\n    Serial.println(resultado);\n}\n\nvoid loop() {\n    // N\u00e3o h\u00e1 c\u00f3digo no loop\n}\n</code></pre> <p>Explica\u00e7\u00e3o:</p> <ul> <li>A fun\u00e7\u00e3o <code>fatorialRecursivo</code> chama a si mesma at\u00e9 que a condi\u00e7\u00e3o base seja atingida (<code>numero &lt;= 1</code>).</li> <li>Calcula o fatorial de forma recursiva.</li> </ul>"},{"location":"aulas/iot/modulos/modulo4.html#82-funcoes-inline","title":"8.2 Fun\u00e7\u00f5es Inline","text":"<p>Fun\u00e7\u00f5es inline s\u00e3o sugest\u00f5es ao compilador para inserir o corpo da fun\u00e7\u00e3o no ponto de chamada, reduzindo a sobrecarga de chamadas de fun\u00e7\u00e3o.</p> <p>Exemplo:</p> <pre><code>inline int quadrado(int x) {\n    return x * x;\n}\n\nvoid setup() {\n    Serial.begin(9600);\n    int num = 4;\n    int q = quadrado(num);\n    Serial.print(\"Quadrado de \");\n    Serial.print(num);\n    Serial.print(\" \u00e9 \");\n    Serial.println(q);\n}\n\nvoid loop() {\n    // N\u00e3o h\u00e1 c\u00f3digo no loop\n}\n</code></pre> <p>Explica\u00e7\u00e3o:</p> <ul> <li>A fun\u00e7\u00e3o <code>quadrado</code> \u00e9 definida como <code>inline</code>, sugerindo ao compilador para otimizar a chamada da fun\u00e7\u00e3o.</li> </ul>"},{"location":"aulas/iot/modulos/modulo4.html#83-sobrecarga-de-funcoes","title":"8.3 Sobrecarga de Fun\u00e7\u00f5es","text":"<p>Sobrecarga permite definir m\u00faltiplas fun\u00e7\u00f5es com o mesmo nome, mas com diferentes par\u00e2metros.</p> <p>Exemplo:</p> <pre><code>int soma(int a, int b) {\n    return a + b;\n}\n\nfloat soma(float a, float b) {\n    return a + b;\n}\n\nvoid setup() {\n    Serial.begin(9600);\n    Serial.print(\"Soma de 5 e 3: \");\n    Serial.println(soma(5, 3));\n    Serial.print(\"Soma de 5.5 e 3.2: \");\n    Serial.println(soma(5.5, 3.2));\n}\n\nvoid loop() {\n    // N\u00e3o h\u00e1 c\u00f3digo no loop\n}\n</code></pre> <p>Explica\u00e7\u00e3o:</p> <ul> <li>Duas fun\u00e7\u00f5es <code>soma</code> s\u00e3o definidas, uma para inteiros e outra para floats.</li> <li>O compilador decide qual fun\u00e7\u00e3o chamar com base nos argumentos fornecidos.</li> </ul>"},{"location":"aulas/iot/modulos/modulo5.html","title":"M\u00f3dulo 5: Arrays e Manipula\u00e7\u00e3o de Dados","text":"<p>Bem-vindo ao M\u00f3dulo 5 do curso \"Programa\u00e7\u00e3o em Arduino: Conceitos Fundamentais sem Hardware\". Neste m\u00f3dulo, voc\u00ea ir\u00e1 aprender sobre arrays e manipula\u00e7\u00e3o de dados na linguagem de programa\u00e7\u00e3o Arduino (C/C++). Arrays s\u00e3o estruturas de dados que armazenam m\u00faltiplos valores do mesmo tipo, permitindo o gerenciamento eficiente de cole\u00e7\u00f5es de dados.</p>"},{"location":"aulas/iot/modulos/modulo5.html#objetivos-do-modulo","title":"Objetivos do M\u00f3dulo","text":"<ul> <li>Compreender o conceito de arrays e sua import\u00e2ncia na programa\u00e7\u00e3o.</li> <li>Aprender a declarar, inicializar e acessar elementos de arrays.</li> <li>Trabalhar com arrays multidimensionais.</li> <li>Aplicar loops para manipular dados em arrays.</li> <li>Implementar fun\u00e7\u00f5es que utilizam arrays como par\u00e2metros.</li> <li>Realizar opera\u00e7\u00f5es de busca e ordena\u00e7\u00e3o em arrays.</li> <li>Resolver exerc\u00edcios pr\u00e1ticos para consolidar o conhecimento sobre arrays e manipula\u00e7\u00e3o de dados.</li> </ul>"},{"location":"aulas/iot/modulos/modulo5.html#1-introducao-aos-arrays","title":"1. Introdu\u00e7\u00e3o aos Arrays","text":""},{"location":"aulas/iot/modulos/modulo5.html#11-o-que-sao-arrays","title":"1.1 O que s\u00e3o Arrays?","text":"<p>Um array \u00e9 uma estrutura de dados que armazena uma cole\u00e7\u00e3o de elementos do mesmo tipo em posi\u00e7\u00f5es cont\u00edguas de mem\u00f3ria. Cada elemento em um array \u00e9 identificado por um \u00edndice, permitindo o acesso r\u00e1pido e eficiente aos dados.</p>"},{"location":"aulas/iot/modulos/modulo5.html#12-beneficios-do-uso-de-arrays","title":"1.2 Benef\u00edcios do Uso de Arrays","text":"<ul> <li>Organiza\u00e7\u00e3o: Permite armazenar m\u00faltiplos valores relacionados de forma organizada.</li> <li>Efici\u00eancia: Facilita o processamento de grandes conjuntos de dados.</li> <li>Facilidade de Acesso: Permite acessar elementos individuais usando \u00edndices.</li> <li>Redu\u00e7\u00e3o de Repeti\u00e7\u00e3o: Evita a necessidade de declarar m\u00faltiplas vari\u00e1veis para armazenar dados semelhantes.</li> </ul>"},{"location":"aulas/iot/modulos/modulo5.html#2-declaracao-e-inicializacao-de-arrays","title":"2. Declara\u00e7\u00e3o e Inicializa\u00e7\u00e3o de Arrays","text":""},{"location":"aulas/iot/modulos/modulo5.html#21-declaracao-de-arrays","title":"2.1 Declara\u00e7\u00e3o de Arrays","text":"<p>Para declarar um array, voc\u00ea especifica o tipo de dados dos elementos e o n\u00famero de elementos que o array ir\u00e1 conter.</p> <p>Sintaxe:</p> <pre><code>tipo nome_array[tamanho];\n</code></pre> <p>Exemplo:</p> <pre><code>int notas[5];\n</code></pre>"},{"location":"aulas/iot/modulos/modulo5.html#22-inicializacao-de-arrays","title":"2.2 Inicializa\u00e7\u00e3o de Arrays","text":"<p>Voc\u00ea pode inicializar um array no momento da declara\u00e7\u00e3o ou atribuir valores individualmente.</p> <p>Inicializa\u00e7\u00e3o na Declara\u00e7\u00e3o:</p> <pre><code>int notas[5] = {85, 90, 78, 92, 88};\n</code></pre> <p>Atribui\u00e7\u00e3o Individual:</p> <pre><code>int notas[5];\nnotas[0] = 85;\nnotas[1] = 90;\nnotas[2] = 78;\nnotas[3] = 92;\nnotas[4] = 88;\n</code></pre>"},{"location":"aulas/iot/modulos/modulo5.html#23-acesso-aos-elementos-do-array","title":"2.3 Acesso aos Elementos do Array","text":"<p>Os elementos de um array s\u00e3o acessados usando \u00edndices, que come\u00e7am em 0.</p> <p>Exemplo:</p> <pre><code>int primeiraNota = notas[0]; // Acessa o primeiro elemento\nint terceiraNota = notas[2]; // Acessa o terceiro elemento\n</code></pre> <p>Imprimindo Elementos no Monitor Serial:</p> <pre><code>void setup() {\n    Serial.begin(9600);\n    Serial.println(notas[0]); // Imprime 85\n    Serial.println(notas[2]); // Imprime 78\n}\n\nvoid loop() {\n    // N\u00e3o h\u00e1 c\u00f3digo no loop\n}\n</code></pre>"},{"location":"aulas/iot/modulos/modulo5.html#3-arrays-multidimensionais","title":"3. Arrays Multidimensionais","text":""},{"location":"aulas/iot/modulos/modulo5.html#31-declaracao-de-arrays-2d","title":"3.1 Declara\u00e7\u00e3o de Arrays 2D","text":"<p>Arrays multidimensionais permitem armazenar dados em uma grade ou tabela.</p> <p>Sintaxe:</p> <pre><code>tipo nome_array[linha][coluna];\n</code></pre> <p>Exemplo:</p> <pre><code>int matriz[3][4];\n</code></pre>"},{"location":"aulas/iot/modulos/modulo5.html#32-inicializacao-de-arrays-2d","title":"3.2 Inicializa\u00e7\u00e3o de Arrays 2D","text":"<pre><code>int matriz[2][3] = {\n    {1, 2, 3},\n    {4, 5, 6}\n};\n</code></pre>"},{"location":"aulas/iot/modulos/modulo5.html#33-acesso-aos-elementos-de-arrays-2d","title":"3.3 Acesso aos Elementos de Arrays 2D","text":"<pre><code>int valor = matriz[1][2]; // Acessa o elemento na segunda linha, terceira coluna (valor = 6)\n</code></pre> <p>Imprimindo uma Matriz no Monitor Serial:</p> <pre><code>void setup() {\n    Serial.begin(9600);\n\n    for(int i = 0; i &lt; 2; i++) { // Percorre as linhas\n        for(int j = 0; j &lt; 3; j++) { // Percorre as colunas\n            Serial.print(matriz[i][j]);\n            Serial.print(\" \");\n        }\n        Serial.println();\n    }\n}\n\nvoid loop() {\n    // N\u00e3o h\u00e1 c\u00f3digo no loop\n}\n</code></pre>"},{"location":"aulas/iot/modulos/modulo5.html#4-manipulacao-de-arrays-com-loops","title":"4. Manipula\u00e7\u00e3o de Arrays com Loops","text":""},{"location":"aulas/iot/modulos/modulo5.html#41-uso-de-for-para-iterar-sobre-arrays","title":"4.1 Uso de <code>for</code> para Iterar sobre Arrays","text":"<pre><code>void setup() {\n    Serial.begin(9600);\n\n    for(int i = 0; i &lt; 5; i++) {\n        Serial.print(\"Nota \");\n        Serial.print(i + 1);\n        Serial.print(\": \");\n        Serial.println(notas[i]);\n    }\n}\n\nvoid loop() {\n    // N\u00e3o h\u00e1 c\u00f3digo no loop\n}\n</code></pre>"},{"location":"aulas/iot/modulos/modulo5.html#42-uso-de-while-para-iterar-sobre-arrays","title":"4.2 Uso de <code>while</code> para Iterar sobre Arrays","text":"<pre><code>void setup() {\n    Serial.begin(9600);\n    int i = 0;\n\n    while(i &lt; 5) {\n        Serial.print(\"Nota \");\n        Serial.print(i + 1);\n        Serial.print(\": \");\n        Serial.println(notas[i]);\n        i++;\n    }\n}\n\nvoid loop() {\n    // N\u00e3o h\u00e1 c\u00f3digo no loop\n}\n</code></pre>"},{"location":"aulas/iot/modulos/modulo5.html#43-uso-de-do-while-para-iterar-sobre-arrays","title":"4.3 Uso de <code>do-while</code> para Iterar sobre Arrays","text":"<pre><code>void setup() {\n    Serial.begin(9600);\n    int i = 0;\n\n    do {\n        Serial.print(\"Nota \");\n        Serial.print(i + 1);\n        Serial.print(\": \");\n        Serial.println(notas[i]);\n        i++;\n    } while(i &lt; 5);\n}\n\nvoid loop() {\n    // N\u00e3o h\u00e1 c\u00f3digo no loop\n}\n</code></pre>"},{"location":"aulas/iot/modulos/modulo5.html#5-funcoes-com-arrays","title":"5. Fun\u00e7\u00f5es com Arrays","text":""},{"location":"aulas/iot/modulos/modulo5.html#51-passando-arrays-como-parametros","title":"5.1 Passando Arrays como Par\u00e2metros","text":"<pre><code>void imprimirNotas(int arr[], int tamanho) {\n    for(int i = 0; i &lt; tamanho; i++) {\n        Serial.print(\"Nota \");\n        Serial.print(i + 1);\n        Serial.print(\": \");\n        Serial.println(arr[i]);\n    }\n}\n\nvoid setup() {\n    Serial.begin(9600);\n    imprimirNotas(notas, 5);\n}\n\nvoid loop() {\n    // N\u00e3o h\u00e1 c\u00f3digo no loop\n}\n</code></pre>"},{"location":"aulas/iot/modulos/modulo5.html#52-funcoes-que-retornam-arrays","title":"5.2 Fun\u00e7\u00f5es que Retornam Arrays","text":"<p>Em C/C++, fun\u00e7\u00f5es n\u00e3o podem retornar arrays diretamente, mas podem retornar ponteiros para arrays ou utilizar estruturas de dados alternativas como <code>std::vector</code> (n\u00e3o muito comum no Arduino devido a limita\u00e7\u00f5es de mem\u00f3ria).</p> <p>Exemplo de Retorno de Ponteiro para Array:</p> <pre><code>int* retornarNotas() {\n    static int notasRetornadas[5] = {85, 90, 78, 92, 88};\n    return notasRetornadas;\n}\n\nvoid setup() {\n    Serial.begin(9600);\n    int* notas = retornarNotas();\n\n    for(int i = 0; i &lt; 5; i++) {\n        Serial.print(\"Nota \");\n        Serial.print(i + 1);\n        Serial.print(\": \");\n        Serial.println(notas[i]);\n    }\n}\n\nvoid loop() {\n    // N\u00e3o h\u00e1 c\u00f3digo no loop\n}\n</code></pre> <p>Explica\u00e7\u00e3o:</p> <ul> <li>A fun\u00e7\u00e3o <code>retornarNotas</code> retorna um ponteiro para o array est\u00e1tico <code>notasRetornadas</code>.</li> <li>O array \u00e9 est\u00e1tico para evitar que seja destru\u00eddo ao sair da fun\u00e7\u00e3o.</li> </ul>"},{"location":"aulas/iot/modulos/modulo5.html#6-operacoes-com-arrays","title":"6. Opera\u00e7\u00f5es com Arrays","text":""},{"location":"aulas/iot/modulos/modulo5.html#61-busca-em-arrays","title":"6.1 Busca em Arrays","text":"<pre><code>int buscarNota(int arr[], int tamanho, int valorBuscado) {\n    for(int i = 0; i &lt; tamanho; i++) {\n        if(arr[i] == valorBuscado) {\n            return i; // Retorna o \u00edndice onde o valor foi encontrado\n        }\n    }\n    return -1; // Retorna -1 se o valor n\u00e3o for encontrado\n}\n\nvoid setup() {\n    Serial.begin(9600);\n    int valor = 90;\n    int indice = buscarNota(notas, 5, valor);\n\n    if(indice != -1) {\n        Serial.print(\"Valor \");\n        Serial.print(valor);\n        Serial.print(\" encontrado no \u00edndice \");\n        Serial.println(indice);\n    } else {\n        Serial.print(\"Valor \");\n        Serial.print(valor);\n        Serial.println(\" n\u00e3o encontrado.\");\n    }\n}\n\nvoid loop() {\n    // N\u00e3o h\u00e1 c\u00f3digo no loop\n}\n</code></pre>"},{"location":"aulas/iot/modulos/modulo5.html#62-ordenacao-de-arrays","title":"6.2 Ordena\u00e7\u00e3o de Arrays","text":""},{"location":"aulas/iot/modulos/modulo5.html#621-ordenacao-bubble-sort","title":"6.2.1 Ordena\u00e7\u00e3o Bubble Sort","text":"<pre><code>void bubbleSort(int arr[], int tamanho) {\n    for(int i = 0; i &lt; tamanho - 1; i++) {\n        for(int j = 0; j &lt; tamanho - i - 1; j++) {\n            if(arr[j] &gt; arr[j + 1]) {\n                // Troca arr[j] e arr[j + 1]\n                int temp = arr[j];\n                arr[j] = arr[j + 1];\n                arr[j + 1] = temp;\n            }\n        }\n    }\n}\n\nvoid setup() {\n    Serial.begin(9600);\n    Serial.println(\"Notas antes da ordena\u00e7\u00e3o:\");\n    imprimirNotas(notas, 5);\n\n    bubbleSort(notas, 5);\n\n    Serial.println(\"Notas ap\u00f3s a ordena\u00e7\u00e3o:\");\n    imprimirNotas(notas, 5);\n}\n\nvoid loop() {\n    // N\u00e3o h\u00e1 c\u00f3digo no loop\n}\n</code></pre> <p>Explica\u00e7\u00e3o:</p> <ul> <li>O algoritmo Bubble Sort compara pares de elementos adjacentes e os troca se estiverem na ordem errada.</li> <li>Este processo \u00e9 repetido at\u00e9 que o array esteja ordenado.</li> </ul>"},{"location":"aulas/iot/modulos/modulo5.html#622-ordenacao-selection-sort","title":"6.2.2 Ordena\u00e7\u00e3o Selection Sort","text":"<pre><code>void selectionSort(int arr[], int tamanho) {\n    for(int i = 0; i &lt; tamanho - 1; i++) {\n        int minIndex = i;\n        for(int j = i + 1; j &lt; tamanho; j++) {\n            if(arr[j] &lt; arr[minIndex]) {\n                minIndex = j;\n            }\n        }\n        // Troca arr[i] e arr[minIndex]\n        int temp = arr[i];\n        arr[i] = arr[minIndex];\n        arr[minIndex] = temp;\n    }\n}\n\nvoid setup() {\n    Serial.begin(9600);\n    Serial.println(\"Notas antes da ordena\u00e7\u00e3o:\");\n    imprimirNotas(notas, 5);\n\n    selectionSort(notas, 5);\n\n    Serial.println(\"Notas ap\u00f3s a ordena\u00e7\u00e3o:\");\n    imprimirNotas(notas, 5);\n}\n\nvoid loop() {\n    // N\u00e3o h\u00e1 c\u00f3digo no loop\n}\n</code></pre> <p>Explica\u00e7\u00e3o:</p> <ul> <li>O algoritmo Selection Sort seleciona o menor elemento do array e o coloca na posi\u00e7\u00e3o correta.</li> <li>Este processo \u00e9 repetido para cada posi\u00e7\u00e3o do array.</li> </ul>"},{"location":"aulas/iot/modulos/modulo5.html#63-media-e-mediana","title":"6.3 M\u00e9dia e Mediana","text":"<pre><code>float calcularMedia(int arr[], int tamanho) {\n    int soma = 0;\n    for(int i = 0; i &lt; tamanho; i++) {\n        soma += arr[i];\n    }\n    return (float)soma / tamanho;\n}\n\nfloat calcularMediana(int arr[], int tamanho) {\n    // Primeiro, ordenar o array\n    bubbleSort(arr, tamanho);\n\n    if(tamanho % 2 == 0) {\n        return (arr[tamanho / 2 - 1] + arr[tamanho / 2]) / 2.0;\n    } else {\n        return arr[tamanho / 2];\n    }\n}\n\nvoid setup() {\n    Serial.begin(9600);\n\n    // Exibir array ordenado\n    bubbleSort(notas, 5);\n    Serial.println(\"Notas ordenadas:\");\n    imprimirNotas(notas, 5);\n\n    float media = calcularMedia(notas, 5);\n    float mediana = calcularMediana(notas, 5);\n\n    Serial.print(\"M\u00e9dia das notas: \");\n    Serial.println(media);\n\n    Serial.print(\"Mediana das notas: \");\n    Serial.println(mediana);\n}\n\nvoid loop() {\n    // N\u00e3o h\u00e1 c\u00f3digo no loop\n}\n</code></pre> <p>Explica\u00e7\u00e3o:</p> <ul> <li>A fun\u00e7\u00e3o <code>calcularMedia</code> soma todos os elementos do array e divide pelo n\u00famero de elementos.</li> <li>A fun\u00e7\u00e3o <code>calcularMediana</code> ordena o array e retorna o valor do meio ou a m\u00e9dia dos dois valores centrais.</li> </ul>"},{"location":"aulas/iot/modulos/modulo5.html#7-exercicios-praticos","title":"7. Exerc\u00edcios Pr\u00e1ticos","text":""},{"location":"aulas/iot/modulos/modulo5.html#exercicio-1-busca-sequencial","title":"Exerc\u00edcio 1: Busca Sequencial","text":"<ul> <li> <p>Tarefa: Crie uma fun\u00e7\u00e3o que realiza busca sequencial em um array de inteiros. A fun\u00e7\u00e3o deve retornar o \u00edndice do elemento buscado ou -1 se n\u00e3o encontrado.</p> </li> <li> <p>Exemplo de C\u00f3digo:</p> </li> </ul> <pre><code>int buscaSequencial(int arr[], int tamanho, int valorBuscado) {\n    for(int i = 0; i &lt; tamanho; i++) {\n        if(arr[i] == valorBuscado) {\n            return i;\n        }\n    }\n    return -1;\n}\n\nvoid setup() {\n    Serial.begin(9600);\n    int valor = 78;\n    int indice = buscaSequencial(notas, 5, valor);\n\n    if(indice != -1) {\n        Serial.print(\"Valor \");\n        Serial.print(valor);\n        Serial.print(\" encontrado no \u00edndice \");\n        Serial.println(indice);\n    } else {\n        Serial.print(\"Valor \");\n        Serial.print(valor);\n        Serial.println(\" n\u00e3o encontrado.\");\n    }\n}\n\nvoid loop() {\n    // N\u00e3o h\u00e1 c\u00f3digo no loop\n}\n</code></pre>"},{"location":"aulas/iot/modulos/modulo5.html#exercicio-2-ordenacao-descrescente","title":"Exerc\u00edcio 2: Ordena\u00e7\u00e3o Descrescente","text":"<ul> <li> <p>Tarefa: Modifique a fun\u00e7\u00e3o de ordena\u00e7\u00e3o Bubble Sort para ordenar o array em ordem decrescente.</p> </li> <li> <p>Exemplo de C\u00f3digo:</p> </li> </ul> <pre><code>void bubbleSortDesc(int arr[], int tamanho) {\n    for(int i = 0; i &lt; tamanho - 1; i++) {\n        for(int j = 0; j &lt; tamanho - i - 1; j++) {\n            if(arr[j] &lt; arr[j + 1]) {\n                // Troca arr[j] e arr[j + 1]\n                int temp = arr[j];\n                arr[j] = arr[j + 1];\n                arr[j + 1] = temp;\n            }\n        }\n    }\n}\n\nvoid setup() {\n    Serial.begin(9600);\n    Serial.println(\"Notas antes da ordena\u00e7\u00e3o decrescente:\");\n    imprimirNotas(notas, 5);\n\n    bubbleSortDesc(notas, 5);\n\n    Serial.println(\"Notas ap\u00f3s a ordena\u00e7\u00e3o decrescente:\");\n    imprimirNotas(notas, 5);\n}\n\nvoid loop() {\n    // N\u00e3o h\u00e1 c\u00f3digo no loop\n}\n</code></pre>"},{"location":"aulas/iot/modulos/modulo5.html#exercicio-3-funcao-para-encontrar-o-maior-e-menor-elemento","title":"Exerc\u00edcio 3: Fun\u00e7\u00e3o para Encontrar o Maior e Menor Elemento","text":"<ul> <li> <p>Tarefa: Crie duas fun\u00e7\u00f5es: uma que retorna o maior elemento em um array e outra que retorna o menor elemento.</p> </li> <li> <p>Exemplo de C\u00f3digo:</p> </li> </ul> <pre><code>int encontrarMaior(int arr[], int tamanho) {\n    int maior = arr[0];\n    for(int i = 1; i &lt; tamanho; i++) {\n        if(arr[i] &gt; maior) {\n            maior = arr[i];\n        }\n    }\n    return maior;\n}\n\nint encontrarMenor(int arr[], int tamanho) {\n    int menor = arr[0];\n    for(int i = 1; i &lt; tamanho; i++) {\n        if(arr[i] &lt; menor) {\n            menor = arr[i];\n        }\n    }\n    return menor;\n}\n\nvoid setup() {\n    Serial.begin(9600);\n    int maior = encontrarMaior(notas, 5);\n    int menor = encontrarMenor(notas, 5);\n\n    Serial.print(\"Maior nota: \");\n    Serial.println(maior);\n\n    Serial.print(\"Menor nota: \");\n    Serial.println(menor);\n}\n\nvoid loop() {\n    // N\u00e3o h\u00e1 c\u00f3digo no loop\n}\n</code></pre>"},{"location":"aulas/iot/modulos/modulo5.html#8-conceitos-importantes","title":"8. Conceitos Importantes","text":""},{"location":"aulas/iot/modulos/modulo5.html#81-vetores-vs-arrays","title":"8.1 Vetores vs. Arrays","text":"<p>Em C/C++, os termos \"vetor\" e \"array\" s\u00e3o frequentemente usados de forma intercambi\u00e1vel para se referirem a estruturas de dados que armazenam m\u00faltiplos elementos do mesmo tipo.</p>"},{"location":"aulas/iot/modulos/modulo5.html#82-limitacoes-dos-arrays-em-arduino","title":"8.2 Limita\u00e7\u00f5es dos Arrays em Arduino","text":"<ul> <li>Tamanho Fixos: Arrays em C/C++ t\u00eam tamanho fixo que deve ser conhecido em tempo de compila\u00e7\u00e3o.</li> <li>Uso de Mem\u00f3ria: Arrays grandes podem consumir significativamente a mem\u00f3ria dispon\u00edvel, especialmente em placas com recursos limitados como o Arduino Uno.</li> <li>Falta de Funcionalidades Avan\u00e7adas: Diferente de linguagens mais modernas, C/C++ n\u00e3o oferece m\u00e9todos avan\u00e7ados para manipula\u00e7\u00e3o de arrays (como inser\u00e7\u00e3o din\u00e2mica).</li> </ul>"},{"location":"aulas/iot/modulos/modulo5.html#83-alternativas-aos-arrays","title":"8.3 Alternativas aos Arrays","text":"<ul> <li>Estruturas (<code>struct</code>): Permitem agrupar diferentes tipos de dados.</li> <li>Listas Ligadas e Outras Estruturas de Dados Din\u00e2micas: Oferecem flexibilidade no gerenciamento de dados, mas s\u00e3o mais complexas para implementar em C/C++ no Arduino.</li> <li>Bibliotecas: Existem bibliotecas que facilitam o uso de arrays din\u00e2micos ou outros tipos de cole\u00e7\u00f5es de dados, mas seu uso deve ser cuidadoso devido \u00e0s limita\u00e7\u00f5es de mem\u00f3ria.</li> </ul>"},{"location":"aulas/iot/modulos/modulo5.html#84-dicas-para-trabalhar-com-arrays","title":"8.4 Dicas para Trabalhar com Arrays","text":"<ul> <li>Sempre Inicialize Arrays: Para evitar valores indeterminados.</li> <li>Evite Acessar \u00cdndices Fora dos Limites: Pode causar comportamentos inesperados ou erros de execu\u00e7\u00e3o.</li> <li>Utilize Constantes para Tamanhos: Facilita a manuten\u00e7\u00e3o do c\u00f3digo.</li> </ul>"},{"location":"aulas/iot/modulos/modulo6.html","title":"M\u00f3dulo 6: Strings e Opera\u00e7\u00f5es com Texto","text":"<p>Bem-vindo ao M\u00f3dulo 6 do curso \"Programa\u00e7\u00e3o em Arduino: Conceitos Fundamentais sem Hardware\". Neste m\u00f3dulo, voc\u00ea ir\u00e1 explorar o uso de strings e opera\u00e7\u00f5es com texto na linguagem de programa\u00e7\u00e3o Arduino (C/C++). Manipular strings \u00e9 essencial para lidar com entradas e sa\u00eddas de texto, especialmente ao interagir com o Monitor Serial.</p>"},{"location":"aulas/iot/modulos/modulo6.html#objetivos-do-modulo","title":"Objetivos do M\u00f3dulo","text":"<ul> <li>Compreender o conceito de strings em Arduino e como utiliz\u00e1-las.</li> <li>Aprender a declarar, inicializar e manipular strings.</li> <li>Trabalhar com fun\u00e7\u00f5es de manipula\u00e7\u00e3o de strings como <code>length()</code>, <code>concat()</code>, <code>substring()</code>, <code>indexOf()</code>, <code>replace()</code>, entre outras.</li> <li>Realizar opera\u00e7\u00f5es de compara\u00e7\u00e3o e busca em strings.</li> <li>Implementar fun\u00e7\u00f5es que utilizam strings como par\u00e2metros e retornos.</li> <li>Entender o gerenciamento de mem\u00f3ria ao trabalhar com strings.</li> <li>Resolver exerc\u00edcios pr\u00e1ticos para consolidar o conhecimento sobre strings e opera\u00e7\u00f5es com texto.</li> </ul>"},{"location":"aulas/iot/modulos/modulo6.html#1-introducao-as-strings","title":"1. Introdu\u00e7\u00e3o \u00e0s Strings","text":""},{"location":"aulas/iot/modulos/modulo6.html#11-o-que-sao-strings","title":"1.1 O que s\u00e3o Strings?","text":"<p>Em C/C++, uma string \u00e9 uma sequ\u00eancia de caracteres terminada por um caractere nulo (<code>'\\0'</code>). No Arduino, as strings podem ser manipuladas de duas formas principais:</p> <ul> <li>Strings em C: Usam arrays de caracteres (<code>char</code>).</li> <li>Classe <code>String</code>: Uma classe que encapsula strings e oferece m\u00e9todos para manipula\u00e7\u00e3o mais f\u00e1cil.</li> </ul>"},{"location":"aulas/iot/modulos/modulo6.html#12-diferencas-entre-strings-em-c-e-a-classe-string","title":"1.2 Diferen\u00e7as entre Strings em C e a Classe <code>String</code>","text":"<ul> <li>Strings em C:</li> <li>Mais eficientes em termos de mem\u00f3ria.</li> <li>Menos seguros, pois requerem cuidado com o gerenciamento de mem\u00f3ria.</li> <li> <p>Manipula\u00e7\u00e3o mais complexa.</p> </li> <li> <p>Classe <code>String</code>:</p> </li> <li>Mais f\u00e1cil de usar com m\u00e9todos integrados para manipula\u00e7\u00e3o.</li> <li>Menos eficiente em termos de mem\u00f3ria, podendo levar a fragmenta\u00e7\u00e3o.</li> <li>Conveniente para iniciantes.</li> </ul>"},{"location":"aulas/iot/modulos/modulo6.html#2-trabalhando-com-a-classe-string","title":"2. Trabalhando com a Classe <code>String</code>","text":""},{"location":"aulas/iot/modulos/modulo6.html#21-declaracao-e-inicializacao","title":"2.1 Declara\u00e7\u00e3o e Inicializa\u00e7\u00e3o","text":"<p>Declarando uma String:</p> <pre><code>String mensagem;\n</code></pre> <p>Inicializando uma String:</p> <pre><code>String mensagem = \"Ol\u00e1, Arduino!\";\n</code></pre>"},{"location":"aulas/iot/modulos/modulo6.html#22-concatenando-strings","title":"2.2 Concatenando Strings","text":"<p>Voc\u00ea pode concatenar strings usando o operador <code>+</code> ou o m\u00e9todo <code>concat()</code>.</p> <p>Usando o Operador <code>+</code>:</p> <pre><code>String saudacao = \"Ol\u00e1\";\nString nome = \"Maria\";\nString mensagem = saudacao + \", \" + nome + \"!\";\n</code></pre> <p>Usando o M\u00e9todo <code>concat()</code>:</p> <pre><code>String mensagem = \"Ol\u00e1\";\nmensagem.concat(\", Maria!\");\n</code></pre>"},{"location":"aulas/iot/modulos/modulo6.html#23-acessando-caracteres-individuais","title":"2.3 Acessando Caracteres Individuais","text":"<p>Voc\u00ea pode acessar caracteres individuais de uma string usando a nota\u00e7\u00e3o de colchetes <code>[]</code>.</p> <pre><code>String palavra = \"Arduino\";\nchar primeiraLetra = palavra[0]; // 'A'\nchar ultimaLetra = palavra[6];    // 'o'\n</code></pre>"},{"location":"aulas/iot/modulos/modulo6.html#24-metodos-comuns-da-classe-string","title":"2.4 M\u00e9todos Comuns da Classe <code>String</code>","text":"<ul> <li><code>length()</code>: Retorna o tamanho da string.</li> </ul> <pre><code>int tamanho = mensagem.length();\n</code></pre> <ul> <li><code>substring()</code>: Retorna uma substring de uma string.</li> </ul> <pre><code>String sub = mensagem.substring(0, 4); // \"Ol\u00e1,\"\n</code></pre> <ul> <li><code>indexOf()</code>: Retorna o \u00edndice da primeira ocorr\u00eancia de um caractere ou substring.</li> </ul> <pre><code>int pos = mensagem.indexOf(\"Maria\"); // 5\n</code></pre> <ul> <li><code>replace()</code>: Substitui todas as ocorr\u00eancias de uma substring por outra.</li> </ul> <pre><code>mensagem.replace(\"Maria\", \"Jo\u00e3o\"); // \"Ol\u00e1, Jo\u00e3o!\"\n</code></pre> <ul> <li><code>toLowerCase()</code> e <code>toUpperCase()</code>: Convertem a string para min\u00fasculas ou mai\u00fasculas.</li> </ul> <pre><code>mensagem.toLowerCase(); // \"ol\u00e1, jo\u00e3o!\"\nmensagem.toUpperCase(); // \"OL\u00c1, JO\u00c3O!\"\n</code></pre>"},{"location":"aulas/iot/modulos/modulo6.html#3-manipulacao-de-strings-com-arrays-de-caracteres","title":"3. Manipula\u00e7\u00e3o de Strings com Arrays de Caracteres","text":""},{"location":"aulas/iot/modulos/modulo6.html#31-declarando-e-inicializando-arrays-de-caracteres","title":"3.1 Declarando e Inicializando Arrays de Caracteres","text":"<pre><code>char mensagem[] = \"Ol\u00e1, Arduino!\";\n</code></pre>"},{"location":"aulas/iot/modulos/modulo6.html#32-funcoes-de-manipulacao-de-strings-em-c","title":"3.2 Fun\u00e7\u00f5es de Manipula\u00e7\u00e3o de Strings em C","text":"<ul> <li><code>strlen()</code>: Retorna o comprimento da string.</li> </ul> <pre><code>int tamanho = strlen(mensagem);\n</code></pre> <ul> <li><code>strcpy()</code>: Copia uma string para outra.</li> </ul> <pre><code>char copia[20];\nstrcpy(copia, mensagem);\n</code></pre> <ul> <li><code>strcat()</code>: Concatena duas strings.</li> </ul> <pre><code>char saudacao[20] = \"Bem-vindo \";\nstrcat(saudacao, \"ao Arduino!\");\n</code></pre> <ul> <li><code>strcmp()</code>: Compara duas strings.</li> </ul> <pre><code>if(strcmp(mensagem, copia) == 0) {\n    // Strings s\u00e3o iguais\n}\n</code></pre>"},{"location":"aulas/iot/modulos/modulo6.html#4-entrada-e-saida-de-strings-com-o-monitor-serial","title":"4. Entrada e Sa\u00edda de Strings com o Monitor Serial","text":""},{"location":"aulas/iot/modulos/modulo6.html#41-enviando-strings-para-o-monitor-serial","title":"4.1 Enviando Strings para o Monitor Serial","text":"<pre><code>void setup() {\n    Serial.begin(9600);\n    String mensagem = \"Ol\u00e1, Mundo!\";\n    Serial.println(mensagem);\n}\n\nvoid loop() {\n    // N\u00e3o h\u00e1 c\u00f3digo no loop\n}\n</code></pre>"},{"location":"aulas/iot/modulos/modulo6.html#42-recebendo-strings-do-monitor-serial","title":"4.2 Recebendo Strings do Monitor Serial","text":"<pre><code>String entrada = \"\";\n\nvoid setup() {\n    Serial.begin(9600);\n    Serial.println(\"Digite uma mensagem:\");\n}\n\nvoid loop() {\n    if(Serial.available() &gt; 0) {\n        entrada = Serial.readString();\n        Serial.print(\"Voc\u00ea digitou: \");\n        Serial.println(entrada);\n        Serial.println(\"Digite outra mensagem:\");\n    }\n}\n</code></pre> <p>Explica\u00e7\u00e3o:</p> <ul> <li>O programa solicita que o usu\u00e1rio digite uma mensagem.</li> <li>Usa <code>Serial.readString()</code> para ler a entrada do usu\u00e1rio.</li> <li>Imprime a mensagem recebida no Monitor Serial.</li> </ul>"},{"location":"aulas/iot/modulos/modulo6.html#5-funcoes-com-strings","title":"5. Fun\u00e7\u00f5es com Strings","text":""},{"location":"aulas/iot/modulos/modulo6.html#51-passando-strings-como-parametros","title":"5.1 Passando Strings como Par\u00e2metros","text":"<pre><code>void imprimirMensagem(String msg) {\n    Serial.println(msg);\n}\n\nvoid setup() {\n    Serial.begin(9600);\n    imprimirMensagem(\"Bem-vindo ao M\u00f3dulo 6!\");\n}\n\nvoid loop() {\n    // N\u00e3o h\u00e1 c\u00f3digo no loop\n}\n</code></pre>"},{"location":"aulas/iot/modulos/modulo6.html#52-funcoes-que-retornam-strings","title":"5.2 Fun\u00e7\u00f5es que Retornam Strings","text":"<pre><code>String obterSaudacao() {\n    return \"Ol\u00e1, estudante!\";\n}\n\nvoid setup() {\n    Serial.begin(9600);\n    String saudacao = obterSaudacao();\n    Serial.println(saudacao);\n}\n\nvoid loop() {\n    // N\u00e3o h\u00e1 c\u00f3digo no loop\n}\n</code></pre> <p>Explica\u00e7\u00e3o:</p> <ul> <li>A fun\u00e7\u00e3o <code>obterSaudacao</code> retorna uma string.</li> <li>A string retornada \u00e9 armazenada na vari\u00e1vel <code>saudacao</code> e impressa no Monitor Serial.</li> </ul>"},{"location":"aulas/iot/modulos/modulo6.html#6-gerenciamento-de-memoria-com-strings","title":"6. Gerenciamento de Mem\u00f3ria com Strings","text":""},{"location":"aulas/iot/modulos/modulo6.html#61-uso-de-strings-vs-arrays-de-caracteres","title":"6.1 Uso de Strings vs. Arrays de Caracteres","text":"<ul> <li>Strings da Classe <code>String</code>:</li> <li>Mais f\u00e1ceis de usar.</li> <li> <p>Podem causar fragmenta\u00e7\u00e3o de mem\u00f3ria em sistemas com recursos limitados.</p> </li> <li> <p>Arrays de Caracteres:</p> </li> <li>Mais eficientes em termos de mem\u00f3ria.</li> <li>Requerem mais cuidado na manipula\u00e7\u00e3o.</li> </ul>"},{"location":"aulas/iot/modulos/modulo6.html#62-evitando-fragmentacao-de-memoria","title":"6.2 Evitando Fragmenta\u00e7\u00e3o de Mem\u00f3ria","text":"<ul> <li>Evitar Muitas Opera\u00e7\u00f5es de Concatena\u00e7\u00e3o:</li> <li> <p>Opera\u00e7\u00f5es frequentes de <code>concat</code> podem fragmentar a mem\u00f3ria.</p> </li> <li> <p>Usar Strings de Forma Constante:</p> </li> <li>Declarar strings como constantes (<code>const char*</code>) sempre que poss\u00edvel.</li> </ul> <pre><code>const char* mensagem = \"Bem-vindo!\";\n</code></pre> <ul> <li>Gerenciar o Tamanho dos Arrays:</li> <li>Certifique-se de que os arrays de caracteres sejam grandes o suficiente para armazenar as strings e o caractere nulo.</li> </ul> <pre><code>char mensagem[20] = \"Este \u00e9 um exemplo seguro.\";\n</code></pre>"},{"location":"aulas/iot/modulos/modulo6.html#7-exemplos-praticos","title":"7. Exemplos Pr\u00e1ticos","text":""},{"location":"aulas/iot/modulos/modulo6.html#71-criando-um-sistema-de-mensagens","title":"7.1 Criando um Sistema de Mensagens","text":"<pre><code>String mensagens[] = {\"Mensagem 1\", \"Mensagem 2\", \"Mensagem 3\"};\nint totalMensagens = 3;\n\nvoid setup() {\n    Serial.begin(9600);\n    for(int i = 0; i &lt; totalMensagens; i++) {\n        Serial.println(mensagens[i]);\n    }\n}\n\nvoid loop() {\n    // N\u00e3o h\u00e1 c\u00f3digo no loop\n}\n</code></pre> <p>Explica\u00e7\u00e3o:</p> <ul> <li>Armazena m\u00faltiplas mensagens em um array de strings.</li> <li>Imprime cada mensagem no Monitor Serial usando um la\u00e7o <code>for</code>.</li> </ul>"},{"location":"aulas/iot/modulos/modulo6.html#72-manipulando-nomes-de-usuarios","title":"7.2 Manipulando Nomes de Usu\u00e1rios","text":"<pre><code>String nome = \"\";\nString saudacao = \"\";\n\nvoid setup() {\n    Serial.begin(9600);\n    Serial.println(\"Digite seu nome:\");\n}\n\nvoid loop() {\n    if(Serial.available() &gt; 0) {\n        nome = Serial.readString();\n        saudacao = \"Ol\u00e1, \" + nome + \"!\";\n        Serial.println(saudacao);\n        Serial.println(\"Digite seu nome novamente ou reinicie o Arduino para sair.\");\n    }\n}\n</code></pre> <p>Explica\u00e7\u00e3o:</p> <ul> <li>Recebe o nome do usu\u00e1rio via Monitor Serial.</li> <li>Concatena a sauda\u00e7\u00e3o com o nome fornecido.</li> <li>Imprime a sauda\u00e7\u00e3o personalizada.</li> </ul>"},{"location":"aulas/iot/modulos/modulo6.html#73-processando-dados-de-sensor-com-strings","title":"7.3 Processando Dados de Sensor com Strings","text":"<pre><code>float temperatura = 23.5;\nfloat umidade = 60.0;\n\nvoid setup() {\n    Serial.begin(9600);\n\n    String dados = \"Temperatura: \" + String(temperatura) + \"\u00b0C, Umidade: \" + String(umidade) + \"%\";\n    Serial.println(dados);\n}\n\nvoid loop() {\n    // N\u00e3o h\u00e1 c\u00f3digo no loop\n}\n</code></pre> <p>Explica\u00e7\u00e3o:</p> <ul> <li>Simula a leitura de dados de sensores.</li> <li>Concatena os valores em uma string formatada.</li> <li>Imprime os dados no Monitor Serial.</li> </ul>"},{"location":"aulas/iot/modulos/modulo6.html#8-exercicios-praticos","title":"8. Exerc\u00edcios Pr\u00e1ticos","text":""},{"location":"aulas/iot/modulos/modulo6.html#exercicio-1-conversor-de-temperatura","title":"Exerc\u00edcio 1: Conversor de Temperatura","text":"<ul> <li> <p>Tarefa: Crie um programa que recebe uma temperatura em Celsius do usu\u00e1rio e converte para Fahrenheit, exibindo o resultado no Monitor Serial.</p> </li> <li> <p>Exemplo de C\u00f3digo:</p> </li> </ul> <pre><code>float celsius = 0.0;\nfloat fahrenheit = 0.0;\n\nvoid setup() {\n    Serial.begin(9600);\n    Serial.println(\"Digite a temperatura em Celsius:\");\n}\n\nvoid loop() {\n    if(Serial.available() &gt; 0) {\n        celsius = Serial.parseFloat();\n        fahrenheit = (celsius * 9.0 / 5.0) + 32.0;\n        Serial.print(celsius);\n        Serial.print(\"\u00b0C \u00e9 igual a \");\n        Serial.print(fahrenheit);\n        Serial.println(\"\u00b0F.\");\n        Serial.println(\"Digite outra temperatura ou reinicie o Arduino para sair.\");\n    }\n}\n</code></pre>"},{"location":"aulas/iot/modulos/modulo6.html#exercicio-2-verificacao-de-palindromo","title":"Exerc\u00edcio 2: Verifica\u00e7\u00e3o de Pal\u00edndromo","text":"<ul> <li> <p>Tarefa: Desenvolva um programa que recebe uma palavra do usu\u00e1rio e verifica se \u00e9 um pal\u00edndromo (mesmo de tr\u00e1s para frente).</p> </li> <li> <p>Exemplo de C\u00f3digo:</p> </li> </ul> <pre><code>String palavra = \"\";\nbool ehPalindromo = true;\n\nbool verificarPalindromo(String str) {\n    int inicio = 0;\n    int fim = str.length() - 1;\n\n    while(inicio &lt; fim) {\n        if(tolower(str[inicio]) != tolower(str[fim])) {\n            return false;\n        }\n        inicio++;\n        fim--;\n    }\n    return true;\n}\n\nvoid setup() {\n    Serial.begin(9600);\n    Serial.println(\"Digite uma palavra para verificar se \u00e9 um pal\u00edndromo:\");\n}\n\nvoid loop() {\n    if(Serial.available() &gt; 0) {\n        palavra = Serial.readString();\n        ehPalindromo = verificarPalindromo(palavra);\n\n        if(ehPalindromo) {\n            Serial.print(palavra);\n            Serial.println(\" \u00e9 um pal\u00edndromo.\");\n        } else {\n            Serial.print(palavra);\n            Serial.println(\" n\u00e3o \u00e9 um pal\u00edndromo.\");\n        }\n\n        Serial.println(\"Digite outra palavra ou reinicie o Arduino para sair.\");\n    }\n}\n</code></pre>"},{"location":"aulas/iot/modulos/modulo6.html#exercicio-3-contador-de-vogais","title":"Exerc\u00edcio 3: Contador de Vogais","text":"<ul> <li> <p>Tarefa: Escreva um programa que recebe uma frase do usu\u00e1rio e conta o n\u00famero de vogais presentes nela.</p> </li> <li> <p>Exemplo de C\u00f3digo:</p> </li> </ul> <pre><code>String frase = \"\";\nint contadorVogais = 0;\n\nint contarVogais(String str) {\n    int count = 0;\n    for(int i = 0; i &lt; str.length(); i++) {\n        char c = tolower(str[i]);\n        if(c == 'a' || c == 'e' || c == 'i' || c == 'o' || c == 'u') {\n            count++;\n        }\n    }\n    return count;\n}\n\nvoid setup() {\n    Serial.begin(9600);\n    Serial.println(\"Digite uma frase para contar as vogais:\");\n}\n\nvoid loop() {\n    if(Serial.available() &gt; 0) {\n        frase = Serial.readString();\n        contadorVogais = contarVogais(frase);\n        Serial.print(\"N\u00famero de vogais: \");\n        Serial.println(contadorVogais);\n        Serial.println(\"Digite outra frase ou reinicie o Arduino para sair.\");\n    }\n}\n</code></pre>"},{"location":"aulas/iot/modulos/modulo6.html#9-conceitos-importantes","title":"9. Conceitos Importantes","text":""},{"location":"aulas/iot/modulos/modulo6.html#91-vetores-vs-arrays","title":"9.1 Vetores vs. Arrays","text":"<p>Em C/C++, os termos \"vetor\" e \"array\" s\u00e3o frequentemente usados de forma intercambi\u00e1vel para se referirem a estruturas de dados que armazenam m\u00faltiplos elementos do mesmo tipo.</p>"},{"location":"aulas/iot/modulos/modulo6.html#92-operacoes-com-strings","title":"9.2 Opera\u00e7\u00f5es com Strings","text":"<ul> <li>Concatena\u00e7\u00e3o:</li> <li> <p>Combine duas ou mais strings em uma \u00fanica string.</p> </li> <li> <p>Compara\u00e7\u00e3o:</p> </li> <li> <p>Verifique se duas strings s\u00e3o iguais ou diferentes.</p> </li> <li> <p>Busca:</p> </li> <li> <p>Encontre a posi\u00e7\u00e3o de uma substring ou caractere dentro de uma string.</p> </li> <li> <p>Substitui\u00e7\u00e3o:</p> </li> <li>Substitua partes de uma string por outras strings.</li> </ul>"},{"location":"aulas/iot/modulos/modulo6.html#93-gerenciamento-de-memoria-com-strings","title":"9.3 Gerenciamento de Mem\u00f3ria com Strings","text":"<ul> <li>Uso de <code>const char*</code>: Para strings que n\u00e3o ser\u00e3o modificadas, use ponteiros para constantes de caracteres.</li> </ul> <pre><code>const char* saudacao = \"Bem-vindo ao Arduino!\";\n</code></pre> <ul> <li>Evitar Repeti\u00e7\u00e3o de Opera\u00e7\u00f5es de Concatena\u00e7\u00e3o: Minimize o uso de opera\u00e7\u00f5es que alteram a string constantemente para reduzir a fragmenta\u00e7\u00e3o de mem\u00f3ria.</li> </ul> <pre><code>char mensagem[50];\nstrcpy(mensagem, \"Este \u00e9 um exemplo seguro.\");\n</code></pre> <ul> <li>Gerenciar o Tamanho dos Arrays: Certifique-se de que os arrays de caracteres s\u00e3o suficientemente grandes para armazenar as strings e o caractere nulo.</li> </ul> <pre><code>char mensagem[50] = \"Este \u00e9 um exemplo seguro.\";\n</code></pre>"},{"location":"aulas/iot/modulos/modulo6.html#94-boas-praticas-com-strings","title":"9.4 Boas Pr\u00e1ticas com Strings","text":"<ul> <li> <p>Evitar Uso Excessivo da Classe <code>String</code>: Em sistemas com mem\u00f3ria limitada, prefira arrays de caracteres para evitar fragmenta\u00e7\u00e3o.</p> </li> <li> <p>Sempre Verificar o Tamanho dos Arrays: Evite overflow garantindo que os arrays s\u00e3o grandes o suficiente para armazenar as strings e o caractere nulo.</p> </li> </ul> <pre><code>char mensagem[50];\nstrcpy(mensagem, \"Este \u00e9 um exemplo seguro.\");\n</code></pre> <ul> <li>Usar Fun\u00e7\u00f5es de Manipula\u00e7\u00e3o de Strings com Cuidado: Certifique-se de que as fun\u00e7\u00f5es utilizadas n\u00e3o ultrapassem os limites dos arrays.</li> </ul>"},{"location":"aulas/iot/modulos/modulo7.html","title":"M\u00f3dulo 7: Ponteiros e Refer\u00eancias","text":"<p>Bem-vindo ao M\u00f3dulo 7 do curso \"Programa\u00e7\u00e3o em Arduino: Conceitos Fundamentais sem Hardware\". Neste m\u00f3dulo, voc\u00ea ir\u00e1 explorar o uso de ponteiros e refer\u00eancias na linguagem de programa\u00e7\u00e3o Arduino (C/C++). Ponteiros s\u00e3o ferramentas poderosas que permitem o acesso direto \u00e0 mem\u00f3ria e a manipula\u00e7\u00e3o eficiente de dados, enquanto refer\u00eancias oferecem uma maneira segura e conveniente de acessar vari\u00e1veis.</p>"},{"location":"aulas/iot/modulos/modulo7.html#objetivos-do-modulo","title":"Objetivos do M\u00f3dulo","text":"<ul> <li>Compreender o conceito de ponteiros e refer\u00eancias e sua import\u00e2ncia na programa\u00e7\u00e3o.</li> <li>Aprender a declarar, inicializar e utilizar ponteiros.</li> <li>Entender a aritm\u00e9tica de ponteiros e como navegar por arrays utilizando ponteiros.</li> <li>Trabalhar com refer\u00eancias e diferenciar entre ponteiros e refer\u00eancias.</li> <li>Utilizar ponteiros em fun\u00e7\u00f5es para manipula\u00e7\u00e3o eficiente de dados.</li> <li>Implementar aloca\u00e7\u00e3o din\u00e2mica de mem\u00f3ria com ponteiros.</li> <li>Resolver exerc\u00edcios pr\u00e1ticos para consolidar o conhecimento sobre ponteiros e refer\u00eancias.</li> </ul>"},{"location":"aulas/iot/modulos/modulo7.html#1-introducao-a-ponteiros-e-referencias","title":"1. Introdu\u00e7\u00e3o a Ponteiros e Refer\u00eancias","text":""},{"location":"aulas/iot/modulos/modulo7.html#11-o-que-sao-ponteiros","title":"1.1 O que s\u00e3o Ponteiros?","text":"<p>Um ponteiro \u00e9 uma vari\u00e1vel que armazena o endere\u00e7o de mem\u00f3ria de outra vari\u00e1vel. Eles s\u00e3o fundamentais para a manipula\u00e7\u00e3o eficiente de dados, permitindo o acesso direto e a modifica\u00e7\u00e3o de vari\u00e1veis em diferentes partes do programa.</p>"},{"location":"aulas/iot/modulos/modulo7.html#12-o-que-sao-referencias","title":"1.2 O que s\u00e3o Refer\u00eancias?","text":"<p>Uma refer\u00eancia \u00e9 um alias para outra vari\u00e1vel. Diferentemente dos ponteiros, refer\u00eancias n\u00e3o podem ser alteradas para apontar para diferentes vari\u00e1veis ap\u00f3s sua inicializa\u00e7\u00e3o e n\u00e3o envolvem opera\u00e7\u00f5es de aritm\u00e9tica de ponteiros.</p>"},{"location":"aulas/iot/modulos/modulo7.html#13-diferencas-entre-ponteiros-e-referencias","title":"1.3 Diferen\u00e7as entre Ponteiros e Refer\u00eancias","text":"<ul> <li>Ponteiros:</li> <li>Podem ser reatribu\u00eddos para apontar para diferentes vari\u00e1veis.</li> <li>Suportam aritm\u00e9tica de ponteiros.</li> <li> <p>Podem ter um valor nulo (<code>NULL</code>).</p> </li> <li> <p>Refer\u00eancias:</p> </li> <li>Devem ser inicializadas no momento da declara\u00e7\u00e3o.</li> <li>N\u00e3o suportam aritm\u00e9tica de ponteiros.</li> <li>N\u00e3o podem ser nulas.</li> </ul>"},{"location":"aulas/iot/modulos/modulo7.html#2-trabalhando-com-ponteiros","title":"2. Trabalhando com Ponteiros","text":""},{"location":"aulas/iot/modulos/modulo7.html#21-declaracao-e-inicializacao-de-ponteiros","title":"2.1 Declara\u00e7\u00e3o e Inicializa\u00e7\u00e3o de Ponteiros","text":"<p>Sintaxe:</p> <pre><code>tipo *nome_ponteiro;\n</code></pre> <p>Exemplo:</p> <pre><code>int *ptr;\nint valor = 10;\nptr = &amp;valor; // ptr aponta para o endere\u00e7o de mem\u00f3ria de 'valor'\n</code></pre>"},{"location":"aulas/iot/modulos/modulo7.html#22-acessando-o-valor-apontado-por-um-ponteiro","title":"2.2 Acessando o Valor Apontado por um Ponteiro","text":"<p>Operador de Desreferencia\u00e7\u00e3o (<code>*</code>):</p> <pre><code>int numero = 20;\nint *ponteiro = &amp;numero;\nSerial.println(*ponteiro); // Imprime 20\n</code></pre> <p>Explica\u00e7\u00e3o:</p> <ul> <li><code>*ponteiro</code> acessa o valor armazenado no endere\u00e7o de mem\u00f3ria para o qual <code>ponteiro</code> aponta.</li> </ul>"},{"location":"aulas/iot/modulos/modulo7.html#23-aritmetica-de-ponteiros","title":"2.3 Aritm\u00e9tica de Ponteiros","text":"<p>Ponteiros podem ser incrementados ou decrementados para navegar por arrays ou estruturas de dados.</p> <p>Exemplo:</p> <pre><code>int arr[3] = {10, 20, 30};\nint *ptr = arr; // Aponta para arr[0]\n\nSerial.println(*ptr); // Imprime 10\nptr++; // Agora aponta para arr[1]\nSerial.println(*ptr); // Imprime 20\nptr++; // Agora aponta para arr[2]\nSerial.println(*ptr); // Imprime 30\n</code></pre> <p>Explica\u00e7\u00e3o:</p> <ul> <li>Incrementar um ponteiro (<code>ptr++</code>) faz com que ele aponte para o pr\u00f3ximo elemento do array.</li> </ul>"},{"location":"aulas/iot/modulos/modulo7.html#24-ponteiros-para-tipos-de-dados-diferentes","title":"2.4 Ponteiros para Tipos de Dados Diferentes","text":"<p>Ponteiros podem apontar para qualquer tipo de dado, incluindo estruturas e outras fun\u00e7\u00f5es.</p> <p>Exemplo com Struct:</p> <pre><code>struct Sensor {\n    int id;\n    float valor;\n};\n\nSensor sensor1 = {1, 23.5};\nSensor *ptrSensor = &amp;sensor1;\n\nSerial.println(ptrSensor-&gt;id);    // Imprime 1\nSerial.println(ptrSensor-&gt;valor); // Imprime 23.5\n</code></pre> <p>Explica\u00e7\u00e3o:</p> <ul> <li>Utiliza-se o operador <code>-&gt;</code> para acessar membros de uma estrutura atrav\u00e9s de um ponteiro.</li> </ul>"},{"location":"aulas/iot/modulos/modulo7.html#3-trabalhando-com-referencias","title":"3. Trabalhando com Refer\u00eancias","text":""},{"location":"aulas/iot/modulos/modulo7.html#31-declaracao-e-inicializacao-de-referencias","title":"3.1 Declara\u00e7\u00e3o e Inicializa\u00e7\u00e3o de Refer\u00eancias","text":"<p>Sintaxe:</p> <pre><code>tipo &amp;nome_referencia = variavel;\n</code></pre> <p>Exemplo:</p> <pre><code>int numero = 50;\nint &amp;ref = numero; // 'ref' \u00e9 uma refer\u00eancia para 'numero'\n\nSerial.println(ref); // Imprime 50\nref = 100;\nSerial.println(numero); // Imprime 100\n</code></pre> <p>Explica\u00e7\u00e3o:</p> <ul> <li>Alterar <code>ref</code> tamb\u00e9m altera <code>numero</code>, j\u00e1 que <code>ref</code> \u00e9 apenas um alias para <code>numero</code>.</li> </ul>"},{"location":"aulas/iot/modulos/modulo7.html#32-passando-referencias-para-funcoes","title":"3.2 Passando Refer\u00eancias para Fun\u00e7\u00f5es","text":"<p>Passar vari\u00e1veis por refer\u00eancia permite que a fun\u00e7\u00e3o modifique o valor original da vari\u00e1vel.</p> <p>Exemplo:</p> <pre><code>void incrementar(int &amp;n) {\n    n += 1;\n}\n\nvoid setup() {\n    Serial.begin(9600);\n    int valor = 5;\n    Serial.println(valor); // Imprime 5\n    incrementar(valor);\n    Serial.println(valor); // Imprime 6\n}\n\nvoid loop() {\n    // N\u00e3o h\u00e1 c\u00f3digo no loop\n}\n</code></pre> <p>Explica\u00e7\u00e3o:</p> <ul> <li>A fun\u00e7\u00e3o <code>incrementar</code> recebe <code>n</code> por refer\u00eancia, permitindo modificar o valor original de <code>valor</code>.</li> </ul>"},{"location":"aulas/iot/modulos/modulo7.html#4-ponteiros-em-funcoes","title":"4. Ponteiros em Fun\u00e7\u00f5es","text":""},{"location":"aulas/iot/modulos/modulo7.html#41-passando-ponteiros-para-funcoes","title":"4.1 Passando Ponteiros para Fun\u00e7\u00f5es","text":"<p>Ponteiros podem ser passados para fun\u00e7\u00f5es para permitir a manipula\u00e7\u00e3o direta das vari\u00e1veis originais.</p> <p>Exemplo:</p> <pre><code>void trocar(int *a, int *b) {\n    int temp = *a;\n    *a = *b;\n    *b = temp;\n}\n\nvoid setup() {\n    Serial.begin(9600);\n    int x = 10;\n    int y = 20;\n    Serial.print(\"Antes: x = \");\n    Serial.print(x);\n    Serial.print(\", y = \");\n    Serial.println(y);\n\n    trocar(&amp;x, &amp;y);\n\n    Serial.print(\"Depois: x = \");\n    Serial.print(x);\n    Serial.print(\", y = \");\n    Serial.println(y);\n}\n\nvoid loop() {\n    // N\u00e3o h\u00e1 c\u00f3digo no loop\n}\n</code></pre> <p>Explica\u00e7\u00e3o:</p> <ul> <li>A fun\u00e7\u00e3o <code>trocar</code> utiliza ponteiros para trocar os valores de <code>x</code> e <code>y</code>.</li> </ul>"},{"location":"aulas/iot/modulos/modulo7.html#42-retornando-ponteiros-de-funcoes","title":"4.2 Retornando Ponteiros de Fun\u00e7\u00f5es","text":"<p>Fun\u00e7\u00f5es podem retornar ponteiros para permitir o acesso a vari\u00e1veis alocadas dinamicamente ou outras estruturas de dados.</p> <p>Exemplo:</p> <pre><code>int* criarArray(int tamanho) {\n    int *arr = new int[tamanho];\n    for(int i = 0; i &lt; tamanho; i++) {\n        arr[i] = i * 2;\n    }\n    return arr;\n}\n\nvoid setup() {\n    Serial.begin(9600);\n    int *meuArray = criarArray(5);\n    for(int i = 0; i &lt; 5; i++) {\n        Serial.println(meuArray[i]);\n    }\n    delete[] meuArray; // Libera a mem\u00f3ria alocada\n}\n\nvoid loop() {\n    // N\u00e3o h\u00e1 c\u00f3digo no loop\n}\n</code></pre> <p>Explica\u00e7\u00e3o:</p> <ul> <li>A fun\u00e7\u00e3o <code>criarArray</code> aloca dinamicamente um array e retorna o ponteiro para ele.</li> <li>\u00c9 importante liberar a mem\u00f3ria alocada com <code>delete[]</code> para evitar vazamentos de mem\u00f3ria.</li> </ul>"},{"location":"aulas/iot/modulos/modulo7.html#5-alocacao-dinamica-de-memoria","title":"5. Aloca\u00e7\u00e3o Din\u00e2mica de Mem\u00f3ria","text":""},{"location":"aulas/iot/modulos/modulo7.html#51-usando-new-e-delete","title":"5.1 Usando <code>new</code> e <code>delete</code>","text":"<p>Ponteiros permitem a aloca\u00e7\u00e3o din\u00e2mica de mem\u00f3ria, onde o tamanho da mem\u00f3ria necess\u00e1ria n\u00e3o \u00e9 conhecido em tempo de compila\u00e7\u00e3o.</p> <p>Exemplo:</p> <pre><code>int *alocarInteiro() {\n    int *ptr = new int;\n    *ptr = 100;\n    return ptr;\n}\n\nvoid setup() {\n    Serial.begin(9600);\n    int *meuInt = alocarInteiro();\n    Serial.println(*meuInt); // Imprime 100\n    delete meuInt; // Libera a mem\u00f3ria alocada\n}\n\nvoid loop() {\n    // N\u00e3o h\u00e1 c\u00f3digo no loop\n}\n</code></pre> <p>Explica\u00e7\u00e3o:</p> <ul> <li>A fun\u00e7\u00e3o <code>alocarInteiro</code> aloca mem\u00f3ria para um inteiro, atribui o valor 100 e retorna o ponteiro.</li> <li>A mem\u00f3ria \u00e9 liberada com <code>delete</code> ap\u00f3s o uso.</li> </ul>"},{"location":"aulas/iot/modulos/modulo7.html#52-alocacao-de-arrays-dinamicos","title":"5.2 Aloca\u00e7\u00e3o de Arrays Din\u00e2micos","text":"<pre><code>int* alocarArray(int tamanho) {\n    int *arr = new int[tamanho];\n    for(int i = 0; i &lt; tamanho; i++) {\n        arr[i] = i + 1;\n    }\n    return arr;\n}\n\nvoid setup() {\n    Serial.begin(9600);\n    int *meuArray = alocarArray(5);\n    for(int i = 0; i &lt; 5; i++) {\n        Serial.println(meuArray[i]);\n    }\n    delete[] meuArray; // Libera a mem\u00f3ria alocada\n}\n\nvoid loop() {\n    // N\u00e3o h\u00e1 c\u00f3digo no loop\n}\n</code></pre> <p>Explica\u00e7\u00e3o:</p> <ul> <li>A fun\u00e7\u00e3o <code>alocarArray</code> aloca dinamicamente um array de inteiros e inicializa os valores.</li> <li>A mem\u00f3ria \u00e9 liberada com <code>delete[]</code> ap\u00f3s o uso.</li> </ul>"},{"location":"aulas/iot/modulos/modulo7.html#6-ponteiros-para-ponteiros","title":"6. Ponteiros para Ponteiros","text":""},{"location":"aulas/iot/modulos/modulo7.html#61-declaracao-e-uso","title":"6.1 Declara\u00e7\u00e3o e Uso","text":"<p>Ponteiros para ponteiros s\u00e3o usados para manipular ponteiros de forma indireta, permitindo m\u00faltiplos n\u00edveis de indire\u00e7\u00e3o.</p> <p>Exemplo:</p> <pre><code>int valor = 50;\nint *ptr = &amp;valor;\nint **ptrPtr = &amp;ptr;\n\nSerial.println(*ptr);    // Imprime 50\nSerial.println(**ptrPtr); // Imprime 50\n</code></pre> <p>Explica\u00e7\u00e3o:</p> <ul> <li><code>ptr</code> \u00e9 um ponteiro para <code>valor</code>.</li> <li><code>ptrPtr</code> \u00e9 um ponteiro para <code>ptr</code>, permitindo acesso indireto ao valor original.</li> </ul>"},{"location":"aulas/iot/modulos/modulo7.html#62-aplicacoes-praticas","title":"6.2 Aplica\u00e7\u00f5es Pr\u00e1ticas","text":"<p>Ponteiros para ponteiros s\u00e3o \u00fateis em situa\u00e7\u00f5es como:</p> <ul> <li>Manipula\u00e7\u00e3o de arrays de ponteiros.</li> <li>Passagem de ponteiros para fun\u00e7\u00f5es que precisam modificar o ponteiro original.</li> <li>Implementa\u00e7\u00e3o de estruturas de dados complexas como listas ligadas.</li> </ul> <p>Exemplo:</p> <pre><code>void modificarPonteiro(int **pptr) {\n    static int novoValor = 200;\n    *pptr = &amp;novoValor;\n}\n\nvoid setup() {\n    Serial.begin(9600);\n    int valor = 100;\n    int *ptr = &amp;valor;\n\n    Serial.println(*ptr); // Imprime 100\n\n    modificarPonteiro(&amp;ptr);\n\n    Serial.println(*ptr); // Imprime 200\n}\n\nvoid loop() {\n    // N\u00e3o h\u00e1 c\u00f3digo no loop\n}\n</code></pre> <p>Explica\u00e7\u00e3o:</p> <ul> <li>A fun\u00e7\u00e3o <code>modificarPonteiro</code> altera o ponteiro original para apontar para <code>novoValor</code>.</li> </ul>"},{"location":"aulas/iot/modulos/modulo7.html#7-exemplos-praticos","title":"7. Exemplos Pr\u00e1ticos","text":""},{"location":"aulas/iot/modulos/modulo7.html#71-manipulando-arrays-com-ponteiros","title":"7.1 Manipulando Arrays com Ponteiros","text":"<pre><code>void imprimirArray(int *arr, int tamanho) {\n    for(int i = 0; i &lt; tamanho; i++) {\n        Serial.println(*(arr + i));\n    }\n}\n\nvoid setup() {\n    Serial.begin(9600);\n    int arr[5] = {10, 20, 30, 40, 50};\n    imprimirArray(arr, 5);\n}\n\nvoid loop() {\n    // N\u00e3o h\u00e1 c\u00f3digo no loop\n}\n</code></pre> <p>Explica\u00e7\u00e3o:</p> <ul> <li>A fun\u00e7\u00e3o <code>imprimirArray</code> usa aritm\u00e9tica de ponteiros para acessar e imprimir os elementos do array.</li> </ul>"},{"location":"aulas/iot/modulos/modulo7.html#72-troca-de-valores-usando-ponteiros","title":"7.2 Troca de Valores Usando Ponteiros","text":"<pre><code>void trocarValores(int *a, int *b) {\n    int temp = *a;\n    *a = *b;\n    *b = temp;\n}\n\nvoid setup() {\n    Serial.begin(9600);\n    int x = 15;\n    int y = 25;\n\n    Serial.print(\"Antes da troca: x = \");\n    Serial.print(x);\n    Serial.print(\", y = \");\n    Serial.println(y);\n\n    trocarValores(&amp;x, &amp;y);\n\n    Serial.print(\"Depois da troca: x = \");\n    Serial.print(x);\n    Serial.print(\", y = \");\n    Serial.println(y);\n}\n\nvoid loop() {\n    // N\u00e3o h\u00e1 c\u00f3digo no loop\n}\n</code></pre> <p>Explica\u00e7\u00e3o:</p> <ul> <li>A fun\u00e7\u00e3o <code>trocarValores</code> troca os valores de <code>x</code> e <code>y</code> usando ponteiros.</li> </ul>"},{"location":"aulas/iot/modulos/modulo7.html#73-alocacao-dinamica-e-liberacao-de-memoria","title":"7.3 Aloca\u00e7\u00e3o Din\u00e2mica e Libera\u00e7\u00e3o de Mem\u00f3ria","text":"<pre><code>int* criarArrayDinamico(int tamanho) {\n    int *arr = new int[tamanho];\n    for(int i = 0; i &lt; tamanho; i++) {\n        arr[i] = i * 10;\n    }\n    return arr;\n}\n\nvoid setup() {\n    Serial.begin(9600);\n    int *meuArray = criarArrayDinamico(4);\n\n    for(int i = 0; i &lt; 4; i++) {\n        Serial.println(meuArray[i]);\n    }\n\n    delete[] meuArray; // Libera a mem\u00f3ria alocada\n}\n\nvoid loop() {\n    // N\u00e3o h\u00e1 c\u00f3digo no loop\n}\n</code></pre> <p>Explica\u00e7\u00e3o:</p> <ul> <li>A fun\u00e7\u00e3o <code>criarArrayDinamico</code> aloca dinamicamente um array e inicializa seus valores.</li> <li>A mem\u00f3ria \u00e9 liberada ap\u00f3s o uso para evitar vazamentos.</li> </ul>"},{"location":"aulas/iot/modulos/modulo7.html#8-exercicios-praticos","title":"8. Exerc\u00edcios Pr\u00e1ticos","text":""},{"location":"aulas/iot/modulos/modulo7.html#exercicio-1-funcao-para-somar-elementos-de-um-array-usando-ponteiros","title":"Exerc\u00edcio 1: Fun\u00e7\u00e3o para Somar Elementos de um Array Usando Ponteiros","text":"<ul> <li> <p>Tarefa: Crie uma fun\u00e7\u00e3o que recebe um array de inteiros e seu tamanho usando ponteiros, e retorna a soma de todos os elementos.</p> </li> <li> <p>Exemplo de C\u00f3digo:</p> </li> </ul> <pre><code>int somarArray(int *arr, int tamanho) {\n    int soma = 0;\n    for(int i = 0; i &lt; tamanho; i++) {\n        soma += *(arr + i);\n    }\n    return soma;\n}\n\nvoid setup() {\n    Serial.begin(9600);\n    int arr[5] = {5, 10, 15, 20, 25};\n    int resultado = somarArray(arr, 5);\n    Serial.print(\"Soma dos elementos: \");\n    Serial.println(resultado); // Imprime 75\n}\n\nvoid loop() {\n    // N\u00e3o h\u00e1 c\u00f3digo no loop\n}\n</code></pre>"},{"location":"aulas/iot/modulos/modulo7.html#exercicio-2-implementar-uma-funcao-que-troca-dois-valores-usando-referencias","title":"Exerc\u00edcio 2: Implementar uma Fun\u00e7\u00e3o que Troca Dois Valores Usando Refer\u00eancias","text":"<ul> <li> <p>Tarefa: Escreva uma fun\u00e7\u00e3o que recebe duas vari\u00e1veis inteiras por refer\u00eancia e troca seus valores.</p> </li> <li> <p>Exemplo de C\u00f3digo:</p> </li> </ul> <pre><code>void trocar(int &amp;a, int &amp;b) {\n    int temp = a;\n    a = b;\n    b = temp;\n}\n\nvoid setup() {\n    Serial.begin(9600);\n    int x = 50;\n    int y = 100;\n\n    Serial.print(\"Antes da troca: x = \");\n    Serial.print(x);\n    Serial.print(\", y = \");\n    Serial.println(y);\n\n    trocar(x, y);\n\n    Serial.print(\"Depois da troca: x = \");\n    Serial.print(x);\n    Serial.print(\", y = \");\n    Serial.println(y);\n}\n\nvoid loop() {\n    // N\u00e3o h\u00e1 c\u00f3digo no loop\n}\n</code></pre>"},{"location":"aulas/iot/modulos/modulo7.html#exercicio-3-criar-uma-funcao-recursiva-para-calcular-o-n-esimo-numero-da-sequencia-de-fibonacci","title":"Exerc\u00edcio 3: Criar uma Fun\u00e7\u00e3o Recursiva para Calcular o N-\u00e9simo N\u00famero da Sequ\u00eancia de Fibonacci","text":"<ul> <li> <p>Tarefa: Desenvolva uma fun\u00e7\u00e3o recursiva que calcula e retorna o N-\u00e9simo n\u00famero da sequ\u00eancia de Fibonacci.</p> </li> <li> <p>Exemplo de C\u00f3digo:</p> </li> </ul> <pre><code>long fibonacci(int n) {\n    if(n &lt;= 1)\n        return n;\n    else\n        return fibonacci(n - 1) + fibonacci(n - 2);\n}\n\nvoid setup() {\n    Serial.begin(9600);\n    int termo = 10;\n    long resultado = fibonacci(termo);\n    Serial.print(\"O \");\n    Serial.print(termo);\n    Serial.print(\"\u00ba termo da sequ\u00eancia de Fibonacci \u00e9: \");\n    Serial.println(resultado); // Imprime 55\n}\n\nvoid loop() {\n    // N\u00e3o h\u00e1 c\u00f3digo no loop\n}\n</code></pre>"},{"location":"aulas/iot/modulos/modulo7.html#9-conceitos-importantes","title":"9. Conceitos Importantes","text":""},{"location":"aulas/iot/modulos/modulo7.html#91-seguranca-com-ponteiros","title":"9.1 Seguran\u00e7a com Ponteiros","text":"<ul> <li>Inicializa\u00e7\u00e3o: Sempre inicialize ponteiros. Ponteiros n\u00e3o inicializados podem levar a comportamentos indefinidos.</li> </ul> <pre><code>int *ptr = nullptr; // Inicializado como nulo\n</code></pre> <ul> <li>Verifica\u00e7\u00e3o de Nulos: Antes de desreferenciar um ponteiro, verifique se ele n\u00e3o \u00e9 nulo.</li> </ul> <pre><code>if(ptr != nullptr) {\n    Serial.println(*ptr);\n}\n</code></pre>"},{"location":"aulas/iot/modulos/modulo7.html#92-gerenciamento-de-memoria","title":"9.2 Gerenciamento de Mem\u00f3ria","text":"<ul> <li>Aloca\u00e7\u00e3o Din\u00e2mica: Sempre libere a mem\u00f3ria alocada dinamicamente usando <code>delete</code> ou <code>delete[]</code> para evitar vazamentos de mem\u00f3ria.</li> </ul> <pre><code>int *arr = new int[10];\n// Uso do array\ndelete[] arr; // Libera a mem\u00f3ria\n</code></pre> <ul> <li>Evitar Ponteiros Vazios: Evite ponteiros que apontam para endere\u00e7os inv\u00e1lidos ou que foram liberados.</li> </ul>"},{"location":"aulas/iot/modulos/modulo7.html#93-ponteiros-constantes","title":"9.3 Ponteiros Constantes","text":"<ul> <li>Ponteiro para Constante: O valor apontado n\u00e3o pode ser alterado atrav\u00e9s do ponteiro.</li> </ul> <pre><code>const int *ptr = &amp;valor;\n</code></pre> <ul> <li>Ponteiro Constante: O pr\u00f3prio ponteiro n\u00e3o pode apontar para outro endere\u00e7o.</li> </ul> <pre><code>int * const ptr = &amp;valor;\n</code></pre> <ul> <li>Ponteiro para Constante Constante: Nem o valor apontado nem o ponteiro podem ser alterados.</li> </ul> <pre><code>const int * const ptr = &amp;valor;\n</code></pre>"},{"location":"aulas/iot/modulos/modulo7.html#94-boas-praticas-com-ponteiros-e-referencias","title":"9.4 Boas Pr\u00e1ticas com Ponteiros e Refer\u00eancias","text":"<ul> <li> <p>Evitar Uso Excessivo de Ponteiros: Use refer\u00eancias quando poss\u00edvel para evitar complexidade desnecess\u00e1ria.</p> </li> <li> <p>Documenta\u00e7\u00e3o: Comente o uso de ponteiros para facilitar a compreens\u00e3o do c\u00f3digo.</p> </li> <li> <p>Valida\u00e7\u00e3o: Sempre valide ponteiros antes de us\u00e1-los para evitar erros de execu\u00e7\u00e3o.</p> </li> </ul>"},{"location":"aulas/iot/modulos/modulo8.html","title":"M\u00f3dulo 8: Estruturas (Structs) e Classes","text":"<p>Bem-vindo ao M\u00f3dulo 8 do curso \"Programa\u00e7\u00e3o em Arduino: Conceitos Fundamentais sem Hardware\". Neste m\u00f3dulo, voc\u00ea ir\u00e1 aprofundar seu conhecimento sobre estruturas (<code>structs</code>) e classes na linguagem de programa\u00e7\u00e3o Arduino (C/C++). Estruturas e classes s\u00e3o fundamentais para a programa\u00e7\u00e3o orientada a objetos, permitindo a cria\u00e7\u00e3o de tipos de dados personalizados e a organiza\u00e7\u00e3o eficiente do c\u00f3digo.</p>"},{"location":"aulas/iot/modulos/modulo8.html#objetivos-do-modulo","title":"Objetivos do M\u00f3dulo","text":"<ul> <li>Compreender o conceito de estruturas (<code>structs</code>) e classes na programa\u00e7\u00e3o.</li> <li>Aprender a declarar e utilizar estruturas em Arduino.</li> <li>Introduzir conceitos b\u00e1sicos de programa\u00e7\u00e3o orientada a objetos (POO) com classes.</li> <li>Trabalhar com atributos e m\u00e9todos dentro de classes.</li> <li>Entender o conceito de encapsulamento, heran\u00e7a e polimorfismo.</li> <li>Implementar construtores e destrutores em classes.</li> <li>Resolver exerc\u00edcios pr\u00e1ticos para consolidar o conhecimento sobre estruturas e classes.</li> </ul>"},{"location":"aulas/iot/modulos/modulo8.html#1-introducao-as-estruturas-structs-e-classes","title":"1. Introdu\u00e7\u00e3o \u00e0s Estruturas (<code>Structs</code>) e Classes","text":""},{"location":"aulas/iot/modulos/modulo8.html#11-o-que-sao-estruturas-structs","title":"1.1 O que s\u00e3o Estruturas (<code>Structs</code>)?","text":"<p>Uma estrutura (<code>struct</code>) \u00e9 uma cole\u00e7\u00e3o de vari\u00e1veis agrupadas sob um \u00fanico nome para representar uma entidade mais complexa. Cada vari\u00e1vel dentro de uma estrutura \u00e9 chamada de membro ou campo da estrutura.</p>"},{"location":"aulas/iot/modulos/modulo8.html#12-o-que-sao-classes","title":"1.2 O que s\u00e3o Classes?","text":"<p>Uma classe \u00e9 uma extens\u00e3o das estruturas, incorporando n\u00e3o apenas dados (atributos) mas tamb\u00e9m fun\u00e7\u00f5es (m\u00e9todos) que operam sobre esses dados. Classes s\u00e3o a base da programa\u00e7\u00e3o orientada a objetos (POO), permitindo a cria\u00e7\u00e3o de objetos que possuem propriedades e comportamentos.</p>"},{"location":"aulas/iot/modulos/modulo8.html#13-diferencas-entre-struct-e-class","title":"1.3 Diferen\u00e7as entre <code>struct</code> e <code>class</code>","text":"<ul> <li>Acesso Padr\u00e3o:</li> <li>Em <code>structs</code>, os membros s\u00e3o p\u00fablicos por padr\u00e3o.</li> <li> <p>Em <code>classes</code>, os membros s\u00e3o privados por padr\u00e3o.</p> </li> <li> <p>Funcionalidades:</p> </li> <li><code>Structs</code> s\u00e3o adequadas para agrupamentos simples de dados.</li> <li><code>Classes</code> suportam POO completa, incluindo encapsulamento, heran\u00e7a e polimorfismo.</li> </ul>"},{"location":"aulas/iot/modulos/modulo8.html#2-trabalhando-com-estruturas-structs","title":"2. Trabalhando com Estruturas (<code>Structs</code>)","text":""},{"location":"aulas/iot/modulos/modulo8.html#21-declaracao-e-inicializacao-de-structs","title":"2.1 Declara\u00e7\u00e3o e Inicializa\u00e7\u00e3o de <code>Structs</code>","text":"<p>Sintaxe:</p> <pre><code>struct NomeEstrutura {\n    tipo membro1;\n    tipo membro2;\n    // ...\n};\n</code></pre> <p>Exemplo:</p> <pre><code>struct Sensor {\n    int id;\n    float valor;\n};\n</code></pre>"},{"location":"aulas/iot/modulos/modulo8.html#22-utilizando-structs-no-arduino","title":"2.2 Utilizando <code>Structs</code> no Arduino","text":"<p>Exemplo Pr\u00e1tico:</p> <pre><code>struct Sensor {\n    int id;\n    float valor;\n};\n\nSensor sensor1;\nSensor sensor2;\n\nvoid setup() {\n    Serial.begin(9600);\n\n    sensor1.id = 1;\n    sensor1.valor = 23.5;\n\n    sensor2.id = 2;\n    sensor2.valor = 47.8;\n\n    Serial.print(\"Sensor \");\n    Serial.print(sensor1.id);\n    Serial.print(\": \");\n    Serial.println(sensor1.valor);\n\n    Serial.print(\"Sensor \");\n    Serial.print(sensor2.id);\n    Serial.print(\": \");\n    Serial.println(sensor2.valor);\n}\n\nvoid loop() {\n    // N\u00e3o h\u00e1 c\u00f3digo no loop\n}\n</code></pre> <p>Explica\u00e7\u00e3o:</p> <ul> <li>Define uma estrutura <code>Sensor</code> com membros <code>id</code> e <code>valor</code>.</li> <li>Declara duas vari\u00e1veis <code>sensor1</code> e <code>sensor2</code> do tipo <code>Sensor</code>.</li> <li>Inicializa os membros e imprime os valores no Monitor Serial.</li> </ul>"},{"location":"aulas/iot/modulos/modulo8.html#3-introducao-a-programacao-orientada-a-objetos-poo-com-classes","title":"3. Introdu\u00e7\u00e3o \u00e0 Programa\u00e7\u00e3o Orientada a Objetos (POO) com Classes","text":""},{"location":"aulas/iot/modulos/modulo8.html#31-conceitos-basicos-de-poo","title":"3.1 Conceitos B\u00e1sicos de POO","text":"<ul> <li>Objeto: Uma inst\u00e2ncia de uma classe que possui estado e comportamento.</li> <li>Classe: Um molde para criar objetos, definindo atributos e m\u00e9todos.</li> <li>Encapsulamento: O ato de esconder os detalhes internos de uma classe e expor apenas o necess\u00e1rio.</li> <li>Heran\u00e7a: Permite que uma classe herde atributos e m\u00e9todos de outra.</li> <li>Polimorfismo: Permite que objetos de diferentes classes sejam tratados de forma uniforme.</li> </ul>"},{"location":"aulas/iot/modulos/modulo8.html#32-beneficios-da-poo","title":"3.2 Benef\u00edcios da POO","text":"<ul> <li>Reutiliza\u00e7\u00e3o de C\u00f3digo: Cria\u00e7\u00e3o de classes reutiliz\u00e1veis.</li> <li>Organiza\u00e7\u00e3o: Estrutura\u00e7\u00e3o l\u00f3gica do c\u00f3digo.</li> <li>Manuten\u00e7\u00e3o: Facilita a atualiza\u00e7\u00e3o e corre\u00e7\u00e3o de c\u00f3digo.</li> <li>Escalabilidade: Permite o crescimento do projeto de forma ordenada.</li> </ul>"},{"location":"aulas/iot/modulos/modulo8.html#4-declaracao-e-uso-de-classes","title":"4. Declara\u00e7\u00e3o e Uso de Classes","text":""},{"location":"aulas/iot/modulos/modulo8.html#41-declaracao-de-uma-classe","title":"4.1 Declara\u00e7\u00e3o de uma Classe","text":"<p>Sintaxe:</p> <pre><code>class NomeClasse {\npublic:\n    // Atributos\n    tipo atributo1;\n    tipo atributo2;\n\n    // M\u00e9todos\n    void metodo1();\n    tipo metodo2();\n};\n</code></pre> <p>Exemplo:</p> <pre><code>class Motor {\npublic:\n    int rpm;\n    float temperatura;\n\n    void ligar() {\n        Serial.println(\"Motor ligado.\");\n    }\n\n    void desligar() {\n        Serial.println(\"Motor desligado.\");\n    }\n\n    float lerTemperatura() {\n        return temperatura;\n    }\n};\n</code></pre>"},{"location":"aulas/iot/modulos/modulo8.html#42-utilizando-classes-no-arduino","title":"4.2 Utilizando Classes no Arduino","text":"<p>Exemplo Pr\u00e1tico:</p> <pre><code>class Motor {\npublic:\n    int rpm;\n    float temperatura;\n\n    void ligar() {\n        Serial.println(\"Motor ligado.\");\n    }\n\n    void desligar() {\n        Serial.println(\"Motor desligado.\");\n    }\n\n    float lerTemperatura() {\n        return temperatura;\n    }\n};\n\nMotor motor1;\n\nvoid setup() {\n    Serial.begin(9600);\n\n    motor1.rpm = 1500;\n    motor1.temperatura = 75.0;\n\n    motor1.ligar();\n    Serial.print(\"RPM: \");\n    Serial.println(motor1.rpm);\n    Serial.print(\"Temperatura: \");\n    Serial.println(motor1.lerTemperatura());\n}\n\nvoid loop() {\n    // N\u00e3o h\u00e1 c\u00f3digo no loop\n}\n</code></pre> <p>Explica\u00e7\u00e3o:</p> <ul> <li>Define uma classe <code>Motor</code> com atributos <code>rpm</code> e <code>temperatura</code> e m\u00e9todos <code>ligar</code>, <code>desligar</code> e <code>lerTemperatura</code>.</li> <li>Cria um objeto <code>motor1</code> da classe <code>Motor</code>.</li> <li>Inicializa os atributos e chama os m\u00e9todos para ligar o motor e imprimir os valores no Monitor Serial.</li> </ul>"},{"location":"aulas/iot/modulos/modulo8.html#5-construtores-e-destrutores","title":"5. Construtores e Destrutores","text":""},{"location":"aulas/iot/modulos/modulo8.html#51-construtores","title":"5.1 Construtores","text":"<p>Um construtor \u00e9 um m\u00e9todo especial que \u00e9 chamado automaticamente quando um objeto \u00e9 criado. Ele \u00e9 usado para inicializar os atributos do objeto.</p> <p>Sintaxe:</p> <pre><code>class NomeClasse {\npublic:\n    NomeClasse() {\n        // C\u00f3digo de inicializa\u00e7\u00e3o\n    }\n};\n</code></pre> <p>Exemplo:</p> <pre><code>class Sensor {\npublic:\n    int id;\n    float valor;\n\n    // Construtor\n    Sensor(int sensorId, float sensorValor) {\n        id = sensorId;\n        valor = sensorValor;\n    }\n\n    void imprimirDados() {\n        Serial.print(\"Sensor \");\n        Serial.print(id);\n        Serial.print(\": \");\n        Serial.println(valor);\n    }\n};\n\nvoid setup() {\n    Serial.begin(9600);\n\n    Sensor sensor1(1, 23.5);\n    Sensor sensor2(2, 47.8);\n\n    sensor1.imprimirDados();\n    sensor2.imprimirDados();\n}\n\nvoid loop() {\n    // N\u00e3o h\u00e1 c\u00f3digo no loop\n}\n</code></pre> <p>Explica\u00e7\u00e3o:</p> <ul> <li>A classe <code>Sensor</code> possui um construtor que inicializa os atributos <code>id</code> e <code>valor</code>.</li> <li>Cria dois objetos <code>sensor1</code> e <code>sensor2</code> com valores iniciais.</li> <li>Chama o m\u00e9todo <code>imprimirDados</code> para exibir os dados no Monitor Serial.</li> </ul>"},{"location":"aulas/iot/modulos/modulo8.html#52-destrutores","title":"5.2 Destrutores","text":"<p>Um destruidor \u00e9 um m\u00e9todo especial que \u00e9 chamado automaticamente quando um objeto \u00e9 destru\u00eddo ou sai de escopo. \u00c9 usado para liberar recursos ou realizar tarefas de limpeza.</p> <p>Sintaxe:</p> <pre><code>class NomeClasse {\npublic:\n    ~NomeClasse() {\n        // C\u00f3digo de limpeza\n    }\n};\n</code></pre> <p>Exemplo:</p> <pre><code>class Motor {\npublic:\n    Motor() {\n        Serial.println(\"Motor criado.\");\n    }\n\n    ~Motor() {\n        Serial.println(\"Motor destru\u00eddo.\");\n    }\n\n    void ligar() {\n        Serial.println(\"Motor ligado.\");\n    }\n};\n\nvoid setup() {\n    Serial.begin(9600);\n    {\n        Motor motor1;\n        motor1.ligar();\n    } // motor1 \u00e9 destru\u00eddo aqui\n}\n\nvoid loop() {\n    // N\u00e3o h\u00e1 c\u00f3digo no loop\n}\n</code></pre> <p>Explica\u00e7\u00e3o:</p> <ul> <li>A classe <code>Motor</code> possui um construtor que imprime uma mensagem ao ser criado e um destruidor que imprime uma mensagem ao ser destru\u00eddo.</li> <li>O objeto <code>motor1</code> \u00e9 criado dentro de um bloco de c\u00f3digo <code>{}</code> e \u00e9 destru\u00eddo ao final do bloco.</li> </ul>"},{"location":"aulas/iot/modulos/modulo8.html#6-encapsulamento-heranca-e-polimorfismo","title":"6. Encapsulamento, Heran\u00e7a e Polimorfismo","text":""},{"location":"aulas/iot/modulos/modulo8.html#61-encapsulamento","title":"6.1 Encapsulamento","text":"<p>Encapsulamento \u00e9 o conceito de esconder os detalhes internos de uma classe e expor apenas o necess\u00e1rio atrav\u00e9s de m\u00e9todos p\u00fablicos.</p> <p>Exemplo:</p> <pre><code>class ContaBancaria {\nprivate:\n    float saldo;\n\npublic:\n    ContaBancaria(float saldoInicial) {\n        saldo = saldoInicial;\n    }\n\n    void depositar(float valor) {\n        saldo += valor;\n    }\n\n    void sacar(float valor) {\n        if(valor &lt;= saldo) {\n            saldo -= valor;\n        } else {\n            Serial.println(\"Saldo insuficiente.\");\n        }\n    }\n\n    float getSaldo() {\n        return saldo;\n    }\n};\n\nvoid setup() {\n    Serial.begin(9600);\n    ContaBancaria minhaConta(1000.0);\n\n    minhaConta.depositar(500.0);\n    minhaConta.sacar(200.0);\n\n    Serial.print(\"Saldo Atual: \");\n    Serial.println(minhaConta.getSaldo());\n}\n\nvoid loop() {\n    // N\u00e3o h\u00e1 c\u00f3digo no loop\n}\n</code></pre> <p>Explica\u00e7\u00e3o:</p> <ul> <li>A classe <code>ContaBancaria</code> encapsula o atributo <code>saldo</code> como privado.</li> <li>M\u00e9todos p\u00fablicos <code>depositar</code>, <code>sacar</code> e <code>getSaldo</code> permitem a manipula\u00e7\u00e3o segura do saldo.</li> </ul>"},{"location":"aulas/iot/modulos/modulo8.html#62-heranca","title":"6.2 Heran\u00e7a","text":"<p>Heran\u00e7a permite que uma classe (classe derivada) herde atributos e m\u00e9todos de outra classe (classe base), promovendo a reutiliza\u00e7\u00e3o de c\u00f3digo.</p> <p>Exemplo:</p> <pre><code>class Veiculo {\npublic:\n    int rodas;\n\n    void mover() {\n        Serial.println(\"Ve\u00edculo em movimento.\");\n    }\n};\n\nclass Carro : public Veiculo {\npublic:\n    string modelo;\n\n    void buzinar() {\n        Serial.println(\"Buzinando!\");\n    }\n};\n\nvoid setup() {\n    Serial.begin(9600);\n    Carro meuCarro;\n    meuCarro.rodas = 4;\n    meuCarro.modelo = \"Sedan\";\n\n    Serial.print(\"Modelo: \");\n    Serial.println(meuCarro.modelo.c_str());\n    Serial.print(\"Rodas: \");\n    Serial.println(meuCarro.rodas);\n\n    meuCarro.mover();\n    meuCarro.buzinar();\n}\n\nvoid loop() {\n    // N\u00e3o h\u00e1 c\u00f3digo no loop\n}\n</code></pre> <p>Explica\u00e7\u00e3o:</p> <ul> <li>A classe <code>Carro</code> herda da classe <code>Veiculo</code>, recebendo o atributo <code>rodas</code> e o m\u00e9todo <code>mover</code>.</li> <li>Adiciona o atributo <code>modelo</code> e o m\u00e9todo <code>buzinar</code>.</li> </ul>"},{"location":"aulas/iot/modulos/modulo8.html#63-polimorfismo","title":"6.3 Polimorfismo","text":"<p>Polimorfismo permite que objetos de diferentes classes sejam tratados de forma uniforme atrav\u00e9s de interfaces comuns.</p> <p>Exemplo:</p> <pre><code>class Forma {\npublic:\n    virtual void desenhar() {\n        Serial.println(\"Desenhando uma forma gen\u00e9rica.\");\n    }\n};\n\nclass Circulo : public Forma {\npublic:\n    void desenhar() override {\n        Serial.println(\"Desenhando um c\u00edrculo.\");\n    }\n};\n\nclass Retangulo : public Forma {\npublic:\n    void desenhar() override {\n        Serial.println(\"Desenhando um ret\u00e2ngulo.\");\n    }\n};\n\nvoid setup() {\n    Serial.begin(9600);\n\n    Forma *formas[2];\n    formas[0] = new Circulo();\n    formas[1] = new Retangulo();\n\n    for(int i = 0; i &lt; 2; i++) {\n        formas[i]-&gt;desenhar();\n    }\n\n    // Libera\u00e7\u00e3o de mem\u00f3ria\n    for(int i = 0; i &lt; 2; i++) {\n        delete formas[i];\n    }\n}\n\nvoid loop() {\n    // N\u00e3o h\u00e1 c\u00f3digo no loop\n}\n</code></pre> <p>Explica\u00e7\u00e3o:</p> <ul> <li>Define uma classe base <code>Forma</code> com um m\u00e9todo virtual <code>desenhar</code>.</li> <li>As classes <code>Circulo</code> e <code>Retangulo</code> sobrescrevem o m\u00e9todo <code>desenhar</code>.</li> <li>Permite que diferentes objetos sejam chamados de forma polim\u00f3rfica atrav\u00e9s de ponteiros da classe base.</li> </ul>"},{"location":"aulas/iot/modulos/modulo8.html#7-exemplos-praticos","title":"7. Exemplos Pr\u00e1ticos","text":""},{"location":"aulas/iot/modulos/modulo8.html#71-criando-uma-classe-para-representar-um-sensor","title":"7.1 Criando uma Classe para Representar um Sensor","text":"<pre><code>class Sensor {\nprivate:\n    int id;\n    float valor;\n\npublic:\n    // Construtor\n    Sensor(int sensorId, float sensorValor) {\n        id = sensorId;\n        valor = sensorValor;\n    }\n\n    // M\u00e9todos para acessar e modificar os atributos\n    int getId() {\n        return id;\n    }\n\n    float getValor() {\n        return valor;\n    }\n\n    void setValor(float novoValor) {\n        valor = novoValor;\n    }\n\n    void imprimirDados() {\n        Serial.print(\"Sensor \");\n        Serial.print(id);\n        Serial.print(\": \");\n        Serial.println(valor);\n    }\n};\n\nvoid setup() {\n    Serial.begin(9600);\n\n    Sensor sensor1(1, 23.5);\n    Sensor sensor2(2, 47.8);\n\n    sensor1.imprimirDados();\n    sensor2.imprimirDados();\n\n    // Atualizando o valor do sensor1\n    sensor1.setValor(25.0);\n    Serial.println(\"Ap\u00f3s atualiza\u00e7\u00e3o:\");\n    sensor1.imprimirDados();\n}\n\nvoid loop() {\n    // N\u00e3o h\u00e1 c\u00f3digo no loop\n}\n</code></pre> <p>Explica\u00e7\u00e3o:</p> <ul> <li>Define a classe <code>Sensor</code> com atributos privados <code>id</code> e <code>valor</code>.</li> <li>Inclui m\u00e9todos p\u00fablicos para acessar e modificar esses atributos.</li> <li>No <code>setup</code>, cria dois objetos <code>sensor1</code> e <code>sensor2</code>, imprime seus dados e atualiza o valor de <code>sensor1</code>.</li> </ul>"},{"location":"aulas/iot/modulos/modulo8.html#72-implementando-uma-classe-de-led-com-metodos-para-ligar-e-desligar","title":"7.2 Implementando uma Classe de LED com M\u00e9todos para Ligar e Desligar","text":"<pre><code>class LED {\nprivate:\n    int pin;\n\npublic:\n    // Construtor\n    LED(int ledPin) {\n        pin = ledPin;\n        pinMode(pin, OUTPUT);\n    }\n\n    // M\u00e9todo para ligar o LED\n    void ligar() {\n        digitalWrite(pin, HIGH);\n    }\n\n    // M\u00e9todo para desligar o LED\n    void desligar() {\n        digitalWrite(pin, LOW);\n    }\n\n    // M\u00e9todo para alternar o estado do LED\n    void alternar() {\n        int estado = digitalRead(pin);\n        digitalWrite(pin, !estado);\n    }\n};\n\nLED meuLED(13); // LED conectado ao pino 13\n\nvoid setup() {\n    Serial.begin(9600);\n    Serial.println(\"Controlando o LED.\");\n\n    meuLED.ligar();\n    delay(1000);\n    meuLED.desligar();\n    delay(1000);\n}\n\nvoid loop() {\n    meuLED.alternar();\n    delay(500);\n}\n</code></pre> <p>Explica\u00e7\u00e3o:</p> <ul> <li>Define a classe <code>LED</code> com um atributo privado <code>pin</code>.</li> <li>Inclui m\u00e9todos para ligar, desligar e alternar o estado do LED.</li> <li>No <code>setup</code>, liga e desliga o LED uma vez.</li> <li>No <code>loop</code>, alterna o estado do LED a cada meio segundo.</li> </ul>"},{"location":"aulas/iot/modulos/modulo8.html#73-criando-uma-classe-para-gerenciar-um-array-de-sensores","title":"7.3 Criando uma Classe para Gerenciar um Array de Sensores","text":"<pre><code>class GerenciadorSensores {\nprivate:\n    Sensor sensores[5];\n    int quantidade;\n\npublic:\n    // Construtor\n    GerenciadorSensores() : sensores{Sensor(1, 23.5), Sensor(2, 47.8), Sensor(3, 30.2), Sensor(4, 50.0), Sensor(5, 25.5)} {\n        quantidade = 5;\n    }\n\n    // M\u00e9todo para imprimir todos os sensores\n    void imprimirTodos() {\n        for(int i = 0; i &lt; quantidade; i++) {\n            sensores[i].imprimirDados();\n        }\n    }\n\n    // M\u00e9todo para atualizar o valor de um sensor espec\u00edfico\n    void atualizarSensor(int id, float novoValor) {\n        for(int i = 0; i &lt; quantidade; i++) {\n            if(sensores[i].getId() == id) {\n                sensores[i].setValor(novoValor);\n                Serial.print(\"Sensor \");\n                Serial.print(id);\n                Serial.println(\" atualizado.\");\n                return;\n            }\n        }\n        Serial.println(\"Sensor n\u00e3o encontrado.\");\n    }\n};\n\nGerenciadorSensores gerenciador;\n\nvoid setup() {\n    Serial.begin(9600);\n    Serial.println(\"Gerenciador de Sensores:\");\n\n    gerenciador.imprimirTodos();\n\n    // Atualizando o valor do sensor 3\n    gerenciador.atualizarSensor(3, 35.0);\n\n    Serial.println(\"Ap\u00f3s atualiza\u00e7\u00e3o:\");\n    gerenciador.imprimirTodos();\n}\n\nvoid loop() {\n    // N\u00e3o h\u00e1 c\u00f3digo no loop\n}\n</code></pre> <p>Explica\u00e7\u00e3o:</p> <ul> <li>Define a classe <code>GerenciadorSensores</code> que gerencia um array de 5 objetos <code>Sensor</code>.</li> <li>Inclui m\u00e9todos para imprimir todos os sensores e atualizar o valor de um sensor espec\u00edfico.</li> <li>No <code>setup</code>, imprime todos os sensores, atualiza o sensor com <code>id</code> 3 e imprime novamente.</li> </ul>"},{"location":"aulas/iot/modulos/modulo8.html#8-exercicios-praticos","title":"8. Exerc\u00edcios Pr\u00e1ticos","text":""},{"location":"aulas/iot/modulos/modulo8.html#exercicio-1-criar-uma-classe-para-representar-um-veiculo","title":"Exerc\u00edcio 1: Criar uma Classe para Representar um Ve\u00edculo","text":"<ul> <li> <p>Tarefa: Desenvolva uma classe <code>Veiculo</code> que possui atributos como <code>marca</code>, <code>modelo</code> e <code>ano</code>. Inclua m\u00e9todos para ligar, desligar e exibir as informa\u00e7\u00f5es do ve\u00edculo.</p> </li> <li> <p>Exemplo de C\u00f3digo:</p> </li> </ul> <pre><code>class Veiculo {\nprivate:\n    String marca;\n    String modelo;\n    int ano;\n    bool ligado;\n\npublic:\n    // Construtor\n    Veiculo(String m, String mo, int a) : marca(m), modelo(mo), ano(a), ligado(false) {}\n\n    // M\u00e9todos\n    void ligar() {\n        if(!ligado) {\n            ligado = true;\n            Serial.println(\"Ve\u00edculo ligado.\");\n        } else {\n            Serial.println(\"Ve\u00edculo j\u00e1 est\u00e1 ligado.\");\n        }\n    }\n\n    void desligar() {\n        if(ligado) {\n            ligado = false;\n            Serial.println(\"Ve\u00edculo desligado.\");\n        } else {\n            Serial.println(\"Ve\u00edculo j\u00e1 est\u00e1 desligado.\");\n        }\n    }\n\n    void exibirInfo() {\n        Serial.print(\"Marca: \");\n        Serial.println(marca);\n        Serial.print(\"Modelo: \");\n        Serial.println(modelo);\n        Serial.print(\"Ano: \");\n        Serial.println(ano);\n        Serial.print(\"Estado: \");\n        Serial.println(ligado ? \"Ligado\" : \"Desligado\");\n    }\n};\n\nVeiculo meuCarro(\"Toyota\", \"Corolla\", 2020);\n\nvoid setup() {\n    Serial.begin(9600);\n    meuCarro.exibirInfo();\n    meuCarro.ligar();\n    meuCarro.exibirInfo();\n    meuCarro.desligar();\n    meuCarro.exibirInfo();\n}\n\nvoid loop() {\n    // N\u00e3o h\u00e1 c\u00f3digo no loop\n}\n</code></pre>"},{"location":"aulas/iot/modulos/modulo8.html#exercicio-2-implementar-heranca-com-classes-animal-e-cachorro","title":"Exerc\u00edcio 2: Implementar Heran\u00e7a com Classes <code>Animal</code> e <code>Cachorro</code>","text":"<ul> <li> <p>Tarefa: Crie uma classe base <code>Animal</code> com atributos e m\u00e9todos gerais, e uma classe derivada <code>Cachorro</code> que herda de <code>Animal</code> e adiciona comportamentos espec\u00edficos.</p> </li> <li> <p>Exemplo de C\u00f3digo:</p> </li> </ul> <pre><code>class Animal {\nprotected:\n    String nome;\n    int idade;\n\npublic:\n    // Construtor\n    Animal(String n, int i) : nome(n), idade(i) {}\n\n    // M\u00e9todo para exibir informa\u00e7\u00f5es\n    void exibirInfo() {\n        Serial.print(\"Nome: \");\n        Serial.println(nome);\n        Serial.print(\"Idade: \");\n        Serial.println(idade);\n    }\n\n    // M\u00e9todo virtual\n    virtual void emitirSom() {\n        Serial.println(\"Animal emite som.\");\n    }\n};\n\nclass Cachorro : public Animal {\npublic:\n    // Construtor\n    Cachorro(String n, int i) : Animal(n, i) {}\n\n    // Sobrescreve o m\u00e9todo emitirSom\n    void emitirSom() override {\n        Serial.println(\"Cachorro diz: Au Au!\");\n    }\n};\n\nvoid setup() {\n    Serial.begin(9600);\n\n    Animal meuAnimal(\"Gen\u00e9rico\", 5);\n    Cachorro meuCachorro(\"Rex\", 3);\n\n    Serial.println(\"Informa\u00e7\u00f5es do Animal:\");\n    meuAnimal.exibirInfo();\n    meuAnimal.emitirSom();\n\n    Serial.println(\"\\nInforma\u00e7\u00f5es do Cachorro:\");\n    meuCachorro.exibirInfo();\n    meuCachorro.emitirSom();\n}\n\nvoid loop() {\n    // N\u00e3o h\u00e1 c\u00f3digo no loop\n}\n</code></pre> <p>Explica\u00e7\u00e3o:</p> <ul> <li>A classe <code>Animal</code> possui atributos <code>nome</code> e <code>idade</code>, e m\u00e9todos para exibir informa\u00e7\u00f5es e emitir som.</li> <li>A classe <code>Cachorro</code> herda de <code>Animal</code> e sobrescreve o m\u00e9todo <code>emitirSom</code> para emitir um som espec\u00edfico.</li> <li>No <code>setup</code>, cria objetos <code>meuAnimal</code> e <code>meuCachorro</code> e chama seus m\u00e9todos.</li> </ul>"},{"location":"aulas/iot/modulos/modulo8.html#exercicio-3-implementar-encapsulamento-com-a-classe-lampada","title":"Exerc\u00edcio 3: Implementar Encapsulamento com a Classe <code>Lampada</code>","text":"<ul> <li> <p>Tarefa: Crie uma classe <code>Lampada</code> que possui atributos privados <code>estado</code> (ligada/desligada) e <code>intensidade</code>. Inclua m\u00e9todos p\u00fablicos para ligar, desligar, aumentar e diminuir a intensidade, e exibir o estado atual.</p> </li> <li> <p>Exemplo de C\u00f3digo:</p> </li> </ul> <pre><code>class Lampada {\nprivate:\n    bool ligada;\n    int intensidade; // De 0 a 100\n\npublic:\n    // Construtor\n    Lampada() : ligada(false), intensidade(0) {}\n\n    // M\u00e9todos\n    void ligar() {\n        ligada = true;\n        Serial.println(\"L\u00e2mpada ligada.\");\n    }\n\n    void desligar() {\n        ligada = false;\n        intensidade = 0;\n        Serial.println(\"L\u00e2mpada desligada.\");\n    }\n\n    void aumentarIntensidade(int valor) {\n        if(ligada) {\n            intensidade += valor;\n            if(intensidade &gt; 100) intensidade = 100;\n            Serial.print(\"Intensidade aumentada para: \");\n            Serial.println(intensidade);\n        } else {\n            Serial.println(\"L\u00e2mpada est\u00e1 desligada. N\u00e3o \u00e9 poss\u00edvel aumentar a intensidade.\");\n        }\n    }\n\n    void diminuirIntensidade(int valor) {\n        if(ligada) {\n            intensidade -= valor;\n            if(intensidade &lt; 0) intensidade = 0;\n            Serial.print(\"Intensidade diminu\u00edda para: \");\n            Serial.println(intensidade);\n        } else {\n            Serial.println(\"L\u00e2mpada est\u00e1 desligada. N\u00e3o \u00e9 poss\u00edvel diminuir a intensidade.\");\n        }\n    }\n\n    void exibirEstado() {\n        Serial.print(\"Estado da L\u00e2mpada: \");\n        Serial.println(ligada ? \"Ligada\" : \"Desligada\");\n        Serial.print(\"Intensidade: \");\n        Serial.println(intensidade);\n    }\n};\n\nLampada minhaLampada;\n\nvoid setup() {\n    Serial.begin(9600);\n    minhaLampada.exibirEstado();\n\n    minhaLampada.ligar();\n    minhaLampada.aumentarIntensidade(30);\n    minhaLampada.aumentarIntensidade(50);\n    minhaLampada.diminuirIntensidade(20);\n    minhaLampada.exibirEstado();\n\n    minhaLampada.desligar();\n    minhaLampada.exibirEstado();\n}\n\nvoid loop() {\n    // N\u00e3o h\u00e1 c\u00f3digo no loop\n}\n</code></pre> <p>Explica\u00e7\u00e3o:</p> <ul> <li>A classe <code>Lampada</code> encapsula os atributos <code>ligada</code> e <code>intensidade</code> como privados.</li> <li>Inclui m\u00e9todos p\u00fablicos para manipular o estado e a intensidade da l\u00e2mpada.</li> <li>No <code>setup</code>, demonstra o uso dos m\u00e9todos da classe <code>Lampada</code>.</li> </ul>"},{"location":"aulas/iot/modulos/modulo8.html#9-conceitos-importantes","title":"9. Conceitos Importantes","text":""},{"location":"aulas/iot/modulos/modulo8.html#91-encapsulamento","title":"9.1 Encapsulamento","text":"<ul> <li>Defini\u00e7\u00e3o: Esconder os detalhes internos de uma classe e expor apenas os necess\u00e1rios atrav\u00e9s de m\u00e9todos p\u00fablicos.</li> <li>Benef\u00edcios:</li> <li>Seguran\u00e7a: Protege os dados contra acessos indevidos.</li> <li>Manuten\u00e7\u00e3o: Facilita a altera\u00e7\u00e3o interna sem afetar o c\u00f3digo externo.</li> </ul>"},{"location":"aulas/iot/modulos/modulo8.html#92-heranca","title":"9.2 Heran\u00e7a","text":"<ul> <li>Defini\u00e7\u00e3o: Permite que uma classe derive atributos e m\u00e9todos de outra classe.</li> <li>Tipos de Heran\u00e7a:</li> <li>P\u00fablica (<code>public</code>): Os membros p\u00fablicos e protegidos da classe base permanecem p\u00fablicos e protegidos na classe derivada.</li> <li>Privada (<code>private</code>): Todos os membros herdados se tornam privados na classe derivada.</li> </ul>"},{"location":"aulas/iot/modulos/modulo8.html#93-polimorfismo","title":"9.3 Polimorfismo","text":"<ul> <li>Defini\u00e7\u00e3o: Permite que objetos de diferentes classes sejam tratados de forma uniforme atrav\u00e9s de interfaces comuns.</li> <li>M\u00e9todos Virtuais: Facilita o polimorfismo, permitindo que m\u00e9todos sejam sobrescritos em classes derivadas.</li> </ul>"},{"location":"aulas/iot/modulos/modulo8.html#94-gerenciamento-de-memoria","title":"9.4 Gerenciamento de Mem\u00f3ria","text":"<ul> <li>Import\u00e2ncia: Classes e objetos podem consumir mem\u00f3ria significativa, especialmente em microcontroladores com recursos limitados.</li> <li>Boas Pr\u00e1ticas:</li> <li>Evitar Aloca\u00e7\u00e3o Din\u00e2mica Desnecess\u00e1ria: Use objetos est\u00e1ticos sempre que poss\u00edvel.</li> <li>Liberar Mem\u00f3ria Alocada Dinamicamente: Utilize <code>delete</code> e <code>delete[]</code> apropriadamente.</li> </ul>"},{"location":"aulas/iot/modulos/modulo8.html#95-boas-praticas-de-programacao-orientada-a-objetos","title":"9.5 Boas Pr\u00e1ticas de Programa\u00e7\u00e3o Orientada a Objetos","text":"<ul> <li>Nomea\u00e7\u00e3o Clara: Use nomes significativos para classes, m\u00e9todos e atributos.</li> <li>Responsabilidade \u00danica: Cada classe deve ter uma \u00fanica responsabilidade ou funcionalidade.</li> <li>Modulariza\u00e7\u00e3o: Divida o c\u00f3digo em m\u00f3dulos e classes que representam entidades do mundo real ou conceitos l\u00f3gicos.</li> <li>Reutiliza\u00e7\u00e3o de C\u00f3digo: Utilize heran\u00e7a e composi\u00e7\u00e3o para reutilizar c\u00f3digo de forma eficiente.</li> </ul>"},{"location":"aulas/iot/modulos/modulo9.html","title":"M\u00f3dulo 9: Interrup\u00e7\u00f5es e Timers","text":"<p>Bem-vindo ao M\u00f3dulo 9 do curso \"Programa\u00e7\u00e3o em Arduino: Conceitos Fundamentais sem Hardware\". Neste m\u00f3dulo, voc\u00ea ir\u00e1 explorar as interrup\u00e7\u00f5es e timers na linguagem de programa\u00e7\u00e3o Arduino (C/C++). Esses conceitos s\u00e3o essenciais para criar programas responsivos e eficientes, capazes de lidar com eventos ass\u00edncronos e temporiza\u00e7\u00f5es precisas.</p>"},{"location":"aulas/iot/modulos/modulo9.html#objetivos-do-modulo","title":"Objetivos do M\u00f3dulo","text":"<ul> <li>Compreender o conceito de interrup\u00e7\u00f5es e sua import\u00e2ncia na programa\u00e7\u00e3o Arduino.</li> <li>Aprender a configurar e utilizar interrup\u00e7\u00f5es externas e internas.</li> <li>Entender o funcionamento dos timers e como utiliz\u00e1-los para gerar eventos temporizados.</li> <li>Implementar aplica\u00e7\u00f5es que utilizam interrup\u00e7\u00f5es e timers para melhorar a efici\u00eancia e a responsividade do programa.</li> <li>Resolver exerc\u00edcios pr\u00e1ticos para consolidar o conhecimento sobre interrup\u00e7\u00f5es e timers.</li> </ul>"},{"location":"aulas/iot/modulos/modulo9.html#1-introducao-a-interrupcoes-e-timers","title":"1. Introdu\u00e7\u00e3o a Interrup\u00e7\u00f5es e Timers","text":""},{"location":"aulas/iot/modulos/modulo9.html#11-o-que-sao-interrupcoes","title":"1.1 O que s\u00e3o Interrup\u00e7\u00f5es?","text":"<p>Interrup\u00e7\u00f5es s\u00e3o sinais que indicam a ocorr\u00eancia de um evento que requer aten\u00e7\u00e3o imediata do processador. Quando uma interrup\u00e7\u00e3o ocorre, o fluxo normal do programa \u00e9 temporariamente interrompido para executar uma rotina de tratamento espec\u00edfica, conhecida como ISR (Interrupt Service Routine). Ap\u00f3s a execu\u00e7\u00e3o da ISR, o programa retorna ao ponto onde foi interrompido.</p>"},{"location":"aulas/iot/modulos/modulo9.html#12-por-que-usar-interrupcoes","title":"1.2 Por que Usar Interrup\u00e7\u00f5es?","text":"<ul> <li>Responsividade: Permite que o microcontrolador reaja rapidamente a eventos externos sem a necessidade de verificar constantemente o estado de entradas.</li> <li>Efici\u00eancia: Reduz o consumo de CPU, j\u00e1 que o processador pode executar outras tarefas enquanto espera por eventos.</li> <li>Precis\u00e3o: Garante que eventos cr\u00edticos sejam tratados imediatamente, aumentando a precis\u00e3o das opera\u00e7\u00f5es temporizadas.</li> </ul>"},{"location":"aulas/iot/modulos/modulo9.html#13-o-que-sao-timers","title":"1.3 O que s\u00e3o Timers?","text":"<p>Timers s\u00e3o m\u00f3dulos internos que contam ciclos de clock e geram eventos ap\u00f3s um determinado per\u00edodo. Eles s\u00e3o usados para criar temporiza\u00e7\u00f5es precisas, gerar sinais PWM, ou criar delays sem bloquear a execu\u00e7\u00e3o do programa principal.</p>"},{"location":"aulas/iot/modulos/modulo9.html#2-trabalhando-com-interrupcoes","title":"2. Trabalhando com Interrup\u00e7\u00f5es","text":""},{"location":"aulas/iot/modulos/modulo9.html#21-tipos-de-interrupcoes-no-arduino","title":"2.1 Tipos de Interrup\u00e7\u00f5es no Arduino","text":"<ul> <li>Interrup\u00e7\u00f5es Externas: Disparadas por sinais em pinos espec\u00edficos (por exemplo, bot\u00f5es ou sensores).</li> <li>Interrup\u00e7\u00f5es Internas: Disparadas por eventos internos, como overflow de timers ou comunica\u00e7\u00e3o serial.</li> </ul>"},{"location":"aulas/iot/modulos/modulo9.html#22-configuracao-de-interrupcoes-externas","title":"2.2 Configura\u00e7\u00e3o de Interrup\u00e7\u00f5es Externas","text":"<p>Os Arduinos possuem pinos espec\u00edficos que suportam interrup\u00e7\u00f5es externas. Por exemplo, no Arduino Uno, os pinos 2 e 3 s\u00e3o comumente usados para esse prop\u00f3sito.</p> <p>Sintaxe:</p> <pre><code>attachInterrupt(digitalPinToInterrupt(pino), nomeISR, modo);\n</code></pre> <ul> <li>pino: N\u00famero do pino que receber\u00e1 a interrup\u00e7\u00e3o.</li> <li>nomeISR: Nome da fun\u00e7\u00e3o que ser\u00e1 chamada quando a interrup\u00e7\u00e3o ocorrer.</li> <li>modo: Condi\u00e7\u00e3o que dispara a interrup\u00e7\u00e3o (<code>LOW</code>, <code>CHANGE</code>, <code>RISING</code>, <code>FALLING</code>).</li> </ul> <p>Exemplo Pr\u00e1tico:</p> <pre><code>volatile bool botaoPressionado = false;\n\nvoid botaoISR() {\n    botaoPressionado = true;\n}\n\nvoid setup() {\n    Serial.begin(9600);\n    pinMode(2, INPUT_PULLUP); // Bot\u00e3o conectado ao pino 2\n    attachInterrupt(digitalPinToInterrupt(2), botaoISR, FALLING);\n}\n\nvoid loop() {\n    if(botaoPressionado) {\n        Serial.println(\"Bot\u00e3o pressionado!\");\n        botaoPressionado = false;\n    }\n}\n</code></pre> <p>Explica\u00e7\u00e3o:</p> <ul> <li><code>volatile</code>: Indica que a vari\u00e1vel pode ser alterada por uma ISR, evitando otimiza\u00e7\u00f5es que poderiam ignorar mudan\u00e7as.</li> <li><code>botaoISR</code>: ISR que altera o estado da vari\u00e1vel <code>botaoPressionado</code> quando o bot\u00e3o \u00e9 pressionado.</li> <li><code>attachInterrupt</code>: Configura a interrup\u00e7\u00e3o no pino 2 para detectar bordas de descida (<code>FALLING</code>).</li> </ul>"},{"location":"aulas/iot/modulos/modulo9.html#23-boas-praticas-com-isrs","title":"2.3 Boas Pr\u00e1ticas com ISRs","text":"<ul> <li>Mantenha as ISRs Curtas: Execute apenas o necess\u00e1rio dentro da ISR para evitar atrasos no processamento.</li> <li>Use Vari\u00e1veis Vol\u00e1teis: Vari\u00e1veis compartilhadas entre a ISR e o loop principal devem ser declaradas como <code>volatile</code>.</li> <li>Evite Fun\u00e7\u00f5es Complexas: Evite chamadas a fun\u00e7\u00f5es que dependem de interrup\u00e7\u00f5es, como <code>Serial.print()</code>, dentro da ISR.</li> </ul>"},{"location":"aulas/iot/modulos/modulo9.html#3-trabalhando-com-timers","title":"3. Trabalhando com Timers","text":""},{"location":"aulas/iot/modulos/modulo9.html#31-tipos-de-timers-no-arduino","title":"3.1 Tipos de Timers no Arduino","text":"<ul> <li>Timer0: Usado pelo <code>millis()</code> e <code>delay()</code>. N\u00e3o deve ser alterado para evitar conflitos.</li> <li>Timer1: Um timer de 16 bits, ideal para aplica\u00e7\u00f5es que requerem precis\u00e3o.</li> <li>Timer2: Um timer de 8 bits, \u00fatil para tarefas menos precisas.</li> </ul>"},{"location":"aulas/iot/modulos/modulo9.html#32-configuracao-de-timer1-para-gerar-uma-interrupcao","title":"3.2 Configura\u00e7\u00e3o de Timer1 para Gerar uma Interrup\u00e7\u00e3o","text":"<p>Exemplo Pr\u00e1tico:</p> <pre><code>volatile unsigned long contador = 0;\n\nISR(TIMER1_COMPA_vect) {\n    contador++;\n}\n\nvoid setup() {\n    Serial.begin(9600);\n\n    // Configura Timer1 para CTC mode (Clear Timer on Compare Match)\n    TCCR1A = 0;\n    TCCR1B = 0;\n    TCCR1B |= (1 &lt;&lt; WGM12);\n\n    // Define valor de compara\u00e7\u00e3o para gerar interrup\u00e7\u00e3o a cada 1 segundo\n    OCR1A = 15624; // (16MHz / (Prescaler * Desired Frequency)) - 1\n    TCCR1B |= (1 &lt;&lt; CS12) | (1 &lt;&lt; CS10); // Prescaler = 1024\n    TIMSK1 |= (1 &lt;&lt; OCIE1A); // Habilita interrup\u00e7\u00e3o por compara\u00e7\u00e3o\n\n    sei(); // Habilita interrup\u00e7\u00f5es globais\n}\n\nvoid loop() {\n    if(contador &gt;= 5) { // Ap\u00f3s 5 segundos\n        Serial.println(\"5 segundos se passaram!\");\n        contador = 0;\n    }\n}\n</code></pre> <p>Explica\u00e7\u00e3o:</p> <ul> <li>CTC Mode: Configura o timer para limpar o contador quando atingir o valor de compara\u00e7\u00e3o.</li> <li>OCR1A: Define o valor de compara\u00e7\u00e3o para gerar uma interrup\u00e7\u00e3o a cada segundo.</li> <li>Prescaler: Reduz a frequ\u00eancia do clock do timer para atingir a temporiza\u00e7\u00e3o desejada.</li> <li><code>sei()</code>: Habilita interrup\u00e7\u00f5es globais.</li> <li><code>ISR(TIMER1_COMPA_vect)</code>: ISR chamada a cada vez que o timer atinge o valor de compara\u00e7\u00e3o, incrementando o contador.</li> </ul>"},{"location":"aulas/iot/modulos/modulo9.html#33-gerando-pwm-com-timers","title":"3.3 Gerando PWM com Timers","text":"<p>Os timers tamb\u00e9m podem ser usados para gerar sinais PWM (Pulse Width Modulation) com maior precis\u00e3o ou em pinos espec\u00edficos.</p> <p>Exemplo Pr\u00e1tico:</p> <pre><code>void setup() {\n    // Configura o pino 9 como sa\u00edda (usado pelo Timer1)\n    pinMode(9, OUTPUT);\n\n    // Configura Timer1 para Fast PWM mode\n    TCCR1A |= (1 &lt;&lt; COM1A1) | (1 &lt;&lt; WGM11);\n    TCCR1B |= (1 &lt;&lt; WGM13) | (1 &lt;&lt; WGM12) | (1 &lt;&lt; CS10); // Prescaler = 1\n    ICR1 = 19999; // Define frequ\u00eancia de 50Hz (usando 16MHz)\n\n    // Define o ciclo de trabalho (Duty Cycle) para 7.5% (posi\u00e7\u00e3o neutra)\n    OCR1A = 1500; // 1.5ms pulse width\n}\n\nvoid loop() {\n    // Pode ajustar OCR1A para alterar o ciclo de trabalho\n}\n</code></pre> <p>Explica\u00e7\u00e3o:</p> <ul> <li>Fast PWM Mode: Configura o timer para modo de PWM r\u00e1pido, permitindo uma frequ\u00eancia est\u00e1vel.</li> <li>ICR1: Define o per\u00edodo do PWM (por exemplo, 20ms para 50Hz).</li> <li>OCR1A: Define a largura do pulso, controlando o ciclo de trabalho.</li> <li>PWM Aplica\u00e7\u00e3o: Comumente usado para controlar servos ou LEDs com brilho ajust\u00e1vel.</li> </ul>"},{"location":"aulas/iot/modulos/modulo9.html#4-exemplos-praticos","title":"4. Exemplos Pr\u00e1ticos","text":""},{"location":"aulas/iot/modulos/modulo9.html#41-monitorando-um-sensor-com-interrupcao","title":"4.1 Monitorando um Sensor com Interrup\u00e7\u00e3o","text":"<pre><code>volatile float leituraSensor = 0.0;\n\nvoid sensorISR() {\n    leituraSensor = analogRead(A0);\n}\n\nvoid setup() {\n    Serial.begin(9600);\n    pinMode(2, INPUT_PULLUP); // Sensor conectado ao pino 2\n\n    attachInterrupt(digitalPinToInterrupt(2), sensorISR, FALLING);\n}\n\nvoid loop() {\n    if(leituraSensor &gt; 0) {\n        Serial.print(\"Leitura do Sensor: \");\n        Serial.println(leituraSensor);\n        leituraSensor = 0.0;\n    }\n}\n</code></pre> <p>Explica\u00e7\u00e3o:</p> <ul> <li><code>sensorISR</code>: ISR que l\u00ea o valor anal\u00f3gico do sensor quando ocorre uma interrup\u00e7\u00e3o no pino 2.</li> <li>Loop Principal: Verifica se uma nova leitura est\u00e1 dispon\u00edvel e a imprime no Monitor Serial.</li> </ul>"},{"location":"aulas/iot/modulos/modulo9.html#42-blink-com-timer1","title":"4.2 Blink com Timer1","text":"<pre><code>volatile bool toggle = false;\n\nISR(TIMER1_COMPA_vect) {\n    toggle = !toggle;\n}\n\nvoid setup() {\n    pinMode(13, OUTPUT);\n\n    // Configura Timer1 para CTC mode\n    TCCR1A = 0;\n    TCCR1B = 0;\n    TCCR1B |= (1 &lt;&lt; WGM12);\n\n    // Define valor de compara\u00e7\u00e3o para 1Hz\n    OCR1A = 15624;\n    TCCR1B |= (1 &lt;&lt; CS12) | (1 &lt;&lt; CS10); // Prescaler = 1024\n    TIMSK1 |= (1 &lt;&lt; OCIE1A); // Habilita interrup\u00e7\u00e3o\n\n    sei(); // Habilita interrup\u00e7\u00f5es globais\n}\n\nvoid loop() {\n    if(toggle) {\n        digitalWrite(13, HIGH);\n    } else {\n        digitalWrite(13, LOW);\n    }\n}\n</code></pre> <p>Explica\u00e7\u00e3o:</p> <ul> <li>ISR <code>TIMER1_COMPA_vect</code>: Alterna o estado da vari\u00e1vel <code>toggle</code> a cada segundo.</li> <li>Loop Principal: Liga ou desliga o LED conectado ao pino 13 com base no estado de <code>toggle</code>.</li> </ul>"},{"location":"aulas/iot/modulos/modulo9.html#5-exercicios-praticos","title":"5. Exerc\u00edcios Pr\u00e1ticos","text":""},{"location":"aulas/iot/modulos/modulo9.html#exercicio-1-contador-de-pulsos-com-interrupcao","title":"Exerc\u00edcio 1: Contador de Pulsos com Interrup\u00e7\u00e3o","text":"<ul> <li> <p>Tarefa: Crie um programa que conta o n\u00famero de pulsos recebidos em um pino espec\u00edfico usando interrup\u00e7\u00f5es e exibe o contador no Monitor Serial a cada segundo.</p> </li> <li> <p>Dicas:</p> </li> <li>Use Timer1 para criar uma interrup\u00e7\u00e3o a cada segundo.</li> <li> <p>Use uma ISR externa para contar os pulsos.</p> </li> <li> <p>Exemplo de C\u00f3digo:</p> </li> </ul> <pre><code>volatile unsigned int contadorPulsos = 0;\nvolatile bool atualizarDisplay = false;\n\n// ISR para contar pulsos no pino 2\nvoid pulseISR() {\n    contadorPulsos++;\n}\n\n// ISR para Timer1 a cada segundo\nISR(TIMER1_COMPA_vect) {\n    atualizarDisplay = true;\n}\n\nvoid setup() {\n    Serial.begin(9600);\n    pinMode(2, INPUT_PULLUP); // Pino de entrada para pulsos\n    attachInterrupt(digitalPinToInterrupt(2), pulseISR, RISING);\n\n    // Configura Timer1 para CTC mode\n    TCCR1A = 0;\n    TCCR1B = 0;\n    TCCR1B |= (1 &lt;&lt; WGM12);\n\n    OCR1A = 15624; // Para 1 segundo\n    TCCR1B |= (1 &lt;&lt; CS12) | (1 &lt;&lt; CS10); // Prescaler = 1024\n    TIMSK1 |= (1 &lt;&lt; OCIE1A); // Habilita interrup\u00e7\u00e3o por compara\u00e7\u00e3o\n\n    sei(); // Habilita interrup\u00e7\u00f5es globais\n}\n\nvoid loop() {\n    if(atualizarDisplay) {\n        Serial.print(\"Pulsos por segundo: \");\n        Serial.println(contadorPulsos);\n        contadorPulsos = 0;\n        atualizarDisplay = false;\n    }\n}\n</code></pre>"},{"location":"aulas/iot/modulos/modulo9.html#exercicio-2-pwm-controlado-por-timer","title":"Exerc\u00edcio 2: PWM Controlado por Timer","text":"<ul> <li> <p>Tarefa: Desenvolva um programa que ajusta a intensidade de um LED usando PWM controlado por Timer1, permitindo aumentar e diminuir o brilho a cada 500ms.</p> </li> <li> <p>Dicas:</p> </li> <li>Configure Timer1 para gerar PWM em um pino espec\u00edfico.</li> <li> <p>Use uma ISR para alterar o ciclo de trabalho periodicamente.</p> </li> <li> <p>Exemplo de C\u00f3digo:</p> </li> </ul> <pre><code>volatile int cicloTrabalho = 128; // Valor inicial (50%)\n\nISR(TIMER1_COMPA_vect) {\n    cicloTrabalho += 32;\n    if(cicloTrabalho &gt; 255) {\n        cicloTrabalho = 0;\n    }\n    OCR1A = cicloTrabalho;\n}\n\nvoid setup() {\n    pinMode(9, OUTPUT); // LED conectado ao pino 9\n\n    // Configura Timer1 para Fast PWM mode\n    TCCR1A |= (1 &lt;&lt; COM1A1) | (1 &lt;&lt; WGM11);\n    TCCR1B |= (1 &lt;&lt; WGM13) | (1 &lt;&lt; WGM12) | (1 &lt;&lt; CS12); // Prescaler = 256\n    ICR1 = 4999; // Define per\u00edodo para 500ms (supondo 16MHz)\n\n    OCR1A = cicloTrabalho; // Define ciclo de trabalho inicial\n\n    // Configura interrup\u00e7\u00e3o para alterar ciclo de trabalho\n    TIMSK1 |= (1 &lt;&lt; OCIE1A);\n    sei(); // Habilita interrup\u00e7\u00f5es globais\n}\n\nvoid loop() {\n    // N\u00e3o h\u00e1 c\u00f3digo no loop\n}\n</code></pre> <p>Explica\u00e7\u00e3o:</p> <ul> <li>ISR <code>TIMER1_COMPA_vect</code>: Incrementa o ciclo de trabalho do PWM a cada 500ms, alterando o brilho do LED.</li> <li>PWM no Pino 9: Controla a intensidade do LED usando PWM gerado pelo Timer1.</li> </ul>"},{"location":"aulas/iot/modulos/modulo9.html#exercicio-3-debounce-de-botao-com-interrupcao","title":"Exerc\u00edcio 3: Debounce de Bot\u00e3o com Interrup\u00e7\u00e3o","text":"<ul> <li> <p>Tarefa: Implemente um sistema que detecta pressionamentos de bot\u00e3o usando interrup\u00e7\u00f5es, com debounce para evitar m\u00faltiplas detec\u00e7\u00f5es indesejadas.</p> </li> <li> <p>Dicas:</p> </li> <li>Use uma vari\u00e1vel para armazenar o \u00faltimo tempo de interrup\u00e7\u00e3o.</li> <li> <p>Ignore interrup\u00e7\u00f5es que ocorram muito pr\u00f3ximas umas das outras.</p> </li> <li> <p>Exemplo de C\u00f3digo:</p> </li> </ul> <pre><code>volatile bool botaoPressionado = false;\nunsigned long ultimoTempo = 0;\nconst unsigned long debounceDelay = 200; // 200ms\n\nvoid botaoISR() {\n    unsigned long tempoAtual = millis();\n    if (tempoAtual - ultimoTempo &gt; debounceDelay) {\n        botaoPressionado = true;\n        ultimoTempo = tempoAtual;\n    }\n}\n\nvoid setup() {\n    Serial.begin(9600);\n    pinMode(2, INPUT_PULLUP); // Bot\u00e3o conectado ao pino 2\n    attachInterrupt(digitalPinToInterrupt(2), botaoISR, FALLING);\n}\n\nvoid loop() {\n    if(botaoPressionado) {\n        Serial.println(\"Bot\u00e3o pressionado!\");\n        botaoPressionado = false;\n    }\n}\n</code></pre> <p>Explica\u00e7\u00e3o:</p> <ul> <li>Debounce: Garante que apenas press\u00f5es de bot\u00e3o com intervalo maior que <code>debounceDelay</code> sejam consideradas v\u00e1lidas.</li> <li>ISR <code>botaoISR</code>: Marca que o bot\u00e3o foi pressionado se o debounce permitir.</li> </ul>"},{"location":"aulas/iot/modulos/modulo9.html#6-conceitos-importantes","title":"6. Conceitos Importantes","text":""},{"location":"aulas/iot/modulos/modulo9.html#61-isr-interrupt-service-routine","title":"6.1 ISR (Interrupt Service Routine)","text":"<ul> <li>Defini\u00e7\u00e3o: Fun\u00e7\u00f5es que s\u00e3o chamadas automaticamente em resposta a interrup\u00e7\u00f5es.</li> <li>Caracter\u00edsticas:</li> <li>N\u00e3o podem retornar valores.</li> <li>Devem ser r\u00e1pidas e eficientes.</li> <li>Devem evitar o uso de fun\u00e7\u00f5es que dependem de interrup\u00e7\u00f5es, como <code>Serial.print()</code>.</li> </ul>"},{"location":"aulas/iot/modulos/modulo9.html#62-aritmetica-de-ponteiros-e-timers","title":"6.2 Aritm\u00e9tica de Ponteiros e Timers","text":"<ul> <li>Aritm\u00e9tica de Ponteiros: Permite navegar por arrays e estruturas de dados de forma eficiente.</li> <li>Timers: Facilitam a cria\u00e7\u00e3o de temporiza\u00e7\u00f5es precisas e a gera\u00e7\u00e3o de sinais PWM.</li> </ul>"},{"location":"aulas/iot/modulos/modulo9.html#63-gerenciamento-de-tempo","title":"6.3 Gerenciamento de Tempo","text":"<ul> <li>Uso de Timers e <code>millis()</code>: Evita o bloqueio do loop principal, permitindo a execu\u00e7\u00e3o de m\u00faltiplas tarefas simultaneamente.</li> <li>Compara\u00e7\u00e3o com <code>delay()</code>: <code>delay()</code> bloqueia a execu\u00e7\u00e3o, enquanto timers e interrup\u00e7\u00f5es permitem um controle mais granular e eficiente.</li> </ul>"},{"location":"aulas/iot/modulos/modulo9.html#64-boas-praticas-com-interrupcoes-e-timers","title":"6.4 Boas Pr\u00e1ticas com Interrup\u00e7\u00f5es e Timers","text":"<ul> <li>Minimize o C\u00f3digo nas ISRs: Execute apenas o essencial dentro das ISRs para evitar atrasos no processamento.</li> <li>Evite Vari\u00e1veis Complexas: Use vari\u00e1veis simples e do tipo <code>volatile</code> para comunica\u00e7\u00e3o entre ISRs e o loop principal.</li> <li>Gerencie a Mem\u00f3ria dos Timers: Configure corretamente os timers para evitar conflitos e sobrecargas.</li> </ul>"},{"location":"aulas/iot/modulos/modulo9.html#7-recursos-adicionais","title":"7. Recursos Adicionais","text":"<ul> <li> <p>Documenta\u00e7\u00e3o Oficial do Arduino:</p> </li> <li> <p>Interrup\u00e7\u00f5es</p> </li> <li> <p>Timers</p> </li> <li> <p>Tutoriais e Guias:</p> </li> <li> <p>Guia Completo de Interrup\u00e7\u00f5es no Arduino</p> </li> <li> <p>Manipula\u00e7\u00e3o Avan\u00e7ada de Timers</p> </li> <li> <p>V\u00eddeos Educacionais:</p> </li> <li> <p>Entendendo Interrup\u00e7\u00f5es no Arduino</p> </li> <li>Timers e PWM Avan\u00e7ados</li> </ul>"},{"location":"aulas/iot/modulos/modulo9.html#8-exercicios-praticos","title":"8. Exerc\u00edcios Pr\u00e1ticos","text":""},{"location":"aulas/iot/modulos/modulo9.html#exercicio-1-led-pisca-com-timer-e-interrupcao","title":"Exerc\u00edcio 1: LED Pisca com Timer e Interrup\u00e7\u00e3o","text":"<ul> <li> <p>Tarefa: Crie um programa que faz um LED piscar a cada 250ms usando Timer1 e uma interrup\u00e7\u00e3o.</p> </li> <li> <p>Dicas:</p> </li> <li>Configure Timer1 para gerar interrup\u00e7\u00f5es a cada 250ms.</li> <li> <p>Use uma ISR para alternar o estado do LED.</p> </li> <li> <p>Exemplo de C\u00f3digo:</p> </li> </ul> <pre><code>volatile bool ledEstado = false;\n\nISR(TIMER1_COMPA_vect) {\n    ledEstado = !ledEstado;\n}\n\nvoid setup() {\n    pinMode(13, OUTPUT);\n    // Configura Timer1 para CTC mode\n    TCCR1A = 0;\n    TCCR1B = 0;\n    TCCR1B |= (1 &lt;&lt; WGM12);\n\n    OCR1A = 3906; // Para 250ms (16MHz / (Prescaler * Desired Frequency)) - 1\n    TCCR1B |= (1 &lt;&lt; CS12) | (1 &lt;&lt; CS10); // Prescaler = 1024\n    TIMSK1 |= (1 &lt;&lt; OCIE1A); // Habilita interrup\u00e7\u00e3o por compara\u00e7\u00e3o\n\n    sei(); // Habilita interrup\u00e7\u00f5es globais\n}\n\nvoid loop() {\n    digitalWrite(13, ledEstado ? HIGH : LOW);\n}\n</code></pre>"},{"location":"aulas/iot/modulos/modulo9.html#exercicio-2-leitura-de-sensor-com-interrupcao","title":"Exerc\u00edcio 2: Leitura de Sensor com Interrup\u00e7\u00e3o","text":"<ul> <li> <p>Tarefa: Desenvolva um programa que l\u00ea um valor de sensor sempre que um bot\u00e3o \u00e9 pressionado, usando interrup\u00e7\u00f5es para detectar o pressionamento.</p> </li> <li> <p>Dicas:</p> </li> <li>Use uma ISR externa para detectar o bot\u00e3o.</li> <li> <p>Armazene o valor do sensor em uma vari\u00e1vel <code>volatile</code>.</p> </li> <li> <p>Exemplo de C\u00f3digo:</p> </li> </ul> <pre><code>volatile bool lerSensor = false;\nvolatile int valorSensor = 0;\n\nvoid botaoISR() {\n    lerSensor = true;\n}\n\nvoid setup() {\n    Serial.begin(9600);\n    pinMode(2, INPUT_PULLUP); // Bot\u00e3o conectado ao pino 2\n    attachInterrupt(digitalPinToInterrupt(2), botaoISR, FALLING);\n}\n\nvoid loop() {\n    if(lerSensor) {\n        valorSensor = analogRead(A0);\n        Serial.print(\"Valor do Sensor: \");\n        Serial.println(valorSensor);\n        lerSensor = false;\n    }\n}\n</code></pre>"},{"location":"aulas/iot/modulos/modulo9.html#exercicio-3-controlar-servo-com-timer-e-interrupcao","title":"Exerc\u00edcio 3: Controlar Servo com Timer e Interrup\u00e7\u00e3o","text":"<ul> <li> <p>Tarefa: Implemente um sistema que controla a posi\u00e7\u00e3o de um servo motor utilizando Timer1 e interrup\u00e7\u00f5es para ajustar a posi\u00e7\u00e3o a cada 500ms.</p> </li> <li> <p>Dicas:</p> </li> <li>Use uma ISR para alterar o \u00e2ngulo do servo.</li> <li> <p>Utilize a biblioteca <code>Servo</code> para facilitar o controle do servo.</p> </li> <li> <p>Exemplo de C\u00f3digo:</p> </li> </ul> <pre><code>#include &lt;Servo.h&gt;\n\nServo meuServo;\nvolatile int angulo = 0;\n\nISR(TIMER1_COMPA_vect) {\n    angulo += 10;\n    if(angulo &gt; 180) {\n        angulo = 0;\n    }\n    meuServo.write(angulo);\n}\n\nvoid setup() {\n    meuServo.attach(9); // Servo conectado ao pino 9\n    meuServo.write(angulo);\n\n    // Configura Timer1 para CTC mode\n    TCCR1A = 0;\n    TCCR1B = 0;\n    TCCR1B |= (1 &lt;&lt; WGM12);\n\n    OCR1A = 15624; // Para 1 segundo\n    TCCR1B |= (1 &lt;&lt; CS12) | (1 &lt;&lt; CS10); // Prescaler = 1024\n    TIMSK1 |= (1 &lt;&lt; OCIE1A); // Habilita interrup\u00e7\u00e3o por compara\u00e7\u00e3o\n\n    sei(); // Habilita interrup\u00e7\u00f5es globais\n}\n\nvoid loop() {\n    // N\u00e3o h\u00e1 c\u00f3digo no loop\n}\n</code></pre>"},{"location":"aulas/iot/modulos/modulo9.html#9-conceitos-importantes","title":"9. Conceitos Importantes","text":""},{"location":"aulas/iot/modulos/modulo9.html#91-variaveis-volateis","title":"9.1 Vari\u00e1veis Vol\u00e1teis","text":"<ul> <li>Defini\u00e7\u00e3o: Vari\u00e1veis declaradas como <code>volatile</code> informam ao compilador que seu valor pode mudar a qualquer momento, prevenindo otimiza\u00e7\u00f5es que poderiam ignorar atualiza\u00e7\u00f5es provenientes de ISRs.</li> </ul> <pre><code>volatile int contador = 0;\n</code></pre>"},{"location":"aulas/iot/modulos/modulo9.html#92-prioridade-de-interrupcoes","title":"9.2 Prioridade de Interrup\u00e7\u00f5es","text":"<ul> <li>Defini\u00e7\u00e3o: Em sistemas com m\u00faltiplas interrup\u00e7\u00f5es, a prioridade determina qual ISR ser\u00e1 executada primeiro.</li> <li>Considera\u00e7\u00f5es:</li> <li>No Arduino, todas as interrup\u00e7\u00f5es t\u00eam a mesma prioridade.</li> <li>Planeje o uso de interrup\u00e7\u00f5es de forma que n\u00e3o haja conflito entre diferentes ISRs.</li> </ul>"},{"location":"aulas/iot/modulos/modulo9.html#93-uso-de-funcoes-nas-isrs","title":"9.3 Uso de Fun\u00e7\u00f5es nas ISRs","text":"<ul> <li>Limita\u00e7\u00f5es: Evite usar fun\u00e7\u00f5es que n\u00e3o sejam seguras para serem chamadas dentro de uma ISR, como <code>Serial.print()</code>.</li> <li>Alternativas: Utilize flags (<code>bool</code>) para indicar ao loop principal que uma a\u00e7\u00e3o deve ser executada.</li> </ul>"},{"location":"aulas/iot/modulos/modulo9.html#94-configuracao-correta-dos-timers","title":"9.4 Configura\u00e7\u00e3o Correta dos Timers","text":"<ul> <li>Import\u00e2ncia: Configura\u00e7\u00f5es incorretas dos timers podem levar a temporiza\u00e7\u00f5es erradas ou ao n\u00e3o funcionamento das interrup\u00e7\u00f5es.</li> <li>Verifique:</li> <li>Modo de opera\u00e7\u00e3o (CTC, Fast PWM, etc.).</li> <li>Prescaler adequado para a temporiza\u00e7\u00e3o desejada.</li> <li>Valores de compara\u00e7\u00e3o (<code>OCRnA</code>).</li> </ul>"},{"location":"aulas/iot/modulos/modulo9.html#95-boas-praticas-com-interrupcoes-e-timers","title":"9.5 Boas Pr\u00e1ticas com Interrup\u00e7\u00f5es e Timers","text":"<ul> <li>Evite Loops Longos nas ISRs: Mantenha as ISRs curtas e r\u00e1pidas.</li> <li>Use Vari\u00e1veis Vol\u00e1teis para Comunica\u00e7\u00e3o: Utilize vari\u00e1veis <code>volatile</code> para comunicar eventos entre ISRs e o loop principal.</li> <li>Gerencie a Prioridade e Frequ\u00eancia de Interrup\u00e7\u00f5es: Planeje a frequ\u00eancia de interrup\u00e7\u00f5es para evitar sobrecarga no processador.</li> </ul>"},{"location":"aulas/iot/modulos/modulo9.html#10-recursos-adicionais","title":"10. Recursos Adicionais","text":"<ul> <li> <p>Documenta\u00e7\u00e3o Oficial do Arduino:</p> </li> <li> <p>Interrup\u00e7\u00f5es</p> </li> <li> <p>Timers</p> </li> <li> <p>Tutoriais e Guias:</p> </li> <li> <p>Guia Completo de Interrup\u00e7\u00f5es no Arduino</p> </li> <li> <p>Manipula\u00e7\u00e3o Avan\u00e7ada de Timers</p> </li> <li> <p>V\u00eddeos Educacionais:</p> </li> <li> <p>Entendendo Interrup\u00e7\u00f5es no Arduino</p> </li> <li>Timers e PWM Avan\u00e7ados</li> </ul>"},{"location":"aulas/iot/modulos/modulo9.html#11-conclusao-do-modulo","title":"11. Conclus\u00e3o do M\u00f3dulo","text":"<p>Neste m\u00f3dulo, voc\u00ea aprendeu:</p> <ul> <li>O que s\u00e3o interrup\u00e7\u00f5es e timers e sua import\u00e2ncia na programa\u00e7\u00e3o Arduino.</li> <li>Como configurar e utilizar interrup\u00e7\u00f5es externas para reagir a eventos ass\u00edncronos.</li> <li>Como configurar e utilizar timers para criar temporiza\u00e7\u00f5es precisas e gerar sinais PWM.</li> <li>Boas pr\u00e1ticas para implementar ISRs eficientes e seguras.</li> <li>Como integrar interrup\u00e7\u00f5es e timers em projetos reais para melhorar a responsividade e efici\u00eancia.</li> <li>Praticou com exemplos e exerc\u00edcios que refor\u00e7am o entendimento das interrup\u00e7\u00f5es e timers.</li> </ul> <p>Voc\u00ea est\u00e1 agora preparado para avan\u00e7ar para o pr\u00f3ximo m\u00f3dulo, onde exploraremos Comunica\u00e7\u00e3o Serial Avan\u00e7ada, aprofundando seu conhecimento em protocolos de comunica\u00e7\u00e3o e troca de dados entre dispositivos Arduino e computadores.</p>"},{"location":"aulas/iot/modulos/modulo9.html#12-proximos-passos","title":"12. Pr\u00f3ximos Passos","text":"<ul> <li>Revisar o conte\u00fado deste m\u00f3dulo e certificar-se de que compreendeu os conceitos apresentados.</li> <li>Completar os exerc\u00edcios propostos para consolidar o aprendizado.</li> <li>Preparar-se para o M\u00f3dulo 10: Comunica\u00e7\u00e3o Serial Avan\u00e7ada.</li> </ul> <p>Se tiver d\u00favidas ou precisar de assist\u00eancia, n\u00e3o hesite em procurar recursos adicionais ou participar de comunidades de aprendizagem para obter suporte.</p> <p>Bom trabalho e continue assim!</p>"},{"location":"aulas/iot/modulos/modulos.html","title":"Modulos","text":""},{"location":"aulas/iot/modulos/modulos.html#programacao-em-arduino-conceitos-fundamentais","title":"Programa\u00e7\u00e3o em Arduino - Conceitos Fundamentais","text":"<p>Este curso b\u00e1sico de Programa\u00e7\u00e3o em Arduino focado nos conceitos da programa\u00e7\u00e3o C/C++.</p> <p>N\u00e3o \u00e9 necess\u00e1rio placa Arduino, utilize o simulador www.wokwi.com para realizar exercicios dos m\u00f3dulos.</p> <p>O curso est\u00e1 dividido em m\u00f3dulos que apresentam conceitos da linguagem C/C++ e sua aplica\u00e7\u00e3o na programa\u00e7\u00e3o Arduino.</p>"},{"location":"aulas/iot/modulos/modulos.html#sumario-do-curso","title":"Sum\u00e1rio do Curso","text":"<ul> <li>M\u00f3dulo 1: Introdu\u00e7\u00e3o ao Arduino</li> <li>M\u00f3dulo 2: Operadores e Express\u00f5es</li> <li>M\u00f3dulo 3: Estruturas de Controle de Fluxo</li> <li>M\u00f3dulo 4: Fun\u00e7\u00f5es e Modulariza\u00e7\u00e3o</li> <li>M\u00f3dulo 5: Arrays e Manipula\u00e7\u00e3o de Dados</li> <li>M\u00f3dulo 6: Strings e Opera\u00e7\u00f5es com Texto</li> <li>M\u00f3dulo 7: Ponteiros e Refer\u00eancias</li> <li>M\u00f3dulo 8: Estruturas (Structs) e Classes</li> </ul>"},{"location":"checkpoint/index.html","title":"CHECKPOINTS","text":""},{"location":"checkpoint/index.html#atencao","title":"Aten\u00e7\u00e3o","text":"<ul> <li> <p>Cuidado com a desonestidade intelectual;</p> </li> <li> <p>AUTO AVALIA\u00c7\u00c3O: Uma auto avalia\u00e7\u00e3o n\u00e3o compat\u00edvel com o material entregue ser\u00e1 interpretada como desonestidade intelectual;</p> </li> <li> <p>PL\u00c1GIO: Atividades que envolvem pesquisas na Internet podem ser enriquecidas com cita\u00e7\u00f5es de v\u00e1rias fontes. No entanto, sempre que utilizar textos ou mesmo imagens que n\u00e3o sejam seus, seu trabalho deve ser acompanhado com um trecho de \u201crefer\u00eancias\u201d. Bastam os hiperlinks utilizados;</p> </li> <li> <p>COLA DE TRABALHOS: N\u00e3o \u00e9 permitida a troca de trabalhos entre os grupos, cada grupo \u00e9 respons\u00e1vel pelo desenvolvimento intelectual do projeto. N\u00e3o copie e entregue o trabalho de outro colega e n\u00e3o permita ser copiado. Atividades duplicadas resultar\u00e3o na anula\u00e7\u00e3o de ambas.</p> </li> </ul>"},{"location":"checkpoint/index.html#como-funcionam-os-checkpoints","title":"COMO FUNCIONAM OS CHECKPOINTS","text":"<p>Leia com aten\u00e7\u00e3o as orienta\u00e7\u00f5es gerais sobre os checkponts</p>"},{"location":"checkpoint/index.html#o-que-e","title":"O que \u00e9:","text":"<p>Os Checkpoints da disciplina s\u00e3o baseados em pequenos projetos com o objetivo de avaliar os conceitos adquiridos dos conte\u00fados ministrados em aula. </p>"},{"location":"checkpoint/index.html#quando-sera","title":"Quando ser\u00e1:","text":"<p>Os checkpoints s\u00e3o sempre divulgados/publicados com anteced\u00eancia (ver agenda das aulas) nesta p\u00e1gina e devem ser realizadas fora do hor\u00e1rio de aula.</p>"},{"location":"checkpoint/index.html#onde-sera","title":"Onde ser\u00e1:","text":"<p>O projeto ser\u00e1 feito no github classroom. O estudante ir\u00e1 receber um link para um reposit\u00f3rio privado no github, \u00e9 neste reposit\u00f3rio que o estudante dever\u00e1 fazer os commits com o desenvolvimento do projeto. </p>"},{"location":"checkpoint/index.html#como-desenvolver-o-projeto","title":"Como desenvolver o projeto:","text":"<p>Existe uma rubrica de nota definida pelo professor e publicada junto com o desafio que o estudante deve seguir. Esta rubrica foi pensada para guiar o desenvolvimento do estudante.</p>"},{"location":"checkpoint/index.html#hora-de-entregar-checkpoint","title":"Hora de entregar checkpoint:","text":"<p>O checkpoint n\u00e3o \u00e9 realizado em sala de aula.</p> <p>O estudante deve realizar a entrega ANTES da data definida para avalia\u00e7\u00e3o do checkpoint.</p> <p>No momento da entrega, o estudante ir\u00e1 responder um question\u00e1rio (google forms) de auto-avalia\u00e7\u00e3o destacando o que foi implementado.</p>"},{"location":"checkpoint/index.html#como-sera-avaliado","title":"Como ser\u00e1 avaliado:","text":"<p>A avalia\u00e7\u00e3o do checkpoint ser\u00e1 feita em sala de aula na data definida na agenda e de forma individual (professor e 1 estudante por vez) onde cada estudante dever\u00e1 demonstrar a evolu\u00e7\u00e3o do seu projeto do github, o question\u00e1rio de auto-avalia\u00e7\u00e3o respondido pelo aluno ser\u00e1 utilizado pelo professor.</p>"},{"location":"checkpoint/index.html#o-que-devo-fazer-agora","title":"O que devo fazer agora??","text":"<p>Aguarde a libera\u00e7\u00e3o do CHECKPOINT...</p>"},{"location":"checkpoint/cp-ml.html","title":"Cp ml","text":"<p>CheckPonint - Estudo de Caso</p>"},{"location":"checkpoint/cp-ml.html#desafio-4-si","title":"Desafio 4 SI","text":"<p>Desenvolver uma solu\u00e7\u00e3o ao desafio proposto.  </p> <ul> <li>Material dispon\u00edvel pelo TEAMS nos arquivo <code>solicitacoescredito.csv</code>. e <code>CP-4SI-24.pdf</code> </li> </ul>"},{"location":"checkpoint/cp-ml.html#dinamicas-das-proximas-aulas","title":"Din\u00e2micas das pr\u00f3ximas aulas","text":"<ul> <li>Aula:<ul> <li>Teoria: Abordando os conceitos </li> <li>Pr\u00e1tica: Exerc\u00edcios de fixa\u00e7\u00e3o</li> <li>Estudio: Est\u00fadio para desenvolvimento do projeto.</li> </ul> </li> </ul>"},{"location":"checkpoint/cp-ml.html#feedback","title":"Feedback","text":"<p>Os grupos que quiserem podem solicitar feedback de acompanhamento do projeto.</p>"},{"location":"checkpoint/cp-ml.html#composicao-da-nota-final","title":"Composi\u00e7\u00e3o da nota final","text":"Data Crit\u00e9rio Nota Aprsenta\u00e7\u00e3o Apresenta\u00e7\u00e3o (at\u00e9 2 pontos) e argui\u00e7\u00e3o (individual at\u00e9 3 pontos) 0 - 5 pontos Aprsenta\u00e7\u00e3o Avalia\u00e7\u00e3o da Documenta\u00e7\u00e3o t\u00e9cnica do projeto  (Qualidade t\u00e9cnica de c\u00f3digo e organiza\u00e7\u00e3o do reposit\u00f3rio github) 0 - 5 pontos <ul> <li>A nota \u00e9 composta de <code>Apresenta\u00e7\u00e3o e argui\u00e7\u00e3o do projeto</code> + <code>valida\u00e7\u00e3o da Documenta\u00e7\u00e3o t\u00e9cnica do projeto</code>.</li> </ul>"},{"location":"checkpoint/cp.html","title":"CHECKPOINT 5","text":"<ul> <li>O objetivo do checkpoint \u00e9 avaliar a compreens\u00e3o dos estudantes em rela\u00e7\u00e3o ao conte\u00fado ministrado pela disciplina.</li> </ul> <p>Obrigat\u00f3rio utilizar como base o c\u00f3digo de exemplo do jogo da mem\u00f3ria dispon\u00edvel:</p> <ul> <li>C\u00f3digo base Jogo da Mem\u00f3ria</li> <li>Wokwi Jogo da Mem\u00f3ria</li> </ul> <p>Materiais Necess\u00e1rios:</p> <ul> <li>\u25b6\ufe0f Arduino UNO</li> <li>\u25b6\ufe0f LEDs</li> <li>\u25b6\ufe0f Bot\u00f5es</li> <li>\u25b6\ufe0f Buzzer</li> <li>\u25b6\ufe0f Resistores, jumpers e protoboard</li> </ul>"},{"location":"checkpoint/cp.html#ideia-geral","title":"Ideia Geral","text":"<p>Neste checkpoint, o desafio \u00e9 desenvolver o prot\u00f3tipo do jogo da mem\u00f3ria \"Genius\" com Arduino, com as seguintes caracter\u00edsticas:</p> <ul> <li>4 (ou mais) LEDs de cores diferentes</li> <li>4 (ou mais) Bot\u00f5es</li> <li>1 Buzzer</li> <li>Possuir Interface de comunica\u00e7\u00e3o serial</li> </ul> <p>Vamos explorar mais detalhadamente o funcionamento do prot\u00f3tipo e os crit\u00e9rios de avalia\u00e7\u00e3o.</p>"},{"location":"checkpoint/cp.html#genius-arduino","title":"Genius Arduino","text":"<p>O jogo tem a din\u00e2mica padr\u00e3o de qualquer outro jogo da mem\u00f3ria: Inicia-se o game, os LEDs piscam em sequ\u00eancia aleat\u00f3ria, e o jogador precisa reproduzir essa sequ\u00eancia pressionando os bot\u00f5es correspondentes. Acertando, avan\u00e7a para o pr\u00f3ximo n\u00edvel; errando, \u00e9 o fim do jogo.</p>"},{"location":"checkpoint/cp.html#atencao-aos-requisitos-funcionais","title":"Aten\u00e7\u00e3o aos requisitos funcionais","text":"<p>Requisitos Funcionais B\u00e1sicos:</p> <ul> <li>LEDs: O jogo deve possuir 4 LEDs de cores diferentes.</li> <li>Bot\u00f5es: O jogo deve possuir 4 bot\u00f5es, cada bot\u00e3o corresponde a um LED.</li> <li> <p>Buzzer: O jogo deve possuir 1 Buzzer que deve emitir uma frequ\u00eancia espec\u00edfica (nota musical) para cada cor de LED, tanto na sequ\u00eancia aleat\u00f3ria quanto ao pressionar das teclas.</p> </li> <li> <p>FASES DO JOGO: O jogo deve possuir 4 fases.</p> </li> <li>Monitor Serial: O jogo deve possuir permitir ao usu\u00e1rio jogar tanto pelos bot\u00f5es f\u00edsicos quanto pelo monitor serial do Arduino.</li> </ul> <p>Requisitos Funcionais Avan\u00e7ados:</p> <ul> <li>FASES DO JOGO: O jogo deve possuir uma quantidade \"infinita\" de niveis de dificuldade.</li> <li>Nivel de dificuldade Crie a fun\u00e7\u00e3o <code>nivelDificuldade</code> que implementa a sele\u00e7\u00e3o de dificuldade do jogo em iniciante, m\u00e9dio e hard. Essa fun\u00e7\u00e3o altera a velocidade com que os leds piscam.</li> <li>Salvar Pontua\u00e7\u00f5es Usar uma mem\u00f3ria EEPROM no Arduino para salvar as pontua\u00e7\u00f5es mais altas, permitindo que os jogadores vejam e tentem superar seus recordes anteriores.</li> <li>Comunica\u00e7\u00e3o Bluetooth: Fa\u00e7a a comunica\u00e7\u00e3o via bluetooth com o notebook ou celular para jogar o jogo.</li> <li>Interface persolnalizada O jogo possui uma interface GUI personalizada que substitui o monitor serial da IDE do Arduino. Pode usar bibliotecas em Python (Tkinter, Streamlit, Flet) ou desenvolver em outra linguagem (C++, C#, Dart, Java, etc.).</li> <li>Comando de Voz: Atrav\u00e9s de um script em Python, ao receber a informa\u00e7\u00e3o da cor, o computador anuncia em voz alta a cor acionada.</li> <li>Vis\u00e3o Computacional: Atrav\u00e9s de um script em Python, utiliza o opencv para jogar com a webcam.</li> <li>Modo Multiplayer Implementar um modo de jogo para dois ou mais jogadores, onde eles se revezam e competem por pontua\u00e7\u00f5es mais altas.</li> <li>Feedback Sonoro Avan\u00e7ado Implementar melodias ou sons mais complexos para feedback ao jogador.</li> <li>OUTRAS FEATURES: O grupo pode propor outras features avan\u00e7adas, mas deve ser aprovado pelo professor.</li> </ul> <p>"},{"location":"checkpoint/cp.html#construindo-uma-caixa-personalizada","title":"Construindo uma Caixa Personalizada:","text":"<ul> <li>Caixa: Utilize o site https://www.festi.info/boxes.py/ para criar uma caixa personalizada para o seu prot\u00f3tipo, de forma simples, online e gratuita.</li> </ul> <p>Links \u00fateis para criar seu case:</p> <ul> <li>Manual do Mundo</li> <li>Angelo Conti</li> <li>Maker Space 307</li> <li>Smoke &amp; Mirrors</li> </ul> <ul> <li>Especifica\u00e7\u00f5es para M\u00e1quina CNC: Selecione a espessura de 3mm para o MDF.</li> </ul> <p></p>"},{"location":"checkpoint/cp.html#rubrica","title":"Rubrica:","text":"Nota Itens 4 Atende aos requisitos funcionais b\u00e1sicos 6 Atende aos requisitos funcionais b\u00e1sicos + caixa personalizada + implementa 1 requisito funcional avan\u00e7ado 7 Atende aos requisitos funcionais b\u00e1sicos  + caixa personalizada + implementa 2 requisitos funcionais avan\u00e7ados 8 Atende aos requisitos funcionais b\u00e1sicos  + caixa personalizada + implementa 3 requisitos funcionais avan\u00e7ados 9 Atende aos requisitos funcionais b\u00e1sicos  + caixa personalizada + implementa 4 requisitos funcionais avan\u00e7ados 10 Atende aos requisitos funcionais b\u00e1sicos + implementa 5 ou mais requisitos funcionais avan\u00e7ados"},{"location":"checkpoint/cp1.html","title":"Cp1","text":""},{"location":"checkpoint/cp1.html#checkpoint-1","title":"CHECKPOINT 1","text":"<ul> <li>Leia com aten\u00e7\u00e3o as instru\u00e7\u00f5es gerais sobre checkpoint;</li> <li>clique aqui no link para criar uma c\u00f3pia do reposit\u00f3rio do CP em seu github;</li> <li>Leia com aten\u00e7\u00e3o as intru\u00e7\u00f5es do CP e desenvolva o projeto;</li> <li>O estudante deve realizar a entrega ANTES da data definida para avalia\u00e7\u00e3o do checkpoint;</li> <li>O CP pode ser feito em at\u00e9 3 estudantes. O primeiro estudante cria o grupo (atrav\u00e9s do link do Classroom) e os demais estudante acessam o grupo criado.</li> </ul> CP1 link Reposit\u00f3rio https://classroom.github.com/a/4x4sqhyD"},{"location":"checkpoint/cp2.html","title":"Cp2","text":""},{"location":"checkpoint/cp2.html#desafio-de-visao-computacional","title":"Desafio de Vis\u00e3o Computacional","text":"<p>Mini Projeto de Vis\u00e3o Computacional aplicado.</p>"},{"location":"checkpoint/cp2.html#atualizacao-da-data-de-apresentacao","title":"ATUALIZA\u00c7\u00c3O DA DATA DE APRESENTA\u00c7\u00c3O","text":""},{"location":"checkpoint/cp2.html#considerar-a-data-de-apresentacao-do-projeto-dia-2305","title":"CONSIDERAR A DATA DE APRESENTA\u00c7\u00c3O DO PROJETO DIA <code>23/05</code>.","text":""},{"location":"checkpoint/cp2.html#objetivo-do-projeto","title":"Objetivo do Projeto:","text":"<p>Desenvolver uma aplica\u00e7\u00e3o pr\u00e1tica e inovadora de vis\u00e3o computacional que possa ser aplicada em v\u00eddeos em tempo real.  A aplica\u00e7\u00e3o deve abordar um problema relevante em uma das seguintes \u00e1reas: jogos, entretenimento, sa\u00fade, bem-estar, agricultura ou  seguran\u00e7a p\u00fablica.</p>"},{"location":"checkpoint/cp2.html#requisitos","title":"Requisitos:","text":"<ul> <li> <p>A solu\u00e7\u00e3o deve ser <code>original e n\u00e3o trivial</code>, demonstrando um entendimento profundo e uma aplica\u00e7\u00e3o criativa das t\u00e9cnicas de vis\u00e3o computacional.</p> </li> <li> <p>Implementa\u00e7\u00e3o em Python e seus frameworks como OpenCV, Tensorflow entre outros.</p> </li> <li> <p>Espera-se que os grupos:</p> <ul> <li>Desenvolvam uma abordagem \u00fanica para o problema escolhido, n\u00e3o pode ser c\u00f3pia direta de solu\u00e7\u00f5es existentes.</li> <li>Mostrem capacidade de integrar e adaptar conceitos de vis\u00e3o computacional para atender \u00e0s necessidades espec\u00edficas do projeto.</li> <li>Demonstrem habilidade em inovar e pensar criticamente sobre como as t\u00e9cnicas de vis\u00e3o computacional podem ser aplicadas de maneiras novas e eficazes.</li> </ul> </li> <li> <p><code>Importante</code>: N\u00e3o ser\u00e1 aceita a simples replica\u00e7\u00e3o de projetos prontos, incluindo o uso de prompts de GPT e outras intelig\u00eancias artificiais generativas sem adapta\u00e7\u00e3o significativa e contribui\u00e7\u00e3o pr\u00f3pria. </p> </li> <li> <p>A aplica\u00e7\u00e3o deve ser capaz de processar v\u00eddeos em tempo real, e/ou usando uma webcam.</p> </li> </ul>"},{"location":"checkpoint/cp2.html#criterios-de-avaliacao","title":"Crit\u00e9rios de Avalia\u00e7\u00e3o:","text":"<ul> <li>Inova\u00e7\u00e3o e criatividade na escolha e abordagem do problema.</li> <li>Efici\u00eancia e precis\u00e3o da solu\u00e7\u00e3o de vis\u00e3o computacional em tempo real.</li> <li>Qualidade t\u00e9cnica de documenta\u00e7\u00e3o e c\u00f3digo e funcionalidade do projeto.</li> <li>Apresenta\u00e7\u00e3o e comunica\u00e7\u00e3o das ideias e resultados.</li> </ul>"},{"location":"checkpoint/cp2.html#dinamicas-das-proximas-aulas","title":"Dinamicas das pr\u00f3ximas aulas:","text":"<ul> <li> <p>1a aula: Demonstra\u00e7\u00e3o de novas t\u00e9cnicas de Vis\u00e3o Computacional, baseada nos laborat\u00f3rios da disciplina.</p> <ul> <li>Os laborat\u00f3rios continuam com as entregas semanais e valer\u00e3o nota <code>B\u00f4nus</code> de participa\u00e7\u00e3o para quem fizer e entregar via atividade do Teams.</li> </ul> </li> <li> <p>2a aula: Aula est\u00fadio para desenvolvimento do projeto.</p> <ul> <li>Entregas de acompanhamento semanal com feedback do projeto, via github.</li> </ul> </li> </ul>"},{"location":"checkpoint/cp2.html#feedback-continuo","title":"Feedback Cont\u00ednuo:","text":"<p>Os grupos receber\u00e3o feedback ap\u00f3s cada atualiza\u00e7\u00e3o do GitHub por meio de issues que ser\u00e3o abertas, e que valer\u00e3o parte da nota final a cada semana,  para garantir que estejam no caminho certo e para ajudar na resolu\u00e7\u00e3o de quaisquer problemas t\u00e9cnicos ou conceituais.</p>"},{"location":"checkpoint/cp2.html#acompanhamento-semanal","title":"Acompanhamento semanal","text":"Data Atividade Nota parcial 11/04 Reposit\u00f3rio GitHub: Inclui README claro, defini\u00e7\u00e3o de projeto bem articulada, <code>rubrica de avalia\u00e7\u00e3o</code> realista e desafiadora, algum c\u00f3digo base organizado. 0 - 2 pontos 18/04 Atualiza\u00e7\u00f5es do GitHub: Progresso documentado e c\u00f3digo atualizado, mostrando implementa\u00e7\u00e3o aproximada de <code>20%</code>. 0 - 2 pontos 25/04 Atualiza\u00e7\u00f5es do GitHub: Progresso documentado e c\u00f3digo atualizado, mostrando implementa\u00e7\u00e3o aproximada de <code>50%</code>. 0 - 2 pontos 02/05 Atualiza\u00e7\u00f5es do GitHub: Progresso documentado e c\u00f3digo atualizado, mostrando implementa\u00e7\u00e3o aproximada de <code>80%</code>. 0 - 2 pontos 09/05 Atualiza\u00e7\u00f5es do GitHub: Progresso documentado e c\u00f3digo atualizado, mostrando implementa\u00e7\u00e3o aproximada de <code>100%</code>. 0 - 2 pontos"},{"location":"checkpoint/cp2.html#composicao-da-nota-final","title":"Composi\u00e7\u00e3o da nota final","text":"Data Crit\u00e9rio Nota 16/05 Apresenta\u00e7\u00e3o e argui\u00e7\u00e3o do projeto 0 - 5 pontos 16/05 Avalia\u00e7\u00e3o da Documenta\u00e7\u00e3o t\u00e9cnica do projeto 0 - 5 pontos De 11/04 at\u00e9 09/05 Acompanhamento semanal (para os grupos que participarem) 0 - 10 pontos <ul> <li> <p>CP2:</p> <ul> <li>Dia 16/05, composta de <code>Apresenta\u00e7\u00e3o e argui\u00e7\u00e3o do projeto</code> + <code>valia\u00e7\u00e3o da Documenta\u00e7\u00e3o t\u00e9cnica do projeto</code>.</li> </ul> </li> <li> <p>CP3:</p> <ul> <li>Os grupos que realizarem o acompanhamento semanal ter\u00e1 a somat\u00f3ria do <code>acompanhamento semanal</code> convertida nota de CP3.</li> <li>Os grupos que <code>n\u00e3o participarem</code> do acompanhamento semanal <code>n\u00e3o ganham nota</code> e podem fazer o CP3 dia 23/05. O <code>CP3 Ser\u00e1 uma avalia\u00e7\u00e3o individual e presencial durante o periodo da aula</code>.  </li> </ul> </li> </ul>"},{"location":"checkpoint/cp3.html","title":"CHECKPOINT 3","text":"<p>Leia com aten\u00e7\u00e3o as instru\u00e7\u00f5es gerais sobre checkpoint;</p> <p>O checkpoint3 \u00e9 a cereja do bolo antes das f\u00e9rias e ser\u00e1 sobre comunica\u00e7\u00e3o entre sistemas, no nosso caso Arduino e vis\u00e3o computacional.</p>"},{"location":"checkpoint/cp3.html#descricao-do-problema","title":"Descri\u00e7\u00e3o do problema:","text":"<p>O objetivo deste desafio \u00e9 criar um sistema que utilize vis\u00e3o computacional em Python e um Arduino para realizar diferentes tarefas de acordo com o objetivo escolhido pelo grupo.</p> <p>O grupo pode escolher entre tr\u00eas alternativas de objetivos: <code>classifica\u00e7\u00e3o de cores, detec\u00e7\u00e3o de m\u00e3os ou detec\u00e7\u00e3o de faces</code>. O sistema deve capturar imagens utilizando uma c\u00e2mera e process\u00e1-las usando a biblioteca OpenCV e/ou Mediapipe. O sistema deve ent\u00e3o comunicar-se com um Arduino via comunica\u00e7\u00e3o serial para realizar tarefas espec\u00edficas com base no objetivo escolhido.</p>"},{"location":"checkpoint/cp3.html#alternativas-de-objetivos","title":"Alternativas de objetivos:","text":"<ul> <li><code>Classifica\u00e7\u00e3o de cores</code>: O sistema dever\u00e1 identificar e classificar objetos de diferentes cores e realizar a\u00e7\u00f5es espec\u00edficas com base na cor identificada.</li> <li><code>Detec\u00e7\u00e3o de m\u00e3os com Mediapipe</code>: O sistema dever\u00e1 detectar m\u00e3os em tempo real e identificar gestos espec\u00edficos, realizando a\u00e7\u00f5es espec\u00edficas com base nos gestos identificados.</li> <li><code>Detec\u00e7\u00e3o de faces</code>: O sistema dever\u00e1 detectar faces em tempo real e realizar a\u00e7\u00f5es espec\u00edficas com base na quantidade de faces detectadas ou nas caracter\u00edsticas faciais (olho aberto/fechado, sorrindo..).</li> </ul>"},{"location":"checkpoint/cp3.html#requisitos-tecnicos","title":"Requisitos t\u00e9cnicos:","text":"<ol> <li>Utiliza\u00e7\u00e3o da linguagem Python para desenvolver a parte de vis\u00e3o computacional.</li> <li>Utiliza\u00e7\u00e3o da biblioteca OpenCV para processar e analisar as imagens.</li> <li>Comunica\u00e7\u00e3o serial entre o sistema de vis\u00e3o computacional em Python e o Arduino.</li> <li>Implementa\u00e7\u00e3o de tarefas espec\u00edficas no Arduino com base na cor do objeto detectado.</li> <li>Documenta\u00e7\u00e3o em reposit\u00f3rio github de forma clara e completa do projeto, incluindo instru\u00e7\u00f5es para replicar o sistema e testes realizados.</li> </ol>"},{"location":"checkpoint/cp3.html#rubrica-de-avaliacao","title":"Rubrica de avalia\u00e7\u00e3o:","text":""},{"location":"checkpoint/cp3.html#funcionalidade-ate-5-pontos","title":"Funcionalidade (at\u00e9 5 pontos)","text":"<ul> <li>O sistema consegue capturar e processar imagens adequadamente.</li> <li>A comunica\u00e7\u00e3o serial entre o Python e o Arduino \u00e9 estabelecida e funciona corretamente.</li> <li>O Arduino realiza as tarefas espec\u00edficas de acordo com o objeto desejado.</li> </ul>"},{"location":"checkpoint/cp3.html#qualidade-do-codigo-ate-2-pontos","title":"Qualidade do c\u00f3digo (at\u00e9 2 pontos)","text":"<ul> <li>O c\u00f3digo \u00e9 bem estruturado e f\u00e1cil de entender.</li> <li>Boas pr\u00e1ticas de programa\u00e7\u00e3o s\u00e3o utilizadas, incluindo coment\u00e1rios, nomes de vari\u00e1veis e fun\u00e7\u00f5es apropriados, facilitando a manuten\u00e7\u00e3o e a compreens\u00e3o.</li> </ul>"},{"location":"checkpoint/cp3.html#documentacao-ate-3-pontos","title":"Documenta\u00e7\u00e3o (at\u00e9 3 pontos)","text":"<ul> <li>A documenta\u00e7\u00e3o do projeto em reposit\u00f3rio github de forma clara e completa, incluindo instru\u00e7\u00f5es para replicar o sistema.</li> <li>Video demonstrando o funcionamento do projeto de forma clara e completa.</li> </ul>"},{"location":"checkpoint/cp4.html","title":"CHECKPOINT 4","text":"<p>Leia com aten\u00e7\u00e3o as instru\u00e7\u00f5es gerais sobre o checkpoint.</p> <ul> <li>O objetivo do checkpoint \u00e9 avaliar sua compreens\u00e3o acerca do conte\u00fado ministrado pela disciplina.</li> </ul>"},{"location":"checkpoint/cp4.html#grupos-e-apresentacao","title":"Grupos e Apresenta\u00e7\u00e3o","text":"<ul> <li>O projeto pode ser realizado individualmente ou por grupos no m\u00e1ximo 5 alunos.</li> <li>A apresenta\u00e7\u00e3o do projeto deve ser realizada no dia program\u00e1tico, ver agenda.</li> </ul>"},{"location":"checkpoint/cp4.html#ideia-geral","title":"Ideia geral","text":""},{"location":"checkpoint/cp4.html#sistema-de-acesso-inteligente-para-ambientes-controlados","title":"Sistema de Acesso Inteligente para Ambientes Controlados","text":"<p>Desenvolver um sistema que controle o acesso a uma \u00e1rea espec\u00edfica (por exemplo, um laborat\u00f3rio, uma sala de servidores ou um armaz\u00e9m) usando RFID para autentica\u00e7\u00e3o e um atuador para liberar ou bloquear a entrada.</p>"},{"location":"checkpoint/cp4.html#funcionamento","title":"Funcionamento:","text":"<ul> <li>O usu\u00e1rio aproxima seu cart\u00e3o RFID do sensor.</li> <li>O Arduino l\u00ea o ID do cart\u00e3o e envia para o Node-RED.</li> <li>O Node-RED verifica em sua base de dados se aquele ID est\u00e1 autorizado a acessar o ambiente.</li> <li>Se autorizado, o Node-RED envia um comando ao Arduino para acionar o atuador, liberando - o acesso. Caso contr\u00e1rio, pode acionar um alarme ou simplesmente negar o acesso.</li> <li>O dashboard mostra em tempo real todas as tentativas de acesso, sejam elas bem-sucedidas ou n\u00e3o. Al\u00e9m disso, permite que um administrador controle manualmente o atuador.</li> </ul> <p>Neste checkpoint, voc\u00eas ir\u00e3o desenvolver o prot\u00f3tipo deste sistema de identifica\u00e7\u00e3o IoT, que em linhas gerais possuir\u00e1 as seguintes interfaces:</p> <p></p>"},{"location":"checkpoint/cp4.html#rubrica","title":"Rubrica","text":"<p>(R1 - NOTA 6) Os requisitos funcionais m\u00ednimos do sistema devem seguir a arquitetura abaixo:</p> <p></p> <p>Para atender a esta rubrica, o sistema est\u00e1 dividido em 2 fluxos: </p> <p>Fluxo 1: Deve ser capaz de coletar a identifica\u00e7\u00e3o da TAG RFID com o Arduino (ARDUINO1) e enviar, utilizando formato JSON, para um fluxo Node-Red que realiza duas fun\u00e7\u00f5es:</p> <ul> <li>Publica em um t\u00f3pico utilizando o protocolo MQTT;</li> <li>Notifica o usu\u00e1rio via outro canal de comunica\u00e7\u00e3o (E-mail, Telegram, Whatsapp, etc...).</li> </ul> <p>Fluxo 2: O fluxo do Node-Red subscreve o t\u00f3pico e exibe o valor da TAG em um DASHBOARD.</p> <ul> <li>Desenvolver um dashboard intuitivo e com boa usabilidade;</li> <li>Exibir em tempo real todas as tentativas de acesso, sejam elas bem-sucedidas ou n\u00e3o.</li> </ul> <p>(R2 - NOTA 7) Os requisitos funcionais m\u00ednimos do sistema devem seguir a imagem abaixo:</p> <p></p> <p>Para atender a esta rubrica, implemente a rubrica R1, e fa\u00e7a a atualiza\u00e7\u00e3o necess\u00e1ria onde o sistema deve se comunicar com o segundo Arduino (ARDUINO2) no formato JSON para realizar o controle de posi\u00e7\u00e3o do servo motor.</p> <ul> <li>A posi\u00e7\u00e3o do servo motor \u00e9 controlada pelo DASHBOARD, ou seja, um administrador controla manualmente o atuador.</li> </ul> <p>(R3 - NOTA 8) Os requisitos funcionais m\u00ednimos do sistema devem seguir a imagem abaixo:</p> <p></p> <ul> <li>Para atender a esta rubrica, implemente a rubrica R2, e o sistema do servidor Node-Red deve estar embarcado na Raspberry PI, sendo capaz de coletar dados do sensor DTH11 (Temperatura e Umidade) a cada 30s. </li> <li>As informa\u00e7\u00f5es do sensor s\u00e3o sempre atualizadas pelo Dashboard e enviadas para o usu\u00e1rio apenas se a umidade estiver abaixo de 50% ou a temperatura estiver acima de 30\u00b0C. Os setpoints de temperatura e umidade s\u00e3o configurados pelo administrador, ou seja, n\u00e3o s\u00e3o <code>hardcode</code>.</li> </ul> <p>(R4 - NOTA 10) Os requisitos funcionais m\u00ednimos do sistema devem seguir a imagem abaixo:</p> <p></p> <p>Para atender a esta rubrica, implemente a rubrica R3, e adicione a integra\u00e7\u00e3o com algum banco de dados e implementa\u00e7\u00e3o mobile (o grupo define a linguagem de programa\u00e7\u00e3o).</p> <p>(BONUS - 2 pontos ) MVP do projeto:</p> <p>Desenvolva uma caixa para acomodar os hardware do projeto, que pode ser desenvolvida pelo MakerLab utilizando a impressora 3D ou MDF cortado no laser.</p> <p></p> <ul> <li>Caixa: Utilize o site https://www.festi.info/boxes.py/ para criar uma caixa personalizada para o seu prot\u00f3tipo, de forma simples, online e gratuita.</li> </ul> <p>Links \u00fateis para criar seu case:</p> <ul> <li>Manual do Mundo</li> <li>Angelo Conti</li> <li>Maker Space 307</li> <li>Smoke &amp; Mirrors</li> </ul> <ul> <li>Especifica\u00e7\u00f5es para M\u00e1quina CNC: Selecione a espessura de 3mm para o MDF.</li> </ul>"},{"location":"checkpoint/cp5-arduino.html","title":"CHECKPOINT 4","text":"<ul> <li>O CP ser\u00e1 realizado em aula, de forma individual. </li> <li>A data de aplica\u00e7\u00e3o est\u00e1 dispon\u00edvel no site, em agenda.</li> </ul>"},{"location":"checkpoint/cp5-arduino.html#conteudo-do-cp","title":"Conte\u00fado do CP","text":"<ul> <li>Conceitos de Programa\u00e7\u00e3o C para arduino</li> <li>Conceitos de Eletrica e Eletr\u00f4nica</li> </ul>"},{"location":"checkpoint/cp6.html","title":"CHECKPOINT 6","text":""},{"location":"checkpoint/cp6.html#cp6-em-breve","title":"CP6 - Em breve","text":"<p>Individual em aula.</p> <p>4SIA - 06/11 4SIR - 07/11</p>"},{"location":"instalacao/index.html","title":"Instru\u00e7\u00f5es para Instala\u00e7\u00e3o da Infraestrutura","text":""},{"location":"instalacao/index.html#1-arduino-ide-windows-linux-macos","title":"1. Arduino IDE (Windows / Linux / macOS)","text":"<ol> <li>Acesse o site oficial do Arduino: https://www.arduino.cc </li> <li>Fa\u00e7a o download da vers\u00e3o compat\u00edvel com o seu sistema operacional.  </li> <li>Instale a IDE seguindo as instru\u00e7\u00f5es fornecidas pelo instalador.</li> </ol>"},{"location":"instalacao/index.html#2-simuladores-de-arduino","title":"2. Simuladores de Arduino","text":"<ul> <li>Wokwi: https://wokwi.com/ </li> <li>crie uma conta gratuita.</li> </ul>"},{"location":"instalacao/index.html#3-instalacao-do-python-3x","title":"3. Instala\u00e7\u00e3o do Python 3.x","text":""},{"location":"instalacao/index.html#windows","title":"Windows","text":"<ol> <li>Acesse: https://www.python.org/downloads/ </li> <li>Baixe o instalador da vers\u00e3o 3.x.  </li> <li>Importante: marque a op\u00e7\u00e3o <code>Add Python to PATH</code> durante a instala\u00e7\u00e3o.  </li> </ol>"},{"location":"instalacao/index.html#linux-macos","title":"Linux / macOS","text":"<ul> <li>O Python 3.x j\u00e1 vem pr\u00e9-instalado na maioria das distribui\u00e7\u00f5es e vers\u00f5es.  </li> <li>Para instalar pacotes, utilize o terminal: <pre><code>pip3 install &lt;nome_do_pacote&gt;\n</code></pre></li> </ul>"},{"location":"instalacao/index.html#alternativa-anaconda","title":"Alternativa \u2013 Anaconda","text":"<p>Se preferir, \u00e9 poss\u00edvel utilizar o Anaconda para gerenciar ambientes virtuais.</p> <ol> <li>Instale o Anaconda.</li> <li>Crie um ambiente virtual e instale os pacotes necess\u00e1rios.</li> </ol>"},{"location":"instalacao/index.html#pacotes-necessarios","title":"Pacotes Necess\u00e1rios","text":"<p>Com o Python configurado, abra o terminal (Linux/macOS) ou Prompt de Comando (Windows) e execute:</p> <pre><code>pip install opencv-python \npip install matplotlib pandas numpy\npip install notebook\npip install scikit-learn tensorflow\n</code></pre>"}]}