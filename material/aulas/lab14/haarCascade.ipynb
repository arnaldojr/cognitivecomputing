{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Objetivos da aula:**\n",
    "\n",
    "*   apresentar uma introdução sobre aprendizado de máquina\n",
    "*   apresentar e aplicar o haar cascade para detecção de face\n",
    "*   apresentar uma intuição do algoritimo de Viola Jones\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Como fazer a deteção de faces?**\n",
    "\n",
    "O nosso objetivo hoje é compreender a essencia de algoritimos para detecção facial, apenas reforçando que já sabemos, esses algoritmos são utilizados para diversas aplicações, desde a lendaria camera tekpix, passando por smartphones e o google fotos para classificador na organização de pastas por pessoas, por exemplo. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Aprendizado de máquina**\n",
    "\n",
    "Antes de entrar em tecnicas mais avançadas de Deep Learning em visão computacional, vamos introduzir este tema estudando e aplicando o método muito clássico de classificação em cascata de faces desenvolvido por Viola e Jones, na OpenCV temos exemplares pré-treinados para detecção de faces e de olhos.\n",
    "\n",
    "\n",
    "**Classificador Haar-Cascade **\n",
    "\n",
    "Você vai ver em todo e qualquer curso ou livro de visão computacional o detector de face de Viola-Jones sendo mencionado. Inventado em 2001, foi disruptivo no campo da visão computacional, por que finalmente permitiu a detecção e o reconhecimento de rostos em tempo real. \n",
    "\n",
    "Muito obrigado Viola e Jones :)\n",
    "\n",
    "ref: https://www.cs.cmu.edu/~efros/courses/LBMV07/Papers/viola-cvpr-01.pdf\n",
    "https://docs.opencv.org/master/db/d28/tutorial_cascade_classifier.html\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para apresentar uma intuição de como funciona, vamos imaginar o seguinte:\n",
    "\n",
    "Algumas caracteristicas do rosto são bem definidas e conseguimos correlacionar tais como bochecha com olhos, testa com nariz.... Para encontrar essas correlações usamos a ideia de feature e convolução que ja estudamos. Podemos visualizar essa técnica no gif da Lena.\n",
    "\n",
    "<img1 src=\"acumulador.jpg\">\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "<img src=\"lena-viola-jones.gif\">\n",
    "\n",
    "ref. https://vimeo.com/12774628\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementação na OpenCV\n",
    "\n",
    "\n",
    "Vamos implementar um detector de face baseado em haar cascade, como essa técnica é baseada em machine learning, vamos utilizar uma rede com os pesos do classificador treinado e dispoiniblizado pela OpenCV. \n",
    "\n",
    "Já temos esses arquivos com os pesos das redes quando instalamos a OpenCV, o que temos que fazer é carregar esses pesos.\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Os pesos estão no diretorio:  C:\\Users\\junior\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\cv2\\data\\haarcascade_frontalface_default.xml\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import cv2\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "#caminho onde estão os pesos\n",
    "path = cv2.data.haarcascades + \"haarcascade_frontalface_default.xml\"\n",
    "\n",
    "# Inicializa o classificador cascade\n",
    "face = cv2.CascadeClassifier(path) \n",
    "\n",
    "print(\"Os pesos estão no diretorio: \", path) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Desafio 1 \n",
    "\n",
    "Pode acontecer de não encontrar o caminho do diretorio com os pesos. Como sugetão, verifique se ja possui os arquivos de pesos. Caso não encontre, será necessário fazer o download desses pesos. Para facilitar a vida, na pasta ***cascade*** já estão os pesos note que são varios arquivos. Faça os ajustes necessários para carregar os pesos da rede. \n",
    "\n",
    "vamos usar o **\"haarcascade_frontalface_default.xml\"**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Faça aqui os ajustes que forem necessários.....\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O método detectMultiScale() realiza o processo de varredura que vimos no gif acima e retorna uma lista com as faces encontrardas.\n",
    "\n",
    "Este possui 3 parametros principais;\n",
    "\n",
    "    gray image – Imagem de entrada na escala de cinza.\n",
    "    scaleFactor – Parametro para ajustar a escala, em uma imagem pode conter rostos maiores e menores. Esse parametro tenta corrigir isso.\n",
    "    minNeighbors – Este parâmetro especifica o número de vizinhos que uma janela deve ter para ser chamado de face. \n",
    "    \n",
    "Você pode ler mais sobre isso aqui. https://docs.opencv.org/2.4.13.2/modules/objdetect/doc/cascade_classification.html#cv2.CascadeClassifier.detectMultiScale\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Faces encontradas:  1 <class 'numpy.ndarray'> [[224 210 156 156]]\n",
      "\n",
      "x: 224\n",
      "y: 224\n",
      "x e y, representam a coodenada top esquerda da face detectada\n",
      "\n",
      "Largura : 224\n",
      "Altura: 224\n"
     ]
    }
   ],
   "source": [
    "img = cv2.imread('lena.png')\n",
    "img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# O método detectMultiScale() realiza o processo de varredura que vimos no gif acima e retorna uma lista com as faces encontrardas.\n",
    "\n",
    "faces_return = face.detectMultiScale(img_gray, scaleFactor = 1.2, minNeighbors = 5)\n",
    "\n",
    "\n",
    "print('Faces encontradas: ', len(faces_return),type(faces_return), faces_return)\n",
    "print(\"\")\n",
    "print(\"x:\", faces_return[0][0])\n",
    "print(\"y:\", faces_return[0][0])\n",
    "print(\"x e y, representam a coodenada top esquerda da face detectada\")\n",
    "print(\"\")\n",
    "print(\"Largura :\", faces_return[0][0])\n",
    "print(\"Altura:\", faces_return[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['x' 'y' 'largura' 'altura']]\n",
      "posição (x,y):  x y largura:  largura altura altura\n"
     ]
    }
   ],
   "source": [
    "## Dica rápida de python\n",
    "\n",
    "#Podemos iterar varias listas ao mesmo tempo dentro de um unico *for* de forma simultanea usando o python\n",
    "\n",
    "# Exemplo, vamos criar uma lista qualquer \n",
    "\n",
    "a = np.array([[\"x\", \"y\", \"largura\", \"altura\"]])\n",
    "\n",
    "print (a)\n",
    "for (x,y,w,h) in a:\n",
    "    print(\"posição (x,y): \", x,y, \"largura: \", w, \"altura\",h)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Desafio 2\n",
    "\n",
    "Usando as posições da lista *face_return*. Implemente uma função que desenha um um retangulo sobre a face detectada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    # Implemente sua solução aqui.....\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Desafio 3\n",
    "\n",
    "Vamos aproveitar que temos as coodenadas da face e vamos lembrar como faz um crop (recorte ) desta imagem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    # Implemente sua solução aqui.....\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Desafio 4\n",
    "\n",
    "Faça a deteção dos olhos da Lena, carrege os pesos que correspodem a detecção de olhos e implemente sua solução. \n",
    "\n",
    "Dica: Os olhos fazem parte da face, nesse sentido, não é necessário fazer a varredura em toda a imagem, basta fazer a varredura dentro dos limites onde está contida a face, concorda???\n",
    "\n",
    "<img src=\"lena-eye-face.png\">\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# implemente aqui sua sulução.............\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Desafio 5\n",
    "\n",
    "No inicio da aula falamos que o método de Viola-Jones foi desruptivo por que tornou capaz a detecção de faces em tempo real. \n",
    "Implemente um código .py que realiza a deteção em tempo real, capturando a imagem da sua webcam.\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Visão_Computacional_Aula_13.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
