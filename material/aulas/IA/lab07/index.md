# Sua Primeira Rede Neural com TensorFlow: Reconhecendo D√≠gitos!

Chegou a hora de sair da teoria e colocar a m√£o na massa! Nesta aula pr√°tica, voc√™ vai construir sua primeira rede neural do zero usando **TensorFlow** ‚Äî uma das bibliotecas mais populares para Deep Learning no mundo.

Nosso desafio √© ensinar um computador a reconhecer d√≠gitos manuscritos, usando o famoso dataset **MNIST**. √â como ensinar uma crian√ßa a ler n√∫meros, mas em vez de mostrar flashcards, vamos mostrar milhares de exemplos para a m√°quina aprender os padr√µes!

![](mnist-samples.png)

**Por que o MNIST √© perfeito para come√ßar?**
- S√£o **60.000 imagens** de treino (muito dados para aprender!)
- Imagens pequenas (**28x28 pixels**) ‚Äî r√°pido de processar
- Problema **bem definido**: 10 classes (d√≠gitos 0-9)
- √â o "Hello World" do Deep Learning ‚Äî se funcionar aqui, voc√™ entendeu os conceitos!

## Preparando o ambiente

Primeiro, vamos garantir que voc√™ tem as ferramentas certas. O TensorFlow √© como uma caixa de ferramentas cheia de componentes pr√©-constru√≠dos para redes neurais:

```bash
pip install tensorflow
```

Agora crie um novo notebook Jupyter ‚Äî vai ser nosso laborat√≥rio de experimentos!


## Carregando os dados: o combust√≠vel da IA

Toda rede neural precisa de dados para aprender, assim como voc√™ precisa de exemplos para aprender matem√°tica. O TensorFlow j√° vem com o MNIST "de f√°brica" ‚Äî que conveni√™ncia!

**O que estamos fazendo aqui:**
1. **Carregamos o dataset** direto da biblioteca do TensorFlow
2. **Separamos** em treino (para ensinar) e teste (para avaliar)
3. **Normalizamos** os pixels de 0-255 para 0-1 (redes neurais gostam de n√∫meros pequenos!)

```python
import tensorflow as tf

# Carregando o conjunto de dados MNIST - como abrir um livro de exerc√≠cios
mnist = tf.keras.datasets.mnist
(x_train, y_train), (x_test, y_test) = mnist.load_data()

# Normalizando os dados - convertendo de 0-255 para 0-1
# √â como ajustar o volume do r√°dio para o n√≠vel ideal
x_train, x_test = x_train / 255.0, x_test / 255.0

print(f"Dados de treino: {x_train.shape}")
print(f"R√≥tulos de treino: {y_train.shape}")
print(f"Dados de teste: {x_test.shape}")
print(f"R√≥tulos de teste: {y_test.shape}")
```

<?quiz?>
question: Por que normalizamos os pixels das imagens de 0-255 para 0-1?
answer: Para economizar espa√ßo de armazenamento
answer: Porque o TensorFlow exige essa convers√£o
answer-correct: Porque redes neurais aprendem melhor com valores pequenos e padronizados
answer: Para acelerar o download dos dados
content:

A normaliza√ß√£o ajuda a rede neural a convergir mais rapidamente durante o treinamento, evitando que valores grandes dominem o processo de aprendizado e garantindo estabilidade num√©rica.
<?/quiz?>


## Construindo nossa rede neural: como montar um Lego inteligente

Agora vem a parte divertida ‚Äî vamos construir nossa rede neural como se fosse um Lego gigante! O TensorFlow nos d√° pe√ßas pr√©-fabricadas que podemos empilhar para criar nossa "m√°quina de reconhecer d√≠gitos".

### Os blocos fundamentais

**üß± Sequential**: Nossa "base" ‚Äî uma pilha simples onde cada camada se conecta √† pr√≥xima
**üîÑ Flatten**: O "achatador" ‚Äî transforma a imagem 28x28 em uma linha de 784 n√∫meros  
**üß† Dense**: As "camadas pensantes" ‚Äî onde a m√°gica acontece!

### Configurando os hiperpar√¢metros

Antes de construir, voc√™ precisa tomar algumas decis√µes importantes:

**Para as camadas ocultas:**
- **Quantos neur√¥nios?** Comece com 128 ou 256 ‚Äî √© um bom meio-termo
- **Qual ativa√ß√£o?** Use `'relu'` ‚Äî ela √© r√°pida e eficiente

**Para a camada de sa√≠da:**
- **Quantos neur√¥nios?** 10 (um para cada d√≠gito: 0, 1, 2... 9)
- **Qual ativa√ß√£o?** Use `'softmax'` ‚Äî transforma sa√≠das em probabilidades

```python
# Construindo nossa rede neural - como montar um rob√¥ inteligente!
model = tf.keras.models.Sequential([
    # Camada 1: Achatar a imagem 28x28 em um vetor de 784 elementos
    tf.keras.layers.Flatten(input_shape=(28, 28)),
    
    # Camada 2: Primeira camada "pensante" com 128 neur√¥nios
    tf.keras.layers.Dense(128, activation='relu'),
    
    # Camada 3: Segunda camada "pensante" com 64 neur√¥nios
    tf.keras.layers.Dense(64, activation='relu'),
    
    # Camada 4: Sa√≠da final - 10 neur√¥nios para 10 d√≠gitos
    tf.keras.layers.Dense(10, activation='softmax')
])

# Vendo nossa cria√ß√£o
model.summary()
```

<?quiz?>
question: Por que usamos a fun√ß√£o de ativa√ß√£o 'softmax' na camada de sa√≠da?
answer: Porque √© mais r√°pida que outras fun√ß√µes
answer: Para reduzir o overfitting
answer-correct: Para converter as sa√≠das em probabilidades que somam 1
answer: Para acelerar o treinamento
content:

Softmax transforma os valores de sa√≠da em probabilidades v√°lidas (entre 0 e 1) que somam 1, permitindo interpretar qual d√≠gito √© mais prov√°vel de ser a resposta correta.
<?/quiz?>

## Configurando o c√©rebro: compila√ß√£o do modelo

Agora que constru√≠mos nossa rede, precisamos ensin√°-la como aprender! √â como configurar os "instintos" de aprendizado da nossa IA. Precisamos definir tr√™s componentes essenciais:

**üéØ Otimizador**: Como a rede ajusta seus pesos (o "professor")
**üìä Fun√ß√£o de perda**: Como medir o qu√£o errada est√° a resposta
**üìà M√©tricas**: O que queremos acompanhar durante o treino

```python
# Configurando como nossa rede vai aprender
model.compile(
    optimizer='adam',                    # Adam: otimizador inteligente que adapta a velocidade
    loss='sparse_categorical_crossentropy',  # Para classifica√ß√£o com n√∫meros inteiros
    metrics=['accuracy']                 # Queremos acompanhar a precis√£o
)

print("Modelo configurado e pronto para treinar! üöÄ")
```

**Por que essas escolhas?**
- **Adam**: √â como um professor experiente que sabe quando ir devagar e quando acelerar
- **sparse_categorical_crossentropy**: Perfeito quando nossos r√≥tulos s√£o n√∫meros (0, 1, 2... 9)
- **accuracy**: A m√©trica mais intuitiva ‚Äî quantos % acertamos?

<?quiz?>
question: Qual √© a fun√ß√£o do otimizador em uma rede neural?
answer: Definir a arquitetura da rede
answer: Calcular a fun√ß√£o de perda
answer-correct: Controlar como os pesos s√£o ajustados durante o treinamento
answer: Normalizar os dados de entrada
content:

O otimizador √© respons√°vel por ajustar os pesos da rede neural baseado nos gradientes calculados, determinando a dire√ß√£o e magnitude das mudan√ßas para minimizar a fun√ß√£o de perda.
<?/quiz?>

## Hora do treino: ensinando nossa IA a reconhecer d√≠gitos!

Este √© o momento mais emocionante ‚Äî vamos colocar nossa rede para aprender! √â como matricular um aluno em uma escola intensiva onde ele vai ver milhares de exemplos de d√≠gitos manuscritos.

**O que vai acontecer:**
- A rede vai ver cada imagem e tentar adivinhar o d√≠gito
- Quando errar, vai ajustar seus "neur√¥nios" para melhorar
- Vai repetir isso por **30 √©pocas** (30 vezes todo o dataset)
- 20% dos dados ficam separados para **valida√ß√£o** (como um teste surpresa!)

```python
import matplotlib.pyplot as plt

# Come√ßando o treinamento - prepare a pipoca! üçø
print("Iniciando treinamento... Isso pode demorar alguns minutos!")

history = model.fit(
    x_train, y_train,           # Dados de treino (professor e aluno)
    epochs=30,                  # 30 "aulas" completas
    validation_split=0.2,       # 20% para teste durante o treino
    verbose=1                   # Mostrar progresso na tela
)

print("Treinamento conclu√≠do! üéâ")
```

**O que significam os n√∫meros que aparecem:**
- **loss**: Qu√£o "confusa" est√° a rede (menor = melhor)
- **accuracy**: % de acertos (maior = melhor)  
- **val_loss** e **val_accuracy**: Mesmas m√©tricas nos dados de valida√ß√£o

<?quiz?>
question: Por que separamos parte dos dados para valida√ß√£o durante o treinamento?
answer: Para acelerar o processo de treinamento
answer: Para economizar mem√≥ria do computador
answer-correct: Para monitorar se a rede est√° generalizando bem ou apenas decorando
answer: Para reduzir o tamanho do dataset
content:

A valida√ß√£o nos permite detectar overfitting - se a acur√°cia de treino sobe mas a de valida√ß√£o estagnar ou cair, significa que a rede est√° "decorando" em vez de aprender padr√µes gerais.
<?/quiz?>

## Visualizando o progresso: os gr√°ficos que contam a hist√≥ria

N√∫meros s√£o legais, mas gr√°ficos s√£o muito mais divertidos! Vamos transformar o hist√≥rico de treinamento em visualiza√ß√µes que mostram como nossa IA evoluiu a cada √©poca.

```python
import pandas as pd
import matplotlib.pyplot as plt

# Transformando o hist√≥rico em um DataFrame para an√°lise
df_historico = pd.DataFrame(history.history)
print("M√©tricas dispon√≠veis:", df_historico.columns.tolist())
df_historico.head()

# Criando gr√°ficos informativos
fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))

# Gr√°fico 1: Evolu√ß√£o da Loss (erro)
ax1.plot(df_historico['loss'], label='Treino', linewidth=2)
ax1.plot(df_historico['val_loss'], label='Valida√ß√£o', linewidth=2)
ax1.set_title('Evolu√ß√£o da Loss ao Longo do Treino')
ax1.set_xlabel('√âpocas')
ax1.set_ylabel('Loss')
ax1.legend()
ax1.grid(True, alpha=0.3)

# Gr√°fico 2: Evolu√ß√£o da Acur√°cia
ax2.plot(df_historico['accuracy'], label='Treino', linewidth=2)
ax2.plot(df_historico['val_accuracy'], label='Valida√ß√£o', linewidth=2)
ax2.set_title('Evolu√ß√£o da Acur√°cia ao Longo do Treino')
ax2.set_xlabel('√âpocas')
ax2.set_ylabel('Acur√°cia')
ax2.legend()
ax2.grid(True, alpha=0.3)

plt.tight_layout()
plt.show()

# Resumo final dos resultados
print(f"\nüìä RESUMO DO TREINAMENTO:")
print(f"‚úÖ Acur√°cia final (treino): {df_historico['accuracy'].iloc[-1]:.3f}")
print(f"‚úÖ Acur√°cia final (valida√ß√£o): {df_historico['val_accuracy'].iloc[-1]:.3f}")
print(f"üìâ Loss final (treino): {df_historico['loss'].iloc[-1]:.3f}")
print(f"üìâ Loss final (valida√ß√£o): {df_historico['val_loss'].iloc[-1]:.3f}")
```

**Como interpretar os gr√°ficos:**
- **Curvas descendentes de loss**: Nossa rede est√° aprendendo! ‚¨áÔ∏è
- **Curvas ascendentes de acur√°cia**: Cada vez mais certeira! ‚¨ÜÔ∏è
- **Linhas pr√≥ximas**: Sem overfitting ‚Äî √≥timo sinal! ‚úÖ
- **Linhas distantes**: Poss√≠vel overfitting ‚Äî precisa investigar üîç

## O momento da verdade: testando nossa IA

Chegou a hora do exame final! Vamos ver como nossa rede se sai com dados que ela **nunca viu antes**. √â como fazer uma prova ap√≥s estudar ‚Äî vamos descobrir se ela realmente aprendeu ou apenas decorou!

```python
# Avalia√ß√£o no conjunto de teste - o momento da verdade! 
print("üéØ Testando a rede neural com dados nunca vistos...")

test_loss, test_accuracy = model.evaluate(x_test, y_test, verbose=0)

print(f"\nüìã RESULTADOS FINAIS:")
print(f"üéØ Acur√°cia no teste: {test_accuracy:.3f} ({test_accuracy*100:.1f}%)")
print(f"üìâ Loss no teste: {test_loss:.3f}")

# Interpretando os resultados
if test_accuracy > 0.95:
    print("üèÜ EXCELENTE! Sua rede √© um verdadeiro especialista em d√≠gitos!")
elif test_accuracy > 0.90:
    print("üëç MUITO BOM! Sua rede est√° bem treinada!")
elif test_accuracy > 0.80:
    print("üòä BOM! H√° espa√ßo para melhorias, mas est√° no caminho certo!")
else:
    print("üîß Precisa de ajustes! Tente mais √©pocas ou ajustar a arquitetura.")
```

<?quiz?>
question: Por que √© importante avaliar o modelo em um conjunto de teste separado?
answer: Para acelerar o processo de avalia√ß√£o
answer: Para economizar recursos computacionais
answer-correct: Para verificar se o modelo generaliza bem para dados n√£o vistos durante o treinamento
answer: Para comparar diferentes arquiteturas de rede
content:

O conjunto de teste simula dados do "mundo real" que o modelo nunca viu, permitindo uma avalia√ß√£o honesta da capacidade de generaliza√ß√£o da rede neural.
<?/quiz?>

## Salvando nossa cria√ß√£o: preservando o conhecimento

Parab√©ns! Voc√™ acabou de treinar uma rede neural funcional! Agora vamos salv√°-la para usar depois ‚Äî afinal, n√£o queremos perder todo esse aprendizado.

```python
# Salvando nossa rede neural treinada - como arquivar um diploma! 
model.save('mnist_mlp_model.h5')
print("‚úÖ Modelo salvo como 'mnist_mlp_model.h5'")
print("üéì Sua IA agora √© persistente e pode ser usada a qualquer momento!")

# Informa√ß√µes sobre o arquivo salvo
import os
file_size = os.path.getsize('mnist_mlp_model.h5') / (1024 * 1024)  # MB
print(f"üìÅ Tamanho do arquivo: {file_size:.2f} MB")
```

**O que cont√©m o arquivo .h5:**
- üß† **Arquitetura completa** da rede (camadas, neur√¥nios, conex√µes)
- ‚öñÔ∏è **Todos os pesos** aprendidos durante o treinamento  
- ‚öôÔ∏è **Configura√ß√µes** de compila√ß√£o (otimizador, loss, m√©tricas)
- üìä **Estado interno** para continuar o treinamento se necess√°rio

## Testando com suas pr√≥prias imagens: o momento m√°gico!

Agora vem a parte mais legal ‚Äî vamos testar nossa IA com imagens que **voc√™** criou! √â como mostrar um desenho para um amigo e perguntar "que n√∫mero √© este?"

### Preparando uma imagem personalizada

Para que funcione perfeitamente, sua imagem precisa seguir o "padr√£o MNIST":
- ‚úèÔ∏è **Fundo branco, n√∫mero preto** (ou vice-versa)
- üìê **Formato quadrado** (ser√° redimensionada para 28x28)
- üé® **Escala de cinza** (sem cores)
- ‚úã **N√∫mero manuscrito** bem centralizado

```python
import tensorflow as tf
from tensorflow.keras.preprocessing import image
import numpy as np
import matplotlib.pyplot as plt

# Carregando nossa IA treinada
print("ü§ñ Carregando a IA especialista em d√≠gitos...")
model = tf.keras.models.load_model('mnist_mlp_model.h5')
print("‚úÖ IA carregada e pronta para reconhecer seus desenhos!")

def preparar_imagem_personalizada(caminho_arquivo):
    """
    Prepara uma imagem personalizada para ser reconhecida pela IA
    """
    # Carregando e redimensionando para 28x28 pixels em escala de cinza
    img = image.load_img(caminho_arquivo, color_mode='grayscale', target_size=(28, 28))
    
    # Convertendo para array numpy
    img_array = image.img_to_array(img)
    img_array = img_array.reshape(1, 28, 28)  # Formato que a rede espera
    
    # Normalizando para 0-1 (mesmo que no treinamento)
    img_array = img_array.astype('float32') / 255.0
    
    return img_array

def reconhecer_digito(caminho_arquivo):
    """
    Fun√ß√£o completa para reconhecer um d√≠gito em uma imagem
    """
    try:
        # Preparando a imagem
        img_preparada = preparar_imagem_personalizada(caminho_arquivo)
        
        # Fazendo a previs√£o
        predicoes = model.predict(img_preparada, verbose=0)
        digito_previsto = np.argmax(predicoes)
        confianca = np.max(predicoes) * 100
        
        # Mostrando o resultado
        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4))
        
        # Imagem original
        ax1.imshow(img_preparada.reshape(28, 28), cmap='gray')
        ax1.set_title(f'Sua imagem (28x28 pixels)')
        ax1.axis('off')
        
        # Gr√°fico de probabilidades
        ax2.bar(range(10), predicoes[0])
        ax2.set_title(f'Previs√£o: {digito_previsto} (Confian√ßa: {confianca:.1f}%)')
        ax2.set_xlabel('D√≠gitos')
        ax2.set_ylabel('Probabilidade')
        ax2.set_xticks(range(10))
        
        plt.tight_layout()
        plt.show()
        
        # Mensagem personalizada baseada na confian√ßa
        if confianca > 90:
            print(f"üéØ CERTEZA ABSOLUTA: √â um {digito_previsto}! (Confian√ßa: {confianca:.1f}%)")
        elif confianca > 70:
            print(f"ü§î PROV√ÅVEL: Parece ser um {digito_previsto} (Confian√ßa: {confianca:.1f}%)")
        else:
            print(f"ü§∑ INCERTO: Talvez seja um {digito_previsto}? (Confian√ßa: {confianca:.1f}%)")
            print("üí° Dica: Tente uma imagem com tra√ßos mais n√≠tidos!")
            
        return digito_previsto, confianca
        
    except Exception as e:
        print(f"‚ùå Erro: {e}")
        print("üí° Verifique se o caminho da imagem est√° correto!")
        return None, 0

# Exemplo de uso - substitua pelo caminho da sua imagem
caminho_da_sua_imagem = 'seu_numero.png'  # ‚Üê Coloque aqui o caminho da sua imagem!

# Testando com sua imagem
print("üß™ Testando IA com sua imagem personalizada...")
digito, confianca = reconhecer_digito(caminho_da_sua_imagem)
```

<?quiz?>
question: Por que a imagem precisa ser convertida para 28x28 pixels e normalizada?
answer: Para economizar espa√ßo de armazenamento
answer: Para acelerar o processamento da GPU
answer-correct: Para manter o mesmo formato dos dados usados no treinamento
answer: Para melhorar a qualidade visual da imagem
content:

A rede neural foi treinada com imagens 28x28 normalizadas, ent√£o qualquer nova imagem deve passar pelo mesmo pr√©-processamento para que a IA possa interpret√°-la corretamente.
<?/quiz?>
